Entirely remove hadoop-yarn-server-globalpolicygenerator

From: Lars Francke <git@lars-francke.de>


---
 hadoop-project/pom.xml                             |    6 
 .../pom.xml                                        |  148 --------
 .../server/globalpolicygenerator/GPGContext.java   |   40 --
 .../globalpolicygenerator/GPGContextImpl.java      |   63 ---
 .../globalpolicygenerator/GPGPolicyFacade.java     |  229 ------------
 .../server/globalpolicygenerator/GPGUtils.java     |  150 --------
 .../GlobalPolicyGenerator.java                     |  386 --------------------
 .../applicationcleaner/ApplicationCleaner.java     |  160 --------
 .../DefaultApplicationCleaner.java                 |   96 -----
 .../applicationcleaner/package-info.java           |   19 -
 .../server/globalpolicygenerator/package-info.java |   19 -
 .../policygenerator/GlobalPolicy.java              |   78 ----
 .../policygenerator/LoadBasedGlobalPolicy.java     |  329 -----------------
 .../policygenerator/NoOpGlobalPolicy.java          |   36 --
 .../policygenerator/PolicyGenerator.java           |  267 --------------
 .../UniformWeightedLocalityGlobalPolicy.java       |   68 ---
 .../policygenerator/package-info.java              |   24 -
 .../subclustercleaner/SubClusterCleaner.java       |  113 ------
 .../subclustercleaner/package-info.java            |   19 -
 .../webapp/GPGController.java                      |   49 ---
 .../webapp/GPGOverviewBlock.java                   |   88 ----
 .../webapp/GPGOverviewPage.java                    |   52 ---
 .../webapp/GPGPoliciesBlock.java                   |  110 ------
 .../webapp/GPGPoliciesPage.java                    |   55 ---
 .../globalpolicygenerator/webapp/GPGWebApp.java    |   47 --
 .../webapp/GPGWebServices.java                     |   62 ---
 .../globalpolicygenerator/webapp/NavBlock.java     |   43 --
 .../globalpolicygenerator/webapp/dao/GpgInfo.java  |   81 ----
 .../webapp/dao/package-info.java                   |   19 -
 .../globalpolicygenerator/webapp/package-info.java |   24 -
 .../globalpolicygenerator/TestGPGPolicyFacade.java |  356 ------------------
 .../TestGlobalPolicyGenerator.java                 |   86 ----
 .../TestDefaultApplicationCleaner.java             |  204 ----------
 .../policygenerator/TestLoadBasedGlobalPolicy.java |  206 -----------
 .../policygenerator/TestPolicyGenerator.java       |  392 --------------------
 .../secure/AbstractGlobalPolicyGeneratorTest.java  |  177 ---------
 .../secure/TestGpgSecureLogins.java                |   50 ---
 .../subclustercleaner/TestSubClusterCleaner.java   |  121 ------
 .../webapp/TestGPGWebApp.java                      |   51 ---
 .../webapp/TestGPGWebServices.java                 |   96 -----
 .../src/test/resources/schedulerInfo1.json         |  134 -------
 .../src/test/resources/schedulerInfo2.json         |  196 ----------
 .../hadoop-yarn/hadoop-yarn-server/pom.xml         |    1 
 hadoop-yarn-project/pom.xml                        |    4 
 44 files changed, 4954 deletions(-)
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/pom.xml
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GPGContext.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GPGContextImpl.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GPGPolicyFacade.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GPGUtils.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GlobalPolicyGenerator.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/applicationcleaner/ApplicationCleaner.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/applicationcleaner/DefaultApplicationCleaner.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/applicationcleaner/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/GlobalPolicy.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/LoadBasedGlobalPolicy.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/NoOpGlobalPolicy.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/PolicyGenerator.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/UniformWeightedLocalityGlobalPolicy.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/subclustercleaner/SubClusterCleaner.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/subclustercleaner/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGController.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGOverviewBlock.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGOverviewPage.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGPoliciesBlock.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGPoliciesPage.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGWebApp.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGWebServices.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/NavBlock.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/dao/GpgInfo.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/dao/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/TestGPGPolicyFacade.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/TestGlobalPolicyGenerator.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/applicationcleaner/TestDefaultApplicationCleaner.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/TestLoadBasedGlobalPolicy.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/TestPolicyGenerator.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/secure/AbstractGlobalPolicyGeneratorTest.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/secure/TestGpgSecureLogins.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/subclustercleaner/TestSubClusterCleaner.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/TestGPGWebApp.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/TestGPGWebServices.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/resources/schedulerInfo1.json
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/resources/schedulerInfo2.json

diff --git a/hadoop-project/pom.xml b/hadoop-project/pom.xml
index d365a5c70da..4cb65cf3741 100644
--- a/hadoop-project/pom.xml
+++ b/hadoop-project/pom.xml
@@ -568,12 +568,6 @@
         <version>${hadoop.version}</version>
       </dependency>
 
-      <dependency>
-        <groupId>org.apache.hadoop</groupId>
-        <artifactId>hadoop-yarn-server-globalpolicygenerator</artifactId>
-        <version>${project.version}</version>
-      </dependency>
-
       <dependency>
         <groupId>org.apache.hadoop</groupId>
          <artifactId>hadoop-mapreduce-client-jobclient</artifactId>
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/pom.xml b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/pom.xml
deleted file mode 100644
index d7b7b5cdd1e..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/pom.xml
+++ /dev/null
@@ -1,148 +0,0 @@
-<?xml version="1.0"?>
-<!--
-  Licensed under the Apache License, Version 2.0 (the "License");
-  you may not use this file except in compliance with the License.
-  You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License. See accompanying LICENSE file.
--->
-<project xmlns="http://maven.apache.org/POM/4.0.0"
-  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
-  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0
-                      http://maven.apache.org/xsd/maven-4.0.0.xsd">
-  <parent>
-    <artifactId>hadoop-yarn-server</artifactId>
-    <groupId>org.apache.hadoop</groupId>
-    <version>3.4.0</version>
-  </parent>
-  <modelVersion>4.0.0</modelVersion>
-  <groupId>org.apache.hadoop</groupId>
-  <artifactId>hadoop-yarn-server-globalpolicygenerator</artifactId>
-  <version>3.4.0</version>
-  <name>Apache Hadoop YARN GlobalPolicyGenerator</name>
-
-  <properties>
-    <!-- Needed for generating FindBugs warnings using parent pom -->
-    <yarn.basedir>${project.parent.parent.basedir}</yarn.basedir>
-  </properties>
-
-  <dependencies>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-server-common</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-common</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-api</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-common</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-common</artifactId>
-      <type>test-jar</type>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-server-timelineservice</artifactId>
-      <scope>provided</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-server-resourcemanager</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>junit</groupId>
-      <artifactId>junit</artifactId>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.mockito</groupId>
-      <artifactId>mockito-all</artifactId>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-server-common</artifactId>
-      <type>test-jar</type>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-common</artifactId>
-      <type>test-jar</type>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.hsqldb</groupId>
-      <artifactId>hsqldb</artifactId>
-      <scope>test</scope>
-      <classifier>jdk8</classifier>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-minikdc</artifactId>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-auth</artifactId>
-      <scope>test</scope>
-      <type>test-jar</type>
-    </dependency>
-
-    <dependency>
-      <groupId>com.sun.jersey.jersey-test-framework</groupId>
-      <artifactId>jersey-test-framework-core</artifactId>
-      <scope>test</scope>
-    </dependency>
-    <dependency>
-      <groupId>com.sun.jersey.jersey-test-framework</groupId>
-      <artifactId>jersey-test-framework-grizzly2</artifactId>
-      <scope>test</scope>
-    </dependency>
-
-  </dependencies>
-
-  <build>
-    <plugins>
-      <plugin>
-        <groupId>org.apache.rat</groupId>
-        <artifactId>apache-rat-plugin</artifactId>
-        <configuration>
-          <excludes>
-            <exclude>src/test/resources/schedulerInfo1.json</exclude>
-            <exclude>src/test/resources/schedulerInfo2.json</exclude>
-          </excludes>
-        </configuration>
-      </plugin>
-    </plugins>
-  </build>
-</project>
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GPGContext.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GPGContext.java
deleted file mode 100644
index e54244d7133..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GPGContext.java
+++ /dev/null
@@ -1,40 +0,0 @@
-/**
- *  Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator;
-
-import org.apache.hadoop.yarn.server.federation.utils.FederationRegistryClient;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-
-/**
- * Context for Global Policy Generator.
- */
-public interface GPGContext {
-
-  FederationStateStoreFacade getStateStoreFacade();
-
-  void setStateStoreFacade(FederationStateStoreFacade facade);
-
-  GPGPolicyFacade getPolicyFacade();
-
-  void setPolicyFacade(GPGPolicyFacade facade);
-
-  FederationRegistryClient getRegistryClient();
-
-  void setRegistryClient(FederationRegistryClient client);
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GPGContextImpl.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GPGContextImpl.java
deleted file mode 100644
index b14f5029901..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GPGContextImpl.java
+++ /dev/null
@@ -1,63 +0,0 @@
-/**
- *  Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator;
-
-import org.apache.hadoop.yarn.server.federation.utils.FederationRegistryClient;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-
-/**
- * Context implementation for Global Policy Generator.
- */
-public class GPGContextImpl implements GPGContext {
-
-  private FederationStateStoreFacade facade;
-  private GPGPolicyFacade policyFacade;
-  private FederationRegistryClient registryClient;
-
-  @Override
-  public FederationStateStoreFacade getStateStoreFacade() {
-    return facade;
-  }
-
-  @Override
-  public void setStateStoreFacade(
-      FederationStateStoreFacade federationStateStoreFacade) {
-    this.facade = federationStateStoreFacade;
-  }
-
-  @Override
-  public GPGPolicyFacade getPolicyFacade(){
-    return policyFacade;
-  }
-
-  @Override
-  public void setPolicyFacade(GPGPolicyFacade gpgPolicyfacade){
-    policyFacade = gpgPolicyfacade;
-  }
-
-  @Override
-  public FederationRegistryClient getRegistryClient() {
-    return registryClient;
-  }
-
-  @Override
-  public void setRegistryClient(FederationRegistryClient client) {
-    registryClient = client;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GPGPolicyFacade.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GPGPolicyFacade.java
deleted file mode 100644
index 78ce60c621b..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GPGPolicyFacade.java
+++ /dev/null
@@ -1,229 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with this
- * work for additional information regarding copyright ownership.  The ASF
- * licenses this file to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance with the License.
- * You may obtain a copy of the License at
- *
- * http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
- * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
- * License for the specific language governing permissions and limitations under
- * the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.federation.policies.FederationPolicyUtils;
-import org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo;
-import org.apache.hadoop.yarn.server.federation.policies.router.FederationRouterPolicy;
-import org.apache.hadoop.yarn.server.federation.policies.amrmproxy.FederationAMRMProxyPolicy;
-import org.apache.hadoop.yarn.server.federation.policies.exceptions.FederationPolicyInitializationException;
-import org.apache.hadoop.yarn.server.federation.policies.manager.FederationPolicyManager;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.nio.ByteBuffer;
-import java.util.HashMap;
-import java.util.Map;
-
-/**
- * A utility class for the GPG Policy Generator to read and write policies
- * into the FederationStateStore. Policy specific logic is abstracted away in
- * this class, so the PolicyGenerator can avoid dealing with policy
- * construction, reinitialization, and serialization.
- *
- * There are only two exposed methods:
- *
- * {@link #getPolicyManager(String)}
- * Gets the PolicyManager via queue name. Null if there is no policy
- * configured for the specified queue. The PolicyManager can be used to
- * extract the {@link FederationRouterPolicy} and
- * {@link FederationAMRMProxyPolicy}, as well as any policy specific parameters
- *
- * {@link #setPolicyManager(FederationPolicyManager)}
- * Sets the PolicyManager. If the policy configuration is the same, no change
- * occurs. Otherwise, the internal cache is updated and the new configuration
- * is written into the FederationStateStore
- *
- * This class assumes that the GPG is the only service
- * writing policies. Thus, the only FederationStateStore reads occur the first
- * time a queue policy is retrieved - after that, the GPG only writes to the
- * FederationStateStore.
- *
- * The class uses a PolicyManager cache and a SubClusterPolicyConfiguration
- * cache. The primary use for these caches are to serve reads, and to
- * identify when the PolicyGenerator has actually changed the policy
- * so unnecessary FederationStateStore policy writes can be avoided.
- */
-
-public class GPGPolicyFacade {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(GPGPolicyFacade.class);
-
-  private FederationStateStoreFacade stateStore;
-
-  private Map<String, FederationPolicyManager> policyManagerMap;
-  private Map<String, SubClusterPolicyConfiguration> policyConfMap;
-
-  private boolean readOnly;
-
-  public GPGPolicyFacade(FederationStateStoreFacade stateStore,
-      Configuration conf) {
-    this.stateStore = stateStore;
-    this.policyManagerMap = new HashMap<>();
-    this.policyConfMap = new HashMap<>();
-    this.readOnly =
-        conf.getBoolean(YarnConfiguration.GPG_POLICY_GENERATOR_READONLY,
-            YarnConfiguration.DEFAULT_GPG_POLICY_GENERATOR_READONLY);
-  }
-
-  /**
-   * Provides a utility for the policy generator to read the policy manager
-   * from the FederationStateStore. Because the policy generator should be the
-   * only component updating the policy, this implementation does not use the
-   * reinitialization feature.
-   *
-   * @param queueName the name of the queue we want the policy manager for.
-   * @return the policy manager responsible for the queue policy.
-   * @throws YarnException exceptions from yarn servers.
-   */
-  public FederationPolicyManager getPolicyManager(String queueName)
-      throws YarnException {
-    FederationPolicyManager policyManager = policyManagerMap.get(queueName);
-
-    // If we don't have the policy manager cached, pull configuration
-    // from the FederationStateStore to create and cache it
-    if (policyManager == null) {
-      try {
-
-        // If we don't have the configuration cached, pull it
-        // from the stateStore
-        SubClusterPolicyConfiguration conf = policyConfMap.get(queueName);
-
-        if (conf == null) {
-          conf = stateStore.getPolicyConfiguration(queueName);
-        }
-
-        // If configuration is still null, it does not exist in the
-        // FederationStateStore
-        if (conf == null) {
-          LOG.info("Read null policy for queue {}.", queueName);
-          return null;
-        }
-
-        // Generate PolicyManager based on PolicyManagerType.
-        String policyManagerType = conf.getType();
-        policyManager = FederationPolicyUtils.instantiatePolicyManager(policyManagerType);
-        policyManager.setQueue(queueName);
-
-        // If PolicyManager supports Weighted PolicyInfo, it means that
-        // we need to use this parameter to determine which sub-cluster the router goes to
-        // or which sub-cluster the container goes to.
-        if (policyManager.isSupportWeightedPolicyInfo()) {
-          ByteBuffer weightedPolicyInfoParams = conf.getParams();
-          if (weightedPolicyInfoParams == null) {
-            LOG.warn("Warning: Queue = {}, FederationPolicyManager {} WeightedPolicyInfo is empty.",
-                queueName, policyManagerType);
-            return null;
-          }
-          WeightedPolicyInfo weightedPolicyInfo =
-              WeightedPolicyInfo.fromByteBuffer(conf.getParams());
-          policyManager.setWeightedPolicyInfo(weightedPolicyInfo);
-        } else {
-          LOG.warn("Warning: FederationPolicyManager of unsupported WeightedPolicyInfo type {}, " +
-              "initialization may be incomplete.", policyManager.getClass());
-        }
-
-        policyManagerMap.put(queueName, policyManager);
-        policyConfMap.put(queueName, conf);
-      } catch (YarnException e) {
-        LOG.error("Error reading SubClusterPolicyConfiguration from state "
-            + "store for queue: {}", queueName);
-        throw e;
-      }
-    }
-    return policyManager;
-  }
-
-  /**
-   * Provides a utility for the policy generator to write a policy manager
-   * into the FederationStateStore. The facade keeps a cache and will only write
-   * into the FederationStateStore if the policy configuration has changed.
-   *
-   * @param policyManager The policy manager we want to update into the state
-   *                      store. It contains policy information as well as
-   *                      the queue name we will update for.
-   * @throws YarnException  exceptions from yarn servers.
-   */
-  public void setPolicyManager(FederationPolicyManager policyManager)
-      throws YarnException {
-    if (policyManager == null) {
-      LOG.warn("Attempting to set null policy manager");
-      return;
-    }
-    // Extract the configuration from the policy manager
-    String queue = policyManager.getQueue();
-    SubClusterPolicyConfiguration conf;
-    try {
-      conf = policyManager.serializeConf();
-    } catch (FederationPolicyInitializationException e) {
-      LOG.warn("Error serializing policy for queue {}", queue);
-      throw e;
-    }
-    if (conf == null) {
-      // State store does not currently support setting a policy back to null
-      // because it reads the queue name to set from the policy!
-      LOG.warn("Skip setting policy to null for queue {} into state store",
-          queue);
-      return;
-    }
-    // Compare with configuration cache, if different, write the conf into
-    // store and update our conf and manager cache
-    if (!confCacheEqual(queue, conf)) {
-      try {
-        if (readOnly) {
-          LOG.info("[read-only] Skipping policy update for queue {}", queue);
-          return;
-        }
-        LOG.info("Updating policy for queue {} into state store", queue);
-        stateStore.setPolicyConfiguration(conf);
-        policyConfMap.put(queue, conf);
-        policyManagerMap.put(queue, policyManager);
-      } catch (YarnException e) {
-        LOG.warn("Error writing SubClusterPolicyConfiguration to state "
-            + "store for queue: {}", queue);
-        throw e;
-      }
-    } else {
-      LOG.info("Setting unchanged policy - state store write skipped");
-    }
-  }
-
-  /**
-   * @param queue the queue to check the cached policy configuration for
-   * @param conf the new policy configuration
-   * @return whether or not the conf is equal to the cached conf
-   */
-  private boolean confCacheEqual(String queue,
-      SubClusterPolicyConfiguration conf) {
-    SubClusterPolicyConfiguration cachedConf = policyConfMap.get(queue);
-    if (conf == null && cachedConf == null) {
-      return true;
-    } else if (conf != null && cachedConf != null) {
-      if (conf.equals(cachedConf)) {
-        return true;
-      }
-    }
-    return false;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GPGUtils.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GPGUtils.java
deleted file mode 100644
index 13e1a8a0127..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GPGUtils.java
+++ /dev/null
@@ -1,150 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator;
-
-import static javax.servlet.http.HttpServletResponse.SC_OK;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.RM_WEB_SERVICE_PATH;
-import static org.apache.hadoop.yarn.webapp.util.WebAppUtils.HTTPS_PREFIX;
-import static org.apache.hadoop.yarn.webapp.util.WebAppUtils.HTTP_PREFIX;
-
-import java.net.InetSocketAddress;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.Set;
-import java.util.concurrent.TimeUnit;
-
-import javax.ws.rs.core.MediaType;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.net.NetUtils;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterIdInfo;
-
-import com.sun.jersey.api.client.Client;
-import com.sun.jersey.api.client.ClientResponse;
-import com.sun.jersey.api.client.WebResource;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts;
-
-/**
- * GPGUtils contains utility functions for the GPG.
- *
- */
-public final class GPGUtils {
-
-  // hide constructor
-  private GPGUtils() {
-  }
-
-  /**
-   * Performs an invocation of the remote RMWebService.
-   *
-   * @param <T> Generic T.
-   * @param webAddr WebAddress.
-   * @param path url path.
-   * @param returnType return type.
-   * @param selectParam query parameters.
-   * @param conf configuration.
-   * @return response entity.
-   */
-  public static <T> T invokeRMWebService(String webAddr, String path, final Class<T> returnType,
-      Configuration conf, String selectParam) {
-    Client client = createJerseyClient(conf);
-    T obj;
-
-    // webAddr stores the form of host:port in subClusterInfo
-    InetSocketAddress socketAddress = NetUtils
-        .getConnectAddress(NetUtils.createSocketAddr(webAddr));
-    String scheme = YarnConfiguration.useHttps(conf) ? HTTPS_PREFIX : HTTP_PREFIX;
-    String webAddress = scheme + socketAddress.getHostName() + ":" + socketAddress.getPort();
-    WebResource webResource = client.resource(webAddress);
-
-    if (selectParam != null) {
-      webResource = webResource.queryParam(RMWSConsts.DESELECTS, selectParam);
-    }
-
-    ClientResponse response = null;
-    try {
-      response = webResource.path(RM_WEB_SERVICE_PATH).path(path)
-          .accept(MediaType.APPLICATION_XML).get(ClientResponse.class);
-      if (response.getStatus() == SC_OK) {
-        obj = response.getEntity(returnType);
-      } else {
-        throw new YarnRuntimeException(
-            "Bad response from remote web service: " + response.getStatus());
-      }
-      return obj;
-    } finally {
-      if (response != null) {
-        response.close();
-        response = null;
-      }
-      client.destroy();
-    }
-  }
-
-  /**
-   * Performs an invocation of the remote RMWebService.
-   *
-   * @param <T> Generic T.
-   * @param webAddr WebAddress.
-   * @param path url path.
-   * @param returnType return type.
-   * @param config configuration.
-   * @return response entity.
-   */
-  public static <T> T invokeRMWebService(String webAddr,
-      String path, final Class<T> returnType, Configuration config) {
-    return invokeRMWebService(webAddr, path, returnType, config, null);
-  }
-
-  /**
-   * Creates a uniform weighting of 1.0 for each sub cluster.
-   *
-   * @param ids subClusterId set
-   * @return weight of subCluster.
-   */
-  public static Map<SubClusterIdInfo, Float> createUniformWeights(
-      Set<SubClusterId> ids) {
-    Map<SubClusterIdInfo, Float> weights = new HashMap<>();
-    for(SubClusterId id : ids) {
-      weights.put(new SubClusterIdInfo(id), 1.0f);
-    }
-    return weights;
-  }
-
-  /**
-   * Create JerseyClient based on configuration file.
-   * We will set the timeout when creating JerseyClient.
-   *
-   * @param conf Configuration.
-   * @return JerseyClient.
-   */
-  public static Client createJerseyClient(Configuration conf) {
-    Client client = Client.create();
-    int connectTimeOut = (int) conf.getTimeDuration(YarnConfiguration.GPG_WEBAPP_CONNECT_TIMEOUT,
-        YarnConfiguration.DEFAULT_GPG_WEBAPP_CONNECT_TIMEOUT, TimeUnit.MILLISECONDS);
-    client.setConnectTimeout(connectTimeOut);
-    int readTimeout = (int) conf.getTimeDuration(YarnConfiguration.GPG_WEBAPP_READ_TIMEOUT,
-        YarnConfiguration.DEFAULT_GPG_WEBAPP_READ_TIMEOUT, TimeUnit.MILLISECONDS);
-    client.setReadTimeout(readTimeout);
-    return client;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GlobalPolicyGenerator.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GlobalPolicyGenerator.java
deleted file mode 100644
index a3e231da1a3..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/GlobalPolicyGenerator.java
+++ /dev/null
@@ -1,386 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator;
-
-import java.io.IOException;
-import java.io.PrintStream;
-import java.net.InetAddress;
-import java.net.UnknownHostException;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.concurrent.ScheduledThreadPoolExecutor;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.atomic.AtomicBoolean;
-
-import org.apache.commons.lang.time.DurationFormatUtils;
-import org.apache.hadoop.classification.VisibleForTesting;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.metrics2.lib.DefaultMetricsSystem;
-import org.apache.hadoop.metrics2.source.JvmMetrics;
-import org.apache.hadoop.security.AuthenticationFilterInitializer;
-import org.apache.hadoop.security.HttpCrossOriginFilterInitializer;
-import org.apache.hadoop.security.SecurityUtil;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.registry.client.api.RegistryOperations;
-import org.apache.hadoop.service.CompositeService;
-import org.apache.hadoop.util.GenericOptionsParser;
-import org.apache.hadoop.util.JvmPauseMonitor;
-import org.apache.hadoop.util.ShutdownHookManager;
-import org.apache.hadoop.util.StringUtils;
-import org.apache.hadoop.yarn.YarnUncaughtExceptionHandler;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.federation.utils.FederationRegistryClient;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.applicationcleaner.ApplicationCleaner;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.policygenerator.PolicyGenerator;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.subclustercleaner.SubClusterCleaner;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.webapp.GPGWebApp;
-import org.apache.hadoop.yarn.webapp.WebApp;
-import org.apache.hadoop.yarn.webapp.WebApps;
-import org.apache.hadoop.yarn.webapp.util.WebAppUtils;
-import org.apache.hadoop.yarn.webapp.util.WebServiceClient;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * Global Policy Generator (GPG) is a Yarn Federation component. By tuning the
- * Federation policies in Federation State Store, GPG overlooks the entire
- * federated cluster and ensures that the system is tuned and balanced all the
- * time.
- *
- * The GPG operates continuously but out-of-band from all cluster operations,
- * that allows to enforce global invariants, affect load balancing, trigger
- * draining of sub-clusters that will undergo maintenance, etc.
- */
-public class GlobalPolicyGenerator extends CompositeService {
-
-  public static final Logger LOG =
-      LoggerFactory.getLogger(GlobalPolicyGenerator.class);
-
-  // YARN Variables
-  private static CompositeServiceShutdownHook gpgShutdownHook;
-  public static final int SHUTDOWN_HOOK_PRIORITY = 30;
-  private AtomicBoolean isStopping = new AtomicBoolean(false);
-  private static final String METRICS_NAME = "Global Policy Generator";
-  private static long gpgStartupTime = System.currentTimeMillis();
-
-  // Federation Variables
-  private GPGContext gpgContext;
-  private RegistryOperations registry;
-
-  // Scheduler service that runs tasks periodically
-  private ScheduledThreadPoolExecutor scheduledExecutorService;
-  private SubClusterCleaner subClusterCleaner;
-  private ApplicationCleaner applicationCleaner;
-  private PolicyGenerator policyGenerator;
-  private String webAppAddress;
-  private JvmPauseMonitor pauseMonitor;
-  private WebApp webApp;
-
-  public GlobalPolicyGenerator() {
-    super(GlobalPolicyGenerator.class.getName());
-    this.gpgContext = new GPGContextImpl();
-  }
-
-  protected void doSecureLogin() throws IOException {
-    Configuration config = getConfig();
-    SecurityUtil.login(config, YarnConfiguration.GPG_KEYTAB,
-        YarnConfiguration.GPG_PRINCIPAL, getHostName(config));
-  }
-
-  protected void initAndStart(Configuration conf, boolean hasToReboot) {
-    // Remove the old hook if we are rebooting.
-    if (hasToReboot && null != gpgShutdownHook) {
-      ShutdownHookManager.get().removeShutdownHook(gpgShutdownHook);
-    }
-    gpgShutdownHook = new CompositeServiceShutdownHook(this);
-    ShutdownHookManager.get().addShutdownHook(gpgShutdownHook,
-        SHUTDOWN_HOOK_PRIORITY);
-    this.init(conf);
-    this.start();
-  }
-
-  @Override
-  protected void serviceInit(Configuration conf) throws Exception {
-    UserGroupInformation.setConfiguration(conf);
-    // Set up the context
-    this.gpgContext.setStateStoreFacade(FederationStateStoreFacade.getInstance(conf));
-    GPGPolicyFacade gpgPolicyFacade =
-        new GPGPolicyFacade(this.gpgContext.getStateStoreFacade(), conf);
-    this.gpgContext.setPolicyFacade(gpgPolicyFacade);
-
-    this.registry = FederationStateStoreFacade.createInstance(conf,
-        YarnConfiguration.YARN_REGISTRY_CLASS,
-        YarnConfiguration.DEFAULT_YARN_REGISTRY_CLASS,
-        RegistryOperations.class);
-    this.registry.init(conf);
-
-    UserGroupInformation user = UserGroupInformation.getCurrentUser();
-    FederationRegistryClient registryClient =
-        new FederationRegistryClient(conf, this.registry, user);
-    this.gpgContext.setRegistryClient(registryClient);
-
-    this.scheduledExecutorService = new ScheduledThreadPoolExecutor(
-        conf.getInt(YarnConfiguration.GPG_SCHEDULED_EXECUTOR_THREADS,
-            YarnConfiguration.DEFAULT_GPG_SCHEDULED_EXECUTOR_THREADS));
-    this.subClusterCleaner = new SubClusterCleaner(conf, this.gpgContext);
-
-    this.applicationCleaner = FederationStateStoreFacade.createInstance(conf,
-        YarnConfiguration.GPG_APPCLEANER_CLASS,
-        YarnConfiguration.DEFAULT_GPG_APPCLEANER_CLASS, ApplicationCleaner.class);
-    this.applicationCleaner.init(conf, this.gpgContext);
-
-    this.policyGenerator = new PolicyGenerator(conf, this.gpgContext);
-
-    this.webAppAddress = WebAppUtils.getGPGWebAppURLWithoutScheme(conf);
-    DefaultMetricsSystem.initialize(METRICS_NAME);
-    JvmMetrics jm = JvmMetrics.initSingleton("GPG", null);
-    pauseMonitor = new JvmPauseMonitor();
-    addService(pauseMonitor);
-    jm.setPauseMonitor(pauseMonitor);
-
-    // super.serviceInit after all services are added
-    super.serviceInit(conf);
-    WebServiceClient.initialize(conf);
-  }
-
-  @Override
-  protected void serviceStart() throws Exception {
-    try {
-      doSecureLogin();
-    } catch (IOException e) {
-      throw new YarnRuntimeException("Failed GPG login", e);
-    }
-
-    super.serviceStart();
-
-    this.registry.start();
-
-    // Schedule SubClusterCleaner service
-    Configuration config = getConfig();
-    long scCleanerIntervalMs = config.getTimeDuration(
-        YarnConfiguration.GPG_SUBCLUSTER_CLEANER_INTERVAL_MS,
-        YarnConfiguration.DEFAULT_GPG_SUBCLUSTER_CLEANER_INTERVAL_MS, TimeUnit.MILLISECONDS);
-    if (scCleanerIntervalMs > 0) {
-      this.scheduledExecutorService.scheduleAtFixedRate(this.subClusterCleaner,
-          0, scCleanerIntervalMs, TimeUnit.MILLISECONDS);
-      LOG.info("Scheduled sub-cluster cleaner with interval: {}",
-          DurationFormatUtils.formatDurationISO(scCleanerIntervalMs));
-    }
-
-    // Schedule ApplicationCleaner service
-    long appCleanerIntervalMs = config.getTimeDuration(
-        YarnConfiguration.GPG_APPCLEANER_INTERVAL_MS,
-        YarnConfiguration.DEFAULT_GPG_APPCLEANER_INTERVAL_MS, TimeUnit.MILLISECONDS);
-
-    if (appCleanerIntervalMs > 0) {
-      this.scheduledExecutorService.scheduleAtFixedRate(this.applicationCleaner,
-          0, appCleanerIntervalMs, TimeUnit.MILLISECONDS);
-      LOG.info("Scheduled application cleaner with interval: {}",
-          DurationFormatUtils.formatDurationISO(appCleanerIntervalMs));
-    }
-
-    // Schedule PolicyGenerator
-    // We recommend using yarn.federation.gpg.policy.generator.interval
-    // instead of yarn.federation.gpg.policy.generator.interval-ms
-
-    // To ensure compatibility,
-    // let's first obtain the value of "yarn.federation.gpg.policy.generator.interval-ms."
-    long policyGeneratorIntervalMillis = 0L;
-    String generatorIntervalMS = config.get(YarnConfiguration.GPG_POLICY_GENERATOR_INTERVAL_MS);
-    if (generatorIntervalMS != null) {
-      LOG.warn("yarn.federation.gpg.policy.generator.interval-ms is deprecated property, " +
-          " we better set it yarn.federation.gpg.policy.generator.interval.");
-      policyGeneratorIntervalMillis = Long.parseLong(generatorIntervalMS);
-    }
-
-    // If it is not available, let's retrieve
-    // the value of "yarn.federation.gpg.policy.generator.interval" instead.
-    if (policyGeneratorIntervalMillis == 0) {
-      policyGeneratorIntervalMillis = config.getTimeDuration(
-          YarnConfiguration.GPG_POLICY_GENERATOR_INTERVAL,
-          YarnConfiguration.DEFAULT_GPG_POLICY_GENERATOR_INTERVAL, TimeUnit.MILLISECONDS);
-    }
-
-    if(policyGeneratorIntervalMillis > 0){
-      this.scheduledExecutorService.scheduleAtFixedRate(this.policyGenerator,
-          0, policyGeneratorIntervalMillis, TimeUnit.MILLISECONDS);
-      LOG.info("Scheduled policy-generator with interval: {}",
-          DurationFormatUtils.formatDurationISO(policyGeneratorIntervalMillis));
-    }
-    startWepApp();
-  }
-
-  @Override
-  protected void serviceStop() throws Exception {
-    if (this.registry != null) {
-      this.registry.stop();
-      this.registry = null;
-    }
-
-    try {
-      if (this.scheduledExecutorService != null
-          && !this.scheduledExecutorService.isShutdown()) {
-        this.scheduledExecutorService.shutdown();
-        LOG.info("Stopped ScheduledExecutorService");
-      }
-    } catch (Exception e) {
-      LOG.error("Failed to shutdown ScheduledExecutorService", e);
-      throw e;
-    }
-
-    if (this.isStopping.getAndSet(true)) {
-      return;
-    }
-    if (webApp != null) {
-      webApp.stop();
-    }
-    DefaultMetricsSystem.shutdown();
-    super.serviceStop();
-    WebServiceClient.destroy();
-  }
-
-  public String getName() {
-    return "FederationGlobalPolicyGenerator";
-  }
-
-  public GPGContext getGPGContext() {
-    return this.gpgContext;
-  }
-
-  @VisibleForTesting
-  public void startWepApp() {
-    Configuration configuration = getConfig();
-
-    boolean enableCors = configuration.getBoolean(YarnConfiguration.GPG_WEBAPP_ENABLE_CORS_FILTER,
-        YarnConfiguration.DEFAULT_GPG_WEBAPP_ENABLE_CORS_FILTER);
-
-    if (enableCors) {
-      configuration.setBoolean(HttpCrossOriginFilterInitializer.PREFIX
-          + HttpCrossOriginFilterInitializer.ENABLED_SUFFIX, true);
-    }
-
-    // Always load pseudo authentication filter to parse "user.name" in an URL
-    // to identify a HTTP request's user.
-    boolean hasHadoopAuthFilterInitializer = false;
-    String filterInitializerConfKey = "hadoop.http.filter.initializers";
-    Class<?>[] initializersClasses = configuration.getClasses(filterInitializerConfKey);
-
-    List<String> targets = new ArrayList<>();
-    if (initializersClasses != null) {
-      for (Class<?> initializer : initializersClasses) {
-        if (initializer.getName().equals(AuthenticationFilterInitializer.class.getName())) {
-          hasHadoopAuthFilterInitializer = true;
-          break;
-        }
-        targets.add(initializer.getName());
-      }
-    }
-    if (!hasHadoopAuthFilterInitializer) {
-      targets.add(AuthenticationFilterInitializer.class.getName());
-      configuration.set(filterInitializerConfKey, StringUtils.join(",", targets));
-    }
-    LOG.info("Instantiating GPGWebApp at {}.", webAppAddress);
-    GPGWebApp gpgWebApp = new GPGWebApp(this);
-    webApp = WebApps.$for("gpg", GPGContext.class, this.gpgContext,
-        "ws").at(webAppAddress).start(gpgWebApp);
-  }
-
-  @SuppressWarnings("resource")
-  public static void startGPG(String[] argv, Configuration conf) {
-    boolean federationEnabled = conf.getBoolean(YarnConfiguration.FEDERATION_ENABLED,
-        YarnConfiguration.DEFAULT_FEDERATION_ENABLED);
-    if (federationEnabled) {
-      Thread.setDefaultUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());
-      StringUtils.startupShutdownMessage(GlobalPolicyGenerator.class, argv, LOG);
-      GlobalPolicyGenerator globalPolicyGenerator = new GlobalPolicyGenerator();
-      globalPolicyGenerator.initAndStart(conf, false);
-    } else {
-      LOG.warn("Federation is not enabled. The gpg cannot start.");
-    }
-  }
-
-  /**
-   * Returns the hostname for this Router. If the hostname is not
-   * explicitly configured in the given config, then it is determined.
-   *
-   * @param config configuration
-   * @return the hostname (NB: may not be a FQDN)
-   * @throws UnknownHostException if the hostname cannot be determined
-   */
-  private String getHostName(Configuration config)
-      throws UnknownHostException {
-    String name = config.get(YarnConfiguration.GPG_KERBEROS_PRINCIPAL_HOSTNAME_KEY);
-    if (name == null) {
-      name = InetAddress.getLocalHost().getHostName();
-    }
-    return name;
-  }
-
-  public static void main(String[] argv) {
-    try {
-      YarnConfiguration conf = new YarnConfiguration();
-      GenericOptionsParser hParser = new GenericOptionsParser(conf, argv);
-      argv = hParser.getRemainingArgs();
-      if (argv.length > 1) {
-        if (argv[0].equals("-format-policy-store")) {
-          handFormatPolicyStateStore(conf);
-        } else {
-          printUsage(System.err);
-        }
-      } else {
-        startGPG(argv, conf);
-      }
-    } catch (Throwable t) {
-      LOG.error("Error starting global policy generator", t);
-      System.exit(-1);
-    }
-  }
-
-  public static long getGPGStartupTime() {
-    return gpgStartupTime;
-  }
-
-  @VisibleForTesting
-  public WebApp getWebApp() {
-    return webApp;
-  }
-
-  private static void printUsage(PrintStream out) {
-    out.println("Usage: yarn gpg [-format-policy-store]");
-  }
-
-  private static void handFormatPolicyStateStore(Configuration conf) {
-    try {
-      System.out.println("Deleting Federation policy state store.");
-      FederationStateStoreFacade facade = FederationStateStoreFacade.getInstance(conf);
-      System.out.println("Federation policy state store has been cleaned.");
-      facade.deleteAllPoliciesConfigurations();
-    } catch (Exception e) {
-      LOG.error("Delete Federation policy state store error.", e);
-      System.err.println("Delete Federation policy state store error, exception = " + e);
-    }
-  }
-
-  @Override
-  public void setConfig(Configuration conf) {
-    super.setConfig(conf);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/applicationcleaner/ApplicationCleaner.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/applicationcleaner/ApplicationCleaner.java
deleted file mode 100644
index 76380af8c98..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/applicationcleaner/ApplicationCleaner.java
+++ /dev/null
@@ -1,160 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator.applicationcleaner;
-
-import java.util.HashSet;
-import java.util.Set;
-
-import org.apache.commons.lang3.time.DurationFormatUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-import org.apache.hadoop.yarn.server.federation.utils.FederationRegistryClient;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GPGContext;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GPGUtils;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.DeSelectFields;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppsInfo;
-import org.apache.hadoop.yarn.webapp.util.WebAppUtils;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * The ApplicationCleaner is a runnable that cleans up old applications from
- * table applicationsHomeSubCluster in FederationStateStore.
- */
-public abstract class ApplicationCleaner implements Runnable {
-  private static final Logger LOG =
-      LoggerFactory.getLogger(ApplicationCleaner.class);
-
-  private Configuration conf;
-  private GPGContext gpgContext;
-  private FederationRegistryClient registryClient;
-
-  private int minRouterSuccessCount;
-  private int maxRouterRetry;
-  private long routerQueryIntevalMillis;
-
-  public void init(Configuration config, GPGContext context)
-      throws YarnException {
-
-    this.gpgContext = context;
-    this.conf = config;
-    this.registryClient = context.getRegistryClient();
-
-    String routerSpecString =
-        this.conf.get(YarnConfiguration.GPG_APPCLEANER_CONTACT_ROUTER_SPEC,
-            YarnConfiguration.DEFAULT_GPG_APPCLEANER_CONTACT_ROUTER_SPEC);
-    String[] specs = routerSpecString.split(",");
-    if (specs.length != 3) {
-      throw new YarnException("Expect three comma separated values in "
-          + YarnConfiguration.GPG_APPCLEANER_CONTACT_ROUTER_SPEC + " but get "
-          + routerSpecString);
-    }
-    this.minRouterSuccessCount = Integer.parseInt(specs[0]);
-    this.maxRouterRetry = Integer.parseInt(specs[1]);
-    this.routerQueryIntevalMillis = Long.parseLong(specs[2]);
-
-    if (this.minRouterSuccessCount > this.maxRouterRetry) {
-      throw new YarnException("minRouterSuccessCount "
-          + this.minRouterSuccessCount
-          + " should not be larger than maxRouterRetry" + this.maxRouterRetry);
-    }
-    if (this.minRouterSuccessCount <= 0) {
-      throw new YarnException("minRouterSuccessCount "
-          + this.minRouterSuccessCount + " should be positive");
-    }
-
-    LOG.info("Initialized AppCleaner with Router query with min success {}, " +
-        "max retry {}, retry interval {}.", this.minRouterSuccessCount,
-        this.maxRouterRetry,
-        DurationFormatUtils.formatDurationISO(this.routerQueryIntevalMillis));
-  }
-
-  public GPGContext getGPGContext() {
-    return this.gpgContext;
-  }
-
-  public FederationRegistryClient getRegistryClient() {
-    return this.registryClient;
-  }
-
-  /**
-   * Query router for applications.
-   *
-   * @return the set of applications
-   * @throws YarnRuntimeException when router call fails
-   */
-  public Set<ApplicationId> getAppsFromRouter() throws YarnRuntimeException {
-    String webAppAddress = WebAppUtils.getRouterWebAppURLWithScheme(conf);
-
-    LOG.info("Contacting router at: {}.", webAppAddress);
-    AppsInfo appsInfo = GPGUtils.invokeRMWebService(webAppAddress, RMWSConsts.APPS,
-        AppsInfo.class, conf, DeSelectFields.DeSelectType.RESOURCE_REQUESTS.toString());
-
-    Set<ApplicationId> appSet = new HashSet<>();
-    for (AppInfo appInfo : appsInfo.getApps()) {
-      appSet.add(ApplicationId.fromString(appInfo.getAppId()));
-    }
-    return appSet;
-  }
-
-  /**
-   * Get the list of known applications in the cluster from Router.
-   *
-   * @return the list of known applications
-   * @throws YarnException if get app fails
-   */
-  public Set<ApplicationId> getRouterKnownApplications() throws YarnException {
-    int successCount = 0, totalAttemptCount = 0;
-    Set<ApplicationId> resultSet = new HashSet<>();
-    while (totalAttemptCount < this.maxRouterRetry) {
-      try {
-        Set<ApplicationId> routerApps = getAppsFromRouter();
-        resultSet.addAll(routerApps);
-        LOG.info("Attempt {}: {} known apps from Router, {} in total",
-            totalAttemptCount, routerApps.size(), resultSet.size());
-
-        successCount++;
-        if (successCount >= this.minRouterSuccessCount) {
-          return resultSet;
-        }
-
-        // Wait for the next attempt
-        try {
-          Thread.sleep(this.routerQueryIntevalMillis);
-        } catch (InterruptedException e) {
-          LOG.warn("Sleep interrupted after attempt {}.", totalAttemptCount);
-        }
-      } catch (Exception e) {
-        LOG.warn("Router query attempt {} failed.", totalAttemptCount, e);
-      } finally {
-        totalAttemptCount++;
-      }
-    }
-    throw new YarnException("Only " + successCount
-        + " success Router queries after " + totalAttemptCount + " retries");
-  }
-
-  @Override
-  public abstract void run();
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/applicationcleaner/DefaultApplicationCleaner.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/applicationcleaner/DefaultApplicationCleaner.java
deleted file mode 100644
index c3f79d0284c..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/applicationcleaner/DefaultApplicationCleaner.java
+++ /dev/null
@@ -1,96 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator.applicationcleaner;
-
-import java.util.Date;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-import java.util.stream.Collectors;
-
-import org.apache.hadoop.util.Sets;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-
-/**
- * The default ApplicationCleaner that cleans up old applications from table
- * applicationsHomeSubCluster in FederationStateStore.
- */
-public class DefaultApplicationCleaner extends ApplicationCleaner {
-  private static final Logger LOG =
-      LoggerFactory.getLogger(DefaultApplicationCleaner.class);
-
-  @Override
-  public void run() {
-    Date now = new Date();
-    LOG.info("Application cleaner run at time {}", now);
-
-    FederationStateStoreFacade facade = getGPGContext().getStateStoreFacade();
-    try {
-      // Get the candidate list from StateStore before calling router
-      Set<ApplicationId> allStateStoreApps = new HashSet<>();
-      List<ApplicationHomeSubCluster> response =
-          facade.getApplicationsHomeSubCluster();
-      for (ApplicationHomeSubCluster app : response) {
-        allStateStoreApps.add(app.getApplicationId());
-      }
-      LOG.info("{} app entries in FederationStateStore", allStateStoreApps.size());
-
-      // Get the candidate list from Registry before calling router
-      List<String> allRegistryApps = getRegistryClient().getAllApplications();
-      LOG.info("{} app entries in FederationRegistry", allStateStoreApps.size());
-
-      // Get the list of known apps from Router
-      Set<ApplicationId> routerApps = getRouterKnownApplications();
-      LOG.info("{} known applications from Router", routerApps.size());
-
-      // Clean up StateStore entries
-      Set<ApplicationId> toDelete =
-          Sets.difference(allStateStoreApps, routerApps);
-
-      LOG.info("Deleting {} applications from statestore", toDelete.size());
-      LOG.debug("Apps to delete: {}.",
-          toDelete.stream().map(Object::toString).collect(Collectors.joining(",")));
-
-      for (ApplicationId appId : toDelete) {
-        try {
-          LOG.debug("Deleting {} from statestore ", appId);
-          facade.deleteApplicationHomeSubCluster(appId);
-        } catch (Exception e) {
-          LOG.error("deleteApplicationHomeSubCluster failed at application {}.", appId, e);
-        }
-      }
-
-      // Clean up Registry entries
-      for (String app : allRegistryApps) {
-        ApplicationId appId = ApplicationId.fromString(app);
-        if (!routerApps.contains(appId)) {
-          LOG.debug("removing finished application entry for {}", app);
-          getRegistryClient().removeAppFromRegistry(appId, true);
-        }
-      }
-    } catch (Throwable e) {
-      LOG.error("Application cleaner started at time {} fails. ", now, e);
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/applicationcleaner/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/applicationcleaner/package-info.java
deleted file mode 100644
index dd302c81f45..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/applicationcleaner/package-info.java
+++ /dev/null
@@ -1,19 +0,0 @@
-/**
- *  Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator.applicationcleaner;
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/package-info.java
deleted file mode 100644
index abaa57c81e0..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/package-info.java
+++ /dev/null
@@ -1,19 +0,0 @@
-/**
- *  Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator;
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/GlobalPolicy.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/GlobalPolicy.java
deleted file mode 100644
index ab60a48434e..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/GlobalPolicy.java
+++ /dev/null
@@ -1,78 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.globalpolicygenerator.policygenerator;
-
-import org.apache.hadoop.conf.Configurable;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.server.federation.policies.manager.FederationPolicyManager;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-
-import java.util.Collections;
-import java.util.Map;
-
-/**
- * This interface defines the plug-able policy that the PolicyGenerator uses
- * to update policies into the state store.
- */
-
-public abstract class GlobalPolicy implements Configurable {
-
-  private Configuration conf;
-
-  @Override
-  public void setConf(Configuration conf) {
-    this.conf = conf;
-  }
-
-  @Override
-  public Configuration getConf() {
-    return conf;
-  }
-
-  /**
-   * Return a map of the object type and RM path to request it from - the
-   * framework will query these paths and provide the objects to the policy.
-   * Delegating this responsibility to the PolicyGenerator enables us to avoid
-   * duplicate calls to the same * endpoints as the GlobalPolicy is invoked
-   * once per queue.
-   *
-   * @return a map of the object type and RM path.
-   */
-  protected Map<Class<?>, String> registerPaths() {
-    // Default register nothing
-    return Collections.emptyMap();
-  }
-
-  /**
-   * Given a queue, cluster metrics, and policy manager, update the policy
-   * to account for the cluster status. This method defines the policy generator
-   * behavior.
-   *
-   * @param queueName   name of the queue
-   * @param clusterInfo subClusterId map to cluster information about the
-   *                    SubCluster used to make policy decisions
-   * @param manager     the FederationPolicyManager for the queue's existing
-   *                    policy the manager may be null, in which case the policy
-   *                    will need to be created
-   * @return policy manager that handles the updated (or created) policy
-   */
-  protected abstract FederationPolicyManager updatePolicy(String queueName,
-      Map<SubClusterId, Map<Class, Object>> clusterInfo,
-      FederationPolicyManager manager);
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/LoadBasedGlobalPolicy.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/LoadBasedGlobalPolicy.java
deleted file mode 100644
index f728b92d71f..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/LoadBasedGlobalPolicy.java
+++ /dev/null
@@ -1,329 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.globalpolicygenerator.policygenerator;
-
-import org.apache.commons.collections.MapUtils;
-import org.apache.hadoop.classification.VisibleForTesting;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-import org.apache.hadoop.yarn.server.federation.policies.manager.FederationPolicyManager;
-import org.apache.hadoop.yarn.server.federation.policies.manager.WeightedLocalityPolicyManager;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterIdInfo;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GPGUtils;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.util.ArrayList;
-import java.util.Comparator;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.FEDERATION_GPG_LOAD_BASED_MIN_PENDING;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.DEFAULT_FEDERATION_GPG_LOAD_BASED_MIN_PENDING;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.FEDERATION_GPG_LOAD_BASED_MAX_PENDING;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.DEFAULT_FEDERATION_GPG_LOAD_BASED_MAX_PENDING;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.FEDERATION_GPG_LOAD_BASED_MIN_WEIGHT;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.DEFAULT_FEDERATION_GPG_LOAD_BASED_MIN_WEIGHT;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.FEDERATION_GPG_LOAD_BASED_MAX_EDIT;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.DEFAULT_FEDERATION_GPG_LOAD_BASED_MAX_EDIT;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.FEDERATION_GPG_LOAD_BASED_SCALING;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.DEFAULT_FEDERATION_GPG_LOAD_BASED_SCALING;
-
-/**
- * Load based policy that generates weighted policies by scaling
- * the cluster load (based on pending) to a weight from 0.0 to 1.0.
- */
-public class LoadBasedGlobalPolicy extends GlobalPolicy {
-
-  private static final Logger LOG = LoggerFactory.getLogger(LoadBasedGlobalPolicy.class);
-
-  public enum Scaling {
-    LINEAR,
-    QUADRATIC,
-    LOG,
-    NONE
-  }
-
-  // Minimum pending count before the policy starts scaling down the weights
-  private int minPending;
-  // Maximum pending count before policy stops scaling down the weights
-  // (they'll be set to min weight)
-  private int maxPending;
-  // Minimum weight that a sub cluster will be assigned
-  private float minWeight;
-  // Maximum number of weights that can be scaled down simultaneously
-  private int maxEdit;
-  // Scaling type
-  private Scaling scaling = Scaling.NONE;
-
-  @Override
-  public void setConf(Configuration conf) {
-    super.setConf(conf);
-    minPending = conf.getInt(FEDERATION_GPG_LOAD_BASED_MIN_PENDING,
-        DEFAULT_FEDERATION_GPG_LOAD_BASED_MIN_PENDING);
-    maxPending = conf.getInt(FEDERATION_GPG_LOAD_BASED_MAX_PENDING,
-        DEFAULT_FEDERATION_GPG_LOAD_BASED_MAX_PENDING);
-    minWeight = conf.getFloat(FEDERATION_GPG_LOAD_BASED_MIN_WEIGHT,
-        DEFAULT_FEDERATION_GPG_LOAD_BASED_MIN_WEIGHT);
-    maxEdit = conf.getInt(FEDERATION_GPG_LOAD_BASED_MAX_EDIT,
-        DEFAULT_FEDERATION_GPG_LOAD_BASED_MAX_EDIT);
-
-    try {
-      scaling = Scaling.valueOf(conf.get(FEDERATION_GPG_LOAD_BASED_SCALING,
-          DEFAULT_FEDERATION_GPG_LOAD_BASED_SCALING));
-    } catch (IllegalArgumentException e) {
-      LOG.warn("Invalid scaling mode provided", e);
-    }
-
-    // Check that all configuration values are valid
-    if (!(minPending <= maxPending)) {
-      throw new YarnRuntimeException("minPending = " + minPending
-          + " must be less than or equal to maxPending=" + maxPending);
-    }
-    if (!(minWeight >= 0 && minWeight < 1)) {
-      throw new YarnRuntimeException(
-          "minWeight = " + minWeight + " must be within range [0,1)");
-    }
-  }
-
-  @Override
-  protected Map<Class<?>, String> registerPaths() {
-    // Register for the endpoints we want to receive information on
-    Map<Class<?>, String> map = new HashMap<>();
-    map.put(ClusterMetricsInfo.class, RMWSConsts.METRICS);
-    return map;
-  }
-
-  /**
-   * Update the policy of the queue.
-   *
-   * @param queueName   name of the queue
-   * @param clusterInfo subClusterId map to cluster information about the
-   *                    SubCluster used to make policy decisions
-   * @param currentManager the FederationPolicyManager for the queue's existing
-   * policy the manager may be null, in which case the policy
-   * will need to be created.
-   *
-   * @return FederationPolicyManager.
-   */
-  @Override
-  protected FederationPolicyManager updatePolicy(String queueName,
-      Map<SubClusterId, Map<Class, Object>> clusterInfo,
-      FederationPolicyManager currentManager) {
-    if (currentManager == null) {
-      LOG.info("Creating load based weighted policy queue {}.", queueName);
-      currentManager = getWeightedLocalityPolicyManager(queueName, clusterInfo);
-    } else if (currentManager instanceof WeightedLocalityPolicyManager) {
-      LOG.info("Updating load based weighted policy queue {}.", queueName);
-      currentManager = getWeightedLocalityPolicyManager(queueName, clusterInfo);
-    } else {
-      LOG.warn("Policy for queue {} is of type {}, expected {}.", queueName,
-          currentManager.getClass(), WeightedLocalityPolicyManager.class);
-    }
-    return currentManager;
-  }
-
-  /**
-   * GPG can help update the policy of the queue.
-   *
-   * We automatically generate the weight of the subCluster
-   * according to the clusterMetrics of the subCluster.
-   *
-   * @param queue queueName.
-   * @param subClusterMetricInfos Metric information of the subCluster.
-   * @return WeightedLocalityPolicyManager.
-   */
-  protected WeightedLocalityPolicyManager getWeightedLocalityPolicyManager(String queue,
-      Map<SubClusterId, Map<Class, Object>> subClusterMetricInfos) {
-
-    // Parse the metric information of the subCluster.
-    Map<SubClusterId, ClusterMetricsInfo> clusterMetrics =
-        getSubClustersMetricsInfo(subClusterMetricInfos);
-
-    if (MapUtils.isEmpty(clusterMetrics)) {
-      return null;
-    }
-
-    // Get the new weight of the subCluster.
-    WeightedLocalityPolicyManager manager = new WeightedLocalityPolicyManager();
-    Map<SubClusterIdInfo, Float> weights = getTargetWeights(clusterMetrics);
-    manager.setQueue(queue);
-    manager.getWeightedPolicyInfo().setAMRMPolicyWeights(weights);
-    manager.getWeightedPolicyInfo().setRouterPolicyWeights(weights);
-    return manager;
-  }
-
-  /**
-   * Get the ClusterMetric information of the subCluster.
-   *
-   * @param subClusterMetricsInfo subCluster Metric Information.
-   * @return Mapping relationship between subCluster and Metric.
-   */
-  protected Map<SubClusterId, ClusterMetricsInfo> getSubClustersMetricsInfo(
-      Map<SubClusterId, Map<Class, Object>> subClusterMetricsInfo) {
-
-    // Check whether the Metric information of the sub-cluster is empty,
-    // if it is empty, we will directly return null.
-    if(MapUtils.isEmpty(subClusterMetricsInfo)) {
-      LOG.warn("The metric info of the subCluster is empty.");
-      return null;
-    }
-
-    Map<SubClusterId, ClusterMetricsInfo> clusterMetrics = new HashMap<>();
-    for (Map.Entry<SubClusterId, Map<Class, Object>> entry : subClusterMetricsInfo.entrySet()) {
-      SubClusterId subClusterId = entry.getKey();
-      Map<Class, Object> subClusterMetrics = entry.getValue();
-      ClusterMetricsInfo clusterMetricsInfo = (ClusterMetricsInfo)
-          subClusterMetrics.getOrDefault(ClusterMetricsInfo.class, null);
-      clusterMetrics.put(subClusterId, clusterMetricsInfo);
-    }
-
-    // return subCluster Metric Information.
-    return clusterMetrics;
-  }
-
-  /**
-   * Get subCluster target weight.
-   *
-   * @param clusterMetrics Metric of the subCluster.
-   * @return subCluster Weights.
-   */
-  @VisibleForTesting
-  protected Map<SubClusterIdInfo, Float> getTargetWeights(
-      Map<SubClusterId, ClusterMetricsInfo> clusterMetrics) {
-    Map<SubClusterIdInfo, Float> weights = GPGUtils.createUniformWeights(clusterMetrics.keySet());
-
-    List<SubClusterId> scs = new ArrayList<>(clusterMetrics.keySet());
-    // Sort the sub clusters into descending order based on pending load
-    scs.sort(new SortByDescendingLoad(clusterMetrics));
-
-    // Keep the top N loaded sub clusters
-    scs = scs.subList(0, Math.min(maxEdit, scs.size()));
-
-    for (SubClusterId sc : scs) {
-      LOG.info("Updating weight for sub cluster {}", sc.toString());
-      int pending = clusterMetrics.get(sc).getAppsPending();
-      if (pending <= minPending) {
-        LOG.info("Load ({}) is lower than minimum ({}), skipping", pending, minPending);
-      } else if (pending < maxPending) {
-        // The different scaling strategies should all map values from the
-        // range min_pending+1 to max_pending to the range min_weight to 1.0f
-        // so we pre-process and simplify the domain to some value [1, MAX-MIN)
-        int val = pending - minPending;
-        int maxVal = maxPending - minPending;
-
-        // Scale the weights to respect the config minimum
-        float weight = getWeightByScaling(maxVal, val);
-        weight = weight * (1.0f - minWeight);
-        weight += minWeight;
-        weights.put(new SubClusterIdInfo(sc), weight);
-        LOG.info("Load ({}) is within maximum ({}), setting weights via {} "
-            + "scale to {}", pending, maxPending, scaling, weight);
-      } else {
-        weights.put(new SubClusterIdInfo(sc), minWeight);
-        LOG.info("Load ({}) exceeded maximum ({}), setting weight to minimum: {}",
-            pending, maxPending, minWeight);
-      }
-    }
-    validateWeights(weights);
-    return weights;
-  }
-
-  /**
-   * Get weight information.
-   * We will calculate the weight information according to different Scaling.
-   *
-   * NONE: No calculation is required, and the weight is 1 at this time.
-   *
-   * LINEAR: For linear computation, we will use (maxPendingVal - curPendingVal) / (maxPendingVal).
-   *
-   * QUADRATIC: Calculated using quadratic,
-   * We will calculate quadratic for maxPendingVal, curPendingVal,
-   * then use this formula = (maxPendingVal - curPendingVal) / (maxPendingVal).
-   *
-   * LOG(LOGARITHM): Calculated using logarithm,
-   * We will calculate logarithm for maxPendingVal, curPendingVal,
-   * then use this formula = (maxPendingVal - curPendingVal) / (maxPendingVal).
-   *
-   * @param maxPendingVal maxPending - minPending
-   * @param curPendingVal pending - minPending
-   * @return Calculated weight information.
-   */
-  protected float getWeightByScaling(int maxPendingVal, int curPendingVal) {
-    float weight = 1.0f;
-    switch (scaling) {
-    case NONE:
-      break;
-    case LINEAR:
-      weight = (float) (maxPendingVal - curPendingVal) / (float) (maxPendingVal);
-      break;
-    case QUADRATIC:
-      double maxValQuad = Math.pow(maxPendingVal, 2);
-      double valQuad = Math.pow(curPendingVal, 2);
-      weight = (float) (maxValQuad - valQuad) / (float) (maxValQuad);
-      break;
-    case LOG:
-      double maxValLog = Math.log(maxPendingVal);
-      double valLog = Math.log(curPendingVal);
-      weight = (float) (maxValLog - valLog) / (float) (maxValLog);
-      break;
-    default:
-      LOG.warn("No suitable scaling found, Skip.");
-      break;
-    }
-    return weight;
-  }
-
-  /**
-   * Helper to avoid all zero weights. If weights are all zero, they're reset
-   * to one
-   * @param weights weights to validate
-   */
-  private void validateWeights(Map<SubClusterIdInfo, Float> weights) {
-    for(Float w : weights.values()) {
-      // If we find a nonzero weight, we're validated
-      if(w > 0.0f) {
-        return;
-      }
-    }
-    LOG.warn("All {} generated weights were 0.0f. Resetting to 1.0f.", weights.size());
-    // All weights were zero. Reset all back to 1.0
-    weights.replaceAll((i, v) -> 1.0f);
-  }
-
-  private static final class SortByDescendingLoad
-      implements Comparator<SubClusterId> {
-
-    private Map<SubClusterId, ClusterMetricsInfo> clusterMetrics;
-
-    private SortByDescendingLoad(
-        Map<SubClusterId, ClusterMetricsInfo> clusterMetrics) {
-      this.clusterMetrics = clusterMetrics;
-    }
-
-    public int compare(SubClusterId a, SubClusterId b) {
-      // Sort by pending load
-      return clusterMetrics.get(b).getAppsPending() - clusterMetrics.get(a)
-          .getAppsPending();
-    }
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/NoOpGlobalPolicy.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/NoOpGlobalPolicy.java
deleted file mode 100644
index c2d578f7717..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/NoOpGlobalPolicy.java
+++ /dev/null
@@ -1,36 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.globalpolicygenerator.policygenerator;
-
-import org.apache.hadoop.yarn.server.federation.policies.manager.FederationPolicyManager;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-
-import java.util.Map;
-
-/**
- * Default policy that does not update any policy configurations.
- */
-public class NoOpGlobalPolicy extends GlobalPolicy{
-
-  @Override
-  public FederationPolicyManager updatePolicy(String queueName,
-      Map<SubClusterId, Map<Class, Object>> clusterInfo,
-      FederationPolicyManager manager) {
-    return null;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/PolicyGenerator.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/PolicyGenerator.java
deleted file mode 100644
index 1f0fbd11a74..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/PolicyGenerator.java
+++ /dev/null
@@ -1,267 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator.policygenerator;
-
-import org.apache.hadoop.classification.VisibleForTesting;
-import org.apache.hadoop.conf.Configurable;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.federation.policies.manager.FederationPolicyManager;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GPGContext;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GPGUtils;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.CapacitySchedulerInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.CapacitySchedulerQueueInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerTypeInfo;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Map;
-import java.util.Set;
-
-/**
- * The PolicyGenerator runs periodically and updates the policy configuration
- * for each queue into the FederationStateStore. The policy update behavior is
- * defined by the GlobalPolicy instance that is used.
- */
-
-public class PolicyGenerator implements Runnable, Configurable {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(PolicyGenerator.class);
-
-  private GPGContext gpgContext;
-  private Configuration conf;
-
-  // Information request map
-  private Map<Class, String> pathMap = new HashMap<>();
-
-  // Global policy instance
-  @VisibleForTesting
-  private GlobalPolicy policy;
-
-  /**
-   * The PolicyGenerator periodically reads SubCluster load and updates
-   * policies into the FederationStateStore.
-   *
-   * @param conf Configuration.
-   * @param context GPG Context.
-   */
-  public PolicyGenerator(Configuration conf, GPGContext context) {
-    setConf(conf);
-    init(context);
-  }
-
-  private void init(GPGContext context) {
-    this.gpgContext = context;
-    LOG.info("Initialized PolicyGenerator");
-  }
-
-  @Override
-  public void setConf(Configuration conf) {
-    this.conf = conf;
-    this.policy = FederationStateStoreFacade.createInstance(conf,
-        YarnConfiguration.GPG_GLOBAL_POLICY_CLASS,
-        YarnConfiguration.DEFAULT_GPG_GLOBAL_POLICY_CLASS, GlobalPolicy.class);
-    policy.setConf(conf);
-    pathMap.putAll(policy.registerPaths());
-  }
-
-  @Override
-  public Configuration getConf() {
-    return this.conf;
-  }
-
-  @Override
-  public final void run() {
-    Map<SubClusterId, SubClusterInfo> activeSubClusters;
-    try {
-      activeSubClusters = gpgContext.getStateStoreFacade().getSubClusters(true);
-    } catch (YarnException e) {
-      LOG.error("Error retrieving active sub-clusters", e);
-      return;
-    }
-
-    // Parse the scheduler information from all the SCs
-    Map<SubClusterId, SchedulerInfo> schedInfo = getSchedulerInfo(activeSubClusters);
-
-    // Extract and enforce that all the schedulers have matching type
-    Set<String> queueNames = extractQueues(schedInfo);
-
-    // Remove black listed SubClusters
-    activeSubClusters.keySet().removeAll(getBlackList());
-    LOG.info("Active non-blacklist sub-clusters: {}",
-        activeSubClusters.keySet());
-
-    // Get cluster metrics information from non-black listed RMs - later used
-    // to evaluate SubCluster load
-    Map<SubClusterId, Map<Class, Object>> clusterInfo =
-        getInfos(activeSubClusters);
-
-    // Update into the FederationStateStore
-    for (String queueName : queueNames) {
-      // Retrieve the manager from the policy facade
-      FederationPolicyManager manager;
-      try {
-        manager = this.gpgContext.getPolicyFacade().getPolicyManager(queueName);
-      } catch (YarnException e) {
-        LOG.error("GetPolicy for queue {} failed.", queueName, e);
-        continue;
-      }
-      LOG.info("Updating policy for queue {}.", queueName);
-      manager = policy.updatePolicy(queueName, clusterInfo, manager);
-      try {
-        this.gpgContext.getPolicyFacade().setPolicyManager(manager);
-      } catch (YarnException e) {
-        LOG.error("SetPolicy for queue {} failed.", queueName, e);
-      }
-    }
-  }
-
-  /**
-   * Helper to retrieve metrics from the RM REST endpoints.
-   *
-   * @param activeSubClusters A map of active SubCluster IDs to info
-   * @return Mapping relationship between SubClusterId and Metric.
-   */
-  @VisibleForTesting
-  protected Map<SubClusterId, Map<Class, Object>> getInfos(
-      Map<SubClusterId, SubClusterInfo> activeSubClusters) {
-
-    Map<SubClusterId, Map<Class, Object>> clusterInfo = new HashMap<>();
-    for (SubClusterInfo sci : activeSubClusters.values()) {
-      for (Map.Entry<Class, String> e : this.pathMap.entrySet()) {
-        if (!clusterInfo.containsKey(sci.getSubClusterId())) {
-          clusterInfo.put(sci.getSubClusterId(), new HashMap<>());
-        }
-        Object ret = GPGUtils.invokeRMWebService(sci.getRMWebServiceAddress(),
-            e.getValue(), e.getKey(), conf);
-        clusterInfo.get(sci.getSubClusterId()).put(e.getKey(), ret);
-      }
-    }
-
-    return clusterInfo;
-  }
-
-  /**
-   * Helper to retrieve SchedulerInfos.
-   *
-   * @param activeSubClusters A map of active SubCluster IDs to info
-   * @return Mapping relationship between SubClusterId and SubClusterInfo.
-   */
-  @VisibleForTesting
-  protected Map<SubClusterId, SchedulerInfo> getSchedulerInfo(
-      Map<SubClusterId, SubClusterInfo> activeSubClusters) {
-    Map<SubClusterId, SchedulerInfo> schedInfo =
-        new HashMap<>();
-    for (SubClusterInfo sci : activeSubClusters.values()) {
-      SchedulerTypeInfo sti = GPGUtils
-          .invokeRMWebService(sci.getRMWebServiceAddress(),
-              RMWSConsts.SCHEDULER, SchedulerTypeInfo.class, conf);
-      if(sti != null){
-        schedInfo.put(sci.getSubClusterId(), sti.getSchedulerInfo());
-      } else {
-        LOG.warn("Skipped null scheduler info from SubCluster {}.", sci.getSubClusterId());
-      }
-    }
-    return schedInfo;
-  }
-
-  /**
-   * Helper to get a set of blacklisted SubCluster Ids from configuration.
-   */
-  private Set<SubClusterId> getBlackList() {
-    String blackListParam =
-        conf.get(YarnConfiguration.GPG_POLICY_GENERATOR_BLACKLIST);
-    if(blackListParam == null){
-      return Collections.emptySet();
-    }
-    Set<SubClusterId> blackList = new HashSet<>();
-    for (String id : blackListParam.split(",")) {
-      blackList.add(SubClusterId.newInstance(id));
-    }
-    return blackList;
-  }
-
-  /**
-   * Given the scheduler information for all RMs, extract the union of
-   * queue names - right now we only consider instances of capacity scheduler.
-   *
-   * @param schedInfo the scheduler information
-   * @return a set of queue names
-   */
-  private Set<String> extractQueues(Map<SubClusterId, SchedulerInfo> schedInfo) {
-    Set<String> queueNames = new HashSet<>();
-    for (Map.Entry<SubClusterId, SchedulerInfo> entry : schedInfo.entrySet()) {
-      if (entry.getValue() instanceof CapacitySchedulerInfo) {
-        // Flatten the queue structure and get only non leaf queues
-        queueNames.addAll(flattenQueue((CapacitySchedulerInfo) entry.getValue())
-            .get(CapacitySchedulerQueueInfo.class));
-      } else {
-        LOG.warn("Skipping SubCluster {}, not configured with capacity scheduler.",
-            entry.getKey());
-      }
-    }
-    return queueNames;
-  }
-
-  // Helpers to flatten the queue structure into a multimap of
-  // queue type to set of queue names
-  private Map<Class, Set<String>> flattenQueue(CapacitySchedulerInfo csi) {
-    Map<Class, Set<String>> flattened = new HashMap<>();
-    addOrAppend(flattened, csi.getClass(), csi.getQueueName());
-    for (CapacitySchedulerQueueInfo csqi : csi.getQueues().getQueueInfoList()) {
-      flattenQueue(csqi, flattened);
-    }
-    return flattened;
-  }
-
-  private void flattenQueue(CapacitySchedulerQueueInfo csi,
-      Map<Class, Set<String>> flattened) {
-    addOrAppend(flattened, csi.getClass(), csi.getQueueName());
-    if (csi.getQueues() != null) {
-      for (CapacitySchedulerQueueInfo csqi : csi.getQueues().getQueueInfoList()) {
-        flattenQueue(csqi, flattened);
-      }
-    }
-  }
-
-  private <K, V> void addOrAppend(Map<K, Set<V>> multimap, K key, V value) {
-    if (!multimap.containsKey(key)) {
-      multimap.put(key, new HashSet<>());
-    }
-    multimap.get(key).add(value);
-  }
-
-  public GlobalPolicy getPolicy() {
-    return policy;
-  }
-
-  public void setPolicy(GlobalPolicy policy) {
-    this.policy = policy;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/UniformWeightedLocalityGlobalPolicy.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/UniformWeightedLocalityGlobalPolicy.java
deleted file mode 100644
index 23e99062c7d..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/UniformWeightedLocalityGlobalPolicy.java
+++ /dev/null
@@ -1,68 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.globalpolicygenerator.policygenerator;
-
-import org.apache.hadoop.yarn.server.federation.policies.manager.FederationPolicyManager;
-import org.apache.hadoop.yarn.server.federation.policies.manager.WeightedLocalityPolicyManager;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterIdInfo;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GPGUtils;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.util.Map;
-
-/**
- * Simple policy that generates and updates uniform weighted locality
- * policies.
- */
-public class UniformWeightedLocalityGlobalPolicy extends GlobalPolicy {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(UniformWeightedLocalityGlobalPolicy.class);
-
-  @Override
-  protected FederationPolicyManager updatePolicy(String queueName,
-      Map<SubClusterId, Map<Class, Object>> clusterInfo, FederationPolicyManager currentManager){
-
-    if(currentManager == null){
-      // Set uniform weights for all SubClusters
-      LOG.info("Creating uniform weighted policy queue {}.", queueName);
-      WeightedLocalityPolicyManager manager = new WeightedLocalityPolicyManager();
-      manager.setQueue(queueName);
-      Map<SubClusterIdInfo, Float> policyWeights =
-          GPGUtils.createUniformWeights(clusterInfo.keySet());
-      manager.getWeightedPolicyInfo().setAMRMPolicyWeights(policyWeights);
-      manager.getWeightedPolicyInfo().setRouterPolicyWeights(policyWeights);
-      currentManager = manager;
-    }
-
-    if(currentManager instanceof WeightedLocalityPolicyManager){
-      LOG.info("Updating policy for queue {} to default weights.", queueName);
-      WeightedLocalityPolicyManager wlpmanager = (WeightedLocalityPolicyManager) currentManager;
-      Map<SubClusterIdInfo, Float> uniformWeights =
-          GPGUtils.createUniformWeights(clusterInfo.keySet());
-      wlpmanager.getWeightedPolicyInfo().setAMRMPolicyWeights(uniformWeights);
-      wlpmanager.getWeightedPolicyInfo().setRouterPolicyWeights(uniformWeights);
-    } else {
-      LOG.info("Policy for queue {} is of type {}, expected {}",
-          queueName, currentManager.getClass(), WeightedLocalityPolicyManager.class);
-    }
-    return currentManager;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/package-info.java
deleted file mode 100644
index e8ff436ad33..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/package-info.java
+++ /dev/null
@@ -1,24 +0,0 @@
-/**
- *  Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Classes comprising the policy generator for the GPG. Responsibilities include
- * generating and updating policies based on the cluster status.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator.policygenerator;
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/subclustercleaner/SubClusterCleaner.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/subclustercleaner/SubClusterCleaner.java
deleted file mode 100644
index aa1dda7464c..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/subclustercleaner/SubClusterCleaner.java
+++ /dev/null
@@ -1,113 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator.subclustercleaner;
-
-import java.util.Date;
-import java.util.Map;
-import java.util.concurrent.TimeUnit;
-
-import org.apache.commons.lang.time.DurationFormatUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterState;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GPGContext;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * The sub-cluster cleaner is one of the GPG's services that periodically checks
- * the membership table in FederationStateStore and mark sub-clusters that have
- * not sent a heartbeat in certain amount of time as LOST.
- */
-public class SubClusterCleaner implements Runnable {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(SubClusterCleaner.class);
-
-  private GPGContext gpgContext;
-  private long heartbeatExpirationMillis;
-
-  /**
-   * The sub-cluster cleaner runnable is invoked by the sub cluster cleaner
-   * service to check the membership table and remove sub clusters that have not
-   * sent a heart beat in some amount of time.
-   *
-   * @param conf configuration.
-   * @param gpgContext GPGContext.
-   */
-  public SubClusterCleaner(Configuration conf, GPGContext gpgContext) {
-    this.heartbeatExpirationMillis = conf.getTimeDuration(
-        YarnConfiguration.GPG_SUBCLUSTER_EXPIRATION_MS,
-        YarnConfiguration.DEFAULT_GPG_SUBCLUSTER_EXPIRATION_MS, TimeUnit.MILLISECONDS);
-    this.gpgContext = gpgContext;
-    LOG.info("Initialized SubClusterCleaner with heartbeat expiration of {}",
-        DurationFormatUtils.formatDurationISO(this.heartbeatExpirationMillis));
-  }
-
-  @Override
-  public void run() {
-    try {
-      Date now = new Date();
-      LOG.info("SubClusterCleaner at {}", now);
-
-      Map<SubClusterId, SubClusterInfo> infoMap =
-          this.gpgContext.getStateStoreFacade().getSubClusters(false, true);
-
-      // Iterate over each sub cluster and check last heartbeat
-      for (Map.Entry<SubClusterId, SubClusterInfo> entry : infoMap.entrySet()) {
-        SubClusterInfo subClusterInfo = entry.getValue();
-
-        Date lastHeartBeat = new Date(subClusterInfo.getLastHeartBeat());
-        if (LOG.isDebugEnabled()) {
-          LOG.debug("Checking subcluster {} in state {}, last heartbeat at {}",
-              subClusterInfo.getSubClusterId(), subClusterInfo.getState(),
-              lastHeartBeat);
-        }
-
-        if (subClusterInfo.getState().isUsable()) {
-          long timeUntilDeregister = this.heartbeatExpirationMillis
-              - (now.getTime() - lastHeartBeat.getTime());
-          // Deregister sub-cluster as SC_LOST if last heartbeat too old
-          if (timeUntilDeregister < 0) {
-            LOG.warn(
-                "Deregistering subcluster {} in state {} last heartbeat at {}",
-                subClusterInfo.getSubClusterId(), subClusterInfo.getState(),
-                new Date(subClusterInfo.getLastHeartBeat()));
-            try {
-              this.gpgContext.getStateStoreFacade().deregisterSubCluster(
-                  subClusterInfo.getSubClusterId(), SubClusterState.SC_LOST);
-            } catch (Exception e) {
-              LOG.error("deregisterSubCluster failed on subcluster "
-                  + subClusterInfo.getSubClusterId(), e);
-            }
-          } else if (LOG.isDebugEnabled()) {
-            LOG.debug("Time until deregister for subcluster {}: {}",
-                entry.getKey(),
-                DurationFormatUtils.formatDurationISO(timeUntilDeregister));
-          }
-        }
-      }
-    } catch (Throwable e) {
-      LOG.error("Subcluster cleaner fails: ", e);
-    }
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/subclustercleaner/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/subclustercleaner/package-info.java
deleted file mode 100644
index f65444aa366..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/subclustercleaner/package-info.java
+++ /dev/null
@@ -1,19 +0,0 @@
-/**
- *  Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator.subclustercleaner;
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGController.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGController.java
deleted file mode 100644
index 4b81c8a128c..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGController.java
+++ /dev/null
@@ -1,49 +0,0 @@
-/**
-* Licensed to the Apache Software Foundation (ASF) under one
-* or more contributor license agreements.  See the NOTICE file
-* distributed with this work for additional information
-* regarding copyright ownership.  The ASF licenses this file
-* to you under the Apache License, Version 2.0 (the
-* "License"); you may not use this file except in compliance
-* with the License.  You may obtain a copy of the License at
-*
-*     http://www.apache.org/licenses/LICENSE-2.0
-*
-* Unless required by applicable law or agreed to in writing, software
-* distributed under the License is distributed on an "AS IS" BASIS,
-* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-* See the License for the specific language governing permissions and
-* limitations under the License.
-*/
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator.webapp;
-
-import org.apache.hadoop.yarn.webapp.Controller;
-import com.google.inject.Inject;
-
-/**
- * Controller for the GPG Web UI.
- */
-public class GPGController extends Controller {
-
-  @Inject
-  GPGController(RequestContext ctx) {
-    super(ctx);
-  }
-
-  @Override
-  public void index() {
-    setTitle("GPG");
-    render(GPGOverviewPage.class);
-  }
-
-  public void overview() {
-    setTitle("GPG");
-    render(GPGOverviewPage.class);
-  }
-
-  public void policies() {
-    setTitle("Global Policy Generator Policies");
-    render(GPGPoliciesPage.class);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGOverviewBlock.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGOverviewBlock.java
deleted file mode 100644
index 06617564ce6..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGOverviewBlock.java
+++ /dev/null
@@ -1,88 +0,0 @@
-/**
-* Licensed to the Apache Software Foundation (ASF) under one
-* or more contributor license agreements.  See the NOTICE file
-* distributed with this work for additional information
-* regarding copyright ownership.  The ASF licenses this file
-* to you under the Apache License, Version 2.0 (the
-* "License"); you may not use this file except in compliance
-* with the License.  You may obtain a copy of the License at
-*
-*     http://www.apache.org/licenses/LICENSE-2.0
-*
-* Unless required by applicable law or agreed to in writing, software
-* distributed under the License is distributed on an "AS IS" BASIS,
-* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-* See the License for the specific language governing permissions and
-* limitations under the License.
-*/
-package org.apache.hadoop.yarn.server.globalpolicygenerator.webapp;
-
-import java.util.Date;
-import java.util.concurrent.TimeUnit;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.util.VersionInfo;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GlobalPolicyGenerator;
-import org.apache.hadoop.yarn.util.YarnVersionInfo;
-import org.apache.hadoop.yarn.webapp.view.HtmlBlock;
-import org.apache.hadoop.yarn.webapp.view.InfoBlock;
-
-import com.google.inject.Inject;
-
-/**
- * Overview block for the GPG Web UI.
- */
-public class GPGOverviewBlock extends HtmlBlock {
-
-  private GlobalPolicyGenerator globalPolicyGenerator;
-
-  @Inject
-  GPGOverviewBlock(GlobalPolicyGenerator gpg, ViewContext ctx) {
-    super(ctx);
-    this.globalPolicyGenerator = gpg;
-  }
-
-  @Override
-  protected void render(Block html) {
-    Configuration config = this.globalPolicyGenerator.getConfig();
-
-    String appCleaner = "disable";
-    long appCleanerIntervalMs = config.getTimeDuration(YarnConfiguration.GPG_APPCLEANER_INTERVAL_MS,
-        YarnConfiguration.DEFAULT_GPG_APPCLEANER_INTERVAL_MS, TimeUnit.MILLISECONDS);
-    if (appCleanerIntervalMs > 0) {
-      appCleaner = "enable, interval : " + appCleanerIntervalMs + " ms";
-    }
-
-    String scCleaner = "disable";
-    long scCleanerIntervalMs = config.getTimeDuration(
-        YarnConfiguration.GPG_SUBCLUSTER_CLEANER_INTERVAL_MS,
-        YarnConfiguration.DEFAULT_GPG_SUBCLUSTER_CLEANER_INTERVAL_MS, TimeUnit.MILLISECONDS);
-    if (scCleanerIntervalMs > 0) {
-      scCleaner = "enable, interval : " + scCleanerIntervalMs + " ms";
-    }
-
-    String pgGenerator = "disable";
-    long policyGeneratorIntervalMillis = config.getTimeDuration(
-        YarnConfiguration.GPG_POLICY_GENERATOR_INTERVAL,
-        YarnConfiguration.DEFAULT_GPG_POLICY_GENERATOR_INTERVAL, TimeUnit.MILLISECONDS);
-
-    if (policyGeneratorIntervalMillis > 0) {
-      pgGenerator = "enable, interval : " + policyGeneratorIntervalMillis + " ms";
-    }
-
-    String policy = config.get(YarnConfiguration.GPG_GLOBAL_POLICY_CLASS,
-        YarnConfiguration.DEFAULT_GPG_GLOBAL_POLICY_CLASS);
-
-    info("GPG Details")
-        .__("GPG started on", new Date(GlobalPolicyGenerator.getGPGStartupTime()))
-        .__("GPG application cleaner", appCleaner)
-        .__("GPG subcluster cleaner", scCleaner)
-        .__("GPG policy generator", pgGenerator)
-        .__("GPG policy generator class", policy)
-        .__("GPG Version", YarnVersionInfo.getVersion())
-        .__("Hadoop Version", VersionInfo.getVersion());
-
-    html.__(InfoBlock.class);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGOverviewPage.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGOverviewPage.java
deleted file mode 100644
index b7086ea71ae..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGOverviewPage.java
+++ /dev/null
@@ -1,52 +0,0 @@
-/**
-* Licensed to the Apache Software Foundation (ASF) under one
-* or more contributor license agreements.  See the NOTICE file
-* distributed with this work for additional information
-* regarding copyright ownership.  The ASF licenses this file
-* to you under the Apache License, Version 2.0 (the
-* "License"); you may not use this file except in compliance
-* with the License.  You may obtain a copy of the License at
-*
-*     http://www.apache.org/licenses/LICENSE-2.0
-*
-* Unless required by applicable law or agreed to in writing, software
-* distributed under the License is distributed on an "AS IS" BASIS,
-* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-* See the License for the specific language governing permissions and
-* limitations under the License.
-*/
-package org.apache.hadoop.yarn.server.globalpolicygenerator.webapp;
-
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.ACCORDION;
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.ACCORDION_ID;
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.initID;
-
-import org.apache.hadoop.yarn.webapp.SubView;
-import org.apache.hadoop.yarn.webapp.view.TwoColumnLayout;
-
-/**
- * Overview page for the GPG Web UI.
- */
-public class GPGOverviewPage extends TwoColumnLayout {
-
-  @Override
-  protected void preHead(Page.HTML<__> html) {
-    commonPreHead(html);
-    setTitle("GPG");
-  }
-
-  protected void commonPreHead(Page.HTML<__> html) {
-    set(ACCORDION_ID, "nav");
-    set(initID(ACCORDION, "nav"), "{autoHeight:false, active:0}");
-  }
-
-  @Override
-  protected Class<? extends SubView> nav() {
-    return NavBlock.class;
-  }
-
-  @Override
-  protected Class<? extends SubView> content() {
-    return GPGOverviewBlock.class;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGPoliciesBlock.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGPoliciesBlock.java
deleted file mode 100644
index 641576a30ca..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGPoliciesBlock.java
+++ /dev/null
@@ -1,110 +0,0 @@
-/**
-* Licensed to the Apache Software Foundation (ASF) under one
-* or more contributor license agreements.  See the NOTICE file
-* distributed with this work for additional information
-* regarding copyright ownership.  The ASF licenses this file
-* to you under the Apache License, Version 2.0 (the
-* "License"); you may not use this file except in compliance
-* with the License.  You may obtain a copy of the License at
-*
-*     http://www.apache.org/licenses/LICENSE-2.0
-*
-* Unless required by applicable law or agreed to in writing, software
-* distributed under the License is distributed on an "AS IS" BASIS,
-* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-* See the License for the specific language governing permissions and
-* limitations under the License.
-*/
-package org.apache.hadoop.yarn.server.globalpolicygenerator.webapp;
-
-import com.google.inject.Inject;
-import org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo;
-import org.apache.hadoop.yarn.server.federation.policies.exceptions.FederationPolicyInitializationException;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterIdInfo;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GlobalPolicyGenerator;
-import org.apache.hadoop.yarn.webapp.hamlet2.Hamlet;
-import org.apache.hadoop.yarn.webapp.view.HtmlBlock;
-
-import java.nio.ByteBuffer;
-import java.util.Collection;
-import java.util.Map;
-
-/**
- * Overview block for the GPG Policies Web UI.
- */
-public class GPGPoliciesBlock extends HtmlBlock {
-
-  private final GlobalPolicyGenerator gpg;
-
-  private final FederationStateStoreFacade facade;
-
-  @Inject
-  GPGPoliciesBlock(GlobalPolicyGenerator gpg, ViewContext ctx) {
-    super(ctx);
-    this.gpg = gpg;
-    this.facade = FederationStateStoreFacade.getInstance(gpg.getConfig());
-  }
-
-  @Override
-  protected void render(Block html) {
-    try {
-      Collection<SubClusterPolicyConfiguration> policies =
-          facade.getPoliciesConfigurations().values();
-      initYarnFederationPolicies(policies, html);
-    } catch (Exception e) {
-      LOG.error("Get GPGPolicies Error.", e);
-    }
-  }
-
-  private void initYarnFederationPolicies(Collection<SubClusterPolicyConfiguration> policies,
-      Block html) throws FederationPolicyInitializationException {
-
-    Hamlet.TBODY<Hamlet.TABLE<Hamlet>> tbody = html.table("#policies").
-        thead().
-        tr().
-        th(".queue", "Queue Name").
-        th(".policyType", "Policy Type").
-        th(".routerPolicyWeights", "Router PolicyWeights").
-        th(".amrmPolicyWeights", "Router AMRMPolicyWeights").
-        th(".headroomAlpha", "Router Headroom Alpha").
-        __().__().
-        tbody();
-
-    if (policies != null) {
-      for (SubClusterPolicyConfiguration policy : policies) {
-        Hamlet.TR<Hamlet.TBODY<Hamlet.TABLE<Hamlet>>> row = tbody.tr().td(policy.getQueue());
-        // Policy Type
-        String type = policy.getType();
-        row = row.td(type);
-
-        // WeightedPolicyInfo
-        ByteBuffer params = policy.getParams();
-        WeightedPolicyInfo weightedPolicyInfo = WeightedPolicyInfo.fromByteBuffer(params);
-        row = row.td(policyWeight2String(weightedPolicyInfo.getRouterPolicyWeights()));
-        row = row.td(policyWeight2String(weightedPolicyInfo.getAMRMPolicyWeights()));
-        row.td(String.valueOf(weightedPolicyInfo.getHeadroomAlpha())).__();
-      }
-    }
-
-    tbody.__().__();
-  }
-
-  /**
-   * We will convert the PolicyWeight to string format.
-   *
-   * @param weights PolicyWeight.
-   * @return string format PolicyWeight. example: SC-1:0.91, SC-2:0.09
-   */
-  private String policyWeight2String(Map<SubClusterIdInfo, Float> weights) {
-    StringBuilder sb = new StringBuilder();
-    for (Map.Entry<SubClusterIdInfo, Float> entry : weights.entrySet()) {
-      sb.append(entry.getKey().toId()).append(": ").append(entry.getValue()).append(", ");
-    }
-    if (sb.length() > 2) {
-      sb.setLength(sb.length() - 2);
-    }
-    return sb.toString();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGPoliciesPage.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGPoliciesPage.java
deleted file mode 100644
index f9ff5f5c8bd..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGPoliciesPage.java
+++ /dev/null
@@ -1,55 +0,0 @@
-/**
-* Licensed to the Apache Software Foundation (ASF) under one
-* or more contributor license agreements.  See the NOTICE file
-* distributed with this work for additional information
-* regarding copyright ownership.  The ASF licenses this file
-* to you under the Apache License, Version 2.0 (the
-* "License"); you may not use this file except in compliance
-* with the License.  You may obtain a copy of the License at
-*
-*     http://www.apache.org/licenses/LICENSE-2.0
-*
-* Unless required by applicable law or agreed to in writing, software
-* distributed under the License is distributed on an "AS IS" BASIS,
-* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-* See the License for the specific language governing permissions and
-* limitations under the License.
-*/
-package org.apache.hadoop.yarn.server.globalpolicygenerator.webapp;
-
-import org.apache.hadoop.yarn.webapp.SubView;
-import org.apache.hadoop.yarn.webapp.view.TwoColumnLayout;
-
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.ACCORDION_ID;
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.ACCORDION;
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.DATATABLES_ID;
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.initID;
-
-/**
- * Overview page for the GPG Policies Web UI.
- */
-public class GPGPoliciesPage extends TwoColumnLayout {
-
-  @Override
-  protected void preHead(Page.HTML<__> html) {
-    commonPreHead(html);
-  }
-
-  protected void commonPreHead(Page.HTML<__> html) {
-    setTitle("Global Policy Generator Policies");
-    set(ACCORDION_ID, "nav");
-    set(initID(ACCORDION, "nav"), "{autoHeight:false, active:0}");
-    set(DATATABLES_ID, "policies");
-  }
-
-  @Override
-  protected Class<? extends SubView> content() {
-    return GPGPoliciesBlock.class;
-  }
-
-  @Override
-  protected Class<? extends SubView> nav() {
-    return NavBlock.class;
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGWebApp.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGWebApp.java
deleted file mode 100644
index 0bbe49db25f..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGWebApp.java
+++ /dev/null
@@ -1,47 +0,0 @@
-/**
-* Licensed to the Apache Software Foundation (ASF) under one
-* or more contributor license agreements.  See the NOTICE file
-* distributed with this work for additional information
-* regarding copyright ownership.  The ASF licenses this file
-* to you under the Apache License, Version 2.0 (the
-* "License"); you may not use this file except in compliance
-* with the License.  You may obtain a copy of the License at
-*
-*     http://www.apache.org/licenses/LICENSE-2.0
-*
-* Unless required by applicable law or agreed to in writing, software
-* distributed under the License is distributed on an "AS IS" BASIS,
-* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-* See the License for the specific language governing permissions and
-* limitations under the License.
-*/
-package org.apache.hadoop.yarn.server.globalpolicygenerator.webapp;
-
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GlobalPolicyGenerator;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.JAXBContextResolver;
-import org.apache.hadoop.yarn.webapp.GenericExceptionHandler;
-import org.apache.hadoop.yarn.webapp.WebApp;
-
-/**
- * The GPG webapp.
- */
-public class GPGWebApp extends WebApp {
-  private GlobalPolicyGenerator gpg;
-
-  public GPGWebApp(GlobalPolicyGenerator gpg) {
-    this.gpg = gpg;
-  }
-
-  @Override
-  public void setup() {
-    bind(GPGWebServices.class);
-    bind(JAXBContextResolver.class);
-    bind(GPGWebApp.class).toInstance(this);
-    bind(GenericExceptionHandler.class);
-    if (gpg != null) {
-      bind(GlobalPolicyGenerator.class).toInstance(gpg);
-    }
-    route("/", GPGController.class, "overview");
-    route("/policies", GPGController.class, "policies");
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGWebServices.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGWebServices.java
deleted file mode 100644
index ef6b50d83ad..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/GPGWebServices.java
+++ /dev/null
@@ -1,62 +0,0 @@
-/** * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.globalpolicygenerator.webapp;
-
-import com.google.inject.Inject;
-import com.google.inject.Singleton;
-import org.apache.hadoop.http.JettyUtils;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GlobalPolicyGenerator;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.webapp.dao.GpgInfo;
-import org.apache.hadoop.yarn.webapp.WebApp;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import javax.ws.rs.GET;
-import javax.ws.rs.Path;
-import javax.ws.rs.Produces;
-import javax.ws.rs.core.MediaType;
-
-@Singleton
-@Path("/ws/v1/gpg")
-public class GPGWebServices {
-
-  private static final Logger LOG = LoggerFactory.getLogger(GPGWebServices.class);
-
-  private GlobalPolicyGenerator gpgGenerator;
-  private WebApp webapp;
-
-  @Inject
-  public GPGWebServices(final GlobalPolicyGenerator gpg, final WebApp webapp) {
-    this.gpgGenerator = gpg;
-    this.webapp = webapp;
-  }
-
-  @GET
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  public GpgInfo get() {
-    return new GpgInfo(this.gpgGenerator.getGPGContext());
-  }
-
-  @GET
-  @Path("/info")
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-       MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  public GpgInfo getGPGInfo() {
-    return new GpgInfo(this.gpgGenerator.getGPGContext());
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/NavBlock.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/NavBlock.java
deleted file mode 100644
index 3650287df38..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/NavBlock.java
+++ /dev/null
@@ -1,43 +0,0 @@
-/**
-* Licensed to the Apache Software Foundation (ASF) under one
-* or more contributor license agreements.  See the NOTICE file
-* distributed with this work for additional information
-* regarding copyright ownership.  The ASF licenses this file
-* to you under the Apache License, Version 2.0 (the
-* "License"); you may not use this file except in compliance
-* with the License.  You may obtain a copy of the License at
-*
-*     http://www.apache.org/licenses/LICENSE-2.0
-*
-* Unless required by applicable law or agreed to in writing, software
-* distributed under the License is distributed on an "AS IS" BASIS,
-* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-* See the License for the specific language governing permissions and
-* limitations under the License.
-*/
-package org.apache.hadoop.yarn.server.globalpolicygenerator.webapp;
-
-import org.apache.hadoop.yarn.webapp.view.HtmlBlock;
-
-/**
- * Navigation block for the GPG Web UI.
- */
-public class NavBlock extends HtmlBlock {
-
-  @Override
-  public void render(Block html) {
-    html.
-      div("#nav").
-        h3("GPG").
-        ul().
-          li().a(url(""), "Overview").__().
-          li().a(url("policies"), "Policies").__().
-        __().
-        h3("Tools").
-        ul().
-          li().a("/conf", "Configuration").__().
-          li().a("/logs", "Local logs").__().
-          li().a("/stacks", "Server stacks").__().
-          li().a("/jmx?qry=Hadoop:*", "Server metrics").__().__().__();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/dao/GpgInfo.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/dao/GpgInfo.java
deleted file mode 100644
index a5c6c29e9fc..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/dao/GpgInfo.java
+++ /dev/null
@@ -1,81 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator.webapp.dao;
-
-import org.apache.hadoop.util.VersionInfo;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GPGContext;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GlobalPolicyGenerator;
-import org.apache.hadoop.yarn.util.YarnVersionInfo;
-
-import javax.xml.bind.annotation.XmlAccessType;
-import javax.xml.bind.annotation.XmlAccessorType;
-import javax.xml.bind.annotation.XmlRootElement;
-
-@XmlRootElement
-@XmlAccessorType(XmlAccessType.FIELD)
-public class GpgInfo {
-  private String gpgVersion;
-  private String gpgBuildVersion;
-  private String gpgVersionBuiltOn;
-  private String hadoopVersion;
-  private String hadoopBuildVersion;
-  private String hadoopVersionBuiltOn;
-  private long gpgStartupTime;
-
-  public GpgInfo() {
-  } // JAXB needs this
-
-  public GpgInfo(final GPGContext context) {
-    this.gpgVersion = YarnVersionInfo.getVersion();
-    this.gpgBuildVersion = YarnVersionInfo.getBuildVersion();
-    this.gpgVersionBuiltOn = YarnVersionInfo.getDate();
-    this.hadoopVersion = VersionInfo.getVersion();
-    this.hadoopBuildVersion = VersionInfo.getBuildVersion();
-    this.hadoopVersionBuiltOn = VersionInfo.getDate();
-    this.gpgStartupTime = GlobalPolicyGenerator.getGPGStartupTime();
-  }
-
-  public String getGpgVersion() {
-    return gpgVersion;
-  }
-
-  public String getGpgBuildVersion() {
-    return gpgBuildVersion;
-  }
-
-  public String getGpgVersionBuiltOn() {
-    return gpgVersionBuiltOn;
-  }
-
-  public String getHadoopVersion() {
-    return hadoopVersion;
-  }
-
-  public String getHadoopBuildVersion() {
-    return hadoopBuildVersion;
-  }
-
-  public String getHadoopVersionBuiltOn() {
-    return hadoopVersionBuiltOn;
-  }
-
-  public long getGpgStartupTime() {
-    return gpgStartupTime;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/dao/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/dao/package-info.java
deleted file mode 100644
index b687ba28907..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/dao/package-info.java
+++ /dev/null
@@ -1,19 +0,0 @@
-/**
- *  Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator.webapp.dao;
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/package-info.java
deleted file mode 100644
index 762212b49a1..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/main/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/package-info.java
+++ /dev/null
@@ -1,24 +0,0 @@
-/**
- *  Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Classes comprising the policy generator for the GPG. Responsibilities include
- * generating and updating policies based on the cluster status.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator.webapp;
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/TestGPGPolicyFacade.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/TestGPGPolicyFacade.java
deleted file mode 100644
index 217c4a58967..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/TestGPGPolicyFacade.java
+++ /dev/null
@@ -1,356 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator;
-
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.times;
-import static org.mockito.Mockito.verify;
-import static org.mockito.Mockito.when;
-
-import org.apache.commons.lang3.NotImplementedException;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.test.LambdaTestUtils;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo;
-import org.apache.hadoop.yarn.server.federation.policies.manager.FederationPolicyManager;
-import org.apache.hadoop.yarn.server.federation.policies.manager.WeightedLocalityPolicyManager;
-import org.apache.hadoop.yarn.server.federation.policies.manager.WeightedHomePolicyManager;
-import org.apache.hadoop.yarn.server.federation.policies.manager.UniformBroadcastPolicyManager;
-import org.apache.hadoop.yarn.server.federation.policies.manager.HashBroadcastPolicyManager;
-import org.apache.hadoop.yarn.server.federation.policies.manager.HomePolicyManager;
-import org.apache.hadoop.yarn.server.federation.policies.manager.RejectAllPolicyManager;
-import org.apache.hadoop.yarn.server.federation.store.FederationStateStore;
-import org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore;
-import org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPolicyConfigurationRequest;
-import org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPolicyConfigurationResponse;
-import org.apache.hadoop.yarn.server.federation.store.records.SetSubClusterPolicyConfigurationRequest;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterIdInfo;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.junit.After;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Test;
-import org.mockito.Matchers;
-
-import java.util.List;
-import java.util.ArrayList;
-import java.util.Map;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Set;
-
-/**
- * Unit test for GPG Policy Facade.
- */
-public class TestGPGPolicyFacade {
-
-  private Configuration conf;
-  private FederationStateStore stateStore;
-  private FederationStateStoreFacade facade;
-  private GPGPolicyFacade policyFacade;
-
-  private Set<SubClusterId> subClusterIds;
-
-  private SubClusterPolicyConfiguration testConf;
-
-  private static final String TEST_QUEUE = "test-queue";
-
-  public TestGPGPolicyFacade() {
-    conf = new Configuration();
-    conf.setInt(YarnConfiguration.FEDERATION_CACHE_TIME_TO_LIVE_SECS, 0);
-    subClusterIds = new HashSet<>();
-    subClusterIds.add(SubClusterId.newInstance("sc0"));
-    subClusterIds.add(SubClusterId.newInstance("sc1"));
-    subClusterIds.add(SubClusterId.newInstance("sc2"));
-    facade = FederationStateStoreFacade.getInstance(conf);
-  }
-
-  @Before
-  public void setUp() throws YarnException {
-    stateStore = new MemoryFederationStateStore();
-    stateStore.init(conf);
-    facade.reinitialize(stateStore, conf);
-    policyFacade = new GPGPolicyFacade(facade, conf);
-    WeightedLocalityPolicyManager manager =
-        new WeightedLocalityPolicyManager();
-    // Add a test policy for test queue
-    manager.setQueue(TEST_QUEUE);
-    manager.getWeightedPolicyInfo().setAMRMPolicyWeights(
-        GPGUtils.createUniformWeights(subClusterIds));
-    manager.getWeightedPolicyInfo().setRouterPolicyWeights(
-        GPGUtils.createUniformWeights(subClusterIds));
-    testConf = manager.serializeConf();
-    stateStore.setPolicyConfiguration(SetSubClusterPolicyConfigurationRequest
-        .newInstance(testConf));
-  }
-
-  @After
-  public void tearDown() throws Exception {
-    stateStore.close();
-    stateStore = null;
-  }
-
-  @Test
-  public void testGetPolicy() throws YarnException {
-    WeightedLocalityPolicyManager manager =
-        (WeightedLocalityPolicyManager) policyFacade
-            .getPolicyManager(TEST_QUEUE);
-    Assert.assertEquals(testConf, manager.serializeConf());
-  }
-
-  /**
-   * Test that new policies are written into the state store.
-   */
-  @Test
-  public void testSetNewPolicy() throws YarnException {
-    WeightedLocalityPolicyManager manager =
-        new WeightedLocalityPolicyManager();
-    manager.setQueue(TEST_QUEUE + 0);
-    manager.getWeightedPolicyInfo().setAMRMPolicyWeights(
-        GPGUtils.createUniformWeights(subClusterIds));
-    manager.getWeightedPolicyInfo().setRouterPolicyWeights(
-        GPGUtils.createUniformWeights(subClusterIds));
-    SubClusterPolicyConfiguration policyConf = manager.serializeConf();
-    policyFacade.setPolicyManager(manager);
-
-    manager =
-        (WeightedLocalityPolicyManager) policyFacade
-            .getPolicyManager(TEST_QUEUE + 0);
-    Assert.assertEquals(policyConf, manager.serializeConf());
-  }
-
-  /**
-   * Test that overwriting policies are updated in the state store.
-   */
-  @Test
-  public void testOverwritePolicy() throws YarnException {
-    subClusterIds.add(SubClusterId.newInstance("sc3"));
-    WeightedLocalityPolicyManager manager =
-        new WeightedLocalityPolicyManager();
-    manager.setQueue(TEST_QUEUE);
-    manager.getWeightedPolicyInfo().setAMRMPolicyWeights(
-        GPGUtils.createUniformWeights(subClusterIds));
-    manager.getWeightedPolicyInfo().setRouterPolicyWeights(
-        GPGUtils.createUniformWeights(subClusterIds));
-    SubClusterPolicyConfiguration policyConf = manager.serializeConf();
-    policyFacade.setPolicyManager(manager);
-
-    manager =
-        (WeightedLocalityPolicyManager) policyFacade
-            .getPolicyManager(TEST_QUEUE);
-    Assert.assertEquals(policyConf, manager.serializeConf());
-  }
-
-  /**
-   * Test that the write through cache works.
-   */
-  @Test
-  public void testWriteCache() throws YarnException {
-    stateStore = mock(MemoryFederationStateStore.class);
-    facade.reinitialize(stateStore, conf);
-    when(stateStore.getPolicyConfiguration(Matchers.any(
-        GetSubClusterPolicyConfigurationRequest.class))).thenReturn(
-        GetSubClusterPolicyConfigurationResponse.newInstance(testConf));
-    policyFacade = new GPGPolicyFacade(facade, conf);
-
-    // Query once to fill the cache
-    FederationPolicyManager manager = policyFacade.getPolicyManager(TEST_QUEUE);
-    // State store should be contacted once
-    verify(stateStore, times(1)).getPolicyConfiguration(
-        Matchers.any(GetSubClusterPolicyConfigurationRequest.class));
-
-    // If we set the same policy, the state store should be untouched
-    policyFacade.setPolicyManager(manager);
-    verify(stateStore, times(0)).setPolicyConfiguration(
-        Matchers.any(SetSubClusterPolicyConfigurationRequest.class));
-  }
-
-  /**
-   * Test that when read only is enabled, the state store is not changed.
-   */
-  @Test
-  public void testReadOnly() throws YarnException {
-    conf.setBoolean(YarnConfiguration.GPG_POLICY_GENERATOR_READONLY, true);
-    stateStore = mock(MemoryFederationStateStore.class);
-    facade.reinitialize(stateStore, conf);
-    when(stateStore.getPolicyConfiguration(Matchers.any(
-        GetSubClusterPolicyConfigurationRequest.class))).thenReturn(
-        GetSubClusterPolicyConfigurationResponse.newInstance(testConf));
-    policyFacade = new GPGPolicyFacade(facade, conf);
-
-    // If we set a policy, the state store should be untouched
-    WeightedLocalityPolicyManager manager =
-        new WeightedLocalityPolicyManager();
-    // Add a test policy for test queue
-    manager.setQueue(TEST_QUEUE);
-    manager.getWeightedPolicyInfo().setAMRMPolicyWeights(
-        GPGUtils.createUniformWeights(subClusterIds));
-    manager.getWeightedPolicyInfo().setRouterPolicyWeights(
-        GPGUtils.createUniformWeights(subClusterIds));
-    policyFacade.setPolicyManager(manager);
-    verify(stateStore, times(0)).setPolicyConfiguration(
-        Matchers.any(SetSubClusterPolicyConfigurationRequest.class));
-  }
-
-  @Test
-  public void testGetWeightedLocalityPolicyManager() throws YarnException {
-    stateStore = new MemoryFederationStateStore();
-    stateStore.init(new Configuration());
-
-    // root.a uses WeightedLocalityPolicyManager.
-    // Step1. Prepare amRMPolicyWeights and routerPolicyWeights
-    Map<SubClusterIdInfo, Float> amrmPolicyWeights = new HashMap<>();
-    amrmPolicyWeights.put(new SubClusterIdInfo("SC-1"), 0.7f);
-    amrmPolicyWeights.put(new SubClusterIdInfo("SC-2"), 0.3f);
-
-    Map<SubClusterIdInfo, Float> routerPolicyWeights = new HashMap<>();
-    routerPolicyWeights.put(new SubClusterIdInfo("SC-1"), 0.6f);
-    routerPolicyWeights.put(new SubClusterIdInfo("SC-2"), 0.4f);
-
-    WeightedPolicyInfo weightedPolicyInfo = new WeightedPolicyInfo();
-    weightedPolicyInfo.setHeadroomAlpha(1);
-    weightedPolicyInfo.setAMRMPolicyWeights(amrmPolicyWeights);
-    weightedPolicyInfo.setRouterPolicyWeights(routerPolicyWeights);
-
-    // Step2. Set PolicyConfiguration.
-    String policyManagerType = WeightedLocalityPolicyManager.class.getName();
-    SubClusterPolicyConfiguration config = SubClusterPolicyConfiguration.newInstance("root.a",
-        policyManagerType, weightedPolicyInfo.toByteBuffer());
-    SetSubClusterPolicyConfigurationRequest request =
-        SetSubClusterPolicyConfigurationRequest.newInstance(config);
-    stateStore.setPolicyConfiguration(request);
-
-    // Step3. Get FederationPolicyManager using policyFacade.
-    facade.reinitialize(stateStore, conf);
-    policyFacade = new GPGPolicyFacade(facade, conf);
-    FederationPolicyManager policyManager = policyFacade.getPolicyManager("root.a");
-    Assert.assertNotNull(policyManager);
-    Assert.assertTrue(policyManager.isSupportWeightedPolicyInfo());
-    WeightedPolicyInfo weightedPolicyInfo1 = policyManager.getWeightedPolicyInfo();
-    Assert.assertNotNull(weightedPolicyInfo1);
-    Assert.assertTrue(policyManager instanceof WeightedLocalityPolicyManager);
-
-    // Step4. Confirm amrmPolicyWeight is accurate.
-    Map<SubClusterIdInfo, Float> amrmPolicyWeights1 = weightedPolicyInfo1.getAMRMPolicyWeights();
-    Assert.assertNotNull(amrmPolicyWeights1);
-    Float sc1Float = amrmPolicyWeights1.get(new SubClusterIdInfo("SC-1"));
-    Float sc2Float = amrmPolicyWeights1.get(new SubClusterIdInfo("SC-2"));
-    Assert.assertEquals(0.7, sc1Float, 0.001);
-    Assert.assertEquals(0.3, sc2Float, 0.001);
-
-    // Step5. Confirm amrmPolicyWeight is accurate.
-    Map<SubClusterIdInfo, Float> routerPolicyWeights1 =
-        weightedPolicyInfo1.getRouterPolicyWeights();
-    Assert.assertNotNull(routerPolicyWeights1);
-    Float sc1Float1 = routerPolicyWeights1.get(new SubClusterIdInfo("SC-1"));
-    Float sc2Float2 = routerPolicyWeights1.get(new SubClusterIdInfo("SC-2"));
-    Assert.assertEquals(0.6, sc1Float1, 0.001);
-    Assert.assertEquals(0.4, sc2Float2, 0.001);
-  }
-
-  @Test
-  public void testGetWeightedHomePolicyManager() throws YarnException {
-    stateStore = new MemoryFederationStateStore();
-    stateStore.init(new Configuration());
-
-    // root.b uses WeightedHomePolicyManager.
-    // Step1. Prepare routerPolicyWeights.
-    Map<SubClusterIdInfo, Float> routerPolicyWeights = new HashMap<>();
-    routerPolicyWeights.put(new SubClusterIdInfo("SC-1"), 0.8f);
-    routerPolicyWeights.put(new SubClusterIdInfo("SC-2"), 0.2f);
-
-    WeightedPolicyInfo weightedPolicyInfo = new WeightedPolicyInfo();
-    weightedPolicyInfo.setHeadroomAlpha(1);
-    weightedPolicyInfo.setRouterPolicyWeights(routerPolicyWeights);
-
-    // Step2. Set PolicyConfiguration.
-    String policyManagerType = WeightedHomePolicyManager.class.getName();
-    SubClusterPolicyConfiguration config = SubClusterPolicyConfiguration.newInstance("root.b",
-        policyManagerType, weightedPolicyInfo.toByteBuffer());
-    SetSubClusterPolicyConfigurationRequest request =
-        SetSubClusterPolicyConfigurationRequest.newInstance(config);
-    stateStore.setPolicyConfiguration(request);
-
-    // Step3. Get FederationPolicyManager using policyFacade.
-    facade.reinitialize(stateStore, conf);
-    policyFacade = new GPGPolicyFacade(facade, conf);
-    FederationPolicyManager policyManager = policyFacade.getPolicyManager("root.b");
-    Assert.assertNotNull(policyManager);
-    Assert.assertTrue(policyManager.isSupportWeightedPolicyInfo());
-    WeightedPolicyInfo weightedPolicyInfo1 = policyManager.getWeightedPolicyInfo();
-    Assert.assertNotNull(weightedPolicyInfo1);
-
-    // Step4. Confirm amrmPolicyWeight is accurate.
-    Map<SubClusterIdInfo, Float> amrmPolicyWeights1 = weightedPolicyInfo1.getAMRMPolicyWeights();
-    Assert.assertNotNull(amrmPolicyWeights1);
-    Assert.assertEquals(0, amrmPolicyWeights1.size());
-
-    // Step5. Confirm amrmPolicyWeight is accurate.
-    Map<SubClusterIdInfo, Float> routerPolicyWeights1 =
-        weightedPolicyInfo1.getRouterPolicyWeights();
-    Assert.assertNotNull(routerPolicyWeights1);
-    Float sc1Float1 = routerPolicyWeights1.get(new SubClusterIdInfo("SC-1"));
-    Float sc2Float2 = routerPolicyWeights1.get(new SubClusterIdInfo("SC-2"));
-    Assert.assertEquals(0.8, sc1Float1, 0.001);
-    Assert.assertEquals(0.2, sc2Float2, 0.001);
-  }
-
-  @Test
-  public void testGetUniformBroadcastPolicyManager() throws Exception {
-    stateStore = new MemoryFederationStateStore();
-    stateStore.init(new Configuration());
-
-    List<String> notSupportWeightedPolicyInfos = new ArrayList<>();
-    notSupportWeightedPolicyInfos.add(HashBroadcastPolicyManager.class.getName());
-    notSupportWeightedPolicyInfos.add(UniformBroadcastPolicyManager.class.getName());
-    notSupportWeightedPolicyInfos.add(HomePolicyManager.class.getName());
-    notSupportWeightedPolicyInfos.add(RejectAllPolicyManager.class.getName());
-    String prefix = "org.apache.hadoop.yarn.server.federation.policies.manager.";
-
-    for (String policyManagerType : notSupportWeightedPolicyInfos) {
-      // root.c uses UniformBroadcastPolicyManager.
-      // Step1. Prepare routerPolicyWeights.
-      WeightedPolicyInfo weightedPolicyInfo = new WeightedPolicyInfo();
-      weightedPolicyInfo.setHeadroomAlpha(1);
-
-      // Step2. Set PolicyConfiguration.
-      SubClusterPolicyConfiguration config = SubClusterPolicyConfiguration.newInstance("root.c",
-          policyManagerType, weightedPolicyInfo.toByteBuffer());
-      SetSubClusterPolicyConfigurationRequest request =
-          SetSubClusterPolicyConfigurationRequest.newInstance(config);
-      stateStore.setPolicyConfiguration(request);
-
-      // Step3. Get FederationPolicyManager using policyFacade.
-      facade.reinitialize(stateStore, conf);
-      policyFacade = new GPGPolicyFacade(facade, conf);
-      FederationPolicyManager policyManager = policyFacade.getPolicyManager("root.c");
-      Assert.assertNotNull(policyManager);
-      Assert.assertFalse(policyManager.isSupportWeightedPolicyInfo());
-      String policyManagerTypeSimple = policyManagerType.replace(prefix, "");
-      // Verify that PolicyManager is initialized successfully,
-      // but getWeightedPolicyInfo is not supported.
-      LambdaTestUtils.intercept(NotImplementedException.class,
-          policyManagerTypeSimple + " does not implement getWeightedPolicyInfo.",
-          () -> policyManager.getWeightedPolicyInfo());
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/TestGlobalPolicyGenerator.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/TestGlobalPolicyGenerator.java
deleted file mode 100644
index a32970488f9..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/TestGlobalPolicyGenerator.java
+++ /dev/null
@@ -1,86 +0,0 @@
-/**
- *  Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.CommonConfigurationKeysPublic;
-import org.apache.hadoop.service.Service;
-import org.apache.hadoop.test.GenericTestUtils;
-import org.apache.hadoop.test.LambdaTestUtils;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.junit.Test;
-
-import java.io.ByteArrayOutputStream;
-import java.io.PrintStream;
-import java.util.List;
-import java.util.concurrent.TimeoutException;
-
-import static org.junit.Assert.assertTrue;
-
-/**
- * Unit test for GlobalPolicyGenerator.
- */
-public class TestGlobalPolicyGenerator {
-
-  @Test(timeout = 1000)
-  public void testNonFederation() {
-    Configuration conf = new YarnConfiguration();
-    conf.setBoolean(YarnConfiguration.FEDERATION_ENABLED, false);
-
-    // If GPG starts running, this call will not return
-    GlobalPolicyGenerator.startGPG(new String[0], conf);
-  }
-
-  @Test
-  public void testGpgWithFederation() throws InterruptedException, TimeoutException {
-    // In this test case, we hope that gpg can start normally in federation mode.
-    Configuration conf = new YarnConfiguration();
-    conf.setBoolean(YarnConfiguration.FEDERATION_ENABLED, true);
-
-    GlobalPolicyGenerator gpg = new GlobalPolicyGenerator();
-    gpg.initAndStart(conf, false);
-
-    GenericTestUtils.waitFor(() -> {
-      List<Service> services = gpg.getServices();
-      return (services.size() == 1 && gpg.getWebApp() != null);
-    }, 100, 5000);
-  }
-
-  @Test
-  public void testGPGCLI() {
-    ByteArrayOutputStream dataOut = new ByteArrayOutputStream();
-    ByteArrayOutputStream dataErr = new ByteArrayOutputStream();
-    System.setOut(new PrintStream(dataOut));
-    System.setErr(new PrintStream(dataErr));
-    GlobalPolicyGenerator.main(new String[]{"-help", "-format-policy-store"});
-    assertTrue(dataErr.toString().contains(
-        "Usage: yarn gpg [-format-policy-store]"));
-  }
-
-  @Test
-  public void testUserProvidedUGIConf() throws Exception {
-    String errMsg = "Invalid attribute value for " +
-        CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION + " of DUMMYAUTH";
-    Configuration dummyConf = new YarnConfiguration();
-    dummyConf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION, "DUMMYAUTH");
-    GlobalPolicyGenerator gpg = new GlobalPolicyGenerator();
-    LambdaTestUtils.intercept(IllegalArgumentException.class, errMsg, () -> gpg.init(dummyConf));
-    gpg.stop();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/applicationcleaner/TestDefaultApplicationCleaner.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/applicationcleaner/TestDefaultApplicationCleaner.java
deleted file mode 100644
index c028bbdbe2c..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/applicationcleaner/TestDefaultApplicationCleaner.java
+++ /dev/null
@@ -1,204 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator.applicationcleaner;
-
-import java.util.ArrayList;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.registry.client.api.RegistryOperations;
-import org.apache.hadoop.registry.client.impl.FSRegistryOperationsService;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.security.token.Token;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-import org.apache.hadoop.yarn.security.AMRMTokenIdentifier;
-import org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore;
-import org.apache.hadoop.yarn.server.federation.store.records.AddApplicationHomeSubClusterRequest;
-import org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster;
-import org.apache.hadoop.yarn.server.federation.store.records.GetApplicationsHomeSubClusterRequest;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.GetApplicationsHomeSubClusterResponse;
-import org.apache.hadoop.yarn.server.federation.utils.FederationRegistryClient;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GPGContext;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GPGContextImpl;
-import org.junit.After;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Test;
-
-/**
- * Unit test for DefaultApplicationCleaner in GPG.
- */
-public class TestDefaultApplicationCleaner {
-  private Configuration conf;
-  private MemoryFederationStateStore stateStore;
-  private FederationStateStoreFacade facade;
-  private ApplicationCleaner appCleaner;
-  private GPGContext gpgContext;
-  private RegistryOperations registry;
-  private FederationRegistryClient registryClient;
-
-  private List<ApplicationId> appIds;
-  // The list of applications returned by mocked router
-  private Set<ApplicationId> routerAppIds;
-
-  private ApplicationId appIdToAddConcurrently;
-
-  @Before
-  public void setup() throws Exception {
-    conf = new YarnConfiguration();
-
-    // No Router query retry
-    conf.set(YarnConfiguration.GPG_APPCLEANER_CONTACT_ROUTER_SPEC, "1,1,0");
-
-    stateStore = new MemoryFederationStateStore();
-    stateStore.init(conf);
-
-    facade = FederationStateStoreFacade.getInstance();
-    facade.reinitialize(stateStore, conf);
-
-    registry = new FSRegistryOperationsService();
-    registry.init(conf);
-    registry.start();
-
-    UserGroupInformation user = UserGroupInformation.getCurrentUser();
-    registryClient = new FederationRegistryClient(conf, registry, user);
-    registryClient.cleanAllApplications();
-    Assert.assertEquals(0, registryClient.getAllApplications().size());
-
-    gpgContext = new GPGContextImpl();
-    gpgContext.setStateStoreFacade(facade);
-    gpgContext.setRegistryClient(registryClient);
-
-    appCleaner = new TestableDefaultApplicationCleaner();
-    appCleaner.init(conf, gpgContext);
-
-    routerAppIds = new HashSet<>();
-
-    appIds = new ArrayList<>();
-    for (int i = 0; i < 3; i++) {
-      ApplicationId appId = ApplicationId.newInstance(0, i);
-      appIds.add(appId);
-
-      SubClusterId subClusterId =
-          SubClusterId.newInstance("SUBCLUSTER-" + i);
-
-      stateStore.addApplicationHomeSubCluster(
-          AddApplicationHomeSubClusterRequest.newInstance(
-              ApplicationHomeSubCluster.newInstance(appId, subClusterId)));
-
-      // Write some registry entries for the app
-      registryClient.writeAMRMTokenForUAM(appId, subClusterId.toString(),
-          new Token<AMRMTokenIdentifier>());
-    }
-    Assert.assertEquals(3, registryClient.getAllApplications().size());
-    appIdToAddConcurrently = null;
-  }
-
-  @After
-  public void breakDown() {
-    if (stateStore != null) {
-      stateStore.close();
-      stateStore = null;
-    }
-    if (registryClient != null) {
-      registryClient.cleanAllApplications();
-      registryClient = null;
-    }
-    if (registry != null) {
-      registry.stop();
-      registry = null;
-    }
-  }
-
-  @Test
-  public void testFederationStateStoreAppsCleanUp() throws YarnException {
-    // Set first app to be still known by Router
-    ApplicationId appId = appIds.get(0);
-    routerAppIds.add(appId);
-
-    // Another random app not in stateStore known by Router
-    appId = ApplicationId.newInstance(100, 200);
-    routerAppIds.add(appId);
-
-    appCleaner.run();
-
-    // Only one app should be left
-    Assert.assertEquals(1,
-        stateStore
-            .getApplicationsHomeSubCluster(
-                GetApplicationsHomeSubClusterRequest.newInstance())
-            .getAppsHomeSubClusters().size());
-
-    // The known app should not be cleaned in registry
-    Assert.assertEquals(1, registryClient.getAllApplications().size());
-  }
-
-  /**
-   * Testable version of DefaultApplicationCleaner.
-   */
-  public class TestableDefaultApplicationCleaner
-      extends DefaultApplicationCleaner {
-    @Override
-    public Set<ApplicationId> getAppsFromRouter() throws YarnRuntimeException {
-      if (appIdToAddConcurrently != null) {
-        SubClusterId scId = SubClusterId.newInstance("MySubClusterId");
-        try {
-          ApplicationHomeSubCluster appHomeSubCluster =
-              ApplicationHomeSubCluster.newInstance(appIdToAddConcurrently, scId);
-          AddApplicationHomeSubClusterRequest request =
-              AddApplicationHomeSubClusterRequest.newInstance(appHomeSubCluster);
-          stateStore.addApplicationHomeSubCluster(request);
-        } catch (YarnException e) {
-          throw new YarnRuntimeException(e);
-        }
-        registryClient.writeAMRMTokenForUAM(appIdToAddConcurrently, scId.toString(),
-            new Token<>());
-      }
-      return routerAppIds;
-    }
-  }
-
-  @Test
-  public void testConcurrentNewApp() throws YarnException {
-    appIdToAddConcurrently = ApplicationId.newInstance(1, 1);
-
-    appCleaner.run();
-
-    // The concurrently added app should be still there
-    GetApplicationsHomeSubClusterRequest appHomeSubClusterRequest =
-         GetApplicationsHomeSubClusterRequest.newInstance();
-    GetApplicationsHomeSubClusterResponse applicationsHomeSubCluster =
-        stateStore.getApplicationsHomeSubCluster(appHomeSubClusterRequest);
-    Assert.assertNotNull(applicationsHomeSubCluster);
-    List<ApplicationHomeSubCluster> appsHomeSubClusters =
-        applicationsHomeSubCluster.getAppsHomeSubClusters();
-    Assert.assertNotNull(appsHomeSubClusters);
-    Assert.assertEquals(1, appsHomeSubClusters.size());
-
-    // The concurrently added app should be still there
-    Assert.assertEquals(1, registryClient.getAllApplications().size());
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/TestLoadBasedGlobalPolicy.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/TestLoadBasedGlobalPolicy.java
deleted file mode 100644
index df58b30aaaa..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/TestLoadBasedGlobalPolicy.java
+++ /dev/null
@@ -1,206 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator.policygenerator;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterIdInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.junit.Before;
-import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.FEDERATION_GPG_LOAD_BASED_MAX_EDIT;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.FEDERATION_GPG_LOAD_BASED_MIN_PENDING;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.FEDERATION_GPG_LOAD_BASED_MAX_PENDING;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.FEDERATION_GPG_LOAD_BASED_MIN_WEIGHT;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.FEDERATION_GPG_LOAD_BASED_SCALING;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.DEFAULT_FEDERATION_GPG_LOAD_BASED_SCALING;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertTrue;
-
-/**
- * Unit test for the Load Based Global Policy.
- */
-public class TestLoadBasedGlobalPolicy {
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestLoadBasedGlobalPolicy.class);
-
-  private static final int NUM_SC = 3;
-  private static final float DELTA = 0.00001f;
-
-  private static final int MIN_PENDING = 100;
-  private static final int MAX_PENDING = 500;
-
-  private List<SubClusterId> subClusterIds;
-  private Map<SubClusterId, ClusterMetricsInfo> clusterMetricsInfos;
-  private Map<SubClusterIdInfo, Float> weights;
-
-  private final Configuration conf;
-  private final LoadBasedGlobalPolicy policyGenerator;
-
-  public TestLoadBasedGlobalPolicy() {
-    conf = new Configuration();
-    policyGenerator = new LoadBasedGlobalPolicy();
-  }
-
-  @Before
-  public void setUp() {
-
-    conf.setInt(FEDERATION_GPG_LOAD_BASED_MAX_EDIT, 2);
-    conf.setInt(FEDERATION_GPG_LOAD_BASED_MIN_PENDING, MIN_PENDING);
-    conf.setInt(FEDERATION_GPG_LOAD_BASED_MAX_PENDING, MAX_PENDING);
-    conf.setFloat(FEDERATION_GPG_LOAD_BASED_MIN_WEIGHT, 0.0f);
-    conf.set(FEDERATION_GPG_LOAD_BASED_SCALING, LoadBasedGlobalPolicy.Scaling.LINEAR.name());
-    policyGenerator.setConf(conf);
-
-    subClusterIds = new ArrayList<>();
-    clusterMetricsInfos = new HashMap<>();
-    // Set up sub clusters
-    for (int i = 0; i < NUM_SC; ++i) {
-      // subClusterId
-      SubClusterId id = SubClusterId.newInstance("sc" + i);
-      subClusterIds.add(id);
-
-      // Cluster metrics info
-      ClusterMetricsInfo metricsInfo = new ClusterMetricsInfo();
-      metricsInfo.setAppsPending(50);
-      clusterMetricsInfos.put(id, metricsInfo);
-    }
-  }
-
-  @Test
-  public void testSimpleTargetWeights() {
-    weights = policyGenerator.getTargetWeights(clusterMetricsInfos);
-    assertEquals(weights.size(), 3);
-    assertEquals(1.0, getWeight(0), DELTA);
-    assertEquals(1.0, getWeight(1), DELTA);
-    assertEquals(1.0, getWeight(2), DELTA);
-  }
-
-  @Test
-  public void testLoadTargetWeights() {
-    getMetric(0).setAppsPending(100);
-    weights = policyGenerator.getTargetWeights(clusterMetricsInfos);
-    assertEquals(weights.size(), 3);
-    assertEquals(1.0, getWeight(0), DELTA);
-    assertEquals(1.0, getWeight(1), DELTA);
-    assertEquals(1.0, getWeight(2), DELTA);
-    getMetric(0).setAppsPending(500);
-    weights = policyGenerator.getTargetWeights(clusterMetricsInfos);
-    assertEquals(weights.size(), 3);
-    assertEquals(0.0, getWeight(0), DELTA);
-    assertEquals(1.0, getWeight(1), DELTA);
-    assertEquals(1.0, getWeight(2), DELTA);
-  }
-
-  @Test
-  public void testMaxEdit() {
-    // The policy should be able to edit 2 weights
-    getMetric(0).setAppsPending(MAX_PENDING + 200);
-    getMetric(1).setAppsPending(MAX_PENDING + 100);
-    weights = policyGenerator.getTargetWeights(clusterMetricsInfos);
-    assertEquals(weights.size(), 3);
-    assertEquals(0.0, getWeight(0), DELTA);
-    assertEquals(0.0, getWeight(1), DELTA);
-    assertEquals(1.0, getWeight(2), DELTA);
-    // After updating the config, it should only edit the most loaded
-    conf.setInt(FEDERATION_GPG_LOAD_BASED_MAX_EDIT, 1);
-    policyGenerator.setConf(conf);
-    weights = policyGenerator.getTargetWeights(clusterMetricsInfos);
-    assertEquals(weights.size(), 3);
-    assertEquals(0.0, getWeight(0), DELTA);
-    assertEquals(1.0, getWeight(1), DELTA);
-    assertEquals(1.0, getWeight(2), DELTA);
-  }
-
-  @Test
-  public void testMinWeight() {
-    // If a minimum weight is set, the generator should not go below it
-    conf.setFloat(FEDERATION_GPG_LOAD_BASED_MIN_WEIGHT, 0.5f);
-    policyGenerator.setConf(conf);
-    getMetric(0).setAppsPending(Integer.MAX_VALUE);
-    weights = policyGenerator.getTargetWeights(clusterMetricsInfos);
-    assertEquals(weights.size(), 3);
-    assertEquals(0.5, getWeight(0), DELTA);
-    assertEquals(1.0, getWeight(1), DELTA);
-    assertEquals(1.0, getWeight(2), DELTA);
-  }
-
-  @Test
-  public void testScaling() {
-    LOG.info("Testing that the generator weights are monotonically"
-        + " decreasing regardless of scaling method");
-    for (LoadBasedGlobalPolicy.Scaling scaling :
-        new LoadBasedGlobalPolicy.Scaling[] {LoadBasedGlobalPolicy.Scaling.LINEAR,
-            LoadBasedGlobalPolicy.Scaling.QUADRATIC, LoadBasedGlobalPolicy.Scaling.LOG }) {
-      LOG.info("Testing {} scaling...", scaling);
-      conf.set(DEFAULT_FEDERATION_GPG_LOAD_BASED_SCALING, scaling.name());
-      policyGenerator.setConf(conf);
-      // Test a continuous range for scaling
-      float prevWeight = 1.01f;
-      for (int load = 0; load < MAX_PENDING * 2; ++load) {
-        getMetric(0).setAppsPending(load);
-        weights = policyGenerator.getTargetWeights(clusterMetricsInfos);
-        if (load < MIN_PENDING) {
-          // Below the minimum load, it should stay 1.0f
-          assertEquals(1.0f, getWeight(0), DELTA);
-        } else if (load < MAX_PENDING) {
-          // In the specified range, the weight should consistently decrease
-          float weight = getWeight(0);
-          assertTrue(weight < prevWeight);
-          prevWeight = weight;
-        } else {
-          // Above the maximum load, it should stay 0.0f
-          assertEquals(0.0f, getWeight(0), DELTA);
-        }
-      }
-    }
-  }
-
-  @Test
-  public void testNonZero() {
-    // If all generated weights are zero, they should be set back to one
-    conf.setFloat(FEDERATION_GPG_LOAD_BASED_MIN_WEIGHT, 0.0f);
-    conf.setInt(FEDERATION_GPG_LOAD_BASED_MAX_EDIT, 3);
-    policyGenerator.setConf(conf);
-    getMetric(0).setAppsPending(Integer.MAX_VALUE);
-    getMetric(1).setAppsPending(Integer.MAX_VALUE);
-    getMetric(2).setAppsPending(Integer.MAX_VALUE);
-    weights = policyGenerator.getTargetWeights(clusterMetricsInfos);
-    assertEquals(weights.size(), 3);
-    assertEquals(1.0, getWeight(0), DELTA);
-    assertEquals(1.0, getWeight(1), DELTA);
-    assertEquals(1.0, getWeight(2), DELTA);
-  }
-
-  private float getWeight(int sc) {
-    return weights.get(new SubClusterIdInfo(subClusterIds.get(sc)));
-  }
-
-  private ClusterMetricsInfo getMetric(int sc) {
-    return clusterMetricsInfos.get(subClusterIds.get(sc));
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/TestPolicyGenerator.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/TestPolicyGenerator.java
deleted file mode 100644
index 446eeee2cd9..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/policygenerator/TestPolicyGenerator.java
+++ /dev/null
@@ -1,392 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator.policygenerator;
-
-import com.sun.jersey.api.json.JSONConfiguration;
-import com.sun.jersey.api.json.JSONJAXBContext;
-import com.sun.jersey.api.json.JSONUnmarshaller;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.net.NetUtils;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.federation.policies.manager.FederationPolicyManager;
-import org.apache.hadoop.yarn.server.federation.policies.manager.WeightedLocalityPolicyManager;
-import org.apache.hadoop.yarn.server.federation.store.FederationStateStore;
-import org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPolicyConfigurationRequest;
-import org.apache.hadoop.yarn.server.federation.store.records.GetSubClusterPolicyConfigurationResponse;
-import org.apache.hadoop.yarn.server.federation.store.records.GetSubClustersInfoResponse;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterState;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GPGContext;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GPGContextImpl;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GPGPolicyFacade;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GPGUtils;
-import org.apache.hadoop.yarn.server.resourcemanager.ResourceManager;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceScheduler;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.CapacitySchedulerInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerTypeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.CapacitySchedulerQueueInfoList;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.CapacitySchedulerQueueInfo;
-import org.apache.hadoop.yarn.webapp.util.WebAppUtils;
-import org.junit.After;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Test;
-import org.mockito.ArgumentCaptor;
-
-import javax.xml.bind.JAXBException;
-import java.io.IOException;
-import java.io.StringReader;
-import java.net.InetSocketAddress;
-import java.nio.file.Files;
-import java.nio.file.Paths;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
-
-import static org.junit.Assert.assertEquals;
-import static org.mockito.Matchers.any;
-import static org.mockito.Matchers.eq;
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.times;
-import static org.mockito.Mockito.verify;
-import static org.mockito.Mockito.when;
-
-/**
- * Unit test for GPG Policy Generator.
- */
-public class TestPolicyGenerator {
-
-  private static final int NUM_SC = 3;
-
-  private Configuration conf;
-  private FederationStateStore stateStore;
-  private FederationStateStoreFacade facade;
-
-  private List<SubClusterId> subClusterIds;
-  private Map<SubClusterId, SubClusterInfo> subClusterInfos;
-  private Map<SubClusterId, Map<Class, Object>> clusterInfos;
-  private Map<SubClusterId, SchedulerInfo> schedulerInfos;
-
-  private GPGContext gpgContext;
-
-  private PolicyGenerator policyGenerator;
-
-  public TestPolicyGenerator() {
-    conf = new Configuration();
-    conf.setInt(YarnConfiguration.FEDERATION_CACHE_TIME_TO_LIVE_SECS, 0);
-    facade = FederationStateStoreFacade.getInstance(conf);
-    gpgContext = new GPGContextImpl();
-    gpgContext.setPolicyFacade(new GPGPolicyFacade(facade, conf));
-    gpgContext.setStateStoreFacade(facade);
-
-  }
-
-  @Before
-  public void setUp() throws IOException, YarnException, JAXBException {
-    subClusterIds = new ArrayList<>();
-    subClusterInfos = new HashMap<>();
-    clusterInfos = new HashMap<>();
-    schedulerInfos = new HashMap<>();
-
-    CapacitySchedulerInfo sti1 =
-        readJSON("src/test/resources/schedulerInfo1.json",
-            CapacitySchedulerInfo.class);
-    CapacitySchedulerInfo sti2 =
-        readJSON("src/test/resources/schedulerInfo2.json",
-            CapacitySchedulerInfo.class);
-
-    // Set up sub clusters
-    for (int i = 0; i < NUM_SC; ++i) {
-      // Sub cluster Id
-      SubClusterId id = SubClusterId.newInstance("sc" + i);
-      subClusterIds.add(id);
-
-      // Sub cluster info
-      SubClusterInfo cluster = SubClusterInfo
-          .newInstance(id, "amrm:" + i, "clientrm:" + i, "rmadmin:" + i,
-              "rmweb:" + i, SubClusterState.SC_RUNNING, 0, "");
-      subClusterInfos.put(id, cluster);
-
-      // Cluster metrics info
-      ClusterMetricsInfo metricsInfo = new ClusterMetricsInfo();
-      metricsInfo.setAppsPending(2000);
-      if (!clusterInfos.containsKey(id)) {
-        clusterInfos.put(id, new HashMap<Class, Object>());
-      }
-      clusterInfos.get(id).put(ClusterMetricsInfo.class, metricsInfo);
-
-      schedulerInfos.put(id, sti1);
-    }
-
-    // Change one of the sub cluster schedulers
-    schedulerInfos.put(subClusterIds.get(0), sti2);
-
-    stateStore = mock(FederationStateStore.class);
-    when(stateStore.getSubClusters(any()))
-        .thenReturn(GetSubClustersInfoResponse.newInstance(
-        new ArrayList<>(subClusterInfos.values())));
-    facade.reinitialize(stateStore, conf);
-  }
-
-  @After
-  public void tearDown() throws Exception {
-    stateStore.close();
-    stateStore = null;
-  }
-
-  private <T> T readJSON(String pathname, Class<T> classy)
-      throws IOException, JAXBException {
-
-    JSONJAXBContext jc =
-        new JSONJAXBContext(JSONConfiguration.mapped().build(), classy);
-    JSONUnmarshaller unmarshaller = jc.createJSONUnmarshaller();
-    String contents = new String(Files.readAllBytes(Paths.get(pathname)));
-    return unmarshaller.unmarshalFromJSON(new StringReader(contents), classy);
-
-  }
-
-  @Test
-  public void testPolicyGenerator() throws YarnException {
-    policyGenerator = new TestablePolicyGenerator();
-    policyGenerator.setPolicy(mock(GlobalPolicy.class));
-    policyGenerator.run();
-    verify(policyGenerator.getPolicy(), times(1))
-        .updatePolicy("default", clusterInfos, null);
-    verify(policyGenerator.getPolicy(), times(1))
-        .updatePolicy("default2", clusterInfos, null);
-  }
-
-  @Test
-  public void testBlacklist() throws YarnException {
-    conf.set(YarnConfiguration.GPG_POLICY_GENERATOR_BLACKLIST,
-        subClusterIds.get(0).toString());
-    Map<SubClusterId, Map<Class, Object>> blacklistedCMI =
-        new HashMap<>(clusterInfos);
-    blacklistedCMI.remove(subClusterIds.get(0));
-    policyGenerator = new TestablePolicyGenerator();
-    policyGenerator.setPolicy(mock(GlobalPolicy.class));
-    policyGenerator.run();
-    verify(policyGenerator.getPolicy(), times(1))
-        .updatePolicy("default", blacklistedCMI, null);
-    verify(policyGenerator.getPolicy(), times(0))
-        .updatePolicy("default", clusterInfos, null);
-  }
-
-  @Test
-  public void testBlacklistTwo() throws YarnException {
-    conf.set(YarnConfiguration.GPG_POLICY_GENERATOR_BLACKLIST,
-        subClusterIds.get(0).toString() + "," + subClusterIds.get(1)
-            .toString());
-    Map<SubClusterId, Map<Class, Object>> blacklistedCMI =
-        new HashMap<>(clusterInfos);
-    blacklistedCMI.remove(subClusterIds.get(0));
-    blacklistedCMI.remove(subClusterIds.get(1));
-    policyGenerator = new TestablePolicyGenerator();
-    policyGenerator.setPolicy(mock(GlobalPolicy.class));
-    policyGenerator.run();
-    verify(policyGenerator.getPolicy(), times(1))
-        .updatePolicy("default", blacklistedCMI, null);
-    verify(policyGenerator.getPolicy(), times(0))
-        .updatePolicy("default", clusterInfos, null);
-  }
-
-  @Test
-  public void testExistingPolicy() throws YarnException {
-    WeightedLocalityPolicyManager manager = new WeightedLocalityPolicyManager();
-    // Add a test policy for test queue
-    manager.setQueue("default");
-    manager.getWeightedPolicyInfo().setAMRMPolicyWeights(GPGUtils
-        .createUniformWeights(new HashSet<>(subClusterIds)));
-    manager.getWeightedPolicyInfo().setRouterPolicyWeights(GPGUtils
-        .createUniformWeights(new HashSet<>(subClusterIds)));
-    SubClusterPolicyConfiguration testConf = manager.serializeConf();
-    when(stateStore.getPolicyConfiguration(
-        GetSubClusterPolicyConfigurationRequest.newInstance("default")))
-        .thenReturn(
-            GetSubClusterPolicyConfigurationResponse.newInstance(testConf));
-
-    policyGenerator = new TestablePolicyGenerator();
-    policyGenerator.setPolicy(mock(GlobalPolicy.class));
-    policyGenerator.run();
-
-    ArgumentCaptor<FederationPolicyManager> argCaptor =
-        ArgumentCaptor.forClass(FederationPolicyManager.class);
-    verify(policyGenerator.getPolicy(), times(1))
-        .updatePolicy(eq("default"), eq(clusterInfos), argCaptor.capture());
-    assertEquals(argCaptor.getValue().getClass(), manager.getClass());
-    assertEquals(argCaptor.getValue().serializeConf(), manager.serializeConf());
-  }
-
-  @Test
-  public void testCallRM() {
-
-    CapacitySchedulerConfiguration csConf =
-        new CapacitySchedulerConfiguration();
-
-    final String a = CapacitySchedulerConfiguration.ROOT + ".a";
-    final String b = CapacitySchedulerConfiguration.ROOT + ".b";
-    final String a1 = a + ".a1";
-    final String a2 = a + ".a2";
-    final String b1 = b + ".b1";
-    final String b2 = b + ".b2";
-    final String b3 = b + ".b3";
-    float aCapacity = 10.5f;
-    float bCapacity = 89.5f;
-    float a1Capacity = 30;
-    float a2Capacity = 70;
-    float b1Capacity = 79.2f;
-    float b2Capacity = 0.8f;
-    float b3Capacity = 20;
-
-    // Define top-level queues
-    csConf.setQueues(CapacitySchedulerConfiguration.ROOT,
-        new String[] {"a", "b"});
-
-    csConf.setCapacity(a, aCapacity);
-    csConf.setCapacity(b, bCapacity);
-
-    // Define 2nd-level queues
-    csConf.setQueues(a, new String[] {"a1", "a2"});
-    csConf.setCapacity(a1, a1Capacity);
-    csConf.setUserLimitFactor(a1, 100.0f);
-    csConf.setCapacity(a2, a2Capacity);
-    csConf.setUserLimitFactor(a2, 100.0f);
-
-    csConf.setQueues(b, new String[] {"b1", "b2", "b3"});
-    csConf.setCapacity(b1, b1Capacity);
-    csConf.setUserLimitFactor(b1, 100.0f);
-    csConf.setCapacity(b2, b2Capacity);
-    csConf.setUserLimitFactor(b2, 100.0f);
-    csConf.setCapacity(b3, b3Capacity);
-    csConf.setUserLimitFactor(b3, 100.0f);
-
-    YarnConfiguration rmConf = new YarnConfiguration(csConf);
-
-    ResourceManager resourceManager = new ResourceManager();
-    rmConf.setClass(YarnConfiguration.RM_SCHEDULER, CapacityScheduler.class,
-        ResourceScheduler.class);
-    resourceManager.init(rmConf);
-    resourceManager.start();
-
-    String rmAddress = WebAppUtils.getRMWebAppURLWithScheme(this.conf);
-    String webAppAddress = getServiceAddress(NetUtils.createSocketAddr(rmAddress));
-
-    SchedulerTypeInfo sti = GPGUtils.invokeRMWebService(webAppAddress, RMWSConsts.SCHEDULER,
-        SchedulerTypeInfo.class, conf);
-
-    Assert.assertNotNull(sti);
-    SchedulerInfo schedulerInfo = sti.getSchedulerInfo();
-    Assert.assertTrue(schedulerInfo instanceof CapacitySchedulerInfo);
-
-    CapacitySchedulerInfo capacitySchedulerInfo = (CapacitySchedulerInfo) schedulerInfo;
-    Assert.assertNotNull(capacitySchedulerInfo);
-
-    CapacitySchedulerQueueInfoList queues = capacitySchedulerInfo.getQueues();
-    Assert.assertNotNull(queues);
-    ArrayList<CapacitySchedulerQueueInfo> queueInfoList = queues.getQueueInfoList();
-    Assert.assertNotNull(queueInfoList);
-    Assert.assertEquals(2, queueInfoList.size());
-
-    CapacitySchedulerQueueInfo queueA = queueInfoList.get(0);
-    Assert.assertNotNull(queueA);
-    Assert.assertEquals("root.a", queueA.getQueuePath());
-    Assert.assertEquals(10.5f, queueA.getCapacity(), 0.00001);
-    CapacitySchedulerQueueInfoList queueAQueues = queueA.getQueues();
-    Assert.assertNotNull(queueAQueues);
-    ArrayList<CapacitySchedulerQueueInfo> queueInfoAList = queueAQueues.getQueueInfoList();
-    Assert.assertNotNull(queueInfoAList);
-    Assert.assertEquals(2, queueInfoAList.size());
-    CapacitySchedulerQueueInfo queueA1 = queueInfoAList.get(0);
-    Assert.assertNotNull(queueA1);
-    Assert.assertEquals(30f, queueA1.getCapacity(), 0.00001);
-    CapacitySchedulerQueueInfo queueA2 = queueInfoAList.get(1);
-    Assert.assertNotNull(queueA2);
-    Assert.assertEquals(70f, queueA2.getCapacity(), 0.00001);
-
-    CapacitySchedulerQueueInfo queueB = queueInfoList.get(1);
-    Assert.assertNotNull(queueB);
-    Assert.assertEquals("root.b", queueB.getQueuePath());
-    Assert.assertEquals(89.5f, queueB.getCapacity(), 0.00001);
-    CapacitySchedulerQueueInfoList queueBQueues = queueB.getQueues();
-    Assert.assertNotNull(queueBQueues);
-    ArrayList<CapacitySchedulerQueueInfo> queueInfoBList = queueBQueues.getQueueInfoList();
-    Assert.assertNotNull(queueInfoBList);
-    Assert.assertEquals(3, queueInfoBList.size());
-    CapacitySchedulerQueueInfo queueB1 = queueInfoBList.get(0);
-    Assert.assertNotNull(queueB1);
-    Assert.assertEquals(79.2f, queueB1.getCapacity(), 0.00001);
-    CapacitySchedulerQueueInfo queueB2 = queueInfoBList.get(1);
-    Assert.assertNotNull(queueB2);
-    Assert.assertEquals(0.8f, queueB2.getCapacity(), 0.00001);
-    CapacitySchedulerQueueInfo queueB3 = queueInfoBList.get(2);
-    Assert.assertNotNull(queueB3);
-    Assert.assertEquals(20f, queueB3.getCapacity(), 0.00001);
-  }
-
-  private String getServiceAddress(InetSocketAddress address) {
-    InetSocketAddress socketAddress = NetUtils.getConnectAddress(address);
-    return socketAddress.getAddress().getHostAddress() + ":" + socketAddress.getPort();
-  }
-
-  /**
-   * Testable policy generator overrides the methods that communicate
-   * with the RM REST endpoint, allowing us to inject faked responses.
-   */
-  class TestablePolicyGenerator extends PolicyGenerator {
-
-    TestablePolicyGenerator() {
-      super(conf, gpgContext);
-    }
-
-    @Override
-    protected Map<SubClusterId, Map<Class, Object>> getInfos(
-        Map<SubClusterId, SubClusterInfo> activeSubClusters) {
-      Map<SubClusterId, Map<Class, Object>> ret = new HashMap<>();
-      for (SubClusterId id : activeSubClusters.keySet()) {
-        if (!ret.containsKey(id)) {
-          ret.put(id, new HashMap<>());
-        }
-        ret.get(id).put(ClusterMetricsInfo.class,
-            clusterInfos.get(id).get(ClusterMetricsInfo.class));
-      }
-      return ret;
-    }
-
-    @Override
-    protected Map<SubClusterId, SchedulerInfo> getSchedulerInfo(
-        Map<SubClusterId, SubClusterInfo> activeSubClusters) {
-      Map<SubClusterId, SchedulerInfo> ret = new HashMap<>();
-      for (SubClusterId id : activeSubClusters.keySet()) {
-        ret.put(id, schedulerInfos.get(id));
-      }
-      return ret;
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/secure/AbstractGlobalPolicyGeneratorTest.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/secure/AbstractGlobalPolicyGeneratorTest.java
deleted file mode 100644
index 03a8e8f22c3..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/secure/AbstractGlobalPolicyGeneratorTest.java
+++ /dev/null
@@ -1,177 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator.secure;
-
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.CommonConfigurationKeysPublic;
-import org.apache.hadoop.metrics2.lib.DefaultMetricsSystem;
-import org.apache.hadoop.minikdc.MiniKdc;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GlobalPolicyGenerator;
-import org.junit.BeforeClass;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.File;
-import java.util.Properties;
-
-import static org.junit.Assert.assertNotNull;
-import static org.junit.Assert.assertNull;
-import static org.junit.Assert.assertTrue;
-
-public abstract class AbstractGlobalPolicyGeneratorTest {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(AbstractGlobalPolicyGeneratorTest.class);
-
-  ////////////////////////////////
-  // Kerberos Constants
-  ////////////////////////////////
-
-  public static final String REALM = "EXAMPLE.COM";
-  public static final String GPG = "gpg";
-  public static final String LOCALHOST = "localhost";
-  public static final String IP127001 = "127.0.0.1";
-  public static final String GPG_LOCALHOST = "gpg/" + LOCALHOST;
-  public static final String GPG_LOCALHOST_REALM = GPG_LOCALHOST + "@" + REALM;
-  public static final String SUN_SECURITY_KRB5_DEBUG = "sun.security.krb5.debug";
-  public static final String KERBEROS = "kerberos";
-
-  ////////////////////////////////
-  // BeforeSecureRouterTestClass Init
-  ////////////////////////////////
-
-  private static MiniKdc kdc;
-  private static File routerKeytab;
-  private static File kdcWorkDir;
-  private static Configuration conf;
-  private GlobalPolicyGenerator gpg;
-
-  @BeforeClass
-  public static void beforeSecureRouterTestClass() throws Exception {
-    // Sets up the KDC and Principals.
-    setupKDCAndPrincipals();
-
-    // Init YarnConfiguration
-    conf = new YarnConfiguration();
-
-    // Enable Kerberos authentication configuration
-    conf.setBoolean(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION, true);
-    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION, KERBEROS);
-
-    // Router Kerberos KeyTab configuration
-    conf.set(YarnConfiguration.GPG_PRINCIPAL, GPG_LOCALHOST_REALM);
-    conf.set(YarnConfiguration.GPG_KEYTAB, routerKeytab.getAbsolutePath());
-
-    DefaultMetricsSystem.setMiniClusterMode(true);
-  }
-
-  /**
-   * Sets up the KDC and Principals.
-   *
-   * @throws Exception an error occurred.
-   */
-  public static void setupKDCAndPrincipals() throws Exception {
-    // set up the KDC
-    File target = new File(System.getProperty("test.dir", "target"));
-    kdcWorkDir = new File(target, "kdc");
-    kdcWorkDir.mkdirs();
-    if (!kdcWorkDir.mkdirs()) {
-      assertTrue(kdcWorkDir.isDirectory());
-    }
-    Properties kdcConf = MiniKdc.createConf();
-    kdcConf.setProperty(MiniKdc.DEBUG, "true");
-    kdc = new MiniKdc(kdcConf, kdcWorkDir);
-    kdc.start();
-    routerKeytab = createKeytab(GPG, "gpg.keytab");
-  }
-
-  /**
-   * Create the keytab for the given principal, includes
-   * raw principal and $principal/localhost.
-   *
-   * @param principal principal short name.
-   * @param filename filename of keytab.
-   * @return file of keytab.
-   * @throws Exception an error occurred.
-   */
-  public static File createKeytab(String principal, String filename) throws Exception {
-    assertTrue("empty principal", StringUtils.isNotBlank(principal));
-    assertTrue("empty host", StringUtils.isNotBlank(filename));
-    assertNotNull("null KDC", kdc);
-    File keytab = new File(kdcWorkDir, filename);
-    kdc.createPrincipal(keytab,
-        principal,
-        principal + "/localhost",
-        principal + "/127.0.0.1");
-    return keytab;
-  }
-
-  /**
-   * Start the router in safe mode.
-   *
-   * @throws Exception an error occurred.
-   */
-  public synchronized void startSecureGPG() {
-    assertNull("GPG is already running", gpg);
-    MemoryFederationStateStore stateStore = new MemoryFederationStateStore();
-    stateStore.init(conf);
-    FederationStateStoreFacade.getInstance(conf).reinitialize(stateStore, conf);
-    UserGroupInformation.setConfiguration(conf);
-    gpg = new GlobalPolicyGenerator();
-    gpg.init(conf);
-    gpg.start();
-  }
-
-  /**
-   * Shut down the KDC service.
-   *
-   * @throws Exception an error occurred.
-   */
-  public static void teardownKDC() throws Exception {
-    if (kdc != null) {
-      kdc.stop();
-      kdc = null;
-    }
-  }
-
-  public GlobalPolicyGenerator getGpg() {
-    return gpg;
-  }
-
-  public static MiniKdc getKdc() {
-    return kdc;
-  }
-
-  /**
-   * Stop the router in safe mode.
-   *
-   * @throws Exception an error occurred.
-   */
-  protected synchronized void stopSecureRouter() throws Exception {
-    if (gpg != null) {
-      gpg.stop();
-      gpg = null;
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/secure/TestGpgSecureLogins.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/secure/TestGpgSecureLogins.java
deleted file mode 100644
index 990a587db50..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/secure/TestGpgSecureLogins.java
+++ /dev/null
@@ -1,50 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.globalpolicygenerator.secure;
-
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GPGContext;
-import org.junit.Assert;
-import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-public class TestGpgSecureLogins extends AbstractGlobalPolicyGeneratorTest {
-  private static final Logger LOG = LoggerFactory.getLogger(TestGpgSecureLogins.class);
-
-  @Test
-  public void testHasRealm() throws Throwable {
-    Assert.assertNotNull(getRealm());
-    LOG.info("Router principal = {}", getPrincipalAndRealm(GPG_LOCALHOST));
-  }
-
-  @Test
-  public void testRouterSecureLogin() throws Exception {
-    startSecureGPG();
-    GPGContext gpgContext = this.getGpg().getGPGContext();
-    Assert.assertNotNull(gpgContext);
-    stopSecureRouter();
-  }
-
-  public static String getPrincipalAndRealm(String principal) {
-    return principal + "@" + getRealm();
-  }
-
-  protected static String getRealm() {
-    return getKdc().getRealm();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/subclustercleaner/TestSubClusterCleaner.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/subclustercleaner/TestSubClusterCleaner.java
deleted file mode 100644
index 996aea820a8..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/subclustercleaner/TestSubClusterCleaner.java
+++ /dev/null
@@ -1,121 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.globalpolicygenerator.subclustercleaner;
-
-import java.util.ArrayList;
-import java.util.concurrent.TimeUnit;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterRegisterRequest;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterState;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GPGContext;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GPGContextImpl;
-import org.junit.After;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Test;
-
-/**
- * Unit test for Sub-cluster Cleaner in GPG.
- */
-public class TestSubClusterCleaner {
-
-  private Configuration conf;
-  private MemoryFederationStateStore stateStore;
-  private FederationStateStoreFacade facade;
-  private SubClusterCleaner cleaner;
-  private GPGContext gpgContext;
-
-  private static final long TWO_SECONDS = TimeUnit.SECONDS.toMillis(2);
-
-  private ArrayList<SubClusterId> subClusterIds;
-
-  @Before
-  public void setup() throws YarnException {
-    conf = new YarnConfiguration();
-
-    // subcluster expires in one second
-    conf.setLong(YarnConfiguration.GPG_SUBCLUSTER_EXPIRATION_MS, 1000);
-
-    stateStore = new MemoryFederationStateStore();
-    stateStore.init(conf);
-
-    facade = FederationStateStoreFacade.getInstance(conf);
-    facade.reinitialize(stateStore, conf);
-
-    gpgContext = new GPGContextImpl();
-    gpgContext.setStateStoreFacade(facade);
-
-    cleaner = new SubClusterCleaner(conf, gpgContext);
-
-    // Create and register six sub clusters
-    subClusterIds = new ArrayList<SubClusterId>();
-    for (int i = 0; i < 3; i++) {
-      // Create sub cluster id and info
-      SubClusterId subClusterId =
-          SubClusterId.newInstance("SUBCLUSTER-" + Integer.toString(i));
-
-      SubClusterInfo subClusterInfo = SubClusterInfo.newInstance(subClusterId,
-          "1.2.3.4:1", "1.2.3.4:2", "1.2.3.4:3", "1.2.3.4:4",
-          SubClusterState.SC_RUNNING, System.currentTimeMillis(), "");
-      // Register the sub cluster
-      stateStore.registerSubCluster(
-          SubClusterRegisterRequest.newInstance(subClusterInfo));
-      // Append the id to a local list
-      subClusterIds.add(subClusterId);
-    }
-  }
-
-  @After
-  public void breakDown() throws Exception {
-    stateStore.close();
-  }
-
-  @Test
-  public void testSubClusterRegisterHeartBeatTime() throws YarnException {
-    cleaner.run();
-    Assert.assertEquals(3, facade.getSubClusters(true, true).size());
-  }
-
-  /**
-   * Test the base use case.
-   */
-  @Test
-  public void testSubClusterHeartBeat() throws YarnException {
-    // The first subcluster reports as Unhealthy
-    SubClusterId subClusterId = subClusterIds.get(0);
-    stateStore.subClusterHeartbeat(SubClusterHeartbeatRequest
-        .newInstance(subClusterId, SubClusterState.SC_UNHEALTHY, "capacity"));
-
-    // The second subcluster didn't heartbeat for two seconds, should mark lost
-    subClusterId = subClusterIds.get(1);
-    stateStore.setSubClusterLastHeartbeat(subClusterId,
-        System.currentTimeMillis() - TWO_SECONDS);
-
-    cleaner.run();
-    Assert.assertEquals(1, facade.getSubClusters(true, true).size());
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/TestGPGWebApp.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/TestGPGWebApp.java
deleted file mode 100644
index 418a0716b4c..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/TestGPGWebApp.java
+++ /dev/null
@@ -1,51 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.globalpolicygenerator.webapp;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GlobalPolicyGenerator;
-import org.apache.hadoop.yarn.webapp.test.WebAppTests;
-import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-
-public class TestGPGWebApp {
-
-  private static final Logger LOG = LoggerFactory.getLogger(TestGPGWebApp.class);
-
-  @Test
-  public void testGPGPoliciesPageWebView()
-      throws InterruptedException, YarnException, IOException {
-    LOG.info("testGPGPoliciesPageWebView.");
-    WebAppTests.testPage(GPGPoliciesPage.class, GlobalPolicyGenerator.class,
-        new GlobalPolicyGenerator());
-  }
-
-  @Test
-  public void testGPGOverview()
-      throws InterruptedException, YarnException, IOException {
-    LOG.info("testGPGOverview.");
-    GlobalPolicyGenerator globalPolicyGenerator = new GlobalPolicyGenerator();
-    globalPolicyGenerator.setConfig(new Configuration());
-    WebAppTests.testPage(GPGOverviewPage.class, GlobalPolicyGenerator.class,
-        globalPolicyGenerator);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/TestGPGWebServices.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/TestGPGWebServices.java
deleted file mode 100644
index 9e665e0c8bb..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/java/org/apache/hadoop/yarn/server/globalpolicygenerator/webapp/TestGPGWebServices.java
+++ /dev/null
@@ -1,96 +0,0 @@
-/** * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.globalpolicygenerator.webapp;
-
-import com.google.inject.Guice;
-import com.google.inject.servlet.GuiceFilter;
-import com.google.inject.servlet.ServletModule;
-import com.sun.jersey.api.client.WebResource;
-import com.sun.jersey.guice.spi.container.servlet.GuiceContainer;
-import com.sun.jersey.test.framework.WebAppDescriptor;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GPGContext;
-import org.apache.hadoop.yarn.server.globalpolicygenerator.GlobalPolicyGenerator;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.JAXBContextResolver;
-import org.apache.hadoop.yarn.webapp.GenericExceptionHandler;
-import org.apache.hadoop.yarn.webapp.GuiceServletConfig;
-import org.apache.hadoop.yarn.webapp.JerseyTestBase;
-import org.apache.hadoop.yarn.webapp.WebApp;
-import org.codehaus.jettison.json.JSONException;
-import org.codehaus.jettison.json.JSONObject;
-import org.junit.Before;
-import org.junit.Test;
-
-import javax.ws.rs.core.MediaType;
-
-import static org.junit.Assert.assertNotNull;
-
-public class TestGPGWebServices extends JerseyTestBase {
-  private static GlobalPolicyGenerator gpg;
-  private static GPGWebApp webApp;
-
-  private static class XWebServletModule extends ServletModule {
-    @Override
-    protected void configureServlets() {
-      bind(JAXBContextResolver.class);
-      bind(GPGWebServices.class);
-      bind(GenericExceptionHandler.class);
-      gpg = new GlobalPolicyGenerator();
-      webApp = new GPGWebApp(gpg);
-      bind(WebApp.class).toInstance(webApp);
-      bind(GlobalPolicyGenerator.class).toInstance(gpg);
-      bind(GPGContext.class).toInstance(gpg.getGPGContext());
-      serve("/*").with(GuiceContainer.class);
-    }
-  }
-
-  static {
-    GuiceServletConfig.setInjector(
-        Guice.createInjector(new XWebServletModule()));
-  }
-
-  @Before
-  @Override
-  public void setUp() throws Exception {
-    super.setUp();
-    GuiceServletConfig.setInjector(
-        Guice.createInjector(new XWebServletModule()));
-  }
-
-  public TestGPGWebServices() {
-    super(new WebAppDescriptor.Builder(
-        "org.apache.hadoop.yarn.server.globalpolicygenerator.webapp")
-        .contextListenerClass(GuiceServletConfig.class)
-        .filterClass(GuiceFilter.class)
-        .contextPath("jersey-guice-filter").servletPath("/").build());
-  }
-
-  @Test
-  public void testGetGPG() throws JSONException, Exception {
-    WebResource r = resource();
-    JSONObject json = r.path("ws").path("v1").path("gpg")
-        .accept(MediaType.APPLICATION_JSON).get(JSONObject.class);
-    assertNotNull(json);
-  }
-
-  @Test
-  public void testGetGPGInfo() throws JSONException, Exception {
-    WebResource r = resource();
-    JSONObject json = r.path("ws").path("v1").path("gpg").path("info")
-        .accept(MediaType.APPLICATION_JSON).get(JSONObject.class);
-    assertNotNull(json);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/resources/schedulerInfo1.json b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/resources/schedulerInfo1.json
deleted file mode 100644
index 3ad45945f96..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/resources/schedulerInfo1.json
+++ /dev/null
@@ -1,134 +0,0 @@
-{
-  "capacity": 100.0,
-  "usedCapacity": 0.0,
-  "maxCapacity": 100.0,
-  "queueName": "root",
-  "queues": {
-    "queue": [
-      {
-        "type": "capacitySchedulerLeafQueueInfo",
-        "capacity": 100.0,
-        "usedCapacity": 0.0,
-        "maxCapacity": 100.0,
-        "absoluteCapacity": 100.0,
-        "absoluteMaxCapacity": 100.0,
-        "absoluteUsedCapacity": 0.0,
-        "numApplications": 484,
-        "queueName": "default",
-        "state": "RUNNING",
-        "resourcesUsed": {
-          "memory": 0,
-          "vCores": 0
-        },
-        "hideReservationQueues": false,
-        "nodeLabels": [
-          "*"
-        ],
-        "numActiveApplications": 484,
-        "numPendingApplications": 0,
-        "numContainers": 0,
-        "maxApplications": 10000,
-        "maxApplicationsPerUser": 10000,
-        "userLimit": 100,
-        "users": {
-          "user": [
-            {
-              "username": "Default",
-              "resourcesUsed": {
-                "memory": 0,
-                "vCores": 0
-              },
-              "numPendingApplications": 0,
-              "numActiveApplications": 468,
-              "AMResourceUsed": {
-                "memory": 30191616,
-                "vCores": 468
-              },
-              "userResourceLimit": {
-                "memory": 31490048,
-                "vCores": 7612
-              }
-            }
-          ]
-        },
-        "userLimitFactor": 1.0,
-        "AMResourceLimit": {
-          "memory": 31490048,
-          "vCores": 7612
-        },
-        "usedAMResource": {
-          "memory": 30388224,
-          "vCores": 532
-        },
-        "userAMResourceLimit": {
-          "memory": 31490048,
-          "vCores": 7612
-        },
-        "preemptionDisabled": true
-      }
-    ]
-  },
-  "health": {
-    "lastrun": 1517951638085,
-    "operationsInfo": {
-      "entry": {
-        "key": "last-allocation",
-        "value": {
-          "nodeId": "node0:0",
-          "containerId": "container_e61477_1517922128312_0340_01_000001",
-          "queue": "root.default"
-        }
-      },
-      "entry": {
-        "key": "last-reservation",
-        "value": {
-          "nodeId": "node0:1",
-          "containerId": "container_e61477_1517879828320_0249_01_000001",
-          "queue": "root.default"
-        }
-      },
-      "entry": {
-        "key": "last-release",
-        "value": {
-          "nodeId": "node0:2",
-          "containerId": "container_e61477_1517922128312_0340_01_000001",
-          "queue": "root.default"
-        }
-      },
-      "entry": {
-        "key": "last-preemption",
-        "value": {
-          "nodeId": "N/A",
-          "containerId": "N/A",
-          "queue": "N/A"
-        }
-      }
-    },
-    "lastRunDetails": [
-      {
-        "operation": "releases",
-        "count": 0,
-        "resources": {
-          "memory": 0,
-          "vCores": 0
-        }
-      },
-      {
-        "operation": "allocations",
-        "count": 0,
-        "resources": {
-          "memory": 0,
-          "vCores": 0
-        }
-      },
-      {
-        "operation": "reservations",
-        "count": 0,
-        "resources": {
-          "memory": 0,
-          "vCores": 0
-        }
-      }
-    ]
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/resources/schedulerInfo2.json b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/resources/schedulerInfo2.json
deleted file mode 100644
index 2ff879e8699..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-globalpolicygenerator/src/test/resources/schedulerInfo2.json
+++ /dev/null
@@ -1,196 +0,0 @@
- {
-      "type": "capacityScheduler",
-      "capacity": 100.0,
-      "usedCapacity": 0.0,
-      "maxCapacity": 100.0,
-      "queueName": "root",
-      "queues": {
-        "queue": [
-          {
-            "type": "capacitySchedulerLeafQueueInfo",
-            "capacity": 100.0,
-            "usedCapacity": 0.0,
-            "maxCapacity": 100.0,
-            "absoluteCapacity": 100.0,
-            "absoluteMaxCapacity": 100.0,
-            "absoluteUsedCapacity": 0.0,
-            "numApplications": 484,
-            "queueName": "default",
-            "state": "RUNNING",
-            "resourcesUsed": {
-              "memory": 0,
-              "vCores": 0
-            },
-            "hideReservationQueues": false,
-            "nodeLabels": [
-              "*"
-            ],
-            "numActiveApplications": 484,
-            "numPendingApplications": 0,
-            "numContainers": 0,
-            "maxApplications": 10000,
-            "maxApplicationsPerUser": 10000,
-            "userLimit": 100,
-            "users": {
-              "user": [
-                {
-                  "username": "Default",
-                  "resourcesUsed": {
-                    "memory": 0,
-                    "vCores": 0
-                  },
-                  "numPendingApplications": 0,
-                  "numActiveApplications": 468,
-                  "AMResourceUsed": {
-                    "memory": 30191616,
-                    "vCores": 468
-                  },
-                  "userResourceLimit": {
-                    "memory": 31490048,
-                    "vCores": 7612
-                  }
-                }
-              ]
-            },
-            "userLimitFactor": 1.0,
-            "AMResourceLimit": {
-              "memory": 31490048,
-              "vCores": 7612
-            },
-            "usedAMResource": {
-              "memory": 30388224,
-              "vCores": 532
-            },
-            "userAMResourceLimit": {
-              "memory": 31490048,
-              "vCores": 7612
-            },
-            "preemptionDisabled": true
-          },
-          {
-            "type": "capacitySchedulerLeafQueueInfo",
-            "capacity": 100.0,
-            "usedCapacity": 0.0,
-            "maxCapacity": 100.0,
-            "absoluteCapacity": 100.0,
-            "absoluteMaxCapacity": 100.0,
-            "absoluteUsedCapacity": 0.0,
-            "numApplications": 484,
-            "queueName": "default2",
-            "state": "RUNNING",
-            "resourcesUsed": {
-              "memory": 0,
-              "vCores": 0
-            },
-            "hideReservationQueues": false,
-            "nodeLabels": [
-              "*"
-            ],
-            "numActiveApplications": 484,
-            "numPendingApplications": 0,
-            "numContainers": 0,
-            "maxApplications": 10000,
-            "maxApplicationsPerUser": 10000,
-            "userLimit": 100,
-            "users": {
-              "user": [
-                {
-                  "username": "Default",
-                  "resourcesUsed": {
-                    "memory": 0,
-                    "vCores": 0
-                  },
-                  "numPendingApplications": 0,
-                  "numActiveApplications": 468,
-                  "AMResourceUsed": {
-                    "memory": 30191616,
-                    "vCores": 468
-                  },
-                  "userResourceLimit": {
-                    "memory": 31490048,
-                    "vCores": 7612
-                  }
-                }
-              ]
-            },
-            "userLimitFactor": 1.0,
-            "AMResourceLimit": {
-              "memory": 31490048,
-              "vCores": 7612
-            },
-            "usedAMResource": {
-              "memory": 30388224,
-              "vCores": 532
-            },
-            "userAMResourceLimit": {
-              "memory": 31490048,
-              "vCores": 7612
-            },
-            "preemptionDisabled": true
-          }
-        ]
-      },
-      "health": {
-        "lastrun": 1517951638085,
-        "operationsInfo": {
-          "entry": {
-            "key": "last-allocation",
-            "value": {
-              "nodeId": "node0:0",
-              "containerId": "container_e61477_1517922128312_0340_01_000001",
-              "queue": "root.default"
-            }
-          },
-          "entry": {
-            "key": "last-reservation",
-            "value": {
-              "nodeId": "node0:1",
-              "containerId": "container_e61477_1517879828320_0249_01_000001",
-              "queue": "root.default"
-            }
-          },
-          "entry": {
-            "key": "last-release",
-            "value": {
-              "nodeId": "node0:2",
-              "containerId": "container_e61477_1517922128312_0340_01_000001",
-              "queue": "root.default"
-            }
-          },
-          "entry": {
-            "key": "last-preemption",
-            "value": {
-              "nodeId": "N/A",
-              "containerId": "N/A",
-              "queue": "N/A"
-            }
-          }
-        },
-        "lastRunDetails": [
-          {
-            "operation": "releases",
-            "count": 0,
-            "resources": {
-              "memory": 0,
-              "vCores": 0
-            }
-          },
-          {
-            "operation": "allocations",
-            "count": 0,
-            "resources": {
-              "memory": 0,
-              "vCores": 0
-            }
-          },
-          {
-            "operation": "reservations",
-            "count": 0,
-            "resources": {
-              "memory": 0,
-              "vCores": 0
-            }
-          }
-        ]
-      }
-    }
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/pom.xml b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/pom.xml
index d30ba8bee60..f37b0ff8573 100644
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/pom.xml
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/pom.xml
@@ -46,6 +46,5 @@
     <module>hadoop-yarn-server-timelineservice-hbase</module>
     <module>hadoop-yarn-server-timelineservice-hbase-tests</module>
     <module>hadoop-yarn-server-timelineservice-documentstore</module>
-    <module>hadoop-yarn-server-globalpolicygenerator</module>
   </modules>
 </project>
diff --git a/hadoop-yarn-project/pom.xml b/hadoop-yarn-project/pom.xml
index da50ab149ad..91631bda56c 100644
--- a/hadoop-yarn-project/pom.xml
+++ b/hadoop-yarn-project/pom.xml
@@ -73,10 +73,6 @@
       <groupId>org.apache.hadoop</groupId>
       <artifactId>hadoop-yarn-server-web-proxy</artifactId>
     </dependency>
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-server-globalpolicygenerator</artifactId>
-    </dependency>
   </dependencies>
 
   <build>
