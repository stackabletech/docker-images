Entirely remove hadoop-yarn-services

From: Lars Francke <git@lars-francke.de>


---
 .../main/resources/assemblies/hadoop-yarn-dist.xml |   25 
 hadoop-project/pom.xml                             |   19 
 .../dev-support/findbugs-exclude.xml               |   59 -
 .../dev-support/findbugs-exclude.xml               |   20 
 .../hadoop-yarn-services-api/pom.xml               |  237 ---
 .../yarn/service/client/ApiServiceClient.java      |  752 --------
 .../service/client/SystemServiceManagerImpl.java   |  410 -----
 .../hadoop/yarn/service/client/package-info.java   |   28 
 .../hadoop/yarn/service/webapp/ApiServer.java      |  973 -----------
 .../yarn/service/webapp/ApiServerWebApp.java       |  161 --
 .../hadoop/yarn/service/webapp/package-info.java   |   28 
 .../resources/definition/YARN-Services-Examples.md |  444 -----
 .../YARN-Simplified-V1-API-Layer-For-Services.yaml |  740 --------
 .../src/main/resources/log4j-server.properties     |   76 -
 .../src/main/resources/webapps/api-server/app      |   16 
 .../src/main/webapp/WEB-INF/web.xml                |   36 
 .../hadoop/yarn/service/ServiceClientTest.java     |  226 ---
 .../apache/hadoop/yarn/service/TestApiServer.java  |  620 -------
 .../hadoop/yarn/service/TestCleanupAfterKill.java  |   95 -
 .../yarn/service/client/TestApiServiceClient.java  |  344 ----
 .../service/client/TestSecureApiServiceClient.java |  192 --
 .../client/TestSystemServiceManagerImpl.java       |  264 ---
 .../src/test/resources/example-app.json            |   16 
 .../src/test/resources/log4j.properties            |   19 
 .../resources/system-services/bad/bad.yarnfile     |   16 
 .../sync/user1/example-app1.yarnfile               |   16 
 .../sync/user1/example-app2.yarnfile               |   16 
 .../system-services/sync/user1/example-app3.json   |   16 
 .../sync/user2/example-app1.yarnfile               |   16 
 .../sync/user2/example-app2.yarnfile               |   16 
 .../src/test/resources/yarn-site.xml               |   19 
 .../conf/yarnservice-log4j.properties              |   62 -
 .../examples/appcatalog/appcatalog.json            |   28 
 .../examples/httpd-no-dns/httpd-no-dns.json        |   63 -
 .../examples/httpd-no-dns/httpd-proxy-no-dns.conf  |   24 
 .../examples/httpd/httpd-proxy.conf                |   24 
 .../examples/httpd/httpd.json                      |   56 -
 .../examples/sleeper/sleeper.json                  |   16 
 .../hadoop-yarn-services-core/pom.xml              |  279 ---
 .../yarn/service/ClientAMPolicyProvider.java       |   39 
 .../hadoop/yarn/service/ClientAMProtocol.java      |   74 -
 .../hadoop/yarn/service/ClientAMSecurityInfo.java  |   62 -
 .../hadoop/yarn/service/ClientAMService.java       |  253 ---
 .../yarn/service/ContainerFailureTracker.java      |   92 -
 .../apache/hadoop/yarn/service/ServiceContext.java |   63 -
 .../apache/hadoop/yarn/service/ServiceEvent.java   |   84 -
 .../hadoop/yarn/service/ServiceEventType.java      |   29 
 .../apache/hadoop/yarn/service/ServiceManager.java |  520 ------
 .../apache/hadoop/yarn/service/ServiceMaster.java  |  357 ----
 .../apache/hadoop/yarn/service/ServiceMetrics.java |   94 -
 .../hadoop/yarn/service/ServiceScheduler.java      | 1145 -------------
 .../yarn/service/UpgradeComponentsFinder.java      |  159 --
 .../yarn/service/api/ServiceApiConstants.java      |   74 -
 .../hadoop/yarn/service/api/records/Artifact.java  |  166 --
 .../yarn/service/api/records/BaseResource.java     |   52 -
 .../hadoop/yarn/service/api/records/Component.java |  563 ------
 .../service/api/records/ComponentContainers.java   |   97 -
 .../yarn/service/api/records/ComponentState.java   |   30 
 .../yarn/service/api/records/ConfigFile.java       |  262 ---
 .../yarn/service/api/records/ConfigFormat.java     |   66 -
 .../yarn/service/api/records/Configuration.java    |  224 --
 .../hadoop/yarn/service/api/records/Container.java |  345 ----
 .../yarn/service/api/records/ContainerState.java   |   31 
 .../hadoop/yarn/service/api/records/Error.java     |  128 -
 .../service/api/records/KerberosPrincipal.java     |  146 --
 .../service/api/records/LocalizationStatus.java    |  132 -
 .../service/api/records/PlacementConstraint.java   |  280 ---
 .../yarn/service/api/records/PlacementPolicy.java  |  101 -
 .../yarn/service/api/records/PlacementScope.java   |   53 -
 .../yarn/service/api/records/PlacementType.java    |   35 
 .../yarn/service/api/records/ReadinessCheck.java   |  197 --
 .../hadoop/yarn/service/api/records/Resource.java  |  191 --
 .../service/api/records/ResourceInformation.java   |  152 --
 .../hadoop/yarn/service/api/records/Service.java   |  472 -----
 .../yarn/service/api/records/ServiceState.java     |   38 
 .../yarn/service/api/records/ServiceStatus.java    |  147 --
 .../hadoop/yarn/service/client/ClientAMProxy.java  |   58 -
 .../hadoop/yarn/service/client/ServiceClient.java  | 1804 --------------------
 .../service/component/AlwaysRestartPolicy.java     |   87 -
 .../hadoop/yarn/service/component/Component.java   | 1310 ---------------
 .../yarn/service/component/ComponentEvent.java     |  126 -
 .../yarn/service/component/ComponentEventType.java |   31 
 .../service/component/ComponentRestartPolicy.java  |   47 -
 .../yarn/service/component/ComponentState.java     |   27 
 .../yarn/service/component/NeverRestartPolicy.java |   90 -
 .../service/component/OnFailureRestartPolicy.java  |   94 -
 .../component/instance/ComponentInstance.java      | 1181 -------------
 .../component/instance/ComponentInstanceEvent.java |   60 -
 .../instance/ComponentInstanceEventType.java       |   28 
 .../component/instance/ComponentInstanceId.java    |   91 -
 .../component/instance/ComponentInstanceState.java |   28 
 .../hadoop/yarn/service/conf/RestApiConstants.java |   56 -
 .../hadoop/yarn/service/conf/SliderExitCodes.java  |   88 -
 .../hadoop/yarn/service/conf/YarnServiceConf.java  |  224 --
 .../yarn/service/conf/YarnServiceConstants.java    |  102 -
 .../service/containerlaunch/AbstractLauncher.java  |  262 ---
 .../containerlaunch/ClasspathConstructor.java      |  172 --
 .../containerlaunch/CommandLineBuilder.java        |   86 -
 .../containerlaunch/ContainerLaunchService.java    |  210 --
 .../containerlaunch/JavaCommandLineBuilder.java    |  180 --
 .../exceptions/BadClusterStateException.java       |   36 
 .../exceptions/BadCommandArgumentsException.java   |   30 
 .../service/exceptions/BadConfigException.java     |   39 
 .../yarn/service/exceptions/ErrorStrings.java      |   44 
 .../yarn/service/exceptions/ExitCodeProvider.java  |   32 
 .../yarn/service/exceptions/LauncherExitCodes.java |  196 --
 .../service/exceptions/RestApiErrorMessages.java   |  131 -
 .../service/exceptions/ServiceLaunchException.java |   73 -
 .../yarn/service/exceptions/SliderException.java   |   66 -
 .../yarn/service/exceptions/UsageException.java    |   34 
 .../pb/client/ClientAMProtocolPBClientImpl.java    |  171 --
 .../impl/pb/service/ClientAMProtocolPB.java        |   29 
 .../pb/service/ClientAMProtocolPBServiceImpl.java  |  145 --
 .../monitor/ComponentHealthThresholdMonitor.java   |  151 --
 .../yarn/service/monitor/ServiceMonitor.java       |  155 --
 .../yarn/service/monitor/probe/DefaultProbe.java   |   99 -
 .../yarn/service/monitor/probe/HttpProbe.java      |  117 -
 .../service/monitor/probe/LogEntryBuilder.java     |   76 -
 .../yarn/service/monitor/probe/MonitorKeys.java    |   78 -
 .../yarn/service/monitor/probe/MonitorUtils.java   |   84 -
 .../yarn/service/monitor/probe/PortProbe.java      |   98 -
 .../hadoop/yarn/service/monitor/probe/Probe.java   |  108 -
 .../yarn/service/monitor/probe/ProbeStatus.java    |  160 --
 .../apache/hadoop/yarn/service/package-info.java   |   24 
 .../service/provider/AbstractClientProvider.java   |  150 --
 .../service/provider/AbstractProviderService.java  |  176 --
 .../yarn/service/provider/ProviderFactory.java     |   76 -
 .../yarn/service/provider/ProviderService.java     |   81 -
 .../yarn/service/provider/ProviderUtils.java       |  493 -----
 .../defaultImpl/DefaultClientProvider.java         |   52 -
 .../defaultImpl/DefaultProviderFactory.java        |   51 -
 .../defaultImpl/DefaultProviderService.java        |   38 
 .../provider/docker/DockerClientProvider.java      |   54 -
 .../yarn/service/provider/docker/DockerKeys.java   |   23 
 .../provider/docker/DockerProviderFactory.java     |   52 -
 .../provider/docker/DockerProviderService.java     |  110 -
 .../provider/tarball/TarballClientProvider.java    |   68 -
 .../provider/tarball/TarballProviderFactory.java   |   52 -
 .../provider/tarball/TarballProviderService.java   |   51 -
 .../service/registry/CustomRegistryConstants.java  |   57 -
 .../registry/YarnRegistryViewForProviders.java     |  252 ---
 .../timelineservice/ServiceMetricsSink.java        |   98 -
 .../timelineservice/ServiceTimelineEntityType.java |   39 
 .../timelineservice/ServiceTimelineEvent.java      |   39 
 .../ServiceTimelineMetricsConstants.java           |   94 -
 .../timelineservice/ServiceTimelinePublisher.java  |  401 ----
 .../yarn/service/timelineservice/package-info.java |   27 
 .../service/utils/ApplicationReportSerDeser.java   |   50 -
 .../yarn/service/utils/ClientRegistryBinder.java   |  201 --
 .../hadoop/yarn/service/utils/Comparators.java     |   62 -
 .../hadoop/yarn/service/utils/ConfigHelper.java    |  157 --
 .../hadoop/yarn/service/utils/ConfigUtils.java     |   41 
 .../hadoop/yarn/service/utils/CoreFileSystem.java  |  556 ------
 .../apache/hadoop/yarn/service/utils/Duration.java |  109 -
 .../hadoop/yarn/service/utils/FilterUtils.java     |   94 -
 .../apache/hadoop/yarn/service/utils/HttpUtil.java |  119 -
 .../hadoop/yarn/service/utils/JsonSerDeser.java    |  238 ---
 .../yarn/service/utils/PatternValidator.java       |   58 -
 .../hadoop/yarn/service/utils/PortScanner.java     |  113 -
 .../yarn/service/utils/PublishedConfiguration.java |  187 --
 .../utils/PublishedConfigurationOutputter.java     |  210 --
 .../service/utils/SerializedApplicationReport.java |   96 -
 .../hadoop/yarn/service/utils/ServiceApiUtil.java  |  786 ---------
 .../yarn/service/utils/ServiceRegistryUtils.java   |  116 -
 .../hadoop/yarn/service/utils/ServiceUtils.java    |  599 -------
 .../yarn/service/utils/SliderFileSystem.java       |  134 -
 .../hadoop/yarn/service/utils/ZookeeperUtils.java  |  146 --
 .../src/main/proto/ClientAMProtocol.proto          |  115 -
 .../org.apache.hadoop.security.SecurityInfo        |   14 
 .../yarn/service/MockRunningServiceContext.java    |  205 --
 .../apache/hadoop/yarn/service/MockServiceAM.java  |  468 -----
 .../hadoop/yarn/service/ServiceTestUtils.java      |  584 ------
 .../TestDefaultUpgradeComponentsFinder.java        |  123 -
 .../apache/hadoop/yarn/service/TestServiceAM.java  |  607 -------
 .../hadoop/yarn/service/TestServiceManager.java    |  431 -----
 .../yarn/service/TestYarnNativeServices.java       | 1028 -----------
 .../client/TestBuildExternalComponents.java        |  119 -
 .../hadoop/yarn/service/client/TestServiceCLI.java |  354 ----
 .../yarn/service/client/TestServiceClient.java     |  334 ----
 .../yarn/service/component/TestComponent.java      |  517 ------
 .../TestComponentDecommissionInstances.java        |  147 --
 .../component/TestComponentRestartPolicy.java      |  131 -
 .../component/instance/TestComponentInstance.java  |  819 ---------
 .../hadoop/yarn/service/conf/ExampleAppJson.java   |   66 -
 .../yarn/service/conf/TestAppJsonResolve.java      |  236 ---
 .../yarn/service/conf/TestLoadExampleAppJson.java  |   71 -
 .../service/conf/TestValidateServiceNames.java     |  125 -
 .../containerlaunch/TestAbstractLauncher.java      |  119 -
 .../yarn/service/monitor/TestServiceMonitor.java   |  126 -
 .../service/monitor/probe/TestDefaultProbe.java    |  155 --
 .../provider/TestAbstractProviderService.java      |  157 --
 .../yarn/service/provider/TestProviderUtils.java   |  185 --
 .../providers/TestAbstractClientProvider.java      |  163 --
 .../providers/TestDefaultClientProvider.java       |   66 -
 .../service/providers/TestProviderFactory.java     |   76 -
 .../TestServiceTimelinePublisher.java              |  297 ---
 .../yarn/service/utils/TestCoreFileSystem.java     |   46 -
 .../hadoop/yarn/service/utils/TestFilterUtils.java |  111 -
 .../yarn/service/utils/TestServiceApiUtil.java     |  771 ---------
 .../src/test/resources/example-app.json            |   16 
 .../src/test/resources/log4j.properties            |   19 
 .../yarn/service/conf/examples/app-override.json   |   77 -
 .../hadoop/yarn/service/conf/examples/app.json     |   60 -
 .../hadoop/yarn/service/conf/examples/default.json |   17 
 .../yarn/service/conf/examples/external0.json      |   16 
 .../yarn/service/conf/examples/external1.json      |   31 
 .../yarn/service/conf/examples/external2.json      |   23 
 .../yarn/service/conf/examples/external3.json      |   27 
 .../src/test/resources/yarn-site.xml               |   19 
 .../hadoop-yarn-services/pom.xml                   |   39 
 .../hadoop-yarn/hadoop-yarn-applications/pom.xml   |    4 
 hadoop-yarn-project/pom.xml                        |    4 
 212 files changed, 37762 deletions(-)
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/dev-support/findbugs-exclude.xml
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/dev-support/findbugs-exclude.xml
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/pom.xml
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/client/ApiServiceClient.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/client/SystemServiceManagerImpl.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/client/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/webapp/ApiServer.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/webapp/ApiServerWebApp.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/webapp/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/resources/definition/YARN-Services-Examples.md
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/resources/definition/YARN-Simplified-V1-API-Layer-For-Services.yaml
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/resources/log4j-server.properties
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/resources/webapps/api-server/app
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/webapp/WEB-INF/web.xml
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/ServiceClientTest.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/TestApiServer.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/TestCleanupAfterKill.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/client/TestApiServiceClient.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/client/TestSecureApiServiceClient.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/client/TestSystemServiceManagerImpl.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/example-app.json
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/log4j.properties
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/bad/bad.yarnfile
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user1/example-app1.yarnfile
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user1/example-app2.yarnfile
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user1/example-app3.json
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user2/example-app1.yarnfile
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user2/example-app2.yarnfile
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/yarn-site.xml
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/conf/yarnservice-log4j.properties
 delete mode 100755 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/appcatalog/appcatalog.json
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/httpd-no-dns/httpd-no-dns.json
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/httpd-no-dns/httpd-proxy-no-dns.conf
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/httpd/httpd-proxy.conf
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/httpd/httpd.json
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/sleeper/sleeper.json
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/pom.xml
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ClientAMPolicyProvider.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ClientAMProtocol.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ClientAMSecurityInfo.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ClientAMService.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ContainerFailureTracker.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceContext.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceEvent.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceEventType.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceManager.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceMaster.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceMetrics.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceScheduler.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/UpgradeComponentsFinder.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/ServiceApiConstants.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Artifact.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/BaseResource.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Component.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ComponentContainers.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ComponentState.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ConfigFile.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ConfigFormat.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Configuration.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Container.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ContainerState.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Error.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/KerberosPrincipal.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/LocalizationStatus.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/PlacementConstraint.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/PlacementPolicy.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/PlacementScope.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/PlacementType.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ReadinessCheck.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Resource.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ResourceInformation.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Service.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ServiceState.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ServiceStatus.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/client/ClientAMProxy.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/client/ServiceClient.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/AlwaysRestartPolicy.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/Component.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/ComponentEvent.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/ComponentEventType.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/ComponentRestartPolicy.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/ComponentState.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/NeverRestartPolicy.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/OnFailureRestartPolicy.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstance.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstanceEvent.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstanceEventType.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstanceId.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstanceState.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/conf/RestApiConstants.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/conf/SliderExitCodes.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/conf/YarnServiceConf.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/conf/YarnServiceConstants.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/AbstractLauncher.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/ClasspathConstructor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/CommandLineBuilder.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/ContainerLaunchService.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/JavaCommandLineBuilder.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/BadClusterStateException.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/BadCommandArgumentsException.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/BadConfigException.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/ErrorStrings.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/ExitCodeProvider.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/LauncherExitCodes.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/RestApiErrorMessages.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/ServiceLaunchException.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/SliderException.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/UsageException.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/impl/pb/client/ClientAMProtocolPBClientImpl.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/impl/pb/service/ClientAMProtocolPB.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/impl/pb/service/ClientAMProtocolPBServiceImpl.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/ComponentHealthThresholdMonitor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/ServiceMonitor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/DefaultProbe.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/HttpProbe.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/LogEntryBuilder.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/MonitorKeys.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/MonitorUtils.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/PortProbe.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/Probe.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/ProbeStatus.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/AbstractClientProvider.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/AbstractProviderService.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/ProviderFactory.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/ProviderService.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/ProviderUtils.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/defaultImpl/DefaultClientProvider.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/defaultImpl/DefaultProviderFactory.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/defaultImpl/DefaultProviderService.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/docker/DockerClientProvider.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/docker/DockerKeys.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/docker/DockerProviderFactory.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/docker/DockerProviderService.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/tarball/TarballClientProvider.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/tarball/TarballProviderFactory.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/tarball/TarballProviderService.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/registry/CustomRegistryConstants.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/registry/YarnRegistryViewForProviders.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceMetricsSink.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceTimelineEntityType.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceTimelineEvent.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceTimelineMetricsConstants.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceTimelinePublisher.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ApplicationReportSerDeser.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ClientRegistryBinder.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/Comparators.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ConfigHelper.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ConfigUtils.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/CoreFileSystem.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/Duration.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/FilterUtils.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/HttpUtil.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/JsonSerDeser.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/PatternValidator.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/PortScanner.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/PublishedConfiguration.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/PublishedConfigurationOutputter.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/SerializedApplicationReport.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ServiceApiUtil.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ServiceRegistryUtils.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ServiceUtils.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/SliderFileSystem.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ZookeeperUtils.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/proto/ClientAMProtocol.proto
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/resources/META-INF/services/org.apache.hadoop.security.SecurityInfo
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/MockRunningServiceContext.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/MockServiceAM.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/ServiceTestUtils.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/TestDefaultUpgradeComponentsFinder.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/TestServiceAM.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/TestServiceManager.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/TestYarnNativeServices.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/client/TestBuildExternalComponents.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/client/TestServiceCLI.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/client/TestServiceClient.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/component/TestComponent.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/component/TestComponentDecommissionInstances.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/component/TestComponentRestartPolicy.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/component/instance/TestComponentInstance.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/conf/ExampleAppJson.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/conf/TestAppJsonResolve.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/conf/TestLoadExampleAppJson.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/conf/TestValidateServiceNames.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/containerlaunch/TestAbstractLauncher.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/monitor/TestServiceMonitor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/monitor/probe/TestDefaultProbe.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/provider/TestAbstractProviderService.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/provider/TestProviderUtils.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/providers/TestAbstractClientProvider.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/providers/TestDefaultClientProvider.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/providers/TestProviderFactory.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/timelineservice/TestServiceTimelinePublisher.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/utils/TestCoreFileSystem.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/utils/TestFilterUtils.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/utils/TestServiceApiUtil.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/example-app.json
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/log4j.properties
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/app-override.json
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/app.json
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/default.json
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/external0.json
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/external1.json
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/external2.json
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/external3.json
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/yarn-site.xml
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/pom.xml

diff --git a/hadoop-assemblies/src/main/resources/assemblies/hadoop-yarn-dist.xml b/hadoop-assemblies/src/main/resources/assemblies/hadoop-yarn-dist.xml
index 3c9cf4642ba..5e5af377854 100644
--- a/hadoop-assemblies/src/main/resources/assemblies/hadoop-yarn-dist.xml
+++ b/hadoop-assemblies/src/main/resources/assemblies/hadoop-yarn-dist.xml
@@ -79,31 +79,6 @@
         <include>*-sources.jar</include>
       </includes>
     </fileSet>
-    <fileSet>
-      <directory>hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/target</directory>
-      <outputDirectory>/share/hadoop/${hadoop.component}/sources</outputDirectory>
-      <includes>
-        <include>*-sources.jar</include>
-      </includes>
-    </fileSet>
-    <fileSet>
-      <directory>hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/conf</directory>
-      <outputDirectory>etc/hadoop</outputDirectory>
-    </fileSet>
-    <fileSet>
-      <directory>hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples</directory>
-      <outputDirectory>/share/hadoop/${hadoop.component}/yarn-service-examples</outputDirectory>
-      <includes>
-        <include>**/*</include>
-      </includes>
-    </fileSet>
-    <fileSet>
-      <directory>hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/target</directory>
-      <outputDirectory>/share/hadoop/${hadoop.component}/sources</outputDirectory>
-      <includes>
-        <include>*-sources.jar</include>
-      </includes>
-    </fileSet>
     <fileSet>
       <directory>hadoop-yarn/hadoop-yarn-client/target</directory>
       <outputDirectory>/share/hadoop/${hadoop.component}/sources</outputDirectory>
diff --git a/hadoop-project/pom.xml b/hadoop-project/pom.xml
index 5792423d725..460cbf132e2 100644
--- a/hadoop-project/pom.xml
+++ b/hadoop-project/pom.xml
@@ -580,25 +580,6 @@
         <version>${project.version}</version>
       </dependency>
 
-      <dependency>
-        <groupId>org.apache.hadoop</groupId>
-        <artifactId>hadoop-yarn-services-core</artifactId>
-        <version>${hadoop.version}</version>
-      </dependency>
-
-      <dependency>
-        <groupId>org.apache.hadoop</groupId>
-        <artifactId>hadoop-yarn-services-core</artifactId>
-        <version>${hadoop.version}</version>
-        <type>test-jar</type>
-      </dependency>
-
-      <dependency>
-        <groupId>org.apache.hadoop</groupId>
-        <artifactId>hadoop-yarn-services-api</artifactId>
-        <version>${hadoop.version}</version>
-      </dependency>
-
       <dependency>
         <groupId>org.apache.hadoop</groupId>
          <artifactId>hadoop-mapreduce-client-jobclient</artifactId>
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/dev-support/findbugs-exclude.xml b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/dev-support/findbugs-exclude.xml
deleted file mode 100644
index 15ce952ef3c..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/dev-support/findbugs-exclude.xml
+++ /dev/null
@@ -1,59 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<FindBugsFilter>
-    <Match>
-        <Package name="org.apache.hadoop.yarn.proto" />
-    </Match>
-    <Match>
-        <class name="org.apache.hadoop.yarn.service.utils.ServiceApiUtil" />
-        <Bug pattern="MS_CANNOT_BE_FINAL" />
-    </Match>
-    <Match>
-        <Class name="org.apache.hadoop.yarn.service.utils.JsonSerDeser" />
-        <Bug pattern="OBL_UNSATISFIED_OBLIGATION" />
-    </Match>
-    <Match>
-        <Class name="org.apache.hadoop.yarn.service.utils.JsonSerDeser" />
-        <Bug pattern="UI_INHERITANCE_UNSAFE_GETRESOURCE" />
-    </Match>
-    <Match>
-        <Package name="org.apache.hadoop.yarn.service.client.params"/>
-        <Bug pattern="UWF_UNWRITTEN_PUBLIC_OR_PROTECTED_FIELD"/>
-    </Match>
-    <Match>
-        <Package name="org.apache.hadoop.yarn.service.client.params"/>
-        <Bug pattern="URF_UNREAD_PUBLIC_OR_PROTECTED_FIELD"/>
-    </Match>
-    <Match>
-        <Class name="org.apache.hadoop.yarn.service.client.ServiceClient"/>
-        <Field name="registryClient" />
-        <Bug pattern="IS2_INCONSISTENT_SYNC"/>
-    </Match>
-    <Match>
-        <Class name="org.apache.hadoop.yarn.service.ClientAMPolicyProvider"/>
-        <Bug pattern="EI_EXPOSE_REP"/>
-    </Match>
-    <!-- SE_BAD_FIELD -->
-    <Match>
-      <Class name="org.apache.hadoop.yarn.service.api.records.Resource" />
-      <Or>
-        <Field name="additional"/>
-      </Or>
-      <Bug pattern="SE_BAD_FIELD" />
-  </Match>
-</FindBugsFilter>
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/dev-support/findbugs-exclude.xml b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/dev-support/findbugs-exclude.xml
deleted file mode 100644
index b89146a264a..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/dev-support/findbugs-exclude.xml
+++ /dev/null
@@ -1,20 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<FindBugsFilter>
-
-</FindBugsFilter>
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/pom.xml b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/pom.xml
deleted file mode 100644
index 2b3e66a0370..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/pom.xml
+++ /dev/null
@@ -1,237 +0,0 @@
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/maven-v4_0_0.xsd">
-  <modelVersion>4.0.0</modelVersion>
-  <parent>
-    <groupId>org.apache.hadoop</groupId>
-    <artifactId>hadoop-yarn-services</artifactId>
-    <version>3.4.0</version>
-  </parent>
-  <artifactId>hadoop-yarn-services-api</artifactId>
-  <name>Apache Hadoop YARN Services API</name>
-  <packaging>jar</packaging>
-  <description>Hadoop YARN REST APIs for services</description>
-
-  <build>
-
-    <!-- resources are filtered for dynamic updates. This gets build info in-->
-    <resources>
-      <resource>
-        <directory>src/main/resources</directory>
-        <filtering>true</filtering>
-      </resource>
-      <resource>
-        <directory>src/main/scripts/</directory>
-        <filtering>true</filtering>
-      </resource>
-    </resources>
-
-    <plugins>
-      <plugin>
-        <groupId>org.apache.maven.plugins</groupId>
-        <artifactId>maven-jar-plugin</artifactId>
-        <!-- The configuration of the plugin -->
-        <configuration>
-          <!-- Configuration of the archiver -->
-          <archive>
-            <manifestEntries>
-              <mode>development</mode>
-              <url>${project.url}</url>
-            </manifestEntries>
-            <!-- Manifest specific configuration -->
-            <manifest>
-            </manifest>
-          </archive>
-        </configuration>
-        <executions>
-          <execution>
-            <goals>
-              <goal>test-jar</goal>
-            </goals>
-          </execution>
-        </executions>
-      </plugin>
-      <plugin>
-        <groupId>org.apache.rat</groupId>
-        <artifactId>apache-rat-plugin</artifactId>
-        <configuration>
-          <excludes>
-            <exclude>**/*.json</exclude>
-            <exclude>**/*.yarnfile</exclude>
-          </excludes>
-        </configuration>
-      </plugin>
-    </plugins>
-  </build>
-
-  <reporting>
-  </reporting>
-
-  <dependencies>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-services-core</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-api</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-client</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-common</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-registry</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-server-common</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-common</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-annotations</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-auth</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>org.slf4j</groupId>
-      <artifactId>slf4j-api</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>org.eclipse.jetty</groupId>
-      <artifactId>jetty-webapp</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>com.google.inject</groupId>
-      <artifactId>guice</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>javax.ws.rs</groupId>
-      <artifactId>jsr311-api</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>javax.servlet</groupId>
-      <artifactId>javax.servlet-api</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>commons-codec</groupId>
-      <artifactId>commons-codec</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>commons-io</groupId>
-      <artifactId>commons-io</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.commons</groupId>
-      <artifactId>commons-lang3</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.hadoop.thirdparty</groupId>
-      <artifactId>hadoop-shaded-guava</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>com.sun.jersey</groupId>
-      <artifactId>jersey-client</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>org.eclipse.jetty</groupId>
-      <artifactId>jetty-server</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>org.eclipse.jetty</groupId>
-      <artifactId>jetty-util</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>org.eclipse.jetty</groupId>
-      <artifactId>jetty-servlet</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>org.mockito</groupId>
-      <artifactId>mockito-core</artifactId>
-      <scope>test</scope>
-    </dependency>
-
-    <!-- ======================================================== -->
-    <!-- Test dependencies -->
-    <!-- ======================================================== -->
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-common</artifactId>
-      <type>test-jar</type>
-    </dependency>
-    <dependency>
-      <groupId>junit</groupId>
-      <artifactId>junit</artifactId>
-      <scope>test</scope>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-services-core</artifactId>
-      <type>test-jar</type>
-      <scope>test</scope>
-    </dependency>
-    <dependency>
-      <groupId>org.junit.jupiter</groupId>
-      <artifactId>junit-jupiter-api</artifactId>
-      <scope>test</scope>
-    </dependency>
-    <dependency>
-      <groupId>org.junit.jupiter</groupId>
-      <artifactId>junit-jupiter-engine</artifactId>
-      <scope>test</scope>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-minicluster</artifactId>
-      <scope>test</scope>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.curator</groupId>
-      <artifactId>curator-test</artifactId>
-      <scope>test</scope>
-    </dependency>
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-minikdc</artifactId>
-      <scope>test</scope>
-      <exclusions>
-        <exclusion>
-          <groupId>junit</groupId>
-          <artifactId>junit</artifactId>
-        </exclusion>
-      </exclusions>
-    </dependency>
-    <dependency>
-      <groupId>org.junit.platform</groupId>
-      <artifactId>junit-platform-launcher</artifactId>
-      <scope>test</scope>
-    </dependency>
-  </dependencies>
-</project>
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/client/ApiServiceClient.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/client/ApiServiceClient.java
deleted file mode 100644
index c0d5272a124..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/client/ApiServiceClient.java
+++ /dev/null
@@ -1,752 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.client;
-
-import static org.apache.hadoop.yarn.service.utils.ServiceApiUtil.jsonSerDeser;
-
-import java.io.File;
-import java.io.IOException;
-import java.net.URI;
-import java.text.MessageFormat;
-import java.util.List;
-import java.util.Map;
-import java.security.PrivilegedExceptionAction;
-
-import javax.ws.rs.core.HttpHeaders;
-import javax.ws.rs.core.MediaType;
-import javax.ws.rs.core.UriBuilder;
-
-import org.apache.hadoop.util.Preconditions;
-
-import org.apache.commons.codec.binary.Base64;
-import org.apache.hadoop.thirdparty.com.google.common.base.Strings;
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.yarn.api.ApplicationConstants;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.ApplicationReport;
-import org.apache.hadoop.yarn.client.api.AppAdminClient;
-import org.apache.hadoop.yarn.client.api.YarnClient;
-import org.apache.hadoop.yarn.client.util.YarnClientUtils;
-import org.apache.hadoop.yarn.conf.HAUtil;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.api.records.ComponentState;
-import org.apache.hadoop.yarn.service.api.records.Container;
-import org.apache.hadoop.yarn.service.api.records.ContainerState;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.api.records.ServiceStatus;
-import org.apache.hadoop.yarn.service.conf.RestApiConstants;
-import org.apache.hadoop.yarn.service.utils.ServiceApiUtil;
-import org.apache.hadoop.yarn.util.RMHAUtils;
-import org.eclipse.jetty.util.UrlEncoded;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import com.sun.jersey.api.client.Client;
-import com.sun.jersey.api.client.ClientResponse;
-import com.sun.jersey.api.client.WebResource.Builder;
-import com.sun.jersey.api.client.config.ClientConfig;
-import com.sun.jersey.api.client.config.DefaultClientConfig;
-
-import static org.apache.hadoop.yarn.service.exceptions.LauncherExitCodes.*;
-
-/**
- * The rest API client for users to manage services on YARN.
- */
-public class ApiServiceClient extends AppAdminClient {
-  private static final Logger LOG =
-      LoggerFactory.getLogger(ApiServiceClient.class);
-  private static final Base64 BASE_64_CODEC = new Base64(0);
-  protected YarnClient yarnClient;
-
-  public ApiServiceClient() {
-  }
-
-  public ApiServiceClient(Configuration c) throws Exception {
-    serviceInit(c);
-  }
-
-  @Override protected void serviceInit(Configuration configuration)
-      throws Exception {
-    yarnClient = YarnClient.createYarnClient();
-    addService(yarnClient);
-    super.serviceInit(configuration);
-  }
-
-  /**
-   * Calculate Resource Manager address base on working REST API.
-   */
-  String getRMWebAddress() throws IOException {
-    Configuration conf = getConfig();
-    String scheme = "http://";
-    String path = "/app/v1/services/version";
-    String rmAddress = conf
-        .get("yarn.resourcemanager.webapp.address");
-    if (YarnConfiguration.useHttps(conf)) {
-      scheme = "https://";
-      rmAddress = conf
-          .get("yarn.resourcemanager.webapp.https.address");
-    }
-
-    if (HAUtil.isHAEnabled(conf)) {
-      boolean useKerberos = UserGroupInformation.isSecurityEnabled();
-      List<String> rmServers = getRMHAWebAddresses(conf);
-      StringBuilder diagnosticsMsg = new StringBuilder();
-      for (String host : rmServers) {
-        try {
-          Client client = Client.create();
-          client.setFollowRedirects(false);
-          StringBuilder sb = new StringBuilder();
-          sb.append(scheme)
-              .append(host)
-              .append(path);
-          if (!useKerberos) {
-            try {
-              String username = UserGroupInformation.getCurrentUser()
-                  .getShortUserName();
-              sb.append("?user.name=")
-                  .append(username);
-            } catch (IOException e) {
-              LOG.debug("Fail to resolve username: {}", e);
-            }
-          }
-          Builder builder = client
-              .resource(sb.toString()).type(MediaType.APPLICATION_JSON);
-          if (useKerberos) {
-            String[] server = host.split(":");
-            String challenge = YarnClientUtils.generateToken(server[0]);
-            builder.header(HttpHeaders.AUTHORIZATION, "Negotiate " +
-                challenge);
-            LOG.debug("Authorization: Negotiate {}", challenge);
-          }
-          ClientResponse test = builder.get(ClientResponse.class);
-          if (test.getStatus() == 200) {
-            return scheme + host;
-          }
-        } catch (Exception e) {
-          LOG.info("Fail to connect to: " + host);
-          LOG.debug("Root cause: ", e);
-          diagnosticsMsg.append("Error connecting to " + host
-              + " due to " + e.getMessage() + "\n");
-        }
-      }
-      throw new IOException(diagnosticsMsg.toString());
-    }
-    return scheme+rmAddress;
-  }
-
-  List<String> getRMHAWebAddresses(Configuration conf) {
-    return RMHAUtils
-        .getRMHAWebappAddresses(new YarnConfiguration(conf));
-  }
-
-  /**
-   * Compute active resource manager API service location.
-   *
-   * @param appName - YARN service name
-   * @return URI to API Service
-   * @throws IOException
-   */
-  public String getServicePath(String appName) throws IOException {
-    String url = getRMWebAddress();
-    StringBuilder api = new StringBuilder();
-    api.append(url)
-        .append("/app/v1/services");
-    if (appName != null) {
-      api.append("/")
-          .append(appName);
-    }
-    appendUserNameIfRequired(api);
-    return api.toString();
-  }
-
-  private String getInstancesPath(String appName) throws IOException {
-    Preconditions.checkNotNull(appName);
-    String url = getRMWebAddress();
-    StringBuilder api = new StringBuilder();
-    api.append(url)
-        .append("/app/v1/services/").append(appName).append("/")
-        .append(RestApiConstants.COMP_INSTANCES);
-    appendUserNameIfRequired(api);
-    return api.toString();
-  }
-
-  private String getInstancePath(String appName, List<String> components,
-      String version, List<String> containerStates) throws IOException {
-    UriBuilder builder = UriBuilder.fromUri(getInstancesPath(appName));
-    if (components != null && !components.isEmpty()) {
-      components.forEach(compName ->
-        builder.queryParam(RestApiConstants.PARAM_COMP_NAME, compName));
-    }
-    if (!Strings.isNullOrEmpty(version)){
-      builder.queryParam(RestApiConstants.PARAM_VERSION, version);
-    }
-    if (containerStates != null && !containerStates.isEmpty()){
-      containerStates.forEach(state ->
-          builder.queryParam(RestApiConstants.PARAM_CONTAINER_STATE, state));
-    }
-    return builder.build().toString();
-  }
-
-  private String getComponentsPath(String appName) throws IOException {
-    Preconditions.checkNotNull(appName);
-    String url = getRMWebAddress();
-    StringBuilder api = new StringBuilder();
-    api.append(url)
-        .append("/app/v1/services/").append(appName).append("/")
-        .append(RestApiConstants.COMPONENTS);
-    appendUserNameIfRequired(api);
-    return api.toString();
-  }
-
-  private void appendUserNameIfRequired(StringBuilder builder)
-      throws IOException {
-    Configuration conf = getConfig();
-    if (conf.get("hadoop.http.authentication.type")
-        .equalsIgnoreCase("simple")) {
-      String username = UserGroupInformation.getCurrentUser()
-            .getShortUserName();
-      builder.append("?user.name=").append(UrlEncoded
-          .encodeString(username));
-    }
-  }
-
-  public Builder getApiClient() throws IOException {
-    return getApiClient(getServicePath(null));
-  }
-
-  /**
-   * Setup API service web request.
-   *
-   * @param requestPath
-   * @return
-   * @throws IOException
-   */
-  public Builder getApiClient(String requestPath)
-      throws IOException {
-    Client client = Client.create(getClientConfig());
-    client.setChunkedEncodingSize(null);
-    Builder builder = client
-        .resource(requestPath).type(MediaType.APPLICATION_JSON);
-    if (UserGroupInformation.isSecurityEnabled()) {
-      try {
-        URI url = new URI(requestPath);
-        String challenge = YarnClientUtils.generateToken(url.getHost());
-        builder.header(HttpHeaders.AUTHORIZATION, "Negotiate " + challenge);
-      } catch (Exception e) {
-        throw new IOException(e);
-      }
-    }
-    return builder
-        .accept("application/json;charset=utf-8");
-  }
-
-  private ClientConfig getClientConfig() {
-    ClientConfig config = new DefaultClientConfig();
-    config.getProperties().put(
-        ClientConfig.PROPERTY_CHUNKED_ENCODING_SIZE, 0);
-    config.getProperties().put(
-        ClientConfig.PROPERTY_BUFFER_RESPONSE_ENTITY_ON_EXCEPTION, true);
-    return config;
-  }
-
-  private int processResponse(ClientResponse response) {
-    response.bufferEntity();
-    String output;
-    if (response.getStatus() == 401) {
-      LOG.error("Authentication required");
-      return EXIT_EXCEPTION_THROWN;
-    }
-    if (response.getStatus() == 503) {
-      LOG.error("YARN Service is unavailable or disabled.");
-      return EXIT_EXCEPTION_THROWN;
-    }
-    try {
-      ServiceStatus ss = response.getEntity(ServiceStatus.class);
-      output = ss.getDiagnostics();
-    } catch (Throwable t) {
-      output = response.getEntity(String.class);
-    }
-    if (output==null) {
-      output = response.getEntity(String.class);
-    }
-    if (response.getStatus() <= 299) {
-      LOG.info(output);
-      return EXIT_SUCCESS;
-    } else {
-      LOG.error(output);
-      return EXIT_EXCEPTION_THROWN;
-    }
-  }
-
-  /**
-   * Utility method to load Service json from disk or from
-   * YARN examples.
-   *
-   * @param fileName - path to yarnfile
-   * @param serviceName - YARN Service Name
-   * @param lifetime - application lifetime
-   * @param queue - Queue to submit application
-   * @return
-   * @throws IOException
-   * @throws YarnException
-   */
-  public Service loadAppJsonFromLocalFS(String fileName, String serviceName,
-      Long lifetime, String queue) throws IOException, YarnException {
-    File file = new File(fileName);
-    if (!file.exists() && fileName.equals(file.getName())) {
-      String examplesDirStr = System.getenv("YARN_SERVICE_EXAMPLES_DIR");
-      String[] examplesDirs;
-      if (examplesDirStr == null) {
-        String yarnHome = System
-            .getenv(ApplicationConstants.Environment.HADOOP_YARN_HOME.key());
-        examplesDirs = new String[]{
-            yarnHome + "/share/hadoop/yarn/yarn-service-examples",
-            yarnHome + "/yarn-service-examples"
-        };
-      } else {
-        examplesDirs = StringUtils.split(examplesDirStr, ":");
-      }
-      for (String dir : examplesDirs) {
-        file = new File(MessageFormat.format("{0}/{1}/{2}.json",
-            dir, fileName, fileName));
-        if (file.exists()) {
-          break;
-        }
-        // Then look for secondary location.
-        file = new File(MessageFormat.format("{0}/{1}.json",
-            dir, fileName));
-        if (file.exists()) {
-          break;
-        }
-      }
-    }
-    if (!file.exists()) {
-      throw new YarnException("File or example could not be found: " +
-          fileName);
-    }
-    Path filePath = new Path(file.getAbsolutePath());
-    LOG.info("Loading service definition from local FS: " + filePath);
-    Service service = jsonSerDeser
-        .load(FileSystem.getLocal(getConfig()), filePath);
-    if (!StringUtils.isEmpty(serviceName)) {
-      service.setName(serviceName);
-    }
-    if (lifetime != null && lifetime > 0) {
-      service.setLifetime(lifetime);
-    }
-    if (!StringUtils.isEmpty(queue)) {
-      service.setQueue(queue);
-    }
-    return service;
-  }
-
-  /**
-   * Launch YARN service application.
-   *
-   * @param fileName - path to yarnfile
-   * @param appName - YARN Service Name
-   * @param lifetime - application lifetime
-   * @param queue - Queue to submit application
-   */
-  @Override
-  public int actionLaunch(String fileName, String appName, Long lifetime,
-      String queue) throws IOException, YarnException {
-    int result = EXIT_SUCCESS;
-    try {
-      Service service =
-          loadAppJsonFromLocalFS(fileName, appName, lifetime, queue);
-      String buffer = jsonSerDeser.toJson(service);
-      ClientResponse response = getApiClient()
-          .post(ClientResponse.class, buffer);
-      result = processResponse(response);
-    } catch (Exception e) {
-      LOG.error("Fail to launch application: ", e);
-      result = EXIT_EXCEPTION_THROWN;
-    }
-    return result;
-  }
-
-  /**
-   * Stop YARN service application.
-   *
-   * @param appName - YARN Service Name
-   */
-  @Override
-  public int actionStop(String appName) throws IOException, YarnException {
-    int result = EXIT_SUCCESS;
-    try {
-      Service service = new Service();
-      service.setName(appName);
-      service.setState(ServiceState.STOPPED);
-      String buffer = jsonSerDeser.toJson(service);
-      ClientResponse response = getApiClient(getServicePath(appName))
-          .put(ClientResponse.class, buffer);
-      result = processResponse(response);
-    } catch (Exception e) {
-      LOG.error("Fail to stop application: ", e);
-      result = EXIT_EXCEPTION_THROWN;
-    }
-    return result;
-  }
-
-  /**
-   * Start YARN service application.
-   *
-   * @param appName - YARN Service Name
-   */
-  @Override
-  public int actionStart(String appName) throws IOException, YarnException {
-    int result = EXIT_SUCCESS;
-    try {
-      Service service = new Service();
-      service.setName(appName);
-      service.setState(ServiceState.STARTED);
-      String buffer = jsonSerDeser.toJson(service);
-      ClientResponse response = getApiClient(getServicePath(appName))
-          .put(ClientResponse.class, buffer);
-      result = processResponse(response);
-    } catch (Exception e) {
-      LOG.error("Fail to start application: ", e);
-      result = EXIT_EXCEPTION_THROWN;
-    }
-    return result;
-  }
-
-  /**
-   * Save Service configuration.
-   *
-   * @param fileName - path to Yarnfile
-   * @param appName - YARN Service Name
-   * @param lifetime - container life time
-   * @param queue - Queue to submit the application
-   */
-  @Override
-  public int actionSave(String fileName, String appName, Long lifetime,
-      String queue) throws IOException, YarnException {
-    int result = EXIT_SUCCESS;
-    try {
-      Service service =
-          loadAppJsonFromLocalFS(fileName, appName, lifetime, queue);
-      service.setState(ServiceState.STOPPED);
-      String buffer = jsonSerDeser.toJson(service);
-      ClientResponse response = getApiClient()
-          .post(ClientResponse.class, buffer);
-      result = processResponse(response);
-    } catch (Exception e) {
-      LOG.error("Fail to save application: ", e);
-      result = EXIT_EXCEPTION_THROWN;
-    }
-    return result;
-  }
-
-  /**
-   * Decommission a YARN service.
-   *
-   * @param appName - YARN Service Name
-   */
-  @Override
-  public int actionDestroy(String appName) throws IOException, YarnException {
-    int result = EXIT_SUCCESS;
-    try {
-      ClientResponse response = getApiClient(getServicePath(appName))
-          .delete(ClientResponse.class);
-      result = processResponse(response);
-    } catch (Exception e) {
-      LOG.error("Fail to destroy application: ", e);
-      result = EXIT_EXCEPTION_THROWN;
-    }
-    return result;
-  }
-
-  /**
-   * Change number of containers associated with a service.
-   *
-   * @param appName - YARN Service Name
-   * @param componentCounts - list of components and desired container count
-   */
-  @Override
-  public int actionFlex(String appName, Map<String, String> componentCounts)
-      throws IOException, YarnException {
-    int result = EXIT_SUCCESS;
-    try {
-      Service service = new Service();
-      service.setName(appName);
-      service.setState(ServiceState.FLEX);
-      for (Map.Entry<String, String> entry : componentCounts.entrySet()) {
-        Component component = new Component();
-        component.setName(entry.getKey());
-        Long numberOfContainers = Long.parseLong(entry.getValue());
-        component.setNumberOfContainers(numberOfContainers);
-        service.addComponent(component);
-      }
-      String buffer = jsonSerDeser.toJson(service);
-      ClientResponse response = getApiClient(getServicePath(appName))
-          .put(ClientResponse.class, buffer);
-      result = processResponse(response);
-    } catch (Exception e) {
-      LOG.error("Fail to flex application: ", e);
-      result = EXIT_EXCEPTION_THROWN;
-    }
-    return result;
-  }
-
-  @Override
-  public int enableFastLaunch(String destinationFolder) throws IOException, YarnException {
-    ServiceClient sc = new ServiceClient();
-    sc.init(getConfig());
-    sc.start();
-    int result = sc.enableFastLaunch(destinationFolder);
-    sc.close();
-    return result;
-  }
-
-  /**
-   * Retrieve Service Status through REST API.
-   *
-   * @param appIdOrName - YARN application ID or application name
-   * @return Status output
-   */
-  @Override
-  public String getStatusString(String appIdOrName) throws IOException,
-      YarnException {
-    String output = "";
-    String appName;
-    try {
-      ApplicationId appId = ApplicationId.fromString(appIdOrName);
-      ApplicationReport appReport = yarnClient.getApplicationReport(appId);
-      appName = appReport.getName();
-    } catch (IllegalArgumentException e) {
-      // not app Id format, may be app name
-      appName = appIdOrName;
-      ServiceApiUtil.validateNameFormat(appName, getConfig());
-    }
-    try {
-      ClientResponse response = getApiClient(getServicePath(appName))
-          .get(ClientResponse.class);
-      if (response.getStatus() == 404) {
-        StringBuilder sb = new StringBuilder();
-        sb.append(" Service ")
-            .append(appName)
-            .append(" not found");
-        return sb.toString();
-      }
-      if (response.getStatus() != 200) {
-        StringBuilder sb = new StringBuilder();
-        sb.append(appName)
-            .append(" Failed : HTTP error code : ")
-            .append(response.getStatus());
-        return sb.toString();
-      }
-      output = response.getEntity(String.class);
-    } catch (Exception e) {
-      LOG.error("Fail to check application status: ", e);
-    }
-    return output;
-  }
-
-  @Override
-  public int actionUpgradeExpress(String appName, File path)
-      throws IOException, YarnException {
-    int result;
-    try {
-      Service service =
-          loadAppJsonFromLocalFS(path.getAbsolutePath(), appName, null, null);
-      service.setState(ServiceState.EXPRESS_UPGRADING);
-      String buffer = jsonSerDeser.toJson(service);
-      LOG.info("Upgrade in progress. Please wait..");
-      ClientResponse response = getApiClient(getServicePath(appName))
-          .put(ClientResponse.class, buffer);
-      result = processResponse(response);
-    } catch (Exception e) {
-      LOG.error("Failed to upgrade application: ", e);
-      result = EXIT_EXCEPTION_THROWN;
-    }
-    return result;
-  }
-
-  @Override
-  public int initiateUpgrade(String appName,
-      String fileName, boolean autoFinalize) throws IOException, YarnException {
-    int result;
-    try {
-      Service service =
-          loadAppJsonFromLocalFS(fileName, appName, null, null);
-      if (autoFinalize) {
-        service.setState(ServiceState.UPGRADING_AUTO_FINALIZE);
-      } else {
-        service.setState(ServiceState.UPGRADING);
-      }
-      String buffer = jsonSerDeser.toJson(service);
-      ClientResponse response = getApiClient(getServicePath(appName))
-          .put(ClientResponse.class, buffer);
-      result = processResponse(response);
-    } catch (Exception e) {
-      LOG.error("Failed to upgrade application: ", e);
-      result = EXIT_EXCEPTION_THROWN;
-    }
-    return result;
-  }
-
-  @Override
-  public int actionUpgradeInstances(String appName, List<String> compInstances)
-      throws IOException, YarnException {
-    int result;
-    Container[] toUpgrade = new Container[compInstances.size()];
-    try {
-      int idx = 0;
-      for (String instanceName : compInstances) {
-        Container container = new Container();
-        container.setComponentInstanceName(instanceName);
-        container.setState(ContainerState.UPGRADING);
-        toUpgrade[idx++] = container;
-      }
-      String buffer = ServiceApiUtil.CONTAINER_JSON_SERDE.toJson(toUpgrade);
-      ClientResponse response = getApiClient(getInstancesPath(appName))
-          .put(ClientResponse.class, buffer);
-      result = processResponse(response);
-    } catch (Exception e) {
-      LOG.error("Failed to upgrade component instance: ", e);
-      result = EXIT_EXCEPTION_THROWN;
-    }
-    return result;
-  }
-
-  @Override
-  public int actionUpgradeComponents(String appName, List<String> components)
-      throws IOException, YarnException {
-    int result;
-    Component[] toUpgrade = new Component[components.size()];
-    try {
-      int idx = 0;
-      for (String compName : components) {
-        Component component = new Component();
-        component.setName(compName);
-        component.setState(ComponentState.UPGRADING);
-        toUpgrade[idx++] = component;
-      }
-      String buffer = ServiceApiUtil.COMP_JSON_SERDE.toJson(toUpgrade);
-      ClientResponse response = getApiClient(getComponentsPath(appName))
-          .put(ClientResponse.class, buffer);
-      result = processResponse(response);
-    } catch (Exception e) {
-      LOG.error("Failed to upgrade components: ", e);
-      result = EXIT_EXCEPTION_THROWN;
-    }
-    return result;
-  }
-
-  @Override
-  public int actionCleanUp(String appName, String userName) throws
-      IOException, YarnException, InterruptedException {
-    UserGroupInformation proxyUser;
-    UserGroupInformation ugi;
-    if (UserGroupInformation.isSecurityEnabled()) {
-      proxyUser = UserGroupInformation.getLoginUser();
-      ugi = UserGroupInformation.createProxyUser(userName, proxyUser);
-    } else {
-      ugi = UserGroupInformation.createRemoteUser(userName);
-    }
-    return ugi.doAs((PrivilegedExceptionAction<Integer>) () -> {
-      ServiceClient sc = new ServiceClient();
-      try {
-        sc.init(getConfig());
-        sc.start();
-        int result = sc.actionCleanUp(appName, userName);
-        return result;
-      } finally {
-        sc.close();
-      }
-    });
-  }
-
-  @Override
-  public String getInstances(String appName, List<String> components,
-      String version, List<String> containerStates) throws IOException,
-      YarnException {
-    try {
-      String uri = getInstancePath(appName, components, version,
-          containerStates);
-      ClientResponse response = getApiClient(uri).get(ClientResponse.class);
-      if (response.getStatus() != 200) {
-        StringBuilder sb = new StringBuilder();
-        sb.append("Failed: HTTP error code: ")
-            .append(response.getStatus())
-            .append(" ErrorMsg: ").append(response.getEntity(String.class));
-        return sb.toString();
-      }
-      return response.getEntity(String.class);
-    } catch (Exception e) {
-      LOG.error("Fail to get containers {}", e);
-    }
-    return null;
-  }
-
-  @Override
-  public int actionCancelUpgrade(
-      String appName) throws IOException, YarnException {
-    int result;
-    try {
-      Service service = new Service();
-      service.setName(appName);
-      service.setState(ServiceState.CANCEL_UPGRADING);
-      String buffer = jsonSerDeser.toJson(service);
-      LOG.info("Cancel upgrade in progress. Please wait..");
-      ClientResponse response = getApiClient(getServicePath(appName))
-          .put(ClientResponse.class, buffer);
-      result = processResponse(response);
-    } catch (Exception e) {
-      LOG.error("Failed to cancel upgrade: ", e);
-      result = EXIT_EXCEPTION_THROWN;
-    }
-    return result;
-  }
-
-  @Override
-  public int actionDecommissionInstances(String appName, List<String>
-      componentInstances) throws IOException, YarnException {
-    int result = EXIT_SUCCESS;
-    try {
-      Service service = new Service();
-      service.setName(appName);
-      for (String instance : componentInstances) {
-        String componentName = ServiceApiUtil.parseComponentName(instance);
-        Component component = service.getComponent(componentName);
-        if (component == null) {
-          component = new Component();
-          component.setName(componentName);
-          service.addComponent(component);
-        }
-        component.addDecommissionedInstance(instance);
-      }
-      String buffer = jsonSerDeser.toJson(service);
-      ClientResponse response = getApiClient(getServicePath(appName))
-          .put(ClientResponse.class, buffer);
-      result = processResponse(response);
-    } catch (Exception e) {
-      LOG.error("Fail to decommission instance: ", e);
-      result = EXIT_EXCEPTION_THROWN;
-    }
-    return result;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/client/SystemServiceManagerImpl.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/client/SystemServiceManagerImpl.java
deleted file mode 100644
index f971d7140aa..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/client/SystemServiceManagerImpl.java
+++ /dev/null
@@ -1,410 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.client;
-
-import org.apache.hadoop.classification.VisibleForTesting;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.FileStatus;
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.fs.RemoteIterator;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.service.AbstractService;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.service.SystemServiceManager;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.conf.SliderExitCodes;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConf;
-import org.apache.hadoop.yarn.service.exceptions.SliderException;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.FileNotFoundException;
-import java.io.IOException;
-import java.lang.reflect.UndeclaredThrowableException;
-import java.security.PrivilegedExceptionAction;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Map;
-import java.util.Set;
-import java.util.concurrent.atomic.AtomicBoolean;
-
-import static org.apache.hadoop.yarn.service.utils.ServiceApiUtil.jsonSerDeser;
-
-/**
- * SystemServiceManager implementation.
- * Scan for configure system service path.
- *
- * The service path structure is as follows:
- * SYSTEM_SERVICE_DIR_PATH
- * |---- sync
- * |     |--- user1
- * |     |    |---- service1.yarnfile
- * |     |    |---- service2.yarnfile
- * |     |--- user2
- * |     |    |---- service1.yarnfile
- * |     |    ....
- * |     |
- * |---- async
- * |     |--- user3
- * |     |    |---- service1.yarnfile
- * |     |    |---- service2.yarnfile
- * |     |--- user4
- * |     |    |---- service1.yarnfile
- * |     |    ....
- * |     |
- *
- * sync: These services are launched at the time of service start synchronously.
- *       It is a blocking service start.
- * async: These services are launched in separate thread without any delay after
- *       service start. Non-blocking service start.
- */
-public class SystemServiceManagerImpl extends AbstractService
-    implements SystemServiceManager {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(SystemServiceManagerImpl.class);
-
-  private static final String YARN_FILE_SUFFIX = ".yarnfile";
-  private static final String SYNC = "sync";
-  private static final String ASYNC = "async";
-
-  private FileSystem fs;
-  private Path systemServiceDir;
-  private AtomicBoolean stopExecutors = new AtomicBoolean(false);
-  private Map<String, Set<Service>> syncUserServices = new HashMap<>();
-  private Map<String, Set<Service>> asyncUserServices = new HashMap<>();
-  private UserGroupInformation loginUGI;
-  private Thread serviceLaucher;
-
-  @VisibleForTesting
-  private int badFileNameExtensionSkipCounter;
-  @VisibleForTesting
-  private Map<String, Integer> ignoredUserServices =
-      new HashMap<>();
-  @VisibleForTesting
-  private int badDirSkipCounter;
-
-  public SystemServiceManagerImpl() {
-    super(SystemServiceManagerImpl.class.getName());
-  }
-
-  @Override
-  protected void serviceInit(Configuration conf) throws Exception {
-    String dirPath =
-        conf.get(YarnServiceConf.YARN_SERVICES_SYSTEM_SERVICE_DIRECTORY);
-    if (dirPath != null) {
-      systemServiceDir = new Path(dirPath);
-      LOG.info("System Service Directory is configured to {}",
-          systemServiceDir);
-      fs = systemServiceDir.getFileSystem(conf);
-      this.loginUGI = UserGroupInformation.isSecurityEnabled() ?
-          UserGroupInformation.getLoginUser() :
-          UserGroupInformation.getCurrentUser();
-      LOG.info("UserGroupInformation initialized to {}", loginUGI);
-    }
-  }
-
-  @Override
-  protected void serviceStart() throws Exception {
-    scanForUserServices();
-    launchUserService(syncUserServices);
-    // Create a thread and submit services in background otherwise it
-    // block RM switch time.
-    serviceLaucher = new Thread(createRunnable());
-    serviceLaucher.setName("System service launcher");
-    serviceLaucher.start();
-  }
-
-  @Override
-  protected void serviceStop() throws Exception {
-    LOG.info("Stopping {}", getName());
-    stopExecutors.set(true);
-
-    if (serviceLaucher != null) {
-      serviceLaucher.interrupt();
-      try {
-        serviceLaucher.join();
-      } catch (InterruptedException ie) {
-        LOG.warn("Interrupted Exception while stopping", ie);
-      }
-    }
-  }
-
-  private Runnable createRunnable() {
-    return new Runnable() {
-      @Override
-      public void run() {
-        launchUserService(asyncUserServices);
-      }
-    };
-  }
-
-  void launchUserService(Map<String, Set<Service>> userServices) {
-    for (Map.Entry<String, Set<Service>> entry : userServices.entrySet()) {
-      String user = entry.getKey();
-      Set<Service> services = entry.getValue();
-      if (services.isEmpty()) {
-        continue;
-      }
-      ServiceClient serviceClient = null;
-      try {
-        UserGroupInformation userUgi = getProxyUser(user);
-        serviceClient = createServiceClient(userUgi);
-        for (Service service : services) {
-          LOG.info("POST: createService = {} user = {}", service, userUgi);
-          try {
-            launchServices(userUgi, serviceClient, service);
-          } catch (IOException | UndeclaredThrowableException e) {
-            if (e.getCause() != null) {
-              LOG.warn(e.getCause().getMessage());
-            } else {
-              String message =
-                  "Failed to create service " + service.getName() + " : ";
-              LOG.error(message, e);
-            }
-          }
-        }
-      } catch (InterruptedException e) {
-        LOG.warn("System service launcher thread interrupted", e);
-        break;
-      } catch (Exception e) {
-        LOG.error("Error while submitting services for user " + user, e);
-      } finally {
-        if (serviceClient != null) {
-          try {
-            serviceClient.close();
-          } catch (IOException e) {
-            LOG.warn("Error while closing serviceClient for user {}", user);
-          }
-        }
-      }
-    }
-  }
-
-  private ServiceClient createServiceClient(UserGroupInformation userUgi)
-      throws IOException, InterruptedException {
-    ServiceClient serviceClient =
-        userUgi.doAs(new PrivilegedExceptionAction<ServiceClient>() {
-          @Override public ServiceClient run()
-              throws IOException, YarnException {
-            ServiceClient sc = getServiceClient();
-            sc.init(getConfig());
-            sc.start();
-            return sc;
-          }
-        });
-    return serviceClient;
-  }
-
-  private void launchServices(UserGroupInformation userUgi,
-      ServiceClient serviceClient, Service service)
-      throws IOException, InterruptedException {
-    if (service.getState() == ServiceState.STOPPED) {
-      userUgi.doAs(new PrivilegedExceptionAction<Void>() {
-        @Override public Void run() throws IOException, YarnException {
-          serviceClient.actionBuild(service);
-          return null;
-        }
-      });
-      LOG.info("Service {} version {} saved.", service.getName(),
-          service.getVersion());
-    } else {
-      ApplicationId applicationId =
-          userUgi.doAs(new PrivilegedExceptionAction<ApplicationId>() {
-            @Override public ApplicationId run()
-                throws IOException, YarnException {
-              boolean tryStart = true;
-              try {
-                serviceClient.actionBuild(service);
-              } catch (Exception e) {
-                if (e instanceof SliderException && ((SliderException) e)
-                    .getExitCode() == SliderExitCodes.EXIT_INSTANCE_EXISTS) {
-                  LOG.info("Service {} already exists, will attempt to start " +
-                      "service", service.getName());
-                } else {
-                  tryStart = false;
-                  LOG.info("Got exception saving {}, will not attempt to " +
-                      "start service", service.getName(), e);
-                }
-              }
-              if (tryStart) {
-                return serviceClient.actionStartAndGetId(service.getName());
-              } else {
-                return null;
-              }
-            }
-          });
-      if (applicationId != null) {
-        LOG.info("Service {} submitted with Application ID: {}",
-            service.getName(), applicationId);
-      }
-    }
-  }
-
-  ServiceClient getServiceClient() {
-    return new ServiceClient();
-  }
-
-  private UserGroupInformation getProxyUser(String user) {
-    UserGroupInformation ugi;
-    if (UserGroupInformation.isSecurityEnabled()) {
-      ugi = UserGroupInformation.createProxyUser(user, loginUGI);
-    } else {
-      ugi = UserGroupInformation.createRemoteUser(user);
-    }
-    return ugi;
-  }
-
-  // scan for both launch service types i.e sync and async
-  void scanForUserServices() throws IOException {
-    if (systemServiceDir == null) {
-      return;
-    }
-    try {
-      LOG.info("Scan for launch type on {}", systemServiceDir);
-      RemoteIterator<FileStatus> iterLaunchType = list(systemServiceDir);
-      while (iterLaunchType.hasNext()) {
-        FileStatus launchType = iterLaunchType.next();
-        if (!launchType.isDirectory()) {
-          LOG.debug("Scanner skips for unknown file {}", launchType.getPath());
-          continue;
-        }
-        if (launchType.getPath().getName().equals(SYNC)) {
-          scanForUserServiceDefinition(launchType.getPath(), syncUserServices);
-        } else if (launchType.getPath().getName().equals(ASYNC)) {
-          scanForUserServiceDefinition(launchType.getPath(), asyncUserServices);
-        } else {
-          badDirSkipCounter++;
-          LOG.debug("Scanner skips for unknown dir {}.", launchType.getPath());
-        }
-      }
-    } catch (FileNotFoundException e) {
-      LOG.warn("System service directory {} doesn't not exist.",
-          systemServiceDir);
-    }
-  }
-
-  // Files are under systemServiceDir/<users>. Scan for 2 levels
-  // 1st level for users
-  // 2nd level for service definitions under user
-  private void scanForUserServiceDefinition(Path userDirPath,
-      Map<String, Set<Service>> userServices) throws IOException {
-    LOG.info("Scan for users on {}", userDirPath);
-    RemoteIterator<FileStatus> iterUsers = list(userDirPath);
-    while (iterUsers.hasNext()) {
-      FileStatus userDir = iterUsers.next();
-      // if 1st level is not user directory then skip it.
-      if (!userDir.isDirectory()) {
-        LOG.info(
-            "Service definition {} doesn't belong to any user. Ignoring.. ",
-            userDir.getPath().getName());
-        continue;
-      }
-      String userName = userDir.getPath().getName();
-      LOG.info("Scanning service definitions for user {}.", userName);
-
-      //2nd level scan
-      RemoteIterator<FileStatus> iterServices = list(userDir.getPath());
-      while (iterServices.hasNext()) {
-        FileStatus serviceCache = iterServices.next();
-        String filename = serviceCache.getPath().getName();
-        if (!serviceCache.isFile()) {
-          LOG.info("Scanner skips for unknown dir {}", filename);
-          continue;
-        }
-        if (!filename.endsWith(YARN_FILE_SUFFIX)) {
-          LOG.info("Scanner skips for unknown file extension, filename = {}",
-              filename);
-          badFileNameExtensionSkipCounter++;
-          continue;
-        }
-        Service service = getServiceDefinition(serviceCache.getPath());
-        if (service != null) {
-          Set<Service> services = userServices.get(userName);
-          if (services == null) {
-            services = new HashSet<>();
-            userServices.put(userName, services);
-          }
-          if (!services.add(service)) {
-            int count = ignoredUserServices.containsKey(userName) ?
-                ignoredUserServices.get(userName) : 0;
-            ignoredUserServices.put(userName, count + 1);
-            LOG.warn(
-                "Ignoring service {} for the user {} as it is already present,"
-                    + " filename = {}", service.getName(), userName, filename);
-          } else {
-            LOG.info("Added service {} for the user {}, filename = {}",
-                service.getName(), userName, filename);
-          }
-        }
-      }
-    }
-  }
-
-  private Service getServiceDefinition(Path filePath) {
-    Service service = null;
-    try {
-      LOG.debug("Loading service definition from FS: {}", filePath);
-      service = jsonSerDeser.load(fs, filePath);
-    } catch (IOException e) {
-      LOG.info("Error while loading service definition from FS: {}", e);
-    }
-    return service;
-  }
-
-  private RemoteIterator<FileStatus> list(Path path) throws IOException {
-    return new StoppableRemoteIterator(fs.listStatusIterator(path));
-  }
-
-  @VisibleForTesting Map<String, Integer> getIgnoredUserServices() {
-    return ignoredUserServices;
-  }
-
-  private class StoppableRemoteIterator implements RemoteIterator<FileStatus> {
-    private final RemoteIterator<FileStatus> remote;
-
-    StoppableRemoteIterator(RemoteIterator<FileStatus> remote) {
-      this.remote = remote;
-    }
-
-    @Override public boolean hasNext() throws IOException {
-      return !stopExecutors.get() && remote.hasNext();
-    }
-
-    @Override public FileStatus next() throws IOException {
-      return remote.next();
-    }
-  }
-
-  @VisibleForTesting
-  Map<String, Set<Service>> getSyncUserServices() {
-    return syncUserServices;
-  }
-
-  @VisibleForTesting
-  int getBadFileNameExtensionSkipCounter() {
-    return badFileNameExtensionSkipCounter;
-  }
-
-  @VisibleForTesting
-  int getBadDirSkipCounter() {
-    return badDirSkipCounter;
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/client/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/client/package-info.java
deleted file mode 100644
index cf5ce112449..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/client/package-info.java
+++ /dev/null
@@ -1,28 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Package org.apache.hadoop.yarn.service.client contains classes
- * for YARN Services Client API.
- */
-@InterfaceAudience.Private
-@InterfaceStability.Unstable
-package org.apache.hadoop.yarn.service.client;
-
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/webapp/ApiServer.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/webapp/ApiServer.java
deleted file mode 100644
index c4c5a760e77..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/webapp/ApiServer.java
+++ /dev/null
@@ -1,973 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.webapp;
-
-import com.google.inject.Inject;
-import com.google.inject.Singleton;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.security.AccessControlException;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.util.Lists;
-import org.apache.hadoop.util.Sets;
-import org.apache.hadoop.util.VersionInfo;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.api.records.ComponentContainers;
-import org.apache.hadoop.yarn.service.api.records.ComponentState;
-import org.apache.hadoop.yarn.service.api.records.Container;
-import org.apache.hadoop.yarn.service.api.records.ContainerState;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.api.records.ServiceStatus;
-import org.apache.hadoop.yarn.service.client.ServiceClient;
-import org.apache.hadoop.yarn.service.conf.RestApiConstants;
-import org.apache.hadoop.yarn.service.utils.ServiceApiUtil;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import org.apache.hadoop.thirdparty.com.google.common.base.Joiner;
-
-import javax.servlet.http.HttpServletRequest;
-import javax.ws.rs.*;
-import javax.ws.rs.core.Context;
-import javax.ws.rs.core.MediaType;
-import javax.ws.rs.core.Response;
-import javax.ws.rs.core.Response.Status;
-
-import java.io.FileNotFoundException;
-import java.io.IOException;
-import java.lang.reflect.UndeclaredThrowableException;
-import java.security.PrivilegedExceptionAction;
-import java.util.*;
-import java.util.stream.Collectors;
-
-import static org.apache.hadoop.yarn.service.api.records.ServiceState.ACCEPTED;
-import static org.apache.hadoop.yarn.service.api.records.ServiceState.CANCEL_UPGRADING;
-import static org.apache.hadoop.yarn.service.conf.RestApiConstants.*;
-import static org.apache.hadoop.yarn.service.exceptions.LauncherExitCodes.*;
-
-/**
- * The rest API endpoints for users to manage services on YARN.
- */
-@Singleton
-@Path(CONTEXT_ROOT)
-public class ApiServer {
-
-  public ApiServer() {
-    super();
-  }
-  
-  @Inject
-  public ApiServer(Configuration conf) {
-    super();
-  }
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(ApiServer.class);
-  private static Configuration YARN_CONFIG = new YarnConfiguration();
-  private ServiceClient serviceClientUnitTest;
-  private boolean unitTest = false;
-
-  static {
-    init();
-  }
-
-  // initialize all the common resources - order is important
-  private static void init() {
-  }
-
-  @GET
-  @Path(VERSION)
-  @Consumes({ MediaType.APPLICATION_JSON })
-  @Produces({ MediaType.APPLICATION_JSON + ";charset=utf-8" })
-  public Response getVersion() {
-    String version = VersionInfo.getBuildVersion();
-    LOG.info(version);
-    return Response.ok("{ \"hadoop_version\": \"" + version + "\"}").build();
-  }
-
-  @POST
-  @Path(SERVICE_ROOT_PATH)
-  @Consumes({ MediaType.APPLICATION_JSON })
-  @Produces({ MediaType.APPLICATION_JSON + ";charset=utf-8" })
-  public Response createService(@Context HttpServletRequest request,
-      Service service) {
-    ServiceStatus serviceStatus = new ServiceStatus();
-    try {
-      UserGroupInformation ugi = getProxyUser(request);
-      LOG.info("POST: createService = {} user = {}", service, ugi);
-      if(service.getState()==ServiceState.STOPPED) {
-        ugi.doAs(new PrivilegedExceptionAction<Void>() {
-          @Override
-          public Void run() throws YarnException, IOException {
-            ServiceClient sc = getServiceClient();
-            try {
-              sc.init(YARN_CONFIG);
-              sc.start();
-              sc.actionBuild(service);
-            } finally {
-              sc.close();
-            }
-            return null;
-          }
-        });
-        serviceStatus.setDiagnostics("Service " + service.getName() +
-            " version " + service.getVersion() + " saved.");
-      } else {
-        ApplicationId applicationId = ugi
-            .doAs(new PrivilegedExceptionAction<ApplicationId>() {
-              @Override
-              public ApplicationId run() throws IOException, YarnException {
-                ServiceClient sc = getServiceClient();
-                try {
-                  sc.init(YARN_CONFIG);
-                  sc.start();
-                  ApplicationId applicationId = sc.actionCreate(service);
-                  return applicationId;
-                } finally {
-                  sc.close();
-                }
-              }
-            });
-        serviceStatus.setDiagnostics("Application ID: " + applicationId);
-      }
-      serviceStatus.setState(ACCEPTED);
-      serviceStatus.setUri(
-          CONTEXT_ROOT + SERVICE_ROOT_PATH + "/" + service
-              .getName());
-      return formatResponse(Status.ACCEPTED, serviceStatus);
-    } catch (AccessControlException e) {
-      serviceStatus.setDiagnostics(e.getMessage());
-      return formatResponse(Status.FORBIDDEN, e.getCause().getMessage());
-    } catch (IllegalArgumentException e) {
-      return formatResponse(Status.BAD_REQUEST, e.getMessage());
-    } catch (IOException | InterruptedException e) {
-      String message = "Failed to create service " + service.getName()
-          + ": {}";
-      LOG.error(message, e);
-      return formatResponse(Status.INTERNAL_SERVER_ERROR, e.getMessage());
-    } catch (UndeclaredThrowableException e) {
-      String message = "Failed to create service " + service.getName()
-          + ": {}";
-      LOG.error(message, e);
-      if (e.getCause().getMessage().contains("already exists")) {
-        message = "Service name " + service.getName() + " is already taken.";
-      } else {
-        message = e.getCause().getMessage();
-      }
-      return formatResponse(Status.INTERNAL_SERVER_ERROR,
-          message);
-    }
-  }
-
-  @GET
-  @Path(SERVICE_PATH)
-  @Consumes({ MediaType.APPLICATION_JSON })
-  @Produces({ MediaType.APPLICATION_JSON + ";charset=utf-8" })
-  public Response getService(@Context HttpServletRequest request,
-      @PathParam(SERVICE_NAME) String appName) {
-    ServiceStatus serviceStatus = new ServiceStatus();
-    try {
-      if (appName == null) {
-        throw new IllegalArgumentException("Service name cannot be null.");
-      }
-      UserGroupInformation ugi = getProxyUser(request);
-      LOG.info("GET: getService for appName = {} user = {}", appName, ugi);
-      Service app = getServiceFromClient(ugi, appName);
-      return Response.ok(app).build();
-    } catch (AccessControlException e) {
-      return formatResponse(Status.FORBIDDEN, e.getMessage());
-    } catch (IllegalArgumentException e) {
-      serviceStatus.setDiagnostics(e.getMessage());
-      serviceStatus.setCode(ERROR_CODE_APP_NAME_INVALID);
-      return Response.status(Status.NOT_FOUND).entity(serviceStatus)
-          .build();
-    } catch (FileNotFoundException e) {
-      serviceStatus.setDiagnostics("Service " + appName + " not found");
-      serviceStatus.setCode(ERROR_CODE_APP_NAME_INVALID);
-      return Response.status(Status.NOT_FOUND).entity(serviceStatus)
-          .build();
-    } catch (IOException | InterruptedException e) {
-      LOG.error("Get service failed: {}", e);
-      return formatResponse(Status.INTERNAL_SERVER_ERROR, e.getMessage());
-    } catch (UndeclaredThrowableException e) {
-      LOG.error("Get service failed: {}", e);
-      return formatResponse(Status.INTERNAL_SERVER_ERROR,
-          e.getCause().getMessage());
-    }
-  }
-
-  @DELETE
-  @Path(SERVICE_PATH)
-  @Consumes({ MediaType.APPLICATION_JSON })
-  @Produces({ MediaType.APPLICATION_JSON + ";charset=utf-8" })
-  public Response deleteService(@Context HttpServletRequest request,
-      @PathParam(SERVICE_NAME) String appName) {
-    try {
-      if (appName == null) {
-        throw new IllegalArgumentException("Service name can not be null.");
-      }
-      UserGroupInformation ugi = getProxyUser(request);
-      LOG.info("DELETE: deleteService for appName = {} user = {}",
-          appName, ugi);
-      return stopService(appName, true, ugi);
-    } catch (AccessControlException e) {
-      return formatResponse(Status.FORBIDDEN, e.getMessage());
-    } catch (IllegalArgumentException e) {
-      return formatResponse(Status.BAD_REQUEST, e.getMessage());
-    } catch (UndeclaredThrowableException e) {
-      LOG.error("Fail to stop service: {}", e);
-      return formatResponse(Status.BAD_REQUEST,
-          e.getCause().getMessage());
-    } catch (YarnException | FileNotFoundException e) {
-      return formatResponse(Status.NOT_FOUND, e.getMessage());
-    } catch (Exception e) {
-      LOG.error("Fail to stop service: {}", e);
-      return formatResponse(Status.INTERNAL_SERVER_ERROR, e.getMessage());
-    }
-  }
-
-  private Response stopService(String appName, boolean destroy,
-      final UserGroupInformation ugi) throws Exception {
-    int result = ugi.doAs(new PrivilegedExceptionAction<Integer>() {
-      @Override
-      public Integer run() throws Exception {
-        int result = 0;
-        ServiceClient sc = getServiceClient();
-        try {
-          sc.init(YARN_CONFIG);
-          sc.start();
-          Exception stopException = null;
-          try {
-            result = sc.actionStop(appName, destroy);
-            if (result == EXIT_SUCCESS) {
-              LOG.info("Successfully stopped service {}", appName);
-            }
-          } catch (Exception e) {
-            LOG.info("Got exception stopping service", e);
-            stopException = e;
-          }
-          if (destroy) {
-            result = sc.actionDestroy(appName);
-            if (result == EXIT_SUCCESS) {
-              LOG.info("Successfully deleted service {}", appName);
-            }
-          } else {
-            if (stopException != null) {
-              throw stopException;
-            }
-          }
-        } finally {
-          sc.close();
-        }
-        return result;
-      }
-    });
-    ServiceStatus serviceStatus = new ServiceStatus();
-    if (destroy) {
-      if (result == EXIT_SUCCESS) {
-        serviceStatus.setDiagnostics("Successfully destroyed service " +
-            appName);
-      } else {
-        if (result == EXIT_NOT_FOUND) {
-          serviceStatus
-              .setDiagnostics("Service " + appName + " doesn't exist");
-          return formatResponse(Status.BAD_REQUEST, serviceStatus);
-        } else {
-          serviceStatus
-              .setDiagnostics("Service " + appName + " error cleaning up " +
-                  "registry");
-          return formatResponse(Status.INTERNAL_SERVER_ERROR, serviceStatus);
-        }
-      }
-    } else {
-      if (result == EXIT_COMMAND_ARGUMENT_ERROR) {
-        serviceStatus
-            .setDiagnostics("Service " + appName + " is already stopped");
-        return formatResponse(Status.BAD_REQUEST, serviceStatus);
-      } else {
-        serviceStatus.setDiagnostics("Successfully stopped service " + appName);
-      }
-    }
-    return formatResponse(Status.OK, serviceStatus);
-  }
-
-  @PUT
-  @Path(COMPONENTS_PATH)
-  @Consumes({MediaType.APPLICATION_JSON})
-  @Produces({RestApiConstants.MEDIA_TYPE_JSON_UTF8, MediaType.TEXT_PLAIN})
-  public Response updateComponents(@Context HttpServletRequest request,
-      @PathParam(SERVICE_NAME) String serviceName,
-      List<Component> requestComponents) {
-
-    try {
-      if (requestComponents == null || requestComponents.isEmpty()) {
-        throw new YarnException("No components provided.");
-      }
-      UserGroupInformation ugi = getProxyUser(request);
-      Set<String> compNamesToUpgrade = new HashSet<>();
-      requestComponents.forEach(reqComp -> {
-        if (reqComp.getState() != null &&
-            reqComp.getState().equals(ComponentState.UPGRADING)) {
-          compNamesToUpgrade.add(reqComp.getName());
-        }
-      });
-      LOG.info("PUT: upgrade components {} for service {} " +
-          "user = {}", compNamesToUpgrade, serviceName, ugi);
-      return processComponentsUpgrade(ugi, serviceName, compNamesToUpgrade);
-    } catch (AccessControlException e) {
-      return formatResponse(Response.Status.FORBIDDEN, e.getMessage());
-    } catch (YarnException e) {
-      return formatResponse(Response.Status.BAD_REQUEST, e.getMessage());
-    } catch (IOException | InterruptedException e) {
-      return formatResponse(Response.Status.INTERNAL_SERVER_ERROR,
-          e.getMessage());
-    } catch (UndeclaredThrowableException e) {
-      return formatResponse(Response.Status.INTERNAL_SERVER_ERROR,
-          e.getCause().getMessage());
-    }
-  }
-
-  @PUT
-  @Path(COMPONENT_PATH)
-  @Consumes({ MediaType.APPLICATION_JSON })
-  @Produces({ MediaType.APPLICATION_JSON + ";charset=utf-8",
-              MediaType.TEXT_PLAIN  })
-  public Response updateComponent(@Context HttpServletRequest request,
-      @PathParam(SERVICE_NAME) String appName,
-      @PathParam(COMPONENT_NAME) String componentName, Component component) {
-
-    try {
-      if (component == null) {
-        throw new YarnException("No component data provided");
-      }
-      if (component.getName() != null
-          && !component.getName().equals(componentName)) {
-        String msg = "Component name in the request object ("
-            + component.getName() + ") does not match that in the URI path ("
-            + componentName + ")";
-        throw new YarnException(msg);
-      }
-      UserGroupInformation ugi = getProxyUser(request);
-      if (component.getState() != null &&
-          component.getState().equals(ComponentState.UPGRADING)) {
-        LOG.info("PUT: upgrade component {} for service {} " +
-            "user = {}", component.getName(), appName, ugi);
-        return processComponentsUpgrade(ugi, appName,
-            Sets.newHashSet(componentName));
-      }
-
-      if (component.getNumberOfContainers() == null) {
-        throw new YarnException("No container count provided");
-      }
-      if (component.getNumberOfContainers() < 0) {
-        String message = "Invalid number of containers specified "
-            + component.getNumberOfContainers();
-        throw new YarnException(message);
-      }
-      Map<String, Long> original = ugi
-          .doAs(new PrivilegedExceptionAction<Map<String, Long>>() {
-            @Override
-            public Map<String, Long> run() throws YarnException, IOException {
-              ServiceClient sc = new ServiceClient();
-              try {
-                sc.init(YARN_CONFIG);
-                sc.start();
-                Map<String, Long> original = sc.flexByRestService(appName,
-                    Collections.singletonMap(componentName,
-                        component.getNumberOfContainers()));
-                return original;
-              } finally {
-                sc.close();
-              }
-            }
-          });
-      ServiceStatus status = new ServiceStatus();
-      status.setDiagnostics(
-          "Updating component (" + componentName + ") size from " + original
-              .get(componentName) + " to " + component.getNumberOfContainers());
-      return formatResponse(Status.OK, status);
-    } catch (AccessControlException e) {
-      return formatResponse(Status.FORBIDDEN, e.getMessage());
-    } catch (YarnException e) {
-      return formatResponse(Status.BAD_REQUEST, e.getMessage());
-    } catch (IOException | InterruptedException e) {
-      return formatResponse(Status.INTERNAL_SERVER_ERROR,
-          e.getMessage());
-    } catch (UndeclaredThrowableException e) {
-      return formatResponse(Status.INTERNAL_SERVER_ERROR,
-          e.getCause().getMessage());
-    }
-  }
-
-  @PUT
-  @Path(SERVICE_PATH)
-  @Consumes({ MediaType.APPLICATION_JSON })
-  @Produces({ MediaType.APPLICATION_JSON + ";charset=utf-8" })
-  public Response updateService(@Context HttpServletRequest request,
-      @PathParam(SERVICE_NAME) String appName,
-      Service updateServiceData) {
-    try {
-      UserGroupInformation ugi = getProxyUser(request);
-      LOG.info("PUT: updateService for app = {} with data = {} user = {}",
-          appName, updateServiceData, ugi);
-      // Ignore the app name provided in updateServiceData and always use
-      // appName path param
-      updateServiceData.setName(appName);
-
-      if (updateServiceData.getState() != null
-          && updateServiceData.getState() == ServiceState.FLEX) {
-        return flexService(updateServiceData, ugi);
-      }
-      // For STOP the app should be running. If already stopped then this
-      // operation will be a no-op. For START it should be in stopped state.
-      // If already running then this operation will be a no-op.
-      if (updateServiceData.getState() != null
-          && updateServiceData.getState() == ServiceState.STOPPED) {
-        return stopService(appName, false, ugi);
-      }
-
-      // If a START is requested
-      if (updateServiceData.getState() != null
-          && updateServiceData.getState() == ServiceState.STARTED) {
-        return startService(appName, ugi);
-      }
-
-      // If an UPGRADE is requested
-      if (updateServiceData.getState() != null && (
-          updateServiceData.getState() == ServiceState.UPGRADING ||
-              updateServiceData.getState() ==
-                  ServiceState.UPGRADING_AUTO_FINALIZE) ||
-          updateServiceData.getState() == ServiceState.EXPRESS_UPGRADING) {
-        return upgradeService(updateServiceData, ugi);
-      }
-
-      // If CANCEL_UPGRADING is requested
-      if (updateServiceData.getState() != null &&
-          updateServiceData.getState() == CANCEL_UPGRADING) {
-        return cancelUpgradeService(appName, ugi);
-      }
-
-      // If new lifetime value specified then update it
-      if (updateServiceData.getLifetime() != null
-          && updateServiceData.getLifetime() > 0) {
-        return updateLifetime(appName, updateServiceData, ugi);
-      }
-
-      for (Component c : updateServiceData.getComponents()) {
-        if (c.getDecommissionedInstances().size() > 0) {
-          return decommissionInstances(updateServiceData, ugi);
-        }
-      }
-    } catch (UndeclaredThrowableException e) {
-      return formatResponse(Status.BAD_REQUEST,
-          e.getCause().getMessage());
-    } catch (AccessControlException e) {
-      return formatResponse(Status.FORBIDDEN, e.getMessage());
-    } catch (FileNotFoundException e) {
-      String message = "Application is not found app: " + appName;
-      LOG.error(message, e);
-      return formatResponse(Status.NOT_FOUND, e.getMessage());
-    } catch (YarnException e) {
-      LOG.error(e.getMessage(), e);
-      return formatResponse(Status.NOT_FOUND, e.getMessage());
-    } catch (Exception e) {
-      String message = "Error while performing operation for app: " + appName;
-      LOG.error(message, e);
-      return formatResponse(Status.INTERNAL_SERVER_ERROR, e.getMessage());
-    }
-
-    // If nothing happens consider it a no-op
-    return Response.status(Status.NO_CONTENT).build();
-  }
-
-  @PUT
-  @Path(COMP_INSTANCE_LONG_PATH)
-  @Consumes({MediaType.APPLICATION_JSON})
-  @Produces({RestApiConstants.MEDIA_TYPE_JSON_UTF8, MediaType.TEXT_PLAIN})
-  public Response updateComponentInstance(@Context HttpServletRequest request,
-      @PathParam(SERVICE_NAME) String serviceName,
-      @PathParam(COMPONENT_NAME) String componentName,
-      @PathParam(COMP_INSTANCE_NAME) String compInstanceName,
-      Container reqContainer) {
-
-    try {
-      UserGroupInformation ugi = getProxyUser(request);
-      LOG.info("PUT: update component instance {} for component = {}" +
-              " service = {} user = {}", compInstanceName, componentName,
-          serviceName, ugi);
-      if (reqContainer == null) {
-        throw new YarnException("No container data provided.");
-      }
-      Service service = getServiceFromClient(ugi, serviceName);
-      Component component = service.getComponent(componentName);
-      if (component == null) {
-        throw new YarnException(String.format(
-            "The component name in the URI path (%s) is invalid.",
-            componentName));
-      }
-
-      Container liveContainer = component.getComponentInstance(
-          compInstanceName);
-      if (liveContainer == null) {
-        throw new YarnException(String.format(
-            "The component (%s) does not have a component instance (%s).",
-            componentName, compInstanceName));
-      }
-
-      if (reqContainer.getState() != null
-          && reqContainer.getState().equals(ContainerState.UPGRADING)) {
-        return processContainersUpgrade(ugi, service,
-            Lists.newArrayList(liveContainer));
-      }
-    } catch (AccessControlException e) {
-      return formatResponse(Response.Status.FORBIDDEN, e.getMessage());
-    } catch (YarnException e) {
-      return formatResponse(Response.Status.BAD_REQUEST, e.getMessage());
-    } catch (IOException | InterruptedException e) {
-      return formatResponse(Response.Status.INTERNAL_SERVER_ERROR,
-          e.getMessage());
-    } catch (UndeclaredThrowableException e) {
-      return formatResponse(Response.Status.INTERNAL_SERVER_ERROR,
-          e.getCause().getMessage());
-    }
-    return Response.status(Status.NO_CONTENT).build();
-  }
-
-  @PUT
-  @Path(COMP_INSTANCES_PATH)
-  @Consumes({MediaType.APPLICATION_JSON})
-  @Produces({RestApiConstants.MEDIA_TYPE_JSON_UTF8, MediaType.TEXT_PLAIN})
-  public Response updateComponentInstances(@Context HttpServletRequest request,
-      @PathParam(SERVICE_NAME) String serviceName,
-      List<Container> requestContainers) {
-
-    try {
-      if (requestContainers == null || requestContainers.isEmpty()) {
-        throw new YarnException("No containers provided.");
-      }
-      UserGroupInformation ugi = getProxyUser(request);
-      List<String> toUpgrade = new ArrayList<>();
-      for (Container reqContainer : requestContainers) {
-        if (reqContainer.getState() != null &&
-            reqContainer.getState().equals(ContainerState.UPGRADING)) {
-          toUpgrade.add(reqContainer.getComponentInstanceName());
-        }
-      }
-
-      if (!toUpgrade.isEmpty()) {
-        Service service = getServiceFromClient(ugi, serviceName);
-        LOG.info("PUT: upgrade component instances {} for service = {} " +
-            "user = {}", toUpgrade, serviceName, ugi);
-        List<Container> liveContainers = ServiceApiUtil
-            .getLiveContainers(service, toUpgrade);
-
-        return processContainersUpgrade(ugi, service, liveContainers);
-      }
-    } catch (AccessControlException e) {
-      return formatResponse(Response.Status.FORBIDDEN, e.getMessage());
-    } catch (YarnException e) {
-      return formatResponse(Response.Status.BAD_REQUEST, e.getMessage());
-    } catch (IOException | InterruptedException e) {
-      return formatResponse(Response.Status.INTERNAL_SERVER_ERROR,
-          e.getMessage());
-    } catch (UndeclaredThrowableException e) {
-      return formatResponse(Response.Status.INTERNAL_SERVER_ERROR,
-          e.getCause().getMessage());
-    }
-    return Response.status(Status.NO_CONTENT).build();
-  }
-
-  @GET
-  @Path(COMP_INSTANCES_PATH)
-  @Produces({RestApiConstants.MEDIA_TYPE_JSON_UTF8})
-  public Response getComponentInstances(@Context HttpServletRequest request,
-      @PathParam(SERVICE_NAME) String serviceName,
-      @QueryParam(PARAM_COMP_NAME) List<String> componentNames,
-      @QueryParam(PARAM_VERSION) String version,
-      @QueryParam(PARAM_CONTAINER_STATE) List<String> containerStates) {
-    try {
-      UserGroupInformation ugi = getProxyUser(request);
-      LOG.info("GET: component instances for service = {}, compNames in {}, " +
-          "version = {}, containerStates in {}, user = {}", serviceName,
-          Objects.toString(componentNames, "[]"), Objects.toString(version, ""),
-          Objects.toString(containerStates, "[]"), ugi);
-
-        List<ContainerState> containerStatesDe = containerStates.stream().map(
-            ContainerState::valueOf).collect(Collectors.toList());
-
-        return Response.ok(getContainers(ugi, serviceName, componentNames,
-            version, containerStatesDe)).build();
-    } catch (IllegalArgumentException iae) {
-      return formatResponse(Status.BAD_REQUEST, "valid container states are: " +
-          Arrays.toString(ContainerState.values()));
-    } catch (AccessControlException e) {
-      return formatResponse(Response.Status.FORBIDDEN, e.getMessage());
-    } catch (IOException | InterruptedException e) {
-      return formatResponse(Response.Status.INTERNAL_SERVER_ERROR,
-          e.getMessage());
-    } catch (UndeclaredThrowableException e) {
-      return formatResponse(Response.Status.INTERNAL_SERVER_ERROR,
-          e.getCause().getMessage());
-    }
-  }
-
-  private Response flexService(Service service, UserGroupInformation ugi)
-      throws IOException, InterruptedException {
-    String appName = service.getName();
-    Response response = Response.status(Status.BAD_REQUEST).build();
-    Map<String, String> componentCountStrings = new HashMap<String, String>();
-    for (Component c : service.getComponents()) {
-      componentCountStrings.put(c.getName(),
-          c.getNumberOfContainers().toString());
-    }
-    Integer result = ugi.doAs(new PrivilegedExceptionAction<Integer>() {
-
-      @Override
-      public Integer run() throws YarnException, IOException {
-        int result = 0;
-        ServiceClient sc = new ServiceClient();
-        try {
-          sc.init(YARN_CONFIG);
-          sc.start();
-          result = sc
-              .actionFlex(appName, componentCountStrings);
-          return Integer.valueOf(result);
-        } finally {
-          sc.close();
-        }
-      }
-    });
-    if (result == EXIT_SUCCESS) {
-      String message = "Service " + appName + " is successfully flexed.";
-      LOG.info(message);
-      ServiceStatus status = new ServiceStatus();
-      status.setDiagnostics(message);
-      status.setState(ServiceState.ACCEPTED);
-      response = formatResponse(Status.ACCEPTED, status);
-    }
-    return response;
-  }
-
-  private Response updateLifetime(String appName, Service updateAppData,
-      final UserGroupInformation ugi) throws IOException,
-      InterruptedException {
-    String newLifeTime = ugi.doAs(new PrivilegedExceptionAction<String>() {
-      @Override
-      public String run() throws YarnException, IOException {
-        ServiceClient sc = getServiceClient();
-        try {
-          sc.init(YARN_CONFIG);
-          sc.start();
-          String newLifeTime = sc.updateLifetime(appName,
-              updateAppData.getLifetime());
-          return newLifeTime;
-        } finally {
-          sc.close();
-        }
-      }
-    });
-    ServiceStatus status = new ServiceStatus();
-    status.setDiagnostics(
-        "Service (" + appName + ")'s lifeTime is updated to " + newLifeTime
-            + ", " + updateAppData.getLifetime() + " seconds remaining");
-    return formatResponse(Status.OK, status);
-  }
-
-  private Response startService(String appName,
-      final UserGroupInformation ugi) throws IOException,
-      InterruptedException {
-    ApplicationId appId =
-        ugi.doAs(new PrivilegedExceptionAction<ApplicationId>() {
-          @Override public ApplicationId run()
-              throws YarnException, IOException {
-            ServiceClient sc = getServiceClient();
-            try {
-              sc.init(YARN_CONFIG);
-              sc.start();
-              ApplicationId appId = sc.actionStartAndGetId(appName);
-              return appId;
-            } finally {
-              sc.close();
-            }
-          }
-        });
-    LOG.info("Successfully started service " + appName);
-    ServiceStatus status = new ServiceStatus();
-    status.setDiagnostics(
-        "Service " + appName + " is successfully started with ApplicationId: "
-            + appId);
-    status.setState(ServiceState.ACCEPTED);
-    return formatResponse(Status.OK, status);
-  }
-
-  private Response upgradeService(Service service,
-      final UserGroupInformation ugi) throws IOException, InterruptedException {
-    ServiceStatus status = new ServiceStatus();
-    ugi.doAs((PrivilegedExceptionAction<Void>) () -> {
-      ServiceClient sc = getServiceClient();
-      try {
-        sc.init(YARN_CONFIG);
-        sc.start();
-        if (service.getState().equals(ServiceState.EXPRESS_UPGRADING)) {
-          sc.actionUpgradeExpress(service);
-        } else {
-          sc.initiateUpgrade(service);
-        }
-      } finally {
-        sc.close();
-      }
-      return null;
-    });
-    LOG.info("Service {} version {} upgrade initialized", service.getName(),
-        service.getVersion());
-    status.setDiagnostics("Service " + service.getName() +
-        " version " + service.getVersion() + " saved.");
-    status.setState(ServiceState.ACCEPTED);
-    return formatResponse(Status.ACCEPTED, status);
-  }
-
-  private Response cancelUpgradeService(String serviceName,
-      final UserGroupInformation ugi) throws IOException, InterruptedException {
-    int result = ugi.doAs((PrivilegedExceptionAction<Integer>) () -> {
-      ServiceClient sc = getServiceClient();
-      try {
-        sc.init(YARN_CONFIG);
-        sc.start();
-        int exitCode = sc.actionCancelUpgrade(serviceName);
-        return exitCode;
-      } finally {
-        sc.close();
-      }
-    });
-    if (result == EXIT_SUCCESS) {
-      ServiceStatus status = new ServiceStatus();
-      LOG.info("Service {} cancelling upgrade", serviceName);
-      status.setDiagnostics("Service " + serviceName +
-          " cancelling upgrade.");
-      status.setState(ServiceState.ACCEPTED);
-      return formatResponse(Status.ACCEPTED, status);
-    }
-    return Response.status(Status.BAD_REQUEST).build();
-  }
-
-  private Response processComponentsUpgrade(UserGroupInformation ugi,
-      String serviceName, Set<String> compNames) throws YarnException,
-      IOException, InterruptedException {
-    Service service = getServiceFromClient(ugi, serviceName);
-    if (!service.getState().equals(ServiceState.UPGRADING) &&
-        !service.getState().equals(ServiceState.UPGRADING_AUTO_FINALIZE)) {
-      throw new YarnException(
-          String.format("The upgrade of service %s has not been initiated.",
-              service.getName()));
-    }
-    List<Container> containersToUpgrade = ServiceApiUtil
-        .validateAndResolveCompsUpgrade(service, compNames);
-    Integer result = invokeContainersUpgrade(ugi, service, containersToUpgrade);
-    if (result == EXIT_SUCCESS) {
-      ServiceStatus status = new ServiceStatus();
-      status.setDiagnostics(
-          "Upgrading components " + Joiner.on(',').join(compNames) + ".");
-      return formatResponse(Response.Status.ACCEPTED, status);
-    }
-    // If result is not a success, consider it a no-op
-    return Response.status(Response.Status.NO_CONTENT).build();
-  }
-
-  private Response processContainersUpgrade(UserGroupInformation ugi,
-      Service service, List<Container> containers) throws YarnException,
-      IOException, InterruptedException {
-
-    if (!service.getState().equals(ServiceState.UPGRADING) &&
-        !service.getState().equals(ServiceState.UPGRADING_AUTO_FINALIZE)) {
-      throw new YarnException(
-          String.format("The upgrade of service %s has not been initiated.",
-              service.getName()));
-    }
-    ServiceApiUtil.validateInstancesUpgrade(containers);
-    Integer result = invokeContainersUpgrade(ugi, service, containers);
-    if (result == EXIT_SUCCESS) {
-      ServiceStatus status = new ServiceStatus();
-      status.setDiagnostics(
-          "Upgrading component instances " + containers.stream()
-              .map(Container::getId).collect(Collectors.joining(",")) + ".");
-      return formatResponse(Response.Status.ACCEPTED, status);
-    }
-    // If result is not a success, consider it a no-op
-    return Response.status(Response.Status.NO_CONTENT).build();
-  }
-
-  private int invokeContainersUpgrade(UserGroupInformation ugi,
-      Service service, List<Container> containers) throws IOException,
-      InterruptedException {
-    return ugi.doAs((PrivilegedExceptionAction<Integer>) () -> {
-      int result1;
-      ServiceClient sc = getServiceClient();
-      try {
-        sc.init(YARN_CONFIG);
-        sc.start();
-        result1 = sc.actionUpgrade(service, containers);
-      } finally {
-        sc.close();
-      }
-      return result1;
-    });
-  }
-
-  private Response decommissionInstances(Service service, UserGroupInformation
-      ugi) throws IOException, InterruptedException {
-    String appName = service.getName();
-    Response response = Response.status(Status.BAD_REQUEST).build();
-
-    List<String> instances = new ArrayList<>();
-    for (Component c : service.getComponents()) {
-      instances.addAll(c.getDecommissionedInstances());
-    }
-    Integer result = ugi.doAs(new PrivilegedExceptionAction<Integer>() {
-      @Override
-      public Integer run() throws YarnException, IOException {
-        int result = 0;
-        ServiceClient sc = new ServiceClient();
-        try {
-          sc.init(YARN_CONFIG);
-          sc.start();
-          result = sc
-              .actionDecommissionInstances(appName, instances);
-          return Integer.valueOf(result);
-        } finally {
-          sc.close();
-        }
-      }
-    });
-    if (result == EXIT_SUCCESS) {
-      String message = "Service " + appName + " has successfully " +
-          "decommissioned instances.";
-      LOG.info(message);
-      ServiceStatus status = new ServiceStatus();
-      status.setDiagnostics(message);
-      status.setState(ServiceState.ACCEPTED);
-      response = formatResponse(Status.ACCEPTED, status);
-    }
-    return response;
-  }
-
-  private Service getServiceFromClient(UserGroupInformation ugi,
-      String serviceName) throws IOException, InterruptedException {
-
-    return ugi.doAs((PrivilegedExceptionAction<Service>) () -> {
-      ServiceClient sc = getServiceClient();
-      try {
-        sc.init(YARN_CONFIG);
-        sc.start();
-        Service app1 = sc.getStatus(serviceName);
-        return app1;
-      } finally {
-        sc.close();
-      }
-    });
-  }
-
-  private ComponentContainers[] getContainers(UserGroupInformation ugi,
-      String serviceName, List<String> componentNames, String version,
-      List<ContainerState> containerStates) throws IOException,
-      InterruptedException {
-    return ugi.doAs((PrivilegedExceptionAction<ComponentContainers[]>) () -> {
-      ComponentContainers[] result;
-      ServiceClient sc = getServiceClient();
-      try {
-        sc.init(YARN_CONFIG);
-        sc.start();
-        result = sc.getContainers(serviceName, componentNames, version,
-            containerStates);
-        return result;
-      } finally {
-        sc.close();
-      }
-    });
-  }
-
-  /**
-   * Used by negative test case.
-   *
-   * @param mockServerClient - A mocked version of ServiceClient
-   */
-  public void setServiceClient(ServiceClient mockServerClient) {
-    serviceClientUnitTest = mockServerClient;
-    unitTest = true;
-  }
-
-  private ServiceClient getServiceClient() {
-    if (unitTest) {
-      return serviceClientUnitTest;
-    } else {
-      return new ServiceClient();
-    }
-  }
-
-  /**
-   * Configure impersonation callback.
-   *
-   * @param request - web request
-   * @return - configured UGI class for proxy callback
-   * @throws IOException - if user is not login.
-   */
-  private UserGroupInformation getProxyUser(HttpServletRequest request)
-      throws AccessControlException {
-    UserGroupInformation proxyUser;
-    UserGroupInformation ugi;
-    String remoteUser = request.getRemoteUser();
-    try {
-      if (UserGroupInformation.isSecurityEnabled()) {
-        proxyUser = UserGroupInformation.getLoginUser();
-        ugi = UserGroupInformation.createProxyUser(remoteUser, proxyUser);
-      } else {
-        ugi = UserGroupInformation.createRemoteUser(remoteUser);
-      }
-      return ugi;
-    } catch (IOException e) {
-      throw new AccessControlException(e.getCause());
-    }
-  }
-
-  /**
-   * Format HTTP response.
-   *
-   * @param status - HTTP Code
-   * @param message - Diagnostic message
-   * @return - HTTP response
-   */
-  private Response formatResponse(Status status, String message) {
-    ServiceStatus entity = new ServiceStatus();
-    entity.setDiagnostics(message);
-    return formatResponse(status, entity);
-  }
-
-  /**
-   * Format HTTP response.
-   *
-   * @param status - HTTP Code
-   * @param entity - ServiceStatus object
-   * @return - HTTP response
-   */
-  private Response formatResponse(Status status, ServiceStatus entity) {
-    return Response.status(status).entity(entity).build();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/webapp/ApiServerWebApp.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/webapp/ApiServerWebApp.java
deleted file mode 100644
index f4acd942cc9..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/webapp/ApiServerWebApp.java
+++ /dev/null
@@ -1,161 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.webapp;
-
-import org.apache.hadoop.http.HttpServer2;
-import org.apache.hadoop.net.NetUtils;
-import org.apache.hadoop.security.AuthenticationFilterInitializer;
-import org.apache.hadoop.security.SecurityUtil;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.service.AbstractService;
-import org.apache.hadoop.util.StringUtils;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.webapp.GenericExceptionHandler;
-import org.apache.hadoop.yarn.webapp.YarnJacksonJaxbJsonProvider;
-import org.eclipse.jetty.webapp.Configuration;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.net.InetSocketAddress;
-import java.net.URI;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.List;
-
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.RM_WEBAPP_SPNEGO_KEYTAB_FILE_KEY;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.RM_WEBAPP_SPNEGO_USER_NAME_KEY;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.*;
-
-/**
- * This class launches the web service using Hadoop HttpServer2 (which uses
- * an embedded Jetty container). This is the entry point to your service.
- * The Java command used to launch this app should call the main method.
- */
-public class ApiServerWebApp extends AbstractService {
-  private static final Logger logger = LoggerFactory
-      .getLogger(ApiServerWebApp.class);
-  private static final String SEP = ";";
-
-  // REST API server for YARN native services
-  private HttpServer2 apiServer;
-  private InetSocketAddress bindAddress;
-
-  public static void main(String[] args) throws IOException {
-    ApiServerWebApp apiWebApp = new ApiServerWebApp();
-    try {
-      apiWebApp.init(new YarnConfiguration());
-      apiWebApp.serviceStart();
-    } catch (Exception e) {
-      logger.error("Got exception starting", e);
-      apiWebApp.close();
-    }
-  }
-
-  public ApiServerWebApp() {
-    super(ApiServerWebApp.class.getName());
-  }
-
-  @Override
-  protected void serviceStart() throws Exception {
-    bindAddress = getConfig().getSocketAddr(API_SERVER_ADDRESS,
-        DEFAULT_API_SERVER_ADDRESS, DEFAULT_API_SERVER_PORT);
-    logger.info("YARN API server running on " + bindAddress);
-    if (UserGroupInformation.isSecurityEnabled()) {
-      doSecureLogin(getConfig());
-    }
-    startWebApp();
-    super.serviceStart();
-  }
-
-  @Override
-  protected void serviceStop() throws Exception {
-    if (apiServer != null) {
-      apiServer.stop();
-    }
-    super.serviceStop();
-  }
-
-  private void doSecureLogin(org.apache.hadoop.conf.Configuration conf)
-      throws IOException {
-    SecurityUtil.login(conf, YarnConfiguration.RM_KEYTAB,
-        YarnConfiguration.RM_PRINCIPAL, bindAddress.getHostName());
-    addFilters(conf);
-  }
-
-  private void addFilters(org.apache.hadoop.conf.Configuration conf) {
-    // Always load pseudo authentication filter to parse "user.name" in an URL
-    // to identify a HTTP request's user.
-    boolean hasHadoopAuthFilterInitializer = false;
-    String filterInitializerConfKey = "hadoop.http.filter.initializers";
-    Class<?>[] initializersClasses =
-        conf.getClasses(filterInitializerConfKey);
-    List<String> targets = new ArrayList<String>();
-    if (initializersClasses != null) {
-      for (Class<?> initializer : initializersClasses) {
-        if (initializer.getName().equals(
-            AuthenticationFilterInitializer.class.getName())) {
-          hasHadoopAuthFilterInitializer = true;
-          break;
-        }
-        targets.add(initializer.getName());
-      }
-    }
-    if (!hasHadoopAuthFilterInitializer) {
-      targets.add(AuthenticationFilterInitializer.class.getName());
-      conf.set(filterInitializerConfKey, StringUtils.join(",", targets));
-    }
-  }
-
-  private void startWebApp() throws IOException {
-    URI uri = URI.create("http://" + NetUtils.getHostPortString(bindAddress));
-
-    apiServer = new HttpServer2.Builder()
-        .setName("api-server")
-        .setConf(getConfig())
-        .setSecurityEnabled(UserGroupInformation.isSecurityEnabled())
-        .setUsernameConfKey(RM_WEBAPP_SPNEGO_USER_NAME_KEY)
-        .setKeytabConfKey(RM_WEBAPP_SPNEGO_KEYTAB_FILE_KEY)
-        .addEndpoint(uri).build();
-
-    String apiPackages =
-        ApiServer.class.getPackage().getName() + SEP
-            + GenericExceptionHandler.class.getPackage().getName() + SEP
-            + YarnJacksonJaxbJsonProvider.class.getPackage().getName();
-    apiServer.addJerseyResourcePackage(apiPackages, "/*");
-
-    try {
-      logger.info("Service starting up. Logging start...");
-      apiServer.start();
-      logger.info("Server status = {}", apiServer.toString());
-      for (Configuration conf : apiServer.getWebAppContext()
-          .getConfigurations()) {
-        logger.info("Configurations = {}", conf);
-      }
-      logger.info("Context Path = {}", Collections.singletonList(
-          apiServer.getWebAppContext().getContextPath()));
-      logger.info("ResourceBase = {}", Collections.singletonList(
-          apiServer.getWebAppContext().getResourceBase()));
-      logger.info("War = {}", Collections
-          .singletonList(apiServer.getWebAppContext().getWar()));
-    } catch (Exception ex) {
-      logger.error("Hadoop HttpServer2 App **failed**", ex);
-      throw ex;
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/webapp/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/webapp/package-info.java
deleted file mode 100644
index 1bdf05adb23..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/java/org/apache/hadoop/yarn/service/webapp/package-info.java
+++ /dev/null
@@ -1,28 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * Package org.apache.hadoop.yarn.service.webapp contains classes to be used
- * for YARN Services API.
- */
-@InterfaceAudience.Private
-@InterfaceStability.Unstable
-package org.apache.hadoop.yarn.service.webapp;
-
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/resources/definition/YARN-Services-Examples.md b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/resources/definition/YARN-Services-Examples.md
deleted file mode 100644
index b7ad6c9f789..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/resources/definition/YARN-Services-Examples.md
+++ /dev/null
@@ -1,444 +0,0 @@
-<!---
-  Licensed under the Apache License, Version 2.0 (the "License");
-  you may not use this file except in compliance with the License.
-  You may obtain a copy of the License at
-
-   http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License. See accompanying LICENSE file.
--->
-
-## Examples
-
-### Create a simple single-component service with most attribute values as defaults
-POST URL - http://localhost:8088/app/v1/services
-
-##### POST Request JSON
-```json
-{
-  "name": "hello-world",
-  "version": "1.0.0",
-  "description": "hello world example",
-  "components" :
-    [
-      {
-        "name": "hello",
-        "number_of_containers": 2,
-        "artifact": {
-          "id": "nginx:latest",
-          "type": "DOCKER"
-        },
-        "launch_command": "./start_nginx.sh",
-        "resource": {
-          "cpus": 1,
-          "memory": "256"
-        }
-      }
-    ]
-}
-```
-
-##### GET Response JSON
-GET URL - http://localhost:8088/app/v1/services/hello-world
-
-Note, lifetime value of -1 means unlimited lifetime.
-
-```json
-{
-    "name": "hello-world",
-    "version": "1.0.0",
-    "description": "hello world example",
-    "id": "application_1503963985568_0002",
-    "lifetime": -1,
-    "state": "STABLE",
-    "components": [
-        {
-            "name": "hello",
-            "state": "STABLE",
-            "resource": {
-                "cpus": 1,
-                "memory": "256"
-            },
-            "configuration": {
-                "properties": {},
-                "env": {},
-                "files": []
-            },
-            "quicklinks": [],
-            "containers": [
-                {
-                    "id": "container_e03_1503963985568_0002_01_000002",
-                    "ip": "10.22.8.143",
-                    "hostname": "ctr-e03-1503963985568-0002-01-000002.example.site",
-                    "state": "READY",
-                    "launch_time": 1504051512412,
-                    "bare_host": "host100.cloud.com",
-                    "component_instance_name": "hello-0"
-                },
-                {
-                    "id": "container_e03_1503963985568_0002_01_000003",
-                    "ip": "10.22.8.144",
-                    "hostname": "ctr-e03-1503963985568-0002-01-000003.example.site",
-                    "state": "READY",
-                    "launch_time": 1504051536450,
-                    "bare_host": "host100.cloud.com",
-                    "component_instance_name": "hello-1"
-                }
-            ],
-            "launch_command": "./start_nginx.sh",
-            "number_of_containers": 1,
-            "run_privileged_container": false
-        }
-    ],
-    "configuration": {
-        "properties": {},
-        "env": {},
-        "files": []
-    },
-    "quicklinks": {}
-}
-
-```
-### Update to modify the lifetime of a service
-PUT URL - http://localhost:8088/app/v1/services/hello-world
-
-##### PUT Request JSON
-
-Note, irrespective of what the current lifetime value is, this update request will set the lifetime of the service to be 3600 seconds (1 hour) from the time the request is submitted. Hence, if a a service has remaining lifetime of 5 mins (say) and would like to extend it to an hour OR if an application has remaining lifetime of 5 hours (say) and would like to reduce it down to an hour, then for both scenarios you need to submit the same request below.
-
-```json
-{
-  "lifetime": 3600
-}
-```
-### Stop a service
-PUT URL - http://localhost:8088/app/v1/services/hello-world
-
-##### PUT Request JSON
-```json
-{
-  "state": "STOPPED"
-}
-```
-
-### Start a service
-PUT URL - http://localhost:8088/app/v1/services/hello-world
-
-##### PUT Request JSON
-```json
-{
-  "state": "STARTED"
-}
-```
-
-### Update to flex up/down the number of containers (instances) of a component of a service
-PUT URL - http://localhost:8088/app/v1/services/hello-world/components/hello
-
-##### PUT Request JSON
-```json
-{
-  "number_of_containers": 3
-}
-```
-
-Alternatively, you can specify the entire "components" section instead.
-
-PUT URL - http://localhost:8088/app/v1/services/hello-world
-##### PUT Request JSON
-```json
-{
-  "state": "FLEX",
-  "components" :
-    [
-      {
-        "name": "hello",
-        "number_of_containers": 3
-      }
-    ]
-}
-```
-
-### Destroy a service
-DELETE URL - http://localhost:8088/app/v1/services/hello-world
-
-***
-
-### Create a complicated service  - HBase
-POST URL - http://localhost:8088:/app/v1/services/hbase-app-1
-
-##### POST Request JSON
-
-```json
-{
-  "name": "hbase-app-1",
-  "version": "1.0.0",
-  "description": "hbase service",
-  "lifetime": "3600",
-  "components": [
-    {
-      "name": "hbasemaster",
-      "number_of_containers": 1,
-      "artifact": {
-        "id": "hbase:latest",
-        "type": "DOCKER"
-      },
-      "launch_command": "/usr/hdp/current/hbase-master/bin/hbase master start",
-      "resource": {
-        "cpus": 1,
-        "memory": "2048"
-      },
-      "configuration": {
-        "env": {
-          "HBASE_LOG_DIR": "<LOG_DIR>"
-        },
-        "files": [
-          {
-            "type": "XML",
-            "dest_file": "/etc/hadoop/conf/core-site.xml",
-            "properties": {
-              "fs.defaultFS": "${CLUSTER_FS_URI}"
-            }
-          },
-          {
-            "type": "XML",
-            "dest_file": "/etc/hbase/conf/hbase-site.xml",
-            "properties": {
-              "hbase.cluster.distributed": "true",
-              "hbase.zookeeper.quorum": "${CLUSTER_ZK_QUORUM}",
-              "hbase.rootdir": "${SERVICE_HDFS_DIR}/hbase",
-              "zookeeper.znode.parent": "${SERVICE_ZK_PATH}",
-              "hbase.master.hostname": "hbasemaster.${SERVICE_NAME}.${USER}.${DOMAIN}",
-              "hbase.master.info.port": "16010"
-            }
-          }
-        ]
-      }
-    },
-    {
-      "name": "regionserver",
-      "number_of_containers": 3,
-      "artifact": {
-        "id": "hbase:latest",
-        "type": "DOCKER"
-      },
-      "launch_command": "/usr/hdp/current/hbase-regionserver/bin/hbase regionserver start",
-      "resource": {
-        "cpus": 1,
-        "memory": "2048"
-      },
-      "configuration": {
-        "env": {
-          "HBASE_LOG_DIR": "<LOG_DIR>"
-        },
-        "files": [
-          {
-            "type": "XML",
-            "dest_file": "/etc/hadoop/conf/core-site.xml",
-            "properties": {
-              "fs.defaultFS": "${CLUSTER_FS_URI}"
-            }
-          },
-          {
-            "type": "XML",
-            "dest_file": "/etc/hbase/conf/hbase-site.xml",
-            "properties": {
-              "hbase.cluster.distributed": "true",
-              "hbase.zookeeper.quorum": "${CLUSTER_ZK_QUORUM}",
-              "hbase.rootdir": "${SERVICE_HDFS_DIR}/hbase",
-              "zookeeper.znode.parent": "${SERVICE_ZK_PATH}",
-              "hbase.master.hostname": "hbasemaster.${SERVICE_NAME}.${USER}.${DOMAIN}",
-              "hbase.master.info.port": "16010",
-              "hbase.regionserver.hostname": "${COMPONENT_INSTANCE_NAME}.${SERVICE_NAME}.${USER}.${DOMAIN}"
-            }
-          }
-        ]
-      }
-    }
-  ],
-  "quicklinks": {
-    "HBase Master Status UI": "http://hbasemaster0.${SERVICE_NAME}.${USER}.${DOMAIN}:16010/master-status",
-    "Proxied HBase Master Status UI": "http://app-proxy/${DOMAIN}/${USER}/${SERVICE_NAME}/hbasemaster/16010/"
-  }
-}
-```
-
-### Create a service requesting GPUs in addition to CPUs and RAM
-POST URL - http://localhost:8088/app/v1/services
-
-##### POST Request JSON
-```json
-{
-  "name": "hello-world",
-  "version": "1.0.0",
-  "description": "hello world example with GPUs",
-  "components" :
-    [
-      {
-        "name": "hello",
-        "number_of_containers": 2,
-        "artifact": {
-          "id": "nginx:latest",
-          "type": "DOCKER"
-        },
-        "launch_command": "./start_nginx.sh",
-        "resource": {
-          "cpus": 1,
-          "memory": "256",
-          "additional" : {
-            "yarn.io/gpu" : {
-              "value" : 4,
-              "unit" : ""
-            }
-          }
-        }
-      }
-    ]
-}
-```
-
-### Create a service with a component requesting anti-affinity placement policy
-POST URL - http://localhost:8088/app/v1/services
-
-##### POST Request JSON
-```json
-{
-  "name": "hello-world",
-  "version": "1.0.0",
-  "description": "hello world example with anti-affinity",
-  "components" :
-    [
-      {
-        "name": "hello",
-        "number_of_containers": 3,
-        "artifact": {
-          "id": "nginx:latest",
-          "type": "DOCKER"
-        },
-        "launch_command": "./start_nginx.sh",
-        "resource": {
-          "cpus": 1,
-          "memory": "256"
-        },
-        "placement_policy": {
-          "constraints": [
-            {
-              "type": "ANTI_AFFINITY",
-              "scope": "NODE",
-              "node_attributes": {
-                "os": ["linux", "windows"],
-                "fault_domain": ["fd1", "fd2"]
-              },
-              "node_partitions": [
-                "gpu",
-                "fast-disk"
-              ],
-              "target_tags": [
-                "hello"
-              ]
-            }
-          ]
-        }
-      }
-    ]
-}
-```
-
-##### GET Response JSON
-GET URL - http://localhost:8088/app/v1/services/hello-world
-
-Note, for an anti-affinity component no more than 1 container will be allocated
-in a specific node. In this example, 3 containers have been requested by
-component "hello". All 3 containers were allocated because the cluster had 3 or
-more NMs. If the cluster had less than 3 NMs then less than 3 containers would
-be allocated. In cases when the number of allocated containers are less than the
-number of requested containers, the component and the service will be in
-non-STABLE state.
-
-```json
-{
-    "name": "hello-world",
-    "version": "1.0.0",
-    "description": "hello world example with anti-affinity",
-    "id": "application_1503963985568_0003",
-    "lifetime": -1,
-    "state": "STABLE",
-    "components": [
-        {
-            "name": "hello",
-            "state": "STABLE",
-            "resource": {
-                "cpus": 1,
-                "memory": "256"
-            },
-            "placement_policy": {
-              "constraints": [
-                {
-                  "type": "ANTI_AFFINITY",
-                  "scope": "NODE",
-                  "node_attributes": {
-                    "os": ["linux", "windows"],
-                    "fault_domain": ["fd1", "fd2"]
-                  },
-                  "node_partitions": [
-                    "gpu",
-                    "fast-disk"
-                  ],
-                  "target_tags": [
-                    "hello"
-                  ]
-                }
-              ]
-            },
-            "configuration": {
-                "properties": {},
-                "env": {},
-                "files": []
-            },
-            "quicklinks": [],
-            "containers": [
-                {
-                    "id": "container_e03_1503963985568_0003_01_000002",
-                    "ip": "10.22.8.143",
-                    "hostname": "ctr-e03-1503963985568-0003-01-000002.example.site",
-                    "state": "READY",
-                    "launch_time": 1504051512412,
-                    "bare_host": "host100.cloud.com",
-                    "component_instance_name": "hello-0"
-                },
-                {
-                    "id": "container_e03_1503963985568_0003_01_000003",
-                    "ip": "10.22.8.144",
-                    "hostname": "ctr-e03-1503963985568-0003-01-000003.example.site",
-                    "state": "READY",
-                    "launch_time": 1504051536450,
-                    "bare_host": "host101.cloud.com",
-                    "component_instance_name": "hello-1"
-                },
-                {
-                    "id": "container_e03_1503963985568_0003_01_000004",
-                    "ip": "10.22.8.145",
-                    "hostname": "ctr-e03-1503963985568-0003-01-000004.example.site",
-                    "state": "READY",
-                    "launch_time": 1504051536450,
-                    "bare_host": "host102.cloud.com",
-                    "component_instance_name": "hello-2"
-                }
-            ],
-            "launch_command": "./start_nginx.sh",
-            "number_of_containers": 1,
-            "run_privileged_container": false
-        }
-    ],
-    "configuration": {
-        "properties": {},
-        "env": {},
-        "files": []
-    },
-    "quicklinks": {}
-}
-```
-
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/resources/definition/YARN-Simplified-V1-API-Layer-For-Services.yaml b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/resources/definition/YARN-Simplified-V1-API-Layer-For-Services.yaml
deleted file mode 100644
index 7b198a008d4..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/resources/definition/YARN-Simplified-V1-API-Layer-For-Services.yaml
+++ /dev/null
@@ -1,740 +0,0 @@
-# Hadoop YARN REST APIs for services v1 spec in YAML
-
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-swagger: '2.0'
-info:
-  title: "YARN Simplified API layer for services"
-  description: |
-    Bringing a new service on YARN today is not a simple experience. The APIs of existing
-    frameworks are either too low level (native YARN), require writing new code (for frameworks with programmatic APIs)
-    or writing a complex spec (for declarative frameworks).
-
-    This simplified REST API can be used to create and manage the lifecycle of YARN services.
-    In most cases, the application owner will not be forced to make any changes to their applications.
-    This is primarily true if the application is packaged with containerization technologies like Docker.
-
-    This document describes the API specifications (aka. YarnFile) for deploying/managing
-    containerized services on YARN. The same JSON spec can be used for both REST API
-    and CLI to manage the services.
-
-  version: "1.0.0"
-  license:
-    name: Apache 2.0
-    url: http://www.apache.org/licenses/LICENSE-2.0.html
-# the domain of the service
-host: localhost
-port: 8088(default)
-# array of all schemes that your API supports
-schemes:
-  - http
-consumes:
-  - application/json
-produces:
-  - application/json
-paths:
-  /app/v1/services/version:
-    get:
-      summary: Get current version of the API server.
-      description: Get current version of the API server.
-      responses:
-        200:
-          description: Successful request
-
-  /app/v1/services:
-    get:
-      summary: (TBD) List of services running in the cluster.
-      description: Get a list of all currently running services (response includes a minimal projection of the service info). For more details do a GET on a specific service name.
-      responses:
-        200:
-          description: An array of services
-          schema:
-            type: array
-            items:
-              $ref: '#/definitions/Service'
-        default:
-          description: Unexpected error
-          schema:
-            $ref: '#/definitions/ServiceStatus'
-    post:
-      summary: Create a service
-      description: Create a service. The request JSON is a service object with details required for creation. If the request is successful it returns 202 Accepted. A success of this API only confirms success in submission of the service creation request. There is no guarantee that the service will actually reach a RUNNING state. Resource availability and several other factors determines if the service will be deployed in the cluster. It is expected that clients would subsequently call the GET API to get details of the service and determine its state.
-      parameters:
-        - name: Service
-          in: body
-          description: Service request object
-          required: true
-          schema:
-            $ref: '#/definitions/Service'
-      responses:
-        202:
-          description: The request to create a service is accepted
-        400:
-          description: Invalid service definition provided in the request body
-        500:
-          description: Failed to create a service
-        default:
-          description: Unexpected error
-          schema:
-            $ref: '#/definitions/ServiceStatus'
-
-  /app/v1/services/{service_name}:
-    put:
-      summary: Update a service or upgrade the binary version of the components of a running service
-      description: Update the runtime properties of a service. Currently the following operations are supported - update lifetime, stop/start a service.
-                   The PUT operation is also used to orchestrate an upgrade of the service containers to a newer version of their artifacts (TBD).
-      parameters:
-        - name: service_name
-          in: path
-          description: Service name
-          required: true
-          type: string
-        - name: Service
-          in: body
-          description: The updated service definition. It can contain the updated lifetime of a service or the desired state (STOPPED/STARTED) of a service to initiate a start/stop operation against the specified service
-          required: true
-          schema:
-            $ref: '#/definitions/Service'
-      responses:
-        204:
-          description: Update or upgrade was successful
-        404:
-          description: Service does not exist
-        default:
-          description: Unexpected error
-          schema:
-            $ref: '#/definitions/ServiceStatus'
-    delete:
-      summary: Destroy a service
-      description: Destroy a service and release all resources. This API might have to return JSON data providing location of logs (TBD), etc.
-      parameters:
-        - name: service_name
-          in: path
-          description: Service name
-          required: true
-          type: string
-      responses:
-        204:
-          description: Destroy was successful
-        404:
-          description: Service does not exist
-        default:
-          description: Unexpected error
-          schema:
-            $ref: '#/definitions/ServiceStatus'
-    get:
-      summary: Get details of a service.
-      description: Return the details (including containers) of a running service
-      parameters:
-        - name: service_name
-          in: path
-          description: Service name
-          required: true
-          type: string
-      responses:
-        200:
-          description: a service object
-          schema:
-            type: object
-            items:
-              $ref: '#/definitions/Service'
-          examples:
-            service_name: logsearch
-            artifact:
-              id: logsearch:latest
-              type: docker
-        404:
-          description: Service does not exist
-        default:
-          description: Unexpected error
-          schema:
-            $ref: '#/definitions/ServiceStatus'
-  /app/v1/services/{service_name}/components:
-    put:
-      summary: Upgrade multiple components.
-      description: Set a component's desired number of instanes
-      parameters:
-        - name: service_name
-          in: path
-          description: Service name
-          required: true
-          type: string
-        - name: components
-          in: body
-          description: Components to be upgraded with state set to UPGRADING
-          required: true
-          schema:
-            type: array
-            items:
-              $ref: '#/definitions/Component'
-      responses:
-        200:
-          description: Upgrading components.
-        404:
-          description: Service does not exist
-        default:
-          description: Unexpected error
-  /app/v1/services/{service_name}/components/{component_name}:
-    put:
-      summary: Flex a component's number of instances or upgrade all the instances of the component.
-      description: Set a component's desired number of instanes or upgrade the component.
-      parameters:
-        - name: service_name
-          in: path
-          description: Service name
-          required: true
-          type: string
-        - name: component_name
-          in: path
-          description: Component name
-          required: true
-          type: string
-        - name: Component
-          in: body
-          description: For flex, the definition of a component which contains the updated number of instances with state set to FLEXING. For upgrade, component definition with state set to UPGRADING.
-          required: true
-          schema:
-            $ref: '#/definitions/Component'
-      responses:
-        200:
-          description: Flex was successful
-        404:
-          description: Service does not exist
-        default:
-          description: Unexpected error
-          schema:
-            $ref: '#/definitions/ServiceStatus'
-  /app/v1/services/{service_name}/component-instances:
-    get:
-      summary: Get component instances.
-      description: Get component instances which match the query params.
-      parameters:
-        - name: service_name
-          in: path
-          description: Service name
-          required: true
-          type: string
-        - name: componentName
-          in: query
-          description: Component name. Multiple values are allowed.
-          type: string
-        - name: version
-          in: query
-          description: Version of the service.
-          type: string
-        - name: containerState
-          in: query
-          description: Container state. Multiple values are allowed.
-          type: string
-      responses:
-        200:
-          description: Component instances.
-          schema:
-            type: array
-            items:
-              $ref: '#/definitions/ComponentContainers'
-        404:
-          description: Service does not exist
-        default:
-          description: Unexpected error
-    put:
-      summary: Upgrade multiple component instances.
-      description: Upgrades multiple component instances
-      parameters:
-        - name: service_name
-          in: path
-          description: Service name
-          required: true
-          type: string
-        - name: component instances
-          in: body
-          description: Component instances with state set to UPGRADING
-          required: true
-          schema:
-            type: array
-            items:
-              $ref: '#/definitions/Container'
-      responses:
-        200:
-          description: Upgrading component instance
-        404:
-          description: Service does not exist
-        default:
-          description: Unexpected error
-  /app/v1/services/{service_name}/components/{component_name}/component-instances/{component_instance_name}:
-    put:
-      summary: Upgrade a single component instance.
-      description: Upgrades a single component instance
-      parameters:
-        - name: service_name
-          in: path
-          description: Service name
-          required: true
-          type: string
-        - name: component_name
-          in: path
-          description: Component name
-          required: true
-          type: string
-        - name: component_instance_name
-          in: path
-          description: Component instance name
-          required: true
-          type: string
-        - name: component instance
-          in: body
-          description: Component instance with state UPGRADING
-          required: true
-          schema:
-            $ref: '#/definitions/Container'
-      responses:
-        200:
-          description: Upgrading component instance
-        404:
-          description: Service does not exist
-        default:
-          description: Unexpected error
-definitions:
-  Service:
-    description: a service resource has the following attributes.
-    required:
-      - name
-      - version
-    properties:
-      name:
-        type: string
-        description: A unique service name. If Registry DNS is enabled, the max length is 63 characters.
-      version:
-        type: string
-        description: Version of the service.
-      description:
-        type: string
-        description: Description of the service.
-      id:
-        type: string
-        description: A unique service id.
-      artifact:
-        description: The default artifact for all components of the service except the components which has Artifact type set to SERVICE (optional).
-        $ref: '#/definitions/Artifact'
-      resource:
-        description: The default resource for all components of the service (optional).
-        $ref: '#/definitions/Resource'
-      launch_time:
-        type: string
-        format: date
-        description: The time when the service was created, e.g. 2016-03-16T01:01:49.000Z.
-      number_of_running_containers:
-        type: integer
-        format: int64
-        description: In get response this provides the total number of running containers for this service (across all components) at the time of request. Note, a subsequent request can return a different number as and when more containers get allocated until it reaches the total number of containers or if a flex request has been made between the two requests.
-      lifetime:
-        type: integer
-        format: int64
-        description: Life time (in seconds) of the service from the time it reaches the STARTED state (after which it is automatically destroyed by YARN). For unlimited lifetime do not set a lifetime value.
-      components:
-        description: Components of a service.
-        type: array
-        items:
-          $ref: '#/definitions/Component'
-      configuration:
-        description: Config properties of a service. Configurations provided at the service/global level are available to all the components. Specific properties can be overridden at the component level.
-        $ref: '#/definitions/Configuration'
-      state:
-        description: State of the service. Specifying a value for this attribute for the PUT payload means update the service to this desired state.
-        $ref: '#/definitions/ServiceState'
-      quicklinks:
-        type: object
-        description: A blob of key-value pairs of quicklinks to be exported for a service.
-        additionalProperties:
-          type: string
-      queue:
-        type: string
-        description: The YARN queue that this service should be submitted to.
-      kerberos_principal:
-        description: The principal info of the user who launches the service.
-        $ref: '#/definitions/KerberosPrincipal'
-      docker_client_config:
-        type: string
-        description: URI of the file containing the docker client configuration (e.g. hdfs:///tmp/config.json).
-      dependencies:
-        type: array
-        items:
-          type: string
-        description: An array of services which should be in STABLE state, before this service can be started.
-  ResourceInformation:
-    description:
-      ResourceInformation determines unit/value of resource types in addition to memory and vcores. It will be part of Resource object.
-    properties:
-      value:
-        type: integer
-        format: int64
-        description: Integer value of the resource.
-      unit:
-        type: string
-        description: Unit of the resource, acceptable values are - p/n/u/m/k/M/G/T/P/Ki/Mi/Gi/Ti/Pi. By default it is empty means no unit.
-  Resource:
-    description:
-      Resource determines the amount of resources (vcores, memory, network, etc.) usable by a container. This field determines the resource to be applied for all the containers of a component or service. The resource specified at the service (or global) level can be overriden at the component level. Only one of profile OR cpu & memory are expected. It raises a validation exception otherwise.
-    properties:
-      profile:
-        type: string
-        description: Each resource profile has a unique id which is associated with a cluster-level predefined memory, cpus, etc.
-      cpus:
-        type: integer
-        format: int32
-        description: Amount of vcores allocated to each container (optional but overrides cpus in profile if specified).
-      memory:
-        type: string
-        description: Amount of memory allocated to each container (optional but overrides memory in profile if specified). Currently accepts only an integer value and default unit is in MB.
-      additional:
-        type: object
-        additionalProperties:
-          $ref: '#/definitions/ResourceInformation'
-        description: A map of resource type name to resource type information. Including value (integer), and unit (string). This will be used to specify resource other than cpu and memory. Please refer to example below.
-  PlacementPolicy:
-    description: Advanced placement policy of the components of a service.
-    required:
-      - constraints
-    properties:
-      constraints:
-        description: Placement constraint details.
-        type: array
-        items:
-          $ref: '#/definitions/PlacementConstraint'
-  PlacementConstraint:
-    description: Placement constraint details.
-    required:
-      - type
-      - scope
-    properties:
-      name:
-        description: An optional name associated to this constraint.
-        type: string
-        example: C1
-      type:
-        description: The type of placement.
-        $ref: '#/definitions/PlacementType'
-      scope:
-        description: The scope of placement.
-        $ref: '#/definitions/PlacementScope'
-      target_tags:
-        description: The name of the components that this component's placement policy is depending upon are added as target tags. So for affinity say, this component's containers are requesting to be placed on hosts where containers of the target tag component(s) are running on. Target tags can also contain the name of this component, in which case it implies that for anti-affinity say, no more than one container of this component can be placed on a host. Similarly, for cardinality, it would mean that containers of this component is requesting to be placed on hosts where at least minCardinality but no more than maxCardinality containers of the target tag component(s) are running.
-        type: array
-        items:
-          type: string
-      node_attributes:
-        description: Node attributes are a set of key:value(s) pairs associated with nodes.
-        type: object
-        additionalProperties:
-          type: array
-          items:
-            type: string
-      node_partitions:
-        description: Node partitions where the containers of this component can run.
-        type: array
-        items:
-          type: string
-      min_cardinality:
-        type: integer
-        format: int64
-        description: When placement type is cardinality, the minimum number of containers of the depending component that a host should have, where containers of this component can be allocated on.
-        example: 2
-      max_cardinality:
-        type: integer
-        format: int64
-        description: When placement type is cardinality, the maximum number of containers of the depending component that a host should have, where containers of this component can be allocated on.
-        example: 3
-  PlacementType:
-    description: The type of placement - affinity/anti-affinity/affinity-with-cardinality with containers of another component or containers of the same component (self).
-    properties:
-      type:
-        type: string
-        enum:
-          - AFFINITY
-          - ANTI_AFFINITY
-          - AFFINITY_WITH_CARDINALITY
-  PlacementScope:
-    description: The scope of placement for the containers of a component.
-    properties:
-      type:
-        type: string
-        enum:
-          - NODE
-          - RACK
-  Artifact:
-    description: Artifact of a service component. If not specified, component will just run the bare launch command and no artifact will be localized.
-    required:
-    - id
-    properties:
-      id:
-        type: string
-        description: Artifact id. Examples are package location uri for tarball based services, image name for docker, name of service, etc.
-      type:
-        type: string
-        description: Artifact type, like docker, tarball, etc. (optional). For TARBALL type, the specified tarball will be localized to the container local working directory under a folder named lib. For SERVICE type, the service specified will be read and its components will be added into this service. The original component with artifact type SERVICE will be removed (any properties specified in the original component will be ignored).
-        enum:
-          - DOCKER
-          - TARBALL
-          - SERVICE
-        default: DOCKER
-      uri:
-        type: string
-        description: Artifact location to support multiple artifact stores (optional).
-  Component:
-    description: One or more components of the service. If the service is HBase say, then the component can be a simple role like master or regionserver. If the service is a complex business webapp then a component can be other services say Kafka or Storm. Thereby it opens up the support for complex and nested services.
-    required:
-    - name
-    properties:
-      name:
-        type: string
-        description: Name of the service component (mandatory). If Registry DNS is enabled, the max length is 63 characters. If unique component support is enabled, the max length is lowered to 44 characters.
-      state:
-        description: The state of the component
-        $ref: "#/definitions/ComponentState"
-      dependencies:
-        type: array
-        items:
-          type: string
-        description: An array of service components which should be in READY state (as defined by readiness check), before this component can be started. The dependencies across all components of a service should be represented as a DAG.
-      readiness_check:
-        description: Readiness check for this component.
-        $ref: '#/definitions/ReadinessCheck'
-      artifact:
-        description: Artifact of the component (optional). If not specified, the service level global artifact takes effect.
-        $ref: '#/definitions/Artifact'
-      launch_command:
-        type: string
-        description: The custom launch command of this component (optional for DOCKER component, required otherwise). When specified at the component level, it overrides the value specified at the global level (if any).
-      resource:
-        description: Resource of this component (optional). If not specified, the service level global resource takes effect.
-        $ref: '#/definitions/Resource'
-      number_of_containers:
-        type: integer
-        format: int64
-        description: Number of containers for this component (optional). If not specified, the service level global number_of_containers takes effect.
-      decommissioned_instances:
-        type: array
-        items:
-          type: string
-        description: List of decommissioned component instances.
-      containers:
-        type: array
-        description: Containers of a started component. Specifying a value for this attribute for the POST payload raises a validation error. This blob is available only in the GET response of a started service.
-        items:
-          $ref: '#/definitions/Container'
-      run_privileged_container:
-        type: boolean
-        description: Run all containers of this component in privileged mode (YARN-4262).
-      placement_policy:
-        description: Advanced scheduling and placement policies for all containers of this component.
-        $ref: '#/definitions/PlacementPolicy'
-      configuration:
-        description: Config properties for this component.
-        $ref: '#/definitions/Configuration'
-      quicklinks:
-        type: array
-        items:
-          type: string
-        description: A list of quicklink keys defined at the service level, and to be resolved by this component.
-      restartPolicy:
-        type: string
-        description: Policy of restart component. Including ALWAYS (Always restart component even if instance exit code = 0); ON_FAILURE (Only restart component if instance exit code != 0); NEVER (Do not restart in any cases)
-        enum:
-          - ALWAYS
-          - ON_FAILURE
-          - NEVER
-        default: ALWAYS
-  ReadinessCheck:
-    description: A check to be performed to determine the readiness of a component instance (a container). If no readiness check is specified, the default readiness check will be used unless the yarn.service.default-readiness-check.enabled configuration property is set to false at the component, service, or system level. The artifact field is currently unsupported but may be implemented in the future, enabling a pluggable helper container to support advanced use cases.
-    required:
-    - type
-    properties:
-      type:
-        type: string
-        description: DEFAULT (AM checks whether the container has an IP and optionally performs a DNS lookup for the container hostname), HTTP (AM performs default checks, plus sends a REST call to the container and expects a response code between 200 and 299), or PORT (AM performs default checks, plus attempts to open a socket connection to the container on a specified port).
-        enum:
-          - DEFAULT
-          - HTTP
-          - PORT
-      properties:
-        type: object
-        description: A blob of key value pairs that will be used to configure the check.
-        additionalProperties:
-          type: string
-      artifact:
-        description: Artifact of the pluggable readiness check helper container (optional). If specified, this helper container typically hosts the http uri and encapsulates the complex scripts required to perform actual container readiness check. At the end it is expected to respond a 204 No content just like the simplified use case. This pluggable framework benefits service owners who can run services without any packaging modifications. Note, artifacts of type docker only is supported for now. NOT IMPLEMENTED YET
-        $ref: '#/definitions/Artifact'
-  Configuration:
-    description: Set of configuration properties that can be injected into the service components via envs, files and custom pluggable helper docker containers. Files of several standard formats like xml, properties, json, yaml and templates will be supported.
-    properties:
-      properties:
-        type: object
-        description: A blob of key-value pairs for configuring the YARN service AM.
-        additionalProperties:
-          type: string
-      env:
-        type: object
-        description: A blob of key-value pairs which will be appended to the default system properties and handed off to the service at start time. All placeholder references to properties will be substituted before injection.
-        additionalProperties:
-          type: string
-      files:
-        description: Array of list of files that needs to be created and made available as volumes in the service component containers.
-        type: array
-        items:
-          $ref: '#/definitions/ConfigFile'
-  ConfigFile:
-    description: A config file that needs to be created and made available as a volume in a service component container.
-    properties:
-      type:
-        type: string
-        description: Config file in the standard format like xml, properties, json, yaml, template.
-        enum:
-          - XML
-          - PROPERTIES
-          - JSON
-          - YAML
-          - TEMPLATE
-          - HADOOP_XML
-          - STATIC
-          - ARCHIVE
-      dest_file:
-        type: string
-        description: The path that this configuration file should be created as. If it is an absolute path, it will be mounted into the DOCKER container. Absolute paths are only allowed for DOCKER containers.  If it is a relative path, only the file name should be provided, and the file will be created in the container local working directory under a folder named conf.
-      src_file:
-        type: string
-        description: This provides the source location of the configuration file, the content of which is dumped to dest_file post property substitutions, in the format as specified in type. Typically the src_file would point to a source controlled network accessible file maintained by tools like puppet, chef, or hdfs etc. Currently, only hdfs is supported.
-      properties:
-        type: object
-        description: A blob of key value pairs that will be dumped in the dest_file in the format as specified in type. If src_file is specified, src_file content are dumped in the dest_file and these properties will overwrite, if any, existing properties in src_file or be added as new properties in src_file.
-        additionalProperties:
-          type: string
-  Container:
-    description: An instance of a running service container.
-    properties:
-      id:
-        type: string
-        description: Unique container id of a running service, e.g. container_e3751_1458061340047_0008_01_000002.
-      launch_time:
-        type: string
-        format: date
-        description: The time when the container was created, e.g. 2016-03-16T01:01:49.000Z. This will most likely be different from cluster launch time.
-      ip:
-        type: string
-        description: IP address of a running container, e.g. 172.31.42.141. The IP address and hostname attribute values are dependent on the cluster/docker network setup as per YARN-4007.
-      hostname:
-        type: string
-        description: Fully qualified hostname of a running container, e.g. ctr-e3751-1458061340047-0008-01-000002.examplestg.site. The IP address and hostname attribute values are dependent on the cluster/docker network setup as per YARN-4007.
-      bare_host:
-        type: string
-        description: The bare node or host in which the container is running, e.g. cn008.example.com.
-      state:
-        description: State of the container of a service.
-        $ref: '#/definitions/ContainerState'
-      component_instance_name:
-        type: string
-        description: Name of the component instance that this container instance belongs to. Component instance name is named as $COMPONENT_NAME-i, where i is a
-                     monotonically increasing integer. E.g. A componet called nginx can have multiple component instances named as nginx-0, nginx-1 etc.
-                     Each component instance is backed by a container instance.
-      resource:
-        description: Resource used for this container.
-        $ref: '#/definitions/Resource'
-      artifact:
-        description: Artifact used for this container.
-        $ref: '#/definitions/Artifact'
-      privileged_container:
-        type: boolean
-        description: Container running in privileged mode or not.
-  ServiceState:
-    description: The current state of a service.
-    properties:
-      state:
-        type: string
-        description: enum of the state of the service
-        enum:
-          - ACCEPTED
-          - STARTED
-          - STABLE
-          - STOPPED
-          - FAILED
-          - FLEX
-          - UPGRADING
-          - UPGRADING_AUTO_FINALIZE
-          - EXPRESS_UPGRADING
-          - SUCCEEDED
-          - CANCEL_UPGRADING
-  ContainerState:
-    description: The current state of the container of a service.
-    properties:
-      state:
-        type: string
-        description: enum of the state of the container
-        enum:
-          - RUNNING_BUT_UNREADY
-          - READY
-          - STOPPED
-          - NEEDS_UPGRADE
-          - UPGRADING
-          - SUCCEEDED
-          - FAILED
-          - FAILED_UPGRADE
-  ComponentState:
-    description: The state of the component
-    properties:
-      state:
-        type: string
-        description: enum of the state of the component
-        enum:
-          - FLEXING
-          - STABLE
-          - NEEDS_UPGRADE
-          - UPGRADING
-          - SUCCEEDED
-          - FAILED
-  ServiceStatus:
-    description: The current status of a submitted service, returned as a response to the GET API.
-    properties:
-      diagnostics:
-        type: string
-        description: Diagnostic information (if any) for the reason of the current state of the service. It typically has a non-null value, if the service is in a non-running state.
-      state:
-        description: Service state.
-        $ref: '#/definitions/ServiceState'
-      code:
-        type: integer
-        format: int32
-        description: An error code specific to a scenario which service owners should be able to use to understand the failure in addition to the diagnostic information.
-  KerberosPrincipal:
-    description: The kerberos principal info of the user who launches the service.
-    properties:
-      principal_name:
-        type: string
-        description: The principal name of the user who launches the service. Note that `_HOST` is required in the `principal_name` field such as `testuser/_HOST@EXAMPLE.COM` because Hadoop client validates that the server's (in this case, the AM's) principal has hostname present when communicating to the server.
-      keytab:
-        type: string
-        description: The URI of the kerberos keytab. Currently supports only files present on the bare host. URI starts with "file\://" - A path on the local host where the keytab is stored. It is assumed that admin pre-installs the keytabs on the local host before AM launches.
-  ComponentContainers:
-    description: Containers of a component.
-    required:
-    - component_name
-    properties:
-      component_name:
-        type: string
-        description: Name of the component.
-      containers:
-        type: array
-        description: Containers of the component.
-        items:
-          $ref: '#/definitions/Container'
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/resources/log4j-server.properties b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/resources/log4j-server.properties
deleted file mode 100644
index 8c679b9fc20..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/resources/log4j-server.properties
+++ /dev/null
@@ -1,76 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one
-#  or more contributor license agreements.  See the NOTICE file
-#  distributed with this work for additional information
-#  regarding copyright ownership.  The ASF licenses this file
-#  to you under the Apache License, Version 2.0 (the
-#  "License"); you may not use this file except in compliance
-#  with the License.  You may obtain a copy of the License at
-#
-#       http://www.apache.org/licenses/LICENSE-2.0
-#
-#  Unless required by applicable law or agreed to in writing, software
-#  distributed under the License is distributed on an "AS IS" BASIS,
-#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-#  See the License for the specific language governing permissions and
-#  limitations under the License.
-#
-
-# This is the log4j configuration for YARN Services REST API Server
-
-# Log rotation based on size (100KB) with a max of 10 backup files
-log4j.rootLogger=INFO, restservicelog
-log4j.threshhold=ALL
-
-log4j.appender.stdout=org.apache.log4j.ConsoleAppender
-log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
-log4j.appender.stdout.layout.ConversionPattern=%d{ISO8601} %-5p [%t] %c{2} (%F:%M(%L)) - %m%n
-
-log4j.appender.restservicelog=org.apache.log4j.RollingFileAppender
-log4j.appender.restservicelog.layout=org.apache.log4j.PatternLayout
-log4j.appender.restservicelog.File=${REST_SERVICE_LOG_DIR}/restservice.log
-log4j.appender.restservicelog.MaxFileSize=1GB
-log4j.appender.restservicelog.MaxBackupIndex=10
-
-# log layout skips stack-trace creation operations by avoiding line numbers and method
-log4j.appender.restservicelog.layout.ConversionPattern=%d{ISO8601} [%t] %-5p %c{2} - %m%n
-
-# debug edition is much more expensive
-#log4j.appender.restservicelog.layout.ConversionPattern=%d{ISO8601} [%t] %-5p %c{2} (%F:%M(%L)) - %m%n
-
-# configure stderr
-# set the conversion pattern of stderr
-# Print the date in ISO 8601 format
-log4j.appender.stderr=org.apache.log4j.ConsoleAppender
-log4j.appender.stderr.Target=System.err
-log4j.appender.stderr.layout=org.apache.log4j.PatternLayout
-log4j.appender.stderr.layout.ConversionPattern=%d{ISO8601} [%t] %-5p %c{2} - %m%n
-
-log4j.appender.subprocess=org.apache.log4j.ConsoleAppender
-log4j.appender.subprocess.layout=org.apache.log4j.PatternLayout
-log4j.appender.subprocess.layout.ConversionPattern=[%c{1}]: %m%n
-
-# for debugging REST API Service
-#log4j.logger.org.apache.hadoop.yarn.services=DEBUG
-
-# uncomment to debug service lifecycle issues
-#log4j.logger.org.apache.hadoop.yarn.service.launcher=DEBUG
-#log4j.logger.org.apache.hadoop.yarn.service=DEBUG
-
-# uncomment for YARN operations
-#log4j.logger.org.apache.hadoop.yarn.client=DEBUG
-
-# uncomment this to debug security problems
-#log4j.logger.org.apache.hadoop.security=DEBUG
-
-#crank back on some noise
-log4j.logger.org.apache.hadoop.util.NativeCodeLoader=ERROR
-log4j.logger.org.apache.hadoop.hdfs=WARN
-log4j.logger.org.apache.hadoop.hdfs.shortcircuit=ERROR
-
-log4j.logger.org.apache.hadoop.yarn.server.nodemanager.containermanager.monitor=WARN
-log4j.logger.org.apache.hadoop.yarn.server.nodemanager.NodeStatusUpdaterImpl=WARN
-log4j.logger.org.apache.zookeeper=WARN
-log4j.logger.org.apache.curator.framework.state=ERROR
-log4j.logger.org.apache.curator.framework.imps=WARN
-
-log4j.logger.org.mortbay.log=DEBUG
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/resources/webapps/api-server/app b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/resources/webapps/api-server/app
deleted file mode 100644
index 6a077b10c2a..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/resources/webapps/api-server/app
+++ /dev/null
@@ -1,16 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-DON'T DELETE. REST WEBAPP RUN SCRIPT WILL STOP WORKING.
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/webapp/WEB-INF/web.xml b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/webapp/WEB-INF/web.xml
deleted file mode 100644
index 1282c9f8635..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/main/webapp/WEB-INF/web.xml
+++ /dev/null
@@ -1,36 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<!--
-  Licensed under the Apache License, Version 2.0 (the "License");
-  you may not use this file except in compliance with the License.
-  You may obtain a copy of the License at
-
-  http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License.
--->
-<web-app xmlns="http://java.sun.com/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
-        xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd"
-        version="3.0">
-
-    <servlet>
-        <servlet-name>Jersey REST API</servlet-name>
-        <servlet-class>com.sun.jersey.spi.container.servlet.ServletContainer</servlet-class>
-        <init-param>
-            <param-name>com.sun.jersey.config.property.packages</param-name>
-            <param-value>org.apache.hadoop.yarn.service.webapp,org.apache.hadoop.yarn.service.api,org.apache.hadoop.yarn.service.api.records</param-value>
-        </init-param>
-        <init-param>
-          <param-name>com.sun.jersey.api.json.POJOMappingFeature</param-name>
-          <param-value>true</param-value>
-        </init-param>
-        <load-on-startup>1</load-on-startup>
-    </servlet>
-    <servlet-mapping>
-        <servlet-name>Jersey REST API</servlet-name>
-        <url-pattern>/*</url-pattern>
-    </servlet-mapping>
-</web-app>
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/ServiceClientTest.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/ServiceClientTest.java
deleted file mode 100644
index 89366b43889..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/ServiceClientTest.java
+++ /dev/null
@@ -1,226 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.exceptions.ApplicationNotFoundException;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.service.api.records.Artifact;
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.api.records.Container;
-import org.apache.hadoop.yarn.service.api.records.ContainerState;
-import org.apache.hadoop.yarn.service.api.records.Resource;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.client.ServiceClient;
-import org.apache.hadoop.yarn.service.utils.ServiceApiUtil;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-
-import java.io.FileNotFoundException;
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.stream.Collectors;
-
-/**
- * A mock version of ServiceClient - This class is design
- * to simulate various error conditions that will happen
- * when a consumer class calls ServiceClient.
- */
-public class ServiceClientTest extends ServiceClient {
-
-  private Configuration conf = new Configuration();
-  private Service goodServiceStatus = buildLiveGoodService();
-  private boolean initialized;
-  private Set<String> expectedInstances = new HashSet<>();
-  private Map<String, ApplicationId> serviceAppId = new HashMap<>();
-
-
-  public ServiceClientTest() {
-    super();
-  }
-
-  @Override
-  public void init(Configuration conf) {
-    if (!initialized) {
-      super.init(conf);
-      initialized = true;
-    }
-  }
-
-  @Override
-  public void stop() {
-    // This is needed for testing  API Server which uses client to get status
-    // and then perform an action.
-  }
-
-  public void forceStop() {
-    expectedInstances.clear();
-    stop();
-  }
-
-  @Override
-  public Configuration getConfig() {
-    return conf;
-  }
-
-  @Override
-  public ApplicationId actionCreate(Service service) throws IOException {
-    ServiceApiUtil.validateAndResolveService(service,
-        new SliderFileSystem(conf), getConfig());
-    ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    serviceAppId.put(service.getName(), appId);
-    return appId;
-  }
-
-  @Override
-  public Service getStatus(String appName) throws FileNotFoundException {
-    if ("jenkins".equals(appName)) {
-      return goodServiceStatus;
-    } else {
-      throw new FileNotFoundException("Service " + appName + " not found");
-    }
-  }
-
-  @Override
-  public ApplicationId actionStartAndGetId(String serviceName)
-      throws YarnException, IOException {
-    if (serviceName != null && serviceName.equals("jenkins")) {
-      ApplicationId appId =
-          ApplicationId.newInstance(System.currentTimeMillis(), 1);
-      serviceAppId.put(serviceName, appId);
-      return appId;
-    } else {
-      throw new ApplicationNotFoundException("");
-    }
-  }
-
-  @Override
-  public int actionStop(String serviceName, boolean waitForAppStopped)
-      throws YarnException, IOException {
-    if (serviceName == null) {
-      throw new NullPointerException();
-    }
-    if (serviceName.equals("jenkins")) {
-      return EXIT_SUCCESS;
-    } else if (serviceName.equals("jenkins-second-stop")) {
-      return EXIT_COMMAND_ARGUMENT_ERROR;
-    } else {
-      throw new ApplicationNotFoundException("");
-    }
-  }
-
-  @Override
-  public int actionDestroy(String serviceName) {
-    if (serviceName != null) {
-      if (serviceName.equals("jenkins")) {
-        return EXIT_SUCCESS;
-      } else if (serviceName.equals("jenkins-already-stopped")) {
-        return EXIT_SUCCESS;
-      } else if (serviceName.equals("jenkins-doesn't-exist")) {
-        return EXIT_NOT_FOUND;
-      } else if (serviceName.equals("jenkins-error-cleaning-registry")) {
-        return EXIT_OTHER_FAILURE;
-      }
-    }
-    throw new IllegalArgumentException();
-  }
-
-  @Override
-  public int initiateUpgrade(Service service) throws YarnException,
-      IOException {
-    if (service.getName() != null && service.getName().equals("jenkins")) {
-      return EXIT_SUCCESS;
-    } else {
-      throw new IllegalArgumentException();
-    }
-  }
-
-  @Override
-  public int actionUpgrade(Service service, List<Container> compInstances)
-      throws IOException, YarnException {
-    if (service.getName() != null && service.getName().equals("jenkins")
-        && compInstances != null) {
-      Set<String> actualInstances = compInstances.stream().map(
-          Container::getComponentInstanceName).collect(Collectors.toSet());
-      if (actualInstances.equals(expectedInstances)) {
-        return EXIT_SUCCESS;
-      }
-    }
-    throw new IllegalArgumentException();
-  }
-
-  Service getGoodServiceStatus() {
-    return goodServiceStatus;
-  }
-
-  void setExpectedInstances(Set<String> instances) {
-    if (instances != null) {
-      expectedInstances.addAll(instances);
-    }
-  }
-
-  static Service buildGoodService() {
-    Service service = new Service();
-    service.setName("jenkins");
-    service.setVersion("v1");
-    Artifact artifact = new Artifact();
-    artifact.setType(Artifact.TypeEnum.DOCKER);
-    artifact.setId("jenkins:latest");
-    Resource resource = new Resource();
-    resource.setCpus(1);
-    resource.setMemory("2048");
-    List<Component> components = new ArrayList<>();
-    for (int i = 0; i < 2; i++) {
-      Component c = new Component();
-      c.setName("jenkins" + i);
-      c.setNumberOfContainers(2L);
-      c.setArtifact(artifact);
-      c.setLaunchCommand("");
-      c.setResource(resource);
-      components.add(c);
-    }
-    service.setComponents(components);
-    return service;
-  }
-
-  static Service buildLiveGoodService() {
-    Service service = buildGoodService();
-    Component comp = service.getComponents().iterator().next();
-    List<Container> containers = new ArrayList<>();
-    for (int i = 0; i < comp.getNumberOfContainers(); i++) {
-      Container container = new Container();
-      container.setComponentInstanceName(comp.getName() + "-" + (i + 1));
-      container.setState(ContainerState.READY);
-      containers.add(container);
-    }
-    comp.setContainers(containers);
-    return service;
-  }
-
-  @Override
-  public synchronized ApplicationId getAppId(String serviceName)
-      throws IOException, YarnException {
-    return serviceAppId.get(serviceName);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/TestApiServer.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/TestApiServer.java
deleted file mode 100644
index db2cffc9345..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/TestApiServer.java
+++ /dev/null
@@ -1,620 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import static org.junit.jupiter.api.Assertions.*;
-
-import java.io.BufferedWriter;
-import java.io.File;
-import java.io.FileWriter;
-import java.util.ArrayList;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-
-import javax.servlet.http.HttpServletRequest;
-import javax.ws.rs.Path;
-import javax.ws.rs.core.Response;
-import javax.ws.rs.core.Response.Status;
-
-import org.apache.commons.io.FileUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.util.Sets;
-import org.apache.hadoop.yarn.service.api.records.Artifact;
-import org.apache.hadoop.yarn.service.api.records.Artifact.TypeEnum;
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.api.records.ComponentState;
-import org.apache.hadoop.yarn.service.api.records.Container;
-import org.apache.hadoop.yarn.service.api.records.ContainerState;
-import org.apache.hadoop.yarn.service.api.records.Resource;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.api.records.ServiceStatus;
-import org.apache.hadoop.yarn.service.conf.RestApiConstants;
-import org.apache.hadoop.yarn.service.webapp.ApiServer;
-import org.junit.jupiter.api.AfterEach;
-import org.junit.jupiter.api.BeforeEach;
-import org.junit.jupiter.api.Test;
-import org.mockito.Mockito;
-
-/**
- * Test case for ApiServer REST API.
- *
- */
-public class TestApiServer {
-  private ApiServer apiServer;
-  private HttpServletRequest request;
-  private ServiceClientTest mockServerClient;
-
-  @BeforeEach
-  public void setup() throws Exception {
-    request = Mockito.mock(HttpServletRequest.class);
-    Mockito.when(request.getRemoteUser())
-        .thenReturn(System.getProperty("user.name"));
-    mockServerClient = new ServiceClientTest();
-    Configuration conf = new Configuration();
-    conf.set("yarn.api-service.service.client.class",
-        ServiceClientTest.class.getName());
-    apiServer = new ApiServer(conf);
-    apiServer.setServiceClient(mockServerClient);
-  }
-
-  @AfterEach
-  public void teardown() {
-    mockServerClient.forceStop();
-  }
-
-  @Test
-  void testPathAnnotation() {
-    assertNotNull(this.apiServer.getClass().getAnnotation(Path.class));
-    assertTrue(this.apiServer.getClass().isAnnotationPresent(Path.class),
-        "The controller has the annotation Path");
-    final Path path = this.apiServer.getClass()
-        .getAnnotation(Path.class);
-    assertEquals("/v1", path.value(), "The path has /v1 annotation");
-  }
-
-  @Test
-  void testGetVersion() {
-    final Response actual = apiServer.getVersion();
-    assertEquals(Response.ok().build().getStatus(),
-        actual.getStatus(),
-        "Version number is");
-  }
-
-  @Test
-  void testBadCreateService() {
-    Service service = new Service();
-    // Test for invalid argument
-    final Response actual = apiServer.createService(request, service);
-    assertEquals(Response.status(Status.BAD_REQUEST).build().getStatus(),
-        actual.getStatus(),
-        "Create service is ");
-  }
-
-  @Test
-  void testGoodCreateService() throws Exception {
-    String json = "{\"auths\": "
-        + "{\"https://index.docker.io/v1/\": "
-        + "{\"auth\": \"foobarbaz\"},"
-        + "\"registry.example.com\": "
-        + "{\"auth\": \"bazbarfoo\"}}}";
-    File dockerTmpDir = new File("target", "docker-tmp");
-    FileUtils.deleteQuietly(dockerTmpDir);
-    dockerTmpDir.mkdirs();
-    String dockerConfig = dockerTmpDir + "/config.json";
-    BufferedWriter bw = new BufferedWriter(new FileWriter(dockerConfig));
-    bw.write(json);
-    bw.close();
-    Service service = ServiceClientTest.buildGoodService();
-    final Response actual = apiServer.createService(request, service);
-    assertEquals(Response.status(Status.ACCEPTED).build().getStatus(),
-        actual.getStatus(),
-        "Create service is ");
-  }
-
-  @Test
-  void testInternalServerErrorDockerClientConfigMissingCreateService() {
-    Service service = new Service();
-    service.setName("jenkins");
-    service.setVersion("v1");
-    service.setDockerClientConfig("/does/not/exist/config.json");
-    Artifact artifact = new Artifact();
-    artifact.setType(TypeEnum.DOCKER);
-    artifact.setId("jenkins:latest");
-    Resource resource = new Resource();
-    resource.setCpus(1);
-    resource.setMemory("2048");
-    List<Component> components = new ArrayList<>();
-    Component c = new Component();
-    c.setName("jenkins");
-    c.setNumberOfContainers(1L);
-    c.setArtifact(artifact);
-    c.setLaunchCommand("");
-    c.setResource(resource);
-    components.add(c);
-    service.setComponents(components);
-    final Response actual = apiServer.createService(request, service);
-    assertEquals(Response.status(Status.BAD_REQUEST).build().getStatus(),
-        actual.getStatus(),
-        "Create service is ");
-  }
-
-  @Test
-  void testBadGetService() {
-    final String serviceName = "nonexistent-jenkins";
-    final Response actual = apiServer.getService(request, serviceName);
-    assertEquals(Response.status(Status.NOT_FOUND).build().getStatus(),
-        actual.getStatus(),
-        "Get service is ");
-    ServiceStatus serviceStatus = (ServiceStatus) actual.getEntity();
-    assertEquals(RestApiConstants.ERROR_CODE_APP_NAME_INVALID, serviceStatus.getCode(),
-        "Response code don't match");
-    assertEquals("Service " + serviceName + " not found", serviceStatus.getDiagnostics(),
-        "Response diagnostics don't match");
-  }
-
-  @Test
-  void testBadGetService2() {
-    final Response actual = apiServer.getService(request, null);
-    assertEquals(Response.status(Status.NOT_FOUND).build().getStatus(), actual.getStatus(),
-        "Get service is ");
-    ServiceStatus serviceStatus = (ServiceStatus) actual.getEntity();
-    assertEquals(RestApiConstants.ERROR_CODE_APP_NAME_INVALID, serviceStatus.getCode(),
-        "Response code don't match");
-    assertEquals("Service name cannot be null.", serviceStatus.getDiagnostics(),
-        "Response diagnostics don't match");
-  }
-
-  @Test
-  void testGoodGetService() {
-    final Response actual = apiServer.getService(request, "jenkins");
-    assertEquals(Response.status(Status.OK).build().getStatus(), actual.getStatus(),
-        "Get service is ");
-  }
-
-  @Test
-  void testBadDeleteService() {
-    final Response actual = apiServer.deleteService(request, "no-jenkins");
-    assertEquals(Response.status(Status.BAD_REQUEST).build().getStatus(),
-        actual.getStatus(),
-        "Delete service is ");
-  }
-
-  @Test
-  void testBadDeleteService2() {
-    final Response actual = apiServer.deleteService(request, null);
-    assertEquals(Response.status(Status.BAD_REQUEST).build().getStatus(),
-        actual.getStatus(),
-        "Delete service is ");
-  }
-
-  @Test
-  void testBadDeleteService3() {
-    final Response actual = apiServer.deleteService(request,
-        "jenkins-doesn't-exist");
-    assertEquals(Response.status(Status.BAD_REQUEST).build().getStatus(),
-        actual.getStatus(),
-        "Delete service is ");
-  }
-
-  @Test
-  void testBadDeleteService4() {
-    final Response actual = apiServer.deleteService(request,
-        "jenkins-error-cleaning-registry");
-    assertEquals(Response.status(Status.INTERNAL_SERVER_ERROR).build().getStatus(),
-        actual.getStatus(),
-        "Delete service is ");
-  }
-
-  @Test
-  void testGoodDeleteService() {
-    final Response actual = apiServer.deleteService(request, "jenkins");
-    assertEquals(Response.status(Status.OK).build().getStatus(), actual.getStatus(),
-        "Delete service is ");
-  }
-
-  @Test
-  void testDeleteStoppedService() {
-    final Response actual = apiServer.deleteService(request, "jenkins-already-stopped");
-    assertEquals(Response.status(Status.OK).build().getStatus(), actual.getStatus(),
-        "Delete service is ");
-  }
-
-  @Test
-  void testDecreaseContainerAndStop() {
-    Service service = new Service();
-    service.setState(ServiceState.STOPPED);
-    service.setName("jenkins");
-    Artifact artifact = new Artifact();
-    artifact.setType(TypeEnum.DOCKER);
-    artifact.setId("jenkins:latest");
-    Resource resource = new Resource();
-    resource.setCpus(1);
-    resource.setMemory("2048");
-    List<Component> components = new ArrayList<Component>();
-    Component c = new Component();
-    c.setName("jenkins");
-    c.setNumberOfContainers(0L);
-    c.setArtifact(artifact);
-    c.setLaunchCommand("");
-    c.setResource(resource);
-    components.add(c);
-    service.setComponents(components);
-    final Response actual = apiServer.updateService(request, "jenkins",
-        service);
-    assertEquals(Response.status(Status.OK).build().getStatus(), actual.getStatus(),
-        "update service is ");
-  }
-
-  @Test
-  void testBadDecreaseContainerAndStop() {
-    Service service = new Service();
-    service.setState(ServiceState.STOPPED);
-    service.setName("no-jenkins");
-    Artifact artifact = new Artifact();
-    artifact.setType(TypeEnum.DOCKER);
-    artifact.setId("jenkins:latest");
-    Resource resource = new Resource();
-    resource.setCpus(1);
-    resource.setMemory("2048");
-    List<Component> components = new ArrayList<Component>();
-    Component c = new Component();
-    c.setName("no-jenkins");
-    c.setNumberOfContainers(-1L);
-    c.setArtifact(artifact);
-    c.setLaunchCommand("");
-    c.setResource(resource);
-    components.add(c);
-    service.setComponents(components);
-    System.out.println("before stop");
-    final Response actual = apiServer.updateService(request, "no-jenkins",
-        service);
-    assertEquals(Response.status(Status.BAD_REQUEST).build().getStatus(),
-        actual.getStatus(),
-        "flex service is ");
-  }
-
-  @Test
-  void testIncreaseContainersAndStart() {
-    Service service = new Service();
-    service.setState(ServiceState.STARTED);
-    service.setName("jenkins");
-    Artifact artifact = new Artifact();
-    artifact.setType(TypeEnum.DOCKER);
-    artifact.setId("jenkins:latest");
-    Resource resource = new Resource();
-    resource.setCpus(1);
-    resource.setMemory("2048");
-    List<Component> components = new ArrayList<Component>();
-    Component c = new Component();
-    c.setName("jenkins");
-    c.setNumberOfContainers(2L);
-    c.setArtifact(artifact);
-    c.setLaunchCommand("");
-    c.setResource(resource);
-    components.add(c);
-    service.setComponents(components);
-    final Response actual = apiServer.updateService(request, "jenkins",
-        service);
-    assertEquals(Response.status(Status.OK).build().getStatus(), actual.getStatus(),
-        "flex service is ");
-  }
-
-  @Test
-  void testBadStartServices() {
-    Service service = new Service();
-    service.setState(ServiceState.STARTED);
-    service.setName("no-jenkins");
-    Artifact artifact = new Artifact();
-    artifact.setType(TypeEnum.DOCKER);
-    artifact.setId("jenkins:latest");
-    Resource resource = new Resource();
-    resource.setCpus(1);
-    resource.setMemory("2048");
-    List<Component> components = new ArrayList<Component>();
-    Component c = new Component();
-    c.setName("jenkins");
-    c.setNumberOfContainers(2L);
-    c.setArtifact(artifact);
-    c.setLaunchCommand("");
-    c.setResource(resource);
-    components.add(c);
-    service.setComponents(components);
-    final Response actual = apiServer.updateService(request, "no-jenkins",
-        service);
-    assertEquals(Response.status(Status.BAD_REQUEST).build().getStatus(),
-        actual.getStatus(),
-        "start service is ");
-  }
-
-  @Test
-  void testGoodStartServices() {
-    Service service = new Service();
-    service.setState(ServiceState.STARTED);
-    service.setName("jenkins");
-    Artifact artifact = new Artifact();
-    artifact.setType(TypeEnum.DOCKER);
-    artifact.setId("jenkins:latest");
-    Resource resource = new Resource();
-    resource.setCpus(1);
-    resource.setMemory("2048");
-    List<Component> components = new ArrayList<Component>();
-    Component c = new Component();
-    c.setName("jenkins");
-    c.setNumberOfContainers(2L);
-    c.setArtifact(artifact);
-    c.setLaunchCommand("");
-    c.setResource(resource);
-    components.add(c);
-    service.setComponents(components);
-    final Response actual = apiServer.updateService(request, "jenkins",
-        service);
-    assertEquals(Response.status(Status.OK).build().getStatus(), actual.getStatus(),
-        "start service is ");
-  }
-
-  @Test
-  void testBadStopServices() {
-    Service service = new Service();
-    service.setState(ServiceState.STOPPED);
-    service.setName("no-jenkins");
-    Artifact artifact = new Artifact();
-    artifact.setType(TypeEnum.DOCKER);
-    artifact.setId("jenkins:latest");
-    Resource resource = new Resource();
-    resource.setCpus(1);
-    resource.setMemory("2048");
-    List<Component> components = new ArrayList<Component>();
-    Component c = new Component();
-    c.setName("no-jenkins");
-    c.setNumberOfContainers(-1L);
-    c.setArtifact(artifact);
-    c.setLaunchCommand("");
-    c.setResource(resource);
-    components.add(c);
-    service.setComponents(components);
-    System.out.println("before stop");
-    final Response actual = apiServer.updateService(request, "no-jenkins",
-        service);
-    assertEquals(Response.status(Status.BAD_REQUEST).build().getStatus(),
-        actual.getStatus(),
-        "stop service is ");
-  }
-
-  @Test
-  void testGoodStopServices() {
-    Service service = new Service();
-    service.setState(ServiceState.STOPPED);
-    service.setName("jenkins");
-    System.out.println("before stop");
-    final Response actual = apiServer.updateService(request, "jenkins",
-        service);
-    assertEquals(Response.status(Status.OK).build().getStatus(), actual.getStatus(),
-        "stop service is ");
-  }
-
-  @Test
-  void testBadSecondStopServices() throws Exception {
-    Service service = new Service();
-    service.setState(ServiceState.STOPPED);
-    service.setName("jenkins-second-stop");
-    // simulates stop on an already stopped service
-    System.out.println("before second stop");
-    final Response actual = apiServer.updateService(request,
-        "jenkins-second-stop", service);
-    assertEquals(Response.status(Status.BAD_REQUEST).build().getStatus(),
-        actual.getStatus(),
-        "stop service should have thrown 400 Bad Request: ");
-    ServiceStatus serviceStatus = (ServiceStatus) actual.getEntity();
-    assertEquals("Service jenkins-second-stop is already stopped",
-        serviceStatus.getDiagnostics(),
-        "Stop service should have failed with service already stopped");
-  }
-
-  @Test
-  void testUpdateService() {
-    Service service = new Service();
-    service.setState(ServiceState.STARTED);
-    service.setName("no-jenkins");
-    Artifact artifact = new Artifact();
-    artifact.setType(TypeEnum.DOCKER);
-    artifact.setId("jenkins:latest");
-    Resource resource = new Resource();
-    resource.setCpus(1);
-    resource.setMemory("2048");
-    List<Component> components = new ArrayList<Component>();
-    Component c = new Component();
-    c.setName("no-jenkins");
-    c.setNumberOfContainers(-1L);
-    c.setArtifact(artifact);
-    c.setLaunchCommand("");
-    c.setResource(resource);
-    components.add(c);
-    service.setComponents(components);
-    System.out.println("before stop");
-    final Response actual = apiServer.updateService(request, "no-jenkins",
-        service);
-    assertEquals(Response.status(Status.BAD_REQUEST)
-        .build().getStatus(), actual.getStatus(), "update service is ");
-  }
-
-  @Test
-  void testUpdateComponent() {
-    Response actual = apiServer.updateComponent(request, "jenkins",
-        "jenkins-master", null);
-    ServiceStatus serviceStatus = (ServiceStatus) actual.getEntity();
-    assertEquals(Response.status(Status.BAD_REQUEST).build().getStatus(),
-        actual.getStatus(),
-        "Update component should have failed with 400 bad request");
-    assertEquals("No component data provided", serviceStatus.getDiagnostics(),
-        "Update component should have failed with no data error");
-
-    Component comp = new Component();
-    actual = apiServer.updateComponent(request, "jenkins", "jenkins-master",
-        comp);
-    serviceStatus = (ServiceStatus) actual.getEntity();
-    assertEquals(Response.status(Status.BAD_REQUEST).build().getStatus(),
-        actual.getStatus(),
-        "Update component should have failed with 400 bad request");
-    assertEquals("No container count provided", serviceStatus.getDiagnostics(),
-        "Update component should have failed with no count error");
-
-    comp.setNumberOfContainers(-1L);
-    actual = apiServer.updateComponent(request, "jenkins", "jenkins-master",
-        comp);
-    serviceStatus = (ServiceStatus) actual.getEntity();
-    assertEquals(Response.status(Status.BAD_REQUEST).build().getStatus(),
-        actual.getStatus(),
-        "Update component should have failed with 400 bad request");
-    assertEquals("Invalid number of containers specified -1", serviceStatus.getDiagnostics(),
-        "Update component should have failed with no count error");
-
-    comp.setName("jenkins-slave");
-    comp.setNumberOfContainers(1L);
-    actual = apiServer.updateComponent(request, "jenkins", "jenkins-master",
-        comp);
-    serviceStatus = (ServiceStatus) actual.getEntity();
-    assertEquals(Response.status(Status.BAD_REQUEST).build().getStatus(),
-        actual.getStatus(),
-        "Update component should have failed with 400 bad request");
-    assertEquals(
-        "Component name in the request object (jenkins-slave) does not match "
-            + "that in the URI path (jenkins-master)",
-        serviceStatus.getDiagnostics(),
-        "Update component should have failed with component name mismatch "
-            + "error");
-  }
-
-  @Test
-  void testInitiateUpgrade() {
-    Service goodService = ServiceClientTest.buildLiveGoodService();
-    goodService.setVersion("v2");
-    goodService.setState(ServiceState.UPGRADING);
-    final Response actual = apiServer.updateService(request,
-        goodService.getName(), goodService);
-    assertEquals(Response.status(Status.ACCEPTED).build().getStatus(),
-        actual.getStatus(),
-        "Initiate upgrade is ");
-  }
-
-  @Test
-  void testUpgradeSingleInstance() {
-    Service goodService = ServiceClientTest.buildLiveGoodService();
-    Component comp = goodService.getComponents().iterator().next();
-    Container container = comp.getContainers().iterator().next();
-    container.setState(ContainerState.UPGRADING);
-
-    // To be able to upgrade, the service needs to be in UPGRADING
-    // and container state needs to be in NEEDS_UPGRADE.
-    Service serviceStatus = mockServerClient.getGoodServiceStatus();
-    serviceStatus.setState(ServiceState.UPGRADING);
-    Container liveContainer = serviceStatus.getComponents().iterator().next()
-        .getContainers().iterator().next();
-    liveContainer.setState(ContainerState.NEEDS_UPGRADE);
-    mockServerClient.setExpectedInstances(Sets.newHashSet(
-        liveContainer.getComponentInstanceName()));
-
-    final Response actual = apiServer.updateComponentInstance(request,
-        goodService.getName(), comp.getName(),
-        container.getComponentInstanceName(), container);
-    assertEquals(Response.status(Status.ACCEPTED).build().getStatus(),
-        actual.getStatus(),
-        "Instance upgrade is ");
-  }
-
-  @Test
-  void testUpgradeMultipleInstances() {
-    Service goodService = ServiceClientTest.buildLiveGoodService();
-    Component comp = goodService.getComponents().iterator().next();
-    comp.getContainers().forEach(container ->
-        container.setState(ContainerState.UPGRADING));
-
-    // To be able to upgrade, the service needs to be in UPGRADING
-    // and container state needs to be in NEEDS_UPGRADE.
-    Service serviceStatus = mockServerClient.getGoodServiceStatus();
-    serviceStatus.setState(ServiceState.UPGRADING);
-    Set<String> expectedInstances = new HashSet<>();
-    serviceStatus.getComponents().iterator().next().getContainers().forEach(
-        container -> {
-          container.setState(ContainerState.NEEDS_UPGRADE);
-          expectedInstances.add(container.getComponentInstanceName());
-        }
-    );
-    mockServerClient.setExpectedInstances(expectedInstances);
-
-    final Response actual = apiServer.updateComponentInstances(request,
-        goodService.getName(), comp.getContainers());
-    assertEquals(Response.status(Status.ACCEPTED).build().getStatus(),
-        actual.getStatus(),
-        "Instance upgrade is ");
-  }
-
-  @Test
-  void testUpgradeComponent() {
-    Service goodService = ServiceClientTest.buildLiveGoodService();
-    Component comp = goodService.getComponents().iterator().next();
-    comp.setState(ComponentState.UPGRADING);
-
-    // To be able to upgrade, the service needs to be in UPGRADING
-    // and component state needs to be in NEEDS_UPGRADE.
-    Service serviceStatus = mockServerClient.getGoodServiceStatus();
-    serviceStatus.setState(ServiceState.UPGRADING);
-    Component liveComp = serviceStatus.getComponent(comp.getName());
-    liveComp.setState(ComponentState.NEEDS_UPGRADE);
-    Set<String> expectedInstances = new HashSet<>();
-    liveComp.getContainers().forEach(container -> {
-      expectedInstances.add(container.getComponentInstanceName());
-      container.setState(ContainerState.NEEDS_UPGRADE);
-    });
-    mockServerClient.setExpectedInstances(expectedInstances);
-
-    final Response actual = apiServer.updateComponent(request,
-        goodService.getName(), comp.getName(), comp);
-    assertEquals(Response.status(Status.ACCEPTED).build().getStatus(),
-        actual.getStatus(),
-        "Component upgrade is ");
-  }
-
-  @Test
-  void testUpgradeMultipleComps() {
-    Service goodService = ServiceClientTest.buildLiveGoodService();
-    goodService.getComponents().forEach(comp ->
-        comp.setState(ComponentState.UPGRADING));
-
-    // To be able to upgrade, the live service needs to be in UPGRADING
-    // and component states needs to be in NEEDS_UPGRADE.
-    Service serviceStatus = mockServerClient.getGoodServiceStatus();
-    serviceStatus.setState(ServiceState.UPGRADING);
-    Set<String> expectedInstances = new HashSet<>();
-    serviceStatus.getComponents().forEach(liveComp -> {
-      liveComp.setState(ComponentState.NEEDS_UPGRADE);
-      liveComp.getContainers().forEach(liveContainer -> {
-        expectedInstances.add(liveContainer.getComponentInstanceName());
-        liveContainer.setState(ContainerState.NEEDS_UPGRADE);
-      });
-    });
-    mockServerClient.setExpectedInstances(expectedInstances);
-
-    final Response actual = apiServer.updateComponents(request,
-        goodService.getName(), goodService.getComponents());
-    assertEquals(Response.status(Status.ACCEPTED).build().getStatus(),
-        actual.getStatus(),
-        "Component upgrade is ");
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/TestCleanupAfterKill.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/TestCleanupAfterKill.java
deleted file mode 100644
index c2f3c689e23..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/TestCleanupAfterKill.java
+++ /dev/null
@@ -1,95 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service;
-
-import org.apache.commons.io.FileUtils;
-import org.apache.hadoop.registry.client.binding.RegistryUtils;
-import org.apache.hadoop.test.GenericTestUtils;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.ApplicationReport;
-import org.apache.hadoop.yarn.api.records.YarnApplicationState;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.client.ServiceClient;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConstants;
-import org.junit.jupiter.api.AfterEach;
-import org.junit.jupiter.api.BeforeEach;
-import org.junit.jupiter.api.Test;
-import org.junit.jupiter.api.Timeout;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.File;
-
-import static org.junit.jupiter.api.Assertions.assertEquals;
-import static org.junit.jupiter.api.Assertions.assertFalse;
-import static org.junit.jupiter.api.Assertions.assertTrue;
-
-import java.io.IOException;
-
-/**
- * Minicluster test that verifies registry cleanup when app lifetime is
- * exceeded.
- */
-public class TestCleanupAfterKill extends ServiceTestUtils {
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestCleanupAfterKill.class);
-
-  @BeforeEach
-  public void setup() throws Exception {
-    File tmpYarnDir = new File("target", "tmp");
-    FileUtils.deleteQuietly(tmpYarnDir);
-  }
-
-  @AfterEach
-  public void tearDown() throws IOException {
-    shutdown();
-  }
-
-  @Test
-  @Timeout(200000)
-  void testRegistryCleanedOnLifetimeExceeded() throws Exception {
-    setupInternal(NUM_NMS);
-    ServiceClient client = createClient(getConf());
-    Service exampleApp = createExampleApplication();
-    exampleApp.setLifetime(30L);
-    client.actionCreate(exampleApp);
-    waitForServiceToBeStable(client, exampleApp);
-    String serviceZKPath = RegistryUtils.servicePath(RegistryUtils
-        .currentUser(), YarnServiceConstants.APP_TYPE, exampleApp.getName());
-    assertTrue(getCuratorService().zkPathExists(serviceZKPath),
-        "Registry ZK service path doesn't exist");
-
-    // wait for app to be killed by RM
-    ApplicationId exampleAppId = ApplicationId.fromString(exampleApp.getId());
-    GenericTestUtils.waitFor(() -> {
-      try {
-        ApplicationReport ar = client.getYarnClient()
-            .getApplicationReport(exampleAppId);
-        return ar.getYarnApplicationState() == YarnApplicationState.KILLED;
-      } catch (YarnException | IOException e) {
-        throw new RuntimeException("while waiting", e);
-      }
-    }, 2000, 200000);
-    assertFalse(getCuratorService().zkPathExists(serviceZKPath),
-        "Registry ZK service path still exists after killed");
-
-    LOG.info("Destroy the service");
-    assertEquals(0, client.actionDestroy(exampleApp.getName()));
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/client/TestApiServiceClient.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/client/TestApiServiceClient.java
deleted file mode 100644
index fe9c081ed64..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/client/TestApiServiceClient.java
+++ /dev/null
@@ -1,344 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.client;
-
-import static org.junit.jupiter.api.Assertions.*;
-
-import java.io.IOException;
-import java.util.HashMap;
-
-import javax.servlet.ServletException;
-import javax.servlet.http.HttpServlet;
-import javax.servlet.http.HttpServletRequest;
-import javax.servlet.http.HttpServletResponse;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.util.Lists;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.eclipse.jetty.server.Server;
-import org.eclipse.jetty.server.ServerConnector;
-import org.eclipse.jetty.servlet.ServletContextHandler;
-import org.eclipse.jetty.servlet.ServletHolder;
-import org.eclipse.jetty.util.thread.QueuedThreadPool;
-import org.junit.jupiter.api.AfterAll;
-import org.junit.jupiter.api.BeforeAll;
-import org.junit.jupiter.api.Test;
-
-import static org.apache.hadoop.yarn.service.exceptions.LauncherExitCodes.*;
-
-/**
- * Test case for CLI to API Service.
- *
- */
-public class TestApiServiceClient {
-  private static ApiServiceClient asc;
-  private static ApiServiceClient badAsc;
-  private static Server server;
-
-  /**
-   * A mocked version of API Service for testing purpose.
-   *
-   */
-  @SuppressWarnings("serial")
-  public static class TestServlet extends HttpServlet {
-
-    @Override
-    protected void doGet(HttpServletRequest req, HttpServletResponse resp)
-        throws ServletException, IOException {
-      System.out.println("Get was called");
-      if (req.getPathInfo() != null
-          && req.getPathInfo().contains("nonexistent-app")) {
-        resp.setStatus(HttpServletResponse.SC_NOT_FOUND);
-      } else {
-        resp.setStatus(HttpServletResponse.SC_OK);
-      }
-    }
-
-    @Override
-    protected void doPost(HttpServletRequest req, HttpServletResponse resp)
-        throws ServletException, IOException {
-      resp.setStatus(HttpServletResponse.SC_OK);
-    }
-
-    @Override
-    protected void doPut(HttpServletRequest req, HttpServletResponse resp)
-        throws ServletException, IOException {
-      resp.setStatus(HttpServletResponse.SC_OK);
-    }
-
-    @Override
-    protected void doDelete(HttpServletRequest req, HttpServletResponse resp)
-        throws ServletException, IOException {
-      resp.setStatus(HttpServletResponse.SC_OK);
-    }
-
-  }
-
-  @BeforeAll
-  public static void setup() throws Exception {
-    server = new Server(8088);
-    ((QueuedThreadPool)server.getThreadPool()).setMaxThreads(20);
-    ServletContextHandler context = new ServletContextHandler();
-    context.setContextPath("/app");
-    server.setHandler(context);
-    context.addServlet(new ServletHolder(TestServlet.class), "/*");
-    ((ServerConnector)server.getConnectors()[0]).setHost("localhost");
-    server.start();
-
-    Configuration conf = new Configuration();
-    conf.set("yarn.resourcemanager.webapp.address",
-        "localhost:8088");
-    asc = new ApiServiceClient();
-    asc.serviceInit(conf);
-
-    Configuration conf2 = new Configuration();
-    conf2.set("yarn.resourcemanager.webapp.address",
-        "localhost:8089");
-    badAsc = new ApiServiceClient();
-    badAsc.serviceInit(conf2);
-  }
-
-  @AfterAll
-  public static void tearDown() throws Exception {
-    server.stop();
-  }
-
-  @Test
-  void testGetRMWebAddress() throws Exception {
-    Configuration conf = new Configuration();
-    conf.setBoolean(YarnConfiguration.RM_HA_ENABLED, true);
-    conf.set(YarnConfiguration.RM_HA_IDS, "rm1");
-    conf.set(YarnConfiguration.RM_HA_ID, "rm1");
-    conf.set("yarn.resourcemanager.webapp.address.rm1", "localhost:0");
-    ApiServiceClient asc1 = new ApiServiceClient(conf);
-    boolean exceptionCaught = false;
-    String diagnosticsMsg = null;
-    try {
-      String rmWebAddress = asc1.getRMWebAddress();
-    } catch (IOException e) {
-      exceptionCaught = true;
-      diagnosticsMsg = e.getMessage();
-    }
-    assertTrue(exceptionCaught, "ApiServiceClient failed to throw exception");
-    assertTrue(diagnosticsMsg.contains("Error connecting to localhost:0"),
-        "Exception Message does not match");
-  }
-
-  @Test
-  void testLaunch() {
-    String fileName = "target/test-classes/example-app.json";
-    String appName = "example-app";
-    long lifetime = 3600L;
-    String queue = "default";
-    try {
-      int result = asc.actionLaunch(fileName, appName, lifetime, queue);
-      assertEquals(EXIT_SUCCESS, result);
-    } catch (IOException | YarnException e) {
-      fail();
-    }
-  }
-
-  @Test
-  void testBadLaunch() {
-    String fileName = "unknown_file";
-    String appName = "unknown_app";
-    long lifetime = 3600L;
-    String queue = "default";
-    try {
-      int result = badAsc.actionLaunch(fileName, appName, lifetime, queue);
-      assertEquals(EXIT_EXCEPTION_THROWN, result);
-    } catch (IOException | YarnException e) {
-      fail();
-    }
-  }
-
-  @Test
-  void testStatus() {
-    String appName = "nonexistent-app";
-    try {
-      String result = asc.getStatusString(appName);
-      assertEquals(" Service " + appName + " not found", result, "Status reponse don't match");
-    } catch (IOException | YarnException e) {
-      fail();
-    }
-  }
-
-  @Test
-  void testStop() {
-    String appName = "example-app";
-    try {
-      int result = asc.actionStop(appName);
-      assertEquals(EXIT_SUCCESS, result);
-    } catch (IOException | YarnException e) {
-      fail();
-    }
-  }
-
-  @Test
-  void testBadStop() {
-    String appName = "unknown_app";
-    try {
-      int result = badAsc.actionStop(appName);
-      assertEquals(EXIT_EXCEPTION_THROWN, result);
-    } catch (IOException | YarnException e) {
-      fail();
-    }
-  }
-
-  @Test
-  void testStart() {
-    String appName = "example-app";
-    try {
-      int result = asc.actionStart(appName);
-      assertEquals(EXIT_SUCCESS, result);
-    } catch (IOException | YarnException e) {
-      fail();
-    }
-  }
-
-  @Test
-  void testBadStart() {
-    String appName = "unknown_app";
-    try {
-      int result = badAsc.actionStart(appName);
-      assertEquals(EXIT_EXCEPTION_THROWN, result);
-    } catch (IOException | YarnException e) {
-      fail();
-    }
-  }
-
-  @Test
-  void testSave() {
-    String fileName = "target/test-classes/example-app.json";
-    String appName = "example-app";
-    long lifetime = 3600L;
-    String queue = "default";
-    try {
-      int result = asc.actionSave(fileName, appName, lifetime, queue);
-      assertEquals(EXIT_SUCCESS, result);
-    } catch (IOException | YarnException e) {
-      fail();
-    }
-  }
-
-  @Test
-  void testBadSave() {
-    String fileName = "unknown_file";
-    String appName = "unknown_app";
-    long lifetime = 3600L;
-    String queue = "default";
-    try {
-      int result = badAsc.actionSave(fileName, appName, lifetime, queue);
-      assertEquals(EXIT_EXCEPTION_THROWN, result);
-    } catch (IOException | YarnException e) {
-      fail();
-    }
-  }
-
-  @Test
-  void testFlex() {
-    String appName = "example-app";
-    HashMap<String, String> componentCounts = new HashMap<String, String>();
-    try {
-      int result = asc.actionFlex(appName, componentCounts);
-      assertEquals(EXIT_SUCCESS, result);
-    } catch (IOException | YarnException e) {
-      fail();
-    }
-  }
-
-  @Test
-  void testBadFlex() {
-    String appName = "unknown_app";
-    HashMap<String, String> componentCounts = new HashMap<String, String>();
-    try {
-      int result = badAsc.actionFlex(appName, componentCounts);
-      assertEquals(EXIT_EXCEPTION_THROWN, result);
-    } catch (IOException | YarnException e) {
-      fail();
-    }
-  }
-
-  @Test
-  void testDestroy() {
-    String appName = "example-app";
-    try {
-      int result = asc.actionDestroy(appName);
-      assertEquals(EXIT_SUCCESS, result);
-    } catch (IOException | YarnException e) {
-      fail();
-    }
-  }
-
-  @Test
-  void testBadDestroy() {
-    String appName = "unknown_app";
-    try {
-      int result = badAsc.actionDestroy(appName);
-      assertEquals(EXIT_EXCEPTION_THROWN, result);
-    } catch (IOException | YarnException e) {
-      fail();
-    }
-  }
-
-  @Test
-  void testInitiateServiceUpgrade() {
-    String appName = "example-app";
-    String upgradeFileName = "target/test-classes/example-app.json";
-    try {
-      int result = asc.initiateUpgrade(appName, upgradeFileName, false);
-      assertEquals(EXIT_SUCCESS, result);
-    } catch (IOException | YarnException e) {
-      fail();
-    }
-  }
-
-  @Test
-  void testInstancesUpgrade() {
-    String appName = "example-app";
-    try {
-      int result = asc.actionUpgradeInstances(appName, Lists.newArrayList(
-          "comp-1", "comp-2"));
-      assertEquals(EXIT_SUCCESS, result);
-    } catch (IOException | YarnException e) {
-      fail();
-    }
-  }
-
-  @Test
-  void testComponentsUpgrade() {
-    String appName = "example-app";
-    try {
-      int result = asc.actionUpgradeComponents(appName, Lists.newArrayList(
-          "comp"));
-      assertEquals(EXIT_SUCCESS, result);
-    } catch (IOException | YarnException e) {
-      fail();
-    }
-  }
-
-  @Test
-  void testNoneSecureApiClient() throws IOException {
-    String url = asc.getServicePath("/foobar");
-    assertTrue(url.contains("user.name"),
-        "User.name flag is missing in service path.");
-    assertTrue(url.contains(System.getProperty("user.name")),
-        "User.name flag is not matching JVM user.");
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/client/TestSecureApiServiceClient.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/client/TestSecureApiServiceClient.java
deleted file mode 100644
index 60c06e9aa75..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/client/TestSecureApiServiceClient.java
+++ /dev/null
@@ -1,192 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.client;
-
-import static org.junit.jupiter.api.Assertions.*;
-
-import java.io.File;
-import java.io.IOException;
-
-import javax.security.sasl.Sasl;
-import javax.servlet.ServletException;
-import javax.servlet.http.HttpServlet;
-import javax.servlet.http.HttpServletRequest;
-import javax.servlet.http.HttpServletResponse;
-
-import java.util.Map;
-import java.util.ArrayList;
-import java.util.Enumeration;
-import java.util.HashMap;
-import java.util.List;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.minikdc.KerberosSecurityTestcase;
-import org.apache.hadoop.security.SecurityUtil;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.security.SaslRpcServer.QualityOfProtection;
-import org.apache.hadoop.security.UserGroupInformation.AuthenticationMethod;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.client.util.YarnClientUtils;
-import org.apache.log4j.Logger;
-import org.eclipse.jetty.server.Server;
-import org.eclipse.jetty.server.ServerConnector;
-import org.eclipse.jetty.servlet.ServletContextHandler;
-import org.eclipse.jetty.servlet.ServletHolder;
-import org.eclipse.jetty.util.thread.QueuedThreadPool;
-import org.junit.jupiter.api.AfterEach;
-import org.junit.jupiter.api.BeforeEach;
-import org.junit.jupiter.api.Test;
-
-/**
- * Test Spnego Client Login.
- */
-public class TestSecureApiServiceClient extends KerberosSecurityTestcase {
-
-  private String clientPrincipal = "client";
-
-  private String server1Protocol = "HTTP";
-
-  private String server2Protocol = "server2";
-
-  private String host = "localhost";
-
-  private String server1Principal = server1Protocol + "/" + host;
-
-  private String server2Principal = server2Protocol + "/" + host;
-
-  private File keytabFile;
-
-  private Configuration testConf = new Configuration();
-
-  private Map<String, String> props;
-  private static Server server;
-  private static Logger LOG = Logger
-      .getLogger(TestSecureApiServiceClient.class);
-  private ApiServiceClient asc;
-
-  /**
-   * A mocked version of API Service for testing purpose.
-   *
-   */
-  @SuppressWarnings("serial")
-  public static class TestServlet extends HttpServlet {
-
-    private static boolean headerFound = false;
-
-    @Override
-    protected void doGet(HttpServletRequest req, HttpServletResponse resp)
-        throws ServletException, IOException {
-      Enumeration<String> headers = req.getHeaderNames();
-      while(headers.hasMoreElements()) {
-        String header = headers.nextElement();
-        LOG.info(header);
-      }
-      if (req.getHeader("Authorization")!=null) {
-        headerFound = true;
-        resp.setStatus(HttpServletResponse.SC_OK);
-      } else {
-        headerFound = false;
-        resp.setStatus(HttpServletResponse.SC_NOT_FOUND);
-      }
-    }
-
-    @Override
-    protected void doPost(HttpServletRequest req, HttpServletResponse resp)
-        throws ServletException, IOException {
-      resp.setStatus(HttpServletResponse.SC_OK);
-    }
-
-    @Override
-    protected void doPut(HttpServletRequest req, HttpServletResponse resp)
-        throws ServletException, IOException {
-      resp.setStatus(HttpServletResponse.SC_OK);
-    }
-
-    @Override
-    protected void doDelete(HttpServletRequest req, HttpServletResponse resp)
-        throws ServletException, IOException {
-      resp.setStatus(HttpServletResponse.SC_OK);
-    }
-
-    public static boolean isHeaderExist() {
-      return headerFound;
-    }
-  }
-
-  @BeforeEach
-  public void setUp() throws Exception {
-    startMiniKdc();
-    keytabFile = new File(getWorkDir(), "keytab");
-    getKdc().createPrincipal(keytabFile, clientPrincipal, server1Principal,
-        server2Principal);
-    SecurityUtil.setAuthenticationMethod(AuthenticationMethod.KERBEROS,
-        testConf);
-    UserGroupInformation.setConfiguration(testConf);
-    UserGroupInformation.setShouldRenewImmediatelyForTests(true);
-    props = new HashMap<String, String>();
-    props.put(Sasl.QOP, QualityOfProtection.AUTHENTICATION.saslQop);
-    server = new Server(8088);
-    ((QueuedThreadPool)server.getThreadPool()).setMaxThreads(20);
-    ServletContextHandler context = new ServletContextHandler();
-    context.setContextPath("/app");
-    server.setHandler(context);
-    context.addServlet(new ServletHolder(TestServlet.class), "/*");
-    ((ServerConnector)server.getConnectors()[0]).setHost("localhost");
-    server.start();
-
-    List<String> rmServers = new ArrayList<String>();
-    rmServers.add("localhost:8088");
-    testConf.set("yarn.resourcemanager.webapp.address",
-        "localhost:8088");
-    testConf.setBoolean(YarnConfiguration.RM_HA_ENABLED, true);
-    asc = new ApiServiceClient() {
-      @Override
-      List<String> getRMHAWebAddresses(Configuration conf) {
-        return rmServers;
-      }
-    };
-    asc.serviceInit(testConf);
-  }
-
-  @AfterEach
-  public void tearDown() throws Exception {
-    server.stop();
-    stopMiniKdc();
-  }
-
-  @Test
-  void testHttpSpnegoChallenge() throws Exception {
-    UserGroupInformation.loginUserFromKeytab(clientPrincipal, keytabFile
-        .getCanonicalPath());
-    String challenge = YarnClientUtils.generateToken("localhost");
-    assertNotNull(challenge);
-  }
-
-  @Test
-  void testAuthorizationHeader() throws Exception {
-    UserGroupInformation.loginUserFromKeytab(clientPrincipal, keytabFile
-        .getCanonicalPath());
-    String rmAddress = asc.getRMWebAddress();
-    if (TestServlet.isHeaderExist()) {
-      assertEquals(rmAddress, "http://localhost:8088");
-    } else {
-      fail("Did not see Authorization header.");
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/client/TestSystemServiceManagerImpl.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/client/TestSystemServiceManagerImpl.java
deleted file mode 100644
index a2f698fd31f..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/java/org/apache/hadoop/yarn/service/client/TestSystemServiceManagerImpl.java
+++ /dev/null
@@ -1,264 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.client;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.hdfs.HdfsConfiguration;
-import org.apache.hadoop.hdfs.MiniDFSCluster;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.conf.SliderExitCodes;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConf;
-import org.apache.hadoop.yarn.service.exceptions.SliderException;
-import org.junit.jupiter.api.AfterEach;
-import org.junit.jupiter.api.BeforeEach;
-import org.junit.jupiter.api.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.File;
-
-import static org.junit.jupiter.api.Assertions.*;
-
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.Map;
-import java.util.Set;
-
-/**
- * Test class for system service manager.
- */
-public class TestSystemServiceManagerImpl {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestSystemServiceManagerImpl.class);
-  private SystemServiceManagerImpl systemService;
-  private Configuration conf;
-  private String resourcePath = "system-services";
-
-  private String[] users = new String[] {"user1", "user2"};
-  private static Map<String, Set<String>> loadedServices = new HashMap<>();
-  private static Map<String, Set<String>> savedServices = new HashMap<>();
-  private static Map<String, Set<String>> submittedServices = new HashMap<>();
-
-  @BeforeEach
-  public void setup() {
-    File file = new File(
-        getClass().getClassLoader().getResource(resourcePath).getFile());
-    conf = new Configuration();
-    conf.set(YarnServiceConf.YARN_SERVICES_SYSTEM_SERVICE_DIRECTORY,
-        file.getAbsolutePath());
-    systemService = new SystemServiceManagerImpl() {
-      @Override ServiceClient getServiceClient() {
-        return new TestServiceClient();
-      }
-    };
-    systemService.init(conf); // do not call explicit start
-
-    constructUserService(users[0], "example-app1");
-    constructUserService(users[1], "example-app1", "example-app2");
-  }
-
-  @AfterEach
-  public void tearDown() {
-    systemService.stop();
-  }
-
-  @Test
-  void testSystemServiceSubmission() throws Exception {
-    systemService.start();
-
-    /* verify for ignored sevices count */
-    Map<String, Integer> ignoredUserServices =
-        systemService.getIgnoredUserServices();
-    assertEquals(1, ignoredUserServices.size());
-    assertTrue(ignoredUserServices.containsKey(users[0]),
-        "User user1 doesn't exist.");
-    int count = ignoredUserServices.get(users[0]);
-    assertEquals(1, count);
-    assertEquals(1,
-        systemService.getBadFileNameExtensionSkipCounter());
-    assertEquals(1, systemService.getBadDirSkipCounter());
-
-    Map<String, Set<Service>> userServices =
-        systemService.getSyncUserServices();
-    assertEquals(loadedServices.size(), userServices.size());
-    verifyForScannedUserServices(userServices);
-
-    verifyForLaunchedUserServices();
-
-    // 2nd time launch service to handle if service exist scenario
-    systemService.launchUserService(userServices);
-    verifyForLaunchedUserServices();
-
-    // verify start of stopped services
-    submittedServices.clear();
-    systemService.launchUserService(userServices);
-    verifyForLaunchedUserServices();
-  }
-
-  private void verifyForScannedUserServices(
-      Map<String, Set<Service>> userServices) {
-    for (String user : users) {
-      Set<Service> services = userServices.get(user);
-      Set<String> serviceNames = loadedServices.get(user);
-      assertEquals(serviceNames.size(), services.size());
-      Iterator<Service> iterator = services.iterator();
-      while (iterator.hasNext()) {
-        Service next = iterator.next();
-        assertTrue(serviceNames.contains(next.getName()),
-            "Service name doesn't exist in expected userService " + serviceNames);
-      }
-    }
-  }
-
-  public void constructUserService(String user, String... serviceNames) {
-    Set<String> service = loadedServices.get(user);
-    if (service == null) {
-      service = new HashSet<>();
-      for (String serviceName : serviceNames) {
-        service.add(serviceName);
-      }
-      loadedServices.put(user, service);
-    }
-  }
-
-  class TestServiceClient extends ServiceClient {
-    @Override
-    protected void serviceStart() throws Exception {
-      // do nothing
-    }
-
-    @Override
-    protected void serviceStop() throws Exception {
-      // do nothing
-    }
-
-    @Override
-    protected void serviceInit(Configuration configuration)
-        throws Exception {
-      // do nothing
-    }
-
-    @Override
-    public int actionBuild(Service service)
-        throws YarnException, IOException {
-      String userName =
-          UserGroupInformation.getCurrentUser().getShortUserName();
-      Set<String> services = savedServices.get(userName);
-      if (services == null) {
-        services = new HashSet<>();
-        savedServices.put(userName, services);
-      }
-      if (services.contains(service.getName())) {
-        String message = "Failed to save service " + service.getName()
-            + ", because it already exists.";
-        throw new SliderException(SliderExitCodes.EXIT_INSTANCE_EXISTS,
-            message);
-      }
-      services.add(service.getName());
-      return 0;
-    }
-
-    @Override
-    public ApplicationId actionStartAndGetId(String serviceName)
-        throws YarnException, IOException {
-      String userName =
-          UserGroupInformation.getCurrentUser().getShortUserName();
-      Set<String> services = submittedServices.get(userName);
-      if (services == null) {
-        services = new HashSet<>();
-        submittedServices.put(userName, services);
-      }
-      if (services.contains(serviceName)) {
-        String message = "Failed to create service " + serviceName
-            + ", because it is already running.";
-        throw new YarnException(message);
-      }
-      services.add(serviceName);
-      return ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    }
-  }
-
-  private void verifyForLaunchedUserServices() {
-    assertEquals(loadedServices.size(), submittedServices.size());
-    for (Map.Entry<String, Set<String>> entry : submittedServices.entrySet()) {
-      String user = entry.getKey();
-      Set<String> serviceSet = entry.getValue();
-      assertTrue(loadedServices.containsKey(user));
-      Set<String> services = loadedServices.get(user);
-      assertEquals(services.size(), serviceSet.size());
-      assertTrue(services.containsAll(serviceSet));
-    }
-  }
-
-  @Test
-  void testFileSystemCloseWhenCleanUpService() throws Exception {
-    FileSystem fs = null;
-    Path path = new Path("/tmp/servicedir");
-
-    HdfsConfiguration hdfsConfig = new HdfsConfiguration();
-    MiniDFSCluster hdfsCluster = new MiniDFSCluster.Builder(hdfsConfig)
-        .numDataNodes(1).build();
-
-    fs = hdfsCluster.getFileSystem();
-    if (!fs.exists(path)) {
-      fs.mkdirs(path);
-    }
-
-    SystemServiceManagerImpl serviceManager = new SystemServiceManagerImpl();
-
-    hdfsConfig.set(YarnServiceConf.YARN_SERVICES_SYSTEM_SERVICE_DIRECTORY,
-        path.toString());
-    serviceManager.init(hdfsConfig);
-
-    // the FileSystem object owned by SystemServiceManager must not be closed
-    // when cleanup a service
-    hdfsConfig.set("hadoop.registry.zk.connection.timeout.ms", "100");
-    hdfsConfig.set("hadoop.registry.zk.retry.times", "1");
-    ApiServiceClient asc = new ApiServiceClient();
-    asc.serviceInit(hdfsConfig);
-    asc.actionCleanUp("testapp", "testuser");
-
-    try {
-      serviceManager.start();
-    } catch (Exception e) {
-      if (e.getMessage().contains("Filesystem closed")) {
-        fail("SystemServiceManagerImpl failed to handle " +
-            "FileSystem close");
-      } else {
-        fail("Should not get any exceptions");
-      }
-    } finally {
-      serviceManager.stop();
-      fs = hdfsCluster.getFileSystem();
-      if (fs.exists(path)) {
-        fs.delete(path, true);
-      }
-      if (hdfsCluster != null) {
-        hdfsCluster.shutdown();
-      }
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/example-app.json b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/example-app.json
deleted file mode 100644
index a2f41cf3cc5..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/example-app.json
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-  "name": "example-app",
-  "version": "1.0.0",
-  "components" :
-  [
-    {
-      "name": "simple",
-      "number_of_containers": 1,
-      "launch_command": "sleep 2",
-      "resource": {
-        "cpus": 1,
-        "memory": "128"
-      }
-    }
-  ]
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/log4j.properties b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/log4j.properties
deleted file mode 100644
index 81a3f6ad5d2..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/log4j.properties
+++ /dev/null
@@ -1,19 +0,0 @@
-#   Licensed under the Apache License, Version 2.0 (the "License");
-#   you may not use this file except in compliance with the License.
-#   You may obtain a copy of the License at
-#
-#       http://www.apache.org/licenses/LICENSE-2.0
-#
-#   Unless required by applicable law or agreed to in writing, software
-#   distributed under the License is distributed on an "AS IS" BASIS,
-#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-#   See the License for the specific language governing permissions and
-#   limitations under the License.
-
-# log4j configuration used during build and unit tests
-
-log4j.rootLogger=info,stdout
-log4j.threshold=ALL
-log4j.appender.stdout=org.apache.log4j.ConsoleAppender
-log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
-log4j.appender.stdout.layout.ConversionPattern=%d{ISO8601} %-5p [%t] %c{2} (%F:%M(%L)) - %m%n
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/bad/bad.yarnfile b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/bad/bad.yarnfile
deleted file mode 100644
index 1d514d665fb..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/bad/bad.yarnfile
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-  "name": "bad",
-  "version": "1.0.0",
-  "components" :
-  [
-    {
-      "name": "simple",
-      "number_of_containers": 1,
-      "launch_command": "sleep 2",
-      "resource": {
-        "cpus": 1,
-        "memory": "128"
-      }
-    }
-  ]
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user1/example-app1.yarnfile b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user1/example-app1.yarnfile
deleted file mode 100644
index 823561d8598..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user1/example-app1.yarnfile
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-  "name": "example-app1",
-  "version": "1.0.0",
-  "components" :
-  [
-    {
-      "name": "simple",
-      "number_of_containers": 1,
-      "launch_command": "sleep 2",
-      "resource": {
-        "cpus": 1,
-        "memory": "128"
-      }
-    }
-  ]
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user1/example-app2.yarnfile b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user1/example-app2.yarnfile
deleted file mode 100644
index 823561d8598..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user1/example-app2.yarnfile
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-  "name": "example-app1",
-  "version": "1.0.0",
-  "components" :
-  [
-    {
-      "name": "simple",
-      "number_of_containers": 1,
-      "launch_command": "sleep 2",
-      "resource": {
-        "cpus": 1,
-        "memory": "128"
-      }
-    }
-  ]
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user1/example-app3.json b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user1/example-app3.json
deleted file mode 100644
index 8a3a5612392..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user1/example-app3.json
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-  "name": "example-app3",
-  "version": "1.0.0",
-  "components" :
-  [
-    {
-      "name": "simple",
-      "number_of_containers": 1,
-      "launch_command": "sleep 2",
-      "resource": {
-        "cpus": 1,
-        "memory": "128"
-      }
-    }
-  ]
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user2/example-app1.yarnfile b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user2/example-app1.yarnfile
deleted file mode 100644
index 823561d8598..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user2/example-app1.yarnfile
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-  "name": "example-app1",
-  "version": "1.0.0",
-  "components" :
-  [
-    {
-      "name": "simple",
-      "number_of_containers": 1,
-      "launch_command": "sleep 2",
-      "resource": {
-        "cpus": 1,
-        "memory": "128"
-      }
-    }
-  ]
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user2/example-app2.yarnfile b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user2/example-app2.yarnfile
deleted file mode 100644
index d8fd1d12fca..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/system-services/sync/user2/example-app2.yarnfile
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-  "name": "example-app2",
-  "version": "1.0.0",
-  "components" :
-  [
-    {
-      "name": "simple",
-      "number_of_containers": 1,
-      "launch_command": "sleep 2",
-      "resource": {
-        "cpus": 1,
-        "memory": "128"
-      }
-    }
-  ]
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/yarn-site.xml b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/yarn-site.xml
deleted file mode 100644
index daac23adcd4..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-api/src/test/resources/yarn-site.xml
+++ /dev/null
@@ -1,19 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
-<!--
-  Licensed under the Apache License, Version 2.0 (the "License");
-  you may not use this file except in compliance with the License.
-  You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License. See accompanying LICENSE file.
--->
-
-<configuration>
-  <!-- Dummy (invalid) config file to be overwritten by ServiceTestUtils with MiniCluster configuration. -->
-</configuration>
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/conf/yarnservice-log4j.properties b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/conf/yarnservice-log4j.properties
deleted file mode 100644
index 58c8e27133a..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/conf/yarnservice-log4j.properties
+++ /dev/null
@@ -1,62 +0,0 @@
-# Licensed to the Apache Software Foundation (ASF) under one
-#  or more contributor license agreements.  See the NOTICE file
-#  distributed with this work for additional information
-#  regarding copyright ownership.  The ASF licenses this file
-#  to you under the Apache License, Version 2.0 (the
-#  "License"); you may not use this file except in compliance
-#  with the License.  You may obtain a copy of the License at
-#
-#       http://www.apache.org/licenses/LICENSE-2.0
-#
-#  Unless required by applicable law or agreed to in writing, software
-#  distributed under the License is distributed on an "AS IS" BASIS,
-#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-#  See the License for the specific language governing permissions and
-#  limitations under the License.
-#
-
-# This is the log4j configuration for Slider Application Master
-
-# Log rotation based on size (256MB) with a max of 20 backup files
-log4j.rootLogger=INFO, amlog
-log4j.threshhold=ALL
-log4j.appender.amlog=org.apache.log4j.RollingFileAppender
-log4j.appender.amlog.layout=org.apache.log4j.PatternLayout
-log4j.appender.amlog.File=${LOG_DIR}/serviceam.log
-log4j.appender.amlog.MaxFileSize=256MB
-log4j.appender.amlog.MaxBackupIndex=20
-
-# log layout skips stack-trace creation operations by avoiding line numbers and method
-log4j.appender.amlog.layout.ConversionPattern=%d{ISO8601} [%t] %-5p %c{2} - %m%n
-
-# debug edition is much more expensive
-#log4j.appender.amlog.layout.ConversionPattern=%d{ISO8601} [%t] %-5p %c{2} (%F:%M(%L)) - %m%n
-
-# configure stderr
-# set the conversion pattern of stderr
-# Print the date in ISO 8601 format
-log4j.appender.stderr=org.apache.log4j.ConsoleAppender
-log4j.appender.stderr.Target=System.err
-log4j.appender.stderr.layout=org.apache.log4j.PatternLayout
-log4j.appender.stderr.layout.ConversionPattern=%d{ISO8601} [%t] %-5p %c{2} - %m%n
-
-log4j.appender.subprocess=org.apache.log4j.ConsoleAppender
-log4j.appender.subprocess.layout=org.apache.log4j.PatternLayout
-log4j.appender.subprocess.layout.ConversionPattern=[%c{1}]: %m%n
-
-# for debugging yarn-service framework
-#log4j.logger.org.apache.hadoop.yarn.service=DEBUG
-
-# uncomment for YARN operations
-#log4j.logger.org.apache.hadoop.yarn.client=DEBUG
-
-# uncomment this to debug security problems
-#log4j.logger.org.apache.hadoop.security=DEBUG
-
-#crank back on some noise
-log4j.logger.org.apache.hadoop.util.NativeCodeLoader=ERROR
-log4j.logger.org.apache.hadoop.hdfs=WARN
-
-log4j.logger.org.apache.zookeeper=WARN
-log4j.logger.org.apache.curator.framework.state=ERROR
-log4j.logger.org.apache.curator.framework.imps=WARN
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/appcatalog/appcatalog.json b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/appcatalog/appcatalog.json
deleted file mode 100755
index 6a5f2f36a61..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/appcatalog/appcatalog.json
+++ /dev/null
@@ -1,28 +0,0 @@
-{
-  "name": "appcatalog",
-  "version": "1",
-  "components" :
-  [
-    {
-      "name": "catalog",
-      "number_of_containers": 1,
-      "artifact": {
-        "id": "apache/hadoop-yarn-applications-catalog-docker:3.3.0-SNAPSHOT",
-        "type": "DOCKER"
-      },
-      "resource": {
-        "cpus": 1,
-        "memory": "2048"
-      },
-      "configuration": {
-        "env": {
-          "YARN_CONTAINER_RUNTIME_DOCKER_RUN_OVERRIDE_DISABLE":"true",
-          "YARN_CONTAINER_RUNTIME_DOCKER_MOUNTS":"/etc/hadoop/conf:/etc/hadoop/conf:ro,/var/lib/sss/pipes:/var/lib/sss/pipes:rw",
-          "JAVA_HOME":"/usr/lib/jvm/jre-1.8.0"
-        },
-        "properties": {
-        }
-      }
-    }
-  ]
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/httpd-no-dns/httpd-no-dns.json b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/httpd-no-dns/httpd-no-dns.json
deleted file mode 100644
index b8098848b35..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/httpd-no-dns/httpd-no-dns.json
+++ /dev/null
@@ -1,63 +0,0 @@
-{
-  "name": "httpd-service-no-dns",
-  "version": "1.0.0",
-  "lifetime": "3600",
-  "components": [
-    {
-      "name": "httpd",
-      "number_of_containers": 2,
-      "artifact": {
-        "id": "centos/httpd-24-centos7:latest",
-        "type": "DOCKER"
-      },
-      "launch_command": "/usr/bin/run-httpd",
-      "resource": {
-        "cpus": 1,
-        "memory": "1024"
-      },
-      "readiness_check": {
-        "type": "HTTP",
-        "properties": {
-          "url": "http://${THIS_HOST}:8080"
-        }
-      },
-      "configuration": {
-        "files": [
-          {
-            "type": "TEMPLATE",
-            "dest_file": "/var/www/html/index.html",
-            "properties": {
-              "content": "<html><header><title>Title</title></header><body>Hello from ${COMPONENT_INSTANCE_NAME}!</body></html>"
-            }
-          }
-        ]
-      }
-    },
-    {
-      "name": "httpd-proxy",
-      "number_of_containers": 1,
-      "dependencies": [ "httpd" ],
-      "artifact": {
-        "id": "centos/httpd-24-centos7:latest",
-        "type": "DOCKER"
-      },
-      "launch_command": "/usr/bin/run-httpd",
-      "resource": {
-        "cpus": 1,
-        "memory": "1024"
-      },
-      "configuration": {
-        "files": [
-          {
-            "type": "TEMPLATE",
-            "dest_file": "/etc/httpd/conf.d/httpd-proxy.conf",
-            "src_file": "httpd-proxy-no-dns.conf"
-          }
-        ]
-      }
-    }
-  ],
-  "quicklinks": {
-    "Apache HTTP Server": "http://httpd-proxy-0.${SERVICE_NAME}.${USER}.${DOMAIN}:8080"
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/httpd-no-dns/httpd-proxy-no-dns.conf b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/httpd-no-dns/httpd-proxy-no-dns.conf
deleted file mode 100644
index 9894e64d508..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/httpd-no-dns/httpd-proxy-no-dns.conf
+++ /dev/null
@@ -1,24 +0,0 @@
-#
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-<Proxy balancer://test>
-  BalancerMember http://${HTTPD-0_IP}:8080
-  BalancerMember http://${HTTPD-1_IP}:8080
-  ProxySet lbmethod=bytraffic
-</Proxy>
-
-ProxyPass "/"  "balancer://test/"
-ProxyPassReverse "/"  "balancer://test/"
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/httpd/httpd-proxy.conf b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/httpd/httpd-proxy.conf
deleted file mode 100644
index e8651a5c6cd..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/httpd/httpd-proxy.conf
+++ /dev/null
@@ -1,24 +0,0 @@
-#
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the "License"); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an "AS IS" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-<Proxy balancer://test>
-  BalancerMember http://httpd-0.${SERVICE_NAME}.${USER}.${DOMAIN}:8080
-  BalancerMember http://httpd-1.${SERVICE_NAME}.${USER}.${DOMAIN}:8080
-  ProxySet lbmethod=bytraffic
-</Proxy>
-
-ProxyPass "/"  "balancer://test/"
-ProxyPassReverse "/"  "balancer://test/"
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/httpd/httpd.json b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/httpd/httpd.json
deleted file mode 100644
index 849cacca345..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/httpd/httpd.json
+++ /dev/null
@@ -1,56 +0,0 @@
-{
-  "name": "httpd-service",
-  "version": "1.0.0",
-  "lifetime": "3600",
-  "components": [
-    {
-      "name": "httpd",
-      "number_of_containers": 2,
-      "artifact": {
-        "id": "centos/httpd-24-centos7:latest",
-        "type": "DOCKER"
-      },
-      "launch_command": "/usr/bin/run-httpd",
-      "resource": {
-        "cpus": 1,
-        "memory": "1024"
-      },
-      "configuration": {
-        "files": [
-          {
-            "type": "TEMPLATE",
-            "dest_file": "/var/www/html/index.html",
-            "properties": {
-              "content": "<html><header><title>Title</title></header><body>Hello from ${COMPONENT_INSTANCE_NAME}!</body></html>"
-            }
-          }
-        ]
-      }
-    },
-    {
-      "name": "httpd-proxy",
-      "number_of_containers": 1,
-      "artifact": {
-        "id": "centos/httpd-24-centos7:latest",
-        "type": "DOCKER"
-      },
-      "launch_command": "/usr/bin/run-httpd",
-      "resource": {
-        "cpus": 1,
-        "memory": "1024"
-      },
-      "configuration": {
-        "files": [
-          {
-            "type": "TEMPLATE",
-            "dest_file": "/etc/httpd/conf.d/httpd-proxy.conf",
-            "src_file": "httpd-proxy.conf"
-          }
-        ]
-      }
-    }
-  ],
-  "quicklinks": {
-    "Apache HTTP Server": "http://httpd-proxy-0.${SERVICE_NAME}.${USER}.${DOMAIN}:8080"
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/sleeper/sleeper.json b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/sleeper/sleeper.json
deleted file mode 100644
index 954c704c24f..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/examples/sleeper/sleeper.json
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-  "name": "sleeper-service",
-  "version": "1.0.0",
-  "components" :
-  [
-    {
-      "name": "sleeper",
-      "number_of_containers": 2,
-      "launch_command": "sleep 900000",
-      "resource": {
-        "cpus": 1,
-        "memory": "256"
-      }
-    }
-  ]
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/pom.xml b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/pom.xml
deleted file mode 100644
index de41abcd74b..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/pom.xml
+++ /dev/null
@@ -1,279 +0,0 @@
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more
-   contributor license agreements.  See the NOTICE file distributed with
-   this work for additional information regarding copyright ownership.
-   The ASF licenses this file to You under the Apache License, Version 2.0
-   (the "License"); you may not use this file except in compliance with
-   the License.  You may obtain a copy of the License at
-
-       http://www.apache.org/licenses/LICENSE-2.0
-
-   Unless required by applicable law or agreed to in writing, software
-   distributed under the License is distributed on an "AS IS" BASIS,
-   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-   See the License for the specific language governing permissions and
-   limitations under the License.
--->
-<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 https://maven.apache.org/maven-v4_0_0.xsd">
-  <modelVersion>4.0.0</modelVersion>
-  <parent>
-    <groupId>org.apache.hadoop</groupId>
-    <artifactId>hadoop-yarn-services</artifactId>
-    <version>3.4.0</version>
-  </parent>
-  <artifactId>hadoop-yarn-services-core</artifactId>
-  <packaging>jar</packaging>
-  <name>Apache Hadoop YARN Services Core</name>
-
-  <properties>
-    <!-- Needed for generating FindBugs warnings using parent pom -->
-    <yarn.basedir>${project.parent.basedir}</yarn.basedir>
-  </properties>
-
-  <build>
-    <!-- resources are filtered for dynamic updates. This gets build info in-->
-    <resources>
-      <resource>
-        <directory>src/main/resources</directory>
-        <filtering>true</filtering>
-      </resource>
-    </resources>
-    
-    <plugins>
-      <plugin>
-        <groupId>org.xolstice.maven.plugins</groupId>
-        <artifactId>protobuf-maven-plugin</artifactId>
-        <executions>
-          <execution>
-            <id>src-compile-protoc</id>
-            <configuration>
-              <skip>false</skip>
-            </configuration>
-          </execution>
-        </executions>
-      </plugin>
-      <plugin>
-        <groupId>com.google.code.maven-replacer-plugin</groupId>
-        <artifactId>replacer</artifactId>
-        <executions>
-          <execution>
-            <id>replace-generated-sources</id>
-            <configuration>
-              <skip>false</skip>
-            </configuration>
-          </execution>
-          <execution>
-            <id>replace-sources</id>
-            <configuration>
-              <skip>false</skip>
-            </configuration>
-          </execution>
-          <execution>
-            <id>replace-test-sources</id>
-            <configuration>
-              <skip>false</skip>
-            </configuration>
-          </execution>
-        </executions>
-      </plugin>
-      <plugin>
-        <groupId>org.apache.maven.plugins</groupId>
-        <artifactId>maven-jar-plugin</artifactId>
-        <executions>
-          <execution>
-            <goals>
-              <goal>test-jar</goal>
-            </goals>
-          </execution>
-        </executions>
-      </plugin>
-
-      <plugin>
-        <groupId>org.apache.maven.plugins</groupId>
-        <artifactId>maven-surefire-plugin</artifactId>
-        <configuration>
-          <forkedProcessTimeoutInSeconds>1800</forkedProcessTimeoutInSeconds>
-          <environmentVariables>
-            <JAVA_HOME>${java.home}</JAVA_HOME>
-          </environmentVariables>
-        </configuration>
-      </plugin>
-
-      <plugin>
-        <groupId>org.apache.rat</groupId>
-        <artifactId>apache-rat-plugin</artifactId>
-        <configuration>
-          <excludes>
-            <exclude>**/*.json</exclude>
-          </excludes>
-        </configuration>
-      </plugin>
-
-    </plugins>
-  </build>
-  <dependencies>
-    <dependency>
-      <groupId>org.slf4j</groupId>
-      <artifactId>slf4j-api</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>ch.qos.reload4j</groupId>
-      <artifactId>reload4j</artifactId>
-      <scope>runtime</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop.thirdparty</groupId>
-      <artifactId>hadoop-shaded-guava</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>com.fasterxml.jackson.core</groupId>
-      <artifactId>jackson-databind</artifactId>
-    </dependency>
-    <dependency>
-      <groupId>com.fasterxml.jackson.core</groupId>
-      <artifactId>jackson-annotations</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-hdfs-client</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-client</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-registry</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-common</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-server-common</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-common</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-annotations</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-api</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-hdfs</artifactId>
-      <exclusions>
-        <exclusion>
-          <groupId>org.ow2.asm</groupId>
-          <artifactId>asm-commons</artifactId>
-        </exclusion>
-      </exclusions>
-    </dependency>
-
-    <dependency>
-      <groupId>com.google.protobuf</groupId>
-      <artifactId>protobuf-java</artifactId>
-      <scope>${transient.protobuf2.scope}</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.commons</groupId>
-      <artifactId>commons-configuration2</artifactId>
-      <exclusions>
-        <exclusion>
-          <groupId>javax.servlet</groupId>
-          <artifactId>servlet-api</artifactId>
-        </exclusion>
-      </exclusions>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.commons</groupId>
-      <artifactId>commons-compress</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>commons-io</groupId>
-      <artifactId>commons-io</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.curator</groupId>
-      <artifactId>curator-client</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.curator</groupId>
-      <artifactId>curator-framework</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>javax.xml.bind</groupId>
-      <artifactId>jaxb-api</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.yaml</groupId>
-      <artifactId>snakeyaml</artifactId>
-    </dependency>
-
-    <dependency>
-        <groupId>io.swagger</groupId>
-        <artifactId>swagger-annotations</artifactId>
-    </dependency>
-
-    <!-- ======================================================== -->
-    <!-- Test dependencies -->
-    <!-- ======================================================== -->
-
-    <dependency>
-      <groupId>junit</groupId>
-      <artifactId>junit</artifactId>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.mockito</groupId>
-      <artifactId>mockito-core</artifactId>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-minicluster</artifactId>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.curator</groupId>
-      <artifactId>curator-test</artifactId>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.assertj</groupId>
-      <artifactId>assertj-core</artifactId>
-      <scope>test</scope>
-    </dependency>
-
-  </dependencies>
-
-</project>
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ClientAMPolicyProvider.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ClientAMPolicyProvider.java
deleted file mode 100644
index 365df0fabcd..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ClientAMPolicyProvider.java
+++ /dev/null
@@ -1,39 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import org.apache.hadoop.security.authorize.PolicyProvider;
-import org.apache.hadoop.security.authorize.Service;
-
-/**
- * PolicyProvider for Client to Service AM protocol.
- */
-public class ClientAMPolicyProvider extends PolicyProvider {
-
-  private static final Service[] CLIENT_AM_SERVICE =
-      new Service[]{
-          new Service(
-              "security.yarn-service.client-am-protocol.acl",
-              ClientAMProtocol.class)};
-
-  @Override
-  public Service[] getServices() {
-    return CLIENT_AM_SERVICE;
-  };
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ClientAMProtocol.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ClientAMProtocol.java
deleted file mode 100644
index e43e6fbf47e..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ClientAMProtocol.java
+++ /dev/null
@@ -1,74 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CancelUpgradeRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CancelUpgradeResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CompInstancesUpgradeResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CompInstancesUpgradeRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.DecommissionCompInstancesRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.DecommissionCompInstancesResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.FlexComponentsRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.FlexComponentsResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetCompInstancesRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetCompInstancesResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetStatusResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetStatusRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.RestartServiceRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.RestartServiceResponseProto;
-
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.StopResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.StopRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.UpgradeServiceRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.UpgradeServiceResponseProto;
-
-
-import java.io.IOException;
-
-public interface ClientAMProtocol {
-  FlexComponentsResponseProto flexComponents(FlexComponentsRequestProto request)
-      throws IOException, YarnException;
-
-  GetStatusResponseProto getStatus(GetStatusRequestProto requestProto)
-      throws IOException, YarnException;
-
-  StopResponseProto stop(StopRequestProto requestProto)
-      throws IOException, YarnException;
-
-  UpgradeServiceResponseProto upgrade(UpgradeServiceRequestProto request)
-      throws IOException, YarnException;
-
-  RestartServiceResponseProto restart(RestartServiceRequestProto request)
-      throws IOException, YarnException;
-
-  CompInstancesUpgradeResponseProto upgrade(
-      CompInstancesUpgradeRequestProto request) throws IOException,
-      YarnException;
-
-  GetCompInstancesResponseProto getCompInstances(
-      GetCompInstancesRequestProto request) throws IOException, YarnException;
-
-  CancelUpgradeResponseProto cancelUpgrade(
-      CancelUpgradeRequestProto request) throws IOException, YarnException;
-
-  DecommissionCompInstancesResponseProto decommissionCompInstances(
-      DecommissionCompInstancesRequestProto request) throws IOException,
-      YarnException;
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ClientAMSecurityInfo.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ClientAMSecurityInfo.java
deleted file mode 100644
index e19284bf12f..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ClientAMSecurityInfo.java
+++ /dev/null
@@ -1,62 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.security.KerberosInfo;
-import org.apache.hadoop.security.SecurityInfo;
-import org.apache.hadoop.security.token.TokenInfo;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConstants;
-import org.apache.hadoop.yarn.service.impl.pb.service.ClientAMProtocolPB;
-
-import java.lang.annotation.Annotation;
-
-/**
- * Security Info for Client to Service AM protocol.
- */
-public class ClientAMSecurityInfo extends SecurityInfo{
-  @Override
-  public KerberosInfo getKerberosInfo(Class<?> protocol, Configuration conf) {
-    if (!protocol.equals(ClientAMProtocolPB.class)) {
-      return null;
-    }
-    return new KerberosInfo() {
-
-      @Override
-      public Class<? extends Annotation> annotationType() {
-        return null;
-      }
-
-      @Override
-      public String serverPrincipal() {
-        return YarnServiceConstants.PRINCIPAL;
-      }
-
-      @Override
-      public String clientPrincipal() {
-        return null;
-      }
-    };
-  }
-
-  @Override
-  public TokenInfo getTokenInfo(Class<?> protocol, Configuration conf) {
-    return null;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ClientAMService.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ClientAMService.java
deleted file mode 100644
index 2a9bf8d5d97..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ClientAMService.java
+++ /dev/null
@@ -1,253 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import org.apache.hadoop.classification.VisibleForTesting;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.CommonConfigurationKeysPublic;
-import org.apache.hadoop.ipc.Server;
-import org.apache.hadoop.net.NetUtils;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.service.AbstractService;
-import org.apache.hadoop.util.ExitUtil;
-import org.apache.hadoop.yarn.api.ApplicationConstants;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.ipc.YarnRPC;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CancelUpgradeRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CancelUpgradeResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CompInstancesUpgradeRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CompInstancesUpgradeResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.ComponentCountProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.DecommissionCompInstancesRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.DecommissionCompInstancesResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.FlexComponentsRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.FlexComponentsResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetCompInstancesRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetCompInstancesResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetStatusRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetStatusResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.RestartServiceRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.RestartServiceResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.StopRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.StopResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.UpgradeServiceRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.UpgradeServiceResponseProto;
-import org.apache.hadoop.yarn.service.api.records.ComponentContainers;
-import org.apache.hadoop.yarn.service.component.ComponentEvent;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEvent;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEventType;
-import org.apache.hadoop.yarn.service.exceptions.BadClusterStateException;
-import org.apache.hadoop.yarn.service.utils.FilterUtils;
-import org.apache.hadoop.yarn.service.utils.ServiceApiUtil;
-import org.apache.hadoop.yarn.service.utils.ServiceUtils;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.net.InetSocketAddress;
-import java.util.List;
-
-import static org.apache.hadoop.yarn.service.component.ComponentEventType.DECOMMISSION_INSTANCE;
-import static org.apache.hadoop.yarn.service.component.ComponentEventType.FLEX;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.YARN_SERVICE_AM_CLIENT_PORT_RANGE;
-
-public class ClientAMService extends AbstractService
-    implements ClientAMProtocol {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(ClientAMService.class);
-
-  private ServiceContext context;
-  private Server server;
-
-  private InetSocketAddress bindAddress;
-
-  public ClientAMService(ServiceContext context) {
-    super("Client AM Service");
-    this.context = context;
-  }
-
-  @Override protected void serviceStart() throws Exception {
-    Configuration conf = getConfig();
-    YarnRPC rpc = YarnRPC.create(conf);
-    String nodeHostString = getNMHostName();
-
-    InetSocketAddress address = new InetSocketAddress(nodeHostString, 0);
-    server = rpc.getServer(ClientAMProtocol.class, this, address, conf,
-        context.secretManager, 1, YARN_SERVICE_AM_CLIENT_PORT_RANGE);
-
-    // Enable service authorization?
-    if (conf.getBoolean(
-        CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION,
-        false)) {
-      this.server.refreshServiceAcl(getConfig(), new ClientAMPolicyProvider());
-    }
-
-    server.start();
-
-    bindAddress = NetUtils.createSocketAddrForHost(nodeHostString,
-        server.getListenerAddress().getPort());
-
-    LOG.info("Instantiated ClientAMService at " + bindAddress);
-    super.serviceStart();
-  }
-
-  @VisibleForTesting
-  String getNMHostName() throws BadClusterStateException {
-    return ServiceUtils.mandatoryEnvVariable(
-        ApplicationConstants.Environment.NM_HOST.name());
-  }
-
-  @Override protected void serviceStop() throws Exception {
-    if (server != null) {
-      server.stop();
-    }
-    super.serviceStop();
-  }
-
-  @Override public FlexComponentsResponseProto flexComponents(
-      FlexComponentsRequestProto request) throws IOException {
-    if (!request.getComponentsList().isEmpty()) {
-      for (ComponentCountProto component : request.getComponentsList()) {
-        ComponentEvent event = new ComponentEvent(component.getName(), FLEX)
-            .setDesired(component.getNumberOfContainers());
-        context.scheduler.getDispatcher().getEventHandler().handle(event);
-        LOG.info("Flexing component {} to {}", component.getName(),
-            component.getNumberOfContainers());
-      }
-    }
-    return FlexComponentsResponseProto.newBuilder().build();
-  }
-
-  @Override
-  public GetStatusResponseProto getStatus(GetStatusRequestProto request)
-      throws IOException, YarnException {
-    String stat = ServiceApiUtil.jsonSerDeser.toJson(context.service);
-    return GetStatusResponseProto.newBuilder().setStatus(stat).build();
-  }
-
-  @Override
-  public StopResponseProto stop(StopRequestProto requestProto)
-      throws IOException, YarnException {
-    LOG.info("Stop the service by {}", UserGroupInformation.getCurrentUser());
-    context.scheduler.getDiagnostics()
-        .append("Stopped by user " + UserGroupInformation.getCurrentUser());
-    context.scheduler.setGracefulStop(FinalApplicationStatus.ENDED);
-
-    // Stop the service in 2 seconds delay to make sure this rpc call is completed.
-    // shutdown hook will be executed which will stop AM gracefully.
-    Thread thread = new Thread() {
-      @Override
-      public void run() {
-        try {
-          Thread.sleep(2000);
-          ExitUtil.terminate(0);
-        } catch (InterruptedException e) {
-          LOG.error("Interrupted while stopping", e);
-        }
-      }
-    };
-    thread.start();
-    return StopResponseProto.newBuilder().build();
-  }
-
-  public InetSocketAddress getBindAddress() {
-    return bindAddress;
-  }
-
-  @Override
-  public UpgradeServiceResponseProto upgrade(
-      UpgradeServiceRequestProto request) throws IOException {
-    try {
-      LOG.info("Upgrading service to version {} by {}", request.getVersion(),
-          UserGroupInformation.getCurrentUser());
-      context.getServiceManager().processUpgradeRequest(request.getVersion(),
-          request.getAutoFinalize(), request.getExpressUpgrade());
-      return UpgradeServiceResponseProto.newBuilder().build();
-    } catch (Exception ex) {
-      return UpgradeServiceResponseProto.newBuilder().setError(ex.getMessage())
-          .build();
-    }
-  }
-
-  @Override
-  public RestartServiceResponseProto restart(RestartServiceRequestProto request)
-      throws IOException, YarnException {
-    ServiceEvent event = new ServiceEvent(ServiceEventType.START);
-    context.scheduler.getDispatcher().getEventHandler().handle(event);
-    LOG.info("Restart service by {}", UserGroupInformation.getCurrentUser());
-    return RestartServiceResponseProto.newBuilder().build();
-  }
-
-  @Override
-  public CompInstancesUpgradeResponseProto upgrade(
-      CompInstancesUpgradeRequestProto request)
-      throws IOException, YarnException {
-    if (!request.getContainerIdsList().isEmpty()) {
-
-      for (String containerId : request.getContainerIdsList()) {
-        ComponentInstanceEvent event =
-            new ComponentInstanceEvent(ContainerId.fromString(containerId),
-                ComponentInstanceEventType.UPGRADE);
-        LOG.info("Upgrade container {}", containerId);
-        context.scheduler.getDispatcher().getEventHandler().handle(event);
-      }
-    }
-    return CompInstancesUpgradeResponseProto.newBuilder().build();
-  }
-
-  @Override
-  public GetCompInstancesResponseProto getCompInstances(
-      GetCompInstancesRequestProto request) throws IOException {
-    List<ComponentContainers> containers = FilterUtils.filterInstances(context,
-        request);
-    return GetCompInstancesResponseProto.newBuilder().setCompInstances(
-        ServiceApiUtil.COMP_CONTAINERS_JSON_SERDE.toJson(containers.toArray(
-            new ComponentContainers[containers.size()]))).build();
-  }
-
-  @Override
-  public CancelUpgradeResponseProto cancelUpgrade(
-      CancelUpgradeRequestProto request) throws IOException, YarnException {
-    LOG.info("Cancel service upgrade by {}",
-        UserGroupInformation.getCurrentUser());
-    ServiceEvent event = new ServiceEvent(ServiceEventType.CANCEL_UPGRADE);
-    context.scheduler.getDispatcher().getEventHandler().handle(event);
-    return CancelUpgradeResponseProto.newBuilder().build();
-  }
-
-  @Override
-  public DecommissionCompInstancesResponseProto decommissionCompInstances(
-      DecommissionCompInstancesRequestProto request)
-      throws IOException, YarnException {
-    if (!request.getCompInstancesList().isEmpty()) {
-      for (String instance : request.getCompInstancesList()) {
-        String componentName = ServiceApiUtil.parseComponentName(instance);
-        ComponentEvent event = new ComponentEvent(componentName,
-            DECOMMISSION_INSTANCE).setInstanceName(instance);
-        context.scheduler.getDispatcher().getEventHandler().handle(event);
-        LOG.info("Decommissioning component {} instance {}", componentName,
-            instance);
-      }
-    }
-    return DecommissionCompInstancesResponseProto.newBuilder().build();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ContainerFailureTracker.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ContainerFailureTracker.java
deleted file mode 100644
index 5982728ca73..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ContainerFailureTracker.java
+++ /dev/null
@@ -1,92 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import org.apache.hadoop.yarn.service.component.Component;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConf;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.DEFAULT_NODE_BLACKLIST_THRESHOLD;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.NODE_BLACKLIST_THRESHOLD;
-
-/**
- * This tracks the container failures per node. If the failure counter exceeds
- * the maxFailurePerNode limit, it'll blacklist that node.
- *
- */
-public class ContainerFailureTracker {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(ContainerFailureTracker.class);
-
-  // Host -> num container failures
-  private Map<String, Integer> failureCountPerNode = new HashMap<>();
-  private Set<String> blackListedNodes = new HashSet<>();
-  private ServiceContext context;
-  private int maxFailurePerNode;
-  private Component component;
-
-  public ContainerFailureTracker(ServiceContext context, Component component) {
-    this.context = context;
-    this.component = component;
-    maxFailurePerNode = YarnServiceConf.getInt(NODE_BLACKLIST_THRESHOLD,
-        DEFAULT_NODE_BLACKLIST_THRESHOLD, component.getComponentSpec()
-        .getConfiguration(), context.scheduler.getConfig());
-  }
-
-
-  public synchronized void incNodeFailure(String host) {
-    int num = 0;
-    if (failureCountPerNode.containsKey(host)) {
-      num = failureCountPerNode.get(host);
-    }
-    num++;
-    failureCountPerNode.put(host, num);
-
-    // black list the node if exceed max failure
-    if (num > maxFailurePerNode && !blackListedNodes.contains(host)) {
-      List<String> blacklists = new ArrayList<>();
-      blacklists.add(host);
-      blackListedNodes.add(host);
-      context.scheduler.getAmRMClient().updateBlacklist(blacklists, null);
-      LOG.info("[COMPONENT {}]: Failed {} times on this host, blacklisted {}."
-              + " Current list of blacklisted nodes: {}",
-          component.getName(), num, host, blackListedNodes);
-    }
-  }
-
-  public synchronized void resetContainerFailures() {
-    // reset container failure counter per node
-    failureCountPerNode.clear();
-    context.scheduler.getAmRMClient()
-        .updateBlacklist(null, new ArrayList<>(blackListedNodes));
-    LOG.info("[COMPONENT {}]: Clearing blacklisted nodes {} ",
-        component.getName(), blackListedNodes);
-    blackListedNodes.clear();
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceContext.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceContext.java
deleted file mode 100644
index 2deffb8674f..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceContext.java
+++ /dev/null
@@ -1,63 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import org.apache.hadoop.util.Preconditions;
-import org.apache.hadoop.thirdparty.com.google.common.cache.LoadingCache;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
-import org.apache.hadoop.yarn.security.client.ClientToAMTokenSecretManager;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ConfigFile;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-
-import java.nio.ByteBuffer;
-
-public class ServiceContext {
-  public Service service = null;
-  public SliderFileSystem fs;
-  public String serviceHdfsDir = "";
-  public ApplicationAttemptId attemptId;
-  public LoadingCache<ConfigFile, Object> configCache;
-  public ServiceScheduler scheduler;
-  public ClientToAMTokenSecretManager secretManager;
-  public ClientAMService clientAMService;
-  // tokens used for container launch
-  public ByteBuffer tokens;
-  // AM keytab principal
-  public String principal;
-  // AM keytab location
-  public String keytab;
-  private ServiceManager serviceManager;
-
-  public ServiceContext() {
-
-  }
-
-  public ServiceManager getServiceManager() {
-    return serviceManager;
-  }
-
-  void setServiceManager(ServiceManager serviceManager) {
-    this.serviceManager = Preconditions.checkNotNull(serviceManager);
-  }
-
-  public Service getService() {
-    return service;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceEvent.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceEvent.java
deleted file mode 100644
index cf4455de378..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceEvent.java
+++ /dev/null
@@ -1,84 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import org.apache.hadoop.yarn.event.AbstractEvent;
-import org.apache.hadoop.yarn.service.api.records.Component;
-
-import java.util.List;
-
-/**
- * Events are handled by {@link ServiceManager} to manage the service
- * state.
- */
-public class ServiceEvent extends AbstractEvent<ServiceEventType> {
-
-  private final ServiceEventType type;
-  private String version;
-  private boolean autoFinalize;
-  private boolean expressUpgrade;
-  // For express upgrade they should be in order.
-  private List<Component> compsToUpgrade;
-
-  public ServiceEvent(ServiceEventType serviceEventType) {
-    super(serviceEventType);
-    this.type = serviceEventType;
-  }
-
-  public ServiceEventType getType() {
-    return type;
-  }
-
-  public String getVersion() {
-    return version;
-  }
-
-  public ServiceEvent setVersion(String version) {
-    this.version = version;
-    return this;
-  }
-
-  public boolean isAutoFinalize() {
-    return autoFinalize;
-  }
-
-  public ServiceEvent setAutoFinalize(boolean autoFinalize) {
-    this.autoFinalize = autoFinalize;
-    return this;
-  }
-
-  public boolean isExpressUpgrade() {
-    return expressUpgrade;
-  }
-
-  public ServiceEvent setExpressUpgrade(boolean expressUpgrade) {
-    this.expressUpgrade = expressUpgrade;
-    return this;
-  }
-
-  public List<Component> getCompsToUpgrade() {
-    return compsToUpgrade;
-  }
-
-  public ServiceEvent setCompsToUpgrade(List<Component> compsToUpgrade) {
-    this.compsToUpgrade = compsToUpgrade;
-    return this;
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceEventType.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceEventType.java
deleted file mode 100644
index 03afdd36f24..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceEventType.java
+++ /dev/null
@@ -1,29 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-/**
- * Types of {@link ServiceEvent}.
- */
-public enum ServiceEventType {
-  START,
-  UPGRADE,
-  CHECK_STABLE,
-  CANCEL_UPGRADE
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceManager.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceManager.java
deleted file mode 100644
index d37e5f0e205..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceManager.java
+++ /dev/null
@@ -1,520 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import org.apache.hadoop.classification.VisibleForTesting;
-import org.apache.hadoop.util.Preconditions;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.event.AsyncDispatcher;
-import org.apache.hadoop.yarn.event.EventHandler;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.component.Component;
-import org.apache.hadoop.yarn.service.component.ComponentEvent;
-import org.apache.hadoop.yarn.service.component.ComponentEventType;
-import org.apache.hadoop.yarn.service.component.ComponentRestartPolicy;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEvent;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEventType;
-import org.apache.hadoop.yarn.service.utils.ServiceApiUtil;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-import org.apache.hadoop.yarn.state.*;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.text.MessageFormat;
-import java.util.ArrayList;
-import java.util.EnumSet;
-import java.util.HashMap;
-import java.util.LinkedList;
-import java.util.List;
-import java.util.Map;
-import java.util.concurrent.locks.ReentrantReadWriteLock;
-
-import static org.apache.hadoop.yarn.service.utils.ServiceApiUtil.jsonSerDeser;
-
-/**
- * Manages the state of Service.
- */
-public class ServiceManager implements EventHandler<ServiceEvent> {
-  private static final Logger LOG = LoggerFactory.getLogger(
-      ServiceManager.class);
-
-  private final Service serviceSpec;
-  private final ServiceContext context;
-  private final ServiceScheduler scheduler;
-  private final ReentrantReadWriteLock.ReadLock readLock;
-  private final ReentrantReadWriteLock.WriteLock writeLock;
-
-  private final StateMachine<State, ServiceEventType, ServiceEvent>
-      stateMachine;
-  private final UpgradeComponentsFinder componentsFinder;
-
-  private final AsyncDispatcher dispatcher;
-  private final SliderFileSystem fs;
-
-  private String upgradeVersion;
-  private List<org.apache.hadoop.yarn.service.api.records
-      .Component> componentsToUpgrade;
-  private List<String> compsAffectedByUpgrade = new ArrayList<>();
-  private String cancelledVersion;
-
-  private static final StateMachineFactory<ServiceManager, State,
-      ServiceEventType, ServiceEvent> STATE_MACHINE_FACTORY =
-      new StateMachineFactory<ServiceManager, State,
-          ServiceEventType, ServiceEvent>(State.STABLE)
-
-          .addTransition(State.STABLE, EnumSet.of(State.STABLE,
-              State.UPGRADING), ServiceEventType.UPGRADE,
-              new StartUpgradeTransition())
-
-          .addTransition(State.STABLE, EnumSet.of(State.STABLE),
-              ServiceEventType.CHECK_STABLE, new CheckStableTransition())
-
-          .addTransition(State.UPGRADING, EnumSet.of(State.STABLE,
-              State.UPGRADING), ServiceEventType.START,
-              new StartFromUpgradeTransition())
-
-          .addTransition(State.UPGRADING, EnumSet.of(State.STABLE,
-              State.UPGRADING), ServiceEventType.CHECK_STABLE,
-              new CheckStableTransition())
-
-          .addTransition(State.UPGRADING, State.UPGRADING,
-              ServiceEventType.CANCEL_UPGRADE, new CancelUpgradeTransition())
-          .installTopology();
-
-  public ServiceManager(ServiceContext context) {
-    Preconditions.checkNotNull(context);
-    this.context = context;
-    serviceSpec = context.service;
-    scheduler = context.scheduler;
-    stateMachine = STATE_MACHINE_FACTORY.make(this);
-    dispatcher = scheduler.getDispatcher();
-
-    ReentrantReadWriteLock lock = new ReentrantReadWriteLock();
-    readLock = lock.readLock();
-    writeLock = lock.writeLock();
-    fs = context.fs;
-    componentsFinder = new UpgradeComponentsFinder
-        .DefaultUpgradeComponentsFinder();
-  }
-
-  @Override
-  public void handle(ServiceEvent event) {
-    writeLock.lock();
-    try {
-      State oldState = getState();
-      try {
-        stateMachine.doTransition(event.getType(), event);
-      } catch (InvalidStateTransitionException e) {
-        LOG.error(MessageFormat.format(
-            "[SERVICE]: Invalid event {1} at {2}.", event.getType(),
-            oldState), e);
-      }
-      if (oldState != getState()) {
-        LOG.info("[SERVICE] Transitioned from {} to {} on {} event.",
-            oldState, getState(), event.getType());
-      }
-    } finally {
-      writeLock.unlock();
-    }
-  }
-
-  private State getState() {
-    this.readLock.lock();
-    try {
-      return this.stateMachine.getCurrentState();
-    } finally {
-      this.readLock.unlock();
-    }
-  }
-
-  private static class StartUpgradeTransition implements
-      MultipleArcTransition<ServiceManager, ServiceEvent, State> {
-
-    @Override
-    public State transition(ServiceManager serviceManager,
-        ServiceEvent event) {
-      serviceManager.upgradeVersion = event.getVersion();
-      serviceManager.componentsToUpgrade = event.getCompsToUpgrade();
-      event.getCompsToUpgrade().forEach(comp ->
-          serviceManager.compsAffectedByUpgrade.add(comp.getName()));
-      try {
-        if (event.isExpressUpgrade()) {
-          serviceManager.dispatchNeedUpgradeEvents(false);
-          serviceManager.upgradeNextCompIfAny(false);
-        } else {
-          serviceManager.dispatchNeedUpgradeEvents(false);
-        }
-
-        if (event.isExpressUpgrade()) {
-          serviceManager.setServiceState(ServiceState.EXPRESS_UPGRADING);
-        } else if (event.isAutoFinalize()) {
-          serviceManager.setServiceState(ServiceState.UPGRADING_AUTO_FINALIZE);
-        } else {
-          serviceManager.setServiceState(ServiceState.UPGRADING);
-        }
-        ServiceApiUtil.checkServiceDependencySatisified(serviceManager
-            .getServiceSpec());
-        return State.UPGRADING;
-      } catch (Throwable e) {
-        LOG.error("[SERVICE]: Upgrade to version {} failed", event.getVersion(),
-            e);
-        return State.STABLE;
-      }
-    }
-  }
-
-  private static class CheckStableTransition implements
-      MultipleArcTransition<ServiceManager, ServiceEvent, State> {
-
-    @Override
-    public State transition(ServiceManager serviceManager,
-        ServiceEvent event) {
-      //trigger check of service state
-      ServiceState currState = serviceManager.serviceSpec.getState();
-      if (currState.equals(ServiceState.STABLE)) {
-        return State.STABLE;
-      }
-      if (currState.equals(ServiceState.EXPRESS_UPGRADING) ||
-          currState.equals(ServiceState.CANCEL_UPGRADING)) {
-
-        if (!serviceManager.componentsToUpgrade.isEmpty()) {
-          org.apache.hadoop.yarn.service.api.records.Component compSpec =
-              serviceManager.componentsToUpgrade.get(0);
-          Component component = serviceManager.scheduler.getAllComponents()
-              .get(compSpec.getName());
-
-          if (!component.isUpgrading()) {
-            serviceManager.componentsToUpgrade.remove(0);
-            serviceManager.upgradeNextCompIfAny(
-                currState.equals(ServiceState.CANCEL_UPGRADING));
-          }
-        }
-      }
-
-      if (currState.equals(ServiceState.UPGRADING_AUTO_FINALIZE) ||
-          ((currState.equals(ServiceState.EXPRESS_UPGRADING) ||
-              currState.equals(ServiceState.CANCEL_UPGRADING)) &&
-              serviceManager.componentsToUpgrade.isEmpty())) {
-
-        ServiceState targetState = checkIfStable(serviceManager.serviceSpec);
-        if (targetState.equals(ServiceState.STABLE)) {
-          if (serviceManager.finalizeUpgrade(
-              currState.equals(ServiceState.CANCEL_UPGRADING))) {
-            return State.STABLE;
-          }
-        }
-      }
-      return State.UPGRADING;
-    }
-  }
-
-  private static class StartFromUpgradeTransition implements
-      MultipleArcTransition<ServiceManager, ServiceEvent, State> {
-
-    @Override
-    public State transition(ServiceManager serviceManager, ServiceEvent event) {
-      ServiceState currState = serviceManager.serviceSpec.getState();
-
-      ServiceState targetState = checkIfStable(serviceManager.serviceSpec);
-      if (targetState.equals(ServiceState.STABLE)) {
-        if (serviceManager.finalizeUpgrade(
-            currState.equals(ServiceState.CANCEL_UPGRADING))) {
-          return State.STABLE;
-        }
-      }
-      return State.UPGRADING;
-    }
-  }
-
-  private static class CancelUpgradeTransition implements
-      SingleArcTransition<ServiceManager, ServiceEvent> {
-
-    @Override
-    public void transition(ServiceManager serviceManager,
-        ServiceEvent event) {
-      if (!serviceManager.getState().equals(State.UPGRADING)) {
-        LOG.info("[SERVICE]: Cannot cancel the upgrade in {} state",
-            serviceManager.getState());
-        return;
-      }
-      try {
-        Service targetSpec = ServiceApiUtil.loadService(
-            serviceManager.context.fs, serviceManager.getName());
-
-        Service sourceSpec = ServiceApiUtil.loadServiceUpgrade(
-            serviceManager.context.fs, serviceManager.getName(),
-            serviceManager.upgradeVersion);
-        serviceManager.cancelledVersion = serviceManager.upgradeVersion;
-        LOG.info("[SERVICE] cancel version {}",
-            serviceManager.cancelledVersion);
-        serviceManager.upgradeVersion = serviceManager.serviceSpec.getVersion();
-        serviceManager.componentsToUpgrade = serviceManager
-            .resolveCompsToUpgrade(sourceSpec, targetSpec);
-
-        serviceManager.compsAffectedByUpgrade.clear();
-        serviceManager.componentsToUpgrade.forEach(comp ->
-            serviceManager.compsAffectedByUpgrade.add(comp.getName()));
-
-        serviceManager.dispatchNeedUpgradeEvents(true);
-        serviceManager.upgradeNextCompIfAny(true);
-        serviceManager.setServiceState(ServiceState.CANCEL_UPGRADING);
-      } catch (Throwable e) {
-        LOG.error("[SERVICE]: Cancellation of upgrade failed", e);
-      }
-    }
-  }
-
-  private void upgradeNextCompIfAny(boolean cancelUpgrade) {
-    if (!componentsToUpgrade.isEmpty()) {
-      org.apache.hadoop.yarn.service.api.records.Component component =
-          componentsToUpgrade.get(0);
-
-      serviceSpec.getComponent(component.getName()).getContainers().forEach(
-          container -> {
-            ComponentInstanceEvent upgradeEvent = new ComponentInstanceEvent(
-                ContainerId.fromString(container.getId()),
-                !cancelUpgrade ? ComponentInstanceEventType.UPGRADE :
-                    ComponentInstanceEventType.CANCEL_UPGRADE);
-            LOG.info("Upgrade container {} {}", container.getId(),
-                cancelUpgrade);
-            dispatcher.getEventHandler().handle(upgradeEvent);
-          });
-    }
-  }
-
-  private void dispatchNeedUpgradeEvents(boolean cancelUpgrade) {
-    if (componentsToUpgrade != null) {
-      componentsToUpgrade.forEach(component -> {
-        ComponentEvent needUpgradeEvent = new ComponentEvent(
-            component.getName(), !cancelUpgrade ? ComponentEventType.UPGRADE :
-            ComponentEventType.CANCEL_UPGRADE)
-            .setTargetSpec(component)
-            .setUpgradeVersion(upgradeVersion);
-        LOG.info("Upgrade component {} {}", component.getName(), cancelUpgrade);
-        context.scheduler.getDispatcher().getEventHandler()
-            .handle(needUpgradeEvent);
-      });
-    }
-  }
-
-  /**
-   * @return whether finalization of upgrade was successful.
-   */
-  private boolean finalizeUpgrade(boolean cancelUpgrade) {
-    if (!cancelUpgrade) {
-      try {
-        // save the application id and state to
-        Service targetSpec = ServiceApiUtil.loadServiceUpgrade(
-            fs, getName(), upgradeVersion);
-        targetSpec.setId(serviceSpec.getId());
-        targetSpec.setState(ServiceState.STABLE);
-        Map<String, Component> allComps = scheduler.getAllComponents();
-        targetSpec.getComponents().forEach(compSpec -> {
-          Component comp = allComps.get(compSpec.getName());
-          compSpec.setState(comp.getComponentSpec().getState());
-        });
-        jsonSerDeser.save(fs.getFileSystem(),
-            ServiceApiUtil.getServiceJsonPath(fs, getName()), targetSpec, true);
-      } catch (IOException e) {
-        LOG.error("Upgrade did not complete because unable to re-write the" +
-            " service definition", e);
-        return false;
-      }
-    }
-
-    try {
-      String upgradeVersionToDel = cancelUpgrade? cancelledVersion :
-          upgradeVersion;
-      LOG.info("[SERVICE]: delete upgrade dir version {}", upgradeVersionToDel);
-      fs.deleteClusterUpgradeDir(getName(), upgradeVersionToDel);
-
-      for (String comp : compsAffectedByUpgrade) {
-        String compDirVersionToDel = cancelUpgrade? cancelledVersion :
-            serviceSpec.getVersion();
-        LOG.info("[SERVICE]: delete {} dir version {}",  comp,
-            compDirVersionToDel);
-        fs.deleteComponentDir(compDirVersionToDel, comp);
-      }
-
-      if (cancelUpgrade) {
-        fs.deleteComponentsVersionDirIfEmpty(cancelledVersion);
-      } else {
-        fs.deleteComponentsVersionDirIfEmpty(serviceSpec.getVersion());
-      }
-
-    } catch (IOException e) {
-      LOG.warn("Unable to delete upgrade definition for service {} " +
-          "version {}", getName(), upgradeVersion);
-    }
-    setServiceState(ServiceState.STABLE);
-    serviceSpec.setVersion(upgradeVersion);
-    upgradeVersion = null;
-    cancelledVersion = null;
-    compsAffectedByUpgrade.clear();
-    return true;
-  }
-
-  private static ServiceState checkIfStable(Service service) {
-    // if desired == running
-    for (org.apache.hadoop.yarn.service.api.records.Component comp :
-        service.getComponents()) {
-      if (!comp.getState().equals(
-          org.apache.hadoop.yarn.service.api.records.ComponentState.STABLE)) {
-        return service.getState();
-      }
-    }
-    return ServiceState.STABLE;
-  }
-
-  /**
-   * Service state gets directly modified by ServiceMaster and Component.
-   * This is a problem for upgrade and flexing. For now, invoking
-   * ServiceMaster.checkAndUpdateServiceState here to make it easy to fix
-   * this in future.
-   */
-  public void checkAndUpdateServiceState() {
-    writeLock.lock();
-    try {
-      if (!getState().equals(State.UPGRADING)) {
-        ServiceMaster.checkAndUpdateServiceState(this.scheduler);
-      }
-    } finally {
-      writeLock.unlock();
-    }
-  }
-
-  void processUpgradeRequest(String upgradeVersion,
-      boolean autoFinalize, boolean expressUpgrade) throws IOException {
-    Service targetSpec = ServiceApiUtil.loadServiceUpgrade(
-        context.fs, context.service.getName(), upgradeVersion);
-
-    List<org.apache.hadoop.yarn.service.api.records.Component>
-        compsNeedUpgradeList = resolveCompsToUpgrade(context.service,
-        targetSpec);
-
-    ServiceEvent event = new ServiceEvent(ServiceEventType.UPGRADE)
-        .setVersion(upgradeVersion)
-        .setAutoFinalize(autoFinalize)
-        .setExpressUpgrade(expressUpgrade);
-
-    if (expressUpgrade) {
-      // In case of express upgrade  components need to be upgraded in order.
-      // Once the service manager gets notified that a component finished
-      // upgrading, it then issues event to upgrade the next component.
-      Map<String, org.apache.hadoop.yarn.service.api.records.Component>
-          compsNeedUpgradeByName = new HashMap<>();
-      if (compsNeedUpgradeList != null) {
-        compsNeedUpgradeList.forEach(component ->
-            compsNeedUpgradeByName.put(component.getName(), component));
-      }
-      List<String> resolvedComps = ServiceApiUtil
-          .resolveCompsDependency(targetSpec);
-
-      List<org.apache.hadoop.yarn.service.api.records.Component>
-          orderedCompUpgrade = new LinkedList<>();
-      resolvedComps.forEach(compName -> {
-        org.apache.hadoop.yarn.service.api.records.Component component =
-            compsNeedUpgradeByName.get(compName);
-        if (component != null ) {
-          orderedCompUpgrade.add(component);
-        }
-      });
-      event.setCompsToUpgrade(orderedCompUpgrade);
-    } else {
-      event.setCompsToUpgrade(compsNeedUpgradeList);
-    }
-    context.scheduler.getDispatcher().getEventHandler().handle(
-        event);
-
-    if (autoFinalize && (compsNeedUpgradeList == null ||
-        compsNeedUpgradeList.isEmpty())) {
-      // nothing to upgrade and auto finalize is requested, trigger a
-      // state check.
-      context.scheduler.getDispatcher().getEventHandler().handle(
-          new ServiceEvent(ServiceEventType.CHECK_STABLE));
-    }
-  }
-
-  private List<org.apache.hadoop.yarn.service.api.records.Component>
-      resolveCompsToUpgrade(Service sourceSpec, Service targetSpec) {
-
-    List<org.apache.hadoop.yarn.service.api.records.Component>
-        compsNeedUpgradeList = componentsFinder.
-        findTargetComponentSpecs(sourceSpec, targetSpec);
-
-    // remove all components from need upgrade list if there restart policy
-    // doesn't all upgrade.
-    if (compsNeedUpgradeList != null) {
-      compsNeedUpgradeList.removeIf(component -> {
-        org.apache.hadoop.yarn.service.api.records.Component.RestartPolicyEnum
-            restartPolicy = component.getRestartPolicy();
-
-        final ComponentRestartPolicy restartPolicyHandler =
-            Component.getRestartPolicyHandler(restartPolicy);
-        // Do not allow upgrades for components which have NEVER/ON_FAILURE
-        // restart policy
-        if (!restartPolicyHandler.allowUpgrades()) {
-          LOG.info("The component {} has a restart policy that doesnt " +
-                  "allow upgrades {} ", component.getName(),
-              component.getRestartPolicy().toString());
-          return true;
-        }
-
-        return false;
-      });
-    }
-
-    return compsNeedUpgradeList;
-  }
-
-  /**
-   * Sets the state of the service in the service spec.
-   * @param state service state
-   */
-  private void setServiceState(
-      org.apache.hadoop.yarn.service.api.records.ServiceState state) {
-    org.apache.hadoop.yarn.service.api.records.ServiceState curState =
-        serviceSpec.getState();
-    if (!curState.equals(state)) {
-      serviceSpec.setState(state);
-      LOG.info("[SERVICE] spec state changed from {} -> {}", curState, state);
-    }
-  }
-
-  /**
-   * Returns the name of the service.
-   */
-  public String getName() {
-    return serviceSpec.getName();
-  }
-
-  /**
-   * State of {@link ServiceManager}.
-   */
-  public enum State {
-    STABLE, UPGRADING
-  }
-
-  @VisibleForTesting
-  Service getServiceSpec() {
-    return serviceSpec;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceMaster.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceMaster.java
deleted file mode 100644
index 00883d94eef..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceMaster.java
+++ /dev/null
@@ -1,357 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import org.apache.hadoop.classification.VisibleForTesting;
-import org.apache.commons.cli.CommandLine;
-import org.apache.commons.cli.Options;
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.hdfs.security.token.delegation.DelegationTokenIdentifier;
-
-import org.apache.hadoop.io.DataOutputBuffer;
-import org.apache.hadoop.metrics2.lib.DefaultMetricsSystem;
-import org.apache.hadoop.security.Credentials;
-import org.apache.hadoop.security.SecurityUtil;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.security.token.Token;
-import org.apache.hadoop.security.token.TokenIdentifier;
-import org.apache.hadoop.service.CompositeService;
-import org.apache.hadoop.util.ExitUtil;
-import org.apache.hadoop.util.GenericOptionsParser;
-import org.apache.hadoop.util.ShutdownHookManager;
-import org.apache.hadoop.yarn.YarnUncaughtExceptionHandler;
-import org.apache.hadoop.yarn.api.ApplicationConstants;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.security.AMRMTokenIdentifier;
-import org.apache.hadoop.yarn.security.client.ClientToAMTokenSecretManager;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.exceptions.BadClusterStateException;
-import org.apache.hadoop.yarn.service.monitor.ServiceMonitor;
-import org.apache.hadoop.yarn.service.utils.ServiceApiUtil;
-import org.apache.hadoop.yarn.service.utils.ServiceUtils;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.File;
-import java.io.IOException;
-import java.net.URI;
-import java.net.URISyntaxException;
-import java.nio.ByteBuffer;
-import java.security.PrivilegedExceptionAction;
-import java.util.Iterator;
-import java.util.Map;
-
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConstants.KEYTAB_LOCATION;
-
-public class ServiceMaster extends CompositeService {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(ServiceMaster.class);
-
-  public static final String YARNFILE_OPTION = "yarnfile";
-  public static final String SERVICE_NAME_OPTION = "service_name";
-  public static final String KEYTAB_OPTION = "keytab";
-  public static final String PRINCIPAL_NAME_OPTION = "principal_name";
-
-  private String serviceDefPath;
-  private String serviceName;
-  private String serviceKeytab;
-  private String servicePrincipalName;
-  protected ServiceContext context;
-
-  public ServiceMaster(String name) {
-    super(name);
-  }
-
-  @Override
-  protected void serviceInit(Configuration conf) throws Exception {
-    printSystemEnv();
-    context = new ServiceContext();
-    Path appDir = getAppDir();
-    context.serviceHdfsDir = appDir.toString();
-    context.tokens = recordTokensForContainers();
-    Credentials credentials = null;
-    if (UserGroupInformation.isSecurityEnabled()) {
-      credentials = UserGroupInformation.getCurrentUser().getCredentials();
-      doSecureLogin();
-    }
-    SliderFileSystem fs = new SliderFileSystem(conf);
-    fs.setAppDir(appDir);
-    context.fs = fs;
-    loadApplicationJson(context, fs);
-    if (UserGroupInformation.isSecurityEnabled()) {
-      // add back the credentials
-      if (credentials != null) {
-        UserGroupInformation.getCurrentUser().addCredentials(credentials);
-      }
-      removeHdfsDelegationToken(UserGroupInformation.getLoginUser());
-    }
-
-    // Take yarn config from YarnFile and merge them into YarnConfiguration
-    for (Map.Entry<String, String> entry : context.service
-        .getConfiguration().getProperties().entrySet()) {
-      conf.set(entry.getKey(), entry.getValue());
-    }
-
-    ContainerId amContainerId = getAMContainerId();
-
-    ApplicationAttemptId attemptId = amContainerId.getApplicationAttemptId();
-    LOG.info("Service AppAttemptId: " + attemptId);
-    context.attemptId = attemptId;
-
-    // configure AM to wait forever for RM
-    conf.setLong(YarnConfiguration.RESOURCEMANAGER_CONNECT_MAX_WAIT_MS, -1);
-    conf.unset(YarnConfiguration.CLIENT_FAILOVER_MAX_ATTEMPTS);
-
-    DefaultMetricsSystem.initialize("ServiceAppMaster");
-
-    context.secretManager = new ClientToAMTokenSecretManager(attemptId, null);
-    ClientAMService clientAMService = createClientAMService();
-    context.clientAMService = clientAMService;
-    addService(clientAMService);
-
-    ServiceScheduler scheduler = createServiceScheduler(context);
-    addService(scheduler);
-    context.scheduler = scheduler;
-
-    ServiceMonitor monitor = new ServiceMonitor("Service Monitor", context);
-    addService(monitor);
-
-    super.serviceInit(conf);
-  }
-
-  @VisibleForTesting
-  protected ClientAMService createClientAMService() {
-    return new ClientAMService(context);
-  }
-
-  // Record the tokens and use them for launching containers.
-  // e.g. localization requires the hdfs delegation tokens
-  @VisibleForTesting
-  protected ByteBuffer recordTokensForContainers() throws IOException {
-    Credentials copy = new Credentials(UserGroupInformation.getCurrentUser()
-        .getCredentials());
-    // Now remove the AM->RM token so that task containers cannot access it.
-    Iterator<Token<?>> iter = copy.getAllTokens().iterator();
-    while (iter.hasNext()) {
-      Token<?> token = iter.next();
-      LOG.info(token.toString());
-      if (token.getKind().equals(AMRMTokenIdentifier.KIND_NAME)) {
-        iter.remove();
-      }
-    }
-    DataOutputBuffer dob = new DataOutputBuffer();
-    try {
-      copy.writeTokenStorageToStream(dob);
-    } finally {
-      dob.close();
-    }
-    return ByteBuffer.wrap(dob.getData(), 0, dob.getLength());
-  }
-
-  // 1. First try to use user specified keytabs
-  // 2. If not specified, then try to use pre-installed keytab at localhost
-  // 3. strip off hdfs delegation tokens to ensure use keytab to talk to hdfs
-  private void doSecureLogin()
-      throws IOException, URISyntaxException {
-    // read the localized keytab specified by user
-    File keytab = new File(String.format(KEYTAB_LOCATION, getServiceName()));
-    if (!keytab.exists()) {
-      LOG.info("No keytab localized at " + keytab);
-      // Check if there exists a pre-installed keytab at host
-      String preInstalledKeytab = context.service == null ? this.serviceKeytab
-          : context.service.getKerberosPrincipal().getKeytab();
-      if (!StringUtils.isEmpty(preInstalledKeytab)) {
-        URI uri = new URI(preInstalledKeytab);
-        if (uri.getScheme().equals("file")) {
-          keytab = new File(uri);
-          LOG.info("Using pre-installed keytab from localhost: " +
-              preInstalledKeytab);
-        }
-      }
-    }
-    if (!keytab.exists()) {
-      LOG.info("No keytab exists: " + keytab);
-      return;
-    }
-    String principal = context.service == null ? this.servicePrincipalName
-        : context.service.getKerberosPrincipal().getPrincipalName();
-    if (StringUtils.isEmpty((principal))) {
-      principal = UserGroupInformation.getLoginUser().getShortUserName();
-      LOG.info("No principal name specified.  Will use AM " +
-          "login identity {} to attempt keytab-based login", principal);
-    }
-
-    LOG.info("User before logged in is: " + UserGroupInformation
-        .getCurrentUser());
-    String principalName = SecurityUtil.getServerPrincipal(principal,
-        ServiceUtils.getLocalHostName(getConfig()));
-    UserGroupInformation.loginUserFromKeytab(principalName,
-        keytab.getAbsolutePath());
-    LOG.info("User after logged in is: " + UserGroupInformation
-        .getCurrentUser());
-    context.principal = principalName;
-    context.keytab = keytab.getAbsolutePath();
-  }
-
-  // Remove HDFS delegation token from login user and ensure AM to use keytab
-  // to talk to hdfs
-  private static void removeHdfsDelegationToken(UserGroupInformation user) {
-    if (!user.isFromKeytab()) {
-      LOG.error("AM is not holding on a keytab in a secure deployment:" +
-          " service will fail when tokens expire");
-    }
-    Credentials credentials = user.getCredentials();
-    Iterator<Token<? extends TokenIdentifier>> iter =
-        credentials.getAllTokens().iterator();
-    while (iter.hasNext()) {
-      Token<? extends TokenIdentifier> token = iter.next();
-      if (token.getKind().equals(
-          DelegationTokenIdentifier.HDFS_DELEGATION_KIND)) {
-        LOG.info("Remove HDFS delegation token {}.", token);
-        iter.remove();
-      }
-    }
-  }
-
-  protected ContainerId getAMContainerId() throws BadClusterStateException {
-    return ContainerId.fromString(ServiceUtils.mandatoryEnvVariable(
-        ApplicationConstants.Environment.CONTAINER_ID.name()));
-  }
-
-  protected Path getAppDir() {
-    return new Path(serviceDefPath).getParent();
-  }
-
-  protected String getServiceName() {
-    return serviceName;
-  }
-
-  protected ServiceScheduler createServiceScheduler(ServiceContext context)
-      throws IOException, YarnException {
-    return new ServiceScheduler(context);
-  }
-
-  protected void loadApplicationJson(ServiceContext context,
-      SliderFileSystem fs) throws IOException {
-    context.service = ServiceApiUtil
-        .loadServiceFrom(fs, new Path(serviceDefPath));
-    context.service.setState(ServiceState.ACCEPTED);
-    LOG.info(context.service.toString());
-  }
-
-  @Override
-  protected void serviceStart() throws Exception {
-    LOG.info("Starting service as user " + UserGroupInformation
-        .getCurrentUser());
-    UserGroupInformation.getLoginUser().doAs(
-        (PrivilegedExceptionAction<Void>) () -> {
-          super.serviceStart();
-          return null;
-        }
-    );
-  }
-  @Override
-  protected void serviceStop() throws Exception {
-    LOG.info("Stopping app master");
-    super.serviceStop();
-  }
-
-  // This method should be called whenever there is an increment or decrement
-  // of a READY state component of a service
-  public static synchronized void checkAndUpdateServiceState(
-      ServiceScheduler scheduler) {
-    ServiceState curState = scheduler.getApp().getState();
-    // Check the state of all components
-    boolean isStable = true;
-    for (org.apache.hadoop.yarn.service.api.records.Component comp : scheduler
-        .getApp().getComponents()) {
-      if (comp.getState() !=
-          org.apache.hadoop.yarn.service.api.records.ComponentState.STABLE) {
-        isStable = false;
-        break;
-      }
-    }
-    if (isStable) {
-      scheduler.getApp().setState(ServiceState.STABLE);
-    } else {
-      // mark new state as started only if current state is stable, otherwise
-      // leave it as is
-      if (curState == ServiceState.STABLE) {
-        scheduler.getApp().setState(ServiceState.STARTED);
-      }
-    }
-    if (curState != scheduler.getApp().getState()) {
-      LOG.info("Service state changed from {} -> {}", curState,
-          scheduler.getApp().getState());
-    }
-    populateYarnSysFS(scheduler);
-  }
-
-  private static void populateYarnSysFS(ServiceScheduler scheduler) {
-    Service service = scheduler.getApp();
-    scheduler.syncSysFs(service);
-  }
-
-  private void printSystemEnv() {
-    for (Map.Entry<String, String> envs : System.getenv().entrySet()) {
-      LOG.info("{} = {}", envs.getKey(), envs.getValue());
-    }
-  }
-
-  public static void main(String[] args) throws Exception {
-    Thread.setDefaultUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());
-    org.apache.hadoop.util.StringUtils
-        .startupShutdownMessage(ServiceMaster.class, args, LOG);
-    try {
-      ServiceMaster serviceMaster = new ServiceMaster("Service Master");
-      ShutdownHookManager.get()
-          .addShutdownHook(new CompositeServiceShutdownHook(serviceMaster), 30);
-      YarnConfiguration conf = new YarnConfiguration();
-      Options opts = new Options();
-      opts.addOption(YARNFILE_OPTION, true, "HDFS path to JSON service " +
-          "specification");
-      opts.getOption(YARNFILE_OPTION).setRequired(true);
-      opts.addOption(SERVICE_NAME_OPTION, true, "Service name");
-      opts.getOption(SERVICE_NAME_OPTION).setRequired(true);
-      opts.addOption(KEYTAB_OPTION, true, "Service AM keytab");
-      opts.addOption(PRINCIPAL_NAME_OPTION, true,
-          "Service AM keytab principal");
-      GenericOptionsParser parser = new GenericOptionsParser(conf, opts, args);
-      CommandLine cmdLine = parser.getCommandLine();
-      serviceMaster.serviceDefPath = cmdLine.getOptionValue(YARNFILE_OPTION);
-      serviceMaster.serviceName = cmdLine.getOptionValue(SERVICE_NAME_OPTION);
-      serviceMaster.serviceKeytab = cmdLine.getOptionValue(KEYTAB_OPTION);
-      serviceMaster.servicePrincipalName = cmdLine
-          .getOptionValue(PRINCIPAL_NAME_OPTION);
-      serviceMaster.init(conf);
-      serviceMaster.start();
-    } catch (Throwable t) {
-      LOG.error("Error starting service master", t);
-      ExitUtil.terminate(1, "Error starting service master");
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceMetrics.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceMetrics.java
deleted file mode 100644
index b5bbb7d0347..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceMetrics.java
+++ /dev/null
@@ -1,94 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import org.apache.hadoop.metrics2.MetricsCollector;
-import org.apache.hadoop.metrics2.MetricsInfo;
-import org.apache.hadoop.metrics2.MetricsSource;
-import org.apache.hadoop.metrics2.annotation.Metric;
-import org.apache.hadoop.metrics2.annotation.Metrics;
-import org.apache.hadoop.metrics2.lib.DefaultMetricsSystem;
-import org.apache.hadoop.metrics2.lib.MetricsRegistry;
-import org.apache.hadoop.metrics2.lib.MutableGaugeInt;
-
-import static org.apache.hadoop.metrics2.lib.Interns.info;
-
-@Metrics(context = "yarn-native-service")
-public class ServiceMetrics implements MetricsSource {
-
-  @Metric("containers requested")
-  public MutableGaugeInt containersRequested;
-
-  @Metric("containers running")
-  public MutableGaugeInt containersRunning;
-
-  @Metric("containers ready")
-  public MutableGaugeInt containersReady;
-
-  @Metric("containers desired")
-  public MutableGaugeInt containersDesired;
-
-  @Metric("containers succeeded")
-  public MutableGaugeInt containersSucceeded;
-
-  @Metric("containers failed")
-  public MutableGaugeInt containersFailed;
-
-  @Metric("containers preempted")
-  public MutableGaugeInt containersPreempted;
-
-  @Metric("containers surplus")
-  public MutableGaugeInt surplusContainers;
-
-  @Metric("containers failed due to disk failure")
-  public MutableGaugeInt containersDiskFailure;
-
-  protected final MetricsRegistry registry;
-
-  public ServiceMetrics(MetricsInfo metricsInfo) {
-    registry = new MetricsRegistry(metricsInfo);
-  }
-
-  @Override
-  public void getMetrics(MetricsCollector collector, boolean all) {
-    registry.snapshot(collector.addRecord(registry.info()), all);
-  }
-
-  public static ServiceMetrics register(String name, String description) {
-    ServiceMetrics metrics = new ServiceMetrics(info(name, description));
-    DefaultMetricsSystem.instance().register(name, description, metrics);
-    return metrics;
-  }
-
-  public void tag(String name, String description, String value) {
-    registry.tag(name, description, value);
-  }
-
-  @Override public String toString() {
-    return "ServiceMetrics{"
-        + "containersRequested=" + containersRequested.value()
-        + ", containersRunning=" + containersRunning.value()
-        + ", containersDesired=" + containersDesired.value()
-        + ", containersSucceeded=" + containersSucceeded.value()
-        + ", containersFailed=" + containersFailed.value()
-        + ", containersPreempted=" + containersPreempted.value()
-        + ", surplusContainers=" + surplusContainers.value() + '}';
-  }
-}
-
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceScheduler.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceScheduler.java
deleted file mode 100644
index 9da8f31fe4b..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/ServiceScheduler.java
+++ /dev/null
@@ -1,1145 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import org.apache.hadoop.thirdparty.com.google.common.cache.CacheBuilder;
-import org.apache.hadoop.thirdparty.com.google.common.cache.CacheLoader;
-import org.apache.hadoop.thirdparty.com.google.common.cache.LoadingCache;
-import com.sun.jersey.api.client.ClientResponse;
-import com.sun.jersey.api.client.WebResource.Builder;
-
-import org.apache.commons.io.IOUtils;
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.FSDataInputStream;
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.metrics2.lib.DefaultMetricsSystem;
-import org.apache.hadoop.registry.client.api.RegistryOperations;
-import org.apache.hadoop.registry.client.api.RegistryOperationsFactory;
-import org.apache.hadoop.registry.client.binding.RegistryPathUtils;
-import org.apache.hadoop.registry.client.binding.RegistryUtils;
-import org.apache.hadoop.registry.client.types.ServiceRecord;
-import org.apache.hadoop.registry.client.types.yarn.PersistencePolicies;
-import org.apache.hadoop.registry.client.types.yarn.YarnRegistryAttributes;
-import org.apache.hadoop.security.HadoopKerberosName;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.service.CompositeService;
-import org.apache.hadoop.yarn.api.ApplicationConstants;
-import org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.Container;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.api.records.ContainerStatus;
-import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;
-import org.apache.hadoop.yarn.api.records.NodeReport;
-import org.apache.hadoop.yarn.api.records.RejectedSchedulingRequest;
-import org.apache.hadoop.yarn.api.records.Resource;
-import org.apache.hadoop.yarn.api.records.UpdatedContainer;
-import org.apache.hadoop.yarn.client.api.AMRMClient;
-import org.apache.hadoop.yarn.client.api.TimelineV2Client;
-import org.apache.hadoop.yarn.client.api.async.AMRMClientAsync;
-import org.apache.hadoop.yarn.client.api.async.NMClientAsync;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.event.AsyncDispatcher;
-import org.apache.hadoop.yarn.event.EventHandler;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-import org.apache.hadoop.yarn.service.api.ServiceApiConstants;
-import org.apache.hadoop.yarn.service.api.records.ContainerState;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.api.records.ConfigFile;
-import org.apache.hadoop.yarn.service.component.ComponentRestartPolicy;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEvent;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEventType;
-import org.apache.hadoop.yarn.service.component.Component;
-import org.apache.hadoop.yarn.service.component.ComponentEvent;
-import org.apache.hadoop.yarn.service.component.ComponentEventType;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConf;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConstants;
-import org.apache.hadoop.yarn.service.containerlaunch.ContainerLaunchService;
-import org.apache.hadoop.yarn.service.provider.ProviderUtils;
-import org.apache.hadoop.yarn.service.registry.YarnRegistryViewForProviders;
-import org.apache.hadoop.yarn.service.timelineservice.ServiceMetricsSink;
-import org.apache.hadoop.yarn.service.timelineservice.ServiceTimelinePublisher;
-import org.apache.hadoop.yarn.service.utils.HttpUtil;
-import org.apache.hadoop.yarn.service.utils.ServiceApiUtil;
-import org.apache.hadoop.yarn.service.utils.ServiceRegistryUtils;
-import org.apache.hadoop.yarn.service.utils.ServiceUtils;
-import org.apache.hadoop.yarn.util.BoundedAppender;
-import org.apache.hadoop.yarn.util.Clock;
-import org.apache.hadoop.yarn.util.SystemClock;
-import org.apache.hadoop.yarn.util.resource.ResourceUtils;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.net.InetSocketAddress;
-import java.net.URI;
-import java.net.URISyntaxException;
-import java.nio.ByteBuffer;
-import java.nio.charset.StandardCharsets;
-import java.text.MessageFormat;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.concurrent.Executors;
-import java.util.concurrent.ScheduledExecutorService;
-import java.util.concurrent.TimeUnit;
-
-import static org.apache.hadoop.fs.FileSystem.FS_DEFAULT_NAME_KEY;
-import static org.apache.hadoop.registry.client.api.RegistryConstants.*;
-import static org.apache.hadoop.yarn.api.records.ContainerExitStatus
-    .KILLED_AFTER_APP_COMPLETION;
-import static org.apache.hadoop.yarn.service.api.ServiceApiConstants.*;
-import static org.apache.hadoop.yarn.service.component.ComponentEventType.*;
-import static org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEventType.START;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConstants
-    .CONTAINER_STATE_REPORT_AS_SERVICE_STATE;
-import static org.apache.hadoop.yarn.service.exceptions.LauncherExitCodes
-    .EXIT_FALSE;
-import static org.apache.hadoop.yarn.service.exceptions.LauncherExitCodes
-    .EXIT_SUCCESS;
-
-/**
- *
- */
-public class ServiceScheduler extends CompositeService {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(ServiceScheduler.class);
-  private Service app;
-
-   // This encapsulates the <code>app</code> with methods to upgrade the app.
-  private ServiceManager serviceManager;
-
-  // component_name -> component
-  private final Map<String, Component> componentsByName =
-      new ConcurrentHashMap<>();
-
-  // id - > component
-  protected final Map<Long, Component> componentsById =
-      new ConcurrentHashMap<>();
-
-  private final Map<ContainerId, ComponentInstance> liveInstances =
-      new ConcurrentHashMap<>();
-
-  private ServiceMetrics serviceMetrics;
-
-  private ServiceTimelinePublisher serviceTimelinePublisher;
-
-  private boolean timelineServiceEnabled;
-
-  // Global diagnostics that will be reported to RM on eRxit.
-  // The unit the number of characters. This will be limited to 64 * 1024
-  // characters.
-  private BoundedAppender diagnostics = new BoundedAppender(64 * 1024);
-
-  // A cache for loading config files from remote such as hdfs
-  public LoadingCache<ConfigFile, Object> configFileCache = null;
-
-  public ScheduledExecutorService executorService;
-  public Map<String, String> globalTokens = new HashMap<>();
-
-  private AMRMClientAsync<AMRMClient.ContainerRequest> amRMClient;
-  private NMClientAsync nmClient;
-  private AsyncDispatcher dispatcher;
-  private YarnRegistryViewForProviders yarnRegistryOperations;
-  private ServiceContext context;
-  private ContainerLaunchService containerLaunchService;
-  private final Map<ContainerId, ComponentInstance> unRecoveredInstances =
-      new ConcurrentHashMap<>();
-  private long containerRecoveryTimeout;
-
-  // If even one component of a service uses placement constraints, then use
-  // placement scheduler to schedule containers for all components (including
-  // the ones with no constraints). Mixing of container requests and scheduling
-  // requests for a single service is not recommended.
-  private boolean hasAtLeastOnePlacementConstraint;
-
-  private boolean gracefulStop = false;
-
-  private volatile FinalApplicationStatus finalApplicationStatus =
-      FinalApplicationStatus.ENDED;
-
-  private Clock systemClock;
-
-  // For unit test override since we don't want to terminate UT process.
-  private ServiceUtils.ProcessTerminationHandler
-      terminationHandler = new ServiceUtils.ProcessTerminationHandler();
-
-  public ServiceScheduler(ServiceContext context) {
-    super(context.getService().getName());
-    this.context = context;
-    this.app = context.getService();
-    this.systemClock = SystemClock.getInstance();
-  }
-
-  public void buildInstance(ServiceContext context, Configuration configuration)
-      throws YarnException, IOException {
-    app = context.service;
-    executorService = Executors.newScheduledThreadPool(10);
-    RegistryOperations registryClient = null;
-    if (UserGroupInformation.isSecurityEnabled() &&
-        !StringUtils.isEmpty(context.principal)
-        && !StringUtils.isEmpty(context.keytab)) {
-      Configuration conf = getConfig();
-      // Only take the first section of the principal
-      // e.g. hdfs-demo@EXAMPLE.COM will take hdfs-demo
-      // This is because somehow zookeeper client only uses the first section
-      // for acl validations.
-      String username = new HadoopKerberosName(context.principal.trim())
-          .getServiceName();
-      LOG.info("Set registry user accounts: sasl:" + username);
-      conf.set(KEY_REGISTRY_USER_ACCOUNTS, "sasl:" + username);
-      registryClient = RegistryOperationsFactory
-          .createKerberosInstance(conf,
-              "Client", context.principal, context.keytab);
-    } else {
-      registryClient = RegistryOperationsFactory
-          .createInstance("ServiceScheduler", configuration);
-    }
-    addIfService(registryClient);
-    yarnRegistryOperations =
-        createYarnRegistryOperations(context, registryClient);
-
-    // register metrics,
-    serviceMetrics = ServiceMetrics
-        .register(app.getName(), "Metrics for service");
-    serviceMetrics.tag("type", "Metrics type [component or service]", "service");
-    serviceMetrics.tag("appId", "Service id for service", app.getId());
-
-    amRMClient = createAMRMClient();
-    addIfService(amRMClient);
-
-    nmClient = createNMClient();
-    nmClient.getClient().cleanupRunningContainersOnStop(false);
-    addIfService(nmClient);
-
-    dispatcher = createAsyncDispatcher();
-    dispatcher.register(ServiceEventType.class, new ServiceEventHandler());
-    dispatcher.register(ComponentEventType.class,
-        new ComponentEventHandler());
-    dispatcher.register(ComponentInstanceEventType.class,
-        new ComponentInstanceEventHandler());
-    dispatcher.setDrainEventsOnStop();
-    addIfService(dispatcher);
-
-    containerLaunchService = new ContainerLaunchService(context);
-    addService(containerLaunchService);
-
-    if (YarnConfiguration.timelineServiceV2Enabled(configuration)) {
-      TimelineV2Client timelineClient = TimelineV2Client
-          .createTimelineClient(context.attemptId.getApplicationId());
-      amRMClient.registerTimelineV2Client(timelineClient);
-      serviceTimelinePublisher = new ServiceTimelinePublisher(timelineClient);
-      addService(serviceTimelinePublisher);
-      DefaultMetricsSystem.instance().register("ServiceMetricsSink",
-          "For processing metrics to ATS",
-          new ServiceMetricsSink(serviceTimelinePublisher));
-      LOG.info("Timeline v2 is enabled.");
-    }
-
-    initGlobalTokensForSubstitute(context);
-    //substitute quicklinks
-    ProviderUtils.substituteMapWithTokens(app.getQuicklinks(), globalTokens);
-    createConfigFileCache(context.fs.getFileSystem());
-
-    createAllComponents();
-    containerRecoveryTimeout = YarnServiceConf.getInt(
-        YarnServiceConf.CONTAINER_RECOVERY_TIMEOUT_MS,
-        YarnServiceConf.DEFAULT_CONTAINER_RECOVERY_TIMEOUT_MS,
-        app.getConfiguration(), getConfig());
-
-    if (YarnConfiguration
-        .timelineServiceV2Enabled(getConfig())) {
-      timelineServiceEnabled = true;
-    }
-
-    serviceManager = createServiceManager();
-    context.setServiceManager(serviceManager);
-
-  }
-
-  protected YarnRegistryViewForProviders createYarnRegistryOperations(
-      ServiceContext context, RegistryOperations registryClient) {
-    return new YarnRegistryViewForProviders(registryClient,
-        RegistryUtils.currentUser(), YarnServiceConstants.APP_TYPE, app.getName(),
-        context.attemptId);
-  }
-
-  protected ServiceManager createServiceManager() {
-    return new ServiceManager(context);
-  }
-
-  protected AsyncDispatcher createAsyncDispatcher() {
-    return new AsyncDispatcher("Component  dispatcher");
-  }
-
-  protected NMClientAsync createNMClient() {
-    return NMClientAsync.createNMClientAsync(new NMClientCallback());
-  }
-
-  protected AMRMClientAsync<AMRMClient.ContainerRequest> createAMRMClient() {
-    return AMRMClientAsync
-        .createAMRMClientAsync(1000, new AMRMClientCallback());
-  }
-
-  public void setGracefulStop(FinalApplicationStatus applicationStatus) {
-    this.gracefulStop = true;
-    this.finalApplicationStatus = applicationStatus;
-    nmClient.getClient().cleanupRunningContainersOnStop(true);
-  }
-
-  @Override
-  public void serviceInit(Configuration conf) throws Exception {
-    try {
-      buildInstance(context, conf);
-    } catch (YarnException e) {
-      throw new YarnRuntimeException(e);
-    }
-    super.serviceInit(conf);
-  }
-
-  @Override
-  public void serviceStop() throws Exception {
-    LOG.info("Stopping service scheduler");
-
-    if (executorService != null) {
-      executorService.shutdownNow();
-    }
-
-    DefaultMetricsSystem.shutdown();
-
-    // only stop the entire service when a graceful stop has been initiated
-    // (e.g. via client RPC, not through the AM receiving a SIGTERM)
-    if (gracefulStop) {
-
-      if (YarnConfiguration.timelineServiceV2Enabled(getConfig())) {
-
-        // mark other component-instances/containers as STOPPED
-        final Map<ContainerId, ComponentInstance> liveInst =
-            getLiveInstances();
-        for (Map.Entry<ContainerId, ComponentInstance> instance : liveInst
-            .entrySet()) {
-          if (!ComponentInstance.isFinalState(
-              instance.getValue().getContainerSpec().getState())) {
-            LOG.info("{} Component instance state changed from {} to {}",
-                instance.getValue().getCompInstanceName(),
-                instance.getValue().getContainerSpec().getState(),
-                ContainerState.STOPPED);
-            serviceTimelinePublisher.componentInstanceFinished(
-                instance.getKey(), KILLED_AFTER_APP_COMPLETION,
-                ContainerState.STOPPED, getDiagnostics().toString());
-          }
-        }
-
-        LOG.info("Service state changed to {}", finalApplicationStatus);
-        // mark attempt as unregistered
-        serviceTimelinePublisher.serviceAttemptUnregistered(context,
-            finalApplicationStatus, diagnostics.toString());
-      }
-
-      // unregister AM
-      amRMClient.unregisterApplicationMaster(finalApplicationStatus,
-          diagnostics.toString(), "");
-      LOG.info("Service {} unregistered with RM, with attemptId = {} "
-              + ", diagnostics = {} ", app.getName(), context.attemptId,
-          diagnostics);
-    }
-    super.serviceStop();
-  }
-
-  @Override
-  public void serviceStart() throws Exception {
-    super.serviceStart();
-    InetSocketAddress bindAddress = context.clientAMService.getBindAddress();
-    // When yarn.resourcemanager.placement-constraints.handler is set to
-    // placement-processor then constraints need to be added during
-    // registerApplicationMaster.
-    RegisterApplicationMasterResponse response = amRMClient
-        .registerApplicationMaster(bindAddress.getHostName(),
-            bindAddress.getPort(), "N/A");
-
-    // Update internal resource types according to response.
-    if (response.getResourceTypes() != null) {
-      ResourceUtils.reinitializeResources(response.getResourceTypes());
-    }
-
-    if (response.getClientToAMTokenMasterKey() != null
-        && response.getClientToAMTokenMasterKey().remaining() != 0) {
-      context.secretManager
-          .setMasterKey(response.getClientToAMTokenMasterKey().array());
-    }
-    registerServiceInstance(context.attemptId, app);
-
-    // Since AM has been started and registered, the service is in STARTED state
-    app.setState(ServiceState.STARTED);
-
-    ServiceApiUtil.checkServiceDependencySatisified(context.service);
-
-    // recover components based on containers sent from RM
-    recoverComponents(response);
-
-    for (Component component : componentsById.values()) {
-      // Trigger initial evaluation of components
-      if (component.areDependenciesReady()) {
-        LOG.info("Triggering initial evaluation of component {}",
-            component.getName());
-        ComponentEvent event = new ComponentEvent(component.getName(), FLEX)
-            .setDesired(component.getComponentSpec().getNumberOfContainers());
-        component.handle(event);
-      }
-    }
-  }
-
-  private void recoverComponents(RegisterApplicationMasterResponse response) {
-    List<Container> containersFromPrevAttempt = response
-        .getContainersFromPreviousAttempts();
-    LOG.info("Received {} containers from previous attempt.",
-        containersFromPrevAttempt.size());
-    Map<String, ServiceRecord> existingRecords = new HashMap<>();
-    List<String> existingComps = null;
-    try {
-      existingComps = yarnRegistryOperations.listComponents();
-      LOG.info("Found {} containers from ZK registry: {}", existingComps.size(),
-          existingComps);
-    } catch (Exception e) {
-      LOG.info("Could not read component paths: {}", e.getMessage());
-    }
-    if (existingComps != null) {
-      for (String existingComp : existingComps) {
-        try {
-          ServiceRecord record =
-              yarnRegistryOperations.getComponent(existingComp);
-          existingRecords.put(existingComp, record);
-        } catch (Exception e) {
-          LOG.warn("Could not resolve record for component {}: {}",
-              existingComp, e);
-        }
-      }
-    }
-    for (Container container : containersFromPrevAttempt) {
-      LOG.info("Handling {} from previous attempt", container.getId());
-      ServiceRecord record = existingRecords.remove(RegistryPathUtils
-          .encodeYarnID(container.getId().toString()));
-      if (record != null) {
-        Component comp = componentsById.get(container.getAllocationRequestId());
-        ComponentEvent event =
-            new ComponentEvent(comp.getName(), CONTAINER_RECOVERED)
-                .setContainer(container)
-                .setInstance(comp.getComponentInstance(record.description));
-        comp.handle(event);
-        // do not remove requests in this case because we do not know if they
-        // have already been removed
-      } else {
-        LOG.info("Record not found in registry for container {} from previous" +
-            " attempt, releasing", container.getId());
-        amRMClient.releaseAssignedContainer(container.getId());
-      }
-    }
-    ApplicationId appId = ApplicationId.fromString(app.getId());
-    existingRecords.forEach((encodedContainerId, record) -> {
-      String componentName = record.get(YarnRegistryAttributes.YARN_COMPONENT);
-      if (componentName != null) {
-        Component component = componentsByName.get(componentName);
-        if (component != null) {
-          ComponentInstance compInstance = component.getComponentInstance(
-              record.description);
-          ContainerId containerId = ContainerId.fromString(record.get(
-              YarnRegistryAttributes.YARN_ID));
-          if (containerId.getApplicationAttemptId().getApplicationId()
-              .equals(appId)) {
-            unRecoveredInstances.put(containerId, compInstance);
-            component.removePendingInstance(compInstance);
-          }
-        }
-      }
-    });
-
-    if (unRecoveredInstances.size() > 0) {
-      executorService.schedule(() -> {
-        synchronized (unRecoveredInstances) {
-          // after containerRecoveryTimeout, all the containers that haven't be
-          // recovered by the RM will released. The corresponding Component
-          // Instances are added to the pending queues of their respective
-          // component.
-          unRecoveredInstances.forEach((containerId, instance) -> {
-            LOG.info("{}, wait on container {} expired",
-                instance.getCompInstanceId(), containerId);
-            instance.cleanupRegistryAndCompHdfsDir(containerId);
-            Component component = componentsByName.get(instance.getCompName());
-            component.requestContainers(1);
-            component.reInsertPendingInstance(instance);
-            amRMClient.releaseAssignedContainer(containerId);
-          });
-          unRecoveredInstances.clear();
-        }
-      }, containerRecoveryTimeout, TimeUnit.MILLISECONDS);
-    }
-  }
-
-  private void initGlobalTokensForSubstitute(ServiceContext context) {
-    // ZK
-    globalTokens.put(ServiceApiConstants.CLUSTER_ZK_QUORUM, getConfig()
-        .getTrimmed(KEY_REGISTRY_ZK_QUORUM, DEFAULT_REGISTRY_ZK_QUORUM));
-    String user = RegistryUtils.currentUser();
-    globalTokens.put(SERVICE_ZK_PATH,
-        ServiceRegistryUtils.mkServiceHomePath(user, app.getName()));
-
-    globalTokens.put(ServiceApiConstants.USER, user);
-    String dnsDomain = getConfig().getTrimmed(KEY_DNS_DOMAIN);
-    if (dnsDomain != null && !dnsDomain.isEmpty()) {
-      globalTokens.put(ServiceApiConstants.DOMAIN, dnsDomain);
-    }
-    // HDFS
-    String clusterFs = getConfig().getTrimmed(FS_DEFAULT_NAME_KEY);
-    if (clusterFs != null && !clusterFs.isEmpty()) {
-      globalTokens.put(ServiceApiConstants.CLUSTER_FS_URI, clusterFs);
-      globalTokens.put(ServiceApiConstants.CLUSTER_FS_HOST,
-          URI.create(clusterFs).getHost());
-    }
-    globalTokens.put(SERVICE_HDFS_DIR, context.serviceHdfsDir);
-    // service name
-    globalTokens.put(SERVICE_NAME_LC, app.getName().toLowerCase());
-    globalTokens.put(SERVICE_NAME, app.getName());
-  }
-
-  private void createConfigFileCache(final FileSystem fileSystem) {
-    this.configFileCache =
-        CacheBuilder.newBuilder().expireAfterAccess(10, TimeUnit.MINUTES)
-            .build(new CacheLoader<ConfigFile, Object>() {
-              @Override public Object load(ConfigFile key) throws Exception {
-                switch (key.getType()) {
-                case HADOOP_XML:
-                  try (FSDataInputStream input = fileSystem
-                      .open(new Path(key.getSrcFile()))) {
-                    org.apache.hadoop.conf.Configuration confRead =
-                        new org.apache.hadoop.conf.Configuration(false);
-                    confRead.addResource(input);
-                    Map<String, String> map = new HashMap<>(confRead.size());
-                    for (Map.Entry<String, String> entry : confRead) {
-                      map.put(entry.getKey(), entry.getValue());
-                    }
-                    return map;
-                  }
-                case TEMPLATE:
-                  try (FSDataInputStream fileInput = fileSystem
-                      .open(new Path(key.getSrcFile()))) {
-                    return IOUtils.toString(fileInput, StandardCharsets.UTF_8);
-                  }
-                default:
-                  return null;
-                }
-              }
-            });
-    context.configCache = configFileCache;
-  }
-
-  private void registerServiceInstance(ApplicationAttemptId attemptId,
-      Service service) throws IOException {
-    LOG.info("Registering " + attemptId + ", " + service.getName()
-        + " into registry");
-    ServiceRecord serviceRecord = new ServiceRecord();
-    serviceRecord.set(YarnRegistryAttributes.YARN_ID,
-        attemptId.getApplicationId().toString());
-    serviceRecord.set(YarnRegistryAttributes.YARN_PERSISTENCE,
-        PersistencePolicies.APPLICATION);
-    serviceRecord.description = "YarnServiceMaster";
-
-    executorService.submit(new Runnable() {
-      @Override public void run() {
-        try {
-          yarnRegistryOperations.registerSelf(serviceRecord, false);
-          LOG.info("Registered service under {}; absolute path {}",
-              yarnRegistryOperations.getSelfRegistrationPath(),
-              yarnRegistryOperations.getAbsoluteSelfRegistrationPath());
-          boolean isFirstAttempt = 1 == attemptId.getAttemptId();
-          // delete the children in case there are any and this is an AM startup.
-          // just to make sure everything underneath is purged
-          if (isFirstAttempt) {
-            yarnRegistryOperations.deleteChildren(
-                yarnRegistryOperations.getSelfRegistrationPath(), true);
-          }
-        } catch (IOException e) {
-          LOG.error(
-              "Failed to register app " + app.getName() + " in registry", e);
-        }
-      }
-    });
-    if (YarnConfiguration.timelineServiceV2Enabled(getConfig())) {
-      serviceTimelinePublisher.serviceAttemptRegistered(app, getConfig());
-    }
-  }
-
-  private void createAllComponents() {
-    long allocateId = 0;
-
-    // sort components by dependencies
-    Collection<org.apache.hadoop.yarn.service.api.records.Component> sortedComponents =
-        ServiceApiUtil.sortByDependencies(app.getComponents());
-
-    for (org.apache.hadoop.yarn.service.api.records.Component compSpec : sortedComponents) {
-      Component component = new Component(compSpec, allocateId, context);
-      componentsById.put(allocateId, component);
-      componentsByName.put(component.getName(), component);
-      allocateId++;
-      if (!hasAtLeastOnePlacementConstraint
-          && compSpec.getPlacementPolicy() != null
-          && compSpec.getPlacementPolicy().getConstraints() != null
-          && !compSpec.getPlacementPolicy().getConstraints().isEmpty()) {
-        hasAtLeastOnePlacementConstraint = true;
-      }
-    }
-  }
-
-  private final class ServiceEventHandler
-      implements EventHandler<ServiceEvent> {
-    @Override
-    public void handle(ServiceEvent event) {
-      try {
-        serviceManager.handle(event);
-      } catch (Throwable t) {
-        LOG.error(MessageFormat
-            .format("[SERVICE]: Error in handling event type {0}",
-                event.getType()), t);
-      }
-    }
-  }
-
-  private final class ComponentEventHandler
-      implements EventHandler<ComponentEvent> {
-    @Override
-    public void handle(ComponentEvent event) {
-      Component component = componentsByName.get(event.getName());
-
-      if (component == null) {
-        LOG.error("No component exists for " + event.getName());
-        return;
-      }
-      try {
-        component.handle(event);
-      } catch (Throwable t) {
-        LOG.error(MessageFormat
-            .format("[COMPONENT {0}]: Error in handling event type {1}",
-                component.getName(), event.getType()), t);
-      }
-    }
-  }
-
-  private final class ComponentInstanceEventHandler
-      implements EventHandler<ComponentInstanceEvent> {
-    @Override
-    public void handle(ComponentInstanceEvent event) {
-      ComponentInstance instance =
-          liveInstances.get(event.getContainerId());
-      if (instance == null) {
-        LOG.error("No component instance exists for " + event.getContainerId());
-        return;
-      }
-      try {
-        instance.handle(event);
-      } catch (Throwable t) {
-        LOG.error(instance.getCompInstanceId() +
-            ": Error in handling event type " + event.getType(), t);
-      }
-    }
-  }
-
-  class AMRMClientCallback extends AMRMClientAsync.AbstractCallbackHandler {
-
-    @Override
-    public void onContainersAllocated(List<Container> containers) {
-      LOG.info(containers.size() + " containers allocated. ");
-      for (Container container : containers) {
-        Component comp = componentsById.get(container.getAllocationRequestId());
-        ComponentEvent event =
-            new ComponentEvent(comp.getName(), CONTAINER_ALLOCATED)
-                .setContainer(container);
-        dispatcher.getEventHandler().handle(event);
-        try {
-          Collection<AMRMClient.ContainerRequest> requests = amRMClient
-              .getMatchingRequests(container.getAllocationRequestId());
-          LOG.info("[COMPONENT {}]: remove {} outstanding container requests " +
-                  "for allocateId " + container.getAllocationRequestId(),
-              comp.getName(), requests.size());
-          // remove the corresponding request
-          if (requests.iterator().hasNext()) {
-            AMRMClient.ContainerRequest request = requests.iterator().next();
-            amRMClient.removeContainerRequest(request);
-          }
-        } catch(Exception e) {
-          //TODO Due to YARN-7490, exception may be thrown, catch and ignore for
-          //now.
-          LOG.error("Exception when removing the matching requests. ", e);
-        }
-      }
-    }
-
-
-    @Override
-    public void onContainersReceivedFromPreviousAttempts(
-        List<Container> containers) {
-      LOG.info("Containers recovered after AM registered: {}", containers);
-      if (containers == null || containers.isEmpty()) {
-        return;
-      }
-      for (Container container : containers) {
-        ComponentInstance compInstance;
-        synchronized (unRecoveredInstances) {
-          compInstance = unRecoveredInstances.remove(container.getId());
-        }
-        if (compInstance != null) {
-          Component component = componentsById.get(
-              container.getAllocationRequestId());
-          ComponentEvent event = new ComponentEvent(component.getName(),
-              CONTAINER_RECOVERED)
-              .setInstance(compInstance)
-              .setContainerId(container.getId())
-              .setContainer(container);
-          component.handle(event);
-        } else {
-          LOG.info("Not waiting to recover container {}, releasing",
-              container.getId());
-          amRMClient.releaseAssignedContainer(container.getId());
-        }
-      }
-    }
-
-    @Override
-    public void onContainersCompleted(List<ContainerStatus> statuses) {
-      for (ContainerStatus status : statuses) {
-        ContainerId containerId = status.getContainerId();
-        ComponentInstance instance = liveInstances.get(status.getContainerId());
-        if (instance == null) {
-          LOG.warn(
-              "Container {} Completed. No component instance exists. exitStatus={}. diagnostics={} ",
-              containerId, status.getExitStatus(), status.getDiagnostics());
-          continue;
-        }
-        ComponentEvent event =
-            new ComponentEvent(instance.getCompName(), CONTAINER_COMPLETED)
-                .setStatus(status).setInstance(instance)
-                .setContainerId(containerId);
-        dispatcher.getEventHandler().handle(event);
-      }
-    }
-
-    @Override
-    public void onContainersUpdated(List<UpdatedContainer> containers) {
-    }
-
-    @Override public void onShutdownRequest() {
-      //Was used for non-work-preserving restart in YARN, should be deprecated.
-    }
-
-    @Override public void onNodesUpdated(List<NodeReport> updatedNodes) {
-      StringBuilder str = new StringBuilder();
-      str.append("Nodes updated info: ").append(System.lineSeparator());
-      for (NodeReport report : updatedNodes) {
-        str.append(report.getNodeId()).append(", state = ")
-            .append(report.getNodeState()).append(", healthDiagnostics = ")
-            .append(report.getHealthReport()).append(System.lineSeparator());
-      }
-      LOG.warn(str.toString());
-    }
-
-    @Override public float getProgress() {
-      // get running containers over desired containers
-      long total = 0;
-      for (org.apache.hadoop.yarn.service.api.records.Component component : app
-          .getComponents()) {
-        total += component.getNumberOfContainers();
-      }
-      // Probably due to user flexed down to 0
-      if (total == 0) {
-        return 100;
-      }
-      return Math.max((float) liveInstances.size() / total * 100, 100);
-    }
-
-    @Override public void onError(Throwable e) {
-      LOG.error("Error in AMRMClient callback handler ", e);
-    }
-
-    @Override
-    public void onRequestsRejected(
-        List<RejectedSchedulingRequest> rejectedSchedulingRequests) {
-      LOG.error("Error in AMRMClient callback handler. Following scheduling "
-          + "requests were rejected: {}", rejectedSchedulingRequests);
-    }
-  }
-
-  private class NMClientCallback extends NMClientAsync.AbstractCallbackHandler {
-
-    @Override public void onContainerStarted(ContainerId containerId,
-        Map<String, ByteBuffer> allServiceResponse) {
-      ComponentInstance instance = liveInstances.get(containerId);
-      if (instance == null) {
-        LOG.error("No component instance exists for " + containerId);
-        return;
-      }
-      ComponentEvent event =
-          new ComponentEvent(instance.getCompName(), CONTAINER_STARTED)
-              .setInstance(instance).setContainerId(containerId);
-      dispatcher.getEventHandler().handle(event);
-    }
-
-    @Override public void onContainerStatusReceived(ContainerId containerId,
-        ContainerStatus containerStatus) {
-
-    }
-
-    @Override public void onContainerStopped(ContainerId containerId) {
-
-    }
-
-    @Override
-    public void onStartContainerError(ContainerId containerId, Throwable t) {
-      ComponentInstance instance = liveInstances.get(containerId);
-      if (instance == null) {
-        LOG.error("No component instance exists for " + containerId);
-        return;
-      }
-      LOG.error("Failed to start " + containerId, t);
-      amRMClient.releaseAssignedContainer(containerId);
-      // After container released, it'll get CONTAINER_COMPLETED event from RM
-      // automatically which will trigger stopping COMPONENT INSTANCE
-    }
-
-    @Override
-    public void onContainerReInitialize(ContainerId containerId) {
-      ComponentInstance instance = liveInstances.get(containerId);
-      if (instance == null) {
-        LOG.error("No component instance exists for {}", containerId);
-        return;
-      }
-      dispatcher.getEventHandler().handle(
-          new ComponentInstanceEvent(containerId, START));
-    }
-
-    @Override
-    public void onContainerReInitializeError(ContainerId containerId,
-        Throwable t) {
-      ComponentInstance instance = liveInstances.get(containerId);
-      if (instance == null) {
-        LOG.error("No component instance exists for {}", containerId);
-        return;
-      }
-      ComponentEvent event = new ComponentEvent(instance.getCompName(),
-          ComponentEventType.CONTAINER_COMPLETED)
-          .setInstance(instance).setContainerId(containerId);
-      dispatcher.getEventHandler().handle(event);
-    }
-
-    @Override public void onContainerResourceIncreased(ContainerId containerId,
-        Resource resource) {
-
-    }
-
-    @Override public void onContainerResourceUpdated(ContainerId containerId,
-        Resource resource) {
-
-    }
-
-    @Override public void onGetContainerStatusError(ContainerId containerId,
-        Throwable t) {
-
-    }
-
-    @Override
-    public void onIncreaseContainerResourceError(ContainerId containerId,
-        Throwable t) {
-
-    }
-
-    @Override
-    public void onUpdateContainerResourceError(ContainerId containerId,
-        Throwable t) {
-
-    }
-
-    @Override
-    public void onStopContainerError(ContainerId containerId, Throwable t) {
-
-    }
-  }
-
-  public ServiceMetrics getServiceMetrics() {
-    return serviceMetrics;
-  }
-
-  public AMRMClientAsync<AMRMClient.ContainerRequest> getAmRMClient() {
-    return amRMClient;
-  }
-
-  public NMClientAsync getNmClient() {
-    return nmClient;
-  }
-
-  public void addLiveCompInstance(ContainerId containerId,
-      ComponentInstance instance) {
-    liveInstances.put(containerId, instance);
-  }
-
-  public void removeLiveCompInstance(ContainerId containerId) {
-    liveInstances.remove(containerId);
-  }
-
-  public YarnRegistryViewForProviders getYarnRegistryOperations() {
-    return yarnRegistryOperations;
-  }
-
-  public ServiceTimelinePublisher getServiceTimelinePublisher() {
-    return serviceTimelinePublisher;
-  }
-
-  public Map<ContainerId, ComponentInstance> getLiveInstances() {
-    return liveInstances;
-  }
-
-  public ContainerLaunchService getContainerLaunchService() {
-    return containerLaunchService;
-  }
-
-  public ServiceContext getContext() {
-    return context;
-  }
-
-  public Map<String, Component> getAllComponents() {
-    return componentsByName;
-  }
-
-  public Service getApp() {
-    return app;
-  }
-
-  public AsyncDispatcher getDispatcher() {
-    return dispatcher;
-  }
-
-  public BoundedAppender getDiagnostics() {
-    return diagnostics;
-  }
-
-  public boolean hasAtLeastOnePlacementConstraint() {
-    return hasAtLeastOnePlacementConstraint;
-  }
-
-  public boolean terminateServiceIfNeeded(Component component) {
-    boolean serviceIsTerminated =
-        terminateServiceIfDominantComponentFinished(component) ||
-            terminateServiceIfAllComponentsFinished();
-    return serviceIsTerminated;
-  }
-
-  /**
-   * If the service state component is finished, the service is also terminated.
-   * @param component
-   */
-  private boolean terminateServiceIfDominantComponentFinished(Component
-      component) {
-    boolean shouldTerminate = false;
-    boolean componentIsDominant = component.getComponentSpec()
-        .getConfiguration().getPropertyBool(
-            CONTAINER_STATE_REPORT_AS_SERVICE_STATE, false);
-    if (componentIsDominant) {
-      ComponentRestartPolicy restartPolicy =
-          component.getRestartPolicyHandler();
-      if (restartPolicy.shouldTerminate(component)) {
-        shouldTerminate = true;
-        boolean isSucceeded = restartPolicy.hasCompletedSuccessfully(component);
-        org.apache.hadoop.yarn.service.api.records.ComponentState state
-            = isSucceeded ?
-            org.apache.hadoop.yarn.service.api.records.ComponentState.SUCCEEDED
-            : org.apache.hadoop.yarn.service.api.records.ComponentState.FAILED;
-        LOG.info("{} Component state changed from {} to {}",
-            component.getName(), component.getComponentSpec().getState(),
-            state);
-        component.getComponentSpec().setState(state);
-        LOG.info("Dominate component {} finished, exiting Service Master... " +
-                ", final status=" + (isSucceeded ? "Succeeded" : "Failed"),
-            component.getName());
-        terminateService(isSucceeded);
-      }
-    }
-    return shouldTerminate;
-  }
-
-  /*
-   * Check if all components of the scheduler finished.
-   * If all components finished
-   * (which #failed-instances + #suceeded-instances = #total-n-containers)
-   * The service will be terminated.
-  */
-  private boolean terminateServiceIfAllComponentsFinished() {
-    boolean shouldTerminate = true;
-
-    // Succeeded comps and failed comps, for logging purposes.
-    Set<String> succeededComponents = new HashSet<>();
-    Set<String> failedComponents = new HashSet<>();
-
-    for (Component comp : getAllComponents().values()) {
-      ComponentRestartPolicy restartPolicy = comp.getRestartPolicyHandler();
-
-      if (restartPolicy.shouldTerminate(comp)) {
-        if (restartPolicy.hasCompletedSuccessfully(comp)) {
-          LOG.info("{} Component state changed from {} to {}",
-              comp.getName(), comp.getComponentSpec().getState(),
-              org.apache.hadoop
-                  .yarn.service.api.records.ComponentState.SUCCEEDED);
-          comp.getComponentSpec().setState(org.apache.hadoop
-              .yarn.service.api.records.ComponentState.SUCCEEDED);
-        } else {
-          LOG.info("{} Component state changed from {} to {}",
-              comp.getName(), comp.getComponentSpec().getState(),
-              org.apache.hadoop
-                  .yarn.service.api.records.ComponentState.FAILED);
-          comp.getComponentSpec().setState(org.apache.hadoop
-              .yarn.service.api.records.ComponentState.FAILED);
-        }
-
-        if (isTimelineServiceEnabled()) {
-          // record in ATS
-          serviceTimelinePublisher.componentFinished(comp.getComponentSpec(),
-              comp.getComponentSpec().getState(), systemClock.getTime());
-        }
-      } else {
-        shouldTerminate = false;
-        break;
-      }
-
-      long nFailed = comp.getNumFailedInstances();
-
-      if (nFailed > 0) {
-        failedComponents.add(comp.getName());
-      } else {
-        succeededComponents.add(comp.getName());
-      }
-    }
-
-    if (shouldTerminate) {
-      LOG.info("All component finished, exiting Service Master... "
-          + ", final status=" + (failedComponents.isEmpty() ?
-          "Succeeded" :
-          "Failed"));
-      LOG.info("Succeeded components: [" + org.apache.commons.lang3.StringUtils
-          .join(succeededComponents, ",") + "]");
-      LOG.info("Failed components: [" + org.apache.commons.lang3.StringUtils
-          .join(failedComponents, ",") + "]");
-
-      terminateService(failedComponents.isEmpty());
-    }
-    return shouldTerminate;
-  }
-
-  private void terminateService(boolean isSucceeded) {
-    int exitStatus = EXIT_SUCCESS;
-    if (isSucceeded) {
-      setGracefulStop(FinalApplicationStatus.SUCCEEDED);
-      app.setState(ServiceState.SUCCEEDED);
-    } else {
-      setGracefulStop(FinalApplicationStatus.FAILED);
-      app.setState(ServiceState.FAILED);
-      exitStatus = EXIT_FALSE;
-    }
-
-    getTerminationHandler().terminate(exitStatus);
-  }
-
-  public Clock getSystemClock() {
-    return systemClock;
-  }
-
-  public boolean isTimelineServiceEnabled() {
-    return timelineServiceEnabled;
-  }
-
-  public ServiceUtils.ProcessTerminationHandler getTerminationHandler() {
-    return terminationHandler;
-  }
-
-  public void syncSysFs(Service yarnApp) {
-    boolean success = true;
-    Configuration conf = getConfig();
-    String spec;
-    boolean useKerberos = UserGroupInformation.isSecurityEnabled();
-    boolean printSyncResult = false;
-    try {
-      String port = conf.get("yarn.nodemanager.webapp.address").split(":")[1];
-      spec = ServiceApiUtil.jsonSerDeser.toJson(yarnApp);
-      for (org.apache.hadoop.yarn.service.api.records.Component c :
-          yarnApp.getComponents()) {
-        Set<String> nodes = new HashSet<String>();
-        boolean update = Boolean.parseBoolean(c.getConfiguration()
-            .getEnv(ApplicationConstants.Environment
-                .YARN_CONTAINER_RUNTIME_YARN_SYSFS_ENABLE.name()));
-        if (!update) {
-          continue;
-        }
-        printSyncResult = true;
-        for (org.apache.hadoop.yarn.service.api.records.Container container :
-            c.getContainers()) {
-          String bareHost = container.getBareHost();
-          nodes.add(bareHost);
-        }
-        for (String bareHost : nodes) {
-          StringBuilder requestPath = new StringBuilder();
-          if (YarnConfiguration.useHttps(conf)) {
-            requestPath.append("https://");
-          } else {
-            requestPath.append("http://");
-          }
-          requestPath.append(bareHost)
-              .append(":")
-              .append(port)
-              .append("/ws/v1/node/yarn/sysfs/")
-              .append(UserGroupInformation.getCurrentUser()
-                  .getShortUserName())
-              .append("/")
-              .append(yarnApp.getId());
-          if (!useKerberos) {
-            requestPath.append("?user.name=")
-                .append(UserGroupInformation.getCurrentUser()
-                    .getShortUserName());
-          }
-          Builder builder = HttpUtil.connect(requestPath.toString());
-          ClientResponse response = builder.put(ClientResponse.class, spec);
-          if (response.getStatus()!=ClientResponse.Status.OK.getStatusCode()) {
-            LOG.warn("Error synchronize YARN sysfs: " +
-                response.getEntity(String.class));
-            success = false;
-          }
-        }
-      }
-      if (printSyncResult && success) {
-        LOG.info("YARN sysfs synchronized.");
-      }
-    } catch (IOException | URISyntaxException | InterruptedException e) {
-      LOG.error("Fail to sync service spec.", e);
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/UpgradeComponentsFinder.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/UpgradeComponentsFinder.java
deleted file mode 100644
index 7a88ccf46c7..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/UpgradeComponentsFinder.java
+++ /dev/null
@@ -1,159 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.api.records.Service;
-
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Objects;
-
-/**
- * Finds all the the target component specs.
- */
-public interface UpgradeComponentsFinder {
-
-  List<Component> findTargetComponentSpecs(Service currentDef,
-      Service targetDef);
-
-  /**
-   * Default implementation of {@link UpgradeComponentsFinder} that finds all
-   * the target component specs.
-   */
-  class DefaultUpgradeComponentsFinder implements UpgradeComponentsFinder {
-
-    @Override
-    public List<Component> findTargetComponentSpecs(Service currentDef,
-        Service targetDef) {
-      if (currentDef.getComponents().size() !=
-          targetDef.getComponents().size()) {
-        throw new UnsupportedOperationException(
-            "addition/deletion of components not supported by upgrade");
-      }
-      if (!currentDef.getKerberosPrincipal().equals(
-          targetDef.getKerberosPrincipal())) {
-        throw new UnsupportedOperationException("changes to kerberos " +
-            "principal not supported by upgrade");
-      }
-      if (!Objects.equals(currentDef.getQueue(), targetDef.getQueue())) {
-        throw new UnsupportedOperationException("changes to queue " +
-            "not supported by upgrade");
-      }
-
-      if (!Objects.equals(currentDef.getResource(), targetDef.getResource())) {
-        throw new UnsupportedOperationException("changes to resource " +
-            "not supported by upgrade");
-      }
-
-      if (!Objects.equals(currentDef.getDescription(),
-          targetDef.getDescription())) {
-        throw new UnsupportedOperationException("changes to description " +
-            "not supported by upgrade");
-      }
-
-      if (!Objects.equals(currentDef.getLaunchTime(),
-          targetDef.getLaunchTime())) {
-        throw new UnsupportedOperationException("changes to launch time " +
-            "not supported by upgrade");
-      }
-
-
-      if (!Objects.equals(currentDef.getLifetime(),
-          targetDef.getLifetime())) {
-        throw new UnsupportedOperationException("changes to lifetime " +
-            "not supported by upgrade");
-      }
-
-      if (!Objects.equals(currentDef.getConfiguration(),
-          targetDef.getConfiguration())) {
-        return targetDef.getComponents();
-      }
-
-      if (!Objects.equals(currentDef.getArtifact(), targetDef.getArtifact())) {
-        return targetDef.getComponents();
-      }
-
-      List<Component> targetComps = new ArrayList<>();
-      targetDef.getComponents().forEach(component -> {
-        Component currentComp = currentDef.getComponent(component.getName());
-
-        if (currentComp != null) {
-          if (!Objects.equals(currentComp.getName(), component.getName())) {
-            throw new UnsupportedOperationException(
-                "changes to component name not supported by upgrade");
-          }
-
-          if (!Objects.equals(currentComp.getDependencies(),
-              component.getDependencies())) {
-            throw new UnsupportedOperationException(
-                "changes to component dependencies not supported by upgrade");
-          }
-
-          if (!Objects.equals(currentComp.getReadinessCheck(),
-              component.getReadinessCheck())) {
-            throw new UnsupportedOperationException(
-                "changes to component readiness check not supported by "
-                    + "upgrade");
-          }
-
-          if (!Objects.equals(currentComp.getResource(),
-              component.getResource())) {
-
-            throw new UnsupportedOperationException(
-                "changes to component resource not supported by upgrade");
-          }
-
-          if (!Objects.equals(currentComp.getRunPrivilegedContainer(),
-              component.getRunPrivilegedContainer())) {
-            throw new UnsupportedOperationException(
-                "changes to run privileged container not supported by upgrade");
-          }
-
-          if (!Objects.equals(currentComp.getPlacementPolicy(),
-              component.getPlacementPolicy())) {
-            throw new UnsupportedOperationException(
-                "changes to component placement policy not supported by "
-                    + "upgrade");
-          }
-
-          if (!Objects.equals(currentComp.getQuicklinks(),
-              component.getQuicklinks())) {
-            throw new UnsupportedOperationException(
-                "changes to component quick links not supported by upgrade");
-          }
-
-          if (!Objects.equals(currentComp.getArtifact(),
-              component.getArtifact()) || !Objects.equals(
-              currentComp.getLaunchCommand(), component.getLaunchCommand())
-              || !Objects.equals(currentComp.getConfiguration(),
-              component.getConfiguration())) {
-            targetComps.add(component);
-          }
-        } else{
-          throw new UnsupportedOperationException(
-              "addition/deletion of components not supported by upgrade. "
-                  + "Could not find component " + component.getName() + " in "
-                  + "current service definition.");
-        }
-      });
-      return targetComps;
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/ServiceApiConstants.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/ServiceApiConstants.java
deleted file mode 100644
index a4f2243d227..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/ServiceApiConstants.java
+++ /dev/null
@@ -1,74 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api;
-
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-
-import static org.apache.hadoop.yarn.service.utils.ServiceApiUtil.$;
-
-/**
- * This class defines constants that can be used in input spec for
- * variable substitutions
- */
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-public interface ServiceApiConstants {
-
-  // Constants for service
-  String SERVICE_NAME = $("SERVICE_NAME");
-
-  String SERVICE_NAME_LC = $("SERVICE_NAME.lc");
-
-  String USER = $("USER");
-
-  String DOMAIN = $("DOMAIN");
-
-  // Constants for component
-  String COMPONENT_NAME = $("COMPONENT_NAME");
-
-  String COMPONENT_NAME_LC = $("COMPONENT_NAME.lc");
-
-  String COMPONENT_INSTANCE_NAME = $("COMPONENT_INSTANCE_NAME");
-
-  // Constants for component instance
-  String COMPONENT_ID = $("COMPONENT_ID");
-
-  String CONTAINER_ID = $("CONTAINER_ID");
-
-  // Templates for component instance host/IP
-  String COMPONENT_INSTANCE_HOST = $("%s_HOST");
-
-  String COMPONENT_INSTANCE_IP = $("%s_IP");
-
-  // Constants for default cluster ZK
-  String CLUSTER_ZK_QUORUM = $("CLUSTER_ZK_QUORUM");
-
-  // URI for the default cluster fs
-  String CLUSTER_FS_URI = $("CLUSTER_FS_URI");
-
-  // the host component of the cluster fs UI
-  String CLUSTER_FS_HOST = $("CLUSTER_FS_HOST");
-
-  // Path in zookeeper for a specific service
-  String SERVICE_ZK_PATH = $("SERVICE_ZK_PATH");
-
-  // Constants for service specific hdfs dir
-  String SERVICE_HDFS_DIR = $("SERVICE_HDFS_DIR");
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Artifact.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Artifact.java
deleted file mode 100644
index 12979f38430..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Artifact.java
+++ /dev/null
@@ -1,166 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import io.swagger.annotations.ApiModel;
-import io.swagger.annotations.ApiModelProperty;
-
-import java.io.Serializable;
-import java.util.Objects;
-
-import javax.xml.bind.annotation.XmlEnum;
-import javax.xml.bind.annotation.XmlType;
-
-import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonProperty;
-import com.fasterxml.jackson.annotation.JsonValue;
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-
-/**
- * Artifact of an service component.
- **/
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-@ApiModel(description = "Artifact of an service component")
-@JsonInclude(JsonInclude.Include.NON_NULL)
-public class Artifact implements Serializable {
-  private static final long serialVersionUID = 3608929500111099035L;
-
-  private String id = null;
-
-  /**
-   * Artifact Type.  DOCKER, TARBALL or SERVICE
-   **/
-  @XmlType(name = "artifact_type")
-  @XmlEnum
-  public enum TypeEnum {
-    DOCKER("DOCKER"), TARBALL("TARBALL"), SERVICE("SERVICE");
-
-    private String value;
-
-    TypeEnum(String value) {
-      this.value = value;
-    }
-
-    @Override
-    @JsonValue
-    public String toString() {
-      return value;
-    }
-  }
-
-  private TypeEnum type = TypeEnum.DOCKER;
-  private String uri = null;
-
-  /**
-   * Artifact id. Examples are package location uri for tarball based services,
-   * image name for docker, etc.
-   **/
-  public Artifact id(String id) {
-    this.id = id;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", required = true, value = "Artifact id. Examples are package location uri for tarball based services, image name for docker, etc.")
-  @JsonProperty("id")
-  public String getId() {
-    return id;
-  }
-
-  public void setId(String id) {
-    this.id = id;
-  }
-
-  /**
-   * Artifact type, like docker, tarball, etc. (optional).
-   **/
-  public Artifact type(TypeEnum type) {
-    this.type = type;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Artifact type, like docker, tarball, etc. (optional).")
-  @JsonProperty("type")
-  public TypeEnum getType() {
-    return type;
-  }
-
-  public void setType(TypeEnum type) {
-    this.type = type;
-  }
-
-  /**
-   * Artifact location to support multiple artifact stores (optional).
-   **/
-  public Artifact uri(String uri) {
-    this.uri = uri;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Artifact location to support multiple artifact stores (optional).")
-  @JsonProperty("uri")
-  public String getUri() {
-    return uri;
-  }
-
-  public void setUri(String uri) {
-    this.uri = uri;
-  }
-
-  @Override
-  public boolean equals(java.lang.Object o) {
-    if (this == o) {
-      return true;
-    }
-    if (o == null || getClass() != o.getClass()) {
-      return false;
-    }
-    Artifact artifact = (Artifact) o;
-    return Objects.equals(this.id, artifact.id)
-        && Objects.equals(this.type, artifact.type)
-        && Objects.equals(this.uri, artifact.uri);
-  }
-
-  @Override
-  public int hashCode() {
-    return Objects.hash(id, type, uri);
-  }
-
-  @Override
-  public String toString() {
-    StringBuilder sb = new StringBuilder();
-    sb.append("class Artifact {\n")
-        .append("    id: ").append(toIndentedString(id)).append("\n")
-        .append("    type: ").append(toIndentedString(type)).append("\n")
-        .append("    uri: ").append(toIndentedString(uri)).append("\n")
-        .append("}");
-    return sb.toString();
-  }
-
-  /**
-   * Convert the given object to string with each line indented by 4 spaces
-   * (except the first line).
-   */
-  private String toIndentedString(java.lang.Object o) {
-    if (o == null) {
-      return "null";
-    }
-    return o.toString().replace("\n", "\n    ");
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/BaseResource.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/BaseResource.java
deleted file mode 100644
index 4ccb3903173..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/BaseResource.java
+++ /dev/null
@@ -1,52 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-
-import java.io.Serializable;
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-public class BaseResource implements Serializable {
-  private static final long serialVersionUID = 1492603053176889431L;
-
-  private String uri;
-
-  /**
-   * Resource location for a service, e.g.
-   * /app/v1/services/helloworld
-   *
-   **/
-  public String getUri() {
-    return uri;
-  }
-
-  public void setUri(String uri) {
-    this.uri = uri;
-  }
-
-  @Override
-  public String toString() {
-    StringBuilder builder = new StringBuilder();
-    builder.append("BaseResource [uri=")
-        .append(uri)
-        .append("]");
-    return builder.toString();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Component.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Component.java
deleted file mode 100644
index 8a5b7d402f7..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Component.java
+++ /dev/null
@@ -1,563 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import com.fasterxml.jackson.annotation.JsonValue;
-import io.swagger.annotations.ApiModel;
-import io.swagger.annotations.ApiModelProperty;
-
-import java.io.Serializable;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.List;
-import java.util.Objects;
-
-import javax.xml.bind.annotation.XmlAccessType;
-import javax.xml.bind.annotation.XmlAccessorType;
-import javax.xml.bind.annotation.XmlElement;
-import javax.xml.bind.annotation.XmlEnum;
-import javax.xml.bind.annotation.XmlRootElement;
-import javax.xml.bind.annotation.XmlType;
-
-import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonProperty;
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-
-/**
- * One or more components of the service. If the service is HBase say,
- * then the component can be a simple role like master or regionserver. If the
- * service is a complex business webapp then a component can be other
- * services say Kafka or Storm. Thereby it opens up the support for complex
- * and nested services.
- **/
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-@ApiModel(description = "One or more components of the service. If the service is HBase say, then the component can be a simple role like master or regionserver. If the service is a complex business webapp then a component can be other services say Kafka or Storm. Thereby it opens up the support for complex and nested services.")
-@XmlRootElement
-@XmlAccessorType(XmlAccessType.FIELD)
-@JsonInclude(JsonInclude.Include.NON_NULL)
-public class Component implements Serializable {
-  private static final long serialVersionUID = -8430058381509087805L;
-
-  @JsonProperty("name")
-  private String name = null;
-
-  @JsonProperty("dependencies")
-  private List<String> dependencies = new ArrayList<String>();
-
-  @JsonProperty("readiness_check")
-  @XmlElement(name = "readiness_check")
-  private ReadinessCheck readinessCheck = null;
-
-  @JsonProperty("artifact")
-  private Artifact artifact = null;
-
-  @JsonProperty("launch_command")
-  @XmlElement(name = "launch_command")
-  private String launchCommand = null;
-
-  @JsonProperty("resource")
-  private Resource resource = null;
-
-  @JsonProperty("number_of_containers")
-  @XmlElement(name = "number_of_containers")
-  private Long numberOfContainers = null;
-
-  @JsonProperty("decommissioned_instances")
-  @XmlElement(name = "decommissioned_instances")
-  private List<String> decommissionedInstances = new ArrayList<>();
-
-  @JsonProperty("run_privileged_container")
-  @XmlElement(name = "run_privileged_container")
-  private Boolean runPrivilegedContainer = false;
-
-  @JsonProperty("placement_policy")
-  @XmlElement(name = "placement_policy")
-  private PlacementPolicy placementPolicy = null;
-
-  @JsonProperty("state")
-  private ComponentState state = ComponentState.FLEXING;
-
-  @JsonProperty("configuration")
-  private Configuration configuration = new Configuration();
-
-  @JsonProperty("quicklinks")
-  private List<String> quicklinks = new ArrayList<String>();
-
-  @JsonProperty("containers")
-  private List<Container> containers =
-      Collections.synchronizedList(new ArrayList<Container>());
-
-
-  @JsonProperty("restart_policy")
-  @XmlElement(name = "restart_policy")
-  private RestartPolicyEnum restartPolicy = RestartPolicyEnum.ALWAYS;
-
-  /**
-   * Policy of restart component. Including ALWAYS - Long lived components
-   * (Always restart component instance even if instance exit code &#x3D; 0.);
-   *
-   * ON_FAILURE (Only restart component instance if instance exit code !&#x3D;
-   * 0);
-   * NEVER (Do not restart in any cases)
-   *
-   * @return restartPolicy
-   **/
-  @XmlType(name = "restart_policy")
-  @XmlEnum
-  public enum RestartPolicyEnum {
-    ALWAYS("ALWAYS"),
-
-    ON_FAILURE("ON_FAILURE"),
-
-    NEVER("NEVER");
-    private String value;
-
-    RestartPolicyEnum(String value) {
-      this.value = value;
-    }
-
-    @Override
-    @JsonValue
-    public String toString() {
-      return value;
-    }
-  }
-
-  public Component restartPolicy(RestartPolicyEnum restartPolicyEnumVal) {
-    this.restartPolicy = restartPolicyEnumVal;
-    return this;
-  }
-
-  /**
-   * Policy of restart component.
-   *
-   * Including
-   * ALWAYS (Always restart component instance even if instance exit
-   * code &#x3D; 0);
-   *
-   * ON_FAILURE (Only restart component instance if instance exit code !&#x3D;
-   * 0);
-   *
-   * NEVER (Do not restart in any cases)
-   *
-   * @return restartPolicy
-   **/
-  @ApiModelProperty(value = "Policy of restart component. Including ALWAYS "
-      + "(Always restart component even if instance exit code = 0); "
-      + "ON_FAILURE (Only restart component if instance exit code != 0); "
-      + "NEVER (Do not restart in any cases)")
-  public RestartPolicyEnum getRestartPolicy() {
-    return restartPolicy;
-  }
-
-  public void setRestartPolicy(RestartPolicyEnum restartPolicy) {
-    this.restartPolicy = restartPolicy;
-  }
-
-
-  /**
-   * Name of the service component (mandatory).
-   **/
-  public Component name(String name) {
-    this.name = name;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", required = true, value = "Name of the service component (mandatory).")
-  public String getName() {
-    return name;
-  }
-
-  public void setName(String name) {
-    this.name = name;
-  }
-
-  /**
-   * An array of service components which should be in READY state (as
-   * defined by readiness check), before this component can be started. The
-   * dependencies across all components of a service should be represented
-   * as a DAG.
-   **/
-  public Component dependencies(List<String> dependencies) {
-    this.dependencies = dependencies;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "An array of service components which should be in READY state (as defined by readiness check), before this component can be started. The dependencies across all components of an service should be represented as a DAG.")
-  public List<String> getDependencies() {
-    return dependencies;
-  }
-
-  public void setDependencies(List<String> dependencies) {
-    this.dependencies = dependencies;
-  }
-
-  /**
-   * Readiness check for this component.
-   **/
-  public Component readinessCheck(ReadinessCheck readinessCheck) {
-    this.readinessCheck = readinessCheck;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Readiness check for this component.")
-  public ReadinessCheck getReadinessCheck() {
-    return readinessCheck;
-  }
-
-  public void setReadinessCheck(ReadinessCheck readinessCheck) {
-    this.readinessCheck = readinessCheck;
-  }
-
-  /**
-   * Artifact of the component (optional). If not specified, the service
-   * level global artifact takes effect.
-   **/
-  public Component artifact(Artifact artifact) {
-    this.artifact = artifact;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Artifact of the component (optional). If not specified, the service level global artifact takes effect.")
-  public Artifact getArtifact() {
-    return artifact;
-  }
-
-  public void setArtifact(Artifact artifact) {
-    this.artifact = artifact;
-  }
-
-  /**
-   * The custom launch command of this component (optional). When specified at
-   * the component level, it overrides the value specified at the global level
-   * (if any).
-   **/
-  public Component launchCommand(String launchCommand) {
-    this.launchCommand = launchCommand;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "The custom launch command of this component (optional). When specified at the component level, it overrides the value specified at the global level (if any).")
-  public String getLaunchCommand() {
-    return launchCommand;
-  }
-
-  public void setLaunchCommand(String launchCommand) {
-    this.launchCommand = launchCommand;
-  }
-
-  /**
-   * Resource of this component (optional). If not specified, the service
-   * level global resource takes effect.
-   **/
-  public Component resource(Resource resource) {
-    this.resource = resource;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Resource of this component (optional). If not specified, the service level global resource takes effect.")
-  public Resource getResource() {
-    return resource;
-  }
-
-  public void setResource(Resource resource) {
-    this.resource = resource;
-  }
-
-  /**
-   * Number of containers for this component (optional). If not specified,
-   * the service level global number_of_containers takes effect.
-   **/
-  public Component numberOfContainers(Long numberOfContainers) {
-    this.numberOfContainers = numberOfContainers;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Number of containers for this component (optional). If not specified, the service level global number_of_containers takes effect.")
-  public Long getNumberOfContainers() {
-    return numberOfContainers;
-  }
-
-  public void setNumberOfContainers(Long numberOfContainers) {
-    this.numberOfContainers = numberOfContainers;
-  }
-
-  /**
-   * A list of decommissioned component instances.
-   **/
-  public Component decommissionedInstances(List<String>
-      decommissionedInstances) {
-    this.decommissionedInstances = decommissionedInstances;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "A list of decommissioned component instances.")
-  public List<String> getDecommissionedInstances() {
-    return decommissionedInstances;
-  }
-
-  public void setDecommissionedInstances(List<String> decommissionedInstances) {
-    this.decommissionedInstances = decommissionedInstances;
-  }
-
-  public void addDecommissionedInstance(String componentInstanceName) {
-    this.decommissionedInstances.add(componentInstanceName);
-  }
-
-  @ApiModelProperty(example = "null", value = "Containers of a started component. Specifying a value for this attribute for the POST payload raises a validation error. This blob is available only in the GET response of a started service.")
-  public List<Container> getContainers() {
-    return containers;
-  }
-
-  public void setContainers(List<Container> containers) {
-    this.containers = containers;
-  }
-
-  public void addContainer(Container container) {
-    this.containers.add(container);
-  }
-
-  public void removeContainer(Container container) {
-    containers.remove(container);
-  }
-  public Container getContainer(String id) {
-    for (Container container : containers) {
-      if (container.getId().equals(id)) {
-        return container;
-      }
-    }
-    return null;
-  }
-
-  public Container getComponentInstance(String compInstanceName) {
-    for (Container container : containers) {
-      if (compInstanceName.equals(container.getComponentInstanceName())) {
-        return container;
-      }
-    }
-    return null;
-  }
-
-  /**
-   * Run all containers of this component in privileged mode (YARN-4262).
-   **/
-  public Component runPrivilegedContainer(Boolean runPrivilegedContainer) {
-    this.runPrivilegedContainer = runPrivilegedContainer;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Run all containers of this component in privileged mode (YARN-4262).")
-  public Boolean getRunPrivilegedContainer() {
-    return runPrivilegedContainer;
-  }
-
-  public void setRunPrivilegedContainer(Boolean runPrivilegedContainer) {
-    this.runPrivilegedContainer = runPrivilegedContainer;
-  }
-
-  /**
-   * Advanced scheduling and placement policies for all containers of this
-   * component.
-   **/
-  public Component placementPolicy(PlacementPolicy placementPolicy) {
-    this.placementPolicy = placementPolicy;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Advanced scheduling and "
-      + "placement policies for all containers of this component.")
-  public PlacementPolicy getPlacementPolicy() {
-    return placementPolicy;
-  }
-
-  public void setPlacementPolicy(PlacementPolicy placementPolicy) {
-    this.placementPolicy = placementPolicy;
-  }
-
-  /**
-   * Config properties for this component.
-   **/
-  public Component configuration(Configuration configuration) {
-    this.configuration = configuration;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Config properties for this component.")
-  public Configuration getConfiguration() {
-    return configuration;
-  }
-
-  public void setConfiguration(Configuration configuration) {
-    this.configuration = configuration;
-  }
-
-  /**
-   * A list of quicklink keys defined at the service level, and to be
-   * resolved by this component.
-   **/
-  public Component quicklinks(List<String> quicklinks) {
-    this.quicklinks = quicklinks;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "A list of quicklink keys defined at the service level, and to be resolved by this component.")
-  public List<String> getQuicklinks() {
-    return quicklinks;
-  }
-
-  public void setQuicklinks(List<String> quicklinks) {
-    this.quicklinks = quicklinks;
-  }
-
-  public Component state(ComponentState state) {
-    this.state = state;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "State of the component.")
-  public ComponentState getState() {
-    return state;
-  }
-
-  public void setState(ComponentState state) {
-    this.state = state;
-  }
-
-  @Override
-  public boolean equals(java.lang.Object o) {
-    if (this == o) {
-      return true;
-    }
-    if (o == null || getClass() != o.getClass()) {
-      return false;
-    }
-    Component component = (Component) o;
-    return Objects.equals(this.name, component.name)
-        && Objects.equals(this.dependencies, component.dependencies)
-        && Objects.equals(this.readinessCheck, component.readinessCheck)
-        && Objects.equals(this.artifact, component.artifact)
-        && Objects.equals(this.launchCommand, component.launchCommand)
-        && Objects.equals(this.resource, component.resource)
-        && Objects.equals(this.numberOfContainers, component.numberOfContainers)
-        && Objects.equals(this.runPrivilegedContainer,
-            component.runPrivilegedContainer)
-        && Objects.equals(this.placementPolicy, component.placementPolicy)
-        && Objects.equals(this.configuration, component.configuration)
-        && Objects.equals(this.quicklinks, component.quicklinks)
-        && Objects.equals(this.state, component.state);
-  }
-
-  @Override
-  public int hashCode() {
-    return Objects.hash(name, dependencies, readinessCheck, artifact,
-        launchCommand, resource, numberOfContainers,
-        runPrivilegedContainer, placementPolicy, configuration, quicklinks, state);
-  }
-
-  @Override
-  public String toString() {
-    StringBuilder sb = new StringBuilder();
-    sb.append("class Component {\n")
-        .append("    name: ").append(toIndentedString(name)).append("\n")
-        .append("    state: ").append(toIndentedString(state)).append("\n")
-        .append("    dependencies: ").append(toIndentedString(dependencies))
-        .append("\n")
-        .append("    readinessCheck: ").append(toIndentedString(readinessCheck))
-        .append("\n")
-        .append("    artifact: ").append(toIndentedString(artifact))
-        .append("\n")
-        .append("    launchCommand: ").append(toIndentedString(launchCommand))
-        .append("\n")
-        .append("    resource: ").append(toIndentedString(resource))
-        .append("\n")
-        .append("    numberOfContainers: ")
-        .append(toIndentedString(numberOfContainers)).append("\n")
-        .append("    containers: ").append(toIndentedString(containers))
-        .append("\n")
-        .append("    runPrivilegedContainer: ")
-        .append(toIndentedString(runPrivilegedContainer)).append("\n")
-        .append("    placementPolicy: ")
-        .append(toIndentedString(placementPolicy))
-        .append("\n")
-        .append("    configuration: ").append(toIndentedString(configuration))
-        .append("\n")
-        .append("    quicklinks: ").append(toIndentedString(quicklinks))
-        .append("\n")
-        .append("}");
-    return sb.toString();
-  }
-
-  /**
-   * Convert the given object to string with each line indented by 4 spaces
-   * (except the first line).
-   */
-  private String toIndentedString(java.lang.Object o) {
-    if (o == null) {
-      return "null";
-    }
-    return o.toString().replace("\n", "\n    ");
-  }
-
-  /**
-   * Merge from another component into this component without overwriting.
-   */
-  public void mergeFrom(Component that) {
-    if (this.getArtifact() == null) {
-      this.setArtifact(that.getArtifact());
-    }
-    if (this.getResource() == null) {
-      this.setResource(that.getResource());
-    }
-    if (this.getNumberOfContainers() == null) {
-      this.setNumberOfContainers(that.getNumberOfContainers());
-    }
-    if (this.getLaunchCommand() == null) {
-      this.setLaunchCommand(that.getLaunchCommand());
-    }
-    this.getConfiguration().mergeFrom(that.getConfiguration());
-    if (this.getQuicklinks() == null) {
-      this.setQuicklinks(that.getQuicklinks());
-    }
-    if (this.getRunPrivilegedContainer() == null) {
-      this.setRunPrivilegedContainer(that.getRunPrivilegedContainer());
-    }
-    if (this.getDependencies() == null) {
-      this.setDependencies(that.getDependencies());
-    }
-    if (this.getPlacementPolicy() == null) {
-      this.setPlacementPolicy(that.getPlacementPolicy());
-    }
-    if (this.getReadinessCheck() == null) {
-      this.setReadinessCheck(that.getReadinessCheck());
-    }
-  }
-
-  public void overwrite(Component that) {
-    setArtifact(that.getArtifact());
-    setResource(that.resource);
-    setNumberOfContainers(that.getNumberOfContainers());
-    setLaunchCommand(that.getLaunchCommand());
-    setConfiguration(that.configuration);
-    setRunPrivilegedContainer(that.getRunPrivilegedContainer());
-    setDependencies(that.getDependencies());
-    setPlacementPolicy(that.getPlacementPolicy());
-    setReadinessCheck(that.getReadinessCheck());
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ComponentContainers.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ComponentContainers.java
deleted file mode 100644
index 7c8ab4a2a46..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ComponentContainers.java
+++ /dev/null
@@ -1,97 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonProperty;
-import io.swagger.annotations.ApiModel;
-import io.swagger.annotations.ApiModelProperty;
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-
-import java.io.Serializable;
-import java.util.List;
-
-/**
- * Containers of a component.
- */
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-@ApiModel(description = "Containers of a component.")
-@JsonInclude(JsonInclude.Include.NON_NULL)
-public class ComponentContainers implements Serializable {
-
-  private static final long serialVersionUID = -1456748479118874991L;
-
-  @JsonProperty("component_name")
-  private String componentName;
-
-  @JsonProperty("containers")
-  private List<Container> containers;
-
-  @ApiModelProperty(example = "null", required = true,
-      value = "Name of the component.")
-  public String getComponentName() {
-    return componentName;
-  }
-
-  public void setComponentName(String name) {
-    this.componentName = name;
-  }
-
-  /**
-   * Name of the service component.
-   **/
-  public ComponentContainers name(String name) {
-    this.componentName = name;
-    return this;
-  }
-
-  /**
-   * Returns the containers of the component.
-   */
-  @ApiModelProperty(example = "null", value = "Containers of the component.")
-  public List<Container> getContainers() {
-    return containers;
-  }
-
-  /**
-   * Sets the containers.
-   * @param containers containers of the component.
-   */
-  public void setContainers(List<Container> containers) {
-    this.containers = containers;
-  }
-
-  /**
-   * Sets the containers.
-   * @param compContainers containers of the component.
-   */
-  public ComponentContainers containers(List<Container> compContainers) {
-    this.containers = compContainers;
-    return this;
-  }
-
-  /**
-   * Add a container.
-   * @param container container
-   */
-  public void addContainer(Container container) {
-    containers.add(container);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ComponentState.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ComponentState.java
deleted file mode 100644
index 472f3749f70..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ComponentState.java
+++ /dev/null
@@ -1,30 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import io.swagger.annotations.ApiModel;
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-@ApiModel(description = "The current state of a component.")
-public enum ComponentState {
-  FLEXING, STABLE, NEEDS_UPGRADE, UPGRADING, SUCCEEDED, FAILED;
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ConfigFile.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ConfigFile.java
deleted file mode 100644
index 060e2045278..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ConfigFile.java
+++ /dev/null
@@ -1,262 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonProperty;
-import com.fasterxml.jackson.annotation.JsonValue;
-import io.swagger.annotations.ApiModel;
-import io.swagger.annotations.ApiModelProperty;
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-import org.apache.hadoop.yarn.api.records.LocalResourceVisibility;
-
-import javax.xml.bind.annotation.XmlElement;
-import javax.xml.bind.annotation.XmlEnum;
-import javax.xml.bind.annotation.XmlRootElement;
-import javax.xml.bind.annotation.XmlType;
-
-import java.io.Serializable;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.Objects;
-
-/**
- * A config file that needs to be created and made available as a volume in an
- * service component container.
- **/
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-@ApiModel(description = "A config file that needs to be created and made available as a volume in an service component container.")
-@XmlRootElement
-@JsonInclude(JsonInclude.Include.NON_NULL)
-public class ConfigFile implements Serializable {
-  private static final long serialVersionUID = -7009402089417704612L;
-
-  /**
-   * Config Type.  XML, JSON, YAML, TEMPLATE and HADOOP_XML are supported.
-   **/
-  @XmlType(name = "config_type")
-  @XmlEnum
-  public enum TypeEnum {
-    XML("XML"), PROPERTIES("PROPERTIES"), JSON("JSON"), YAML("YAML"), TEMPLATE(
-        "TEMPLATE"), HADOOP_XML("HADOOP_XML"), STATIC("STATIC"), ARCHIVE(
-        "ARCHIVE");
-
-    private String value;
-
-    TypeEnum(String value) {
-      this.value = value;
-    }
-
-    @Override
-    @JsonValue
-    public String toString() {
-      return value;
-    }
-  }
-
-  private TypeEnum type = null;
-  private String destFile = null;
-  private String srcFile = null;
-  private LocalResourceVisibility visibility = null;
-  private Map<String, String> properties = new HashMap<>();
-
-  public ConfigFile copy() {
-    ConfigFile copy = new ConfigFile();
-    copy.setType(this.getType());
-    copy.setSrcFile(this.getSrcFile());
-    copy.setDestFile(this.getDestFile());
-    copy.setVisibility(this.visibility);
-    if (this.getProperties() != null && !this.getProperties().isEmpty()) {
-      copy.getProperties().putAll(this.getProperties());
-    }
-    return copy;
-  }
-
-  /**
-   * Config file in the standard format like xml, properties, json, yaml,
-   * template.
-   **/
-  public ConfigFile type(TypeEnum type) {
-    this.type = type;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Config file in the standard format like xml, properties, json, yaml, template.")
-  @JsonProperty("type")
-  public TypeEnum getType() {
-    return type;
-  }
-
-  public void setType(TypeEnum type) {
-    this.type = type;
-  }
-
-  /**
-   * The absolute path that this configuration file should be mounted as, in the
-   * service container.
-   **/
-  public ConfigFile destFile(String destFile) {
-    this.destFile = destFile;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "The absolute path that this configuration file should be mounted as, in the service container.")
-  @JsonProperty("dest_file")
-  public String getDestFile() {
-    return destFile;
-  }
-
-  @XmlElement(name = "dest_file")
-  public void setDestFile(String destFile) {
-    this.destFile = destFile;
-  }
-
-  /**
-   * This provides the source location of the configuration file, the content
-   * of which is dumped to dest_file post property substitutions, in the format
-   * as specified in type. Typically the src_file would point to a source
-   * controlled network accessible file maintained by tools like puppet, chef,
-   * or hdfs etc. Currently, only hdfs is supported.
-   **/
-  public ConfigFile srcFile(String srcFile) {
-    this.srcFile = srcFile;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "This provides the source location of the configuration file, "
-      + "the content of which is dumped to dest_file post property substitutions, in the format as specified in type. "
-      + "Typically the src_file would point to a source controlled network accessible file maintained by tools like puppet, chef, or hdfs etc. Currently, only hdfs is supported.")
-  @JsonProperty("src_file")
-  public String getSrcFile() {
-    return srcFile;
-  }
-
-  @XmlElement(name = "src_file")
-  public void setSrcFile(String srcFile) {
-    this.srcFile = srcFile;
-  }
-
-
-  /**
-   * Visibility of the Config file.
-   **/
-  public ConfigFile visibility(LocalResourceVisibility localrsrcVisibility) {
-    this.visibility = localrsrcVisibility;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Visibility of the Config file")
-  @JsonProperty("visibility")
-  public LocalResourceVisibility getVisibility() {
-    return visibility;
-  }
-
-  @XmlElement(name = "visibility", defaultValue="APPLICATION")
-  public void setVisibility(LocalResourceVisibility localrsrcVisibility) {
-    this.visibility = localrsrcVisibility;
-  }
-
-  /**
-   A blob of key value pairs that will be dumped in the dest_file in the format
-   as specified in type. If src_file is specified, src_file content are dumped
-   in the dest_file and these properties will overwrite, if any, existing
-   properties in src_file or be added as new properties in src_file.
-   **/
-  public ConfigFile properties(Map<String, String> properties) {
-    this.properties = properties;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "A blob of key value pairs that will be dumped in the dest_file in the format as specified in type."
-      + " If src_file is specified, src_file content are dumped in the dest_file and these properties will overwrite, if any,"
-      + " existing properties in src_file or be added as new properties in src_file.")
-  @JsonProperty("properties")
-  public Map<String, String> getProperties() {
-    return properties;
-  }
-
-  public void setProperties(Map<String, String> properties) {
-    this.properties = properties;
-  }
-
-  public long getLong(String name, long defaultValue) {
-    if (name == null) {
-      return defaultValue;
-    }
-    String value = properties.get(name.trim());
-    return Long.parseLong(value);
-  }
-
-  public boolean getBoolean(String name, boolean defaultValue) {
-    if (name == null) {
-      return defaultValue;
-    }
-    return Boolean.valueOf(properties.get(name.trim()));
-  }
-
-  @Override
-  public boolean equals(java.lang.Object o) {
-    if (this == o) {
-      return true;
-    }
-    if (o == null || getClass() != o.getClass()) {
-      return false;
-    }
-    ConfigFile configFile = (ConfigFile) o;
-    return Objects.equals(this.type, configFile.type)
-        && Objects.equals(this.destFile, configFile.destFile)
-        && Objects.equals(this.srcFile, configFile.srcFile)
-        && Objects.equals(this.visibility, configFile.visibility)
-        && Objects.equals(this.properties, configFile.properties);
-  }
-
-  @Override
-  public int hashCode() {
-    return Objects.hash(type, destFile, srcFile, visibility, properties);
-  }
-
-  @Override
-  public String toString() {
-    StringBuilder sb = new StringBuilder();
-    sb.append("class ConfigFile {\n")
-
-        .append("    type: ").append(toIndentedString(type)).append("\n")
-        .append("    destFile: ").append(toIndentedString(destFile))
-        .append("\n")
-        .append("    srcFile: ").append(toIndentedString(srcFile)).append("\n")
-        .append("    visibility: ").append(toIndentedString(visibility))
-        .append("\n")
-        .append("    properties: ").append(toIndentedString(properties))
-        .append("\n")
-        .append("}");
-    return sb.toString();
-  }
-
-  /**
-   * Convert the given object to string with each line indented by 4 spaces
-   * (except the first line).
-   */
-  private String toIndentedString(java.lang.Object o) {
-    if (o == null) {
-      return "null";
-    }
-    return o.toString().replace("\n", "\n    ");
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ConfigFormat.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ConfigFormat.java
deleted file mode 100644
index 4e21ea08f98..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ConfigFormat.java
+++ /dev/null
@@ -1,66 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-
-import java.util.Locale;
-
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-public enum ConfigFormat {
-
-  JSON("json"),
-  PROPERTIES("properties"),
-  XML("xml"),
-  HADOOP_XML("hadoop_xml"),
-  TEMPLATE("template"),
-  YAML("yaml");
-
-  ConfigFormat(String suffix) {
-    this.suffix = suffix;
-  }
-
-  private final String suffix;
-
-  public String getSuffix() {
-    return suffix;
-  }
-
-
-  @Override
-  public String toString() {
-    return suffix;
-  }
-
-  /**
-   * Get a matching format or null
-   * @param type
-   * @return the format
-   */
-  public static ConfigFormat resolve(String type) {
-    for (ConfigFormat format: values()) {
-      if (format.getSuffix().equals(type.toLowerCase(Locale.ENGLISH))) {
-        return format;
-      }
-    }
-    return null;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Configuration.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Configuration.java
deleted file mode 100644
index f52c7f27a04..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Configuration.java
+++ /dev/null
@@ -1,224 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonProperty;
-import io.swagger.annotations.ApiModel;
-import io.swagger.annotations.ApiModelProperty;
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-import org.apache.hadoop.yarn.service.utils.ServiceUtils;
-
-import java.io.Serializable;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Objects;
-
-/**
- * Set of configuration properties that can be injected into the service
- * components via envs, files and custom pluggable helper docker containers.
- * Files of several standard formats like xml, properties, json, yaml and
- * templates will be supported.
- **/
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-@ApiModel(description = "Set of configuration properties that can be injected into the service components via envs, files and custom pluggable helper docker containers. Files of several standard formats like xml, properties, json, yaml and templates will be supported.")
-@JsonInclude(JsonInclude.Include.NON_NULL)
-public class Configuration implements Serializable {
-  private static final long serialVersionUID = -4330788704981074466L;
-
-  private Map<String, String> properties = new HashMap<String, String>();
-  private Map<String, String> env = new HashMap<String, String>();
-  private List<ConfigFile> files = new ArrayList<ConfigFile>();
-
-  /**
-   * A blob of key-value pairs of common service properties.
-   **/
-  public Configuration properties(Map<String, String> properties) {
-    this.properties = properties;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "A blob of key-value pairs of common service properties.")
-  @JsonProperty("properties")
-  public Map<String, String> getProperties() {
-    return properties;
-  }
-
-  public void setProperties(Map<String, String> properties) {
-    this.properties = properties;
-  }
-
-  /**
-   * A blob of key-value pairs which will be appended to the default system
-   * properties and handed off to the service at start time. All placeholder
-   * references to properties will be substituted before injection.
-   **/
-  public Configuration env(Map<String, String> env) {
-    this.env = env;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "A blob of key-value pairs which will be appended to the default system properties and handed off to the service at start time. All placeholder references to properties will be substituted before injection.")
-  @JsonProperty("env")
-  public Map<String, String> getEnv() {
-    return env;
-  }
-
-  public void setEnv(Map<String, String> env) {
-    this.env = env;
-  }
-
-  /**
-   * Array of list of files that needs to be created and made available as
-   * volumes in the service component containers.
-   **/
-  public Configuration files(List<ConfigFile> files) {
-    this.files = files;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Array of list of files that needs to be created and made available as volumes in the service component containers.")
-  @JsonProperty("files")
-  public List<ConfigFile> getFiles() {
-    return files;
-  }
-
-  public void setFiles(List<ConfigFile> files) {
-    this.files = files;
-  }
-
-  public long getPropertyLong(String name, long defaultValue) {
-    String value = getProperty(name);
-    if (StringUtils.isEmpty(value)) {
-      return defaultValue;
-    }
-    return Long.parseLong(value);
-  }
-
-  public int getPropertyInt(String name, int defaultValue) {
-    String value = getProperty(name);
-    if (StringUtils.isEmpty(value)) {
-      return defaultValue;
-    }
-    return Integer.parseInt(value);
-  }
-
-  public boolean getPropertyBool(String name, boolean defaultValue) {
-    String value = getProperty(name);
-    if (StringUtils.isEmpty(value)) {
-      return defaultValue;
-    }
-    return Boolean.parseBoolean(value);
-  }
-
-  public String getProperty(String name, String defaultValue) {
-    String value = getProperty(name);
-    if (StringUtils.isEmpty(value)) {
-      return defaultValue;
-    }
-    return value;
-  }
-
-  public void setProperty(String name, String value) {
-    properties.put(name, value);
-  }
-
-  public String getProperty(String name) {
-    return properties.get(name.trim());
-  }
-
-  public String getEnv(String name) {
-    return env.get(name.trim());
-  }
-
-  @Override
-  public boolean equals(java.lang.Object o) {
-    if (this == o) {
-      return true;
-    }
-    if (o == null || getClass() != o.getClass()) {
-      return false;
-    }
-    Configuration configuration = (Configuration) o;
-    return Objects.equals(this.properties, configuration.properties)
-        && Objects.equals(this.env, configuration.env)
-        && Objects.equals(this.files, configuration.files);
-  }
-
-  @Override
-  public int hashCode() {
-    return Objects.hash(properties, env, files);
-  }
-
-  @Override
-  public String toString() {
-    StringBuilder sb = new StringBuilder();
-    sb.append("class Configuration {\n")
-
-        .append("    properties: ").append(toIndentedString(properties))
-        .append("\n")
-        .append("    env: ").append(toIndentedString(env)).append("\n")
-        .append("    files: ").append(toIndentedString(files)).append("\n")
-        .append("}");
-    return sb.toString();
-  }
-
-  /**
-   * Convert the given object to string with each line indented by 4 spaces
-   * (except the first line).
-   */
-  private String toIndentedString(java.lang.Object o) {
-    if (o == null) {
-      return "null";
-    }
-    return o.toString().replace("\n", "\n    ");
-  }
-
-  /**
-   * Merge all properties and envs from that configuration to this configration.
-   * For ConfigFiles, all properties and envs of that ConfigFile are merged into
-   * this ConfigFile.
-   */
-  public synchronized void mergeFrom(Configuration that) {
-    ServiceUtils.mergeMapsIgnoreDuplicateKeys(this.properties, that
-        .getProperties());
-    ServiceUtils.mergeMapsIgnoreDuplicateKeys(this.env, that.getEnv());
-
-    Map<String, ConfigFile> thatMap = new HashMap<>();
-    for (ConfigFile file : that.getFiles()) {
-      thatMap.put(file.getDestFile(), file.copy());
-    }
-    for (ConfigFile thisFile : files) {
-      if(thatMap.containsKey(thisFile.getDestFile())) {
-        ConfigFile thatFile = thatMap.get(thisFile.getDestFile());
-        ServiceUtils.mergeMapsIgnoreDuplicateKeys(thisFile.getProperties(),
-            thatFile.getProperties());
-        thatMap.remove(thisFile.getDestFile());
-      }
-    }
-    // add remaining new files from that Configration
-    for (ConfigFile thatFile : thatMap.values()) {
-      files.add(thatFile.copy());
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Container.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Container.java
deleted file mode 100644
index 0c03c9ed0b9..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Container.java
+++ /dev/null
@@ -1,345 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import io.swagger.annotations.ApiModel;
-import io.swagger.annotations.ApiModelProperty;
-
-import java.util.Date;
-import java.util.List;
-import java.util.Map;
-import java.util.Objects;
-
-import javax.xml.bind.annotation.XmlElement;
-import javax.xml.bind.annotation.XmlRootElement;
-
-import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonProperty;
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-
-/**
- * An instance of a running service container.
- **/
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-@ApiModel(description = "An instance of a running service container")
-@XmlRootElement
-@JsonInclude(JsonInclude.Include.NON_NULL)
-public class Container extends BaseResource {
-  private static final long serialVersionUID = -8955788064529288L;
-
-  private String id = null;
-  private Date launchTime = null;
-  private String ip = null;
-  private String hostname = null;
-  private String bareHost = null;
-  private ContainerState state = null;
-  private String componentInstanceName = null;
-  private Resource resource = null;
-  private Artifact artifact = null;
-  private Boolean privilegedContainer = null;
-  private Map<String, List<Map<String, String>>> exposedPorts = null;
-  private List<LocalizationStatus> localizationStatuses = null;
-
-  /**
-   * Unique container id of a running service, e.g.
-   * container_e3751_1458061340047_0008_01_000002.
-   **/
-  public Container id(String id) {
-    this.id = id;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Unique container id of a running service, e.g. container_e3751_1458061340047_0008_01_000002.")
-  @JsonProperty("id")
-  public String getId() {
-    return id;
-  }
-
-  public void setId(String id) {
-    this.id = id;
-  }
-
-  /**
-   * The time when the container was created, e.g. 2016-03-16T01:01:49.000Z.
-   * This will most likely be different from cluster launch time.
-   **/
-  public Container launchTime(Date launchTime) {
-    this.launchTime = launchTime == null ? null : (Date) launchTime.clone();
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "The time when the container was created, e.g. 2016-03-16T01:01:49.000Z. This will most likely be different from cluster launch time.")
-  @JsonProperty("launch_time")
-  public Date getLaunchTime() {
-    return launchTime == null ? null : (Date) launchTime.clone();
-  }
-
-  @XmlElement(name = "launch_time")
-  public void setLaunchTime(Date launchTime) {
-    this.launchTime = launchTime == null ? null : (Date) launchTime.clone();
-  }
-
-  /**
-   * IP address of a running container, e.g. 172.31.42.141. The IP address and
-   * hostname attribute values are dependent on the cluster/docker network setup
-   * as per YARN-4007.
-   **/
-  public Container ip(String ip) {
-    this.ip = ip;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "IP address of a running container, e.g. 172.31.42.141. The IP address and hostname attribute values are dependent on the cluster/docker network setup as per YARN-4007.")
-  @JsonProperty("ip")
-  public String getIp() {
-    return ip;
-  }
-
-  public void setIp(String ip) {
-    this.ip = ip;
-  }
-
-  /**
-   * Fully qualified hostname of a running container, e.g.
-   * ctr-e3751-1458061340047-0008-01-000002.examplestg.site. The IP address and
-   * hostname attribute values are dependent on the cluster/docker network setup
-   * as per YARN-4007.
-   **/
-  public Container hostname(String hostname) {
-    this.hostname = hostname;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Fully qualified hostname of a running container, e.g. ctr-e3751-1458061340047-0008-01-000002.examplestg.site. The IP address and hostname attribute values are dependent on the cluster/docker network setup as per YARN-4007.")
-  @JsonProperty("hostname")
-  public String getHostname() {
-    return hostname;
-  }
-
-  public void setHostname(String hostname) {
-    this.hostname = hostname;
-  }
-
-  /**
-   * The bare node or host in which the container is running, e.g.
-   * cn008.example.com.
-   **/
-  public Container bareHost(String bareHost) {
-    this.bareHost = bareHost;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "The bare node or host in which the container is running, e.g. cn008.example.com.")
-  @JsonProperty("bare_host")
-  public String getBareHost() {
-    return bareHost;
-  }
-
-  @XmlElement(name = "bare_host")
-  public void setBareHost(String bareHost) {
-    this.bareHost = bareHost;
-  }
-
-  /**
-   * State of the container of an service.
-   **/
-  public Container state(ContainerState state) {
-    this.state = state;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "State of the container of an service.")
-  @JsonProperty("state")
-  public ContainerState getState() {
-    return state;
-  }
-
-  public void setState(ContainerState state) {
-    this.state = state;
-  }
-
-  /**
-   * Name of the component instance that this container instance belongs to.
-   **/
-  public Container componentInstanceName(String componentInstanceName) {
-    this.componentInstanceName = componentInstanceName;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Name of the component instance that this container instance belongs to.")
-  @JsonProperty("component_instance_name")
-  public String getComponentInstanceName() {
-    return componentInstanceName;
-  }
-
-  @XmlElement(name = "component_instance_name")
-  public void setComponentInstanceName(String componentInstanceName) {
-    this.componentInstanceName = componentInstanceName;
-  }
-
-  /**
-   * Resource used for this container.
-   **/
-  public Container resource(Resource resource) {
-    this.resource = resource;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Resource used for this container.")
-  @JsonProperty("resource")
-  public Resource getResource() {
-    return resource;
-  }
-
-  public void setResource(Resource resource) {
-    this.resource = resource;
-  }
-
-  /**
-   * Artifact used for this container.
-   **/
-  public Container artifact(Artifact artifact) {
-    this.artifact = artifact;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Artifact used for this container.")
-  @JsonProperty("artifact")
-  public Artifact getArtifact() {
-    return artifact;
-  }
-
-  public void setArtifact(Artifact artifact) {
-    this.artifact = artifact;
-  }
-
-  /**
-   * Container running in privileged mode or not.
-   **/
-  public Container privilegedContainer(Boolean privilegedContainer) {
-    this.privilegedContainer = privilegedContainer;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Container running in privileged mode or not.")
-  @JsonProperty("privileged_container")
-  public Boolean getPrivilegedContainer() {
-    return privilegedContainer;
-  }
-
-  public void setPrivilegedContainer(Boolean privilegedContainer) {
-    this.privilegedContainer = privilegedContainer;
-  }
-
-  @ApiModelProperty(example = "null",
-      value = "Ports exposed for this container.")
-  @JsonProperty("exposed_ports")
-  public Map<String, List<Map<String, String>>> getExposedPorts() {
-    return exposedPorts;
-  }
-
-  public void setExposedPorts(Map<String, List<Map<String, String>>> ports) {
-    this.exposedPorts = ports;
-  }
-
-  /**
-   * Localization statuses.
-   */
-  @ApiModelProperty(example = "null", value =
-      "Localization statuses of a container.")
-  @JsonProperty("localization_statuses")
-  public List<LocalizationStatus> getLocalizationStatuses() {
-    return localizationStatuses;
-  }
-
-  /**
-   * Sets the localization statuses.
-   * @param statuses localization statuses.
-   */
-  @XmlElement(name = "localization_statuses")
-  public void setLocalizationStatuses(List<LocalizationStatus> statuses) {
-    this.localizationStatuses = statuses;
-  }
-
-  /**
-   * Sets the localization statuses and returns the container.
-   * @param statuses
-   * @return
-   */
-  public Container localizationStatuses(List<LocalizationStatus> statuses) {
-    this.localizationStatuses = statuses;
-    return this;
-  }
-
-  @Override
-  public boolean equals(java.lang.Object o) {
-    if (this == o) {
-      return true;
-    }
-    if (o == null || getClass() != o.getClass()) {
-      return false;
-    }
-    Container container = (Container) o;
-    return Objects.equals(this.id, container.id);
-  }
-
-  @Override
-  public int hashCode() {
-    return Objects.hash(id);
-  }
-
-  @Override
-  public String toString() {
-    StringBuilder sb = new StringBuilder();
-    sb.append("class Container {\n");
-
-    sb.append("    id: ").append(toIndentedString(id)).append("\n")
-        .append("    launchTime: ").append(toIndentedString(launchTime))
-        .append("\n")
-        .append("    ip: ").append(toIndentedString(ip)).append("\n")
-        .append("    hostname: ").append(toIndentedString(hostname))
-        .append("\n")
-        .append("    bareHost: ").append(toIndentedString(bareHost))
-        .append("\n")
-        .append("    state: ").append(toIndentedString(state)).append("\n")
-        .append("    componentInstanceName: ").append(toIndentedString(
-            componentInstanceName))
-        .append("\n")
-        .append("    resource: ").append(toIndentedString(resource))
-        .append("\n")
-        .append("    artifact: ").append(toIndentedString(artifact))
-        .append("\n")
-        .append("    privilegedContainer: ")
-        .append(toIndentedString(privilegedContainer)).append("\n")
-        .append("}");
-    return sb.toString();
-  }
-
-  /**
-   * Convert the given object to string with each line indented by 4 spaces
-   * (except the first line).
-   */
-  private String toIndentedString(java.lang.Object o) {
-    if (o == null) {
-      return "null";
-    }
-    return o.toString().replace("\n", "\n    ");
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ContainerState.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ContainerState.java
deleted file mode 100644
index a6e9a2e7d82..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ContainerState.java
+++ /dev/null
@@ -1,31 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-
-/**
- * The current state of the container of an application.
- **/
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-public enum ContainerState {
-  RUNNING_BUT_UNREADY, READY, STOPPED, NEEDS_UPGRADE, UPGRADING, SUCCEEDED,
-  FAILED, FAILED_UPGRADE;
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Error.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Error.java
deleted file mode 100644
index 1ba30f2e351..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Error.java
+++ /dev/null
@@ -1,128 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import io.swagger.annotations.ApiModelProperty;
-
-import java.util.Objects;
-
-import com.fasterxml.jackson.annotation.JsonProperty;
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-public class Error {
-
-  private Integer code = null;
-  private String message = null;
-  private String fields = null;
-
-  /**
-   **/
-  public Error code(Integer code) {
-    this.code = code;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "")
-  @JsonProperty("code")
-  public Integer getCode() {
-    return code;
-  }
-
-  public void setCode(Integer code) {
-    this.code = code;
-  }
-
-  /**
-   **/
-  public Error message(String message) {
-    this.message = message;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "")
-  @JsonProperty("message")
-  public String getMessage() {
-    return message;
-  }
-
-  public void setMessage(String message) {
-    this.message = message;
-  }
-
-  /**
-   **/
-  public Error fields(String fields) {
-    this.fields = fields;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "")
-  @JsonProperty("fields")
-  public String getFields() {
-    return fields;
-  }
-
-  public void setFields(String fields) {
-    this.fields = fields;
-  }
-
-  @Override
-  public boolean equals(java.lang.Object o) {
-    if (this == o) {
-      return true;
-    }
-    if (o == null || getClass() != o.getClass()) {
-      return false;
-    }
-    Error error = (Error) o;
-    return Objects.equals(this.code, error.code)
-        && Objects.equals(this.message, error.message)
-        && Objects.equals(this.fields, error.fields);
-  }
-
-  @Override
-  public int hashCode() {
-    return Objects.hash(code, message, fields);
-  }
-
-  @Override
-  public String toString() {
-    StringBuilder sb = new StringBuilder();
-    sb.append("class Error {\n")
-
-        .append("    code: ").append(toIndentedString(code)).append("\n")
-        .append("    message: ").append(toIndentedString(message)).append("\n")
-        .append("    fields: ").append(toIndentedString(fields)).append("\n")
-        .append("}");
-    return sb.toString();
-  }
-
-  /**
-   * Convert the given object to string with each line indented by 4 spaces
-   * (except the first line).
-   */
-  private String toIndentedString(java.lang.Object o) {
-    if (o == null) {
-      return "null";
-    }
-    return o.toString().replace("\n", "\n    ");
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/KerberosPrincipal.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/KerberosPrincipal.java
deleted file mode 100644
index 27125fbedc3..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/KerberosPrincipal.java
+++ /dev/null
@@ -1,146 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonProperty;
-import io.swagger.annotations.ApiModel;
-import io.swagger.annotations.ApiModelProperty;
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-
-import javax.xml.bind.annotation.XmlElement;
-import java.io.Serializable;
-import java.util.Objects;
-
-/**
- * The kerberos principal of the service.
- */
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-@ApiModel(description = "The kerberos principal of the service.")
-@JsonInclude(JsonInclude.Include.NON_NULL)
-public class KerberosPrincipal implements Serializable {
-  private static final long serialVersionUID = -6431667195287650037L;
-
-  @JsonProperty("principal_name")
-  @XmlElement(name = "principal_name")
-  private String principalName = null;
-
-  @JsonProperty("keytab")
-  @XmlElement(name = "keytab")
-  private String keytab = null;
-
-  public KerberosPrincipal principalName(String principalName) {
-    this.principalName = principalName;
-    return this;
-  }
-
-  /**
-   * The principal name of the service.
-   *
-   * @return principalName
-   **/
-  @ApiModelProperty(value = "The principal name of the service.")
-  public String getPrincipalName() {
-    return principalName;
-  }
-
-  public void setPrincipalName(String principalName) {
-    this.principalName = principalName;
-  }
-
-  public KerberosPrincipal keytab(String keytab) {
-    this.keytab = keytab;
-    return this;
-  }
-
-  /**
-   * The URI of the kerberos keytab. It supports hadoop supported schemes
-   * like \&quot;hdfs\&quot; \&quot;file\&quot; \&quot;s3\&quot;
-   *  \&quot;viewfs\&quot; etc.If the URI starts with \&quot;
-   * hdfs://\&quot; scheme, it indicates the path on hdfs where the keytab is
-   * stored. The keytab will be localized by YARN and made available to AM in
-   * its local directory. If the URI starts with \&quot;file://\&quot;
-   * scheme, it indicates a path on the local host presumbaly installed by
-   * admins upfront.
-   *
-   * @return keytab
-   **/
-  @ApiModelProperty(value = "The URI of the kerberos keytab. It supports"
-      + " Hadoop supported filesystem types like \"hdfs\", \"file\","
-      + " \"viewfs\", \"s3\" etc.If the URI starts with \"hdfs://\" scheme, "
-      + "it indicates the path on hdfs where the keytab is stored. The "
-      + "keytab will be localized by YARN and made available to AM in its local"
-      + " directory. If the URI starts with \"file://\" scheme, it indicates a "
-      + "path on the local host where the keytab is presumbaly installed by "
-      + "admins upfront. ")
-  public String getKeytab() {
-    return keytab;
-  }
-
-  public void setKeytab(String keytab) {
-    this.keytab = keytab;
-  }
-
-
-  @Override
-  public boolean equals(java.lang.Object o) {
-    if (this == o) {
-      return true;
-    }
-    if (o == null || getClass() != o.getClass()) {
-      return false;
-    }
-    KerberosPrincipal kerberosPrincipal = (KerberosPrincipal) o;
-    return Objects.equals(this.principalName, kerberosPrincipal
-        .principalName) &&
-        Objects.equals(this.keytab, kerberosPrincipal.keytab);
-  }
-
-  @Override
-  public int hashCode() {
-    return Objects.hash(principalName, keytab);
-  }
-
-
-  @Override
-  public String toString() {
-    StringBuilder sb = new StringBuilder();
-    sb.append("class KerberosPrincipal {\n")
-
-        .append("    principalName: ").append(toIndentedString(principalName))
-        .append("\n")
-        .append("    keytab: ").append(toIndentedString(keytab)).append("\n")
-        .append("}");
-    return sb.toString();
-  }
-
-  /**
-   * Convert the given object to string with each line indented by 4 spaces
-   * (except the first line).
-   */
-  private String toIndentedString(java.lang.Object o) {
-    if (o == null) {
-      return "null";
-    }
-    return o.toString().replace("\n", "\n    ");
-  }
-
-}
-
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/LocalizationStatus.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/LocalizationStatus.java
deleted file mode 100644
index 3f76ba3a346..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/LocalizationStatus.java
+++ /dev/null
@@ -1,132 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonProperty;
-import io.swagger.annotations.ApiModel;
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-import org.apache.hadoop.yarn.api.records.LocalizationState;
-
-import javax.xml.bind.annotation.XmlElement;
-import javax.xml.bind.annotation.XmlRootElement;
-import java.io.Serializable;
-
-/**
- * The status of localization.
- */
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-@ApiModel(description = "Localization status of a resource.")
-@XmlRootElement
-@JsonInclude(JsonInclude.Include.NON_NULL)
-public class LocalizationStatus implements Serializable {
-
-  private static final long serialVersionUID = -5745287278502373531L;
-
-  private String destFile;
-
-  private LocalizationState state;
-
-  private String diagnostics;
-
-  /**
-   * Destination file.
-   */
-  @JsonProperty("dest_file")
-  public String getDestFile() {
-    return destFile;
-  }
-
-  /**
-   * Sets the destination file.
-   *
-   * @param destFile destination file
-   */
-  @XmlElement(name = "dest_file")
-  public void setDestFile(String destFile) {
-    this.destFile = destFile;
-  }
-
-  /**
-   * Sets the destination file and returns the localization status.
-   *
-   * @param fileName destination file
-   */
-  public LocalizationStatus destFile(String fileName) {
-    this.destFile = fileName;
-    return this;
-  }
-
-  /**
-   * Localization state.
-   */
-  @JsonProperty("state")
-  public LocalizationState getState() {
-    return state;
-  }
-
-  /**
-   * Sets the localization state.
-   *
-   * @param localizationState localization state
-   */
-  @XmlElement(name = "state")
-  public void setState(LocalizationState localizationState) {
-    this.state = localizationState;
-  }
-
-  /**
-   * Sets the localization state and returns the localization status.
-   *
-   * @param localizationState localization state
-   */
-  public LocalizationStatus state(LocalizationState localizationState) {
-    this.state = localizationState;
-    return this;
-  }
-
-  /**
-   * Diagnostics.
-   */
-  @JsonProperty("diagnostics")
-  public String getDiagnostics() {
-    return diagnostics;
-  }
-
-  /**
-   * Sets the diagnostics.
-   *
-   * @param diag diagnostics
-   */
-  @XmlElement(name = "diagnostics")
-  public void setDiagnostics(String diag) {
-    this.diagnostics = diag;
-  }
-
-  /**
-   * Sets the diagnostics and returns the localization status.
-   *
-   * @param diag diagnostics
-   */
-  public LocalizationStatus diagnostics(String diag) {
-    this.diagnostics = diag;
-    return this;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/PlacementConstraint.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/PlacementConstraint.java
deleted file mode 100644
index 6b0bc61c424..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/PlacementConstraint.java
+++ /dev/null
@@ -1,280 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import java.io.Serializable;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Objects;
-
-import javax.xml.bind.annotation.XmlElement;
-
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-
-import com.fasterxml.jackson.annotation.JsonProperty;
-
-import io.swagger.annotations.ApiModel;
-import io.swagger.annotations.ApiModelProperty;
-
-/**
- * Placement constraint details.
- **/
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-@ApiModel(description = "Placement constraint details.")
-public class PlacementConstraint implements Serializable {
-  private static final long serialVersionUID = 1518017165676511762L;
-
-  private String name = null;
-  private PlacementType type = null;
-  private PlacementScope scope = null;
-  @JsonProperty("target_tags")
-  @XmlElement(name = "target_tags")
-  private List<String> targetTags = new ArrayList<>();
-  @JsonProperty("node_attributes")
-  @XmlElement(name = "node_attributes")
-  private Map<String, List<String>> nodeAttributes = new HashMap<>();
-  @JsonProperty("node_partitions")
-  @XmlElement(name = "node_partitions")
-  private List<String> nodePartitions = new ArrayList<>();
-  @JsonProperty("min_cardinality")
-  @XmlElement(name = "min_cardinality")
-  private Long minCardinality = null;
-  @JsonProperty("max_cardinality")
-  @XmlElement(name = "max_cardinality")
-  private Long maxCardinality = null;
-
-  /**
-   * An optional name associated to this constraint.
-   **/
-  public PlacementConstraint name(String name) {
-    this.name = name;
-    return this;
-  }
-
-  @ApiModelProperty(example = "C1", required = true)
-  @JsonProperty("name")
-  public String getName() {
-    return name;
-  }
-
-  public void setName(String name) {
-    this.name = name;
-  }
-
-  /**
-   * The type of placement.
-   **/
-  public PlacementConstraint type(PlacementType type) {
-    this.type = type;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", required = true)
-  @JsonProperty("type")
-  public PlacementType getType() {
-    return type;
-  }
-
-  public void setType(PlacementType type) {
-    this.type = type;
-  }
-
-  /**
-   * The scope of placement.
-   **/
-  public PlacementConstraint scope(PlacementScope scope) {
-    this.scope = scope;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", required = true)
-  @JsonProperty("scope")
-  public PlacementScope getScope() {
-    return scope;
-  }
-
-  public void setScope(PlacementScope scope) {
-    this.scope = scope;
-  }
-
-  /**
-   * The name of the components that this component's placement policy is
-   * depending upon are added as target tags. So for affinity say, this
-   * component's containers are requesting to be placed on hosts where
-   * containers of the target tag component(s) are running on. Target tags can
-   * also contain the name of this component, in which case it implies that for
-   * anti-affinity say, no more than one container of this component can be
-   * placed on a host. Similarly, for cardinality, it would mean that containers
-   * of this component is requesting to be placed on hosts where at least
-   * minCardinality but no more than maxCardinality containers of the target tag
-   * component(s) are running.
-   **/
-  public PlacementConstraint targetTags(List<String> targetTags) {
-    this.targetTags = targetTags;
-    return this;
-  }
-
-  @ApiModelProperty(example = "[\"hbase-regionserver\"]")
-  public List<String> getTargetTags() {
-    return targetTags;
-  }
-
-  public void setTargetTags(List<String> targetTags) {
-    this.targetTags = targetTags;
-  }
-
-  /**
-   * Node attributes are a set of key:value(s) pairs associated with nodes.
-   */
-  public PlacementConstraint nodeAttributes(
-      Map<String, List<String>> nodeAttributes) {
-    this.nodeAttributes = nodeAttributes;
-    return this;
-  }
-
-  @ApiModelProperty(example = "\"JavaVersion\":[\"1.7\", \"1.8\"]")
-  public Map<String, List<String>> getNodeAttributes() {
-    return nodeAttributes;
-  }
-
-  public void setNodeAttributes(Map<String, List<String>> nodeAttributes) {
-    this.nodeAttributes = nodeAttributes;
-  }
-
-  /**
-   * Node partitions where the containers of this component can run.
-   */
-  public PlacementConstraint nodePartitions(
-      List<String> nodePartitions) {
-    this.nodePartitions = nodePartitions;
-    return this;
-  }
-
-  @ApiModelProperty(example = "[\"gpu\", \"fast_disk\"]")
-  public List<String> getNodePartitions() {
-    return nodePartitions;
-  }
-
-  public void setNodePartitions(List<String> nodePartitions) {
-    this.nodePartitions = nodePartitions;
-  }
-
-  /**
-   * When placement type is cardinality, the minimum number of containers of the
-   * depending component that a host should have, where containers of this
-   * component can be allocated on.
-   **/
-  public PlacementConstraint minCardinality(Long minCardinality) {
-    this.minCardinality = minCardinality;
-    return this;
-  }
-
-  @ApiModelProperty(example = "2")
-  public Long getMinCardinality() {
-    return minCardinality;
-  }
-
-  public void setMinCardinality(Long minCardinality) {
-    this.minCardinality = minCardinality;
-  }
-
-  /**
-   * When placement type is cardinality, the maximum number of containers of the
-   * depending component that a host should have, where containers of this
-   * component can be allocated on.
-   **/
-  public PlacementConstraint maxCardinality(Long maxCardinality) {
-    this.maxCardinality = maxCardinality;
-    return this;
-  }
-
-  @ApiModelProperty(example = "3")
-  public Long getMaxCardinality() {
-    return maxCardinality;
-  }
-
-  public void setMaxCardinality(Long maxCardinality) {
-    this.maxCardinality = maxCardinality;
-  }
-
-  @Override
-  public boolean equals(java.lang.Object o) {
-    if (this == o) {
-      return true;
-    }
-    if (o == null || getClass() != o.getClass()) {
-      return false;
-    }
-    PlacementConstraint placementConstraint = (PlacementConstraint) o;
-    return Objects.equals(this.name, placementConstraint.name)
-        && Objects.equals(this.type, placementConstraint.type)
-        && Objects.equals(this.scope, placementConstraint.scope)
-        && Objects.equals(this.targetTags, placementConstraint.targetTags)
-        && Objects.equals(this.nodeAttributes,
-            placementConstraint.nodeAttributes)
-        && Objects.equals(this.nodePartitions,
-            placementConstraint.nodePartitions)
-        && Objects.equals(this.minCardinality,
-            placementConstraint.minCardinality)
-        && Objects.equals(this.maxCardinality,
-            placementConstraint.maxCardinality);
-  }
-
-  @Override
-  public int hashCode() {
-    return Objects.hash(name, type, scope, targetTags, nodeAttributes,
-        nodePartitions, minCardinality, maxCardinality);
-  }
-
-  @Override
-  public String toString() {
-    StringBuilder sb = new StringBuilder();
-    sb.append("class PlacementConstraint {\n")
-
-        .append("    name: ").append(toIndentedString(name)).append("\n")
-        .append("    type: ").append(toIndentedString(type)).append("\n")
-        .append("    scope: ").append(toIndentedString(scope)).append("\n")
-        .append("    targetTags: ").append(toIndentedString(targetTags))
-        .append("\n")
-        .append("    nodeAttributes: ").append(toIndentedString(nodeAttributes))
-        .append("\n")
-        .append("    nodePartitions: ").append(toIndentedString(nodePartitions))
-        .append("\n")
-        .append("    minCardinality: ").append(toIndentedString(minCardinality))
-        .append("\n")
-        .append("    maxCardinality: ").append(toIndentedString(maxCardinality))
-        .append("\n")
-        .append("}");
-    return sb.toString();
-  }
-
-  /**
-   * Convert the given object to string with each line indented by 4 spaces
-   * (except the first line).
-   */
-  private String toIndentedString(java.lang.Object o) {
-    if (o == null) {
-      return "null";
-    }
-    return o.toString().replace("\n", "\n    ");
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/PlacementPolicy.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/PlacementPolicy.java
deleted file mode 100644
index 0b4225e1d68..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/PlacementPolicy.java
+++ /dev/null
@@ -1,101 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import java.io.Serializable;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Objects;
-
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-
-import com.fasterxml.jackson.annotation.JsonProperty;
-
-import io.swagger.annotations.ApiModel;
-import io.swagger.annotations.ApiModelProperty;
-
-/**
- * Advanced placement policy of the components of a service.
- **/
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-@ApiModel(description = "Advanced placement policy of the components of a "
-    + "service.")
-public class PlacementPolicy implements Serializable {
-  private static final long serialVersionUID = 4341110649551172231L;
-
-  private List<PlacementConstraint> constraints = new ArrayList<>();
-
-  /**
-   * Placement constraint details.
-   **/
-  public PlacementPolicy constraints(List<PlacementConstraint> constraints) {
-    this.constraints = constraints;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", required = true)
-  @JsonProperty("constraints")
-  public List<PlacementConstraint> getConstraints() {
-    return constraints;
-  }
-
-  public void setConstraints(List<PlacementConstraint> constraints) {
-    this.constraints = constraints;
-  }
-
-  @Override
-  public boolean equals(java.lang.Object o) {
-    if (this == o) {
-      return true;
-    }
-    if (o == null || getClass() != o.getClass()) {
-      return false;
-    }
-    PlacementPolicy placementPolicy = (PlacementPolicy) o;
-    return Objects.equals(this.constraints, placementPolicy.constraints);
-  }
-
-  @Override
-  public int hashCode() {
-    return Objects.hash(constraints);
-  }
-
-  @Override
-  public String toString() {
-    StringBuilder sb = new StringBuilder();
-    sb.append("class PlacementPolicy {\n")
-
-        .append("    constraints: ").append(toIndentedString(constraints))
-        .append("\n")
-        .append("}");
-    return sb.toString();
-  }
-
-  /**
-   * Convert the given object to string with each line indented by 4 spaces
-   * (except the first line).
-   */
-  private String toIndentedString(java.lang.Object o) {
-    if (o == null) {
-      return "null";
-    }
-    return o.toString().replace("\n", "\n    ");
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/PlacementScope.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/PlacementScope.java
deleted file mode 100644
index 01b1d5dedf3..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/PlacementScope.java
+++ /dev/null
@@ -1,53 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-import org.apache.hadoop.yarn.api.resource.PlacementConstraints;
-
-import com.fasterxml.jackson.annotation.JsonValue;
-
-import io.swagger.annotations.ApiModel;
-
-/**
- * The scope of placement for the containers of a component.
- **/
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-@ApiModel(description = "The scope of placement for the containers of a "
-    + "component.")
-public enum PlacementScope {
-  NODE(PlacementConstraints.NODE), RACK(PlacementConstraints.RACK);
-
-  private String value;
-
-  PlacementScope(String value) {
-    this.value = value;
-  }
-
-  public String getValue() {
-    return value;
-  }
-
-  @Override
-  @JsonValue
-  public String toString() {
-    return value;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/PlacementType.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/PlacementType.java
deleted file mode 100644
index 6dfe935fc53..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/PlacementType.java
+++ /dev/null
@@ -1,35 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import io.swagger.annotations.ApiModel;
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-
-/**
- * The type of placement - affinity/anti-affinity/affinity-with-cardinality with
- * containers of another component or containers of the same component (self).
- **/
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-@ApiModel(description = "The type of placement - affinity/anti-affinity/"
-    + "affinity-with-cardinality with containers of another component or "
-    + "containers of the same component (self).")
-public enum PlacementType {
-  AFFINITY, ANTI_AFFINITY, AFFINITY_WITH_CARDINALITY;
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ReadinessCheck.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ReadinessCheck.java
deleted file mode 100644
index 5f94d49e14e..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ReadinessCheck.java
+++ /dev/null
@@ -1,197 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import io.swagger.annotations.ApiModel;
-import io.swagger.annotations.ApiModelProperty;
-
-import java.io.Serializable;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.Objects;
-
-import javax.xml.bind.annotation.XmlAccessType;
-import javax.xml.bind.annotation.XmlAccessorType;
-import javax.xml.bind.annotation.XmlElement;
-import javax.xml.bind.annotation.XmlEnum;
-import javax.xml.bind.annotation.XmlRootElement;
-import javax.xml.bind.annotation.XmlType;
-
-import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonProperty;
-import com.fasterxml.jackson.annotation.JsonValue;
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-
-/**
- * A custom command or a pluggable helper container to determine the readiness
- * of a container of a component. Readiness for every service is different.
- * Hence the need for a simple interface, with scope to support advanced
- * usecases.
- **/
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-@ApiModel(description = "A custom command or a pluggable helper container to determine the readiness of a container of a component. Readiness for every service is different. Hence the need for a simple interface, with scope to support advanced usecases.")
-@XmlRootElement
-@XmlAccessorType(XmlAccessType.FIELD)
-@JsonInclude(JsonInclude.Include.NON_NULL)
-public class ReadinessCheck implements Serializable {
-  private static final long serialVersionUID = -3836839816887186801L;
-
-  /**
-   * Type. HTTP and PORT
-   **/
-  @XmlType(name = "type")
-  @XmlEnum
-  public enum TypeEnum {
-    DEFAULT("DEFAULT"),
-    HTTP("HTTP"),
-    PORT("PORT");
-
-    private String value;
-
-    TypeEnum(String value) {
-      this.value = value;
-    }
-
-    @Override
-    @JsonValue
-    public String toString() {
-      return value;
-    }
-  }
-
-  @JsonProperty("type")
-  @XmlElement(name = "type")
-  private TypeEnum type = null;
-  @JsonProperty("properties")
-  @XmlElement(name = "properties")
-  private Map<String, String> properties = new HashMap<String, String>();
-  @JsonProperty("artifact")
-  @XmlElement(name = "artifact")
-  private Artifact artifact = null;
-
-  /**
-   * E.g. HTTP (YARN will perform a simple REST call at a regular interval and
-   * expect a 204 No content).
-   **/
-  public ReadinessCheck type(TypeEnum type) {
-    this.type = type;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "E.g. HTTP (YARN will perform a simple REST call at a regular interval and expect a 204 No content).")
-  public TypeEnum getType() {
-    return type;
-  }
-
-  public void setType(TypeEnum type) {
-    this.type = type;
-  }
-
-  public ReadinessCheck properties(Map<String, String> properties) {
-    this.properties = properties;
-    return this;
-  }
-
-  public ReadinessCheck putPropsItem(String key, String propsItem) {
-    this.properties.put(key, propsItem);
-    return this;
-  }
-
-  /**
-   * A blob of key value pairs that will be used to configure the check.
-   * @return properties
-   **/
-  @ApiModelProperty(example = "null", value = "A blob of key value pairs that will be used to configure the check.")
-  public Map<String, String> getProperties() {
-    return properties;
-  }
-
-  public void setProperties(Map<String, String> properties) {
-    this.properties = properties;
-  }
-
-  /**
-   * Artifact of the pluggable readiness check helper container (optional). If
-   * specified, this helper container typically hosts the http uri and
-   * encapsulates the complex scripts required to perform actual container
-   * readiness check. At the end it is expected to respond a 204 No content just
-   * like the simplified use case. This pluggable framework benefits service
-   * owners who can run services without any packaging modifications. Note,
-   * artifacts of type docker only is supported for now.
-   **/
-  public ReadinessCheck artifact(Artifact artifact) {
-    this.artifact = artifact;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Artifact of the pluggable readiness check helper container (optional). If specified, this helper container typically hosts the http uri and encapsulates the complex scripts required to perform actual container readiness check. At the end it is expected to respond a 204 No content just like the simplified use case. This pluggable framework benefits service owners who can run services without any packaging modifications. Note, artifacts of type docker only is supported for now.")
-  public Artifact getArtifact() {
-    return artifact;
-  }
-
-  public void setArtifact(Artifact artifact) {
-    this.artifact = artifact;
-  }
-
-  @Override
-  public boolean equals(java.lang.Object o) {
-    if (this == o) {
-      return true;
-    }
-    if (o == null || getClass() != o.getClass()) {
-      return false;
-    }
-    ReadinessCheck readinessCheck = (ReadinessCheck) o;
-    return Objects.equals(this.type, readinessCheck.type) &&
-        Objects.equals(this.properties, readinessCheck.properties) &&
-        Objects.equals(this.artifact, readinessCheck.artifact);
-  }
-
-  @Override
-  public int hashCode() {
-    return Objects.hash(type, properties, artifact);
-  }
-
-
-  @Override
-  public String toString() {
-    StringBuilder sb = new StringBuilder();
-    sb.append("class ReadinessCheck {\n")
-
-        .append("    type: ").append(toIndentedString(type)).append("\n")
-        .append("    properties: ").append(toIndentedString(properties))
-        .append("\n")
-        .append("    artifact: ").append(toIndentedString(artifact))
-        .append("\n")
-        .append("}");
-    return sb.toString();
-  }
-
-  /**
-   * Convert the given object to string with each line indented by 4 spaces
-   * (except the first line).
-   */
-  private String toIndentedString(java.lang.Object o) {
-    if (o == null) {
-      return "null";
-    }
-    return o.toString().replace("\n", "\n    ");
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Resource.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Resource.java
deleted file mode 100644
index 4ffe87be37b..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Resource.java
+++ /dev/null
@@ -1,191 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
-import com.fasterxml.jackson.annotation.JsonProperty;
-import io.swagger.annotations.ApiModel;
-import io.swagger.annotations.ApiModelProperty;
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-
-import javax.xml.bind.annotation.XmlElement;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.Objects;
-
-/**
- * Resource determines the amount of resources (vcores, memory, network, etc.)
- * usable by a container. This field determines the resource to be applied for
- * all the containers of a component or service. The resource specified at
- * the service (or global) level can be overriden at the component level. Only one
- * of profile OR cpu &amp; memory are expected. It raises a validation
- * exception otherwise.
- **/
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-@ApiModel(description = "Resource determines the amount of resources (vcores, memory, network, etc.) usable by a container. This field determines the resource to be applied for all the containers of a component or service. The resource specified at the service (or global) level can be overriden at the component level. Only one of profile OR cpu & memory are expected. It raises a validation exception otherwise.")
-public class Resource extends BaseResource implements Cloneable {
-  private static final long serialVersionUID = -6431667797380250037L;
-
-  private String profile = null;
-  private Integer cpus = 1;
-  private String memory = null;
-
-  @JsonProperty("additional")
-  @XmlElement(name = "additional")
-  private Map<String, ResourceInformation> additional = new HashMap<>();
-
-  /**
-   * Each resource profile has a unique id which is associated with a
-   * cluster-level predefined memory, cpus, etc.
-   **/
-  public Resource profile(String profile) {
-    this.profile = profile;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Each resource profile has a unique id which is associated with a cluster-level predefined memory, cpus, etc.")
-  @JsonProperty("profile")
-  public String getProfile() {
-    return profile;
-  }
-
-  public void setProfile(String profile) {
-    this.profile = profile;
-  }
-
-  /**
-   * Amount of vcores allocated to each container (optional but overrides cpus
-   * in profile if specified).
-   **/
-  public Resource cpus(Integer cpus) {
-    this.cpus = cpus;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Amount of vcores allocated to each container (optional but overrides cpus in profile if specified).")
-  @JsonProperty("cpus")
-  public Integer getCpus() {
-    return cpus;
-  }
-
-  public void setCpus(Integer cpus) {
-    this.cpus = cpus;
-  }
-
-  /**
-   * Amount of memory allocated to each container (optional but overrides memory
-   * in profile if specified). Currently accepts only an integer value and
-   * default unit is in MB.
-   **/
-  public Resource memory(String memory) {
-    this.memory = memory;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Amount of memory allocated to each container (optional but overrides memory in profile if specified). Currently accepts only an integer value and default unit is in MB.")
-  @JsonProperty("memory")
-  public String getMemory() {
-    return memory;
-  }
-
-  public void setMemory(String memory) {
-    this.memory = memory;
-  }
-
-  @JsonIgnoreProperties(ignoreUnknown=true)
-  public long calcMemoryMB() {
-    if (this.memory == null) {
-      return 0;
-    }
-    return Long.parseLong(memory);
-  }
-
-  public Resource setResourceInformations(
-      Map<String, ResourceInformation> resourceInformations) {
-    this.additional = resourceInformations;
-    return this;
-  }
-
-  public Resource resourceInformations(
-      Map<String, ResourceInformation> resourceInformations) {
-    this.additional = resourceInformations;
-    return this;
-  }
-
-  /**
-   * Map of resource name to ResourceInformation
-   * @return additional
-   **/
-  @ApiModelProperty(value = "Map of resource name to ResourceInformation")
-  @JsonProperty("additional")
-  public Map<String, ResourceInformation> getAdditional() {
-    return additional;
-  }
-
-  @Override
-  public boolean equals(java.lang.Object o) {
-    if (this == o) {
-      return true;
-    }
-    if (o == null || getClass() != o.getClass()) {
-      return false;
-    }
-    Resource resource = (Resource) o;
-    return Objects.equals(this.profile, resource.profile) && Objects.equals(
-        this.cpus, resource.cpus) && Objects.equals(this.memory,
-        resource.memory) && Objects.equals(this.additional,
-        resource.additional);
-  }
-
-  @Override
-  public int hashCode() {
-    return Objects.hash(profile, cpus, memory, additional);
-  }
-
-  @Override
-  public String toString() {
-    StringBuilder sb = new StringBuilder();
-    sb.append("class Resource {\n")
-
-        .append("    profile: ").append(toIndentedString(profile)).append("\n")
-        .append("    cpus: ").append(toIndentedString(cpus)).append("\n")
-        .append("    memory: ").append(toIndentedString(memory)).append("\n")
-        .append("    additional: ").append(
-            toIndentedString(additional)).append("\n")
-        .append("}");
-    return sb.toString();
-  }
-
-  /**
-   * Convert the given object to string with each line indented by 4 spaces
-   * (except the first line).
-   */
-  private String toIndentedString(java.lang.Object o) {
-    if (o == null) {
-      return "null";
-    }
-    return o.toString().replace("\n", "\n    ");
-  }
-
-  @Override
-  public Object clone() throws CloneNotSupportedException {
-    return super.clone();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ResourceInformation.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ResourceInformation.java
deleted file mode 100644
index 98f71268fbe..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ResourceInformation.java
+++ /dev/null
@@ -1,152 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import com.fasterxml.jackson.annotation.JsonProperty;
-import org.apache.hadoop.thirdparty.com.google.common.collect.ImmutableMap;
-import org.apache.hadoop.thirdparty.com.google.common.collect.ImmutableSet;
-import com.google.gson.annotations.SerializedName;
-import io.swagger.annotations.ApiModel;
-import io.swagger.annotations.ApiModelProperty;
-
-import java.util.Map;
-import java.util.Objects;
-import java.util.Set;
-
-/**
- * ResourceInformation determines unit/name/value of resource types in addition to memory and vcores. It will be part of Resource object
- */
-@ApiModel(description = "ResourceInformation determines unit/value of resource types in addition to memory and vcores. It will be part of Resource object")
-public class ResourceInformation {
-  @SerializedName("value")
-  private Long value = null;
-
-  @SerializedName("unit")
-  private String unit = null;
-
-  @SerializedName("attributes")
-  private Map<String, String> attributes = null;
-
-  @SerializedName("tags")
-  private Set<String> tags = null;
-
-  public ResourceInformation value(Long value) {
-    this.value = value;
-    return this;
-  }
-
-  public ResourceInformation tags(Set<String> resourceTags) {
-    this.tags = resourceTags;
-    return this;
-  }
-
-  @ApiModelProperty(value = "")
-  @JsonProperty("tags")
-  public Set<String> getTags() {
-    return tags == null ? ImmutableSet.of() : tags;
-  }
-
-  @ApiModelProperty(value = "")
-  @JsonProperty("attributes")
-  public Map<String, String> getAttributes() {
-    return attributes == null ? ImmutableMap.of() : attributes;
-  }
-
-  public ResourceInformation attributes(Map<String, String> attributes) {
-    this.attributes = attributes;
-    return this;
-  }
-
-  /**
-   * Integer value of the resource.
-   *
-   * @return value
-   **/
-  @ApiModelProperty(value = "Integer value of the resource.")
-  @JsonProperty("value")
-  public Long getValue() {
-    return value;
-  }
-
-  public void setValue(Long value) {
-    this.value = value;
-  }
-
-  public ResourceInformation unit(String unit) {
-    this.unit = unit;
-    return this;
-  }
-
-  /**
-   * @return unit
-   **/
-  @ApiModelProperty(value = "")
-  @JsonProperty("unit")
-  public String getUnit() {
-    return unit == null ? "" : unit;
-  }
-
-  public void setUnit(String unit) {
-    this.unit = unit;
-  }
-
-  @Override
-  public boolean equals(java.lang.Object o) {
-    if (this == o) {
-      return true;
-    }
-    if (o == null || getClass() != o.getClass()) {
-      return false;
-    }
-    ResourceInformation resourceInformation = (ResourceInformation) o;
-    return Objects
-        .equals(this.value, resourceInformation.value) && Objects.equals(
-        this.unit, resourceInformation.unit);
-  }
-
-  @Override
-  public int hashCode() {
-    return Objects.hash(value, unit);
-  }
-
-  @Override
-  public String toString() {
-    StringBuilder sb = new StringBuilder();
-    sb.append("class ResourceInformation {\n")
-        .append("    value: ").append(toIndentedString(value)).append("\n")
-        .append("    unit: ").append(toIndentedString(unit)).append("\n")
-        .append("    attributes: ").append(toIndentedString(attributes))
-        .append("\n")
-        .append("    tags: ").append(toIndentedString(tags)).append("\n")
-        .append("}");
-    return sb.toString();
-  }
-
-  /**
-   * Convert the given object to string with each line indented by 4 spaces
-   * (except the first line).
-   */
-  private String toIndentedString(java.lang.Object o) {
-    if (o == null) {
-      return "null";
-    }
-    return o.toString().replace("\n", "\n    ");
-  }
-
-}
-
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Service.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Service.java
deleted file mode 100644
index 4171e189e1d..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/Service.java
+++ /dev/null
@@ -1,472 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonProperty;
-import com.fasterxml.jackson.annotation.JsonPropertyOrder;
-import io.swagger.annotations.ApiModel;
-import io.swagger.annotations.ApiModelProperty;
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-
-import javax.xml.bind.annotation.XmlAccessType;
-import javax.xml.bind.annotation.XmlAccessorType;
-import javax.xml.bind.annotation.XmlElement;
-import javax.xml.bind.annotation.XmlRootElement;
-import java.util.ArrayList;
-import java.util.Date;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Objects;
-
-/**
- * An Service resource has the following attributes.
- **/
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-@ApiModel(description = "An Service resource has the following attributes.")
-@XmlRootElement
-@XmlAccessorType(XmlAccessType.FIELD)
-@JsonInclude(JsonInclude.Include.NON_NULL)
-@JsonPropertyOrder({ "name", "version", "description", "state", "resource",
-    "number_of_containers", "lifetime", "containers" })
-public class Service extends BaseResource {
-  private static final long serialVersionUID = -4491694636566094885L;
-
-  private String name = null;
-  private String id = null;
-  private Artifact artifact = null;
-  private Resource resource = null;
-  @JsonProperty("launch_time")
-  @XmlElement(name = "launch_time")
-  private Date launchTime = null;
-  @JsonProperty("number_of_running_containers")
-  @XmlElement(name = "number_of_running_containers")
-  private Long numberOfRunningContainers = null;
-  private Long lifetime = null;
-  private List<Component> components = new ArrayList<>();
-  private Configuration configuration = new Configuration();
-  private ServiceState state = null;
-  private Map<String, String> quicklinks = new HashMap<>();
-  private String queue = null;
-  @JsonProperty("kerberos_principal")
-  @XmlElement(name = "kerberos_principal")
-  private KerberosPrincipal kerberosPrincipal = new KerberosPrincipal();
-  private String version = null;
-  private String description = null;
-  private String dockerClientConfig = null;
-  private List<String> dependencies = new ArrayList<String>();
-
-  /**
-   * A unique service name.
-   **/
-  public Service name(String name) {
-    this.name = name;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", required = true, value = "A unique service name.")
-  @JsonProperty("name")
-  public String getName() {
-    return name;
-  }
-
-  public void setName(String name) {
-    this.name = name;
-  }
-
-  /**
-   * A unique service id.
-   **/
-  public Service id(String id) {
-    this.id = id;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "A unique service id.")
-  @JsonProperty("id")
-  public String getId() {
-    return id;
-  }
-
-  public void setId(String id) {
-    this.id = id;
-  }
-
-  @ApiModelProperty(example = "null", required = true,
-      value = "Version of the service.")
-  @JsonProperty("version")
-  public String getVersion() {
-    return version;
-  }
-
-  public void setVersion(String version) {
-    this.version = version;
-  }
-
-  /**
-   * Version of the service.
-   */
-  public Service version(String version) {
-    this.version = version;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Description of the service.")
-  @JsonProperty("description")
-  public String getDescription() {
-    return description;
-  }
-
-  public void setDescription(String description) {
-    this.description = description;
-  }
-
-  /**
-   * Description of the service.
-   */
-  public Service description(String description) {
-    this.description = description;
-    return this;
-  }
-
-  /**
-   * Artifact of single-component services. Mandatory if components
-   * attribute is not specified.
-   **/
-  public Service artifact(Artifact artifact) {
-    this.artifact = artifact;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Artifact of single-component services. Mandatory if components attribute is not specified.")
-  @JsonProperty("artifact")
-  public Artifact getArtifact() {
-    return artifact;
-  }
-
-  public void setArtifact(Artifact artifact) {
-    this.artifact = artifact;
-  }
-
-  /**
-   * Resource of single-component services or the global default for
-   * multi-component services. Mandatory if it is a single-component
-   * service and if cpus and memory are not specified at the Service
-   * level.
-   **/
-  public Service resource(Resource resource) {
-    this.resource = resource;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Resource of single-component services or the global default for multi-component services. Mandatory if it is a single-component service and if cpus and memory are not specified at the Service level.")
-  @JsonProperty("resource")
-  public Resource getResource() {
-    return resource;
-  }
-
-  public void setResource(Resource resource) {
-    this.resource = resource;
-  }
-
-  /**
-   * The time when the service was created, e.g. 2016-03-16T01:01:49.000Z.
-   **/
-  public Service launchTime(Date launchTime) {
-    this.launchTime = launchTime == null ? null : (Date) launchTime.clone();
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "The time when the service was created, e.g. 2016-03-16T01:01:49.000Z.")
-  public Date getLaunchTime() {
-    return launchTime == null ? null : (Date) launchTime.clone();
-  }
-
-  public void setLaunchTime(Date launchTime) {
-    this.launchTime = launchTime == null ? null : (Date) launchTime.clone();
-  }
-
-  /**
-   * In get response this provides the total number of running containers for
-   * this service (across all components) at the time of request. Note, a
-   * subsequent request can return a different number as and when more
-   * containers get allocated until it reaches the total number of containers or
-   * if a flex request has been made between the two requests.
-   **/
-  public Service numberOfRunningContainers(Long numberOfRunningContainers) {
-    this.numberOfRunningContainers = numberOfRunningContainers;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "In get response this provides the total number of running containers for this service (across all components) at the time of request. Note, a subsequent request can return a different number as and when more containers get allocated until it reaches the total number of containers or if a flex request has been made between the two requests.")
-  public Long getNumberOfRunningContainers() {
-    return numberOfRunningContainers;
-  }
-
-  public void setNumberOfRunningContainers(Long numberOfRunningContainers) {
-    this.numberOfRunningContainers = numberOfRunningContainers;
-  }
-
-  /**
-   * Life time (in seconds) of the service from the time it reaches the
-   * RUNNING_BUT_UNREADY state (after which it is automatically destroyed by YARN). For
-   * unlimited lifetime do not set a lifetime value.
-   **/
-  public Service lifetime(Long lifetime) {
-    this.lifetime = lifetime;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Life time (in seconds) of the service from the time it reaches the RUNNING_BUT_UNREADY state (after which it is automatically destroyed by YARN). For unlimited lifetime do not set a lifetime value.")
-  @JsonProperty("lifetime")
-  public Long getLifetime() {
-    return lifetime;
-  }
-
-  public void setLifetime(Long lifetime) {
-    this.lifetime = lifetime;
-  }
-
-  /**
-   * Components of an service.
-   **/
-  public Service components(List<Component> components) {
-    this.components = components;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Components of an service.")
-  @JsonProperty("components")
-  public List<Component> getComponents() {
-    return components;
-  }
-
-  public void setComponents(List<Component> components) {
-    this.components = components;
-  }
-
-  public void addComponent(Component component) {
-    components.add(component);
-  }
-
-  public Component getComponent(String name) {
-    for (Component component : components) {
-      if (component.getName().equals(name)) {
-        return component;
-      }
-    }
-    return null;
-  }
-
-  /**
-   * Config properties of an service. Configurations provided at the
-   * service/global level are available to all the components. Specific
-   * properties can be overridden at the component level.
-   **/
-  public Service configuration(Configuration configuration) {
-    this.configuration = configuration;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Config properties of an service. Configurations provided at the service/global level are available to all the components. Specific properties can be overridden at the component level.")
-  @JsonProperty("configuration")
-  public Configuration getConfiguration() {
-    return configuration;
-  }
-
-  public void setConfiguration(Configuration configuration) {
-    this.configuration = configuration;
-  }
-
-  /**
-   * State of the service. Specifying a value for this attribute for the
-   * POST payload raises a validation error. This attribute is available only in
-   * the GET response of a started service.
-   **/
-  public Service state(ServiceState state) {
-    this.state = state;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "State of the service. Specifying a value for this attribute for the POST payload raises a validation error. This attribute is available only in the GET response of a started service.")
-  @JsonProperty("state")
-  public ServiceState getState() {
-    return state;
-  }
-
-  public void setState(ServiceState state) {
-    this.state = state;
-  }
-
-  /**
-   * A blob of key-value pairs of quicklinks to be exported for an service.
-   **/
-  public Service quicklinks(Map<String, String> quicklinks) {
-    this.quicklinks = quicklinks;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "A blob of key-value pairs of quicklinks to be exported for an service.")
-  @JsonProperty("quicklinks")
-  public Map<String, String> getQuicklinks() {
-    return quicklinks;
-  }
-
-  public void setQuicklinks(Map<String, String> quicklinks) {
-    this.quicklinks = quicklinks;
-  }
-
-  /**
-   * The YARN queue that this service should be submitted to.
-   **/
-  public Service queue(String queue) {
-    this.queue = queue;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "The YARN queue that this service should be submitted to.")
-  @JsonProperty("queue")
-  public String getQueue() {
-    return queue;
-  }
-
-  public void setQueue(String queue) {
-    this.queue = queue;
-  }
-
-  @ApiModelProperty(example = "null", value = "A list of dependent services.")
-  @XmlElement(name = "dependencies")
-  @JsonProperty("dependencies")
-  public List<String> getDependencies() {
-    return dependencies;
-  }
-
-  public void setDependencies(List<String>
-      dependencies) {
-    this.dependencies = dependencies;
-  }
-
-  public Service kerberosPrincipal(KerberosPrincipal kerberosPrincipal) {
-    this.kerberosPrincipal = kerberosPrincipal;
-    return this;
-  }
-
-  /**
-   * The Kerberos Principal of the service.
-   * @return kerberosPrincipal
-   **/
-  @ApiModelProperty(value = "The Kerberos Principal of the service")
-  public KerberosPrincipal getKerberosPrincipal() {
-    return kerberosPrincipal;
-  }
-
-  public void setKerberosPrincipal(KerberosPrincipal kerberosPrincipal) {
-    this.kerberosPrincipal = kerberosPrincipal;
-  }
-
-  @JsonProperty("docker_client_config")
-  @XmlElement(name = "docker_client_config")
-  @SuppressWarnings("checkstyle:hiddenfield")
-  public Service dockerClientConfig(String dockerClientConfig) {
-    this.dockerClientConfig = dockerClientConfig;
-    return this;
-  }
-
-  /**
-   * The Docker client config for the service.
-   * @return dockerClientConfig
-   */
-  @ApiModelProperty(value = "The Docker client config for the service")
-  public String getDockerClientConfig() {
-    return dockerClientConfig;
-  }
-
-  public void setDockerClientConfig(String dockerClientConfig) {
-    this.dockerClientConfig = dockerClientConfig;
-  }
-
-  @Override
-  public boolean equals(java.lang.Object o) {
-    if (this == o) {
-      return true;
-    }
-    if (o == null || getClass() != o.getClass()) {
-      return false;
-    }
-    Service service = (Service) o;
-    return Objects.equals(this.name, service.name);
-  }
-
-  @Override
-  public int hashCode() {
-    return Objects.hash(name);
-  }
-
-  @Override
-  public String toString() {
-    StringBuilder sb = new StringBuilder();
-    sb.append("class Service {\n")
-
-        .append("    name: ").append(toIndentedString(name)).append("\n")
-        .append("    id: ").append(toIndentedString(id)).append("\n")
-        .append("    version: ").append(toIndentedString(version)).append("\n")
-        .append("    description: ").append(toIndentedString(description))
-        .append("\n")
-        .append("    artifact: ").append(toIndentedString(artifact))
-        .append("\n")
-        .append("    resource: ").append(toIndentedString(resource))
-        .append("\n")
-        .append("    launchTime: ").append(toIndentedString(launchTime))
-        .append("\n")
-        .append("    numberOfRunningContainers: ")
-        .append(toIndentedString(numberOfRunningContainers)).append("\n")
-        .append("    lifetime: ").append(toIndentedString(lifetime))
-        .append("\n")
-        .append("    components: ").append(toIndentedString(components))
-        .append("\n")
-        .append("    configuration: ").append(toIndentedString(configuration))
-        .append("\n")
-        .append("    state: ").append(toIndentedString(state)).append("\n")
-        .append("    quicklinks: ").append(toIndentedString(quicklinks))
-        .append("\n")
-        .append("    queue: ").append(toIndentedString(queue)).append("\n")
-        .append("    kerberosPrincipal: ")
-        .append(toIndentedString(kerberosPrincipal)).append("\n")
-        .append("    dockerClientConfig: ")
-        .append(toIndentedString(dockerClientConfig)).append("\n")
-        .append("    dependencies: ")
-        .append(toIndentedString(dependencies)).append("\n")
-        .append("}");
-    return sb.toString();
-  }
-
-  /**
-   * Convert the given object to string with each line indented by 4 spaces
-   * (except the first line).
-   */
-  private String toIndentedString(java.lang.Object o) {
-    if (o == null) {
-      return "null";
-    }
-    return o.toString().replace("\n", "\n    ");
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ServiceState.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ServiceState.java
deleted file mode 100644
index 3f2f4f6b91d..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ServiceState.java
+++ /dev/null
@@ -1,38 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import io.swagger.annotations.ApiModel;
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-
-/**
- * The current state of an service.
- **/
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-@ApiModel(description = "The current state of an service.")
-public enum ServiceState {
-  ACCEPTED, STARTED, STABLE, STOPPED, FAILED, FLEX, UPGRADING,
-  UPGRADING_AUTO_FINALIZE, EXPRESS_UPGRADING, SUCCEEDED, CANCEL_UPGRADING;
-
-  public static boolean isUpgrading(ServiceState state) {
-    return state.equals(UPGRADING) || state.equals(UPGRADING_AUTO_FINALIZE)
-        || state.equals(EXPRESS_UPGRADING);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ServiceStatus.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ServiceStatus.java
deleted file mode 100644
index 60f8f2d891f..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/api/records/ServiceStatus.java
+++ /dev/null
@@ -1,147 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.api.records;
-
-import io.swagger.annotations.ApiModel;
-import io.swagger.annotations.ApiModelProperty;
-
-import java.util.Objects;
-
-import javax.xml.bind.annotation.XmlRootElement;
-
-import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.annotation.JsonProperty;
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-
-/**
- * The current status of a submitted service, returned as a response to the
- * GET API.
- **/
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-@ApiModel(description = "The current status of a submitted service, returned as a response to the GET API.")
-@XmlRootElement
-@JsonInclude(JsonInclude.Include.NON_NULL)
-public class ServiceStatus extends BaseResource {
-  private static final long serialVersionUID = -3469885905347851034L;
-
-  private String diagnostics = null;
-  private ServiceState state = null;
-  private Integer code = null;
-
-  /**
-   * Diagnostic information (if any) for the reason of the current state of the
-   * service. It typically has a non-null value, if the service is in a
-   * non-running state.
-   **/
-  public ServiceStatus diagnostics(String diagnostics) {
-    this.diagnostics = diagnostics;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Diagnostic information (if any) for the reason of the current state of the service. It typically has a non-null value, if the service is in a non-running state.")
-  @JsonProperty("diagnostics")
-  public String getDiagnostics() {
-    return diagnostics;
-  }
-
-  public void setDiagnostics(String diagnostics) {
-    this.diagnostics = diagnostics;
-  }
-
-  /**
-   * Service state.
-   **/
-  public ServiceStatus state(ServiceState state) {
-    this.state = state;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "Service state.")
-  @JsonProperty("state")
-  public ServiceState getState() {
-    return state;
-  }
-
-  public void setState(ServiceState state) {
-    this.state = state;
-  }
-
-  /**
-   * An error code specific to a scenario which service owners should be able to
-   * use to understand the failure in addition to the diagnostic information.
-   **/
-  public ServiceStatus code(Integer code) {
-    this.code = code;
-    return this;
-  }
-
-  @ApiModelProperty(example = "null", value = "An error code specific to a scenario which service owners should be able to use to understand the failure in addition to the diagnostic information.")
-  @JsonProperty("code")
-  public Integer getCode() {
-    return code;
-  }
-
-  public void setCode(Integer code) {
-    this.code = code;
-  }
-
-  @Override
-  public boolean equals(java.lang.Object o) {
-    if (this == o) {
-      return true;
-    }
-    if (o == null || getClass() != o.getClass()) {
-      return false;
-    }
-    ServiceStatus serviceStatus = (ServiceStatus) o;
-    return Objects.equals(this.diagnostics, serviceStatus.diagnostics)
-        && Objects.equals(this.state, serviceStatus.state)
-        && Objects.equals(this.code, serviceStatus.code);
-  }
-
-  @Override
-  public int hashCode() {
-    return Objects.hash(diagnostics, state, code);
-  }
-
-  @Override
-  public String toString() {
-    StringBuilder sb = new StringBuilder();
-    sb.append("class ServiceStatus {\n")
-
-        .append("    diagnostics: ").append(toIndentedString(diagnostics))
-        .append("\n")
-        .append("    state: ").append(toIndentedString(state)).append("\n")
-        .append("    code: ").append(toIndentedString(code)).append("\n")
-        .append("}");
-    return sb.toString();
-  }
-
-  /**
-   * Convert the given object to string with each line indented by 4 spaces
-   * (except the first line).
-   */
-  private String toIndentedString(java.lang.Object o) {
-    if (o == null) {
-      return "null";
-    }
-    return o.toString().replace("\n", "\n    ");
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/client/ClientAMProxy.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/client/ClientAMProxy.java
deleted file mode 100644
index e8e7de42c02..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/client/ClientAMProxy.java
+++ /dev/null
@@ -1,58 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.client;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.CommonConfigurationKeysPublic;
-import org.apache.hadoop.io.retry.RetryPolicy;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.yarn.client.ServerProxy;
-import org.apache.hadoop.yarn.ipc.YarnRPC;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConf;
-
-import java.net.InetSocketAddress;
-
-import static org.apache.hadoop.io.retry.RetryPolicies.TRY_ONCE_THEN_FAIL;
-
-public class ClientAMProxy extends ServerProxy{
-
-  public static <T> T createProxy(final Configuration conf,
-      final Class<T> protocol, final UserGroupInformation ugi,
-      final YarnRPC rpc, final InetSocketAddress serverAddress) {
-    Configuration confClone = new Configuration(conf);
-    confClone.setInt(
-        CommonConfigurationKeysPublic.IPC_CLIENT_CONNECT_MAX_RETRIES_KEY, 0);
-    confClone.setInt(CommonConfigurationKeysPublic.
-        IPC_CLIENT_CONNECT_MAX_RETRIES_ON_SOCKET_TIMEOUTS_KEY, 0);
-    RetryPolicy retryPolicy;
-
-    if (conf.getLong(YarnServiceConf.CLIENT_AM_RETRY_MAX_WAIT_MS, 0) == 0) {
-      // by default no retry
-      retryPolicy = TRY_ONCE_THEN_FAIL;
-    } else {
-      retryPolicy =
-          createRetryPolicy(conf, YarnServiceConf.CLIENT_AM_RETRY_MAX_WAIT_MS,
-              YarnServiceConf.DEFAULT_CLIENT_AM_RETRY_MAX_WAIT_MS,
-              YarnServiceConf.CLIENT_AM_RETRY_MAX_INTERVAL_MS,
-              YarnServiceConf.DEFAULT_CLIENT_AM_RETRY_MAX_INTERVAL_MS);
-    }
-    return createRetriableProxy(confClone, protocol, ugi, rpc, serverAddress,
-        retryPolicy);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/client/ServiceClient.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/client/ServiceClient.java
deleted file mode 100644
index 9098bb4a751..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/client/ServiceClient.java
+++ /dev/null
@@ -1,1804 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.client;
-
-import org.apache.hadoop.classification.VisibleForTesting;
-
-import org.apache.commons.compress.archivers.tar.TarArchiveEntry;
-import org.apache.commons.compress.archivers.tar.TarArchiveOutputStream;
-import org.apache.commons.compress.utils.IOUtils;
-import org.apache.commons.lang3.StringUtils;
-import org.apache.curator.framework.CuratorFramework;
-import org.apache.curator.framework.CuratorFrameworkFactory;
-import org.apache.curator.retry.RetryNTimes;
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.fs.permission.FsAction;
-import org.apache.hadoop.fs.permission.FsPermission;
-import org.apache.hadoop.hdfs.DFSConfigKeys;
-import org.apache.hadoop.io.DataOutputBuffer;
-import org.apache.hadoop.net.NetUtils;
-import org.apache.hadoop.registry.client.api.RegistryConstants;
-import org.apache.hadoop.registry.client.api.RegistryOperations;
-import org.apache.hadoop.registry.client.api.RegistryOperationsFactory;
-import org.apache.hadoop.registry.client.binding.RegistryUtils;
-import org.apache.hadoop.security.Credentials;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.security.authorize.AccessControlList;
-import org.apache.hadoop.security.token.Token;
-import org.apache.hadoop.yarn.api.ApplicationConstants;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsRequest;
-
-import org.apache.hadoop.yarn.api.records.*;
-import org.apache.hadoop.yarn.client.api.AppAdminClient;
-import org.apache.hadoop.yarn.client.api.YarnClient;
-import org.apache.hadoop.yarn.client.api.YarnClientApplication;
-import org.apache.hadoop.yarn.client.cli.ApplicationCLI;
-import org.apache.hadoop.yarn.client.util.YarnClientUtils;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.ApplicationNotFoundException;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.ipc.YarnRPC;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CancelUpgradeRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CompInstancesUpgradeRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.ComponentCountProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.DecommissionCompInstancesRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.FlexComponentsRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetCompInstancesRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetCompInstancesResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetStatusRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetStatusResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.RestartServiceRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.StopRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.UpgradeServiceRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.UpgradeServiceResponseProto;
-import org.apache.hadoop.yarn.service.ClientAMProtocol;
-import org.apache.hadoop.yarn.service.ServiceMaster;
-import org.apache.hadoop.yarn.service.api.records.ComponentContainers;
-import org.apache.hadoop.yarn.service.api.records.Container;
-import org.apache.hadoop.yarn.service.api.records.ContainerState;
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.api.records.ConfigFile;
-import org.apache.hadoop.yarn.service.api.records.ConfigFile.TypeEnum;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.conf.SliderExitCodes;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConf;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConstants;
-import org.apache.hadoop.yarn.service.containerlaunch.ClasspathConstructor;
-import org.apache.hadoop.yarn.service.containerlaunch.JavaCommandLineBuilder;
-import org.apache.hadoop.yarn.service.exceptions.BadClusterStateException;
-import org.apache.hadoop.yarn.service.exceptions.BadConfigException;
-import org.apache.hadoop.yarn.service.exceptions.ErrorStrings;
-import org.apache.hadoop.yarn.service.exceptions.SliderException;
-import org.apache.hadoop.yarn.service.provider.AbstractClientProvider;
-import org.apache.hadoop.yarn.service.provider.ProviderUtils;
-import org.apache.hadoop.yarn.service.utils.ServiceApiUtil;
-import org.apache.hadoop.yarn.service.utils.ServiceRegistryUtils;
-import org.apache.hadoop.yarn.service.utils.ServiceUtils;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-import org.apache.hadoop.yarn.service.utils.ZookeeperUtils;
-import org.apache.hadoop.yarn.util.DockerClientConfigHandler;
-import org.apache.hadoop.yarn.util.Records;
-import org.apache.hadoop.yarn.util.Times;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.BufferedOutputStream;
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.FileOutputStream;
-import java.io.IOException;
-import java.io.OutputStreamWriter;
-import java.io.Writer;
-import java.net.InetSocketAddress;
-import java.net.URI;
-import java.net.URISyntaxException;
-import java.nio.ByteBuffer;
-import java.nio.charset.StandardCharsets;
-import java.nio.file.Files;
-import java.text.MessageFormat;
-import java.util.*;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.stream.Collectors;
-
-import static org.apache.hadoop.yarn.api.records.YarnApplicationState.*;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.*;
-import static org.apache.hadoop.yarn.service.utils.ServiceApiUtil.jsonSerDeser;
-import static org.apache.hadoop.yarn.service.utils.ServiceUtils.*;
-
-@InterfaceAudience.Public
-@InterfaceStability.Unstable
-public class ServiceClient extends AppAdminClient implements SliderExitCodes,
-    YarnServiceConstants {
-  private static final Logger LOG =
-      LoggerFactory.getLogger(ServiceClient.class);
-  private SliderFileSystem fs;
-  //TODO disable retry so that client / rest API doesn't block?
-  protected YarnClient yarnClient;
-  // Avoid looking up applicationId from fs all the time.
-  private Map<String, AppInfo> cachedAppInfo = new ConcurrentHashMap<>();
-
-  private RegistryOperations registryClient;
-  private CuratorFramework curatorClient;
-  private YarnRPC rpc;
-
-  private static EnumSet<YarnApplicationState> terminatedStates =
-      EnumSet.of(FINISHED, FAILED, KILLED);
-  private static EnumSet<YarnApplicationState> liveStates =
-      EnumSet.of(NEW, NEW_SAVING, SUBMITTED, ACCEPTED, RUNNING);
-  private static EnumSet<YarnApplicationState> preRunningStates =
-      EnumSet.of(NEW, NEW_SAVING, SUBMITTED, ACCEPTED);
-
-  @Override protected void serviceInit(Configuration configuration)
-      throws Exception {
-    fs = new SliderFileSystem(configuration);
-    yarnClient = YarnClient.createYarnClient();
-    rpc = YarnRPC.create(configuration);
-    addService(yarnClient);
-    super.serviceInit(configuration);
-  }
-
-  @Override
-  protected void serviceStop() throws Exception {
-    if (registryClient != null) {
-      registryClient.stop();
-    }
-    fs.getFileSystem().close();
-    super.serviceStop();
-  }
-
-  public Service loadAppJsonFromLocalFS(String fileName, String serviceName,
-      Long lifetime, String queue) throws IOException, YarnException {
-    File file = new File(fileName);
-    if (!file.exists() && fileName.equals(file.getName())) {
-      String examplesDirStr = System.getenv("YARN_SERVICE_EXAMPLES_DIR");
-      String[] examplesDirs;
-      if (examplesDirStr == null) {
-        String yarnHome = System
-            .getenv(ApplicationConstants.Environment.HADOOP_YARN_HOME.key());
-        examplesDirs = new String[]{
-            yarnHome + "/share/hadoop/yarn/yarn-service-examples",
-            yarnHome + "/yarn-service-examples"
-        };
-      } else {
-        examplesDirs = StringUtils.split(examplesDirStr, ":");
-      }
-      for (String dir : examplesDirs) {
-        file = new File(MessageFormat.format("{0}/{1}/{2}.json",
-            dir, fileName, fileName));
-        if (file.exists()) {
-          break;
-        }
-        // Then look for secondary location.
-        file = new File(MessageFormat.format("{0}/{1}.json",
-            dir, fileName));
-        if (file.exists()) {
-          break;
-        }
-      }
-    }
-    if (!file.exists()) {
-      throw new YarnException("File or example could not be found: " +
-          fileName);
-    }
-    Path filePath = new Path(file.getAbsolutePath());
-    LOG.info("Loading service definition from local FS: " + filePath);
-    Service service = jsonSerDeser
-        .load(FileSystem.getLocal(getConfig()), filePath);
-    if (!StringUtils.isEmpty(serviceName)) {
-      service.setName(serviceName);
-    }
-    if (lifetime != null && lifetime > 0) {
-      service.setLifetime(lifetime);
-    }
-    if (!StringUtils.isEmpty(queue)) {
-      service.setQueue(queue);
-    }
-    return service;
-  }
-
-  @Override
-  public int actionSave(String fileName, String serviceName, Long lifetime,
-      String queue) throws IOException, YarnException {
-    return actionBuild(loadAppJsonFromLocalFS(fileName, serviceName,
-        lifetime, queue));
-  }
-
-  public int actionBuild(Service service)
-      throws YarnException, IOException {
-    ServiceApiUtil.validateAndResolveService(service, fs, getConfig());
-    Path appDir = checkAppNotExistOnHdfs(service, false);
-    ServiceApiUtil.createDirAndPersistApp(fs, appDir, service);
-    return EXIT_SUCCESS;
-  }
-
-  private ApplicationReport upgradePrecheck(Service service)
-      throws YarnException, IOException {
-    boolean upgradeEnabled = getConfig().getBoolean(
-        YARN_SERVICE_UPGRADE_ENABLED, YARN_SERVICE_UPGRADE_ENABLED_DEFAULT);
-    if (!upgradeEnabled) {
-      throw new YarnException(ErrorStrings.SERVICE_UPGRADE_DISABLED);
-    }
-    Service persistedService = ServiceApiUtil.loadService(fs,
-        service.getName());
-    if (!StringUtils.isEmpty(persistedService.getId())) {
-      cachedAppInfo.put(persistedService.getName(),
-          new AppInfo(ApplicationId.fromString(persistedService.getId()),
-              persistedService.getKerberosPrincipal().getPrincipalName()));
-    }
-
-    if (persistedService.getVersion().equals(service.getVersion())) {
-      String message = service.getName() + " is already at version "
-          + service.getVersion() + ". There is nothing to upgrade.";
-      LOG.error(message);
-      throw new YarnException(message);
-    }
-    boolean foundNotNeverComp = false;
-    for (Component comp : persistedService.getComponents()) {
-      // If restart policy of any component is not NEVER then upgrade is
-      // allowed.
-      if (!comp.getRestartPolicy().equals(Component.RestartPolicyEnum.NEVER)) {
-        foundNotNeverComp = true;
-        break;
-      }
-    }
-    if (!foundNotNeverComp) {
-      String message = "All the components of the service " + service.getName()
-          + " have " + Component.RestartPolicyEnum.NEVER + " restart policy, " +
-          "so it cannot be upgraded.";
-      LOG.error(message);
-      throw new YarnException(message);
-    }
-    Service liveService = getStatus(service.getName());
-    if (!liveService.getState().equals(ServiceState.STABLE)) {
-      String message = service.getName() + " is at " + liveService.getState()
-          + " state and upgrade can only be initiated when service is STABLE.";
-      LOG.error(message);
-      throw new YarnException(message);
-    }
-
-    Path serviceUpgradeDir = checkAppNotExistOnHdfs(service, true);
-    ServiceApiUtil.validateAndResolveService(service, fs, getConfig());
-    ServiceApiUtil.createDirAndPersistApp(fs, serviceUpgradeDir, service);
-
-    ApplicationReport appReport = yarnClient
-        .getApplicationReport(getAppId(service.getName()));
-    if (StringUtils.isEmpty(appReport.getHost())) {
-      throw new YarnException(service.getName() + " AM hostname is empty");
-    }
-    return appReport;
-  }
-
-  @Override
-  public int actionUpgradeExpress(String appName, File path)
-      throws IOException, YarnException {
-    Service service =
-        loadAppJsonFromLocalFS(path.getAbsolutePath(), appName, null, null);
-    service.setState(ServiceState.UPGRADING_AUTO_FINALIZE);
-    actionUpgradeExpress(service);
-    return EXIT_SUCCESS;
-  }
-
-  public int actionUpgradeExpress(Service service) throws YarnException,
-      IOException {
-    ApplicationReport appReport = upgradePrecheck(service);
-    ClientAMProtocol proxy = createAMProxy(service.getName(), appReport);
-    UpgradeServiceRequestProto.Builder requestBuilder =
-        UpgradeServiceRequestProto.newBuilder();
-    requestBuilder.setVersion(service.getVersion());
-    if (service.getState().equals(ServiceState.UPGRADING_AUTO_FINALIZE)) {
-      requestBuilder.setAutoFinalize(true);
-    }
-    if (service.getState().equals(ServiceState.EXPRESS_UPGRADING)) {
-      requestBuilder.setExpressUpgrade(true);
-      requestBuilder.setAutoFinalize(true);
-    }
-    UpgradeServiceResponseProto responseProto = proxy.upgrade(
-        requestBuilder.build());
-    if (responseProto.hasError()) {
-      LOG.error("Service {} express upgrade to version {} failed because {}",
-          service.getName(), service.getVersion(), responseProto.getError());
-      throw new YarnException("Failed to express upgrade service " +
-          service.getName() + " to version " + service.getVersion() +
-          " because " + responseProto.getError());
-    }
-    return EXIT_SUCCESS;
-  }
-
-  @Override
-  public int initiateUpgrade(String appName, String fileName,
-      boolean autoFinalize)
-      throws IOException, YarnException {
-    Service upgradeService = loadAppJsonFromLocalFS(fileName, appName,
-        null, null);
-    if (autoFinalize) {
-      upgradeService.setState(ServiceState.UPGRADING_AUTO_FINALIZE);
-    } else {
-      upgradeService.setState(ServiceState.UPGRADING);
-    }
-    return initiateUpgrade(upgradeService);
-  }
-
-  public int initiateUpgrade(Service service) throws YarnException,
-      IOException {
-    ApplicationReport appReport = upgradePrecheck(service);
-    ClientAMProtocol proxy = createAMProxy(service.getName(), appReport);
-
-    UpgradeServiceRequestProto.Builder requestBuilder =
-        UpgradeServiceRequestProto.newBuilder();
-    requestBuilder.setVersion(service.getVersion());
-    if (service.getState().equals(ServiceState.UPGRADING_AUTO_FINALIZE)) {
-      requestBuilder.setAutoFinalize(true);
-    }
-    UpgradeServiceResponseProto responseProto = proxy.upgrade(
-        requestBuilder.build());
-    if (responseProto.hasError()) {
-      LOG.error("Service {} upgrade to version {} failed because {}",
-          service.getName(), service.getVersion(), responseProto.getError());
-      throw new YarnException("Failed to upgrade service " + service.getName()
-          + " to version " + service.getVersion() + " because " +
-          responseProto.getError());
-    }
-    return EXIT_SUCCESS;
-  }
-
-  @Override
-  public int actionUpgradeInstances(String appName,
-      List<String> componentInstances) throws IOException, YarnException {
-    checkAppExistOnHdfs(appName);
-    Service persistedService = ServiceApiUtil.loadService(fs, appName);
-    List<Container> containersToUpgrade = ServiceApiUtil.
-        getLiveContainers(persistedService, componentInstances);
-    ServiceApiUtil.validateInstancesUpgrade(containersToUpgrade);
-    return actionUpgrade(persistedService, containersToUpgrade);
-  }
-
-  @Override
-  public int actionUpgradeComponents(String appName,
-      List<String> components) throws IOException, YarnException {
-    checkAppExistOnHdfs(appName);
-    Service persistedService = ServiceApiUtil.loadService(fs, appName);
-    List<Container> containersToUpgrade = ServiceApiUtil
-        .validateAndResolveCompsUpgrade(persistedService, components);
-    return actionUpgrade(persistedService, containersToUpgrade);
-  }
-
-  @Override
-  public int actionCancelUpgrade(String appName) throws IOException,
-      YarnException {
-    Service liveService = getStatus(appName);
-    if (liveService == null ||
-        !ServiceState.isUpgrading(liveService.getState())) {
-      throw new YarnException("Service " + appName + " is not upgrading, " +
-          "so nothing to cancel.");
-    }
-
-    ApplicationReport appReport = yarnClient.getApplicationReport(
-        getAppId(appName));
-    if (StringUtils.isEmpty(appReport.getHost())) {
-      throw new YarnException(appName + " AM hostname is empty");
-    }
-    ClientAMProtocol proxy = createAMProxy(appName, appReport);
-    proxy.cancelUpgrade(CancelUpgradeRequestProto.newBuilder().build());
-    return EXIT_SUCCESS;
-  }
-
-  @Override
-  public int actionDecommissionInstances(String appName,
-      List<String> componentInstances) throws IOException, YarnException {
-    checkAppExistOnHdfs(appName);
-    Service persistedService = ServiceApiUtil.loadService(fs, appName);
-    if (StringUtils.isEmpty(persistedService.getId())) {
-      throw new YarnException(
-          persistedService.getName() + " appId is null, may be not submitted " +
-              "to YARN yet");
-    }
-    cachedAppInfo.put(persistedService.getName(), new AppInfo(
-        ApplicationId.fromString(persistedService.getId()), persistedService
-        .getKerberosPrincipal().getPrincipalName()));
-
-    for (String instance : componentInstances) {
-      String componentName = ServiceApiUtil.parseComponentName(
-          ServiceApiUtil.parseAndValidateComponentInstanceName(instance,
-              appName, getConfig()));
-      Component component = persistedService.getComponent(componentName);
-      if (component == null) {
-        throw new IllegalArgumentException(instance + " does not exist !");
-      }
-      if (!component.getDecommissionedInstances().contains(instance)) {
-        component.addDecommissionedInstance(instance);
-        component.setNumberOfContainers(Math.max(0, component
-            .getNumberOfContainers() - 1));
-      }
-    }
-    ServiceApiUtil.writeAppDefinition(fs, persistedService);
-
-    ApplicationReport appReport =
-        yarnClient.getApplicationReport(ApplicationId.fromString(
-            persistedService.getId()));
-    if (appReport.getYarnApplicationState() != RUNNING) {
-      String message =
-          persistedService.getName() + " is at " + appReport
-              .getYarnApplicationState() + " state, decommission can only be " +
-              "invoked when service is running";
-      LOG.error(message);
-      throw new YarnException(message);
-    }
-
-    if (StringUtils.isEmpty(appReport.getHost())) {
-      throw new YarnException(persistedService.getName() + " AM hostname is " +
-          "empty");
-    }
-    ClientAMProtocol proxy =
-        createAMProxy(persistedService.getName(), appReport);
-    DecommissionCompInstancesRequestProto.Builder requestBuilder =
-        DecommissionCompInstancesRequestProto.newBuilder();
-    requestBuilder.addAllCompInstances(componentInstances);
-    proxy.decommissionCompInstances(requestBuilder.build());
-    return EXIT_SUCCESS;
-  }
-
-  @Override
-  public int actionCleanUp(String appName, String userName) throws
-      IOException, YarnException {
-    if (cleanUpRegistry(appName, userName)) {
-      return EXIT_SUCCESS;
-    } else {
-      return EXIT_FALSE;
-    }
-  }
-
-  @Override
-  public String getInstances(String appName,
-      List<String> components, String version, List<String> containerStates)
-      throws IOException, YarnException {
-    GetCompInstancesResponseProto result = filterContainers(appName, components,
-        version, containerStates);
-    return result.getCompInstances();
-  }
-
-  public ComponentContainers[] getContainers(String appName,
-      List<String> components,
-      String version, List<ContainerState> containerStates)
-      throws IOException, YarnException {
-    GetCompInstancesResponseProto result = filterContainers(appName, components,
-        version, containerStates != null ? containerStates.stream()
-            .map(Enum::toString).collect(Collectors.toList()) : null);
-
-    return ServiceApiUtil.COMP_CONTAINERS_JSON_SERDE.fromJson(
-        result.getCompInstances());
-  }
-
-  private GetCompInstancesResponseProto filterContainers(String appName,
-      List<String> components, String version,
-      List<String> containerStates) throws IOException, YarnException {
-    ApplicationReport appReport = yarnClient.getApplicationReport(getAppId(
-        appName));
-    if (StringUtils.isEmpty(appReport.getHost())) {
-      throw new YarnException(appName + " AM hostname is empty.");
-    }
-    ClientAMProtocol proxy = createAMProxy(appName, appReport);
-    GetCompInstancesRequestProto.Builder req = GetCompInstancesRequestProto
-        .newBuilder();
-    if (components != null && !components.isEmpty()) {
-      req.addAllComponentNames(components);
-    }
-    if (version != null) {
-      req.setVersion(version);
-    }
-    if (containerStates != null && !containerStates.isEmpty()){
-      req.addAllContainerStates(containerStates);
-    }
-    return proxy.getCompInstances(req.build());
-  }
-
-  public int actionUpgrade(Service service, List<Container> compInstances)
-      throws IOException, YarnException {
-    ApplicationReport appReport =
-        yarnClient.getApplicationReport(getAppId(service.getName()));
-
-    if (appReport.getYarnApplicationState() != RUNNING) {
-      String message = service.getName() + " is at " +
-          appReport.getYarnApplicationState()
-          + " state, upgrade can only be invoked when service is running.";
-      LOG.error(message);
-      throw new YarnException(message);
-    }
-    if (StringUtils.isEmpty(appReport.getHost())) {
-      throw new YarnException(service.getName() + " AM hostname is empty.");
-    }
-    ClientAMProtocol proxy = createAMProxy(service.getName(), appReport);
-
-    List<String> containerIdsToUpgrade = new ArrayList<>();
-    compInstances.forEach(compInst ->
-        containerIdsToUpgrade.add(compInst.getId()));
-    LOG.info("instances to upgrade {}", containerIdsToUpgrade);
-    CompInstancesUpgradeRequestProto.Builder upgradeRequestBuilder =
-        CompInstancesUpgradeRequestProto.newBuilder();
-    upgradeRequestBuilder.addAllContainerIds(containerIdsToUpgrade);
-    proxy.upgrade(upgradeRequestBuilder.build());
-    return EXIT_SUCCESS;
-  }
-
-  public int actionLaunch(String fileName, String serviceName, Long lifetime,
-      String queue) throws IOException, YarnException {
-    actionCreate(loadAppJsonFromLocalFS(fileName, serviceName, lifetime,
-        queue));
-    return EXIT_SUCCESS;
-  }
-
-  public ApplicationId actionCreate(Service service)
-      throws IOException, YarnException {
-    String serviceName = service.getName();
-    ServiceApiUtil.validateAndResolveService(service, fs, getConfig());
-    verifyNoLiveAppInRM(serviceName, "create");
-    Path appDir = checkAppNotExistOnHdfs(service, false);
-
-    // Write the definition first and then submit - AM will read the definition
-    ServiceApiUtil.createDirAndPersistApp(fs, appDir, service);
-    ApplicationId appId;
-    try {
-      appId = submitApp(service);
-    } catch(YarnException e){
-      actionDestroy(serviceName);
-      throw e;
-    }
-    cachedAppInfo.put(serviceName, new AppInfo(appId, service
-        .getKerberosPrincipal().getPrincipalName()));
-    service.setId(appId.toString());
-    // update app definition with appId
-    ServiceApiUtil.writeAppDefinition(fs, appDir, service);
-    return appId;
-  }
-
-  public int actionFlex(String serviceName, Map<String, String>
-      componentCountStrings) throws YarnException, IOException {
-    Map<String, Long> componentCounts =
-        new HashMap<>(componentCountStrings.size());
-    Service persistedService =
-        ServiceApiUtil.loadService(fs, serviceName);
-    if (!StringUtils.isEmpty(persistedService.getId())) {
-      cachedAppInfo.put(persistedService.getName(), new AppInfo(
-          ApplicationId.fromString(persistedService.getId()),
-          persistedService.getKerberosPrincipal().getPrincipalName()));
-    } else {
-      throw new YarnException(persistedService.getName()
-          + " appId is null, may be not submitted to YARN yet");
-    }
-
-    for (Map.Entry<String, String> entry : componentCountStrings.entrySet()) {
-      String compName = entry.getKey();
-      ServiceApiUtil.validateNameFormat(compName, getConfig());
-      Component component = persistedService.getComponent(compName);
-      if (component == null) {
-        throw new IllegalArgumentException(entry.getKey() + " does not exist !");
-      }
-      long numberOfContainers =
-          parseNumberOfContainers(component, entry.getValue());
-      componentCounts.put(compName, numberOfContainers);
-    }
-    flexComponents(serviceName, componentCounts, persistedService);
-    return EXIT_SUCCESS;
-  }
-
-  // Parse the number of containers requested by user, e.g.
-  // +5 means add 5 additional containers
-  // -5 means reduce 5 containers, if it goes to negative, sets it to 0
-  // 5 means sets it to 5 containers.
-  private long parseNumberOfContainers(Component component, String newNumber) {
-
-    long orig = component.getNumberOfContainers();
-    if (newNumber.startsWith("+")) {
-      return orig + Long.parseLong(newNumber.substring(1));
-    } else if (newNumber.startsWith("-")) {
-      long ret = orig - Long.parseLong(newNumber.substring(1));
-      if (ret < 0) {
-        LOG.warn(MessageFormat.format(
-            "[COMPONENT {0}]: component count goes to negative ({1}{2} = {3}),"
-                + " ignore and reset it to 0.",
-            component.getName(), orig, newNumber, ret));
-        ret = 0;
-      }
-      return ret;
-    } else {
-      return Long.parseLong(newNumber);
-    }
-  }
-
-  // Called by Rest Service
-  public Map<String, Long> flexByRestService(String serviceName,
-      Map<String, Long> componentCounts) throws YarnException, IOException {
-    // load app definition
-    Service persistedService = ServiceApiUtil.loadService(fs, serviceName);
-    if (StringUtils.isEmpty(persistedService.getId())) {
-      throw new YarnException(
-          serviceName + " appId is null, may be not submitted to YARN yet");
-    }
-    cachedAppInfo.put(persistedService.getName(), new AppInfo(
-        ApplicationId.fromString(persistedService.getId()), persistedService
-        .getKerberosPrincipal().getPrincipalName()));
-    return flexComponents(serviceName, componentCounts, persistedService);
-  }
-
-  private Map<String, Long> flexComponents(String serviceName,
-      Map<String, Long> componentCounts, Service persistedService)
-      throws YarnException, IOException {
-    ServiceApiUtil.validateNameFormat(serviceName, getConfig());
-
-    Map<String, Long> original = new HashMap<>(componentCounts.size());
-
-    ComponentCountProto.Builder countBuilder = ComponentCountProto.newBuilder();
-    FlexComponentsRequestProto.Builder requestBuilder =
-        FlexComponentsRequestProto.newBuilder();
-
-    for (Component persistedComp : persistedService.getComponents()) {
-      String name = persistedComp.getName();
-      if (componentCounts.containsKey(persistedComp.getName())) {
-        original.put(name, persistedComp.getNumberOfContainers());
-        persistedComp.setNumberOfContainers(componentCounts.get(name));
-
-        // build the request
-        countBuilder.setName(persistedComp.getName())
-            .setNumberOfContainers(persistedComp.getNumberOfContainers());
-        requestBuilder.addComponents(countBuilder.build());
-      }
-    }
-    if (original.size() < componentCounts.size()) {
-      componentCounts.keySet().removeAll(original.keySet());
-      throw new YarnException("Components " + componentCounts.keySet()
-          + " do not exist in app definition.");
-    }
-    ServiceApiUtil.writeAppDefinition(fs, persistedService);
-
-    ApplicationId appId = getAppId(serviceName);
-    if (appId == null) {
-      String message = "Application ID doesn't exist for " + serviceName;
-      LOG.error(message);
-      throw new YarnException(message);
-    }
-    ApplicationReport appReport =
-        yarnClient.getApplicationReport(appId);
-    if (appReport.getYarnApplicationState() != RUNNING) {
-      String message =
-          serviceName + " is at " + appReport.getYarnApplicationState()
-              + " state, flex can only be invoked when service is running";
-      LOG.error(message);
-      throw new YarnException(message);
-    }
-
-    Service liveService = getStatus(serviceName);
-    if (liveService.getState().equals(ServiceState.UPGRADING) ||
-        liveService.getState().equals(ServiceState.UPGRADING_AUTO_FINALIZE)) {
-      String message = serviceName + " is at " +
-          liveService.getState()
-          + " state, flex can not be invoked when service is upgrading. ";
-      LOG.error(message);
-      throw new YarnException(message);
-    }
-
-    if (StringUtils.isEmpty(appReport.getHost())) {
-      throw new YarnException(serviceName + " AM hostname is empty");
-    }
-    ClientAMProtocol proxy =
-        createAMProxy(serviceName, appReport);
-    proxy.flexComponents(requestBuilder.build());
-    for (Map.Entry<String, Long> entry : original.entrySet()) {
-      LOG.info("[COMPONENT {}]: number of containers changed from {} to {}",
-          entry.getKey(), entry.getValue(),
-          componentCounts.get(entry.getKey()));
-    }
-    return original;
-  }
-
-  @Override
-  public int actionStop(String serviceName)
-      throws YarnException, IOException {
-    return actionStop(serviceName, true);
-  }
-
-  public int actionStop(String serviceName, boolean waitForAppStopped)
-      throws YarnException, IOException {
-    ServiceApiUtil.validateNameFormat(serviceName, getConfig());
-    ApplicationId currentAppId = getAppId(serviceName);
-    if (currentAppId == null) {
-      LOG.info("Application ID doesn't exist for service {}", serviceName);
-      cleanUpRegistry(serviceName);
-      return EXIT_COMMAND_ARGUMENT_ERROR;
-    }
-    ApplicationReport report = yarnClient.getApplicationReport(currentAppId);
-    if (terminatedStates.contains(report.getYarnApplicationState())) {
-      LOG.info("Service {} is already in a terminated state {}", serviceName,
-          report.getYarnApplicationState());
-      cleanUpRegistry(serviceName);
-      return EXIT_COMMAND_ARGUMENT_ERROR;
-    }
-    if (preRunningStates.contains(report.getYarnApplicationState())) {
-      String msg = serviceName + " is at " + report.getYarnApplicationState()
-          + ", forcefully killed by user!";
-      yarnClient.killApplication(currentAppId, msg);
-      LOG.info(msg);
-      cleanUpRegistry(serviceName);
-      return EXIT_SUCCESS;
-    }
-    if (StringUtils.isEmpty(report.getHost())) {
-      throw new YarnException(serviceName + " AM hostname is empty");
-    }
-    LOG.info("Stopping service {}, with appId = {}", serviceName, currentAppId);
-    try {
-      ClientAMProtocol proxy =
-          createAMProxy(serviceName, report);
-      cachedAppInfo.remove(serviceName);
-      if (proxy != null) {
-        // try to stop the app gracefully.
-        StopRequestProto request = StopRequestProto.newBuilder().build();
-        proxy.stop(request);
-        LOG.info("Service " + serviceName + " is being gracefully stopped...");
-      } else {
-        yarnClient.killApplication(currentAppId,
-            serviceName + " is forcefully killed by user!");
-        LOG.info("Forcefully kill the service: " + serviceName);
-        cleanUpRegistry(serviceName);
-        return EXIT_SUCCESS;
-      }
-
-      if (!waitForAppStopped) {
-        cleanUpRegistry(serviceName);
-        return EXIT_SUCCESS;
-      }
-      // Wait until the app is killed.
-      long startTime = System.currentTimeMillis();
-      int pollCount = 0;
-      while (true) {
-        Thread.sleep(2000);
-        report = yarnClient.getApplicationReport(currentAppId);
-        if (terminatedStates.contains(report.getYarnApplicationState())) {
-          LOG.info("Service " + serviceName + " is stopped.");
-          break;
-        }
-        // Forcefully kill after 10 seconds.
-        if ((System.currentTimeMillis() - startTime) > 10000) {
-          LOG.info("Stop operation timeout stopping, forcefully kill the app "
-              + serviceName);
-          yarnClient.killApplication(currentAppId,
-              "Forcefully kill the app by user");
-          break;
-        }
-        if (++pollCount % 10 == 0) {
-          LOG.info("Waiting for service " + serviceName + " to be stopped.");
-        }
-      }
-    } catch (IOException | YarnException | InterruptedException e) {
-      LOG.info("Failed to stop " + serviceName + " gracefully due to: "
-          + e.getMessage() + ", forcefully kill the app.");
-      yarnClient.killApplication(currentAppId, "Forcefully kill the app");
-    }
-    cleanUpRegistry(serviceName);
-    return EXIT_SUCCESS;
-  }
-
-  @Override
-  public int actionDestroy(String serviceName) throws YarnException,
-      IOException {
-    ServiceApiUtil.validateNameFormat(serviceName, getConfig());
-    verifyNoLiveAppInRM(serviceName, "destroy");
-
-    Path appDir = fs.buildClusterDirPath(serviceName);
-    FileSystem fileSystem = fs.getFileSystem();
-    // remove from the appId cache
-    cachedAppInfo.remove(serviceName);
-    int ret = EXIT_SUCCESS;
-    if (fileSystem.exists(appDir)) {
-      if (fileSystem.delete(appDir, true)) {
-        LOG.info("Successfully deleted service dir for " + serviceName + ": "
-            + appDir);
-      } else {
-        String message =
-            "Failed to delete service + " + serviceName + " at:  " + appDir;
-        LOG.info(message);
-        throw new YarnException(message);
-      }
-    } else {
-      LOG.info("Service '" + serviceName + "' doesn't exist at hdfs path: "
-          + appDir);
-      ret = EXIT_NOT_FOUND;
-    }
-
-    // Delete Public Resource Dir
-    Path publicResourceDir = new Path(fs.getBasePath(), serviceName);
-    if (fileSystem.exists(publicResourceDir)) {
-      if (fileSystem.delete(publicResourceDir, true)) {
-        LOG.info("Successfully deleted public resource dir for "
-            + serviceName + ": " + publicResourceDir);
-      } else {
-        String message = "Failed to delete public resource dir for service "
-            + serviceName + " at:  " + publicResourceDir;
-        LOG.info(message);
-        throw new YarnException(message);
-      }
-    }
-
-    try {
-      deleteZKNode(serviceName);
-      // don't set destroySucceed to false if no ZK node exists because not
-      // all services use a ZK node
-    } catch (Exception e) {
-      throw new IOException("Could not delete zk node for " + serviceName, e);
-    }
-    if (!cleanUpRegistry(serviceName)) {
-      if (ret == EXIT_SUCCESS) {
-        ret = EXIT_OTHER_FAILURE;
-      }
-    }
-    if (ret == EXIT_SUCCESS) {
-      LOG.info("Successfully destroyed service {}", serviceName);
-      return ret;
-    } else if (ret == EXIT_NOT_FOUND) {
-      LOG.error("Error on destroy '" + serviceName + "': not found.");
-      return ret;
-    } else {
-      LOG.error("Error on destroy '" + serviceName + "': error cleaning up " +
-          "registry.");
-      return ret;
-    }
-  }
-
-  private boolean cleanUpRegistry(String serviceName, String user) throws
-      SliderException {
-    String encodedName = RegistryUtils.registryUser(user);
-
-    String registryPath = RegistryUtils.servicePath(encodedName,
-        YarnServiceConstants.APP_TYPE, serviceName);
-    return cleanUpRegistryPath(registryPath, serviceName);
-  }
-
-  private boolean cleanUpRegistry(String serviceName) throws SliderException {
-    String registryPath =
-        ServiceRegistryUtils.registryPathForInstance(serviceName);
-    return cleanUpRegistryPath(registryPath, serviceName);
-  }
-
-  private boolean cleanUpRegistryPath(String registryPath, String
-      serviceName) throws SliderException {
-    try {
-      if (getRegistryClient().exists(registryPath)) {
-        getRegistryClient().delete(registryPath, true);
-      } else {
-        LOG.info(
-            "Service '" + serviceName + "' doesn't exist at ZK registry path: "
-                + registryPath);
-        // not counted as a failure if the registry entries don't exist
-      }
-    } catch (IOException e) {
-      LOG.warn("Error deleting registry entry {}", registryPath, e);
-      return false;
-    }
-    return true;
-  }
-
-  private synchronized RegistryOperations getRegistryClient()
-      throws SliderException, IOException {
-
-    if (registryClient == null) {
-      registryClient =
-          RegistryOperationsFactory.createInstance("ServiceClient", getConfig());
-      registryClient.init(getConfig());
-      registryClient.start();
-    }
-    return registryClient;
-  }
-
-  /**
-   * Delete service's ZK node. This is a different node from the service's
-   * registry entry and is set aside for the service to use for its own ZK data.
-   *
-   * @param serviceName service name
-   * @return true if the node was deleted, false if the node doesn't exist
-   * @throws Exception if the node couldn't be deleted
-   */
-  private boolean deleteZKNode(String serviceName) throws Exception {
-    CuratorFramework curatorFramework = getCuratorClient();
-    String user = RegistryUtils.currentUser();
-    String zkPath = ServiceRegistryUtils.mkServiceHomePath(user, serviceName);
-    if (curatorFramework.checkExists().forPath(zkPath) != null) {
-      curatorFramework.delete().deletingChildrenIfNeeded().forPath(zkPath);
-      LOG.info("Deleted zookeeper path: " + zkPath);
-      return true;
-    } else {
-      LOG.info(
-          "Service '" + serviceName + "' doesn't exist at ZK path: " + zkPath);
-      return false;
-    }
-  }
-
-  private synchronized CuratorFramework getCuratorClient()
-      throws BadConfigException {
-    String registryQuorum =
-        getConfig().get(RegistryConstants.KEY_REGISTRY_ZK_QUORUM);
-
-    // though if neither is set: trouble
-    if (ServiceUtils.isUnset(registryQuorum)) {
-      throw new BadConfigException(
-          "No Zookeeper quorum provided in the" + " configuration property "
-              + RegistryConstants.KEY_REGISTRY_ZK_QUORUM);
-    }
-    ZookeeperUtils.splitToHostsAndPortsStrictly(registryQuorum);
-
-    if (curatorClient == null) {
-      curatorClient =
-          CuratorFrameworkFactory.builder().connectString(registryQuorum)
-              .sessionTimeoutMs(10000).retryPolicy(new RetryNTimes(5, 2000))
-              .build();
-      curatorClient.start();
-    }
-    return curatorClient;
-  }
-
-  private void verifyNoLiveAppInRM(String serviceName, String action)
-      throws IOException, YarnException {
-    Set<String> types = new HashSet<>(1);
-    types.add(YarnServiceConstants.APP_TYPE);
-    Set<String> tags = null;
-    if (serviceName != null) {
-      tags = Collections.singleton(ServiceUtils.createNameTag(serviceName));
-    }
-    GetApplicationsRequest request = GetApplicationsRequest.newInstance();
-    request.setApplicationTypes(types);
-    request.setApplicationTags(tags);
-    request.setApplicationStates(liveStates);
-    String user = UserGroupInformation.getCurrentUser().getUserName();
-    if (user != null) {
-      request.setUsers(Collections.singleton(user));
-    }
-    List<ApplicationReport> reports = yarnClient.getApplications(request);
-    if (!reports.isEmpty()) {
-      String message = "";
-      if (action.equals("destroy")) {
-        message = "Failed to destroy service " + serviceName
-            + ", because it is still running.";
-      } else {
-        message = "Failed to " + action + " service " + serviceName
-            + ", because it already exists.";
-      }
-      throw new YarnException(message);
-    }
-  }
-
-  @VisibleForTesting
-  ApplicationId submitApp(Service app) throws IOException, YarnException {
-    String serviceName = app.getName();
-    Configuration conf = getConfig();
-    Path appRootDir = fs.buildClusterDirPath(app.getName());
-
-    YarnClientApplication yarnApp = yarnClient.createApplication();
-    ApplicationSubmissionContext submissionContext =
-        yarnApp.getApplicationSubmissionContext();
-    ServiceApiUtil.validateCompResourceSize(
-        yarnApp.getNewApplicationResponse().getMaximumResourceCapability(),
-        app);
-
-    submissionContext.setKeepContainersAcrossApplicationAttempts(true);
-    if (app.getLifetime() > 0) {
-      Map<ApplicationTimeoutType, Long> appTimeout = new HashMap<>();
-      appTimeout.put(ApplicationTimeoutType.LIFETIME, app.getLifetime());
-      submissionContext.setApplicationTimeouts(appTimeout);
-    }
-    submissionContext.setMaxAppAttempts(YarnServiceConf
-        .getInt(YarnServiceConf.AM_RESTART_MAX, DEFAULT_AM_RESTART_MAX, app
-            .getConfiguration(), conf));
-    submissionContext.setAttemptFailuresValidityInterval(YarnServiceConf
-        .getLong(YarnServiceConf.AM_FAILURES_VALIDITY_INTERVAL,
-            DEFAULT_AM_FAILURES_VALIDITY_INTERVAL, app.getConfiguration(),
-            conf));
-
-    setLogAggregationContext(app, conf, submissionContext);
-
-    Map<String, LocalResource> localResources = new HashMap<>();
-
-    // copy local slideram-log4j.properties to hdfs and add to localResources
-    boolean hasAMLog4j =
-        addAMLog4jResource(serviceName, conf, localResources);
-    // copy jars to hdfs and add to localResources
-    addJarResource(serviceName, localResources);
-    // add keytab if in secure env
-    addKeytabResourceIfSecure(fs, localResources, app);
-    // add yarn sysfs to localResources
-    addYarnSysFs(appRootDir, localResources, app);
-    if (LOG.isDebugEnabled()) {
-      printLocalResources(localResources);
-    }
-    Map<String, String> env = addAMEnv();
-
-    // create AM CLI
-    String cmdStr = buildCommandLine(app, conf, appRootDir, hasAMLog4j);
-    submissionContext.setResource(Resource.newInstance(YarnServiceConf
-        .getLong(YarnServiceConf.AM_RESOURCE_MEM,
-            YarnServiceConf.DEFAULT_KEY_AM_RESOURCE_MEM,
-            app.getConfiguration(), conf), 1));
-    String queue = app.getQueue();
-    if (StringUtils.isEmpty(queue)) {
-      queue = conf.get(YARN_QUEUE, DEFAULT_YARN_QUEUE);
-    }
-    submissionContext.setQueue(queue);
-    submissionContext.setApplicationName(serviceName);
-    submissionContext.setApplicationType(YarnServiceConstants.APP_TYPE);
-    Set<String> appTags =
-        AbstractClientProvider.createApplicationTags(serviceName, null, null);
-    if (!appTags.isEmpty()) {
-      submissionContext.setApplicationTags(appTags);
-    }
-    ContainerLaunchContext amLaunchContext =
-        Records.newRecord(ContainerLaunchContext.class);
-    amLaunchContext.setCommands(Collections.singletonList(cmdStr));
-    amLaunchContext.setEnvironment(env);
-    amLaunchContext.setLocalResources(localResources);
-    addCredentials(amLaunchContext, app);
-    submissionContext.setAMContainerSpec(amLaunchContext);
-    yarnClient.submitApplication(submissionContext);
-    return submissionContext.getApplicationId();
-  }
-
-  /**
-   * Compress (tar) the input files to the output file.
-   *
-   * @param files The files to compress
-   * @param output The resulting output file (should end in .tar.gz)
-   * @param bundleRoot
-   * @throws IOException
-   */
-  public static File compressFiles(Collection<File> files, File output,
-      String bundleRoot) throws IOException {
-    try (FileOutputStream fos = new FileOutputStream(output);
-        TarArchiveOutputStream taos = new TarArchiveOutputStream(
-            new BufferedOutputStream(fos))) {
-      taos.setLongFileMode(TarArchiveOutputStream.LONGFILE_GNU);
-      for (File f : files) {
-        addFilesToCompression(taos, f, "sysfs", bundleRoot);
-      }
-    }
-    return output;
-  }
-
-  /**
-   * Compile file list for compression and going recursive for
-   * nested directories.
-   *
-   * @param taos The archive
-   * @param file The file to add to the archive
-   * @param dir The directory that should serve as
-   *            the parent directory in the archive
-   * @throws IOException
-   */
-  private static void addFilesToCompression(TarArchiveOutputStream taos,
-      File file, String dir, String bundleRoot) throws IOException {
-    if (!file.isHidden()) {
-      // Create an entry for the file
-      if (!dir.equals(".")) {
-        if (File.separator.equals("\\")) {
-          dir = dir.replaceAll("\\\\", "/");
-        }
-      }
-      taos.putArchiveEntry(
-          new TarArchiveEntry(file, dir + "/" + file.getName()));
-      if (file.isFile()) {
-        // Add the file to the archive
-        try (FileInputStream input = new FileInputStream(file)) {
-          IOUtils.copy(input, taos);
-          taos.closeArchiveEntry();
-        }
-      } else if (file.isDirectory()) {
-        // close the archive entry
-        if (!dir.equals(".")) {
-          taos.closeArchiveEntry();
-        }
-        // go through all the files in the directory and using recursion, add
-        // them to the archive
-        File[] allFiles = file.listFiles();
-        if (allFiles != null) {
-          for (File childFile : allFiles) {
-            addFilesToCompression(taos, childFile,
-                file.getPath().substring(bundleRoot.length()), bundleRoot);
-          }
-        }
-      }
-    }
-  }
-
-  private void addYarnSysFs(Path path,
-      Map<String, LocalResource> localResources, Service app)
-          throws IOException {
-    List<Component> componentsWithYarnSysFS = new ArrayList<Component>();
-    for(Component c : app.getComponents()) {
-      boolean enabled = Boolean.parseBoolean(c.getConfiguration()
-          .getEnv(ApplicationConstants.Environment
-              .YARN_CONTAINER_RUNTIME_YARN_SYSFS_ENABLE.name()));
-      if (enabled) {
-        componentsWithYarnSysFS.add(c);
-      }
-    }
-    if(componentsWithYarnSysFS.size() == 0) {
-      return;
-    }
-    String buffer = ServiceApiUtil.jsonSerDeser.toJson(app);
-    File testDir =
-        new File(System.getProperty("java.io.tmpdir"));
-    File tmpDir = Files.createTempDirectory(
-        testDir.toPath(), System.currentTimeMillis() + "-").toFile();
-    if (tmpDir.exists()) {
-      String serviceJsonPath = tmpDir.getAbsolutePath() + "/app.json";
-      File localFile = new File(serviceJsonPath);
-      if (localFile.createNewFile()) {
-        try (Writer writer = new OutputStreamWriter(
-            new FileOutputStream(localFile), StandardCharsets.UTF_8)) {
-          writer.write(buffer);
-        }
-      } else {
-        throw new IOException("Fail to write app.json to temp directory");
-      }
-      File destinationFile = new File(tmpDir.getAbsolutePath() + "/sysfs.tar");
-      if (!destinationFile.createNewFile()) {
-        throw new IOException("Fail to localize sysfs.tar.");
-      }
-      List<File> files = new ArrayList<File>();
-      files.add(localFile);
-      compressFiles(files, destinationFile, "sysfs");
-      LocalResource localResource =
-          fs.submitFile(destinationFile, path, ".", "sysfs.tar");
-      Path serviceJson = new Path(path, "sysfs.tar");
-      for (Component c  : componentsWithYarnSysFS) {
-        ConfigFile e = new ConfigFile();
-        e.type(TypeEnum.ARCHIVE);
-        e.srcFile(serviceJson.toString());
-        e.destFile("/hadoop/yarn");
-        if (!c.getConfiguration().getFiles().contains(e)) {
-          c.getConfiguration().getFiles().add(e);
-        }
-      }
-      localResources.put("sysfs", localResource);
-      if (!tmpDir.delete()) {
-        LOG.warn("Failed to delete temp file: " + tmpDir.getAbsolutePath());
-      }
-    } else {
-      throw new IOException("Fail to localize sysfs resource.");
-    }
-  }
-
-  private void setLogAggregationContext(Service app, Configuration conf,
-      ApplicationSubmissionContext submissionContext) {
-    LogAggregationContext context = Records.newRecord(LogAggregationContext
-        .class);
-    String finalLogInclude = YarnServiceConf.get
-        (FINAL_LOG_INCLUSION_PATTERN, null, app.getConfiguration(), conf);
-    if (!StringUtils.isEmpty(finalLogInclude)) {
-      context.setIncludePattern(finalLogInclude);
-    }
-    String finalLogExclude = YarnServiceConf.get
-        (FINAL_LOG_EXCLUSION_PATTERN, null, app.getConfiguration(), conf);
-    if (!StringUtils.isEmpty(finalLogExclude)) {
-      context.setExcludePattern(finalLogExclude);
-    }
-    String rollingLogInclude = YarnServiceConf.get
-        (ROLLING_LOG_INCLUSION_PATTERN, null, app.getConfiguration(), conf);
-    if (!StringUtils.isEmpty(rollingLogInclude)) {
-      context.setRolledLogsIncludePattern(rollingLogInclude);
-    }
-    String rollingLogExclude = YarnServiceConf.get
-        (ROLLING_LOG_EXCLUSION_PATTERN, null, app.getConfiguration(), conf);
-    if (!StringUtils.isEmpty(rollingLogExclude)) {
-      context.setRolledLogsExcludePattern(rollingLogExclude);
-    }
-    submissionContext.setLogAggregationContext(context);
-  }
-
-  private void printLocalResources(Map<String, LocalResource> map) {
-    LOG.debug("Added LocalResource for localization: ");
-    StringBuilder builder = new StringBuilder();
-    for (Map.Entry<String, LocalResource> entry : map.entrySet()) {
-      builder.append(entry.getKey()).append(" -> ")
-          .append(entry.getValue().getResource().getFile())
-          .append(System.lineSeparator());
-    }
-    LOG.debug("{}", builder);
-  }
-
-  private String buildCommandLine(Service app, Configuration conf,
-      Path appRootDir, boolean hasSliderAMLog4j) throws BadConfigException {
-    JavaCommandLineBuilder CLI = new JavaCommandLineBuilder();
-    CLI.forceIPv4().headless();
-    String jvmOpts = YarnServiceConf
-        .get(YarnServiceConf.JVM_OPTS, "", app.getConfiguration(), conf);
-    if (!jvmOpts.contains("-Xmx")) {
-      jvmOpts += DEFAULT_AM_JVM_XMX;
-    }
-
-    // validate possible command injection.
-    ServiceApiUtil.validateJvmOpts(jvmOpts);
-
-    CLI.setJVMOpts(jvmOpts);
-    if (hasSliderAMLog4j) {
-      CLI.sysprop(SYSPROP_LOG4J_CONFIGURATION, YARN_SERVICE_LOG4J_FILENAME);
-      CLI.sysprop(SYSPROP_LOG_DIR, ApplicationConstants.LOG_DIR_EXPANSION_VAR);
-    }
-    CLI.add(ServiceMaster.class.getCanonicalName());
-    //TODO debugAM CLI.add(Arguments.ARG_DEBUG)
-    CLI.add("-" + ServiceMaster.YARNFILE_OPTION, new Path(appRootDir,
-        app.getName() + ".json"));
-    CLI.add("-" + ServiceMaster.SERVICE_NAME_OPTION, app.getName());
-    if (app.getKerberosPrincipal() != null) {
-      if (!StringUtils.isEmpty(app.getKerberosPrincipal().getKeytab())) {
-        CLI.add("-" + ServiceMaster.KEYTAB_OPTION,
-            app.getKerberosPrincipal().getKeytab());
-      }
-      if (!StringUtils.isEmpty(app.getKerberosPrincipal().getPrincipalName())) {
-        CLI.add("-" + ServiceMaster.PRINCIPAL_NAME_OPTION,
-            app.getKerberosPrincipal().getPrincipalName());
-      }
-    }
-    // pass the registry binding
-    CLI.addConfOptionToCLI(conf, RegistryConstants.KEY_REGISTRY_ZK_ROOT,
-        RegistryConstants.DEFAULT_ZK_REGISTRY_ROOT);
-    CLI.addMandatoryConfOption(conf, RegistryConstants.KEY_REGISTRY_ZK_QUORUM);
-
-    // write out the path output
-    CLI.addOutAndErrFiles(STDOUT_AM, STDERR_AM);
-    String cmdStr = CLI.build();
-    LOG.debug("AM launch command: {}", cmdStr);
-    return cmdStr;
-  }
-
-  @VisibleForTesting
-  protected Map<String, String> addAMEnv() throws IOException {
-    Map<String, String> env = new HashMap<>();
-    ClasspathConstructor classpath = buildClasspath(
-        YarnServiceConstants.SUBMITTED_CONF_DIR,
-        "lib",
-        fs,
-        getConfig().get(YarnServiceConf.YARN_SERVICE_CLASSPATH, ""),
-        getConfig().getBoolean(YarnConfiguration.IS_MINI_YARN_CLUSTER, false));
-    env.put("CLASSPATH", classpath.buildClasspath());
-    env.put("LANG", "en_US.UTF-8");
-    env.put("LC_ALL", "en_US.UTF-8");
-    env.put("LANGUAGE", "en_US.UTF-8");
-    String jaas = System.getenv("HADOOP_JAAS_DEBUG");
-    if (jaas != null) {
-      env.put("HADOOP_JAAS_DEBUG", jaas);
-    }
-    if (!UserGroupInformation.isSecurityEnabled()) {
-      String userName = UserGroupInformation.getCurrentUser().getUserName();
-      LOG.debug("Run as user {}", userName);
-      // HADOOP_USER_NAME env is used by UserGroupInformation when log in
-      // This env makes AM run as this user
-      env.put("HADOOP_USER_NAME", userName);
-    }
-    LOG.debug("AM env: \n{}", stringifyMap(env));
-    return env;
-  }
-
-  protected Path addJarResource(String serviceName,
-      Map<String, LocalResource> localResources)
-      throws IOException, YarnException {
-    Path libPath = fs.buildClusterDirPath(serviceName);
-    ProviderUtils
-        .addProviderJar(localResources, ServiceMaster.class, SERVICE_CORE_JAR, fs,
-            libPath, "lib", false);
-    Path dependencyLibTarGzip = fs.getDependencyTarGzip();
-    if (actionDependency(null, false) == EXIT_SUCCESS) {
-      LOG.info("Loading lib tar from " + dependencyLibTarGzip);
-      fs.submitTarGzipAndUpdate(localResources);
-    } else {
-      if (dependencyLibTarGzip != null) {
-        LOG.warn("Property {} has a value {}, but is not a valid file",
-            YarnServiceConf.DEPENDENCY_TARBALL_PATH, dependencyLibTarGzip);
-      }
-      String[] libs = ServiceUtils.getLibDirs();
-      LOG.info("Uploading all dependency jars to HDFS. For faster submission of"
-          + " apps, set config property {} to the dependency tarball location."
-          + " Dependency tarball can be uploaded to any HDFS path directly"
-          + " or by using command: yarn app -{} [<Destination Folder>]",
-          YarnServiceConf.DEPENDENCY_TARBALL_PATH,
-          ApplicationCLI.ENABLE_FAST_LAUNCH);
-      for (String libDirProp : libs) {
-        ProviderUtils.addAllDependencyJars(localResources, fs, libPath, "lib",
-            libDirProp);
-      }
-    }
-    return libPath;
-  }
-
-  private boolean addAMLog4jResource(String serviceName, Configuration conf,
-      Map<String, LocalResource> localResources)
-      throws IOException, BadClusterStateException {
-    boolean hasAMLog4j = false;
-    String hadoopConfDir =
-        System.getenv(ApplicationConstants.Environment.HADOOP_CONF_DIR.name());
-    if (hadoopConfDir != null) {
-      File localFile =
-          new File(hadoopConfDir, YarnServiceConstants.YARN_SERVICE_LOG4J_FILENAME);
-      if (localFile.exists()) {
-        Path localFilePath = createLocalPath(localFile);
-        Path appDirPath = fs.buildClusterDirPath(serviceName);
-        Path remoteConfPath =
-            new Path(appDirPath, YarnServiceConstants.SUBMITTED_CONF_DIR);
-        Path remoteFilePath =
-            new Path(remoteConfPath, YarnServiceConstants.YARN_SERVICE_LOG4J_FILENAME);
-        copy(conf, localFilePath, remoteFilePath);
-        LocalResource localResource =
-            fs.createAmResource(remoteConfPath, LocalResourceType.FILE,
-            LocalResourceVisibility.APPLICATION);
-        localResources.put(localFilePath.getName(), localResource);
-        hasAMLog4j = true;
-      } else {
-        LOG.warn("AM log4j property file doesn't exist: " + localFile);
-      }
-    }
-    return hasAMLog4j;
-  }
-
-  @Override
-  public int actionStart(String serviceName) throws YarnException, IOException {
-    actionStartAndGetId(serviceName);
-    return EXIT_SUCCESS;
-  }
-
-  public ApplicationId actionStartAndGetId(String serviceName) throws
-      YarnException, IOException {
-    ServiceApiUtil.validateNameFormat(serviceName, getConfig());
-    Service liveService = getStatus(serviceName);
-    if (liveService == null ||
-        !liveService.getState().equals(ServiceState.UPGRADING)) {
-      Path appDir = checkAppExistOnHdfs(serviceName);
-      Service service = ServiceApiUtil.loadService(fs, serviceName);
-      ServiceApiUtil.validateAndResolveService(service, fs, getConfig());
-      // see if it is actually running and bail out;
-      verifyNoLiveAppInRM(serviceName, "start");
-      ApplicationId appId;
-      try {
-        appId = submitApp(service);
-      } catch (YarnException e) {
-        actionDestroy(serviceName);
-        throw e;
-      }
-      cachedAppInfo.put(serviceName, new AppInfo(appId, service
-          .getKerberosPrincipal().getPrincipalName()));
-      service.setId(appId.toString());
-      // write app definition on to hdfs
-      Path appJson = ServiceApiUtil.writeAppDefinition(fs, appDir, service);
-      LOG.info("Persisted service " + service.getName() + " at " + appJson);
-      return appId;
-    } else {
-      LOG.info("Finalize service {} upgrade", serviceName);
-      ApplicationId appId = getAppId(serviceName);
-      ApplicationReport appReport = yarnClient.getApplicationReport(appId);
-      if (StringUtils.isEmpty(appReport.getHost())) {
-        throw new YarnException(serviceName + " AM hostname is empty");
-      }
-      ClientAMProtocol proxy = createAMProxy(serviceName, appReport);
-
-      RestartServiceRequestProto.Builder requestBuilder =
-          RestartServiceRequestProto.newBuilder();
-      proxy.restart(requestBuilder.build());
-      return appId;
-    }
-  }
-
-  /**
-   * Verifies that the service definition does not exist on hdfs.
-   *
-   * @param service   service
-   * @param isUpgrade true for upgrades; false otherwise
-   * @return path to the service definition..
-   * @throws IOException
-   * @throws SliderException
-   */
-  private Path checkAppNotExistOnHdfs(Service service, boolean isUpgrade)
-      throws IOException, SliderException {
-    Path appDir = !isUpgrade ? fs.buildClusterDirPath(service.getName()) :
-        fs.buildClusterUpgradeDirPath(service.getName(), service.getVersion());
-    fs.verifyDirectoryNonexistent(
-        new Path(appDir, service.getName() + ".json"));
-    return appDir;
-  }
-
-  /**
-   * Verifies that the service exists on hdfs.
-   * @param serviceName service name
-   * @return path to the service definition.
-   * @throws IOException
-   * @throws SliderException
-   */
-  private Path checkAppExistOnHdfs(String serviceName)
-      throws IOException, SliderException {
-    Path appDir = fs.buildClusterDirPath(serviceName);
-    fs.verifyPathExists(new Path(appDir, serviceName + ".json"));
-    return appDir;
-  }
-
-  private void addCredentials(ContainerLaunchContext amContext, Service app)
-      throws IOException {
-    Credentials allCreds = new Credentials();
-    // HDFS DT
-    if (UserGroupInformation.isSecurityEnabled()) {
-      String tokenRenewer = YarnClientUtils.getRmPrincipal(getConfig());
-      if (StringUtils.isEmpty(tokenRenewer)) {
-        throw new IOException(
-            "Can't get Master Kerberos principal for the RM to use as renewer");
-      }
-      final org.apache.hadoop.security.token.Token<?>[] tokens =
-          fs.getFileSystem().addDelegationTokens(tokenRenewer, allCreds);
-      if (LOG.isDebugEnabled()) {
-        if (tokens != null && tokens.length != 0) {
-          for (Token<?> token : tokens) {
-            LOG.debug("Got DT: {}", token);
-          }
-        }
-      }
-    }
-
-    if (!StringUtils.isEmpty(app.getDockerClientConfig())) {
-      allCreds.addAll(DockerClientConfigHandler.readCredentialsFromConfigFile(
-          new Path(app.getDockerClientConfig()), getConfig(), app.getName()));
-    }
-
-    if (allCreds.numberOfTokens() > 0) {
-      DataOutputBuffer dob = new DataOutputBuffer();
-      allCreds.writeTokenStorageToStream(dob);
-      ByteBuffer tokens = ByteBuffer.wrap(dob.getData(), 0, dob.getLength());
-      amContext.setTokens(tokens);
-    }
-  }
-
-  private void addKeytabResourceIfSecure(SliderFileSystem fileSystem,
-      Map<String, LocalResource> localResource, Service service)
-      throws IOException, YarnException {
-    if (!UserGroupInformation.isSecurityEnabled()) {
-      return;
-    }
-    String principalName = service.getKerberosPrincipal().getPrincipalName();
-    if (StringUtils.isEmpty(principalName)) {
-      LOG.warn("No Kerberos principal name specified for " + service.getName());
-      return;
-    }
-    if (StringUtils.isEmpty(service.getKerberosPrincipal().getKeytab())) {
-      LOG.warn("No Kerberos keytab specified for " + service.getName());
-      return;
-    }
-
-    URI keytabURI;
-    try {
-      keytabURI = new URI(service.getKerberosPrincipal().getKeytab());
-    } catch (URISyntaxException e) {
-      throw new YarnException(e);
-    }
-
-    if ("file".equals(keytabURI.getScheme())) {
-      LOG.info("Using a keytab from localhost: " + keytabURI);
-    } else {
-      Path keytabPath = new Path(keytabURI);
-      if (!fileSystem.getFileSystem().exists(keytabPath)) {
-        LOG.warn(service.getName() + "'s keytab (principalName = "
-            + principalName + ") doesn't exist at: " + keytabPath);
-        return;
-      }
-      LocalResource keytabRes = fileSystem.createAmResource(keytabPath,
-          LocalResourceType.FILE, LocalResourceVisibility.PRIVATE);
-      localResource.put(String.format(YarnServiceConstants.KEYTAB_LOCATION,
-          service.getName()), keytabRes);
-      LOG.info("Adding " + service.getName() + "'s keytab for "
-          + "localization, uri = " + keytabPath);
-    }
-  }
-
-  public String updateLifetime(String serviceName, long lifetime)
-      throws YarnException, IOException {
-    ApplicationId currentAppId = getAppId(serviceName);
-    if (currentAppId == null) {
-      throw new YarnException("Application ID not found for " + serviceName);
-    }
-    ApplicationReport report = yarnClient.getApplicationReport(currentAppId);
-    if (report == null) {
-      throw new YarnException("Service not found for " + serviceName);
-    }
-    ApplicationId appId = report.getApplicationId();
-    LOG.info("Updating lifetime of an service: serviceName = " + serviceName
-        + ", appId = " + appId + ", lifetime = " + lifetime);
-    Map<ApplicationTimeoutType, String> map = new HashMap<>();
-    String newTimeout =
-        Times.formatISO8601(System.currentTimeMillis() + lifetime * 1000);
-    map.put(ApplicationTimeoutType.LIFETIME, newTimeout);
-    UpdateApplicationTimeoutsRequest request =
-        UpdateApplicationTimeoutsRequest.newInstance(appId, map);
-    yarnClient.updateApplicationTimeouts(request);
-    LOG.info(
-        "Successfully updated lifetime for an service: serviceName = " + serviceName
-            + ", appId = " + appId + ". New expiry time in ISO8601 format is "
-            + newTimeout);
-    return newTimeout;
-  }
-
-  public ServiceState convertState(YarnApplicationState state) {
-    switch (state) {
-    case NEW:
-    case NEW_SAVING:
-    case SUBMITTED:
-    case ACCEPTED:
-      return ServiceState.ACCEPTED;
-    case RUNNING:
-      return ServiceState.STARTED;
-    case FINISHED:
-    case KILLED:
-      return ServiceState.STOPPED;
-    case FAILED:
-      return ServiceState.FAILED;
-    default:
-      return ServiceState.ACCEPTED;
-    }
-  }
-
-  @Override
-  public String getStatusString(String appIdOrName)
-      throws IOException, YarnException {
-    try {
-      // try parsing appIdOrName, if it succeeds, it means it's appId
-      ApplicationId appId = ApplicationId.fromString(appIdOrName);
-      return getStatusByAppId(appId);
-    } catch (IllegalArgumentException e) {
-      // not appId format, it could be appName.
-      Service status = getStatus(appIdOrName);
-      return ServiceApiUtil.jsonSerDeser.toJson(status);
-    }
-  }
-
-  private String getStatusByAppId(ApplicationId appId)
-      throws IOException, YarnException {
-    ApplicationReport appReport =
-        yarnClient.getApplicationReport(appId);
-
-    if (appReport.getYarnApplicationState() != RUNNING) {
-      return "";
-    }
-    if (StringUtils.isEmpty(appReport.getHost())) {
-      return "";
-    }
-    ClientAMProtocol amProxy = createAMProxy(appReport.getName(), appReport);
-    GetStatusResponseProto response =
-        amProxy.getStatus(GetStatusRequestProto.newBuilder().build());
-    return response.getStatus();
-  }
-
-  public Service getStatus(String serviceName)
-      throws IOException, YarnException {
-    ServiceApiUtil.validateNameFormat(serviceName, getConfig());
-    Service appSpec = new Service();
-    appSpec.setName(serviceName);
-    appSpec.setState(ServiceState.STOPPED);
-    ApplicationId currentAppId = getAppId(serviceName);
-    if (currentAppId == null) {
-      LOG.info("Service {} does not have an application ID", serviceName);
-      return appSpec;
-    }
-    appSpec.setId(currentAppId.toString());
-    ApplicationReport appReport = null;
-    try {
-      appReport = yarnClient.getApplicationReport(currentAppId);
-    } catch (ApplicationNotFoundException e) {
-      LOG.info("application ID {} doesn't exist", currentAppId);
-      return appSpec;
-    }
-    if (appReport == null) {
-      LOG.warn("application ID {} is reported as null", currentAppId);
-      return appSpec;
-    }
-    appSpec.setState(convertState(appReport.getYarnApplicationState()));
-    ApplicationTimeout lifetime =
-        appReport.getApplicationTimeouts().get(ApplicationTimeoutType.LIFETIME);
-    if (lifetime != null) {
-      appSpec.setLifetime(lifetime.getRemainingTime());
-    }
-
-    if (appReport.getYarnApplicationState() != RUNNING) {
-      LOG.info("Service {} is at {} state", serviceName,
-          appReport.getYarnApplicationState());
-      return appSpec;
-    }
-    if (StringUtils.isEmpty(appReport.getHost())) {
-      LOG.warn(serviceName + " AM hostname is empty");
-      return appSpec;
-    }
-    ClientAMProtocol amProxy =
-        createAMProxy(serviceName, appReport);
-    GetStatusResponseProto response =
-        amProxy.getStatus(GetStatusRequestProto.newBuilder().build());
-    appSpec = jsonSerDeser.fromJson(response.getStatus());
-    if (lifetime != null) {
-      appSpec.setLifetime(lifetime.getRemainingTime());
-    }
-    return appSpec;
-  }
-
-  public YarnClient getYarnClient() {
-    return this.yarnClient;
-  }
-
-  public int enableFastLaunch(String destinationFolder)
-      throws IOException, YarnException {
-    return actionDependency(destinationFolder, true);
-  }
-
-  public int actionDependency(String destinationFolder, boolean overwrite) {
-    String currentUser = RegistryUtils.currentUser();
-    LOG.info("Running command as user {}", currentUser);
-
-    Path dependencyLibTarGzip;
-    if (destinationFolder == null) {
-      dependencyLibTarGzip = fs.getDependencyTarGzip();
-    } else {
-      dependencyLibTarGzip = new Path(destinationFolder,
-          YarnServiceConstants.DEPENDENCY_TAR_GZ_FILE_NAME
-              + YarnServiceConstants.DEPENDENCY_TAR_GZ_FILE_EXT);
-    }
-
-    // Check if dependency has already been uploaded, in which case log
-    // appropriately and exit success (unless overwrite has been requested)
-    if (fs.isFile(dependencyLibTarGzip) && !overwrite) {
-      System.out.println(String.format(
-          "Dependency libs are already uploaded to %s.", dependencyLibTarGzip
-              .toUri()));
-      return EXIT_SUCCESS;
-    }
-
-    String[] libDirs = ServiceUtils.getLibDirs();
-    if (libDirs.length > 0) {
-      File tempLibTarGzipFile = null;
-      try {
-        if (!checkPermissions(dependencyLibTarGzip)) {
-          return EXIT_UNAUTHORIZED;
-        }
-
-        tempLibTarGzipFile = File.createTempFile(
-            YarnServiceConstants.DEPENDENCY_TAR_GZ_FILE_NAME + "_",
-            YarnServiceConstants.DEPENDENCY_TAR_GZ_FILE_EXT);
-        // copy all jars
-        tarGzipFolder(libDirs, tempLibTarGzipFile, createJarFilter());
-
-        fs.copyLocalFileToHdfs(tempLibTarGzipFile, dependencyLibTarGzip,
-            new FsPermission(YarnServiceConstants.DEPENDENCY_DIR_PERMISSIONS));
-        LOG.info("To let apps use this tarball, in yarn-site set config " +
-                "property {} to {}", YarnServiceConf.DEPENDENCY_TARBALL_PATH,
-            dependencyLibTarGzip);
-        return EXIT_SUCCESS;
-      } catch (IOException e) {
-        LOG.error("Got exception creating tarball and uploading to HDFS", e);
-        return EXIT_EXCEPTION_THROWN;
-      } finally {
-        if (tempLibTarGzipFile != null) {
-          if (!tempLibTarGzipFile.delete()) {
-            LOG.warn("Failed to delete tmp file {}", tempLibTarGzipFile);
-          }
-        }
-      }
-    } else {
-      return EXIT_FALSE;
-    }
-  }
-
-  private boolean checkPermissions(Path dependencyLibTarGzip) throws
-      IOException {
-    AccessControlList yarnAdminAcl = new AccessControlList(getConfig().get(
-        YarnConfiguration.YARN_ADMIN_ACL,
-        YarnConfiguration.DEFAULT_YARN_ADMIN_ACL));
-    AccessControlList dfsAdminAcl = new AccessControlList(
-        getConfig().get(DFSConfigKeys.DFS_ADMIN, " "));
-    UserGroupInformation ugi = UserGroupInformation.getCurrentUser();
-    if (!yarnAdminAcl.isUserAllowed(ugi) && !dfsAdminAcl.isUserAllowed(ugi)) {
-      LOG.error("User must be on the {} or {} list to have permission to " +
-          "upload AM dependency tarball", YarnConfiguration.YARN_ADMIN_ACL,
-          DFSConfigKeys.DFS_ADMIN);
-      return false;
-    }
-
-    Path parent = dependencyLibTarGzip.getParent();
-    while (parent != null) {
-      if (fs.getFileSystem().exists(parent)) {
-        FsPermission perm = fs.getFileSystem().getFileStatus(parent)
-            .getPermission();
-        if (!perm.getOtherAction().implies(FsAction.READ_EXECUTE)) {
-          LOG.error("Parent directory {} of {} tarball location {} does not " +
-              "have world read/execute permission", parent, YarnServiceConf
-              .DEPENDENCY_TARBALL_PATH, dependencyLibTarGzip);
-          return false;
-        }
-      }
-      parent = parent.getParent();
-    }
-    return true;
-  }
-
-  protected ClientAMProtocol createAMProxy(String serviceName,
-      ApplicationReport appReport) throws IOException, YarnException {
-
-    if (UserGroupInformation.isSecurityEnabled()) {
-      if (!cachedAppInfo.containsKey(serviceName)) {
-        Service persistedService  = ServiceApiUtil.loadService(fs, serviceName);
-        cachedAppInfo.put(serviceName, new AppInfo(appReport.getApplicationId(),
-            persistedService.getKerberosPrincipal().getPrincipalName()));
-      }
-      String principalName = cachedAppInfo.get(serviceName).principalName;
-      // Inject the principal into hadoop conf, because Hadoop
-      // SaslRpcClient#getServerPrincipal requires a config for the
-      // principal
-      if (!StringUtils.isEmpty(principalName)) {
-        getConfig().set(PRINCIPAL, principalName);
-      } else {
-        throw new YarnException("No principal specified in the persisted " +
-            "service definition, fail to connect to AM.");
-      }
-    }
-    InetSocketAddress address =
-        NetUtils.createSocketAddrForHost(appReport.getHost(), appReport
-            .getRpcPort());
-    return ClientAMProxy.createProxy(getConfig(), ClientAMProtocol.class,
-        UserGroupInformation.getCurrentUser(), rpc, address);
-  }
-
-  @VisibleForTesting
-  void setFileSystem(SliderFileSystem fileSystem)
-      throws IOException {
-    this.fs = fileSystem;
-  }
-
-  @VisibleForTesting
-  void setYarnClient(YarnClient yarnClient) {
-    this.yarnClient = yarnClient;
-  }
-
-  public synchronized ApplicationId getAppId(String serviceName)
-      throws IOException, YarnException {
-    if (cachedAppInfo.containsKey(serviceName)) {
-      return cachedAppInfo.get(serviceName).appId;
-    }
-    Service persistedService = ServiceApiUtil.loadService(fs, serviceName);
-    if (persistedService == null) {
-      throw new YarnException("Service " + serviceName
-          + " doesn't exist on hdfs. Please check if the app exists in RM");
-    }
-    if (persistedService.getId() == null) {
-      return null;
-    }
-    ApplicationId currentAppId = ApplicationId.fromString(persistedService
-        .getId());
-    cachedAppInfo.put(serviceName, new AppInfo(currentAppId, persistedService
-        .getKerberosPrincipal().getPrincipalName()));
-    return currentAppId;
-  }
-
-  private static class AppInfo {
-    ApplicationId appId;
-    String principalName;
-
-    AppInfo(ApplicationId appId, String principalName) {
-      this.appId = appId;
-      this.principalName = principalName;
-    }
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/AlwaysRestartPolicy.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/AlwaysRestartPolicy.java
deleted file mode 100644
index 505120d8c25..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/AlwaysRestartPolicy.java
+++ /dev/null
@@ -1,87 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.component;
-
-import org.apache.hadoop.yarn.api.records.ContainerStatus;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-
-/**
- * Always restart policy allows for restarts for long live components which
- * never terminate.
- */
-public final class AlwaysRestartPolicy implements ComponentRestartPolicy {
-
-  private static AlwaysRestartPolicy INSTANCE = new AlwaysRestartPolicy();
-
-  private AlwaysRestartPolicy() {
-  }
-
-  public static AlwaysRestartPolicy getInstance() {
-    return INSTANCE;
-  }
-
-  @Override public boolean isLongLived() {
-    return true;
-  }
-
-  /**
-   * This is always false since these components never terminate
-   *
-   * @param component
-   * @return
-   */
-  @Override public boolean hasCompleted(Component component) {
-    return false;
-  }
-
-  /**
-   * This is always false since these components never terminate
-   *
-   * @param component
-   * @return
-   */
-  @Override public boolean hasCompletedSuccessfully(Component component) {
-    return false;
-  }
-
-  @Override public boolean shouldRelaunchInstance(
-      ComponentInstance componentInstance, ContainerStatus containerStatus) {
-    return true;
-  }
-
-  @Override public boolean isReadyForDownStream(Component dependentComponent) {
-    if (dependentComponent.getNumReadyInstances() < dependentComponent
-        .getNumDesiredInstances()) {
-      return false;
-    }
-    return true;
-  }
-
-  @Override public boolean allowUpgrades() {
-    return true;
-  }
-
-  @Override public boolean shouldTerminate(Component component) {
-    return false;
-  }
-
-  @Override public boolean allowContainerRetriesForInstance(
-      ComponentInstance componentInstance) {
-    return true;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/Component.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/Component.java
deleted file mode 100644
index 4e9932a9e28..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/Component.java
+++ /dev/null
@@ -1,1310 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.component;
-
-import org.apache.hadoop.classification.VisibleForTesting;
-import org.apache.hadoop.util.Preconditions;
-import org.apache.hadoop.yarn.api.records.Container;
-import org.apache.hadoop.yarn.api.records.ContainerStatus;
-import org.apache.hadoop.yarn.api.records.ExecutionType;
-import static org.apache.hadoop.yarn.service.api.records.Component
-    .RestartPolicyEnum;
-import org.apache.hadoop.yarn.api.records.ExecutionTypeRequest;
-import org.apache.hadoop.yarn.api.records.NodeAttributeOpCode;
-import org.apache.hadoop.yarn.api.records.Priority;
-import org.apache.hadoop.yarn.api.records.Resource;
-import org.apache.hadoop.yarn.api.records.ResourceSizing;
-import org.apache.hadoop.yarn.api.records.SchedulingRequest;
-import org.apache.hadoop.yarn.api.resource.PlacementConstraint;
-import org.apache.hadoop.yarn.api.resource.PlacementConstraint.TargetExpression;
-import org.apache.hadoop.yarn.api.resource.PlacementConstraints;
-import org.apache.hadoop.yarn.api.resource.PlacementConstraints.PlacementTargets;
-import org.apache.hadoop.yarn.client.api.AMRMClient.ContainerRequest;
-import org.apache.hadoop.yarn.client.api.async.AMRMClientAsync;
-import org.apache.hadoop.yarn.event.AsyncDispatcher;
-import org.apache.hadoop.yarn.event.EventHandler;
-import org.apache.hadoop.yarn.service.ServiceEvent;
-import org.apache.hadoop.yarn.service.ServiceEventType;
-import org.apache.hadoop.yarn.service.api.records.ContainerState;
-import org.apache.hadoop.yarn.service.api.records.ResourceInformation;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceId;
-import org.apache.hadoop.yarn.service.ContainerFailureTracker;
-import org.apache.hadoop.yarn.service.ServiceContext;
-import org.apache.hadoop.yarn.service.ServiceMetrics;
-import org.apache.hadoop.yarn.service.ServiceScheduler;
-import org.apache.hadoop.yarn.service.api.records.PlacementPolicy;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEvent;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConf;
-import org.apache.hadoop.yarn.service.monitor.ComponentHealthThresholdMonitor;
-import org.apache.hadoop.yarn.service.monitor.probe.MonitorUtils;
-import org.apache.hadoop.yarn.service.monitor.probe.Probe;
-import org.apache.hadoop.yarn.service.containerlaunch.ContainerLaunchService;
-import org.apache.hadoop.yarn.service.provider.ProviderService;
-import org.apache.hadoop.yarn.service.provider.ProviderUtils;
-import org.apache.hadoop.yarn.service.utils.ServiceApiUtil;
-import org.apache.hadoop.yarn.service.utils.ServiceUtils;
-import org.apache.hadoop.yarn.state.InvalidStateTransitionException;
-import org.apache.hadoop.yarn.state.MultipleArcTransition;
-import org.apache.hadoop.yarn.state.SingleArcTransition;
-import org.apache.hadoop.yarn.state.StateMachine;
-import org.apache.hadoop.yarn.state.StateMachineFactory;
-import org.apache.hadoop.yarn.util.Apps;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.text.MessageFormat;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.EnumSet;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.LinkedList;
-import java.util.List;
-import java.util.Map;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.concurrent.Future;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.atomic.AtomicBoolean;
-import java.util.concurrent.atomic.AtomicInteger;
-import java.util.concurrent.atomic.AtomicLong;
-import java.util.concurrent.locks.ReentrantReadWriteLock;
-
-import static org.apache.hadoop.yarn.api.records.ContainerExitStatus.*;
-import static org.apache.hadoop.yarn.service.api.ServiceApiConstants.*;
-import static org.apache.hadoop.yarn.service.component.ComponentEventType.*;
-import static org.apache.hadoop.yarn.service.component.ComponentEventType.CANCEL_UPGRADE;
-import static org.apache.hadoop.yarn.service.component.ComponentEventType.UPGRADE;
-import static org.apache.hadoop.yarn.service.component.ComponentState.*;
-import static org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEventType.*;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.*;
-
-public class Component implements EventHandler<ComponentEvent> {
-  private static final Logger LOG = LoggerFactory.getLogger(Component.class);
-
-  private org.apache.hadoop.yarn.service.api.records.Component componentSpec;
-  private long allocateId;
-  private Priority priority;
-  private ServiceMetrics componentMetrics;
-  private ServiceScheduler scheduler;
-  private ServiceContext context;
-  private AMRMClientAsync<ContainerRequest> amrmClient;
-  private AtomicLong instanceIdCounter = new AtomicLong();
-  private Map<String, ComponentInstance> compInstances =
-      new ConcurrentHashMap<>();
-  // component instances to be assigned with a container
-  private List<ComponentInstance> pendingInstances =
-      Collections.synchronizedList(new LinkedList<>());
-  private ContainerFailureTracker failureTracker;
-  private Probe probe;
-  private final ReentrantReadWriteLock.ReadLock readLock;
-  private final ReentrantReadWriteLock.WriteLock writeLock;
-  public int maxContainerFailurePerComp;
-  // The number of containers failed since last reset. This excludes preempted,
-  // disk_failed containers etc. This will be reset to 0 periodically.
-  public AtomicInteger currentContainerFailure = new AtomicInteger(0);
-
-  //succeeded and Failed instances are Populated only for RestartPolicyEnum
-  //.ON_FAILURE/NEVER
-  private Map<String, ComponentInstance> succeededInstances =
-      new ConcurrentHashMap<>();
-  private Map<String, ComponentInstance> failedInstances =
-      new ConcurrentHashMap<>();
-  private boolean healthThresholdMonitorEnabled = false;
-
-  private UpgradeStatus upgradeStatus = new UpgradeStatus();
-  private UpgradeStatus cancelUpgradeStatus = new UpgradeStatus();
-
-  private StateMachine<ComponentState, ComponentEventType, ComponentEvent>
-      stateMachine;
-  private AsyncDispatcher dispatcher;
-  private static final StateMachineFactory<Component, ComponentState, ComponentEventType, ComponentEvent>
-      stateMachineFactory =
-      new StateMachineFactory<Component, ComponentState, ComponentEventType, ComponentEvent>(
-          INIT)
-           // INIT will only got to FLEXING
-          .addTransition(INIT, EnumSet.of(STABLE, FLEXING, INIT),
-              FLEX, new FlexComponentTransition())
-          // container recovered on AM restart
-          .addTransition(INIT, INIT, CONTAINER_RECOVERED,
-              new ContainerRecoveredTransition())
-          // instance decommissioned
-          .addTransition(INIT, INIT, DECOMMISSION_INSTANCE,
-              new DecommissionInstanceTransition())
-
-          // container recovered in AM heartbeat
-          .addTransition(FLEXING, FLEXING, CONTAINER_RECOVERED,
-              new ContainerRecoveredTransition())
-
-          // container allocated by RM
-          .addTransition(FLEXING, FLEXING, CONTAINER_ALLOCATED,
-              new ContainerAllocatedTransition())
-          // container launched on NM
-          .addTransition(FLEXING, EnumSet.of(STABLE, FLEXING, UPGRADING),
-              CONTAINER_STARTED, new ContainerStartedTransition())
-          // container failed while flexing
-          .addTransition(FLEXING, FLEXING, CONTAINER_COMPLETED,
-              new ContainerCompletedTransition())
-          // Flex while previous flex is still in progress
-          .addTransition(FLEXING, EnumSet.of(FLEXING, STABLE), FLEX,
-              new FlexComponentTransition())
-          .addTransition(FLEXING, EnumSet.of(UPGRADING, FLEXING, STABLE),
-              CHECK_STABLE, new CheckStableTransition())
-          // instance decommissioned
-          .addTransition(FLEXING, FLEXING, DECOMMISSION_INSTANCE,
-              new DecommissionInstanceTransition())
-
-          // container failed while stable
-          .addTransition(STABLE, FLEXING, CONTAINER_COMPLETED,
-              new ContainerCompletedTransition())
-          // Ignore surplus container
-          .addTransition(STABLE, STABLE, CONTAINER_ALLOCATED,
-              new ContainerAllocatedTransition())
-          // Flex by user
-          // For flex up, go to FLEXING state
-          // For flex down, go to STABLE state
-          .addTransition(STABLE, EnumSet.of(STABLE, FLEXING),
-              FLEX, new FlexComponentTransition())
-          // instance decommissioned
-          .addTransition(STABLE, STABLE, DECOMMISSION_INSTANCE,
-              new DecommissionInstanceTransition())
-          // upgrade component
-          .addTransition(STABLE, UPGRADING, UPGRADE,
-              new NeedsUpgradeTransition())
-          .addTransition(STABLE, CANCEL_UPGRADING, CANCEL_UPGRADE,
-              new NeedsUpgradeTransition())
-          .addTransition(STABLE, EnumSet.of(STABLE, FLEXING), CHECK_STABLE,
-              new CheckStableTransition())
-
-          // Cancel upgrade while previous upgrade is still in progress
-          .addTransition(UPGRADING, CANCEL_UPGRADING,
-              CANCEL_UPGRADE, new NeedsUpgradeTransition())
-          .addTransition(UPGRADING, EnumSet.of(UPGRADING, FLEXING, STABLE),
-              CHECK_STABLE, new CheckStableTransition())
-          .addTransition(UPGRADING, UPGRADING, CONTAINER_COMPLETED,
-              new CompletedAfterUpgradeTransition())
-          // instance decommissioned
-          .addTransition(UPGRADING, UPGRADING, DECOMMISSION_INSTANCE,
-              new DecommissionInstanceTransition())
-
-          .addTransition(CANCEL_UPGRADING, EnumSet.of(CANCEL_UPGRADING, FLEXING,
-              STABLE), CHECK_STABLE, new CheckStableTransition())
-          .addTransition(CANCEL_UPGRADING, CANCEL_UPGRADING,
-              CONTAINER_COMPLETED, new CompletedAfterUpgradeTransition())
-          .addTransition(CANCEL_UPGRADING, FLEXING, CONTAINER_ALLOCATED,
-              new ContainerAllocatedTransition())
-          // instance decommissioned
-          .addTransition(CANCEL_UPGRADING, CANCEL_UPGRADING,
-              DECOMMISSION_INSTANCE, new DecommissionInstanceTransition())
-          .installTopology();
-
-  public Component(
-      org.apache.hadoop.yarn.service.api.records.Component component,
-      long allocateId, ServiceContext context) {
-    this.allocateId = allocateId;
-    this.priority = Priority.newInstance((int) allocateId);
-    this.componentSpec = component;
-    componentMetrics = ServiceMetrics.register(component.getName(),
-        "Metrics for component " + component.getName());
-    componentMetrics
-        .tag("type", "Metrics type [component or service]", "component");
-    this.scheduler = context.scheduler;
-    this.context = context;
-    amrmClient = scheduler.getAmRMClient();
-    ReentrantReadWriteLock lock = new ReentrantReadWriteLock();
-    this.readLock = lock.readLock();
-    this.writeLock = lock.writeLock();
-    this.stateMachine = stateMachineFactory.make(this);
-    dispatcher = scheduler.getDispatcher();
-    failureTracker =
-        new ContainerFailureTracker(context, this);
-    if (componentSpec.getReadinessCheck() != null ||
-        YarnServiceConf.getBoolean(DEFAULT_READINESS_CHECK_ENABLED,
-            DEFAULT_READINESS_CHECK_ENABLED_DEFAULT,
-            componentSpec.getConfiguration(), scheduler.getConfig())) {
-      probe = MonitorUtils.getProbe(componentSpec.getReadinessCheck());
-    }
-    maxContainerFailurePerComp = YarnServiceConf.getInt(
-        CONTAINER_FAILURE_THRESHOLD, DEFAULT_CONTAINER_FAILURE_THRESHOLD,
-        componentSpec.getConfiguration(), scheduler.getConfig());
-    createNumCompInstances(component.getNumberOfContainers());
-    setDesiredContainers(component.getNumberOfContainers().intValue());
-    checkAndScheduleHealthThresholdMonitor();
-  }
-
-  private void createNumCompInstances(long count) {
-    for (int i = 0; i < count; i++) {
-      createOneCompInstance();
-    }
-  }
-
-  private void createOneCompInstance() {
-    ComponentInstanceId id =
-        new ComponentInstanceId(instanceIdCounter.getAndIncrement(),
-            componentSpec.getName());
-    while (componentSpec.getDecommissionedInstances().contains(id
-        .getCompInstanceName())) {
-      id = new ComponentInstanceId(instanceIdCounter.getAndIncrement(),
-          componentSpec.getName());
-    }
-    ComponentInstance instance = new ComponentInstance(this, id);
-    compInstances.put(instance.getCompInstanceName(), instance);
-    pendingInstances.add(instance);
-  }
-
-  private void checkAndScheduleHealthThresholdMonitor() {
-    // Determine health threshold percent
-    int healthThresholdPercent = YarnServiceConf.getInt(
-        CONTAINER_HEALTH_THRESHOLD_PERCENT,
-        DEFAULT_CONTAINER_HEALTH_THRESHOLD_PERCENT,
-        componentSpec.getConfiguration(), scheduler.getConfig());
-    // Validations
-    if (healthThresholdPercent == CONTAINER_HEALTH_THRESHOLD_PERCENT_DISABLED) {
-      LOG.info("No health threshold monitor enabled for component {}",
-          componentSpec.getName());
-      return;
-    }
-    // If threshold is set to outside acceptable range then don't enable monitor
-    if (healthThresholdPercent <= 0 || healthThresholdPercent > 100) {
-      LOG.error(
-          "Invalid health threshold percent {}% for component {}. Monitor not "
-              + "enabled.",
-          healthThresholdPercent, componentSpec.getName());
-      return;
-    }
-    // Determine the threshold properties
-    long window = YarnServiceConf.getLong(CONTAINER_HEALTH_THRESHOLD_WINDOW_SEC,
-        DEFAULT_CONTAINER_HEALTH_THRESHOLD_WINDOW_SEC,
-        componentSpec.getConfiguration(), scheduler.getConfig());
-    long initDelay = YarnServiceConf.getLong(
-        CONTAINER_HEALTH_THRESHOLD_INIT_DELAY_SEC,
-        DEFAULT_CONTAINER_HEALTH_THRESHOLD_INIT_DELAY_SEC,
-        componentSpec.getConfiguration(), scheduler.getConfig());
-    long pollFrequency = YarnServiceConf.getLong(
-        CONTAINER_HEALTH_THRESHOLD_POLL_FREQUENCY_SEC,
-        DEFAULT_CONTAINER_HEALTH_THRESHOLD_POLL_FREQUENCY_SEC,
-        componentSpec.getConfiguration(), scheduler.getConfig());
-    // Validations
-    if (window <= 0) {
-      LOG.error(
-          "Invalid health monitor window {} secs for component {}. Monitor not "
-              + "enabled.",
-          window, componentSpec.getName());
-      return;
-    }
-    if (initDelay < 0) {
-      LOG.error("Invalid health monitor init delay {} secs for component {}. "
-          + "Monitor not enabled.", initDelay, componentSpec.getName());
-      return;
-    }
-    if (pollFrequency <= 0) {
-      LOG.error(
-          "Invalid health monitor poll frequency {} secs for component {}. "
-              + "Monitor not enabled.",
-          pollFrequency, componentSpec.getName());
-      return;
-    }
-    LOG.info(
-        "Scheduling the health threshold monitor for component {} with percent "
-            + "= {}%, window = {} secs, poll freq = {} secs, init-delay = {} "
-            + "secs",
-        componentSpec.getName(), healthThresholdPercent, window, pollFrequency,
-        initDelay);
-    // Add 3 extra seconds to initial delay to account for the time taken to
-    // request containers before the monitor starts calculating health.
-    this.scheduler.executorService.scheduleAtFixedRate(
-        new ComponentHealthThresholdMonitor(this, healthThresholdPercent,
-            window),
-        initDelay + 3, pollFrequency, TimeUnit.SECONDS);
-    setHealthThresholdMonitorEnabled(true);
-  }
-
-  private static class FlexComponentTransition implements
-      MultipleArcTransition<Component, ComponentEvent, ComponentState> {
-    // For flex up, go to FLEXING state
-    // For flex down, go to STABLE state
-    @Override
-    public ComponentState transition(Component component,
-        ComponentEvent event) {
-      component.setDesiredContainers((int) event.getDesired());
-      if (!component.areDependenciesReady()) {
-        LOG.info("[FLEX COMPONENT {}]: Flex deferred because dependencies not"
-            + " satisfied.", component.getName());
-        return component.getState();
-      }
-      if (component.getState() == INIT) {
-        // This happens on init
-        LOG.info("[INIT COMPONENT " + component.getName() + "]: " + event
-            .getDesired() + " instances.");
-        component.requestContainers(component.pendingInstances.size());
-        return checkIfStable(component);
-      }
-      long before = component.getComponentSpec().getNumberOfContainers();
-      long delta = event.getDesired() - before;
-      component.getComponentSpec().setNumberOfContainers(event.getDesired());
-      if (delta > 0) {
-        // Scale up
-        LOG.info("[FLEX UP COMPONENT " + component.getName() + "]: scaling up from "
-                + before + " to " + event.getDesired());
-        component.requestContainers(delta);
-        component.createNumCompInstances(delta);
-        component.setComponentState(
-            org.apache.hadoop.yarn.service.api.records.ComponentState.FLEXING);
-        component.getScheduler().getApp().setState(ServiceState.STARTED);
-        return FLEXING;
-      } else if (delta < 0) {
-        delta = 0 - delta;
-        // scale down
-        LOG.info("[FLEX DOWN COMPONENT " + component.getName()
-            + "]: scaling down from " + before + " to " + event.getDesired());
-        List<ComponentInstance> list =
-            new ArrayList<>(component.getAllComponentInstances());
-
-        // sort in Most recent -> oldest order, destroy most recent ones.
-        list.sort(Collections.reverseOrder());
-        for (int i = 0; i < delta; i++) {
-          ComponentInstance instance = list.get(i);
-          // remove the instance
-          component.compInstances.remove(instance.getCompInstanceName());
-          component.pendingInstances.remove(instance);
-          // decrement id counter
-          component.instanceIdCounter.decrementAndGet();
-          instance.destroy();
-        }
-        checkAndUpdateComponentState(component, false);
-        return component.componentSpec.getState()
-            == org.apache.hadoop.yarn.service.api.records.ComponentState.STABLE
-                ? STABLE : FLEXING;
-      } else {
-        LOG.info("[FLEX COMPONENT " + component.getName() + "]: already has " +
-            event.getDesired() + " instances, ignoring");
-        return STABLE;
-      }
-    }
-  }
-
-  private static class DecommissionInstanceTransition extends BaseTransition {
-    @Override
-    public void transition(Component component, ComponentEvent event) {
-      String instanceName = event.getInstanceName();
-      String hostnameSuffix = component.getHostnameSuffix();
-      if (instanceName.endsWith(hostnameSuffix)) {
-        instanceName = instanceName.substring(0,
-            instanceName.length() - hostnameSuffix.length());
-      }
-      if (component.getComponentSpec().getDecommissionedInstances()
-          .contains(instanceName)) {
-        LOG.info("Instance {} already decommissioned", instanceName);
-        return;
-      }
-      component.getComponentSpec().addDecommissionedInstance(instanceName);
-      ComponentInstance instance = component.getComponentInstance(instanceName);
-      if (instance == null) {
-        LOG.info("Instance was null for decommissioned instance {}",
-            instanceName);
-        return;
-      }
-      // remove the instance
-      component.compInstances.remove(instance.getCompInstanceName());
-      component.pendingInstances.remove(instance);
-      component.scheduler.getServiceMetrics().containersDesired.decr();
-      component.componentMetrics.containersDesired.decr();
-      component.getComponentSpec().setNumberOfContainers(component
-          .getComponentSpec().getNumberOfContainers() - 1);
-      instance.destroy();
-    }
-  }
-
-  private static class ContainerAllocatedTransition extends BaseTransition {
-    @Override
-    public void transition(Component component, ComponentEvent event) {
-      component.assignContainerToCompInstance(event.getContainer());
-    }
-  }
-
-  private static class ContainerRecoveredTransition extends BaseTransition {
-    @Override
-    public void transition(Component component, ComponentEvent event) {
-      ComponentInstance instance = event.getInstance();
-      Container container = event.getContainer();
-      if (instance == null) {
-        LOG.info("[COMPONENT {}]: Trying to recover {} but event did not " +
-                "specify component instance",
-            component.getName(), container.getId());
-        component.releaseContainer(container);
-        return;
-      }
-
-      component.pendingInstances.remove(instance);
-      instance.setContainer(container);
-
-      ProviderUtils.initCompInstanceDir(component.getContext().fs,
-          component.createLaunchContext(component.componentSpec,
-              component.scheduler.getApp().getVersion()), instance);
-      component.getScheduler().addLiveCompInstance(container.getId(), instance);
-      LOG.info("[COMPONENT {}]: Recovered {} for component instance {} on " +
-              "host {}, num pending component instances reduced to {} ",
-          component.getName(), container.getId(),
-          instance.getCompInstanceName(), container.getNodeId(),
-          component.pendingInstances.size());
-      component.dispatcher.getEventHandler().handle(
-          new ComponentInstanceEvent(container.getId(), START));
-    }
-  }
-
-  private static class ContainerStartedTransition implements
-      MultipleArcTransition<Component,ComponentEvent,ComponentState> {
-
-    @Override public ComponentState transition(Component component,
-        ComponentEvent event) {
-      component.dispatcher.getEventHandler().handle(
-          new ComponentInstanceEvent(event.getContainerId(), START));
-      return checkIfStable(component);
-    }
-  }
-
-  @VisibleForTesting
-  static ComponentState checkIfStable(Component component) {
-    if (component.getRestartPolicyHandler().isLongLived()) {
-      return updateStateForLongRunningComponents(component);
-    } else{
-      //NEVER/ON_FAILURE
-      return updateStateForTerminatingComponents(component);
-    }
-  }
-
-  private static ComponentState updateStateForTerminatingComponents(
-      Component component) {
-    if (component.getNumRunningInstances() + component
-        .getNumSucceededInstances() + component.getNumFailedInstances()
-        < component.getComponentSpec().getNumberOfContainers()) {
-      component.setComponentState(
-          org.apache.hadoop.yarn.service.api.records.ComponentState.FLEXING);
-      return FLEXING;
-    } else{
-      component.setComponentState(
-          org.apache.hadoop.yarn.service.api.records.ComponentState.STABLE);
-      return STABLE;
-    }
-  }
-
-  private static ComponentState updateStateForLongRunningComponents(
-      Component component) {
-    // if desired == running
-    if (component.componentMetrics.containersReady.value() == component
-        .getComponentSpec().getNumberOfContainers() &&
-        !component.doesNeedUpgrade()) {
-      component.setComponentState(
-          org.apache.hadoop.yarn.service.api.records.ComponentState.STABLE);
-      return STABLE;
-    } else if (component.doesNeedUpgrade()) {
-      component.setComponentState(org.apache.hadoop.yarn.service.api.records.
-          ComponentState.NEEDS_UPGRADE);
-      return component.getState();
-    } else if (component.componentMetrics.containersReady.value() != component
-        .getComponentSpec().getNumberOfContainers()) {
-      component.setComponentState(
-          org.apache.hadoop.yarn.service.api.records.ComponentState.FLEXING);
-      return FLEXING;
-    }
-    return component.getState();
-  }
-
-  // This method should be called whenever there is an increment or decrement
-  // of a READY state container of a component
-  //This should not matter for terminating components
-  private static synchronized void checkAndUpdateComponentState(
-      Component component, boolean isIncrement) {
-
-    if (component.getRestartPolicyHandler().isLongLived()) {
-      if (isIncrement) {
-        // check if all containers are in READY state
-        if (!component.upgradeStatus.areContainersUpgrading() &&
-            !component.cancelUpgradeStatus.areContainersUpgrading() &&
-            component.componentMetrics.containersReady.value() ==
-                component.componentMetrics.containersDesired.value()) {
-          component.setComponentState(
-              org.apache.hadoop.yarn.service.api.records.ComponentState.STABLE);
-          // component state change will trigger re-check of service state
-          component.context.getServiceManager().checkAndUpdateServiceState();
-        }
-      } else{
-        // container moving out of READY state could be because of FLEX down so
-        // still need to verify the count before changing the component state
-        if (component.componentMetrics.containersReady.value()
-            < component.componentMetrics.containersDesired.value()) {
-          component.setComponentState(
-              org.apache.hadoop.yarn.service.api.records.ComponentState
-                  .FLEXING);
-        } else if (component.componentMetrics.containersReady.value()
-            == component.componentMetrics.containersDesired.value()) {
-          component.setComponentState(
-              org.apache.hadoop.yarn.service.api.records.ComponentState.STABLE);
-        }
-        // component state change will trigger re-check of service state
-        component.context.getServiceManager().checkAndUpdateServiceState();
-      }
-    } else {
-      // component state change will trigger re-check of service state
-      component.context.getServiceManager().checkAndUpdateServiceState();
-    }
-    // triggers the state machine in component to reach appropriate state
-    // once the state in spec is changed.
-    component.dispatcher.getEventHandler().handle(
-        new ComponentEvent(component.getName(),
-            ComponentEventType.CHECK_STABLE));
-  }
-
-  private static class ContainerCompletedTransition extends BaseTransition {
-    @Override
-    public void transition(Component component, ComponentEvent event) {
-      Preconditions.checkNotNull(event.getContainerId());
-      component.updateMetrics(event.getStatus());
-      component.dispatcher.getEventHandler().handle(
-          new ComponentInstanceEvent(event.getContainerId(), STOP)
-              .setStatus(event.getStatus()));
-
-      ComponentRestartPolicy restartPolicy =
-          component.getRestartPolicyHandler();
-
-      if (restartPolicy.shouldRelaunchInstance(event.getInstance(),
-          event.getStatus())) {
-        component.componentSpec.setState(
-            org.apache.hadoop.yarn.service.api.records.ComponentState.FLEXING);
-
-        if (component.context.service.getState().equals(ServiceState.STABLE)) {
-          component.getScheduler().getApp().setState(ServiceState.STARTED);
-          LOG.info("Service def state changed from {} -> {}",
-              ServiceState.STABLE, ServiceState.STARTED);
-        }
-      }
-    }
-  }
-
-  private static class CompletedAfterUpgradeTransition extends BaseTransition {
-    @Override
-    public void transition(Component component, ComponentEvent event) {
-      Preconditions.checkNotNull(event.getContainerId());
-      component.updateMetrics(event.getStatus());
-      component.dispatcher.getEventHandler().handle(
-          new ComponentInstanceEvent(event.getContainerId(), STOP)
-              .setStatus(event.getStatus()));
-    }
-  }
-
-  private static class NeedsUpgradeTransition extends BaseTransition {
-    @Override
-    public void transition(Component component, ComponentEvent event) {
-      boolean isCancel = event.getType().equals(CANCEL_UPGRADE);
-      UpgradeStatus status = !isCancel ? component.upgradeStatus :
-          component.cancelUpgradeStatus;
-
-      status.inProgress.set(true);
-      status.targetSpec = event.getTargetSpec();
-      status.targetVersion = event.getUpgradeVersion();
-      LOG.info("[COMPONENT {}]: need upgrade to {}",
-          component.getName(), status.targetVersion);
-
-      status.containersNeedUpgrade.set(
-          component.componentSpec.getNumberOfContainers());
-
-      component.setComponentState(org.apache.hadoop.yarn.service.api.
-          records.ComponentState.NEEDS_UPGRADE);
-
-      component.getAllComponentInstances().forEach(instance -> {
-        instance.setContainerState(ContainerState.NEEDS_UPGRADE);
-      });
-
-      if (event.getType().equals(CANCEL_UPGRADE)) {
-        component.upgradeStatus.reset();
-      }
-    }
-  }
-
-  private static class CheckStableTransition implements MultipleArcTransition
-      <Component, ComponentEvent, ComponentState> {
-
-    @Override
-    public ComponentState transition(Component component,
-        ComponentEvent componentEvent) {
-      // checkIfStable also updates the state in definition when STABLE
-      ComponentState targetState = checkIfStable(component);
-
-      if (targetState.equals(STABLE) &&
-          !(component.upgradeStatus.isCompleted() &&
-              component.cancelUpgradeStatus.isCompleted())) {
-        // Component stable after upgrade or cancel upgrade
-        UpgradeStatus status = !component.cancelUpgradeStatus.isCompleted() ?
-            component.cancelUpgradeStatus : component.upgradeStatus;
-
-        component.componentSpec.overwrite(status.getTargetSpec());
-        status.reset();
-
-        ServiceEvent checkStable = new ServiceEvent(ServiceEventType.
-            CHECK_STABLE);
-        component.dispatcher.getEventHandler().handle(checkStable);
-      }
-      return targetState;
-    }
-  }
-
-  public void removePendingInstance(ComponentInstance instance) {
-    pendingInstances.remove(instance);
-  }
-
-  public void reInsertPendingInstance(ComponentInstance instance) {
-    pendingInstances.add(instance);
-  }
-
-  private void releaseContainer(Container container) {
-    scheduler.getAmRMClient().releaseAssignedContainer(container.getId());
-    componentMetrics.surplusContainers.incr();
-    scheduler.getServiceMetrics().surplusContainers.incr();
-  }
-
-  private void assignContainerToCompInstance(Container container) {
-    if (pendingInstances.size() == 0) {
-      LOG.info(
-          "[COMPONENT {}]: No pending component instance left, release surplus container {}",
-          getName(), container.getId());
-      releaseContainer(container);
-      return;
-    }
-    ComponentInstance instance = pendingInstances.remove(0);
-    LOG.info(
-        "[COMPONENT {}]: {} allocated, num pending component instances reduced to {}",
-        getName(), container.getId(), pendingInstances.size());
-    instance.setContainer(container);
-    scheduler.addLiveCompInstance(container.getId(), instance);
-    LOG.info(
-        "[COMPONENT {}]: Assigned {} to component instance {} and launch on host {} ",
-        getName(), container.getId(), instance.getCompInstanceName(),
-        container.getNodeId());
-    Future<ProviderService.ResolvedLaunchParams> resolvedParamFuture;
-    if (!(upgradeStatus.isCompleted() && cancelUpgradeStatus.isCompleted())) {
-      UpgradeStatus status = !cancelUpgradeStatus.isCompleted() ?
-          cancelUpgradeStatus : upgradeStatus;
-
-      resolvedParamFuture = scheduler.getContainerLaunchService()
-          .launchCompInstance(scheduler.getApp(), instance, container,
-              createLaunchContext(status.getTargetSpec(),
-                  status.getTargetVersion()));
-    } else {
-      resolvedParamFuture = scheduler.getContainerLaunchService()
-          .launchCompInstance(
-          scheduler.getApp(), instance, container,
-          createLaunchContext(componentSpec, scheduler.getApp().getVersion()));
-    }
-    instance.updateResolvedLaunchParams(resolvedParamFuture);
-  }
-
-  public ContainerLaunchService.ComponentLaunchContext createLaunchContext(
-      org.apache.hadoop.yarn.service.api.records.Component compSpec,
-      String version) {
-    ContainerLaunchService.ComponentLaunchContext launchContext =
-        new ContainerLaunchService.ComponentLaunchContext(compSpec.getName(),
-            version);
-    launchContext.setArtifact(compSpec.getArtifact())
-        .setConfiguration(compSpec.getConfiguration())
-        .setLaunchCommand(compSpec.getLaunchCommand())
-        .setRunPrivilegedContainer(compSpec.getRunPrivilegedContainer());
-    return launchContext;
-  }
-
-  @SuppressWarnings({ "unchecked" })
-  public void requestContainers(long count) {
-    LOG.info("[COMPONENT {}] Requesting for {} container(s)",
-        componentSpec.getName(), count);
-    org.apache.hadoop.yarn.service.api.records.Resource componentResource =
-        componentSpec.getResource();
-
-    Resource resource = Resource.newInstance(componentResource.calcMemoryMB(),
-        componentResource.getCpus());
-
-    if (componentResource.getAdditional() != null) {
-      for (Map.Entry<String, ResourceInformation> entry : componentResource
-          .getAdditional().entrySet()) {
-
-        String resourceName = entry.getKey();
-
-        // Avoid setting memory/cpu under "additional"
-        if (resourceName.equals(
-            org.apache.hadoop.yarn.api.records.ResourceInformation.MEMORY_URI)
-            || resourceName.equals(
-            org.apache.hadoop.yarn.api.records.ResourceInformation.VCORES_URI)) {
-          LOG.warn("Please set memory/vcore in the main section of resource, "
-              + "ignoring this entry=" + resourceName);
-          continue;
-        }
-
-        ResourceInformation specInfo = entry.getValue();
-        org.apache.hadoop.yarn.api.records.ResourceInformation ri =
-            org.apache.hadoop.yarn.api.records.ResourceInformation.newInstance(
-                entry.getKey(),
-                specInfo.getUnit(),
-                specInfo.getValue(),
-                specInfo.getTags(),
-                specInfo.getAttributes());
-        resource.setResourceInformation(resourceName, ri);
-      }
-    }
-
-    if (!scheduler.hasAtLeastOnePlacementConstraint()) {
-      for (int i = 0; i < count; i++) {
-        ContainerRequest request = ContainerRequest.newBuilder()
-            .capability(resource).priority(priority)
-            .allocationRequestId(allocateId).relaxLocality(true).build();
-        LOG.info("[COMPONENT {}] Submitting container request : {}",
-            componentSpec.getName(), request);
-        amrmClient.addContainerRequest(request);
-      }
-    } else {
-      // Schedule placement requests. Validation of non-null target tags and
-      // that they refer to existing component names are already done. So, no
-      // need to validate here.
-      PlacementPolicy placementPolicy = componentSpec.getPlacementPolicy();
-      Collection<SchedulingRequest> schedulingRequests = new HashSet<>();
-      // We prepare an AND-ed composite constraint to be the final composite
-      // constraint. If placement expressions are specified to create advanced
-      // composite constraints then this AND-ed composite constraint is not
-      // used.
-      PlacementConstraint finalConstraint = null;
-      if (placementPolicy != null) {
-        for (org.apache.hadoop.yarn.service.api.records.PlacementConstraint
-            yarnServiceConstraint : placementPolicy.getConstraints()) {
-          List<TargetExpression> targetExpressions = new ArrayList<>();
-          // Currently only intra-application allocation tags are supported.
-          if (!yarnServiceConstraint.getTargetTags().isEmpty()) {
-            targetExpressions.add(PlacementTargets.allocationTag(
-                yarnServiceConstraint.getTargetTags().toArray(new String[0])));
-          }
-          // Add all node attributes
-          for (Map.Entry<String, List<String>> attribute : yarnServiceConstraint
-              .getNodeAttributes().entrySet()) {
-            targetExpressions
-                .add(PlacementTargets.nodeAttribute(attribute.getKey(),
-                    attribute.getValue().toArray(new String[0])));
-          }
-          // Add all node partitions
-          if (!yarnServiceConstraint.getNodePartitions().isEmpty()) {
-            targetExpressions
-                .add(PlacementTargets.nodePartition(yarnServiceConstraint
-                    .getNodePartitions().toArray(new String[0])));
-          }
-          PlacementConstraint constraint = null;
-          switch (yarnServiceConstraint.getType()) {
-          case AFFINITY:
-            constraint = getAffinityConstraint(yarnServiceConstraint,
-              targetExpressions);
-            break;
-          case ANTI_AFFINITY:
-            constraint = getAntiAffinityConstraint(yarnServiceConstraint,
-              targetExpressions);
-            break;
-          case AFFINITY_WITH_CARDINALITY:
-            constraint = PlacementConstraints.targetCardinality(
-                yarnServiceConstraint.getScope().name().toLowerCase(),
-                yarnServiceConstraint.getMinCardinality() == null ? 0
-                    : yarnServiceConstraint.getMinCardinality().intValue(),
-                yarnServiceConstraint.getMaxCardinality() == null
-                    ? Integer.MAX_VALUE
-                    : yarnServiceConstraint.getMaxCardinality().intValue(),
-                targetExpressions.toArray(new TargetExpression[0])).build();
-            break;
-          }
-          if (constraint == null) {
-            LOG.info("[COMPONENT {}] Placement constraint: null ",
-                componentSpec.getName());
-            continue;
-          }
-          // The default AND-ed final composite constraint
-          if (finalConstraint != null) {
-            finalConstraint = PlacementConstraints
-                .and(constraint.getConstraintExpr(),
-                    finalConstraint.getConstraintExpr())
-                .build();
-          } else {
-            finalConstraint = constraint;
-          }
-          LOG.debug("[COMPONENT {}] Placement constraint: {}",
-              componentSpec.getName(),
-              constraint.getConstraintExpr().toString());
-        }
-      }
-      ResourceSizing resourceSizing = ResourceSizing.newInstance((int) count,
-          resource);
-      LOG.debug("[COMPONENT {}] Resource sizing: {}", componentSpec.getName(),
-          resourceSizing);
-      SchedulingRequest request = SchedulingRequest.newBuilder()
-          .priority(priority).allocationRequestId(allocateId)
-          .allocationTags(Collections.singleton(componentSpec.getName()))
-          .executionType(
-              ExecutionTypeRequest.newInstance(ExecutionType.GUARANTEED, true))
-          .placementConstraintExpression(finalConstraint)
-          .resourceSizing(resourceSizing).build();
-      LOG.info("[COMPONENT {}] Submitting scheduling request: {}",
-          componentSpec.getName(), request);
-      schedulingRequests.add(request);
-      amrmClient.addSchedulingRequests(schedulingRequests);
-    }
-  }
-
-  private PlacementConstraint getAffinityConstraint(
-      org.apache.hadoop.yarn.service.api.records.PlacementConstraint
-      yarnServiceConstraint, List<TargetExpression> targetExpressions) {
-    PlacementConstraint constraint = null;
-    if (!yarnServiceConstraint.getTargetTags().isEmpty() ||
-        !yarnServiceConstraint.getNodePartitions().isEmpty()) {
-      constraint = PlacementConstraints
-        .targetIn(yarnServiceConstraint.getScope().getValue(),
-            targetExpressions.toArray(new TargetExpression[0]))
-                .build();
-    }
-    if (!yarnServiceConstraint.getNodeAttributes().isEmpty()) {
-      constraint = PlacementConstraints
-        .targetNodeAttribute(yarnServiceConstraint.getScope().getValue(),
-            NodeAttributeOpCode.EQ, targetExpressions.toArray(
-                new TargetExpression[0])).build();
-    }
-    return constraint;
-  }
-
-  private PlacementConstraint getAntiAffinityConstraint(
-      org.apache.hadoop.yarn.service.api.records.PlacementConstraint
-      yarnServiceConstraint, List<TargetExpression> targetExpressions) {
-    PlacementConstraint constraint = null;
-    if (!yarnServiceConstraint.getTargetTags().isEmpty() ||
-        !yarnServiceConstraint.getNodePartitions().isEmpty()) {
-      constraint = PlacementConstraints
-        .targetNotIn(yarnServiceConstraint.getScope().getValue(),
-            targetExpressions.toArray(new TargetExpression[0]))
-                .build();
-    }
-    if (!yarnServiceConstraint.getNodeAttributes().isEmpty()) {
-      constraint = PlacementConstraints
-        .targetNodeAttribute(yarnServiceConstraint.getScope().getValue(),
-            NodeAttributeOpCode.NE, targetExpressions.toArray(
-                new TargetExpression[0])).build();
-    }
-    return constraint;
-  }
-
-  private void setDesiredContainers(int n) {
-    int delta = n - scheduler.getServiceMetrics().containersDesired.value();
-    if (delta != 0) {
-      scheduler.getServiceMetrics().containersDesired.incr(delta);
-    }
-    componentMetrics.containersDesired.set(n);
-  }
-
-  private void updateMetrics(ContainerStatus status) {
-    //when a container preparation fails while building launch context, then
-    //the container status may not exist.
-    if (status != null) {
-      switch (status.getExitStatus()) {
-        case SUCCESS:
-          componentMetrics.containersSucceeded.incr();
-          scheduler.getServiceMetrics().containersSucceeded.incr();
-          return;
-        case PREEMPTED:
-          componentMetrics.containersPreempted.incr();
-          scheduler.getServiceMetrics().containersPreempted.incr();
-          break;
-        case DISKS_FAILED:
-          componentMetrics.containersDiskFailure.incr();
-          scheduler.getServiceMetrics().containersDiskFailure.incr();
-          break;
-        default:
-          break;
-      }
-    }
-
-    // containersFailed include preempted, disks_failed etc.
-    componentMetrics.containersFailed.incr();
-    scheduler.getServiceMetrics().containersFailed.incr();
-
-    if (status != null && Apps.shouldCountTowardsNodeBlacklisting(
-        status.getExitStatus())) {
-      String host = scheduler.getLiveInstances().get(status.getContainerId())
-          .getNodeId().getHost();
-      failureTracker.incNodeFailure(host);
-      currentContainerFailure.getAndIncrement();
-    }
-  }
-
-  private boolean doesNeedUpgrade() {
-    return cancelUpgradeStatus.areContainersUpgrading() ||
-        upgradeStatus.areContainersUpgrading() ||
-        upgradeStatus.failed.get();
-  }
-
-  public boolean areDependenciesReady() {
-    List<String> dependencies = componentSpec.getDependencies();
-    if (ServiceUtils.isEmpty(dependencies)) {
-      return true;
-    }
-    for (String dependency : dependencies) {
-      Component dependentComponent = scheduler.getAllComponents().get(
-          dependency);
-      if (dependentComponent == null) {
-        LOG.error("Couldn't find dependency {} for {} (should never happen)",
-            dependency, getName());
-        continue;
-      }
-
-      if (!dependentComponent.isReadyForDownstream()) {
-        LOG.info("[COMPONENT {}]: Dependency {} not satisfied, only {} of {}"
-                + " instances are ready or the dependent component has not "
-                + "completed ", getName(), dependency,
-            dependentComponent.getNumReadyInstances(),
-            dependentComponent.getNumDesiredInstances());
-        return false;
-      }
-    }
-    return true;
-  }
-
-
-  public Map<String, String> getDependencyHostIpTokens() {
-    Map<String, String> tokens = new HashMap<>();
-    List<String> dependencies = componentSpec.getDependencies();
-    if (ServiceUtils.isEmpty(dependencies)) {
-      return tokens;
-    }
-    for (String dependency : dependencies) {
-      Collection<ComponentInstance> instances = scheduler.getAllComponents()
-          .get(dependency).getAllComponentInstances();
-      for (ComponentInstance instance : instances) {
-        if (instance.getContainerStatus() == null) {
-          continue;
-        }
-        if (ServiceUtils.isEmpty(instance.getContainerStatus().getIPs()) ||
-            ServiceUtils.isUnset(instance.getContainerStatus().getHost())) {
-          continue;
-        }
-        String ip = instance.getContainerStatus().getIPs().get(0);
-        String host = instance.getContainerStatus().getHost();
-        tokens.put(String.format(COMPONENT_INSTANCE_IP,
-            instance.getCompInstanceName().toUpperCase()), ip);
-        tokens.put(String.format(COMPONENT_INSTANCE_HOST,
-            instance.getCompInstanceName().toUpperCase()), host);
-      }
-    }
-    return tokens;
-  }
-
-  public void incRunningContainers() {
-    componentMetrics.containersRunning.incr();
-    scheduler.getServiceMetrics().containersRunning.incr();
-  }
-
-  public void decRunningContainers() {
-    componentMetrics.containersRunning.decr();
-    scheduler.getServiceMetrics().containersRunning.decr();
-  }
-
-  public void incContainersReady(boolean updateDefinition) {
-    componentMetrics.containersReady.incr();
-    scheduler.getServiceMetrics().containersReady.incr();
-    if (updateDefinition) {
-      checkAndUpdateComponentState(this, true);
-    }
-  }
-
-  public void decContainersReady(boolean updateDefinition) {
-    componentMetrics.containersReady.decr();
-    scheduler.getServiceMetrics().containersReady.decr();
-    if (updateDefinition) {
-      checkAndUpdateComponentState(this, false);
-    }
-  }
-
-  public int getNumReadyInstances() {
-    return componentMetrics.containersReady.value();
-  }
-
-  public int getNumRunningInstances() {
-    return componentMetrics.containersRunning.value();
-  }
-
-  public int getNumDesiredInstances() {
-    return componentMetrics.containersDesired.value();
-  }
-
-  public ComponentInstance getComponentInstance(String componentInstanceName) {
-    return compInstances.get(componentInstanceName);
-  }
-
-  public Collection<ComponentInstance> getAllComponentInstances() {
-    return compInstances.values();
-  }
-
-  public org.apache.hadoop.yarn.service.api.records.Component getComponentSpec() {
-    return this.componentSpec;
-  }
-
-  public void resetCompFailureCount() {
-    LOG.info("[COMPONENT {}]: Reset container failure count from {} to 0.",
-        getName(), currentContainerFailure.get());
-    currentContainerFailure.set(0);
-    failureTracker.resetContainerFailures();
-  }
-
-  public Probe getProbe() {
-    return probe;
-  }
-
-  public Priority getPriority() {
-    return priority;
-  }
-
-  public long getAllocateId() {
-    return allocateId;
-  }
-
-  public String getName () {
-    return componentSpec.getName();
-  }
-
-  public ComponentState getState() {
-    this.readLock.lock();
-
-    try {
-      return this.stateMachine.getCurrentState();
-    } finally {
-      this.readLock.unlock();
-    }
-  }
-
-  /**
-   * Returns whether a component is upgrading or not.
-   */
-  public boolean isUpgrading() {
-    this.readLock.lock();
-
-    try {
-      return !(upgradeStatus.isCompleted() &&
-          cancelUpgradeStatus.isCompleted());
-    } finally {
-      this.readLock.unlock();
-    }
-  }
-
-  public UpgradeStatus getUpgradeStatus() {
-    this.readLock.lock();
-    try {
-      return upgradeStatus;
-    } finally {
-      this.readLock.unlock();
-    }
-  }
-
-  public UpgradeStatus getCancelUpgradeStatus() {
-    this.readLock.lock();
-    try {
-      return cancelUpgradeStatus;
-    } finally {
-      this.readLock.unlock();
-    }
-  }
-
-  public ServiceScheduler getScheduler() {
-    return scheduler;
-  }
-
-  @Override
-  public void handle(ComponentEvent event) {
-    writeLock.lock();
-    try {
-      ComponentState oldState = getState();
-      try {
-        stateMachine.doTransition(event.getType(), event);
-      } catch (InvalidStateTransitionException e) {
-        LOG.error(MessageFormat.format("[COMPONENT {0}]: Invalid event {1} at {2}",
-            componentSpec.getName(), event.getType(), oldState), e);
-      }
-      if (oldState != getState()) {
-        LOG.info("[COMPONENT {}] Transitioned from {} to {} on {} event.",
-            componentSpec.getName(), oldState, getState(), event.getType());
-      }
-    } finally {
-      writeLock.unlock();
-    }
-  }
-
-  private static class BaseTransition implements
-      SingleArcTransition<Component, ComponentEvent> {
-
-    @Override public void transition(Component component,
-        ComponentEvent event) {
-    }
-  }
-
-  /**
-   * Sets the state of the component in the component spec.
-   * @param state component state
-   */
-  private void setComponentState(
-      org.apache.hadoop.yarn.service.api.records.ComponentState state) {
-    org.apache.hadoop.yarn.service.api.records.ComponentState curState =
-        componentSpec.getState();
-    if (!curState.equals(state)) {
-      componentSpec.setState(state);
-      LOG.info("[COMPONENT {}] spec state changed from {} -> {}",
-          componentSpec.getName(), curState, state);
-    }
-  }
-
-  /**
-   * Status of upgrade.
-   */
-  public static class UpgradeStatus {
-    private org.apache.hadoop.yarn.service.api.records.Component targetSpec;
-    private String targetVersion;
-    private AtomicBoolean inProgress = new AtomicBoolean(false);
-    private AtomicLong containersNeedUpgrade = new AtomicLong(0);
-    private AtomicBoolean failed = new AtomicBoolean(false);
-
-    public org.apache.hadoop.yarn.service.api.records.
-        Component getTargetSpec() {
-      return targetSpec;
-    }
-
-    public String getTargetVersion() {
-      return targetVersion;
-    }
-
-    /*
-     * @return whether the upgrade is completed or not
-     */
-    public boolean isCompleted() {
-      return !inProgress.get();
-    }
-
-    public void decContainersThatNeedUpgrade() {
-      if (inProgress.get()) {
-        containersNeedUpgrade.decrementAndGet();
-      }
-    }
-
-    public void containerFailedUpgrade() {
-      failed.set(true);
-    }
-
-    void reset() {
-      containersNeedUpgrade.set(0);
-      targetSpec = null;
-      targetVersion = null;
-      inProgress.set(false);
-      failed.set(false);
-    }
-
-    boolean areContainersUpgrading() {
-      return containersNeedUpgrade.get() != 0;
-    }
-  }
-
-  public ServiceContext getContext() {
-    return context;
-  }
-
-  // Only for testing
-  public List<ComponentInstance> getPendingInstances() {
-    return pendingInstances;
-  }
-
-  public boolean isHealthThresholdMonitorEnabled() {
-    return healthThresholdMonitorEnabled;
-  }
-
-  public void setHealthThresholdMonitorEnabled(
-      boolean healthThresholdMonitorEnabled) {
-    this.healthThresholdMonitorEnabled = healthThresholdMonitorEnabled;
-  }
-
-  public Collection<ComponentInstance> getSucceededInstances() {
-    return succeededInstances.values();
-  }
-
-  public long getNumSucceededInstances() {
-    return succeededInstances.size();
-  }
-
-  public long getNumFailedInstances() {
-    return failedInstances.size();
-  }
-
-  public Collection<ComponentInstance> getFailedInstances() {
-    return failedInstances.values();
-  }
-
-  public synchronized void markAsSucceeded(ComponentInstance instance) {
-    removeFailedInstanceIfExists(instance);
-    succeededInstances.put(instance.getCompInstanceName(), instance);
-  }
-
-  public synchronized void markAsFailed(ComponentInstance instance) {
-    removeSuccessfulInstanceIfExists(instance);
-    failedInstances.put(instance.getCompInstanceName(), instance);
-  }
-
-  public boolean removeFailedInstanceIfExists(ComponentInstance instance) {
-    if (failedInstances.containsKey(instance.getCompInstanceName())) {
-      failedInstances.remove(instance.getCompInstanceName());
-      return true;
-    }
-    return false;
-  }
-
-  public boolean removeSuccessfulInstanceIfExists(ComponentInstance instance) {
-    if (succeededInstances.containsKey(instance.getCompInstanceName())) {
-      succeededInstances.remove(instance.getCompInstanceName());
-      return true;
-    }
-    return false;
-  }
-
-  public boolean isReadyForDownstream() {
-    return getRestartPolicyHandler().isReadyForDownStream(this);
-  }
-
-  public static ComponentRestartPolicy getRestartPolicyHandler(
-      RestartPolicyEnum restartPolicyEnum) {
-
-    if (RestartPolicyEnum.NEVER == restartPolicyEnum) {
-      return NeverRestartPolicy.getInstance();
-    } else if (RestartPolicyEnum.ON_FAILURE == restartPolicyEnum) {
-      return OnFailureRestartPolicy.getInstance();
-    } else{
-      return AlwaysRestartPolicy.getInstance();
-    }
-  }
-
-  public ComponentRestartPolicy getRestartPolicyHandler() {
-    RestartPolicyEnum restartPolicyEnum = getComponentSpec().getRestartPolicy();
-    return getRestartPolicyHandler(restartPolicyEnum);
-  }
-
-  public String getHostnameSuffix() {
-    return ServiceApiUtil.getHostnameSuffix(context.service.getName(),
-        scheduler.getConfig());
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/ComponentEvent.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/ComponentEvent.java
deleted file mode 100644
index 47a833a4068..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/ComponentEvent.java
+++ /dev/null
@@ -1,126 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.component;
-
-import org.apache.hadoop.util.Preconditions;
-import org.apache.hadoop.yarn.api.records.Container;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.api.records.ContainerStatus;
-import org.apache.hadoop.yarn.event.AbstractEvent;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-
-public class ComponentEvent extends AbstractEvent<ComponentEventType> {
-  private long desired;
-  private final String name;
-  private final ComponentEventType type;
-  private Container container;
-  private ComponentInstance instance;
-  private String instanceName;
-  private ContainerStatus status;
-  private ContainerId containerId;
-  private org.apache.hadoop.yarn.service.api.records.Component targetSpec;
-  private String upgradeVersion;
-
-  public ContainerId getContainerId() {
-    return containerId;
-  }
-
-  public ComponentEvent setContainerId(ContainerId containerId) {
-    this.containerId = containerId;
-    return this;
-  }
-
-  public ComponentEvent(String name, ComponentEventType type) {
-    super(type);
-    this.name = name;
-    this.type = type;
-  }
-
-  public String getName() {
-    return name;
-  }
-
-  public ComponentEventType getType() {
-    return type;
-  }
-
-  public long getDesired() {
-    return desired;
-  }
-
-  public ComponentEvent setDesired(long desired) {
-    this.desired = desired;
-    return this;
-  }
-
-  public Container getContainer() {
-    return container;
-  }
-
-  public ComponentEvent setContainer(Container container) {
-    this.container = container;
-    return this;
-  }
-
-  public ComponentInstance getInstance() {
-    return instance;
-  }
-
-  public ComponentEvent setInstance(ComponentInstance instance) {
-    this.instance = instance;
-    return this;
-  }
-
-  public String getInstanceName() {
-    return instanceName;
-  }
-
-  public ComponentEvent setInstanceName(String instanceName) {
-    this.instanceName = instanceName;
-    return this;
-  }
-
-  public ContainerStatus getStatus() {
-    return status;
-  }
-
-  public ComponentEvent setStatus(ContainerStatus status) {
-    this.status = status;
-    return this;
-  }
-
-  public org.apache.hadoop.yarn.service.api.records.Component getTargetSpec() {
-    return targetSpec;
-  }
-
-  public ComponentEvent setTargetSpec(
-      org.apache.hadoop.yarn.service.api.records.Component targetSpec) {
-    this.targetSpec = Preconditions.checkNotNull(targetSpec);
-    return this;
-  }
-
-  public String getUpgradeVersion() {
-    return upgradeVersion;
-  }
-
-  public ComponentEvent setUpgradeVersion(String upgradeVersion) {
-    this.upgradeVersion = upgradeVersion;
-    return this;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/ComponentEventType.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/ComponentEventType.java
deleted file mode 100644
index 558dc90f1f8..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/ComponentEventType.java
+++ /dev/null
@@ -1,31 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.component;
-
-public enum ComponentEventType {
-  FLEX,
-  CONTAINER_ALLOCATED,
-  CONTAINER_RECOVERED,
-  CONTAINER_STARTED,
-  CONTAINER_COMPLETED,
-  CANCEL_UPGRADE,
-  UPGRADE,
-  CHECK_STABLE,
-  DECOMMISSION_INSTANCE
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/ComponentRestartPolicy.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/ComponentRestartPolicy.java
deleted file mode 100644
index c5adffebcc8..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/ComponentRestartPolicy.java
+++ /dev/null
@@ -1,47 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.component;
-
-import org.apache.hadoop.yarn.api.records.ContainerStatus;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-
-/**
- * Interface for Component Restart policies.
- * Which is used to make decisions on termination/restart of components and
- * their instances.
- */
-public interface ComponentRestartPolicy {
-
-  boolean isLongLived();
-
-  boolean hasCompleted(Component component);
-
-  boolean hasCompletedSuccessfully(Component component);
-
-  boolean shouldRelaunchInstance(ComponentInstance componentInstance,
-      ContainerStatus containerStatus);
-
-  boolean isReadyForDownStream(Component component);
-
-  boolean allowUpgrades();
-
-  boolean shouldTerminate(Component component);
-
-  boolean allowContainerRetriesForInstance(ComponentInstance componentInstance);
-
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/ComponentState.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/ComponentState.java
deleted file mode 100644
index e1cd0c1bdf4..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/ComponentState.java
+++ /dev/null
@@ -1,27 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.component;
-
-public enum ComponentState {
-  INIT,
-  FLEXING,
-  STABLE,
-  UPGRADING,
-  CANCEL_UPGRADING
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/NeverRestartPolicy.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/NeverRestartPolicy.java
deleted file mode 100644
index a3d67144223..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/NeverRestartPolicy.java
+++ /dev/null
@@ -1,90 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.component;
-
-import org.apache.hadoop.yarn.api.records.ContainerStatus;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-
-/**
- * Policy for components with instances that do not require/support a restart.
- */
-public final class NeverRestartPolicy implements ComponentRestartPolicy {
-
-  private static NeverRestartPolicy INSTANCE = new NeverRestartPolicy();
-
-  private NeverRestartPolicy() {
-  }
-
-  public static NeverRestartPolicy getInstance() {
-    return INSTANCE;
-  }
-
-  @Override public boolean isLongLived() {
-    return false;
-  }
-
-  @Override public boolean hasCompleted(Component component) {
-    if (component.getNumSucceededInstances() + component.getNumFailedInstances()
-        < component.getNumDesiredInstances()) {
-      return false;
-    }
-    return true;
-  }
-
-  @Override public boolean hasCompletedSuccessfully(Component component) {
-    if (component.getNumSucceededInstances() == component
-        .getNumDesiredInstances()) {
-      return true;
-    }
-    return false;
-  }
-
-  @Override public boolean shouldRelaunchInstance(
-      ComponentInstance componentInstance, ContainerStatus containerStatus) {
-    return false;
-  }
-
-  @Override public boolean isReadyForDownStream(Component dependentComponent) {
-    if (dependentComponent.getNumReadyInstances()
-        + dependentComponent.getNumSucceededInstances()
-        + dependentComponent.getNumFailedInstances()
-        < dependentComponent.getNumDesiredInstances()) {
-      return false;
-    }
-    return true;
-  }
-
-  @Override public boolean allowUpgrades() {
-    return false;
-  }
-
-  @Override public boolean shouldTerminate(Component component) {
-    long nSucceeded = component.getNumSucceededInstances();
-    long nFailed = component.getNumFailedInstances();
-    if (nSucceeded + nFailed < component.getComponentSpec()
-        .getNumberOfContainers()) {
-      return false;
-    }
-    return true;
-  }
-
-  @Override public boolean allowContainerRetriesForInstance(
-      ComponentInstance componentInstance) {
-    return false;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/OnFailureRestartPolicy.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/OnFailureRestartPolicy.java
deleted file mode 100644
index 28ebf9ef329..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/OnFailureRestartPolicy.java
+++ /dev/null
@@ -1,94 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.component;
-
-import org.apache.hadoop.yarn.api.records.ContainerStatus;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-
-/**
- * Policy for components that require restarts for instances on failure.
- */
-public final class OnFailureRestartPolicy implements ComponentRestartPolicy {
-
-  private static OnFailureRestartPolicy INSTANCE = new OnFailureRestartPolicy();
-
-  private OnFailureRestartPolicy() {
-  }
-
-  public static OnFailureRestartPolicy getInstance() {
-    return INSTANCE;
-  }
-
-  @Override public boolean isLongLived() {
-    return false;
-  }
-
-  @Override public boolean hasCompleted(Component component) {
-    if (hasCompletedSuccessfully(component)) {
-      return true;
-    }
-
-    return false;
-  }
-
-  @Override public boolean hasCompletedSuccessfully(Component component) {
-    if (component.getNumSucceededInstances() == component
-        .getNumDesiredInstances()) {
-      return true;
-    }
-
-    return false;
-  }
-
-  @Override public boolean shouldRelaunchInstance(
-      ComponentInstance componentInstance, ContainerStatus containerStatus) {
-
-    if (ComponentInstance.hasContainerFailed(containerStatus)) {
-      return true;
-    }
-
-    return false;
-  }
-
-  @Override public boolean isReadyForDownStream(Component dependentComponent) {
-    if (dependentComponent.getNumReadyInstances()
-        + dependentComponent.getNumSucceededInstances()
-        + dependentComponent.getNumFailedInstances()
-        < dependentComponent.getNumDesiredInstances()) {
-      return false;
-    }
-    return true;
-  }
-
-  @Override public boolean allowUpgrades() {
-    return false;
-  }
-
-  @Override public boolean shouldTerminate(Component component) {
-    long nSucceeded = component.getNumSucceededInstances();
-    if (nSucceeded < component.getComponentSpec().getNumberOfContainers()) {
-      return false;
-    }
-    return true;
-  }
-
-  @Override public boolean allowContainerRetriesForInstance(
-      ComponentInstance componentInstance) {
-    return true;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstance.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstance.java
deleted file mode 100644
index cab48704935..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstance.java
+++ /dev/null
@@ -1,1181 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.component.instance;
-
-import com.fasterxml.jackson.core.type.TypeReference;
-import com.fasterxml.jackson.databind.ObjectMapper;
-import org.apache.hadoop.classification.VisibleForTesting;
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.registry.client.binding.RegistryPathUtils;
-import org.apache.hadoop.registry.client.types.ServiceRecord;
-import org.apache.hadoop.registry.client.types.yarn.PersistencePolicies;
-import org.apache.hadoop.util.StringUtils;
-import org.apache.hadoop.yarn.api.records.Container;
-import org.apache.hadoop.yarn.api.records.ContainerExitStatus;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.api.records.ContainerStatus;
-import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;
-import org.apache.hadoop.yarn.api.records.LocalizationState;
-import org.apache.hadoop.yarn.api.records.NodeId;
-import org.apache.hadoop.yarn.client.api.NMClient;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.event.EventHandler;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-import org.apache.hadoop.yarn.security.ContainerTokenIdentifier;
-import org.apache.hadoop.yarn.server.utils.BuilderUtils;
-import org.apache.hadoop.yarn.service.ServiceScheduler;
-import org.apache.hadoop.yarn.service.api.records.Artifact;
-import org.apache.hadoop.yarn.service.api.records.ComponentState;
-import org.apache.hadoop.yarn.service.api.records.ContainerState;
-import org.apache.hadoop.yarn.service.api.records.LocalizationStatus;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.component.Component;
-import org.apache.hadoop.yarn.service.component.ComponentEvent;
-import org.apache.hadoop.yarn.service.component.ComponentEventType;
-import org.apache.hadoop.yarn.service.component.ComponentRestartPolicy;
-import org.apache.hadoop.yarn.service.monitor.probe.DefaultProbe;
-import org.apache.hadoop.yarn.service.monitor.probe.ProbeStatus;
-import org.apache.hadoop.yarn.service.provider.ProviderService;
-import org.apache.hadoop.yarn.service.registry.YarnRegistryViewForProviders;
-import org.apache.hadoop.yarn.service.timelineservice.ServiceTimelinePublisher;
-import org.apache.hadoop.yarn.service.utils.ServiceUtils;
-import org.apache.hadoop.yarn.state.InvalidStateTransitionException;
-import org.apache.hadoop.yarn.state.MultipleArcTransition;
-import org.apache.hadoop.yarn.state.SingleArcTransition;
-import org.apache.hadoop.yarn.state.StateMachine;
-import org.apache.hadoop.yarn.state.StateMachineFactory;
-import org.apache.hadoop.yarn.util.BoundedAppender;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.text.MessageFormat;
-import java.util.ArrayList;
-import java.util.Date;
-import java.util.EnumSet;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.concurrent.ExecutionException;
-import java.util.concurrent.Future;
-import java.util.concurrent.ScheduledFuture;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.atomic.AtomicBoolean;
-import java.util.concurrent.locks.ReentrantReadWriteLock;
-import java.util.concurrent.locks.ReentrantReadWriteLock.ReadLock;
-import java.util.concurrent.locks.ReentrantReadWriteLock.WriteLock;
-
-import static org.apache.hadoop.registry.client.types.yarn.YarnRegistryAttributes.*;
-
-import static org.apache.hadoop.yarn.api.records.ContainerExitStatus
-    .KILLED_AFTER_APP_COMPLETION;
-import static org.apache.hadoop.yarn.api.records.ContainerExitStatus.KILLED_BY_APPMASTER;
-import static org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEventType.*;
-import static org.apache.hadoop.yarn.service.component.instance.ComponentInstanceState.*;
-
-public class ComponentInstance implements EventHandler<ComponentInstanceEvent>,
-    Comparable<ComponentInstance> {
-  private static final Logger LOG =
-      LoggerFactory.getLogger(ComponentInstance.class);
-  private static final String FAILED_BEFORE_LAUNCH_DIAG =
-      "failed before launch";
-  private static final String UPGRADE_FAILED = "upgrade failed";
-
-  private StateMachine<ComponentInstanceState, ComponentInstanceEventType,
-      ComponentInstanceEvent> stateMachine;
-  private Component component;
-  private final ReadLock readLock;
-  private final WriteLock writeLock;
-
-  private ComponentInstanceId compInstanceId = null;
-  private Path compInstanceDir;
-  private Container container;
-  private YarnRegistryViewForProviders yarnRegistryOperations;
-  private FileSystem fs;
-  private boolean timelineServiceEnabled = false;
-  private ServiceTimelinePublisher serviceTimelinePublisher;
-  private ServiceScheduler scheduler;
-  private BoundedAppender diagnostics = new BoundedAppender(64 * 1024);
-  private volatile ScheduledFuture containerStatusFuture;
-  private volatile ContainerStatus status;
-  private long containerStartedTime = 0;
-  // This container object is used for rest API query
-  private org.apache.hadoop.yarn.service.api.records.Container containerSpec;
-  private String serviceVersion;
-  private AtomicBoolean upgradeInProgress = new AtomicBoolean(false);
-  private boolean pendingCancelUpgrade = false;
-  private ProviderService.ResolvedLaunchParams resolvedParams;
-  private ScheduledFuture lclizationRetrieverFuture;
-
-  private static final StateMachineFactory<ComponentInstance,
-      ComponentInstanceState, ComponentInstanceEventType,
-      ComponentInstanceEvent>
-      stateMachineFactory =
-      new StateMachineFactory<ComponentInstance, ComponentInstanceState,
-          ComponentInstanceEventType, ComponentInstanceEvent>(INIT)
-      .addTransition(INIT, STARTED, START,
-          new ContainerStartedTransition())
-      .addTransition(INIT, INIT, STOP,
-          // container failed before launching, nothing to cleanup from registry
-          // This could happen if NMClient#startContainerAsync failed, container
-          // will be completed, but COMP_INSTANCE is still at INIT.
-          new ContainerStoppedTransition(true))
-
-      //From Running
-      .addTransition(STARTED, INIT, STOP,
-          new ContainerStoppedTransition())
-      .addTransition(STARTED, READY, BECOME_READY,
-          new ContainerBecomeReadyTransition(false))
-
-      // FROM READY
-      .addTransition(READY, STARTED, BECOME_NOT_READY,
-          new ContainerBecomeNotReadyTransition())
-      .addTransition(READY, INIT, STOP, new ContainerStoppedTransition())
-      .addTransition(READY, UPGRADING, UPGRADE, new UpgradeTransition())
-      .addTransition(READY, EnumSet.of(READY, CANCEL_UPGRADING), CANCEL_UPGRADE,
-          new CancelUpgradeTransition())
-
-      // FROM UPGRADING
-      .addTransition(UPGRADING, EnumSet.of(READY, CANCEL_UPGRADING),
-          CANCEL_UPGRADE, new CancelUpgradeTransition())
-      .addTransition(UPGRADING, EnumSet.of(REINITIALIZED), START,
-          new StartedAfterUpgradeTransition())
-      .addTransition(UPGRADING, UPGRADING, STOP,
-          new StoppedAfterUpgradeTransition())
-
-      // FROM CANCEL_UPGRADING
-      .addTransition(CANCEL_UPGRADING, EnumSet.of(CANCEL_UPGRADING,
-          REINITIALIZED), START, new StartedAfterUpgradeTransition())
-      .addTransition(CANCEL_UPGRADING, EnumSet.of(CANCEL_UPGRADING, INIT),
-          STOP, new StoppedAfterCancelUpgradeTransition())
-
-      // FROM REINITIALIZED
-      .addTransition(REINITIALIZED, CANCEL_UPGRADING, CANCEL_UPGRADE,
-          new CancelledAfterReinitTransition())
-      .addTransition(REINITIALIZED, READY, BECOME_READY,
-           new ContainerBecomeReadyTransition(true))
-      .addTransition(REINITIALIZED, REINITIALIZED, STOP,
-          new StoppedAfterUpgradeTransition())
-      .installTopology();
-
-  public ComponentInstance(Component component,
-      ComponentInstanceId compInstanceId) {
-    this.stateMachine = stateMachineFactory.make(this);
-    this.component = component;
-    this.compInstanceId = compInstanceId;
-    this.scheduler = component.getScheduler();
-    this.yarnRegistryOperations =
-        component.getScheduler().getYarnRegistryOperations();
-    this.serviceTimelinePublisher =
-        component.getScheduler().getServiceTimelinePublisher();
-    if (YarnConfiguration
-        .timelineServiceV2Enabled(component.getScheduler().getConfig())) {
-      this.timelineServiceEnabled = true;
-    }
-    ReentrantReadWriteLock lock = new ReentrantReadWriteLock();
-    this.readLock = lock.readLock();
-    this.writeLock = lock.writeLock();
-    this.fs = scheduler.getContext().fs.getFileSystem();
-  }
-
-  private static class ContainerStartedTransition extends  BaseTransition {
-    @Override public void transition(ComponentInstance compInstance,
-        ComponentInstanceEvent event) {
-      // Query container status for ip and host
-      compInstance.initializeStatusRetriever(event, 0);
-      compInstance.initializeLocalizationStatusRetriever(
-          event.getContainerId());
-
-      long containerStartTime = System.currentTimeMillis();
-      try {
-        ContainerTokenIdentifier containerTokenIdentifier = BuilderUtils
-            .newContainerTokenIdentifier(compInstance.getContainer()
-                .getContainerToken());
-        containerStartTime = containerTokenIdentifier.getCreationTime();
-      } catch (Exception e) {
-        LOG.info("Could not get container creation time, using current time");
-      }
-      org.apache.hadoop.yarn.service.api.records.Container container =
-          new org.apache.hadoop.yarn.service.api.records.Container();
-      container.setId(event.getContainerId().toString());
-      container.setLaunchTime(new Date(containerStartTime));
-      container.setState(ContainerState.RUNNING_BUT_UNREADY);
-      container.setBareHost(compInstance.getNodeId().getHost());
-      container.setComponentInstanceName(compInstance.getCompInstanceName());
-      if (compInstance.containerSpec != null) {
-        // remove the previous container.
-        compInstance.getCompSpec().removeContainer(compInstance.containerSpec);
-      }
-      compInstance.containerSpec = container;
-      compInstance.getCompSpec().addContainer(container);
-      compInstance.containerStartedTime = containerStartTime;
-      compInstance.component.incRunningContainers();
-      compInstance.serviceVersion = compInstance.scheduler.getApp()
-          .getVersion();
-
-      if (compInstance.timelineServiceEnabled) {
-        compInstance.serviceTimelinePublisher
-            .componentInstanceStarted(container, compInstance);
-      }
-    }
-  }
-
-  private static class ContainerBecomeReadyTransition extends BaseTransition {
-    private final boolean isReinitialized;
-
-    ContainerBecomeReadyTransition(boolean isReinitialized) {
-      this.isReinitialized = isReinitialized;
-    }
-
-    @Override
-    public void transition(ComponentInstance compInstance,
-        ComponentInstanceEvent event) {
-      compInstance.setContainerState(ContainerState.READY);
-      if (!isReinitialized) {
-        compInstance.component.incContainersReady(true);
-      } else {
-        compInstance.component.incContainersReady(false);
-        ComponentEvent checkState = new ComponentEvent(
-            compInstance.component.getName(), ComponentEventType.CHECK_STABLE);
-        compInstance.scheduler.getDispatcher().getEventHandler().handle(
-            checkState);
-      }
-      compInstance.postContainerReady();
-    }
-  }
-
-  private static class StartedAfterUpgradeTransition implements
-      MultipleArcTransition<ComponentInstance, ComponentInstanceEvent,
-          ComponentInstanceState> {
-
-    @Override
-    public ComponentInstanceState transition(ComponentInstance instance,
-        ComponentInstanceEvent event) {
-
-      if (instance.pendingCancelUpgrade) {
-        // cancellation of upgrade was triggered before the upgrade was
-        // finished.
-        LOG.info("{} received started but cancellation pending",
-            event.getContainerId());
-        instance.upgradeInProgress.set(true);
-        instance.cancelUpgrade();
-        instance.pendingCancelUpgrade = false;
-        return instance.getState();
-      }
-
-      instance.upgradeInProgress.set(false);
-      instance.setContainerState(ContainerState.RUNNING_BUT_UNREADY);
-      if (instance.component.getProbe() != null &&
-          instance.component.getProbe() instanceof DefaultProbe) {
-        instance.initializeStatusRetriever(event, 30);
-      } else {
-        instance.initializeStatusRetriever(event, 0);
-      }
-      instance.initializeLocalizationStatusRetriever(event.getContainerId());
-
-      Component.UpgradeStatus status = instance.getState().equals(UPGRADING) ?
-          instance.component.getUpgradeStatus() :
-          instance.component.getCancelUpgradeStatus();
-      status.decContainersThatNeedUpgrade();
-
-      instance.serviceVersion = status.getTargetVersion();
-      return ComponentInstanceState.REINITIALIZED;
-    }
-  }
-
-  private void postContainerReady() {
-    if (timelineServiceEnabled) {
-      serviceTimelinePublisher.componentInstanceBecomeReady(containerSpec);
-    }
-    try {
-      List<org.apache.hadoop.yarn.api.records.LocalizationStatus>
-          statusesFromNM = scheduler.getNmClient().getClient()
-          .getLocalizationStatuses(container.getId(), container.getNodeId());
-      if (statusesFromNM != null && !statusesFromNM.isEmpty()) {
-        updateLocalizationStatuses(statusesFromNM);
-      }
-    } catch (YarnException | IOException e) {
-      LOG.warn("{} failure getting localization statuses", container.getId(),
-          e);
-    }
-  }
-
-  private static class ContainerBecomeNotReadyTransition extends BaseTransition {
-    @Override
-    public void transition(ComponentInstance compInstance,
-        ComponentInstanceEvent event) {
-      compInstance.setContainerState(ContainerState.RUNNING_BUT_UNREADY);
-      compInstance.component.decContainersReady(true);
-    }
-  }
-
-  @VisibleForTesting
-  static void handleComponentInstanceRelaunch(ComponentInstance compInstance,
-      ComponentInstanceEvent event, boolean failureBeforeLaunch,
-      String containerDiag) {
-    Component comp = compInstance.getComponent();
-
-    // Do we need to relaunch the service?
-    boolean hasContainerFailed = failureBeforeLaunch || hasContainerFailed(
-        event.getStatus());
-
-    ComponentRestartPolicy restartPolicy = comp.getRestartPolicyHandler();
-    ContainerState containerState =
-        hasContainerFailed ? ContainerState.FAILED : ContainerState.SUCCEEDED;
-
-    if (compInstance.getContainerSpec() != null) {
-      compInstance.getContainerSpec().setState(containerState);
-    }
-
-    if (restartPolicy.shouldRelaunchInstance(compInstance, event.getStatus())) {
-      // re-ask the failed container.
-      comp.requestContainers(1);
-      comp.reInsertPendingInstance(compInstance);
-
-      StringBuilder builder = new StringBuilder();
-      builder.append(compInstance.getCompInstanceId()).append(": ")
-          .append(event.getContainerId()).append(
-              " completed. Reinsert back to pending list and requested ")
-          .append("a new container.").append(System.lineSeparator())
-          .append(" exitStatus=").append(
-              failureBeforeLaunch || event.getStatus() == null ? null :
-                  event.getStatus().getExitStatus())
-          .append(", diagnostics=")
-          .append(failureBeforeLaunch ?
-              FAILED_BEFORE_LAUNCH_DIAG :
-              (event.getStatus() != null ? event.getStatus().getDiagnostics() :
-                  UPGRADE_FAILED));
-
-      if (event.getStatus() != null && event.getStatus().getExitStatus() != 0) {
-        LOG.error(builder.toString());
-      } else{
-        LOG.info(builder.toString());
-      }
-
-      if (compInstance.timelineServiceEnabled) {
-        // record in ATS
-        LOG.info("Publishing component instance status {} {} ",
-            event.getContainerId(), containerState);
-        int exitStatus = failureBeforeLaunch || event.getStatus() == null ?
-            ContainerExitStatus.INVALID : event.getStatus().getExitStatus();
-        compInstance.serviceTimelinePublisher.componentInstanceFinished(
-            event.getContainerId(), exitStatus,
-            containerState, containerDiag);
-      }
-
-    } else{
-      // When no relaunch, update component's #succeeded/#failed
-      // instances.
-      if (hasContainerFailed) {
-        comp.markAsFailed(compInstance);
-      } else{
-        comp.markAsSucceeded(compInstance);
-      }
-
-      if (compInstance.timelineServiceEnabled) {
-        // record in ATS
-        int exitStatus = failureBeforeLaunch || event.getStatus() == null ?
-            ContainerExitStatus.INVALID : event.getStatus().getExitStatus();
-        compInstance.serviceTimelinePublisher.componentInstanceFinished(
-            event.getContainerId(), exitStatus,
-            containerState, containerDiag);
-      }
-
-      LOG.info(compInstance.getCompInstanceId() + (!hasContainerFailed ?
-          " succeeded" :
-          " failed") + " without retry, exitStatus=" + event.getStatus());
-      comp.getScheduler().terminateServiceIfNeeded(comp);
-    }
-  }
-
-  public static boolean hasContainerFailed(ContainerStatus containerStatus) {
-    //Mark conainer as failed if we cant get its exit status i.e null?
-    return containerStatus == null || containerStatus
-        .getExitStatus() != ContainerExitStatus.SUCCESS;
-  }
-
-  private static class ContainerStoppedTransition extends  BaseTransition {
-    // whether the container failed before launched by AM or not.
-    boolean failedBeforeLaunching = false;
-    public ContainerStoppedTransition(boolean failedBeforeLaunching) {
-      this.failedBeforeLaunching = failedBeforeLaunching;
-    }
-
-    public ContainerStoppedTransition() {
-      this(false);
-    }
-
-    @Override
-    public void transition(ComponentInstance compInstance,
-        ComponentInstanceEvent event) {
-
-      Component comp = compInstance.component;
-      ContainerStatus status = event.getStatus();
-      // status is not available when upgrade fails
-      String containerDiag = compInstance.getCompInstanceId() + ": " + (
-          failedBeforeLaunching ? FAILED_BEFORE_LAUNCH_DIAG :
-              (status != null ? status.getDiagnostics() : UPGRADE_FAILED));
-      compInstance.diagnostics.append(containerDiag + System.lineSeparator());
-      compInstance.cancelContainerStatusRetriever();
-      compInstance.cancelLclRetriever();
-
-      if (compInstance.getState().equals(READY)) {
-        compInstance.component.decContainersReady(true);
-      }
-      compInstance.component.decRunningContainers();
-      // Should we fail (terminate) the service?
-      boolean shouldFailService = false;
-
-      final ServiceScheduler scheduler = comp.getScheduler();
-      scheduler.getAmRMClient().releaseAssignedContainer(
-          event.getContainerId());
-
-      // Check if it exceeds the failure threshold, but only if health threshold
-      // monitor is not enabled
-      if (!comp.isHealthThresholdMonitorEnabled()
-          && comp.currentContainerFailure.get()
-          > comp.maxContainerFailurePerComp) {
-        String exitDiag = MessageFormat.format(
-            "[COMPONENT {0}]: Failed {1} times, exceeded the limit - {2}. "
-                + "Shutting down now... "
-                + System.lineSeparator(), comp.getName(),
-            comp.currentContainerFailure.get(),
-            comp.maxContainerFailurePerComp);
-        compInstance.diagnostics.append(exitDiag);
-        // append to global diagnostics that will be reported to RM.
-        scheduler.getDiagnostics().append(containerDiag);
-        scheduler.getDiagnostics().append(exitDiag);
-        LOG.warn(exitDiag);
-
-        compInstance.getContainerSpec().setState(ContainerState.FAILED);
-        comp.getComponentSpec().setState(ComponentState.FAILED);
-        comp.getScheduler().getApp().setState(ServiceState.FAILED);
-
-        if (compInstance.timelineServiceEnabled) {
-          // record in ATS
-          compInstance.scheduler.getServiceTimelinePublisher()
-              .componentInstanceFinished(compInstance.getContainer().getId(),
-                  failedBeforeLaunching || status == null ? -1 :
-                      status.getExitStatus(),
-                  ContainerState.FAILED, containerDiag);
-
-          // mark other component-instances/containers as STOPPED
-          for (ContainerId containerId : scheduler.getLiveInstances()
-              .keySet()) {
-            if (!compInstance.container.getId().equals(containerId)
-                && !isFinalState(compInstance.getContainerSpec().getState())) {
-              compInstance.getContainerSpec().setState(ContainerState.STOPPED);
-              compInstance.scheduler.getServiceTimelinePublisher()
-                  .componentInstanceFinished(containerId,
-                      KILLED_AFTER_APP_COMPLETION, ContainerState.STOPPED,
-                      scheduler.getDiagnostics().toString());
-            }
-          }
-
-          compInstance.scheduler.getServiceTimelinePublisher()
-              .componentFinished(comp.getComponentSpec(), ComponentState.FAILED,
-                  scheduler.getSystemClock().getTime());
-
-          compInstance.scheduler.getServiceTimelinePublisher()
-              .serviceAttemptUnregistered(comp.getContext(),
-                  FinalApplicationStatus.FAILED,
-                  scheduler.getDiagnostics().toString());
-        }
-
-        shouldFailService = true;
-      }
-
-      if (!failedBeforeLaunching) {
-        // clean up registry
-        // If the container failed before launching, no need to cleanup
-        // registry,
-        // because it was not registered before.
-        // hdfs dir content will be overwritten when a new container gets
-        // started,
-        // so no need remove.
-        compInstance.scheduler.executorService.submit(
-            () -> compInstance.cleanupRegistry(event.getContainerId()));
-      }
-
-      // remove the failed ContainerId -> CompInstance mapping
-      scheduler.removeLiveCompInstance(event.getContainerId());
-
-      // According to component restart policy, handle container restart
-      // or finish the service (if all components finished)
-      handleComponentInstanceRelaunch(compInstance, event,
-          failedBeforeLaunching, containerDiag);
-
-      if (shouldFailService) {
-        scheduler.getTerminationHandler().terminate(-1);
-      }
-    }
-  }
-
-  public static boolean isFinalState(ContainerState state) {
-    return ContainerState.FAILED.equals(state) || ContainerState.STOPPED
-        .equals(state) || ContainerState.SUCCEEDED.equals(state);
-  }
-
-  private static class StoppedAfterUpgradeTransition extends
-      BaseTransition {
-
-    @Override
-    public void transition(ComponentInstance instance,
-        ComponentInstanceEvent event) {
-      instance.component.getUpgradeStatus().decContainersThatNeedUpgrade();
-      instance.component.decRunningContainers();
-
-      final ServiceScheduler scheduler = instance.component.getScheduler();
-      scheduler.getAmRMClient().releaseAssignedContainer(
-          event.getContainerId());
-      instance.scheduler.executorService.submit(
-          () -> instance.cleanupRegistry(event.getContainerId()));
-      scheduler.removeLiveCompInstance(event.getContainerId());
-      instance.component.getUpgradeStatus().containerFailedUpgrade();
-      instance.setContainerState(ContainerState.FAILED_UPGRADE);
-      instance.upgradeInProgress.set(false);
-    }
-  }
-
-  private static class StoppedAfterCancelUpgradeTransition implements
-      MultipleArcTransition<ComponentInstance, ComponentInstanceEvent,
-          ComponentInstanceState> {
-
-    private ContainerStoppedTransition stoppedTransition =
-        new ContainerStoppedTransition();
-
-    @Override
-    public ComponentInstanceState transition(ComponentInstance instance,
-        ComponentInstanceEvent event) {
-      if (instance.pendingCancelUpgrade) {
-        // cancellation of upgrade was triggered before the upgrade was
-        // finished.
-        LOG.info("{} received stopped but cancellation pending",
-            event.getContainerId());
-        instance.upgradeInProgress.set(true);
-        instance.cancelUpgrade();
-        instance.pendingCancelUpgrade = false;
-        return instance.getState();
-      }
-
-      // When upgrade is cancelled, and container re-init fails
-      instance.component.getCancelUpgradeStatus()
-          .decContainersThatNeedUpgrade();
-      instance.upgradeInProgress.set(false);
-      stoppedTransition.transition(instance, event);
-      return ComponentInstanceState.INIT;
-    }
-  }
-
-  private static class UpgradeTransition extends BaseTransition {
-
-    @Override
-    public void transition(ComponentInstance instance,
-        ComponentInstanceEvent event) {
-      if (!instance.component.getCancelUpgradeStatus().isCompleted()) {
-        // last check to see if cancellation was triggered. The component may
-        // have processed the cancel upgrade event but the instance doesn't know
-        // it yet. If cancellation has been triggered then no point in
-        // upgrading.
-        return;
-      }
-      instance.upgradeInProgress.set(true);
-      instance.setContainerState(ContainerState.UPGRADING);
-      instance.component.decContainersReady(false);
-
-      Component.UpgradeStatus upgradeStatus = instance.component.
-          getUpgradeStatus();
-      instance.reInitHelper(upgradeStatus);
-    }
-  }
-
-  private static class CancelledAfterReinitTransition extends BaseTransition {
-    @Override
-    public void transition(ComponentInstance instance,
-        ComponentInstanceEvent event) {
-      if (instance.upgradeInProgress.compareAndSet(false, true)) {
-        instance.cancelUpgrade();
-      } else {
-        LOG.info("{} pending cancellation", event.getContainerId());
-        instance.pendingCancelUpgrade = true;
-      }
-    }
-  }
-
-  private static class CancelUpgradeTransition implements
-      MultipleArcTransition<ComponentInstance, ComponentInstanceEvent,
-          ComponentInstanceState> {
-
-    @Override
-    public ComponentInstanceState transition(ComponentInstance instance,
-        ComponentInstanceEvent event) {
-      if (instance.upgradeInProgress.compareAndSet(false, true)) {
-
-        Component.UpgradeStatus cancelStatus = instance.component
-            .getCancelUpgradeStatus();
-
-        if (instance.getServiceVersion().equals(
-            cancelStatus.getTargetVersion())) {
-          // previous upgrade didn't happen so just go back to READY
-          LOG.info("{} nothing to cancel", event.getContainerId());
-          cancelStatus.decContainersThatNeedUpgrade();
-          instance.setContainerState(ContainerState.READY);
-          ComponentEvent checkState = new ComponentEvent(
-              instance.component.getName(), ComponentEventType.CHECK_STABLE);
-          instance.scheduler.getDispatcher().getEventHandler()
-              .handle(checkState);
-          return ComponentInstanceState.READY;
-        } else {
-          instance.component.decContainersReady(false);
-          instance.cancelUpgrade();
-        }
-      } else {
-        LOG.info("{} pending cancellation", event.getContainerId());
-        instance.pendingCancelUpgrade = true;
-      }
-      return ComponentInstanceState.CANCEL_UPGRADING;
-    }
-  }
-
-  private void cancelUpgrade() {
-    LOG.info("{} cancelling upgrade", container.getId());
-    setContainerState(ContainerState.UPGRADING);
-    Component.UpgradeStatus cancelStatus = component.getCancelUpgradeStatus();
-    reInitHelper(cancelStatus);
-  }
-
-  private void reInitHelper(Component.UpgradeStatus upgradeStatus) {
-    cancelContainerStatusRetriever();
-    cancelLclRetriever();
-    setContainerStatus(container.getId(), null);
-    scheduler.executorService.submit(() -> cleanupRegistry(container.getId()));
-    Future<ProviderService.ResolvedLaunchParams> launchParamsFuture =
-        scheduler.getContainerLaunchService()
-        .reInitCompInstance(scheduler.getApp(), this,
-            this.container, this.component.createLaunchContext(
-                upgradeStatus.getTargetSpec(),
-                upgradeStatus.getTargetVersion()));
-    updateResolvedLaunchParams(launchParamsFuture);
-  }
-
-  private void initializeStatusRetriever(ComponentInstanceEvent event,
-      long initialDelay) {
-    boolean cancelOnSuccess = true;
-    if (getCompSpec().getArtifact() != null &&
-        getCompSpec().getArtifact().getType() == Artifact.TypeEnum.DOCKER) {
-      // A docker container might get a different IP if the container is
-      // relaunched by the NM, so we need to keep checking the status.
-      // This is a temporary fix until the NM provides a callback for
-      // container relaunch (see YARN-8265).
-      cancelOnSuccess = false;
-    }
-    LOG.info("{} retrieve status after {}", compInstanceId, initialDelay);
-    containerStatusFuture =
-        scheduler.executorService.scheduleAtFixedRate(
-            new ContainerStatusRetriever(scheduler, event.getContainerId(),
-                this, cancelOnSuccess), initialDelay, 1,
-            TimeUnit.SECONDS);
-  }
-
-  public ComponentInstanceState getState() {
-    this.readLock.lock();
-
-    try {
-      return this.stateMachine.getCurrentState();
-    } finally {
-      this.readLock.unlock();
-    }
-  }
-
-  /**
-   * Returns the version of service at which the instance is at.
-   */
-  public String getServiceVersion() {
-    this.readLock.lock();
-    try {
-      return this.serviceVersion;
-    } finally {
-      this.readLock.unlock();
-    }
-  }
-
-  /**
-   * Returns the state of the container in the container spec.
-   */
-  public ContainerState getContainerState() {
-    this.readLock.lock();
-    try {
-      return this.containerSpec.getState();
-    } finally {
-      this.readLock.unlock();
-    }
-  }
-
-  /**
-   * Sets the state of the container in the container spec. It is write
-   * protected.
-   *
-   * @param state container state
-   */
-  public void setContainerState(ContainerState state) {
-    this.writeLock.lock();
-    try {
-      ContainerState curState = containerSpec.getState();
-      if (!curState.equals(state)) {
-        containerSpec.setState(state);
-        LOG.info("{} spec state state changed from {} -> {}",
-            getCompInstanceId(), curState, state);
-      }
-    } finally {
-      this.writeLock.unlock();
-    }
-  }
-
-  @Override
-  public void handle(ComponentInstanceEvent event) {
-    writeLock.lock();
-    try {
-      ComponentInstanceState oldState = getState();
-      try {
-        stateMachine.doTransition(event.getType(), event);
-      } catch (InvalidStateTransitionException e) {
-        LOG.error(getCompInstanceId() + ": Invalid event " + event.getType() +
-            " at " + oldState, e);
-      }
-      if (oldState != getState()) {
-        LOG.info(getCompInstanceId() + " Transitioned from " + oldState + " to "
-            + getState() + " on " + event.getType() + " event");
-      }
-    } finally {
-      writeLock.unlock();
-    }
-  }
-
-  public void setContainer(Container container) {
-    this.container = container;
-    this.compInstanceId.setContainerId(container.getId());
-  }
-
-  public String getCompInstanceName() {
-    return compInstanceId.getCompInstanceName();
-  }
-
-  @VisibleForTesting
-  void updateLocalizationStatuses(
-      List<org.apache.hadoop.yarn.api.records.LocalizationStatus> statuses) {
-    Map<String, String> resourcesCpy = new HashMap<>();
-    readLock.lock();
-    try {
-      if (resolvedParams == null || resolvedParams.didLaunchFail() ||
-          resolvedParams.getResolvedRsrcPaths() == null ||
-          resolvedParams.getResolvedRsrcPaths().isEmpty()) {
-        cancelLclRetriever();
-        return;
-      }
-      resourcesCpy.putAll(resolvedParams.getResolvedRsrcPaths());
-    } finally {
-      readLock.unlock();
-    }
-    boolean allCompleted = true;
-    Map<String, LocalizationStatus> fromNM = new HashMap<>();
-    statuses.forEach(statusFromNM -> {
-      LocalizationStatus lstatus = new LocalizationStatus()
-          .destFile(statusFromNM.getResourceKey())
-          .diagnostics(statusFromNM.getDiagnostics())
-          .state(statusFromNM.getLocalizationState());
-      fromNM.put(statusFromNM.getResourceKey(), lstatus);
-    });
-
-    for (String resourceKey : resourcesCpy.keySet()) {
-      LocalizationStatus lstatus = fromNM.get(resourceKey);
-      if (lstatus == null ||
-          lstatus.getState().equals(LocalizationState.PENDING)) {
-        allCompleted = false;
-        break;
-      }
-    }
-
-    List<LocalizationStatus> statusList = new ArrayList<>();
-    statusList.addAll(fromNM.values());
-    this.containerSpec.setLocalizationStatuses(statusList);
-    if (allCompleted) {
-      cancelLclRetriever();
-    }
-  }
-
-  public void updateResolvedLaunchParams(
-      Future<ProviderService.ResolvedLaunchParams> future) {
-    writeLock.lock();
-    try {
-      this.resolvedParams = future.get();
-    } catch (InterruptedException | ExecutionException e) {
-      LOG.error("{} updating resolved params", getCompInstanceId(), e);
-    } finally {
-      writeLock.unlock();
-    }
-  }
-
-  public ContainerStatus getContainerStatus() {
-    readLock.lock();
-    try {
-      return status;
-    } finally {
-      readLock.unlock();
-    }
-  }
-
-  private void setContainerStatus(ContainerId containerId,
-      ContainerStatus latestStatus) {
-    writeLock.lock();
-    try {
-      this.status = latestStatus;
-      org.apache.hadoop.yarn.service.api.records.Container containerRec =
-          getCompSpec().getContainer(containerId.toString());
-
-      if (containerRec != null) {
-        if (latestStatus != null) {
-          containerRec.setIp(StringUtils.join(",", latestStatus.getIPs()));
-          containerRec.setHostname(latestStatus.getHost());
-        } else {
-          containerRec.setIp(null);
-          containerRec.setHostname(null);
-        }
-      }
-    } finally {
-      writeLock.unlock();
-    }
-  }
-
-  public void updateContainerStatus(ContainerStatus status) {
-    org.apache.hadoop.yarn.service.api.records.Container containerRec =
-        getCompSpec().getContainer(status.getContainerId().toString());
-    boolean doRegistryUpdate = true;
-    if (containerRec != null) {
-      String existingIP = containerRec.getIp();
-      String newIP = StringUtils.join(",", status.getIPs());
-      if (existingIP != null && newIP.equals(existingIP)) {
-        doRegistryUpdate = false;
-      }
-    }
-    ObjectMapper mapper = new ObjectMapper();
-    try {
-      Map<String, List<Map<String, String>>> ports = null;
-      ports = mapper.readValue(status.getExposedPorts(),
-          new TypeReference<Map<String, List<Map<String, String>>>>(){});
-      container.setExposedPorts(ports);
-    } catch (IOException e) {
-      LOG.warn("Unable to process container ports mapping: {}", e);
-    }
-    setContainerStatus(status.getContainerId(), status);
-    if (containerRec != null && timelineServiceEnabled && doRegistryUpdate) {
-      serviceTimelinePublisher.componentInstanceIPHostUpdated(containerRec);
-    }
-
-    if (doRegistryUpdate) {
-      cleanupRegistry(status.getContainerId());
-      LOG.info(
-          getCompInstanceId() + " new IP = " + status.getIPs() + ", host = "
-              + status.getHost() + ", updating registry");
-      updateServiceRecord(yarnRegistryOperations, status);
-    }
-  }
-
-  public String getCompName() {
-    return compInstanceId.getCompName();
-  }
-
-  public void setCompInstanceDir(Path dir) {
-    this.compInstanceDir = dir;
-  }
-
-  public Component getComponent() {
-    return component;
-  }
-
-  public Container getContainer() {
-    return container;
-  }
-
-  public ComponentInstanceId getCompInstanceId() {
-    return compInstanceId;
-  }
-
-  public NodeId getNodeId() {
-    return this.container.getNodeId();
-  }
-
-  private org.apache.hadoop.yarn.service.api.records.Component getCompSpec() {
-    return component.getComponentSpec();
-  }
-
-  private static class BaseTransition implements
-      SingleArcTransition<ComponentInstance, ComponentInstanceEvent> {
-
-    @Override public void transition(ComponentInstance compInstance,
-        ComponentInstanceEvent event) {
-    }
-  }
-
-  public ProbeStatus ping() {
-    if (component.getProbe() == null) {
-      ProbeStatus status = new ProbeStatus();
-      status.setSuccess(true);
-      return status;
-    }
-    return component.getProbe().ping(this);
-  }
-
-  // Write service record into registry
-  private  void updateServiceRecord(
-      YarnRegistryViewForProviders yarnRegistry, ContainerStatus status) {
-    ServiceRecord record = new ServiceRecord();
-    String containerId = status.getContainerId().toString();
-    record.set(YARN_ID, containerId);
-    record.description = getCompInstanceName();
-    record.set(YARN_PERSISTENCE, PersistencePolicies.CONTAINER);
-    record.set(YARN_IP, status.getIPs().get(0));
-    record.set(YARN_HOSTNAME, status.getHost());
-    record.set(YARN_COMPONENT, component.getName());
-    try {
-      yarnRegistry
-          .putComponent(RegistryPathUtils.encodeYarnID(containerId), record);
-    } catch (IOException e) {
-      LOG.error(
-          "Failed to update service record in registry: " + containerId + "");
-    }
-  }
-
-  // Called when user flexed down the container and ContainerStoppedTransition
-  // is not executed in this case.
-  // Release the container, dec running,
-  // cleanup registry, hdfs dir, and send record to ATS
-  public void destroy() {
-    LOG.info(getCompInstanceId() + ": Flexed down by user, destroying.");
-    diagnostics.append(getCompInstanceId() + ": Flexed down by user");
-
-    // update metrics
-    if (getState() == STARTED) {
-      component.decRunningContainers();
-    }
-    if (getState() == READY) {
-      component.decContainersReady(true);
-      component.decRunningContainers();
-    }
-    getCompSpec().removeContainer(containerSpec);
-
-    if (container == null) {
-      LOG.info(getCompInstanceId() + " no container is assigned when " +
-          "destroying");
-      return;
-    }
-
-    ContainerId containerId = container.getId();
-    scheduler.removeLiveCompInstance(containerId);
-    component.getScheduler().getAmRMClient()
-        .releaseAssignedContainer(containerId);
-
-    if (timelineServiceEnabled) {
-      serviceTimelinePublisher.componentInstanceFinished(containerId,
-          KILLED_BY_APPMASTER, ContainerState.STOPPED, diagnostics.toString());
-    }
-    cancelContainerStatusRetriever();
-    scheduler.executorService.submit(() ->
-        cleanupRegistryAndCompHdfsDir(containerId));
-    cancelLclRetriever();
-  }
-
-  private void cleanupRegistry(ContainerId containerId) {
-    String cid = RegistryPathUtils.encodeYarnID(containerId.toString());
-    try {
-       yarnRegistryOperations.deleteComponent(getCompInstanceId(), cid);
-    } catch (IOException e) {
-      LOG.error(getCompInstanceId() + ": Failed to delete registry", e);
-    }
-  }
-
-  //TODO Maybe have a dedicated cleanup service.
-  public void cleanupRegistryAndCompHdfsDir(ContainerId containerId) {
-    cleanupRegistry(containerId);
-    try {
-      if (compInstanceDir != null && fs.exists(compInstanceDir)) {
-        boolean deleted = fs.delete(compInstanceDir, true);
-        if (!deleted) {
-          LOG.error(getCompInstanceId()
-              + ": Failed to delete component instance dir: "
-              + compInstanceDir);
-        } else {
-          LOG.info(getCompInstanceId() + ": Deleted component instance dir: "
-              + compInstanceDir);
-        }
-      }
-    } catch (IOException e) {
-      LOG.warn(getCompInstanceId() + ": Failed to delete directory", e);
-    }
-  }
-
-  // Query container status until ip and hostname are available and update
-  // the service record into registry service
-  private static class ContainerStatusRetriever implements Runnable {
-    private ContainerId containerId;
-    private NodeId nodeId;
-    private NMClient nmClient;
-    private ComponentInstance instance;
-    private boolean cancelOnSuccess;
-    ContainerStatusRetriever(ServiceScheduler scheduler,
-        ContainerId containerId, ComponentInstance instance, boolean
-        cancelOnSuccess) {
-      this.containerId = containerId;
-      this.nodeId = instance.getNodeId();
-      this.nmClient = scheduler.getNmClient().getClient();
-      this.instance = instance;
-      this.cancelOnSuccess = cancelOnSuccess;
-    }
-    @Override public void run() {
-      ContainerStatus status = null;
-      try {
-        status = nmClient.getContainerStatus(containerId, nodeId);
-      } catch (Exception e) {
-        if (e instanceof YarnException) {
-          throw new YarnRuntimeException(
-              instance.compInstanceId + " Failed to get container status on "
-                  + nodeId + " , cancelling.", e);
-        }
-        LOG.error(instance.compInstanceId + " Failed to get container status on "
-            + nodeId + ", will try again", e);
-        return;
-      }
-      if (ServiceUtils.isEmpty(status.getIPs()) || ServiceUtils
-          .isUnset(status.getHost())) {
-        return;
-      }
-      instance.updateContainerStatus(status);
-      if (cancelOnSuccess) {
-        LOG.info(
-            instance.compInstanceId + " IP = " + status.getIPs() + ", host = "
-                + status.getHost() + ", cancel container status retriever");
-        instance.containerStatusFuture.cancel(false);
-      }
-    }
-  }
-
-  private void cancelContainerStatusRetriever() {
-    if (containerStatusFuture != null && !containerStatusFuture.isDone()) {
-      containerStatusFuture.cancel(true);
-    }
-  }
-
-  private static class LocalizationStatusRetriever implements Runnable {
-    private ContainerId containerId;
-    private NodeId nodeId;
-    private NMClient nmClient;
-    private ComponentInstance instance;
-
-    LocalizationStatusRetriever(ServiceScheduler scheduler,
-        ContainerId containerId, ComponentInstance instance) {
-      this.nmClient = scheduler.getNmClient().getClient();
-      this.containerId = containerId;
-      this.instance = instance;
-      this.nodeId = instance.getNodeId();
-    }
-
-    @Override
-    public void run() {
-      List<org.apache.hadoop.yarn.api.records.LocalizationStatus>
-          statusesFromNM = null;
-      try {
-        statusesFromNM = nmClient.getLocalizationStatuses(containerId,
-            nodeId);
-      } catch (YarnException | IOException e) {
-        LOG.error("{} Failed to get localization statuses for {} {} ",
-            instance.compInstanceId, nodeId, containerId, e);
-      }
-      if (statusesFromNM != null && !statusesFromNM.isEmpty()) {
-        instance.updateLocalizationStatuses(statusesFromNM);
-      }
-    }
-  }
-
-  private void initializeLocalizationStatusRetriever(
-      ContainerId containerId) {
-    LOG.info("{} retrieve localization statuses", compInstanceId);
-    lclizationRetrieverFuture = scheduler.executorService.scheduleAtFixedRate(
-        new LocalizationStatusRetriever(scheduler, containerId, this),
-        0, 1, TimeUnit.SECONDS
-    );
-  }
-
-  private void cancelLclRetriever() {
-    if (lclizationRetrieverFuture != null &&
-        !lclizationRetrieverFuture.isDone()) {
-      LOG.info("{} cancelling localization retriever", compInstanceId);
-      lclizationRetrieverFuture.cancel(true);
-    }
-  }
-
-  @VisibleForTesting
-  boolean isLclRetrieverActive() {
-    return lclizationRetrieverFuture != null &&
-        !lclizationRetrieverFuture.isCancelled()
-         && !lclizationRetrieverFuture.isDone();
-  }
-
-  public String getHostname() {
-    return getCompInstanceName() + getComponent().getHostnameSuffix();
-  }
-
-  @Override
-  public int compareTo(ComponentInstance to) {
-    return getCompInstanceId().compareTo(to.getCompInstanceId());
-  }
-
-  @Override public boolean equals(Object o) {
-    if (this == o)
-      return true;
-    if (o == null || getClass() != o.getClass())
-      return false;
-
-    ComponentInstance instance = (ComponentInstance) o;
-
-    if (containerStartedTime != instance.containerStartedTime)
-      return false;
-    return compInstanceId.equals(instance.compInstanceId);
-  }
-
-  @Override public int hashCode() {
-    int result = compInstanceId.hashCode();
-    result = 31 * result + (int) (containerStartedTime ^ (containerStartedTime
-        >>> 32));
-    return result;
-  }
-
-  /**
-   * Returns container spec.
-   */
-  public org.apache.hadoop.yarn.service.api.records
-      .Container getContainerSpec() {
-    readLock.lock();
-    try {
-      return containerSpec;
-    } finally {
-      readLock.unlock();
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstanceEvent.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstanceEvent.java
deleted file mode 100644
index f88252618c3..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstanceEvent.java
+++ /dev/null
@@ -1,60 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.component.instance;
-
-import org.apache.hadoop.util.Preconditions;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.api.records.ContainerStatus;
-import org.apache.hadoop.yarn.event.AbstractEvent;
-
-public class ComponentInstanceEvent
-    extends AbstractEvent<ComponentInstanceEventType> {
-
-  private ContainerId id;
-  private ContainerStatus status;
-  private boolean shouldDestroy = false;
-
-  public ComponentInstanceEvent(ContainerId containerId,
-      ComponentInstanceEventType componentInstanceEventType) {
-    super(componentInstanceEventType);
-    Preconditions.checkNotNull(containerId);
-    this.id = containerId;
-  }
-
-  public ContainerId getContainerId() {
-    return id;
-  }
-
-  public ContainerStatus getStatus() {
-    return this.status;
-  }
-
-  public ComponentInstanceEvent setStatus(ContainerStatus status) {
-    this.status = status;
-    return this;
-  }
-
-  public void setShouldDestroy() {
-    shouldDestroy = true;
-  }
-
-  public boolean shouldDestroy() {
-    return shouldDestroy;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstanceEventType.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstanceEventType.java
deleted file mode 100644
index b9181e5b3a4..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstanceEventType.java
+++ /dev/null
@@ -1,28 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.component.instance;
-
-public enum ComponentInstanceEventType {
-  START,
-  STOP,
-  BECOME_READY,
-  BECOME_NOT_READY,
-  UPGRADE,
-  CANCEL_UPGRADE
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstanceId.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstanceId.java
deleted file mode 100644
index 14387ba0832..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstanceId.java
+++ /dev/null
@@ -1,91 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.component.instance;
-
-import org.apache.hadoop.yarn.api.records.ContainerId;
-
-public class ComponentInstanceId implements Comparable<ComponentInstanceId> {
-
-  private long Id;
-  private String name;
-  private ContainerId containerId;
-
-  public ComponentInstanceId(long id, String name) {
-    Id = id;
-    this.name = name;
-  }
-
-  public long getId() {
-    return Id;
-  }
-
-  public String getCompName() {
-    return name;
-  }
-
-  public String getCompInstanceName() {
-    return getCompName() + "-" + getId();
-  }
-
-  public void setContainerId(ContainerId containerId) {
-    this.containerId = containerId;
-  }
-
-  @Override
-  public String toString() {
-    if (containerId == null) {
-      return "[COMPINSTANCE " + getCompInstanceName() + "]";
-    } else {
-      return "[COMPINSTANCE " + getCompInstanceName() + " : " + containerId + "]";
-    }
-  }
-
-  @Override public boolean equals(Object o) {
-    if (this == o)
-      return true;
-    if (o == null || getClass() != o.getClass())
-      return false;
-
-    ComponentInstanceId that = (ComponentInstanceId) o;
-
-    if (getId() != that.getId())
-      return false;
-    return getCompName() != null ? getCompName().equals(that.getCompName()) :
-        that.getCompName() == null;
-
-  }
-
-  @Override public int hashCode() {
-    int result = (int) (getId() ^ (getId() >>> 32));
-    result = 31 * result + (getCompName() != null ? getCompName().hashCode() : 0);
-    return result;
-  }
-
-  @Override
-  public int compareTo(ComponentInstanceId to) {
-    int delta = this.getCompName().compareTo(to.getCompName());
-    if (delta == 0) {
-      return Long.compare(this.getId(), to.getId());
-    } else if (delta < 0) {
-      return -1;
-    } else {
-      return 1;
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstanceState.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstanceState.java
deleted file mode 100644
index 92b221efdb9..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/component/instance/ComponentInstanceState.java
+++ /dev/null
@@ -1,28 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.component.instance;
-
-public enum ComponentInstanceState {
-  INIT,
-  STARTED,
-  READY,
-  UPGRADING,
-  CANCEL_UPGRADING,
-  REINITIALIZED
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/conf/RestApiConstants.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/conf/RestApiConstants.java
deleted file mode 100644
index 45ad7e4adbb..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/conf/RestApiConstants.java
+++ /dev/null
@@ -1,56 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.conf;
-
-import javax.ws.rs.core.MediaType;
-
-public interface RestApiConstants {
-
-  // Rest endpoints
-  String CONTEXT_ROOT = "/v1";
-  String VERSION = "/services/version";
-  String SERVICE_ROOT_PATH = "/services";
-  String SERVICE_PATH = "/services/{service_name}";
-  String COMPONENT_PATH = "/services/{service_name}/components/{component_name}";
-
-  String COMP_INSTANCE_PATH = SERVICE_PATH +
-      "/component-instances/{component_instance_name}";
-  String COMP_INSTANCE_LONG_PATH = COMPONENT_PATH +
-      "/component-instances/{component_instance_name}";
-  String COMP_INSTANCES = "component-instances";
-  String COMP_INSTANCES_PATH = SERVICE_PATH + "/" + COMP_INSTANCES;
-  String COMPONENTS = "components";
-  String COMPONENTS_PATH = SERVICE_PATH + "/" + COMPONENTS;
-
-  String SERVICE_NAME = "service_name";
-  String COMPONENT_NAME = "component_name";
-  String COMP_INSTANCE_NAME = "component_instance_name";
-
-  String PARAM_COMP_NAME = "componentName";
-  String PARAM_VERSION = "version";
-  String PARAM_CONTAINER_STATE = "containerState";
-
-  String MEDIA_TYPE_JSON_UTF8 = MediaType.APPLICATION_JSON + ";charset=utf-8";
-
-  Long DEFAULT_UNLIMITED_LIFETIME = -1l;
-
-  Integer ERROR_CODE_APP_DOES_NOT_EXIST = 404001;
-  Integer ERROR_CODE_APP_IS_NOT_RUNNING = 404002;
-  Integer ERROR_CODE_APP_SUBMITTED_BUT_NOT_RUNNING_YET = 404003;
-  Integer ERROR_CODE_APP_NAME_INVALID = 404004;
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/conf/SliderExitCodes.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/conf/SliderExitCodes.java
deleted file mode 100644
index ee270cb90dd..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/conf/SliderExitCodes.java
+++ /dev/null
@@ -1,88 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.conf;
-
-import org.apache.hadoop.yarn.service.exceptions.LauncherExitCodes;
-
-public interface SliderExitCodes extends LauncherExitCodes {
-
-  /**
-   * starting point for exit codes; not an exception itself
-   */
-  int _EXIT_CODE_BASE =           64;
-
-  /**
-   * service entered the failed state: {@value}
-   */
-  int EXIT_YARN_SERVICE_FAILED =  65;
-
-  /**
-   * service was killed: {@value}
-   */
-  int EXIT_YARN_SERVICE_KILLED =  66;
-
-  /**
-   * timeout on monitoring client: {@value}
-   */
-  int EXIT_TIMED_OUT =            67;
-
-  /**
-   * service finished with an error: {@value}
-   */
-  int EXIT_YARN_SERVICE_FINISHED_WITH_ERROR = 68;
-
-  /**
-   * the service instance is unknown: {@value}
-   */
-  int EXIT_UNKNOWN_INSTANCE =     69;
-
-  /**
-   * the service instance is in the wrong state for that operation: {@value}
-   */
-  int EXIT_BAD_STATE =            70;
-
-  /**
-   * A spawned master process failed 
-   */
-  int EXIT_PROCESS_FAILED =       71;
-
-  /**
-   * The instance failed -too many containers were
-   * failing or some other threshold was reached
-   */
-  int EXIT_DEPLOYMENT_FAILED =    72;
-
-  /**
-   * The service is live -and the requested operation
-   * does not work if the cluster is running
-   */
-  int EXIT_APPLICATION_IN_USE =   73;
-
-  /**
-   * There already is an service instance of that name
-   * when an attempt is made to create a new instance
-   */
-  int EXIT_INSTANCE_EXISTS =      75;
-
-  /**
-   * Exit code when the configurations in valid/incomplete: {@value}
-   */
-  int EXIT_BAD_CONFIGURATION =    77;
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/conf/YarnServiceConf.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/conf/YarnServiceConf.java
deleted file mode 100644
index d3716b91933..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/conf/YarnServiceConf.java
+++ /dev/null
@@ -1,224 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.conf;
-
-import org.apache.hadoop.yarn.service.api.records.Configuration;
-
-// ALL SERVICE AM PROPERTIES ADDED TO THIS FILE MUST BE DOCUMENTED
-// in the yarn site yarn-service/Configurations.md file.
-public class YarnServiceConf {
-
-  private static final String YARN_SERVICE_PREFIX = "yarn.service.";
-
-  // Retry settings for the ServiceClient to talk to Service AppMaster
-  public static final String CLIENT_AM_RETRY_MAX_WAIT_MS = "yarn.service.client-am.retry.max-wait-ms";
-  public static final long DEFAULT_CLIENT_AM_RETRY_MAX_WAIT_MS = 15 * 60 * 1000;
-  public static final String CLIENT_AM_RETRY_MAX_INTERVAL_MS = "yarn.service.client-am.retry-interval-ms";
-  public static final long DEFAULT_CLIENT_AM_RETRY_MAX_INTERVAL_MS = 2 * 1000;
-
-  // Retry settings for container failures
-  public static final String CONTAINER_RETRY_MAX = "yarn.service.container-failure.retry.max";
-  public static final int DEFAULT_CONTAINER_RETRY_MAX = 10;
-  public static final String CONTAINER_RETRY_INTERVAL = "yarn.service.container-failure.retry-interval-ms";
-  public static final int DEFAULT_CONTAINER_RETRY_INTERVAL = 30000;
-  public static final String CONTAINER_FAILURES_VALIDITY_INTERVAL =
-      "yarn.service.container-failure.validity-interval-ms";
-  public static final long DEFAULT_CONTAINER_FAILURES_VALIDITY_INTERVAL =
-      600000;
-
-  public static final String AM_RESTART_MAX = "yarn.service.am-restart.max-attempts";
-  public static final int DEFAULT_AM_RESTART_MAX = 20;
-  public static final String AM_FAILURES_VALIDITY_INTERVAL =
-      "yarn.service.am-failure.validity-interval-ms";
-  public static final long DEFAULT_AM_FAILURES_VALIDITY_INTERVAL = -1;
-  public static final String AM_RESOURCE_MEM = "yarn.service.am-resource.memory";
-  public static final long DEFAULT_KEY_AM_RESOURCE_MEM = 1024;
-  public static final String YARN_SERVICE_AM_CLIENT_PORT_RANGE =
-      YARN_SERVICE_PREFIX + "am.client.port-range";
-
-  public static final String YARN_QUEUE = "yarn.service.queue";
-  public static final String DEFAULT_YARN_QUEUE = "default";
-
-  public static final String API_SERVER_ADDRESS = "yarn.service.api-server.address";
-  public static final String DEFAULT_API_SERVER_ADDRESS = "0.0.0.0:";
-  public static final int DEFAULT_API_SERVER_PORT = 9191;
-
-  public static final String FINAL_LOG_INCLUSION_PATTERN = "yarn.service.log.include-pattern";
-  public static final String FINAL_LOG_EXCLUSION_PATTERN = "yarn.service.log.exclude-pattern";
-
-  public static final String ROLLING_LOG_INCLUSION_PATTERN = "yarn.service.rolling-log.include-pattern";
-  public static final String ROLLING_LOG_EXCLUSION_PATTERN = "yarn.service.rolling-log.exclude-pattern";
-
-  public static final String YARN_SERVICE_CLASSPATH = "yarn.service.classpath";
-
-  public static final String YARN_SERVICES_SYSTEM_SERVICE_DIRECTORY =
-      YARN_SERVICE_PREFIX + "system-service.dir";
-
-  /**
-   * The yarn service base path:
-   * Defaults to HomeDir/.yarn/
-   */
-  public static final String YARN_SERVICE_BASE_PATH = "yarn.service.base.path";
-
-  /**
-   * maximum number of failed containers (in a single component)
-   * before the app exits
-   */
-  public static final String CONTAINER_FAILURE_THRESHOLD =
-      "yarn.service.container-failure-per-component.threshold";
-  public static final int DEFAULT_CONTAINER_FAILURE_THRESHOLD = 10;
-
-  /**
-   * Maximum number of container failures on a node before the node is blacklisted
-   */
-  public static final String NODE_BLACKLIST_THRESHOLD =
-      "yarn.service.node-blacklist.threshold";
-  public static final int DEFAULT_NODE_BLACKLIST_THRESHOLD = 3;
-
-  /**
-   * The failure count for CONTAINER_FAILURE_THRESHOLD and NODE_BLACKLIST_THRESHOLD
-   * gets reset periodically, the unit is seconds.
-   */
-  public static final String CONTAINER_FAILURE_WINDOW =
-      "yarn.service.failure-count-reset.window";
-  public static final long DEFAULT_CONTAINER_FAILURE_WINDOW = 21600;
-
-  /**
-   * interval between readiness checks.
-   */
-  public static final String READINESS_CHECK_INTERVAL = "yarn.service.readiness-check-interval.seconds";
-  public static final int DEFAULT_READINESS_CHECK_INTERVAL = 30; // seconds
-
-  /**
-   * Default readiness check enabled.
-   */
-  public static final String DEFAULT_READINESS_CHECK_ENABLED =
-      "yarn.service.default-readiness-check.enabled";
-  public static final boolean DEFAULT_READINESS_CHECK_ENABLED_DEFAULT = true;
-
-  /**
-   * JVM opts.
-   */
-  public static final String JVM_OPTS = "yarn.service.am.java.opts";
-  public static final String DEFAULT_AM_JVM_XMX = " -Xmx768m ";
-
-  /**
-   * How long to wait until a container is considered dead.
-   */
-  public static final String CONTAINER_RECOVERY_TIMEOUT_MS =
-      YARN_SERVICE_PREFIX + "container-recovery.timeout.ms";
-
-  public static final int DEFAULT_CONTAINER_RECOVERY_TIMEOUT_MS = 120000;
-
-  /**
-   * The dependency tarball file location.
-   */
-  public static final String DEPENDENCY_TARBALL_PATH = YARN_SERVICE_PREFIX
-      + "framework.path";
-
-  public static final String YARN_SERVICE_CONTAINER_HEALTH_THRESHOLD_PREFIX =
-      YARN_SERVICE_PREFIX + "container-health-threshold.";
-
-  /**
-   * Upgrade feature enabled for services.
-   */
-  public static final String YARN_SERVICE_UPGRADE_ENABLED =
-      "yarn.service.upgrade.enabled";
-  public static final boolean YARN_SERVICE_UPGRADE_ENABLED_DEFAULT = false;
-
-  /**
-   * The container health threshold percent when explicitly set for a specific
-   * component or globally for all components, will schedule a health check
-   * monitor to periodically check for the percentage of healthy containers. It
-   * runs the check at a specified/default poll frequency. It allows a component
-   * to be below the health threshold for a specified/default window after which
-   * it considers the service to be unhealthy and triggers a service stop. When
-   * health threshold percent is enabled, CONTAINER_FAILURE_THRESHOLD is
-   * ignored.
-   */
-  public static final String CONTAINER_HEALTH_THRESHOLD_PERCENT =
-      YARN_SERVICE_CONTAINER_HEALTH_THRESHOLD_PREFIX + "percent";
-  /**
-   * Health check monitor poll frequency. It is an advanced setting and does not
-   * need to be set unless the service owner understands the implication and
-   * does not want the default.
-   */
-  public static final String CONTAINER_HEALTH_THRESHOLD_POLL_FREQUENCY_SEC =
-      YARN_SERVICE_CONTAINER_HEALTH_THRESHOLD_PREFIX + "poll-frequency-secs";
-  /**
-   * The amount of time the health check monitor allows a specific component to
-   * be below the health threshold after which it considers the service to be
-   * unhealthy.
-   */
-  public static final String CONTAINER_HEALTH_THRESHOLD_WINDOW_SEC =
-      YARN_SERVICE_CONTAINER_HEALTH_THRESHOLD_PREFIX + "window-secs";
-  /**
-   * The amount of initial time the health check monitor waits before the first
-   * check kicks in. It gives a lead time for the service containers to come up
-   * for the first time.
-   */
-  public static final String CONTAINER_HEALTH_THRESHOLD_INIT_DELAY_SEC =
-      YARN_SERVICE_CONTAINER_HEALTH_THRESHOLD_PREFIX + "init-delay-secs";
-  /**
-   * By default the health threshold percent does not come into play until it is
-   * explicitly set in resource config for a specific component or globally for
-   * all components. -1 signifies disabled.
-   */
-  public static final int CONTAINER_HEALTH_THRESHOLD_PERCENT_DISABLED = -1;
-
-  public static final int DEFAULT_CONTAINER_HEALTH_THRESHOLD_PERCENT =
-      CONTAINER_HEALTH_THRESHOLD_PERCENT_DISABLED;
-  public static final long DEFAULT_CONTAINER_HEALTH_THRESHOLD_POLL_FREQUENCY_SEC = 10;
-  public static final long DEFAULT_CONTAINER_HEALTH_THRESHOLD_WINDOW_SEC = 600;
-  // The default for initial delay is same as default health window
-  public static final long DEFAULT_CONTAINER_HEALTH_THRESHOLD_INIT_DELAY_SEC =
-      DEFAULT_CONTAINER_HEALTH_THRESHOLD_WINDOW_SEC;
-
-  /**
-   * Get long value for the property. First get from the userConf, if not
-   * present, get from systemConf.
-   *
-   * @param name name of the property
-   * @param defaultValue default value of the property, if it is not defined in
-   *                     userConf and systemConf.
-   * @param userConf Configuration provided by client in the JSON definition
-   * @param systemConf The YarnConfiguration in the system.
-   * @return long value for the property
-   */
-  public static long getLong(String name, long defaultValue,
-      Configuration userConf, org.apache.hadoop.conf.Configuration systemConf) {
-    return userConf.getPropertyLong(name, systemConf.getLong(name, defaultValue));
-  }
-
-  public static int getInt(String name, int defaultValue,
-      Configuration userConf, org.apache.hadoop.conf.Configuration systemConf) {
-    return userConf.getPropertyInt(name, systemConf.getInt(name, defaultValue));
-  }
-
-  public static boolean getBoolean(String name, boolean defaultValue,
-      Configuration userConf, org.apache.hadoop.conf.Configuration systemConf) {
-    return userConf.getPropertyBool(name, systemConf.getBoolean(name,
-        defaultValue));
-  }
-
-  public static String get(String name, String defaultVal,
-      Configuration userConf, org.apache.hadoop.conf.Configuration systemConf) {
-    return userConf.getProperty(name, systemConf.get(name, defaultVal));
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/conf/YarnServiceConstants.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/conf/YarnServiceConstants.java
deleted file mode 100644
index dd940650c8a..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/conf/YarnServiceConstants.java
+++ /dev/null
@@ -1,102 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.conf;
-
-public interface YarnServiceConstants {
-
-  /**
-   * The path under which cluster and temp data are stored
-   */
-  String SERVICE_BASE_DIRECTORY = ".yarn";
-
-  /**
-   * The paths under which Service AM dependency libraries are stored
-   */
-  String DEPENDENCY_LOCALIZED_DIR_LINK = "service_dep";
-  String DEPENDENCY_DIR = "/yarn-services/%s/";
-  String DEPENDENCY_TAR_GZ_FILE_NAME = "service-dep";
-  String DEPENDENCY_TAR_GZ_FILE_EXT = ".tar.gz";
-  String DEPENDENCY_DIR_PERMISSIONS = "755";
-
-  /**
-   * Service type for YARN service
-   */
-  String APP_TYPE = "yarn-service";
-
-  String KEYTAB_DIR = "keytabs";
-  String KEYTAB_LOCATION = KEYTAB_DIR + "/%s" + ".keytab";
-
-  String RESOURCE_DIR = "resources";
-
-
-  String SERVICES_DIRECTORY = "services";
-
-  String SERVICES_PUBLIC_DIRECTORY = "/tmp/hadoop-yarn/staging/";
-
-  /**
-   * JVM property to define the service lib directory;
-   * this is set by the yarn.sh script
-   */
-  String PROPERTY_LIB_DIR = "service.libdir";
-
-  /**
-   * name of generated dir for this conf
-   */
-  String SUBMITTED_CONF_DIR = "conf";
-
-  /**
-   * Service AM log4j file name
-   */
-  String YARN_SERVICE_LOG4J_FILENAME = "yarnservice-log4j.properties";
-
-  /**
-   * Log4j sysprop to name the resource
-   */
-  String SYSPROP_LOG4J_CONFIGURATION = "log4j.configuration";
-
-  /**
-   * sysprop for Service AM log4j directory
-   */
-  String SYSPROP_LOG_DIR = "LOG_DIR";
-
-  String TMP_DIR_PREFIX = "tmp";
-
-
-  String SERVICE_CORE_JAR = "yarn-service-core.jar";
-
-  String STDOUT_AM = "serviceam-out.txt";
-  String STDERR_AM = "serviceam-err.txt";
-
-  String HADOOP_USER_NAME = "HADOOP_USER_NAME";
-
-  String APP_CONF_DIR = "conf";
-  String APP_RESOURCES_DIR = "resources";
-
-  String APP_LIB_DIR = "lib";
-
-  String OUT_FILE = "stdout.txt";
-  String ERR_FILE = "stderr.txt";
-
-  String CONTENT = "content";
-  String PRINCIPAL = "yarn.service.am.principal";
-
-  String UPGRADE_DIR = "upgrade";
-  String CONTAINER_STATE_REPORT_AS_SERVICE_STATE =
-      "yarn.service.container-state-report-as-service-state";
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/AbstractLauncher.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/AbstractLauncher.java
deleted file mode 100644
index 7db78949230..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/AbstractLauncher.java
+++ /dev/null
@@ -1,262 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.containerlaunch;
-
-import org.apache.hadoop.classification.VisibleForTesting;
-import org.apache.hadoop.util.Preconditions;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;
-import org.apache.hadoop.yarn.api.records.ContainerRetryContext;
-import org.apache.hadoop.yarn.api.records.ContainerRetryPolicy;
-import org.apache.hadoop.yarn.api.records.LocalResource;
-import org.apache.hadoop.yarn.service.ServiceContext;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConstants;
-import org.apache.hadoop.yarn.service.utils.ServiceUtils;
-import org.apache.hadoop.yarn.util.Records;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Map.Entry;
-
-/**
- * Launcher of applications: base class
- */
-public class AbstractLauncher {
-  private static final Logger log =
-    LoggerFactory.getLogger(AbstractLauncher.class);
-  public static final String CLASSPATH = "CLASSPATH";
-  public static final String ENV_DOCKER_CONTAINER_MOUNTS =
-      "YARN_CONTAINER_RUNTIME_DOCKER_MOUNTS";
-  /**
-   * Env vars; set up at final launch stage
-   */
-  protected final Map<String, String> envVars = new HashMap<>();
-  protected final ContainerLaunchContext containerLaunchContext =
-    Records.newRecord(ContainerLaunchContext.class);
-  protected final List<String> commands = new ArrayList<>(20);
-  protected final Map<String, LocalResource> localResources = new HashMap<>();
-  protected final Map<String, String> mountPaths = new HashMap<>();
-  private final Map<String, ByteBuffer> serviceData = new HashMap<>();
-  protected boolean yarnDockerMode = false;
-  protected String dockerImage;
-  protected String dockerNetwork;
-  protected String dockerHostname;
-  protected boolean runPrivilegedContainer = false;
-  private ServiceContext context;
-
-  public AbstractLauncher(ServiceContext context) {
-    this.context = context;
-  }
-  
-  public void setYarnDockerMode(boolean yarnDockerMode){
-    this.yarnDockerMode = yarnDockerMode;
-  }
-
-  /**
-   * Get the env vars to work on
-   * @return env vars
-   */
-  public Map<String, String> getEnv() {
-    return envVars;
-  }
-
-  /**
-   * Get the launch commands.
-   * @return the live list of commands 
-   */
-  public List<String> getCommands() {
-    return commands;
-  }
-
-  public void addLocalResource(String subPath, LocalResource resource) {
-    localResources.put(subPath, resource);
-  }
-
-  public void addLocalResource(String subPath, LocalResource resource, String mountPath) {
-    localResources.put(subPath, resource);
-    mountPaths.put(subPath, mountPath);
-  }
-
-
-  public void addCommand(String cmd) {
-    commands.add(cmd);
-  }
-
-  /**
-   * Complete the launch context (copy in env vars, etc).
-   * @return the container to launch
-   */
-  public ContainerLaunchContext completeContainerLaunch() throws IOException {
-    
-    String cmdStr = ServiceUtils.join(commands, " ", false);
-    log.debug("Completed setting up container command {}", cmdStr);
-    containerLaunchContext.setCommands(commands);
-
-    //env variables
-    if (log.isDebugEnabled()) {
-      log.debug("Environment variables");
-      for (Map.Entry<String, String> envPair : envVars.entrySet()) {
-        log.debug("    \"{}\"=\"{}\"", envPair.getKey(), envPair.getValue());
-      }
-    }    
-    containerLaunchContext.setEnvironment(envVars);
-
-    //service data
-    if (log.isDebugEnabled()) {
-      log.debug("Service Data size");
-      for (Map.Entry<String, ByteBuffer> entry : serviceData.entrySet()) {
-        log.debug("\"{}\"=> {} bytes of data", entry.getKey(),
-            entry.getValue().array().length);
-      }
-    }
-    containerLaunchContext.setServiceData(serviceData);
-
-    // resources
-    dumpLocalResources();
-    containerLaunchContext.setLocalResources(localResources);
-
-    //tokens
-    if (context.tokens != null) {
-      containerLaunchContext.setTokens(context.tokens.duplicate());
-    }
-
-    if(yarnDockerMode){
-      Map<String, String> env = containerLaunchContext.getEnvironment();
-      env.put("YARN_CONTAINER_RUNTIME_TYPE", "docker");
-      env.put("YARN_CONTAINER_RUNTIME_DOCKER_IMAGE", dockerImage);
-      if (ServiceUtils.isSet(dockerNetwork)) {
-        env.put("YARN_CONTAINER_RUNTIME_DOCKER_CONTAINER_NETWORK",
-            dockerNetwork);
-      }
-      env.put("YARN_CONTAINER_RUNTIME_DOCKER_CONTAINER_HOSTNAME",
-          dockerHostname);
-      if (runPrivilegedContainer) {
-        env.put("YARN_CONTAINER_RUNTIME_DOCKER_RUN_PRIVILEGED_CONTAINER",
-            "true");
-      }
-      if (!mountPaths.isEmpty()) {
-        StringBuilder sb = new StringBuilder();
-        if (env.get(ENV_DOCKER_CONTAINER_MOUNTS) != null) {
-          // user specified mounts in the spec
-          sb.append(env.get(ENV_DOCKER_CONTAINER_MOUNTS));
-        }
-        for (Entry<String, String> mount : mountPaths.entrySet()) {
-          if (sb.length() > 0) {
-            sb.append(",");
-          }
-          sb.append(mount.getKey()).append(":")
-              .append(mount.getValue()).append(":ro");
-        }
-        env.put(ENV_DOCKER_CONTAINER_MOUNTS, sb.toString());
-      }
-      log.info("yarn docker env var has been set {}",
-          containerLaunchContext.getEnvironment().toString());
-    }
-
-    return containerLaunchContext;
-  }
-
-  public void setRetryContext(int maxRetries, int retryInterval,
-      long failuresValidityInterval) {
-    ContainerRetryContext retryContext = ContainerRetryContext
-        .newInstance(ContainerRetryPolicy.RETRY_ON_ALL_ERRORS, null,
-            maxRetries, retryInterval, failuresValidityInterval);
-    containerLaunchContext.setContainerRetryContext(retryContext);
-  }
-
-  /**
-   * Dump local resources at debug level
-   */
-  private void dumpLocalResources() {
-    if (log.isDebugEnabled()) {
-      log.debug("{} resources: ", localResources.size());
-      for (Map.Entry<String, LocalResource> entry : localResources.entrySet()) {
-
-        String key = entry.getKey();
-        LocalResource val = entry.getValue();
-        log.debug("{} = {}", key, ServiceUtils.stringify(val.getResource()));
-      }
-    }
-  }
-
-  /**
-   * This is critical for an insecure cluster -it passes
-   * down the username to YARN, and so gives the code running
-   * in containers the rights it needs to work with
-   * data.
-   * @throws IOException problems working with current user
-   */
-  protected void propagateUsernameInInsecureCluster() throws IOException {
-    //insecure cluster: propagate user name via env variable
-    String userName = UserGroupInformation.getCurrentUser().getUserName();
-    envVars.put(YarnServiceConstants.HADOOP_USER_NAME, userName);
-  }
-
-  /**
-   * Utility method to set up the classpath
-   * @param classpath classpath to use
-   */
-  public void setClasspath(ClasspathConstructor classpath) {
-    setEnv(CLASSPATH, classpath.buildClasspath());
-  }
-
-  /**
-   * Set an environment variable in the launch context
-   * @param var variable name
-   * @param value value (must be non null)
-   */
-  public void setEnv(String var, String value) {
-    Preconditions.checkArgument(var != null, "null variable name");
-    Preconditions.checkArgument(value != null, "null value");
-    envVars.put(var, value);
-  }
-
-
-  public void putEnv(Map<String, String> map) {
-    envVars.putAll(map);
-  }
-
-
-  public void setDockerImage(String dockerImage) {
-    this.dockerImage = dockerImage;
-  }
-
-  public void setDockerNetwork(String dockerNetwork) {
-    this.dockerNetwork = dockerNetwork;
-  }
-
-  public void setDockerHostname(String dockerHostname) {
-    this.dockerHostname = dockerHostname;
-  }
-
-  public void setRunPrivilegedContainer(boolean runPrivilegedContainer) {
-    this.runPrivilegedContainer = runPrivilegedContainer;
-  }
-
-  @VisibleForTesting
-  public String getDockerImage() {
-    return dockerImage;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/ClasspathConstructor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/ClasspathConstructor.java
deleted file mode 100644
index 711abb25eac..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/ClasspathConstructor.java
+++ /dev/null
@@ -1,172 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.containerlaunch;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.util.StringUtils;
-import org.apache.hadoop.yarn.api.ApplicationConstants;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.service.utils.ServiceUtils;
-
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.List;
-
-/**
- * build a classpath -allows for entries to be injected in front of
- * YARN classpath as well as behind, adds appropriate separators, 
- * extraction of local classpath, etc.
- */
-public class ClasspathConstructor {
-
-    public static final String CLASS_PATH_SEPARATOR = ApplicationConstants.CLASS_PATH_SEPARATOR;
-  private final List<String> pathElements = new ArrayList<>();
-
-  public ClasspathConstructor() {
-  }
-
-
-  /**
-   * Get the list of JARs from the YARN settings
-   * @param config configuration
-   */
-  public List<String> yarnApplicationClasspath(Configuration config) {
-    String[] cp = config.getTrimmedStrings(
-      YarnConfiguration.YARN_APPLICATION_CLASSPATH,
-      YarnConfiguration.DEFAULT_YARN_CROSS_PLATFORM_APPLICATION_CLASSPATH);
-    return cp != null ? Arrays.asList(cp) : new ArrayList<String>(0);
-
-  }
-
-
-  @Override
-  public String toString() {
-    return buildClasspath();
-  }
-
-  public String buildClasspath() {
-    return ServiceUtils.join(pathElements,
-        CLASS_PATH_SEPARATOR,
-        false);
-  }
-
-  /**
-   * Get a copy of the path list
-   * @return the JARs
-   */
-  public List<String> getPathElements() {
-    return Collections.unmodifiableList(pathElements);
-  }
-
-  /**
-   * Append an entry
-   * @param path path
-   */
-  public void append(String path) {
-    pathElements.add(path);
-  }
-
-  /**
-   * Insert a path at the front of the list. This places it ahead of
-   * the standard YARN artifacts
-   * @param path path to the JAR. Absolute or relative -on the target
-   * system
-   */
-  public void insert(String path) {
-    pathElements.add(0, path);
-  }
-
-  public void appendAll(Collection<String> paths) {
-    pathElements.addAll(paths);
-  }
-
-  public void insertAll(Collection<String> paths) {
-    pathElements.addAll(0, paths);
-  }
-
-
-  public void addLibDir(String pathToLibDir) {
-    append(buildLibDir(pathToLibDir));
-  }
-
-  public void insertLibDir(String pathToLibDir) {
-    insert(buildLibDir(pathToLibDir));
-  }
-
-  public void addClassDirectory(String pathToDir) {
-    append(appendDirectoryTerminator(pathToDir));
-  }
-
-  public void insertClassDirectory(String pathToDir) {
-    insert(buildLibDir(appendDirectoryTerminator(pathToDir)));
-  }
-
-
-  public void addRemoteClasspathEnvVar() {
-    append(ApplicationConstants.Environment.CLASSPATH.$$());
-  }
-
-
-  public void insertRemoteClasspathEnvVar() {
-    append(ApplicationConstants.Environment.CLASSPATH.$$());
-  }
-
-
-  /**
-   * Build a lib dir path
-   * @param pathToLibDir path to the directory; may or may not end with a
-   * trailing space
-   * @return a path to a lib dir that is compatible with the java classpath
-   */
-  public String buildLibDir(String pathToLibDir) {
-    String dir = appendDirectoryTerminator(pathToLibDir);
-    dir += "*";
-    return dir;
-  }
-
-  private String appendDirectoryTerminator(String pathToLibDir) {
-    String dir = pathToLibDir.trim();
-    if (!dir.endsWith("/")) {
-      dir += "/";
-    }
-    return dir;
-  }
-
-  /**
-   * Split a classpath. This uses the local path separator so MUST NOT
-   * be used to work with remote classpaths
-   * @param localpath local path
-   * @return a splite
-   */
-  public Collection<String> splitClasspath(String localpath) {
-    String separator = System.getProperty("path.separator");
-    return StringUtils.getStringCollection(localpath, separator);
-  }
-
-  /**
-   * Get the local JVM classpath split up
-   * @return the list of entries on the JVM classpath env var
-   */
-  public Collection<String> localJVMClasspath() {
-    return splitClasspath(System.getProperty("java.class.path"));
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/CommandLineBuilder.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/CommandLineBuilder.java
deleted file mode 100644
index 70e3fc23abb..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/CommandLineBuilder.java
+++ /dev/null
@@ -1,86 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.containerlaunch;
-
-import org.apache.hadoop.util.Preconditions;
-import org.apache.hadoop.yarn.api.ApplicationConstants;
-import org.apache.hadoop.yarn.service.utils.ServiceUtils;
-
-import java.util.ArrayList;
-import java.util.List;
-
-/**
- * Build a single command line to include in the container commands;
- * Special support for JVM command buildup.
- */
-public class CommandLineBuilder {
-  protected final List<String> argumentList = new ArrayList<>(20);
-
-  /**
-   * Add an entry to the command list
-   * @param args arguments -these will be converted strings
-   */
-  public void add(Object... args) {
-    for (Object arg : args) {
-      argumentList.add(arg.toString());
-    }
-  }
-
-  // Get the number of arguments
-  public int size() {
-    return argumentList.size();
-  }
-  
-  /**
-   * Append the output and error files to the tail of the command
-   * @param stdout out
-   * @param stderr error. Set this to null to append into stdout
-   */
-  public void addOutAndErrFiles(String stdout, String stderr) {
-    Preconditions.checkNotNull(stdout, "Null output file");
-    Preconditions.checkState(!stdout.isEmpty(), "output filename invalid");
-    // write out the path output
-    argumentList.add("1>" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/" +
-             stdout);
-    if (stderr != null) {
-      argumentList.add("2>" + ApplicationConstants.LOG_DIR_EXPANSION_VAR + "/" +
-               stderr);
-    } else {
-      argumentList.add("2>&1");
-    }
-  }
-
-  /**
-   * This just returns the command line
-   * @see #build()
-   * @return the command line
-   */
-  @Override
-  public String toString() {
-    return build();
-  }
-
-  /**
-   * Build the command line
-   * @return the command line
-   */
-  public String build() {
-    return ServiceUtils.join(argumentList, " ");
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/ContainerLaunchService.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/ContainerLaunchService.java
deleted file mode 100644
index 3debc45f670..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/ContainerLaunchService.java
+++ /dev/null
@@ -1,210 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.containerlaunch;
-
-import org.apache.hadoop.util.Preconditions;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.service.AbstractService;
-import org.apache.hadoop.yarn.api.records.Container;
-import org.apache.hadoop.yarn.service.ServiceContext;
-import org.apache.hadoop.yarn.service.api.records.Artifact;
-import org.apache.hadoop.yarn.service.component.ComponentEvent;
-import org.apache.hadoop.yarn.service.component.ComponentEventType;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.apache.hadoop.yarn.service.provider.ProviderService;
-import org.apache.hadoop.yarn.service.provider.ProviderFactory;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.util.concurrent.Callable;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
-import java.util.concurrent.Future;
-
-import static org.apache.hadoop.yarn.service.provider.ProviderService.FAILED_LAUNCH_PARAMS;
-
-public class ContainerLaunchService extends AbstractService{
-
-  protected static final Logger LOG =
-      LoggerFactory.getLogger(ContainerLaunchService.class);
-
-  private ExecutorService executorService;
-  private SliderFileSystem fs;
-  private ServiceContext context;
-  public ContainerLaunchService(ServiceContext context) {
-    super(ContainerLaunchService.class.getName());
-    this.fs = context.fs;
-    this.context = context;
-  }
-
-  @Override
-  public void serviceInit(Configuration conf) throws Exception {
-    executorService = Executors.newCachedThreadPool();
-    super.serviceInit(conf);
-  }
-
-  @Override
-  protected void serviceStop() throws Exception {
-    if (executorService != null) {
-      executorService.shutdownNow();
-    }
-    super.serviceStop();
-  }
-
-  public Future<ProviderService.ResolvedLaunchParams> launchCompInstance(
-      Service service,
-      ComponentInstance instance, Container container,
-      ComponentLaunchContext componentLaunchContext) {
-    ContainerLauncher launcher =
-        new ContainerLauncher(service, instance, container,
-            componentLaunchContext, false);
-    return executorService.submit(launcher);
-  }
-
-  public Future<ProviderService.ResolvedLaunchParams> reInitCompInstance(
-      Service service,
-      ComponentInstance instance, Container container,
-      ComponentLaunchContext componentLaunchContext) {
-    ContainerLauncher reInitializer = new ContainerLauncher(service, instance,
-        container, componentLaunchContext, true);
-    return executorService.submit(reInitializer);
-  }
-
-  private class ContainerLauncher implements
-      Callable<ProviderService.ResolvedLaunchParams> {
-    public final Container container;
-    public final Service service;
-    public ComponentInstance instance;
-    private final ComponentLaunchContext componentLaunchContext;
-    private final boolean reInit;
-
-    ContainerLauncher(Service service, ComponentInstance instance,
-        Container container, ComponentLaunchContext componentLaunchContext,
-        boolean reInit) {
-      this.container = container;
-      this.service = service;
-      this.instance = instance;
-      this.componentLaunchContext = componentLaunchContext;
-      this.reInit = reInit;
-    }
-
-    @Override
-    public ProviderService.ResolvedLaunchParams call() {
-      ProviderService provider = ProviderFactory.getProviderService(
-          componentLaunchContext.getArtifact());
-      AbstractLauncher launcher = new AbstractLauncher(context);
-      ProviderService.ResolvedLaunchParams resolvedParams = null;
-      try {
-        resolvedParams = provider.buildContainerLaunchContext(launcher, service,
-            instance, fs, getConfig(), container, componentLaunchContext);
-        if (!reInit) {
-          LOG.info("launching container {}", container.getId());
-          instance.getComponent().getScheduler().getNmClient()
-              .startContainerAsync(container,
-                  launcher.completeContainerLaunch());
-        } else {
-          LOG.info("reInitializing container {} with version {}",
-              container.getId(), componentLaunchContext.getServiceVersion());
-          instance.getComponent().getScheduler().getNmClient()
-              .reInitializeContainerAsync(container.getId(),
-                  launcher.completeContainerLaunch(), true);
-        }
-      } catch (Exception e) {
-        LOG.error("{}: Failed to launch container.",
-            instance.getCompInstanceId(), e);
-        ComponentEvent event = new ComponentEvent(instance.getCompName(),
-            ComponentEventType.CONTAINER_COMPLETED)
-            .setInstance(instance).setContainerId(container.getId());
-        context.scheduler.getDispatcher().getEventHandler().handle(event);
-      }
-      if (resolvedParams != null) {
-        return resolvedParams;
-      } else {
-        return FAILED_LAUNCH_PARAMS;
-      }
-    }
-  }
-
-  /**
-   * Launch context of a component.
-   */
-  public static class ComponentLaunchContext {
-    private final String name;
-    private final String serviceVersion;
-    private Artifact artifact;
-    private org.apache.hadoop.yarn.service.api.records.Configuration
-        configuration;
-    private String launchCommand;
-    private boolean runPrivilegedContainer;
-
-    public ComponentLaunchContext(String name, String serviceVersion) {
-      this.name = Preconditions.checkNotNull(name);
-      this.serviceVersion = Preconditions.checkNotNull(serviceVersion);
-    }
-
-    public String getName() {
-      return name;
-    }
-
-    public String getServiceVersion() {
-      return serviceVersion;
-    }
-
-    public Artifact getArtifact() {
-      return artifact;
-    }
-
-    public org.apache.hadoop.yarn.service.api.records.
-        Configuration getConfiguration() {
-      return configuration;
-    }
-
-    public String getLaunchCommand() {
-      return launchCommand;
-    }
-
-    public boolean isRunPrivilegedContainer() {
-      return runPrivilegedContainer;
-    }
-
-    public ComponentLaunchContext setArtifact(Artifact artifact) {
-      this.artifact = artifact;
-      return this;
-    }
-
-    public ComponentLaunchContext setConfiguration(org.apache.hadoop.yarn.
-        service.api.records.Configuration configuration) {
-      this.configuration = configuration;
-      return this;
-    }
-
-    public ComponentLaunchContext setLaunchCommand(String launchCommand) {
-      this.launchCommand = launchCommand;
-      return this;
-    }
-
-    public ComponentLaunchContext setRunPrivilegedContainer(
-        boolean runPrivilegedContainer) {
-      this.runPrivilegedContainer = runPrivilegedContainer;
-      return this;
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/JavaCommandLineBuilder.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/JavaCommandLineBuilder.java
deleted file mode 100644
index 5578ea3624e..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/containerlaunch/JavaCommandLineBuilder.java
+++ /dev/null
@@ -1,180 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.containerlaunch;
-
-
-import org.apache.hadoop.util.Preconditions;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.api.ApplicationConstants;
-import org.apache.hadoop.yarn.service.utils.ServiceUtils;
-import org.apache.hadoop.yarn.service.exceptions.BadConfigException;
-
-import java.util.Map;
-
-/**
- * Command line builder purely for the Java CLI.
- * Some of the <code>define</code> methods are designed to work with Hadoop tool and
- * Slider launcher applications.
- */
-public class JavaCommandLineBuilder extends CommandLineBuilder {
-
-  public JavaCommandLineBuilder() {
-    add(getJavaBinary());
-  }
-
-  /**
-   * Get the java binary. This is called in the constructor so don't try and
-   * do anything other than return a constant.
-   * @return the path to the Java binary
-   */
-  protected String getJavaBinary() {
-    return ApplicationConstants.Environment.JAVA_HOME.$$() + "/bin/java";
-  }
-
-  /**
-   * Set JVM opts.
-   * @param jvmOpts JVM opts
-   */
-  public void setJVMOpts(String jvmOpts) {
-    if (ServiceUtils.isSet(jvmOpts)) {
-      add(jvmOpts);
-    }
-  }
-
-  /**
-   * Turn Java assertions on
-   */
-  public void enableJavaAssertions() {
-    add("-ea");
-    add("-esa");
-  }
-
-  /**
-   * Add a system property definition -must be used before setting the main entry point
-   * @param property
-   * @param value
-   */
-  public void sysprop(String property, String value) {
-    Preconditions.checkArgument(property != null, "null property name");
-    Preconditions.checkArgument(value != null, "null value");
-    add("-D" + property + "=" + value);
-  }
-  
-  public JavaCommandLineBuilder forceIPv4() {
-    sysprop("java.net.preferIPv4Stack", "true");
-    return this;
-  }
-  
-  public JavaCommandLineBuilder headless() {
-    sysprop("java.awt.headless", "true");
-    return this;
-  }
-
-  public boolean addConfOption(Configuration conf, String key) {
-    return defineIfSet(key, conf.get(key));
-  }
-
-  /**
-   * Add a varargs list of configuration parameters if they are present
-   * @param conf configuration source
-   * @param keys keys
-   */
-  public void addConfOptions(Configuration conf, String... keys) {
-    for (String key : keys) {
-      addConfOption(conf, key);
-    }
-  }
-
-  /**
-   * Add all configuration options which match the prefix
-   * @param conf configuration
-   * @param prefix prefix, e.g {@code "slider."}
-   * @return the number of entries copied
-   */
-  public int addPrefixedConfOptions(Configuration conf, String prefix) {
-    int copied = 0;
-    for (Map.Entry<String, String> entry : conf) {
-      if (entry.getKey().startsWith(prefix)) {
-        define(entry.getKey(), entry.getValue());
-        copied++;
-      }
-    }
-    return copied;
-  }
-
-  /**
-   * Ass a configuration option to the command line of  the application
-   * @param conf configuration
-   * @param key key
-   * @param defVal default value
-   * @return the resolved configuration option
-   * @throws IllegalArgumentException if key is null or the looked up value
-   * is null (that is: the argument is missing and devVal was null.
-   */
-  public String addConfOptionToCLI(Configuration conf,
-      String key,
-      String defVal) {
-    Preconditions.checkArgument(key != null, "null key");
-    String val = conf.get(key, defVal);
-    define(key, val);
-    return val;
-  }
-
-  /**
-   * Add a <code>-D key=val</code> command to the CLI. This is very Hadoop API
-   * @param key key
-   * @param val value
-   * @throws IllegalArgumentException if either argument is null
-   */
-  public void define(String key, String val) {
-    Preconditions.checkArgument(key != null, "null key");
-    Preconditions.checkArgument(val != null, "null value");
-    add("-D", key + "=" + val);
-  }
-
-  /**
-   * Add a <code>-D key=val</code> command to the CLI if <code>val</code>
-   * is not null
-   * @param key key
-   * @param val value
-   */
-  public boolean defineIfSet(String key, String val) {
-    Preconditions.checkArgument(key != null, "null key");
-    if (val != null) {
-      define(key, val);
-      return true;
-    } else {
-      return false;
-    }
-  }
-
-  /**
-   * Add a mandatory config option
-   * @param conf configuration
-   * @param key key
-   * @throws BadConfigException if the key is missing
-   */
-  public void addMandatoryConfOption(Configuration conf,
-      String key) throws BadConfigException {
-    if (!addConfOption(conf, key)) {
-      throw new BadConfigException("Missing configuration option: " + key);
-    }
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/BadClusterStateException.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/BadClusterStateException.java
deleted file mode 100644
index db9de7a1c26..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/BadClusterStateException.java
+++ /dev/null
@@ -1,36 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.exceptions;
-
-import org.apache.hadoop.yarn.service.exceptions.SliderException;
-
-/**
- * The system is in a bad state
- */
-public class BadClusterStateException extends SliderException {
-  public BadClusterStateException(String message,
-                                  Object... args) {
-    super(EXIT_BAD_STATE, message, args);
-  }
-
-  public BadClusterStateException(Throwable throwable,
-                                  String message, Object... args) {
-    super(EXIT_BAD_STATE, throwable, message, args);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/BadCommandArgumentsException.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/BadCommandArgumentsException.java
deleted file mode 100644
index 41e325159d2..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/BadCommandArgumentsException.java
+++ /dev/null
@@ -1,30 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.exceptions;
-
-public class BadCommandArgumentsException extends SliderException {
-  public BadCommandArgumentsException(String s, Object... args) {
-    super(EXIT_COMMAND_ARGUMENT_ERROR, s, args);
-  }
-
-  public BadCommandArgumentsException(Throwable throwable, String message,
-                                      Object... args) {
-    super(EXIT_COMMAND_ARGUMENT_ERROR, throwable, message, args);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/BadConfigException.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/BadConfigException.java
deleted file mode 100644
index 8199c3c17ed..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/BadConfigException.java
+++ /dev/null
@@ -1,39 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.exceptions;
-
-/**
- * An exception to raise on a bad configuration
- */
-public class BadConfigException extends SliderException {
-
-  public BadConfigException(String s) {
-    super(EXIT_BAD_CONFIGURATION, s);
-  }
-
-  public BadConfigException(String message, Object... args) {
-    super(EXIT_BAD_CONFIGURATION, message, args);
-  }
-
-  public BadConfigException(
-                            Throwable throwable,
-                            String message, Object... args) {
-    super(EXIT_BAD_CONFIGURATION, throwable, message, args);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/ErrorStrings.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/ErrorStrings.java
deleted file mode 100644
index 6ae124faedd..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/ErrorStrings.java
+++ /dev/null
@@ -1,44 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.exceptions;
-
-public interface ErrorStrings {
-
-  String PRINTF_E_INSTANCE_ALREADY_EXISTS = "Service Instance \"%s\" already exists and is defined in %s";
-  String PRINTF_E_INSTANCE_DIR_ALREADY_EXISTS = "Service Instance dir already exists: %s";
-
-  /**
-   * ERROR Strings
-   */
-  String ERROR_NO_ACTION = "No action specified";
-  String ERROR_UNKNOWN_ACTION = "Unknown command: ";
-  String ERROR_NOT_ENOUGH_ARGUMENTS =
-    "Not enough arguments for action: ";
-  String ERROR_PARSE_FAILURE =
-      "Failed to parse ";
-  /**
-   * All the remaining values after argument processing
-   */
-  String ERROR_TOO_MANY_ARGUMENTS =
-    "Too many arguments";
-  String ERROR_DUPLICATE_ENTRY = "Duplicate entry for ";
-
-  String SERVICE_UPGRADE_DISABLED = "Service upgrade is disabled.";
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/ExitCodeProvider.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/ExitCodeProvider.java
deleted file mode 100644
index d66b86030eb..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/ExitCodeProvider.java
+++ /dev/null
@@ -1,32 +0,0 @@
-/*
- *  Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.exceptions;
-
-/**
- * Get the exit code of an exception. Making it an interface allows
- * us to retrofit exit codes onto existing classes
- */
-public interface ExitCodeProvider {
-
-  /**
-   * Method to get the exit code
-   * @return the exit code
-   */
-  int  getExitCode();
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/LauncherExitCodes.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/LauncherExitCodes.java
deleted file mode 100644
index 483fb48d465..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/LauncherExitCodes.java
+++ /dev/null
@@ -1,196 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.exceptions;
-
-/*
- * Common Exit codes
- * <p>
- * Exit codes from 64 up are service specific.
- * <p>
- * Many of the exit codes are designed to resemble HTTP error codes,
- * squashed into a single byte. e.g 44 , "not found" is the equivalent
- * of 404
- * <pre>
- *    0-10: general command issues
- *   30-39: equivalent to the 3XX responses, where those responses are
- *          considered errors by the service.
- *   40-49: request-related errors
- *   50-59: server-side problems. These may be triggered by the request.
- *   64-  : service specific error codes
- * </pre>
- */
-public interface LauncherExitCodes {
-  
-  /**
-   * 0: success
-   */
-  int EXIT_SUCCESS                    =  0;
-
-  /**
-   * -1: generic "false" response. The operation worked but
-   * the result was not true
-   */
-  int EXIT_FALSE                      = -1;
-
-  /**
-   * Exit code when a client requested service termination: {@value}
-   */
-  int EXIT_CLIENT_INITIATED_SHUTDOWN  =  1;
-
-  /**
-   * Exit code when targets could not be launched: {@value}
-   */
-  int EXIT_TASK_LAUNCH_FAILURE        =  2;
-
-  /**
-   * Exit code when a control-C, kill -3, signal was picked up: {@value}
-   */
-  int EXIT_INTERRUPTED                = 3;
-
-  /**
-   * Exit code when a usage message was printed: {@value}
-   */
-  int EXIT_USAGE                      = 4;
-
-  /**
-   * Exit code when something happened but we can't be specific: {@value}
-   */
-  int EXIT_OTHER_FAILURE               = 5;
-
-  /**
-   * Exit code on connectivity problems: {@value}
-   */
-  int EXIT_MOVED                      = 31;
-  
-  /**
-   * found: {@value}.
-   * <p>
-   * This is low value as in HTTP it is normally a success/redirect;
-   * whereas on the command line 0 is the sole success code.
-   * <p>
-   * <code>302 Found</code>
-   */
-  int EXIT_FOUND                      = 32;
-
-  /**
-   * Exit code on a request where the destination has not changed
-   * and (somehow) the command specified that this is an error.
-   * That is, this exit code is somehow different from a "success"
-   * : {@value}
-   * <p>
-   * <code>304 Not Modified </code>
-  */
-  int EXIT_NOT_MODIFIED               = 34;
-
-  /**
-   * Exit code when the command line doesn't parse: {@value}, or
-   * when it is otherwise invalid.
-   * <p>
-   * <code>400 BAD REQUEST</code>
-   */
-  int EXIT_COMMAND_ARGUMENT_ERROR     = 40;
-
-  /**
-   * The request requires user authentication: {@value}
-   * <p>
-   * <code>401 Unauthorized</code>
-   */
-  int EXIT_UNAUTHORIZED               = 41;
-  
-  /**
-   * Forbidden action: {@value}
-   * <p>
-   * <code>403: Forbidden</code>
-   */
-  int EXIT_FORBIDDEN                  = 43;
-  
-  /**
-   * Something was not found: {@value}
-   * <p>
-   * <code>404: NOT FOUND</code>
-   */
-  int EXIT_NOT_FOUND                  = 44;
-
-  /**
-   * The operation is not allowed: {@value}
-   * <p>
-   * <code>405: NOT ALLOWED</code>
-   */
-  int EXIT_OPERATION_NOT_ALLOWED       = 45;
-
-  /**
-   * The command is somehow not acceptable: {@value}
-   * <p>
-   * <code>406: NOT ACCEPTABLE</code>
-   */
-  int EXIT_NOT_ACCEPTABLE            = 46;
-
-  /**
-   * Exit code on connectivity problems: {@value}
-   * <p>
-   * <code>408: Request Timeout</code>
-   */
-  int EXIT_CONNECTIVITY_PROBLEM       = 48;
-
-  /**
-   * The request could not be completed due to a conflict with the current
-   * state of the resource.  {@value}
-   * <p>
-   * <code>409: conflict</code>
-   */
-  int EXIT_CONFLICT                   = 49;
-
-  /**
-   * internal error: {@value}
-   * <p>
-   * <code>500 Internal Server Error</code>
-   */
-  int EXIT_INTERNAL_ERROR             = 50;
-
-  /**
-   * Unimplemented feature: {@value}
-   * <p>
-   * <code>501: Not Implemented</code>
-   */
-  int EXIT_UNIMPLEMENTED              = 51;
-
-  /**
-   * Service Unavailable; it may be available later: {@value}
-   * <p>
-   * <code>503 Service Unavailable</code>
-   */
-  int EXIT_SERVICE_UNAVAILABLE        = 53;
-
-  /**
-   * The service does not support, or refuses to support this version: {@value}.
-   * If raised, this is expected to be raised server-side and likely due
-   * to client/server version incompatibilities.
-   * <p>
-   * <code> 505: Version Not Supported</code>
-   */
-  int EXIT_UNSUPPORTED_VERSION        = 55;
-
-  /**
-   * Exit code when an exception was thrown from the service: {@value}
-   * <p>
-   * <code>5XX</code>
-   */
-  int EXIT_EXCEPTION_THROWN           = 56;
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/RestApiErrorMessages.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/RestApiErrorMessages.java
deleted file mode 100644
index 295f14af098..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/RestApiErrorMessages.java
+++ /dev/null
@@ -1,131 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.exceptions;
-
-public interface RestApiErrorMessages {
-  String ERROR_APPLICATION_NAME_INVALID =
-      "Service name is either empty or not provided";
-  String ERROR_APPLICATION_VERSION_INVALID =
-      "Version of service %s is either empty or not provided";
-  String ERROR_APPLICATION_NAME_INVALID_FORMAT =
-      "Service name %s is not valid - only lower case letters, digits, " +
-          "and hyphen are allowed, and the name must be no more " +
-          "than 63 characters";
-  String ERROR_COMPONENT_NAME_INVALID =
-      "Component name must be no more than %s characters: %s";
-  String ERROR_COMPONENT_NAME_CONFLICTS_WITH_SERVICE_NAME =
-      "Component name %s must not be same as service name %s";
-  String ERROR_USER_NAME_INVALID =
-      "User name must be no more than 63 characters";
-
-  String ERROR_APPLICATION_NOT_RUNNING = "Service not running";
-  String ERROR_APPLICATION_DOES_NOT_EXIST = "Service not found";
-  String ERROR_APPLICATION_IN_USE = "Service already exists in started"
-      + " state";
-  String ERROR_APPLICATION_INSTANCE_EXISTS = "Service already exists in"
-      + " stopped/failed state (either restart with PUT or destroy with DELETE"
-      + " before creating a new one)";
-
-  String ERROR_SUFFIX_FOR_COMPONENT =
-      " for component %s (nor at the global level)";
-  String ERROR_ARTIFACT_INVALID = "Artifact is not provided";
-  String ERROR_ARTIFACT_FOR_COMP_INVALID =
-      ERROR_ARTIFACT_INVALID + ERROR_SUFFIX_FOR_COMPONENT;
-  String ERROR_ARTIFACT_ID_INVALID =
-      "Artifact id (like docker image name) is either empty or not provided";
-  String ERROR_ARTIFACT_ID_FOR_COMP_INVALID =
-      ERROR_ARTIFACT_ID_INVALID + ERROR_SUFFIX_FOR_COMPONENT;
-  String ERROR_ARTIFACT_PATH_FOR_COMP_INVALID = "For component %s with %s "
-      + "artifact, path does not exist: %s";
-  String ERROR_CONFIGFILE_DEST_FILE_FOR_COMP_NOT_ABSOLUTE = "For component %s "
-      + "with %s artifact, dest_file must be a relative path: %s";
-
-  String ERROR_RESOURCE_INVALID = "Resource is not provided";
-  String ERROR_RESOURCE_FOR_COMP_INVALID =
-      ERROR_RESOURCE_INVALID + ERROR_SUFFIX_FOR_COMPONENT;
-  String ERROR_RESOURCE_MEMORY_INVALID =
-      "Service resource or memory not provided";
-  String ERROR_RESOURCE_CPUS_INVALID =
-      "Service resource or cpus not provided";
-  String ERROR_RESOURCE_CPUS_INVALID_RANGE =
-      "Unacceptable no of cpus specified, either zero or negative";
-  String ERROR_RESOURCE_MEMORY_FOR_COMP_INVALID =
-      ERROR_RESOURCE_MEMORY_INVALID + ERROR_SUFFIX_FOR_COMPONENT;
-  String ERROR_RESOURCE_CPUS_FOR_COMP_INVALID =
-      ERROR_RESOURCE_CPUS_INVALID + ERROR_SUFFIX_FOR_COMPONENT;
-  String ERROR_RESOURCE_CPUS_FOR_COMP_INVALID_RANGE =
-      ERROR_RESOURCE_CPUS_INVALID_RANGE
-          + " for component %s (or at the global level)";
-  String ERROR_CONTAINERS_COUNT_INVALID =
-      "Invalid no of containers specified";
-  String ERROR_CONTAINERS_COUNT_FOR_COMP_INVALID =
-      ERROR_CONTAINERS_COUNT_INVALID + ERROR_SUFFIX_FOR_COMPONENT;
-  String ERROR_DEPENDENCY_INVALID = "Dependency %s for component %s is " +
-      "invalid, does not exist as a component";
-  String ERROR_DEPENDENCY_CYCLE = "Invalid dependencies, a cycle may " +
-      "exist: %s";
-
-  String ERROR_RESOURCE_PROFILE_MULTIPLE_VALUES_NOT_SUPPORTED =
-      "Cannot specify" + " cpus/memory along with profile";
-  String ERROR_RESOURCE_PROFILE_MULTIPLE_VALUES_FOR_COMP_NOT_SUPPORTED =
-      ERROR_RESOURCE_PROFILE_MULTIPLE_VALUES_NOT_SUPPORTED
-          + " for component %s";
-  String ERROR_RESOURCE_PROFILE_NOT_SUPPORTED_YET =
-      "Resource profile is not " + "supported yet. Please specify cpus/memory.";
-
-  String ERROR_NULL_ARTIFACT_ID =
-      "Artifact Id can not be null if artifact type is none";
-  String ERROR_ABSENT_NUM_OF_INSTANCE =
-      "Num of instances should appear either globally or per component";
-  String ERROR_ABSENT_LAUNCH_COMMAND =
-      "launch_command is required when type is not DOCKER";
-
-  String ERROR_QUICKLINKS_FOR_COMP_INVALID = "Quicklinks specified at"
-      + " component level, needs corresponding values set at service level";
-  // Note: %sin is not a typo. Constraint name is optional so the error messages
-  // below handle that scenario by adding a space if name is specified.
-  String ERROR_PLACEMENT_POLICY_CONSTRAINT_TYPE_NULL = "Type not specified "
-      + "for constraint %sin placement policy of component %s.";
-  String ERROR_PLACEMENT_POLICY_CONSTRAINT_SCOPE_NULL = "Scope not specified "
-      + "for constraint %sin placement policy of component %s.";
-  String ERROR_PLACEMENT_POLICY_CONSTRAINT_TAGS_NULL = "Tag(s) not specified "
-      + "for constraint %sin placement policy of component %s.";
-  String ERROR_PLACEMENT_POLICY_TAG_NAME_NOT_SAME = "Invalid target tag %s "
-      + "specified in placement policy of component %s. For now, target tags "
-      + "support self reference only. Specifying anything other than its "
-      + "component name is not supported. Set target tag of component %s to "
-      + "%s.";
-  String ERROR_PLACEMENT_POLICY_TAG_NAME_INVALID = "Invalid target tag %s "
-      + "specified in placement policy of component %s. Target tags should be "
-      + "a valid component name in the service.";
-  String ERROR_PLACEMENT_POLICY_EXPRESSION_ELEMENT_NAME_INVALID = "Invalid "
-      + "expression element name %s specified in placement policy of component "
-      + "%s. Expression element names should be a valid constraint name or an "
-      + "expression name defined for this component only.";
-
-  String ERROR_COMP_INSTANCE_DOES_NOT_NEED_UPGRADE = "The component instance " +
-      "(%s) does not need an upgrade.";
-
-  String ERROR_COMP_DOES_NOT_NEED_UPGRADE = "The component (%s) does not need" +
-      " an upgrade.";
-  String ERROR_KERBEROS_PRINCIPAL_NAME_FORMAT = "Kerberos principal (%s) does " +
-      " not contain a hostname.";
-  String ERROR_KERBEROS_PRINCIPAL_MISSING = "Kerberos principal or keytab is" +
-      " missing.";
-  String ERROR_JVM_OPTS = "Invalid character in yarn.service.am.java.opts.";
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/ServiceLaunchException.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/ServiceLaunchException.java
deleted file mode 100644
index e83ccbe5973..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/ServiceLaunchException.java
+++ /dev/null
@@ -1,73 +0,0 @@
-/*
- *  Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.exceptions;
-
-
-import org.apache.hadoop.yarn.exceptions.YarnException;
-
-/**
- * A service launch exception that includes an exit code;
- * when caught by the ServiceLauncher, it will convert that
- * into a process exit code.
- */
-public class ServiceLaunchException extends YarnException
-  implements ExitCodeProvider, LauncherExitCodes {
-
-  private final int exitCode;
-
-  /**
-   * Create an exception with the specific exit code
-   * @param exitCode exit code
-   * @param cause cause of the exception
-   */
-  public ServiceLaunchException(int exitCode, Throwable cause) {
-    super(cause);
-    this.exitCode = exitCode;
-  }
-
-  /**
-   * Create an exception with the specific exit code and text
-   * @param exitCode exit code
-   * @param message message to use in exception
-   */
-  public ServiceLaunchException(int exitCode, String message) {
-    super(message);
-    this.exitCode = exitCode;
-  }
-
-  /**
-   * Create an exception with the specific exit code, text and cause
-   * @param exitCode exit code
-   * @param message message to use in exception
-   * @param cause cause of the exception
-   */
-  public ServiceLaunchException(int exitCode, String message, Throwable cause) {
-    super(message, cause);
-    this.exitCode = exitCode;
-  }
-
-  /**
-   * Get the exit code
-   * @return the exit code
-   */
-  @Override
-  public int getExitCode() {
-    return exitCode;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/SliderException.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/SliderException.java
deleted file mode 100644
index 5b74b80e298..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/SliderException.java
+++ /dev/null
@@ -1,66 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.exceptions;
-
-import org.apache.hadoop.yarn.service.conf.SliderExitCodes;
-
-public class SliderException extends ServiceLaunchException implements
-    SliderExitCodes {
-  public SliderException() {
-    super(EXIT_EXCEPTION_THROWN, "SliderException");
-  }
-
-  public SliderException(int code, String message) {
-    super(code, message);
-  }
-
-  public SliderException(String s) {
-    super(EXIT_EXCEPTION_THROWN, s);
-  }
-
-  public SliderException(String s, Throwable throwable) {
-    super(EXIT_EXCEPTION_THROWN, s, throwable);
-  }
-
-  /**
-   * Format the exception as you create it
-   * @param code exit code
-   * @param message exception message -sprintf formatted
-   * @param args arguments for the formatting
-   */
-  public SliderException(int code, String message, Object... args) {
-    super(code, String.format(message, args));
-  }
-
-  /**
-   * Format the exception, include a throwable. 
-   * The throwable comes before the message so that it is out of the varargs
-   * @param code exit code
-   * @param throwable thrown
-   * @param message message
-   * @param args arguments
-   */
-  public SliderException(int code,
-      Throwable throwable,
-      String message,
-      Object... args) {
-    super(code, String.format(message, args), throwable);
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/UsageException.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/UsageException.java
deleted file mode 100644
index 3a9fa25507d..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/exceptions/UsageException.java
+++ /dev/null
@@ -1,34 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.exceptions;
-
-/**
- * Used to raise a usage exception ... this has the exit code
- * {@link #EXIT_USAGE}
- */
-public class UsageException extends SliderException {
-  public UsageException(String s, Object... args) {
-    super(EXIT_USAGE, s, args);
-  }
-
-  public UsageException(Throwable throwable, String message,
-      Object... args) {
-    super(EXIT_USAGE, throwable, message, args);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/impl/pb/client/ClientAMProtocolPBClientImpl.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/impl/pb/client/ClientAMProtocolPBClientImpl.java
deleted file mode 100644
index 79d6773d0ec..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/impl/pb/client/ClientAMProtocolPBClientImpl.java
+++ /dev/null
@@ -1,171 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.impl.pb.client;
-
-import org.apache.hadoop.thirdparty.protobuf.ServiceException;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.ipc.ProtobufRpcEngine2;
-import org.apache.hadoop.ipc.RPC;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.ipc.RPCUtil;
-import org.apache.hadoop.yarn.service.ClientAMProtocol;
-
-import java.io.Closeable;
-import java.io.IOException;
-import java.net.InetSocketAddress;
-
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CancelUpgradeRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CancelUpgradeResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CompInstancesUpgradeResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CompInstancesUpgradeRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.DecommissionCompInstancesRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.DecommissionCompInstancesResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.FlexComponentsRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.FlexComponentsResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetCompInstancesRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetCompInstancesResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetStatusRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetStatusResponseProto;
-import org.apache.hadoop.yarn.service.impl.pb.service.ClientAMProtocolPB;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.RestartServiceRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.RestartServiceResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.StopResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.StopRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.UpgradeServiceRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.UpgradeServiceResponseProto;
-
-public class ClientAMProtocolPBClientImpl
-    implements ClientAMProtocol, Closeable {
-
-  private ClientAMProtocolPB proxy;
-
-  public ClientAMProtocolPBClientImpl(long clientVersion,
-      InetSocketAddress addr, Configuration conf) throws IOException {
-    RPC.setProtocolEngine(conf, ClientAMProtocolPB.class,
-        ProtobufRpcEngine2.class);
-    proxy = RPC.getProxy(ClientAMProtocolPB.class, clientVersion, addr, conf);
-
-  }
-
-  @Override public FlexComponentsResponseProto flexComponents(
-      FlexComponentsRequestProto request) throws IOException, YarnException {
-    try {
-      return proxy.flexComponents(null, request);
-    } catch (ServiceException e) {
-      RPCUtil.unwrapAndThrowException(e);
-    }
-    return null;
-  }
-
-  @Override
-  public GetStatusResponseProto getStatus(GetStatusRequestProto request)
-      throws IOException, YarnException {
-    try {
-      return proxy.getStatus(null, request);
-    } catch (ServiceException e) {
-      RPCUtil.unwrapAndThrowException(e);
-    }
-    return null;
-  }
-
-  @Override
-  public StopResponseProto stop(StopRequestProto requestProto)
-      throws IOException, YarnException {
-    try {
-      return proxy.stop(null, requestProto);
-    } catch (ServiceException e) {
-      RPCUtil.unwrapAndThrowException(e);
-    }
-    return null;
-  }
-
-  @Override public void close() {
-    if (this.proxy != null) {
-      RPC.stopProxy(this.proxy);
-    }
-  }
-
-  @Override
-  public UpgradeServiceResponseProto upgrade(
-      UpgradeServiceRequestProto request) throws IOException, YarnException {
-    try {
-      return proxy.upgradeService(null, request);
-    } catch (ServiceException e) {
-      RPCUtil.unwrapAndThrowException(e);
-    }
-    return null;
-  }
-
-  @Override
-  public RestartServiceResponseProto restart(RestartServiceRequestProto request)
-      throws IOException, YarnException {
-    try {
-      return proxy.restartService(null, request);
-    } catch (ServiceException e) {
-      RPCUtil.unwrapAndThrowException(e);
-    }
-    return null;
-  }
-
-  @Override
-  public CompInstancesUpgradeResponseProto upgrade(
-      CompInstancesUpgradeRequestProto request)
-      throws IOException, YarnException {
-    try {
-      return proxy.upgrade(null, request);
-    } catch (ServiceException e) {
-      RPCUtil.unwrapAndThrowException(e);
-    }
-    return null;
-  }
-
-  @Override
-  public GetCompInstancesResponseProto getCompInstances(
-      GetCompInstancesRequestProto request) throws IOException, YarnException {
-    try {
-      return proxy.getCompInstances(null, request);
-    } catch (ServiceException e) {
-      RPCUtil.unwrapAndThrowException(e);
-    }
-    return null;
-  }
-
-  @Override
-  public CancelUpgradeResponseProto cancelUpgrade(
-      CancelUpgradeRequestProto request) throws IOException, YarnException {
-    try {
-      return proxy.cancelUpgrade(null, request);
-    } catch (ServiceException e) {
-      RPCUtil.unwrapAndThrowException(e);
-    }
-    return null;
-  }
-
-  @Override
-  public DecommissionCompInstancesResponseProto decommissionCompInstances(
-      DecommissionCompInstancesRequestProto request)
-      throws IOException, YarnException {
-    try {
-      return proxy.decommissionCompInstances(null, request);
-    } catch (ServiceException e) {
-      RPCUtil.unwrapAndThrowException(e);
-    }
-    return null;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/impl/pb/service/ClientAMProtocolPB.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/impl/pb/service/ClientAMProtocolPB.java
deleted file mode 100644
index 6a9cd3785eb..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/impl/pb/service/ClientAMProtocolPB.java
+++ /dev/null
@@ -1,29 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.impl.pb.service;
-
-import org.apache.hadoop.ipc.ProtocolInfo;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol;
-
-@ProtocolInfo(
-    protocolName = "org.apache.hadoop.yarn.service.ClientAMProtocol",
-    protocolVersion = 1)
-public interface ClientAMProtocolPB extends
-    ClientAMProtocol.ClientAMProtocolService.BlockingInterface {
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/impl/pb/service/ClientAMProtocolPBServiceImpl.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/impl/pb/service/ClientAMProtocolPBServiceImpl.java
deleted file mode 100644
index 47b11ebe960..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/impl/pb/service/ClientAMProtocolPBServiceImpl.java
+++ /dev/null
@@ -1,145 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.impl.pb.service;
-
-import org.apache.hadoop.thirdparty.protobuf.RpcController;
-import org.apache.hadoop.thirdparty.protobuf.ServiceException;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CancelUpgradeRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CancelUpgradeResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CompInstancesUpgradeRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CompInstancesUpgradeResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.DecommissionCompInstancesRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.DecommissionCompInstancesResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.FlexComponentsRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.FlexComponentsResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetCompInstancesRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetCompInstancesResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetStatusRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetStatusResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.RestartServiceRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.RestartServiceResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.UpgradeServiceRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.UpgradeServiceResponseProto;
-import org.apache.hadoop.yarn.service.ClientAMProtocol;
-
-import java.io.IOException;
-
-public class ClientAMProtocolPBServiceImpl implements ClientAMProtocolPB {
-
-  private ClientAMProtocol real;
-
-  public ClientAMProtocolPBServiceImpl(ClientAMProtocol impl) {
-    this.real = impl;
-  }
-
-  @Override
-  public FlexComponentsResponseProto flexComponents(RpcController controller,
-      FlexComponentsRequestProto request) throws ServiceException {
-    try {
-      return real.flexComponents(request);
-    } catch (IOException | YarnException e) {
-      throw new ServiceException(e);
-    }
-  }
-
-  @Override public GetStatusResponseProto getStatus(RpcController controller,
-      GetStatusRequestProto request) throws ServiceException {
-    try {
-      return real.getStatus(request);
-    } catch (IOException | YarnException e) {
-      throw new ServiceException(e);
-    }
-  }
-
-  @Override
-  public org.apache.hadoop.yarn.proto.ClientAMProtocol.StopResponseProto stop(
-      RpcController controller,
-      org.apache.hadoop.yarn.proto.ClientAMProtocol.StopRequestProto request)
-      throws ServiceException {
-    try {
-      return real.stop(request);
-    } catch (IOException | YarnException e) {
-      throw new ServiceException(e);
-    }
-  }
-
-  @Override
-  public UpgradeServiceResponseProto upgradeService(RpcController controller,
-      UpgradeServiceRequestProto request) throws ServiceException {
-    try {
-      return real.upgrade(request);
-    } catch (IOException | YarnException e) {
-      throw new ServiceException(e);
-    }
-  }
-
-  @Override
-  public RestartServiceResponseProto restartService(RpcController controller,
-      RestartServiceRequestProto request) throws ServiceException {
-    try {
-      return real.restart(request);
-    } catch (IOException | YarnException e) {
-      throw new ServiceException(e);
-    }
-  }
-
-  @Override
-  public CompInstancesUpgradeResponseProto upgrade(RpcController controller,
-      CompInstancesUpgradeRequestProto request) throws ServiceException {
-    try {
-      return real.upgrade(request);
-    } catch (IOException | YarnException e) {
-      throw new ServiceException(e);
-    }
-  }
-
-  @Override
-  public GetCompInstancesResponseProto getCompInstances(
-      RpcController controller, GetCompInstancesRequestProto request)
-      throws ServiceException {
-    try {
-      return real.getCompInstances(request);
-    } catch (IOException | YarnException e) {
-      throw new ServiceException(e);
-    }
-  }
-
-  @Override
-  public CancelUpgradeResponseProto cancelUpgrade(
-      RpcController controller, CancelUpgradeRequestProto request)
-      throws ServiceException {
-    try {
-      return real.cancelUpgrade(request);
-    } catch (IOException | YarnException e) {
-      throw new ServiceException(e);
-    }
-  }
-
-  @Override
-  public DecommissionCompInstancesResponseProto decommissionCompInstances(
-      RpcController controller, DecommissionCompInstancesRequestProto
-      request) throws ServiceException {
-    try {
-      return real.decommissionCompInstances(request);
-    } catch (IOException | YarnException e) {
-      throw new ServiceException(e);
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/ComponentHealthThresholdMonitor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/ComponentHealthThresholdMonitor.java
deleted file mode 100644
index 9cf62fcb410..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/ComponentHealthThresholdMonitor.java
+++ /dev/null
@@ -1,151 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.monitor;
-
-import java.util.Date;
-import java.util.concurrent.TimeUnit;
-
-import org.apache.hadoop.util.ExitUtil;
-import org.apache.hadoop.yarn.service.component.Component;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * Monitors the health of containers of a specific component at a regular
- * interval. It takes necessary actions when the health of a component drops
- * below a desired threshold.
- */
-public class ComponentHealthThresholdMonitor implements Runnable {
-  private static final Logger LOG = LoggerFactory
-      .getLogger(ComponentHealthThresholdMonitor.class);
-  private final Component component;
-  private final int healthThresholdPercent;
-  private final long healthThresholdWindowSecs;
-  private final long healthThresholdWindowNanos;
-  private long firstOccurrenceTimestamp = 0;
-  // Sufficient logging happens when component health is below threshold.
-  // However, there has to be some logging when it is above threshold, otherwise
-  // service owners have no idea how the health is fluctuating. So let's log
-  // whenever there is a change in component health, thereby preventing
-  // excessive logging on every poll.
-  private float prevReadyContainerFraction = 0;
-
-  public ComponentHealthThresholdMonitor(Component component,
-      int healthThresholdPercent, long healthThresholdWindowSecs) {
-    this.component = component;
-    this.healthThresholdPercent = healthThresholdPercent;
-    this.healthThresholdWindowSecs = healthThresholdWindowSecs;
-    this.healthThresholdWindowNanos = TimeUnit.NANOSECONDS
-        .convert(healthThresholdWindowSecs, TimeUnit.SECONDS);
-  }
-
-  @Override
-  public void run() {
-    LOG.debug("ComponentHealthThresholdMonitor run method");
-    // Perform container health checks against desired threshold
-    long desiredContainerCount = component.getNumDesiredInstances();
-    // If desired container count for this component is 0 then nothing to do
-    if (desiredContainerCount == 0) {
-      return;
-    }
-    long readyContainerCount = component.getNumReadyInstances();
-    float thresholdFraction = (float) healthThresholdPercent / 100;
-    // No possibility of div by 0 since desiredContainerCount won't be 0 here
-    float readyContainerFraction = (float) readyContainerCount
-        / desiredContainerCount;
-    boolean healthChanged = false;
-    if (Math.abs(
-        readyContainerFraction - prevReadyContainerFraction) > .0000001) {
-      prevReadyContainerFraction = readyContainerFraction;
-      healthChanged = true;
-    }
-    String readyContainerPercentStr = String.format("%.2f",
-        readyContainerFraction * 100);
-    // Check if the current ready container percent is less than the
-    // threshold percent
-    if (readyContainerFraction < thresholdFraction) {
-      // Check if it is the first occurrence and if yes set the timestamp
-      long currentTimestamp = System.nanoTime();
-      if (firstOccurrenceTimestamp == 0) {
-        firstOccurrenceTimestamp = currentTimestamp;
-        Date date = new Date();
-        LOG.info(
-            "[COMPONENT {}] Health has gone below threshold. Starting health "
-                + "threshold timer at ts = {} ({})",
-            component.getName(), date.getTime(), date);
-      }
-      long elapsedTime = currentTimestamp - firstOccurrenceTimestamp;
-      long elapsedTimeSecs = TimeUnit.SECONDS.convert(elapsedTime,
-          TimeUnit.NANOSECONDS);
-      LOG.warn(
-          "[COMPONENT {}] Current health {}% is below health threshold of "
-              + "{}% for {} secs (threshold window = {} secs)",
-          component.getName(), readyContainerPercentStr,
-          healthThresholdPercent, elapsedTimeSecs, healthThresholdWindowSecs);
-      if (elapsedTime > healthThresholdWindowNanos) {
-        LOG.warn(
-            "[COMPONENT {}] Current health {}% has been below health "
-                + "threshold of {}% for {} secs (threshold window = {} secs)",
-            component.getName(), readyContainerPercentStr,
-            healthThresholdPercent, elapsedTimeSecs, healthThresholdWindowSecs);
-        // Trigger service stop
-        String exitDiag = String.format(
-            "Service is being killed because container health for component "
-                + "%s was %s%% (health threshold = %d%%) for %d secs "
-                + "(threshold window = %d secs)",
-            component.getName(), readyContainerPercentStr,
-            healthThresholdPercent, elapsedTimeSecs, healthThresholdWindowSecs);
-        // Append to global diagnostics that will be reported to RM.
-        component.getScheduler().getDiagnostics().append(exitDiag);
-        LOG.warn(exitDiag);
-        // Sleep for 5 seconds in hope that the state can be recorded in ATS.
-        // In case there's a client polling the component state, it can be
-        // notified.
-        try {
-          Thread.sleep(5000);
-        } catch (InterruptedException e) {
-          LOG.error("Interrupted on sleep while exiting.", e);
-        }
-        ExitUtil.terminate(-1);
-      }
-    } else {
-      String logMsg = "[COMPONENT {}] Health threshold = {}%, Current health "
-          + "= {}% (Current Ready count = {}, Desired count = {})";
-      if (healthChanged) {
-        LOG.info(logMsg, component.getName(), healthThresholdPercent,
-            readyContainerPercentStr, readyContainerCount,
-            desiredContainerCount);
-      } else {
-        LOG.debug(logMsg, component.getName(), healthThresholdPercent,
-            readyContainerPercentStr, readyContainerCount,
-            desiredContainerCount);
-      }
-      // The container health might have recovered above threshold after being
-      // below for less than the threshold window amount of time. So we need
-      // to reset firstOccurrenceTimestamp to 0.
-      if (firstOccurrenceTimestamp != 0) {
-        Date date = new Date();
-        LOG.info(
-            "[COMPONENT {}] Health recovered above threshold at ts = {} ({})",
-            component.getName(), date.getTime(), date);
-        firstOccurrenceTimestamp = 0;
-      }
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/ServiceMonitor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/ServiceMonitor.java
deleted file mode 100644
index 9e77e41bb9b..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/ServiceMonitor.java
+++ /dev/null
@@ -1,155 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.monitor;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.service.AbstractService;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.service.ServiceContext;
-import org.apache.hadoop.yarn.service.component.Component;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceState;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConf;
-import org.apache.hadoop.yarn.service.component.ComponentEvent;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEvent;
-import org.apache.hadoop.yarn.service.component.ComponentState;
-import org.apache.hadoop.yarn.service.monitor.probe.ProbeStatus;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.util.Map;
-import java.util.concurrent.Executors;
-import java.util.concurrent.ScheduledExecutorService;
-import java.util.concurrent.TimeUnit;
-
-import static org.apache.hadoop.yarn.service.component.instance.ComponentInstanceState.REINITIALIZED;
-import static org.apache.hadoop.yarn.service.component.instance.ComponentInstanceState.STARTED;
-import static org.apache.hadoop.yarn.service.component.ComponentEventType.FLEX;
-import static org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEventType.BECOME_NOT_READY;
-import static org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEventType.BECOME_READY;
-import static org.apache.hadoop.yarn.service.component.instance.ComponentInstanceState.READY;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.CONTAINER_FAILURE_WINDOW;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.DEFAULT_CONTAINER_FAILURE_WINDOW;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.DEFAULT_READINESS_CHECK_INTERVAL;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.READINESS_CHECK_INTERVAL;
-
-public class ServiceMonitor extends AbstractService {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(ServiceMonitor.class);
-
-  public ScheduledExecutorService executorService;
-  private  Map<ContainerId, ComponentInstance> liveInstances = null;
-  private ServiceContext context;
-  private Configuration conf;
-
-  public ServiceMonitor(String name, ServiceContext context) {
-    super(name);
-    liveInstances = context.scheduler.getLiveInstances();
-    this.context = context;
-  }
-
-  @Override
-  public void serviceInit(Configuration conf) throws Exception {
-    executorService = Executors.newScheduledThreadPool(1);
-    this.conf = conf;
-    super.serviceInit(conf);
-  }
-
-  @Override
-  public void serviceStart() throws Exception {
-    long readinessCheckInterval = YarnServiceConf
-        .getLong(READINESS_CHECK_INTERVAL, DEFAULT_READINESS_CHECK_INTERVAL,
-            context.service.getConfiguration(), conf);
-
-    executorService
-        .scheduleAtFixedRate(new ReadinessChecker(), readinessCheckInterval,
-            readinessCheckInterval, TimeUnit.SECONDS);
-
-    // Default 6 hours.
-    long failureResetInterval = YarnServiceConf
-        .getLong(CONTAINER_FAILURE_WINDOW, DEFAULT_CONTAINER_FAILURE_WINDOW,
-            context.service.getConfiguration(), conf);
-
-    executorService
-        .scheduleAtFixedRate(new ContainerFailureReset(), failureResetInterval,
-            failureResetInterval, TimeUnit.SECONDS);
-  }
-
-  @Override
-  public void serviceStop() throws Exception {
-    if (executorService != null) {
-      executorService.shutdownNow();
-    }
-  }
-
-  private class ReadinessChecker implements Runnable {
-
-    @Override
-    public void run() {
-
-      // check if the comp instance are ready
-      for (Map.Entry<ContainerId, ComponentInstance> entry : liveInstances
-          .entrySet()) {
-        ComponentInstance instance = entry.getValue();
-
-        ProbeStatus status = instance.ping();
-        ComponentInstanceState instanceState = instance.getState();
-        if (status.isSuccess()) {
-          if (instanceState == STARTED || instanceState == REINITIALIZED) {
-            LOG.info("Readiness check succeeded for {}: {}", instance
-                .getCompInstanceName(), status);
-            // synchronously update the state.
-            instance.handle(
-                new ComponentInstanceEvent(entry.getKey(), BECOME_READY));
-          }
-        } else {
-          LOG.info("Readiness check failed for {}: {}", instance
-              .getCompInstanceName(), status);
-          if (instance.getState() == READY) {
-            instance.handle(
-                new ComponentInstanceEvent(entry.getKey(), BECOME_NOT_READY));
-          }
-        }
-      }
-
-      for (Component component : context.scheduler.getAllComponents()
-          .values()) {
-        // If comp hasn't started yet and its dependencies are satisfied
-        if (component.getState() == ComponentState.INIT && component
-            .areDependenciesReady()) {
-          LOG.info("[COMPONENT {}]: Dependencies satisfied, ramping up.",
-              component.getName());
-          ComponentEvent event = new ComponentEvent(component.getName(), FLEX)
-              .setDesired(component.getComponentSpec().getNumberOfContainers());
-          component.handle(event);
-        }
-      }
-    }
-  }
-
-  private class ContainerFailureReset implements Runnable {
-    @Override
-    public void run() {
-      for (Component component : context.scheduler.getAllComponents().values()) {
-        component.resetCompFailureCount();
-      }
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/DefaultProbe.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/DefaultProbe.java
deleted file mode 100644
index 4077013392e..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/DefaultProbe.java
+++ /dev/null
@@ -1,99 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.monitor.probe;
-
-import org.apache.hadoop.yarn.api.records.ContainerStatus;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.apache.hadoop.yarn.service.utils.ServiceRegistryUtils;
-import org.apache.hadoop.yarn.service.utils.ServiceUtils;
-
-import java.io.IOException;
-import java.util.Collections;
-import java.util.Map;
-
-/**
- * A probe that checks whether the AM has retrieved an IP for a container.
- * Optional parameters enable a subsequent check for whether a DNS lookup can
- * be performed for the container's hostname. Configurable properties include:
- *
- *   dns.check.enabled - true if DNS check should be performed (default false)
- *   dns.address - optional IP:port address of DNS server to use for DNS check
- */
-public class DefaultProbe extends Probe {
-  private final boolean dnsCheckEnabled;
-  private final String dnsAddress;
-
-  public DefaultProbe(Map<String, String> props) {
-    this("Default probe: IP presence", props);
-  }
-
-  protected DefaultProbe(String name, Map<String, String> props) {
-    this.dnsCheckEnabled = getPropertyBool(props,
-        DEFAULT_PROBE_DNS_CHECK_ENABLED,
-        DEFAULT_PROBE_DNS_CHECK_ENABLED_DEFAULT);
-    this.dnsAddress = props.get(DEFAULT_PROBE_DNS_ADDRESS);
-    String additionalName = "";
-    if (dnsCheckEnabled) {
-      if (dnsAddress == null) {
-        additionalName = " with DNS checking";
-      } else {
-        additionalName =  " with DNS checking and DNS server address " +
-            dnsAddress;
-      }
-    }
-    setName(name + additionalName);
-  }
-
-  public static DefaultProbe create() throws IOException {
-    return new DefaultProbe(Collections.emptyMap());
-  }
-
-  public static DefaultProbe create(Map<String, String> props) throws
-      IOException {
-    return new DefaultProbe(props);
-  }
-
-  @Override
-  public ProbeStatus ping(ComponentInstance instance) {
-    ProbeStatus status = new ProbeStatus();
-
-    ContainerStatus containerStatus = instance.getContainerStatus();
-    if (containerStatus == null || ServiceUtils.isEmpty(containerStatus
-        .getIPs())) {
-      status.fail(this, new IOException(
-          instance.getCompInstanceName() + ": IP is not available yet"));
-      return status;
-    }
-
-    String hostname = instance.getHostname();
-    if (dnsCheckEnabled && !ServiceRegistryUtils.registryDNSLookupExists(
-        dnsAddress, hostname)) {
-      status.fail(this, new IOException(
-          instance.getCompInstanceName() + ": DNS checking is enabled, but " +
-              "lookup for " + hostname + " is not available yet"));
-      return status;
-    }
-
-    status.succeed(this);
-    return status;
-  }
-
-  protected boolean isDnsCheckEnabled() {
-    return dnsCheckEnabled;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/HttpProbe.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/HttpProbe.java
deleted file mode 100644
index 40a87937629..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/HttpProbe.java
+++ /dev/null
@@ -1,117 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.monitor.probe;
-
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.net.HttpURLConnection;
-import java.net.URL;
-import java.util.Map;
-
-/**
- * A probe that checks whether a successful HTTP response code can be obtained
- * from a container. A well-formed URL must be provided. The URL is intended
- * to contain a token ${THIS_HOST} that will be replaced by the IP of the
- * container. This probe also performs the checks of the {@link DefaultProbe}.
- * Additional configurable properties include:
- *
- *   url - required URL for HTTP connection, e.g. http://${THIS_HOST}:8080
- *   timeout - connection timeout (default 1000)
- *   min.success - minimum response code considered successful (default 200)
- *   max.success - maximum response code considered successful (default 299)
- *
- */
-public class HttpProbe extends DefaultProbe {
-  protected static final Logger log = LoggerFactory.getLogger(HttpProbe.class);
-
-  private static final String HOST_TOKEN = "${THIS_HOST}";
-
-  private final String urlString;
-  private final int timeout;
-  private final int min, max;
-
-
-  public HttpProbe(String url, int timeout, int min, int max,
-      Map<String, String> props) {
-    super("Http probe of " + url + " [" + min + "-" + max + "]", props);
-    this.urlString = url;
-    this.timeout = timeout;
-    this.min = min;
-    this.max = max;
-  }
-
-  public static HttpProbe create(Map<String, String> props)
-      throws IOException {
-    String urlString = getProperty(props, WEB_PROBE_URL, null);
-    new URL(urlString);
-    int timeout = getPropertyInt(props, WEB_PROBE_CONNECT_TIMEOUT,
-        WEB_PROBE_CONNECT_TIMEOUT_DEFAULT);
-    int minSuccess = getPropertyInt(props, WEB_PROBE_MIN_SUCCESS,
-        WEB_PROBE_MIN_SUCCESS_DEFAULT);
-    int maxSuccess = getPropertyInt(props, WEB_PROBE_MAX_SUCCESS,
-        WEB_PROBE_MAX_SUCCESS_DEFAULT);
-    return new HttpProbe(urlString, timeout, minSuccess, maxSuccess, props);
-  }
-
-
-  private static HttpURLConnection getConnection(URL url, int timeout) throws
-      IOException {
-    HttpURLConnection connection = (HttpURLConnection) url.openConnection();
-    connection.setInstanceFollowRedirects(true);
-    connection.setConnectTimeout(timeout);
-    return connection;
-  }
-
-  @Override
-  public ProbeStatus ping(ComponentInstance instance) {
-    ProbeStatus status = super.ping(instance);
-    if (!status.isSuccess()) {
-      return status;
-    }
-    String ip = instance.getContainerStatus().getIPs().get(0);
-    HttpURLConnection connection = null;
-    String hostString = urlString.replace(HOST_TOKEN, ip);
-    try {
-      URL url = new URL(hostString);
-      connection = getConnection(url, this.timeout);
-      int rc = connection.getResponseCode();
-      if (rc < min || rc > max) {
-        String error = "Probe " + url + " error code: " + rc;
-        log.info(error);
-        status.fail(this,
-            new IOException(error));
-      } else {
-        status.succeed(this);
-      }
-    } catch (Throwable e) {
-      String error =
-          "Probe " + hostString + " failed for IP " + ip + ": " + e;
-      log.info(error, e);
-      status.fail(this,
-          new IOException(error, e));
-    } finally {
-      if (connection != null) {
-        connection.disconnect();
-      }
-    }
-    return status;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/LogEntryBuilder.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/LogEntryBuilder.java
deleted file mode 100644
index 9ad86fe61bb..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/LogEntryBuilder.java
+++ /dev/null
@@ -1,76 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.monitor.probe;
-
-/**
- * Build up log entries for ease of splunk
- */
-public class LogEntryBuilder {
-
-  private final StringBuilder builder = new StringBuilder();
-
-  public LogEntryBuilder() {
-  }
-
-  public LogEntryBuilder(String text) {
-    elt(text);
-  }
-
-
-  public LogEntryBuilder(String name, Object value) {
-    entry(name, value);
-  }
-
-  public LogEntryBuilder elt(String text) {
-    addComma();
-    builder.append(text);
-    return this;
-  }
-
-  public LogEntryBuilder elt(String name, Object value) {
-    addComma();
-    entry(name, value);
-    return this;
-  }
-
-  private void addComma() {
-    if (!isEmpty()) {
-      builder.append(", ");
-    }
-  }
-
-  private void entry(String name, Object value) {
-    builder.append(name).append('=');
-    if (value != null) {
-      builder.append('"').append(value.toString()).append('"');
-    } else {
-      builder.append("null");
-    }
-  }
-
-  @Override
-  public String toString() {
-    return builder.toString();
-  }
-
-  private boolean isEmpty() {
-    return builder.length() == 0;
-  }
-
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/MonitorKeys.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/MonitorKeys.java
deleted file mode 100644
index 97770d4d2b1..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/MonitorKeys.java
+++ /dev/null
@@ -1,78 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.monitor.probe;
-
-/**
- * Config keys for monitoring
- */
-public interface MonitorKeys {
-
-  /**
-   * Default probing key : DNS check enabled {@value}.
-   */
-  String DEFAULT_PROBE_DNS_CHECK_ENABLED = "dns.check.enabled";
-  /**
-   * Default probing default : DNS check enabled {@value}.
-   */
-  boolean DEFAULT_PROBE_DNS_CHECK_ENABLED_DEFAULT = false;
-  /**
-   * Default probing key : DNS checking address IP:port {@value}.
-   */
-  String DEFAULT_PROBE_DNS_ADDRESS = "dns.address";
-  /**
-   * Port probing key : port to attempt to create a TCP connection to {@value}.
-   */
-  String PORT_PROBE_PORT = "port";
-  /**
-   * Port probing key : timeout for the the connection attempt {@value}.
-   */
-  String PORT_PROBE_CONNECT_TIMEOUT = "timeout";
-  /**
-   * Port probing default : timeout for the connection attempt {@value}.
-   */
-  int PORT_PROBE_CONNECT_TIMEOUT_DEFAULT = 1000;
-
-  /**
-   * Web probing key : URL {@value}.
-   */
-  String WEB_PROBE_URL = "url";
-  /**
-   * Web probing key : min success code {@value}.
-   */
-  String WEB_PROBE_MIN_SUCCESS = "min.success";
-  /**
-   * Web probing key : max success code {@value}.
-   */
-  String WEB_PROBE_MAX_SUCCESS = "max.success";
-  /**
-   * Web probing default : min successful response code {@value}.
-   */
-  int WEB_PROBE_MIN_SUCCESS_DEFAULT = 200;
-  /**
-   * Web probing default : max successful response code {@value}.
-   */
-  int WEB_PROBE_MAX_SUCCESS_DEFAULT = 299;
-  /**
-   * Web probing key : timeout for the connection attempt {@value}
-   */
-  String WEB_PROBE_CONNECT_TIMEOUT = "timeout";
-  /**
-   * Port probing default : timeout for the connection attempt {@value}.
-   */
-  int WEB_PROBE_CONNECT_TIMEOUT_DEFAULT = 1000;
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/MonitorUtils.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/MonitorUtils.java
deleted file mode 100644
index 0b57e6c6bf5..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/MonitorUtils.java
+++ /dev/null
@@ -1,84 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.monitor.probe;
-
-import org.apache.hadoop.yarn.service.api.records.ReadinessCheck;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.util.Formatter;
-import java.util.Locale;
-
-/**
- * Various utils to work with the monitor
- */
-public final class MonitorUtils {
-  protected static final Logger LOG = LoggerFactory.getLogger(MonitorUtils
-      .class);
-
-  private MonitorUtils() {
-  }
-
-  public static String toPlural(int val) {
-    return val != 1 ? "s" : "";
-  }
-
-  /**
-   * Convert milliseconds to human time -the exact format is unspecified
-   * @param milliseconds a time in milliseconds
-   * @return a time that is converted to human intervals
-   */
-  public static String millisToHumanTime(long milliseconds) {
-    StringBuilder sb = new StringBuilder();
-    // Send all output to the Appendable object sb
-    Formatter formatter = new Formatter(sb, Locale.US);
-
-    long s = Math.abs(milliseconds / 1000);
-    long m = Math.abs(milliseconds % 1000);
-    if (milliseconds > 0) {
-      formatter.format("%d.%03ds", s, m);
-    } else if (milliseconds == 0) {
-      formatter.format("0");
-    } else {
-      formatter.format("-%d.%03ds", s, m);
-    }
-    return sb.toString();
-  }
-
-  public static Probe getProbe(ReadinessCheck readinessCheck) {
-    try {
-      if (readinessCheck == null) {
-        return DefaultProbe.create();
-      }
-      if (readinessCheck.getType() == null) {
-        return DefaultProbe.create(readinessCheck.getProperties());
-      }
-      switch (readinessCheck.getType()) {
-      case HTTP:
-        return HttpProbe.create(readinessCheck.getProperties());
-      case PORT:
-        return PortProbe.create(readinessCheck.getProperties());
-      default:
-        return DefaultProbe.create(readinessCheck.getProperties());
-      }
-    } catch (Throwable t) {
-      throw new IllegalArgumentException("Error creating readiness check " +
-          t);
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/PortProbe.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/PortProbe.java
deleted file mode 100644
index e62048a0aeb..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/PortProbe.java
+++ /dev/null
@@ -1,98 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.monitor.probe;
-
-import org.apache.hadoop.io.IOUtils;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.net.InetSocketAddress;
-import java.net.Socket;
-import java.util.Map;
-
-/**
- * A probe that checks whether a container has a specified port open. This
- * probe also performs the checks of the {@link DefaultProbe}. Additional
- * configurable properties include:
- *
- *   port - required port for socket connection
- *   timeout - connection timeout (default 1000)
- */
-public class PortProbe extends DefaultProbe {
-  protected static final Logger log = LoggerFactory.getLogger(PortProbe.class);
-  private final int port;
-  private final int timeout;
-
-  public PortProbe(int port, int timeout, Map<String, String> props) {
-    super("Port probe of " + port + " for " + timeout + "ms", props);
-    this.port = port;
-    this.timeout = timeout;
-  }
-
-  public static PortProbe create(Map<String, String> props)
-      throws IOException {
-    int port = getPropertyInt(props, PORT_PROBE_PORT, null);
-
-    if (port >= 65536) {
-      throw new IOException(PORT_PROBE_PORT + " " + port + " is out of " +
-          "range");
-    }
-
-    int timeout = getPropertyInt(props, PORT_PROBE_CONNECT_TIMEOUT,
-        PORT_PROBE_CONNECT_TIMEOUT_DEFAULT);
-
-    return new PortProbe(port, timeout, props);
-  }
-
-  /**
-   * Try to connect to the (host,port); a failure to connect within
-   * the specified timeout is a failure.
-   * @param instance role instance
-   * @return the outcome
-   */
-  @Override
-  public ProbeStatus ping(ComponentInstance instance) {
-    ProbeStatus status = super.ping(instance);
-    if (!status.isSuccess()) {
-      return status;
-    }
-
-    String ip = instance.getContainerStatus().getIPs().get(0);
-    InetSocketAddress sockAddr = new InetSocketAddress(ip, port);
-    Socket socket = new Socket();
-    try {
-      if (log.isDebugEnabled()) {
-        log.debug(instance.getCompInstanceName() + ": Connecting " + sockAddr
-            .toString() + ", timeout=" + MonitorUtils
-            .millisToHumanTime(timeout));
-      }
-      socket.connect(sockAddr, timeout);
-      status.succeed(this);
-    } catch (Throwable e) {
-      String error =
-          instance.getCompInstanceName() + ": Probe " + sockAddr + " failed";
-      log.debug(error, e);
-      status.fail(this, new IOException(error, e));
-    } finally {
-      IOUtils.closeSocket(socket);
-    }
-    return status;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/Probe.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/Probe.java
deleted file mode 100644
index 78c79c7535b..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/Probe.java
+++ /dev/null
@@ -1,108 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.monitor.probe;
-
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-
-import java.io.IOException;
-import java.util.Map;
-
-/**
- * Base class of all probes.
- */
-public abstract class Probe implements MonitorKeys {
-
-  private String name;
-
-  protected Probe() {
-  }
-
-  /**
-   * Create a probe of a specific name
-   *
-   * @param name probe name
-   */
-  public Probe(String name) {
-    this.name = name;
-  }
-
-
-  protected void setName(String name) {
-    this.name = name;
-  }
-
-  public String getName() {
-    return name;
-  }
-
-
-  @Override
-  public String toString() {
-    return getName();
-  }
-
-  public static String getProperty(Map<String, String> props, String name,
-      String defaultValue) throws IOException {
-    String value = props.get(name);
-    if (StringUtils.isEmpty(value)) {
-      if (defaultValue == null) {
-        throw new IOException(name + " not specified");
-      }
-      return defaultValue;
-    }
-    return value;
-  }
-
-  public static int getPropertyInt(Map<String, String> props, String name,
-      Integer defaultValue) throws IOException {
-    String value = props.get(name);
-    if (StringUtils.isEmpty(value)) {
-      if (defaultValue == null) {
-        throw new IOException(name + " not specified");
-      }
-      return defaultValue;
-    }
-    return Integer.parseInt(value);
-  }
-
-  public static boolean getPropertyBool(Map<String, String> props, String name,
-      boolean defaultValue) {
-    String value = props.get(name);
-    if (StringUtils.isEmpty(value)) {
-      return defaultValue;
-    }
-    return Boolean.parseBoolean(value);
-  }
-
-  /**
-   * perform any prelaunch initialization
-   */
-  public void init() throws IOException {
-
-  }
-
-  /**
-   * Ping the endpoint. All exceptions must be caught and included in the
-   * (failure) status.
-   *
-   * @param instance instance to ping
-   * @return the status
-   */
-  public abstract ProbeStatus ping(ComponentInstance instance);
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/ProbeStatus.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/ProbeStatus.java
deleted file mode 100644
index bc62dcd0c1c..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/monitor/probe/ProbeStatus.java
+++ /dev/null
@@ -1,160 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *      http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.monitor.probe;
-
-import java.io.Serializable;
-import java.util.Date;
-
-/**
- * Status message of a probe. This is designed to be sent over the wire, though the exception
- * Had better be unserializable at the far end if that is to work.
- */
-public final class ProbeStatus implements Serializable {
-  private static final long serialVersionUID = 165468L;
-
-  private long timestamp;
-  private String timestampText;
-  private boolean success;
-  private boolean realOutcome;
-  private String message;
-  private Throwable thrown;
-  private transient Probe originator;
-
-  public ProbeStatus() {
-  }
-
-  public ProbeStatus(long timestamp, String message, Throwable thrown) {
-    this.success = false;
-    this.message = message;
-    this.thrown = thrown;
-    setTimestamp(timestamp);
-  }
-
-  public ProbeStatus(long timestamp, String message) {
-    this.success = true;
-    setTimestamp(timestamp);
-    this.message = message;
-    this.thrown = null;
-  }
-
-  public long getTimestamp() {
-    return timestamp;
-  }
-
-  public void setTimestamp(long timestamp) {
-    this.timestamp = timestamp;
-    timestampText = new Date(timestamp).toString();
-  }
-
-  public boolean isSuccess() {
-    return success;
-  }
-
-  /**
-   * Set both the success and the real outcome bits to the same value
-   * @param success the new value
-   */
-  public void setSuccess(boolean success) {
-    this.success = success;
-    realOutcome = success;
-  }
-
-  public String getTimestampText() {
-    return timestampText;
-  }
-
-  public boolean getRealOutcome() {
-    return realOutcome;
-  }
-
-  public String getMessage() {
-    return message;
-  }
-
-  public void setMessage(String message) {
-    this.message = message;
-  }
-
-  public Throwable getThrown() {
-    return thrown;
-  }
-
-  public void setThrown(Throwable thrown) {
-    this.thrown = thrown;
-  }
-
-  /**
-   * Get the probe that generated this result. May be null
-   * @return a possibly null reference to a probe
-   */
-  public Probe getOriginator() {
-    return originator;
-  }
-
-  /**
-   * The probe has succeeded -capture the current timestamp, set
-   * success to true, and record any other data needed.
-   * @param probe probe
-   */
-  public void succeed(Probe probe) {
-    finish(probe, true, probe.getName(), null);
-  }
-
-  /**
-   * A probe has failed either because the test returned false, or an exception
-   * was thrown. The {@link #success} field is set to false, any exception 
-   * thrown is recorded.
-   * @param probe probe that failed
-   * @param thrown an exception that was thrown.
-   */
-  public void fail(Probe probe, Throwable thrown) {
-    finish(probe, false, "Failure in " + probe, thrown);
-  }
-
-  public void finish(Probe probe, boolean succeeded, String text, Throwable thrown) {
-    setTimestamp(System.currentTimeMillis());
-    setSuccess(succeeded);
-    originator = probe;
-    message = text;
-    this.thrown = thrown;
-  }
-
-  @Override
-  public String toString() {
-    LogEntryBuilder builder = new LogEntryBuilder("Probe Status");
-    builder.elt("time", timestampText)
-           .elt("outcome", (success ? "success" : "failure"));
-
-    if (success != realOutcome) {
-      builder.elt("originaloutcome", (realOutcome ? "success" : "failure"));
-    }
-    builder.elt("message", message);
-    if (thrown != null) {
-      builder.elt("exception", thrown);
-    }
-
-    return builder.toString();
-  }
-
-  /**
-   * Flip the success bit on while the real outcome bit is kept false
-   */
-  public void markAsSuccessful() {
-    success = true;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/package-info.java
deleted file mode 100644
index 766da0d6e30..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/package-info.java
+++ /dev/null
@@ -1,24 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-/**
- * Yarn Service framework.
- */
-@InterfaceAudience.Private
-package org.apache.hadoop.yarn.service;
-import org.apache.hadoop.classification.InterfaceAudience;
-
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/AbstractClientProvider.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/AbstractClientProvider.java
deleted file mode 100644
index ae796196d25..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/AbstractClientProvider.java
+++ /dev/null
@@ -1,150 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.provider;
-
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.fs.FileStatus;
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.yarn.service.api.records.Artifact;
-import org.apache.hadoop.yarn.service.api.records.ConfigFile;
-import org.apache.hadoop.yarn.service.utils.ServiceUtils;
-
-import java.io.IOException;
-import java.nio.file.Paths;
-import java.text.MessageFormat;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConstants.CONTENT;
-
-public abstract class AbstractClientProvider {
-
-  public AbstractClientProvider() {
-  }
-
-  /**
-   * Generates a fixed format of application tags given one or more of
-   * application name, version and description. This allows subsequent query for
-   * an application with a name only, version only or description only or any
-   * combination of those as filters.
-   *
-   * @param appName name of the application
-   * @param appVersion version of the application
-   * @param appDescription brief description of the application
-   * @return
-   */
-  public static final Set<String> createApplicationTags(String appName,
-      String appVersion, String appDescription) {
-    Set<String> tags = new HashSet<>();
-    tags.add(ServiceUtils.createNameTag(appName));
-    if (appVersion != null) {
-      tags.add(ServiceUtils.createVersionTag(appVersion));
-    }
-    if (appDescription != null) {
-      tags.add(ServiceUtils.createDescriptionTag(appDescription));
-    }
-    return tags;
-  }
-
-  /**
-   * Validate the artifact.
-   * @param artifact
-   */
-  public abstract void validateArtifact(Artifact artifact, String compName,
-      FileSystem fileSystem) throws IOException;
-
-  protected abstract void validateConfigFile(ConfigFile configFile,
-      String compName, FileSystem fileSystem) throws IOException;
-
-  /**
-   * Validate the config files.
-   * @param configFiles config file list
-   * @param fs file system
-   */
-  public void validateConfigFiles(List<ConfigFile> configFiles, String compName,
-      FileSystem fs) throws IOException {
-    Set<String> destFileSet = new HashSet<>();
-
-    for (ConfigFile file : configFiles) {
-      if (file.getType() == null) {
-        throw new IllegalArgumentException("File type is empty");
-      }
-      ConfigFile.TypeEnum fileType = file.getType();
-
-      if (fileType.equals(ConfigFile.TypeEnum.TEMPLATE)) {
-        if (StringUtils.isEmpty(file.getSrcFile()) &&
-            !file.getProperties().containsKey(CONTENT)) {
-          throw new IllegalArgumentException(MessageFormat.format("For {0} " +
-                  "format, either src_file must be specified in ConfigFile," +
-                  " or the \"{1}\" key must be specified in " +
-                  "the 'properties' field of ConfigFile. ",
-              ConfigFile.TypeEnum.TEMPLATE, CONTENT));
-        }
-      } else if (fileType.equals(ConfigFile.TypeEnum.STATIC) || fileType.equals(
-          ConfigFile.TypeEnum.ARCHIVE)) {
-        if (!file.getProperties().isEmpty()) {
-          throw new IllegalArgumentException(String
-              .format("For %s format, should not specify any 'properties.'",
-                  fileType));
-        }
-
-        String srcFile = file.getSrcFile();
-        if (srcFile == null || srcFile.isEmpty()) {
-          throw new IllegalArgumentException(String.format(
-              "For %s format, should make sure that srcFile is specified",
-              fileType));
-        }
-        FileStatus fileStatus = fs.getFileStatus(new Path(srcFile));
-        if (fileStatus != null && fileStatus.isDirectory()) {
-          throw new IllegalArgumentException("srcFile=" + srcFile +
-              " is a directory, which is not supported.");
-        }
-      }
-      if (!StringUtils.isEmpty(file.getSrcFile())) {
-        Path p = new Path(file.getSrcFile());
-        if (!fs.exists(p)) {
-          throw new IllegalArgumentException(
-              "Specified src_file does not exist on " + fs.getScheme() + ": "
-                  + file.getSrcFile());
-        }
-      }
-
-      if (StringUtils.isEmpty(file.getDestFile())) {
-        throw new IllegalArgumentException("dest_file is empty.");
-      }
-
-      if (destFileSet.contains(file.getDestFile())) {
-        throw new IllegalArgumentException(
-            "Duplicated ConfigFile exists: " + file.getDestFile());
-      }
-      destFileSet.add(file.getDestFile());
-
-      java.nio.file.Path destPath = Paths.get(file.getDestFile());
-      if (!destPath.isAbsolute() && destPath.getNameCount() > 1) {
-        throw new IllegalArgumentException("Non-absolute dest_file has more " +
-            "than one path element");
-      }
-
-      // provider-specific validation
-      validateConfigFile(file, compName, fs);
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/AbstractProviderService.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/AbstractProviderService.java
deleted file mode 100644
index 52f2a4eb018..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/AbstractProviderService.java
+++ /dev/null
@@ -1,176 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.provider;
-
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.api.ApplicationConstants;
-import org.apache.hadoop.yarn.api.records.Container;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.component.ComponentRestartPolicy;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConf;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConstants;
-import org.apache.hadoop.yarn.service.containerlaunch.ContainerLaunchService;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-import org.apache.hadoop.yarn.service.utils.ServiceUtils;
-import org.apache.hadoop.yarn.service.exceptions.SliderException;
-import org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher;
-import org.apache.hadoop.yarn.service.containerlaunch.CommandLineBuilder;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.apache.hadoop.yarn.service.ServiceContext;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.util.Map;
-import java.util.Map.Entry;
-
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.CONTAINER_FAILURES_VALIDITY_INTERVAL;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.CONTAINER_RETRY_INTERVAL;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.CONTAINER_RETRY_MAX;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.DEFAULT_CONTAINER_FAILURES_VALIDITY_INTERVAL;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.DEFAULT_CONTAINER_RETRY_INTERVAL;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.DEFAULT_CONTAINER_RETRY_MAX;
-import static org.apache.hadoop.yarn.service.utils.ServiceApiUtil.$;
-
-public abstract class AbstractProviderService implements ProviderService,
-    YarnServiceConstants {
-
-  protected static final Logger log =
-      LoggerFactory.getLogger(AbstractProviderService.class);
-
-  public abstract void processArtifact(AbstractLauncher launcher,
-      ComponentInstance compInstance, SliderFileSystem fileSystem,
-      Service service,
-      ContainerLaunchService.ComponentLaunchContext compLaunchCtx)
-      throws IOException;
-
-  public Map<String, String> buildContainerTokens(ComponentInstance instance,
-      Container container,
-      ContainerLaunchService.ComponentLaunchContext compLaunchContext) {
-      // Generate tokens (key-value pair) for config substitution.
-      // Get pre-defined tokens
-      Map<String, String> globalTokens =
-          instance.getComponent().getScheduler().globalTokens;
-      Map<String, String> tokensForSubstitution = ProviderUtils
-          .initCompTokensForSubstitute(instance, container,
-              compLaunchContext);
-      tokensForSubstitution.putAll(globalTokens);
-      return tokensForSubstitution;
-  }
-
-  public void buildContainerEnvironment(AbstractLauncher launcher,
-      Service service, ComponentInstance instance,
-      SliderFileSystem fileSystem, Configuration yarnConf, Container container,
-      ContainerLaunchService.ComponentLaunchContext compLaunchContext,
-      Map<String, String> tokensForSubstitution)
-          throws IOException, SliderException {
-    // Set the environment variables in launcher
-    launcher.putEnv(ServiceUtils.buildEnvMap(
-        compLaunchContext.getConfiguration(), tokensForSubstitution));
-    launcher.setEnv("WORK_DIR", ApplicationConstants.Environment.PWD.$());
-    launcher.setEnv("LOG_DIR", ApplicationConstants.LOG_DIR_EXPANSION_VAR);
-    if (System.getenv(HADOOP_USER_NAME) != null) {
-      launcher.setEnv(HADOOP_USER_NAME, System.getenv(HADOOP_USER_NAME));
-    }
-    launcher.setEnv("LANG", "en_US.UTF-8");
-    launcher.setEnv("LC_ALL", "en_US.UTF-8");
-    launcher.setEnv("LANGUAGE", "en_US.UTF-8");
-
-    for (Entry<String, String> entry : launcher.getEnv().entrySet()) {
-      tokensForSubstitution.put($(entry.getKey()), entry.getValue());
-    }
-  }
-
-  public void buildContainerLaunchCommand(AbstractLauncher launcher,
-      Service service, ComponentInstance instance,
-      SliderFileSystem fileSystem, Configuration yarnConf, Container container,
-      ContainerLaunchService.ComponentLaunchContext compLaunchContext,
-      Map<String, String> tokensForSubstitution)
-          throws IOException, SliderException {
-    // substitute launch command
-    String launchCommand = compLaunchContext.getLaunchCommand();
-    // docker container may have empty commands
-    if (!StringUtils.isEmpty(launchCommand)) {
-      launchCommand = ProviderUtils
-          .substituteStrWithTokens(launchCommand, tokensForSubstitution);
-      CommandLineBuilder operation = new CommandLineBuilder();
-      operation.add(launchCommand);
-      operation.addOutAndErrFiles(OUT_FILE, ERR_FILE);
-      launcher.addCommand(operation.build());
-    }
-  }
-
-  public void buildContainerRetry(AbstractLauncher launcher,
-      Configuration yarnConf,
-      ContainerLaunchService.ComponentLaunchContext compLaunchContext,
-      ComponentInstance instance) {
-    // By default retry forever every 30 seconds
-
-    ComponentRestartPolicy restartPolicy = instance.getComponent()
-        .getRestartPolicyHandler();
-    if (restartPolicy.allowContainerRetriesForInstance(instance)) {
-      launcher.setRetryContext(YarnServiceConf
-          .getInt(CONTAINER_RETRY_MAX, DEFAULT_CONTAINER_RETRY_MAX,
-              compLaunchContext.getConfiguration(), yarnConf), YarnServiceConf
-          .getInt(CONTAINER_RETRY_INTERVAL, DEFAULT_CONTAINER_RETRY_INTERVAL,
-              compLaunchContext.getConfiguration(), yarnConf), YarnServiceConf
-          .getLong(CONTAINER_FAILURES_VALIDITY_INTERVAL,
-              DEFAULT_CONTAINER_FAILURES_VALIDITY_INTERVAL,
-              compLaunchContext.getConfiguration(), yarnConf));
-    }
-  }
-
-  public ResolvedLaunchParams buildContainerLaunchContext(
-      AbstractLauncher launcher,
-      Service service, ComponentInstance instance,
-      SliderFileSystem fileSystem, Configuration yarnConf, Container container,
-      ContainerLaunchService.ComponentLaunchContext compLaunchContext)
-      throws IOException, SliderException {
-    ResolvedLaunchParams resolved = new ResolvedLaunchParams();
-    processArtifact(launcher, instance, fileSystem, service, compLaunchContext);
-
-    ServiceContext context =
-        instance.getComponent().getScheduler().getContext();
-    // Generate tokens (key-value pair) for config substitution.
-    Map<String, String> tokensForSubstitution =
-        buildContainerTokens(instance, container, compLaunchContext);
-
-    // Setup launch context environment
-    buildContainerEnvironment(launcher, service, instance,
-        fileSystem, yarnConf, container, compLaunchContext,
-        tokensForSubstitution);
-
-    // create config file on hdfs and addResolvedRsrcPath local resource
-    ProviderUtils.createConfigFileAndAddLocalResource(launcher, fileSystem,
-        compLaunchContext, tokensForSubstitution, instance, context, resolved);
-
-    // handles static files (like normal file / archive file) for localization.
-    ProviderUtils.handleStaticFilesForLocalization(launcher, fileSystem,
-        compLaunchContext, resolved);
-
-    // replace launch command with token specific information
-    buildContainerLaunchCommand(launcher, service, instance, fileSystem,
-        yarnConf, container, compLaunchContext, tokensForSubstitution);
-
-    // Setup container retry settings
-    buildContainerRetry(launcher, yarnConf, compLaunchContext, instance);
-
-    return resolved;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/ProviderFactory.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/ProviderFactory.java
deleted file mode 100644
index 0f949e0bace..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/ProviderFactory.java
+++ /dev/null
@@ -1,76 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.provider;
-
-import org.apache.hadoop.yarn.service.provider.defaultImpl.DefaultProviderFactory;
-import org.apache.hadoop.yarn.service.api.records.Artifact;
-import org.apache.hadoop.yarn.service.provider.docker.DockerProviderFactory;
-import org.apache.hadoop.yarn.service.provider.tarball.TarballProviderFactory;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * Base class for factories.
- */
-public abstract class ProviderFactory {
-  protected static final Logger LOG =
-      LoggerFactory.getLogger(ProviderFactory.class);
-
-  protected ProviderFactory() {}
-
-  public abstract AbstractClientProvider createClientProvider();
-
-  public abstract ProviderService createServerProvider();
-
-  public static synchronized ProviderService getProviderService(Artifact
-      artifact) {
-    return createServiceProviderFactory(artifact).createServerProvider();
-  }
-
-  public static synchronized AbstractClientProvider getClientProvider(Artifact
-      artifact) {
-    return createServiceProviderFactory(artifact).createClientProvider();
-  }
-
-  /**
-   * Create a provider for a specific service
-   * @param artifact artifact
-   * @return provider factory
-   */
-  public static synchronized ProviderFactory createServiceProviderFactory(
-      Artifact artifact) {
-    if (artifact == null || artifact.getType() == null) {
-      LOG.debug("Loading service provider type default");
-      return DefaultProviderFactory.getInstance();
-    }
-    LOG.debug("Loading service provider type {}", artifact.getType());
-    switch (artifact.getType()) {
-      // TODO add handling for custom types?
-      // TODO handle service
-      case DOCKER:
-        return DockerProviderFactory.getInstance();
-      case TARBALL:
-        return TarballProviderFactory.getInstance();
-      default:
-        throw new IllegalArgumentException(String.format("Resolution error, " +
-                "%s should not be passed to createServiceProviderFactory",
-            artifact.getType()));
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/ProviderService.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/ProviderService.java
deleted file mode 100644
index 6a7464f41f6..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/ProviderService.java
+++ /dev/null
@@ -1,81 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.provider;
-
-import org.apache.hadoop.util.Preconditions;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.api.records.Container;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.containerlaunch.ContainerLaunchService;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-import org.apache.hadoop.yarn.service.exceptions.SliderException;
-import org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-
-public interface ProviderService {
-
-  /**
-   * Set up the entire container launch context
-   */
-  ResolvedLaunchParams buildContainerLaunchContext(
-      AbstractLauncher containerLauncher,
-      Service service, ComponentInstance instance,
-      SliderFileSystem sliderFileSystem, Configuration yarnConf,
-      Container container,
-      ContainerLaunchService.ComponentLaunchContext componentLaunchContext)
-      throws IOException, SliderException;
-
-  /**
-   * This holds any information that is resolved during building the launch
-   * context for a container.
-   * <p>
-   * Right now it contains a mapping of resource keys to destination files
-   * for resources that need to be localized.
-   */
-  class ResolvedLaunchParams {
-    private Map<String, String> resolvedRsrcPaths = new HashMap<>();
-
-    void addResolvedRsrcPath(String resourceKey, String destFile) {
-      Preconditions.checkNotNull(destFile, "dest file cannot be null");
-      Preconditions.checkNotNull(resourceKey,
-          "local resource cannot be null");
-      resolvedRsrcPaths.put(resourceKey, destFile);
-    }
-
-    public Map<String, String> getResolvedRsrcPaths() {
-      return this.resolvedRsrcPaths;
-    }
-
-    public boolean didLaunchFail() {
-      return false;
-    }
-  }
-
-  ResolvedLaunchParams FAILED_LAUNCH_PARAMS = new ResolvedLaunchParams() {
-    @Override
-    public boolean didLaunchFail() {
-      return true;
-    }
-  };
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/ProviderUtils.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/ProviderUtils.java
deleted file mode 100644
index 57d76dfeecd..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/ProviderUtils.java
+++ /dev/null
@@ -1,493 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.provider;
-
-import org.apache.hadoop.fs.FSDataOutputStream;
-import org.apache.hadoop.fs.FileStatus;
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.fs.permission.FsAction;
-import org.apache.hadoop.fs.permission.FsPermission;
-import org.apache.hadoop.yarn.api.records.Container;
-import org.apache.hadoop.yarn.api.records.LocalResource;
-import org.apache.hadoop.yarn.api.records.LocalResourceType;
-import org.apache.hadoop.yarn.api.records.LocalResourceVisibility;
-import org.apache.hadoop.yarn.service.ServiceContext;
-import org.apache.hadoop.yarn.service.api.records.ConfigFile;
-import org.apache.hadoop.yarn.service.api.records.ConfigFormat;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConstants;
-import org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher;
-import org.apache.hadoop.yarn.service.containerlaunch.ContainerLaunchService;
-import org.apache.hadoop.yarn.service.exceptions.BadCommandArgumentsException;
-import org.apache.hadoop.yarn.service.exceptions.SliderException;
-import org.apache.hadoop.yarn.service.utils.PublishedConfiguration;
-import org.apache.hadoop.yarn.service.utils.PublishedConfigurationOutputter;
-import org.apache.hadoop.yarn.service.utils.ServiceUtils;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.File;
-import java.io.FileNotFoundException;
-import java.io.IOException;
-import java.io.OutputStream;
-import java.nio.charset.StandardCharsets;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.concurrent.ExecutionException;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
-import static org.apache.hadoop.yarn.service.api.ServiceApiConstants.COMPONENT_ID;
-import static org.apache.hadoop.yarn.service.api.ServiceApiConstants.COMPONENT_INSTANCE_NAME;
-import static org.apache.hadoop.yarn.service.api.ServiceApiConstants.COMPONENT_NAME;
-import static org.apache.hadoop.yarn.service.api.ServiceApiConstants.COMPONENT_NAME_LC;
-import static org.apache.hadoop.yarn.service.api.ServiceApiConstants.CONTAINER_ID;
-
-/**
- * This is a factoring out of methods handy for providers. It's bonded to a log
- * at construction time.
- */
-public class ProviderUtils implements YarnServiceConstants {
-
-  protected static final Logger log =
-      LoggerFactory.getLogger(ProviderUtils.class);
-
-
-  /**
-   * Add oneself to the classpath. This does not work
-   * on minicluster test runs where the JAR is not built up.
-   * @param providerResources map of provider resources to add these entries to
-   * @param providerClass provider to add
-   * @param jarName name of the jar to use
-   * @param sliderFileSystem target filesystem
-   * @param tempPath path in the cluster FS for temp files
-   * @param libdir relative directory to place resources
-   * @param miniClusterTestRun true if minicluster is being used
-   * @return true if the class was found in a JAR
-   * 
-   * @throws FileNotFoundException if the JAR was not found and this is NOT
-   * a mini cluster test run
-   * @throws IOException IO problems
-   * @throws SliderException any Slider problem
-   */
-  public static boolean addProviderJar(
-      Map<String, LocalResource> providerResources,
-      Class providerClass,
-      String jarName,
-      SliderFileSystem sliderFileSystem,
-      Path tempPath,
-      String libdir,
-      boolean miniClusterTestRun) throws
-      IOException,
-      SliderException {
-    try {
-      ServiceUtils.putJar(providerResources,
-          sliderFileSystem,
-          providerClass,
-          tempPath,
-          libdir,
-          jarName);
-      return true;
-    } catch (FileNotFoundException e) {
-      if (miniClusterTestRun) {
-        return false;
-      } else {
-        throw e;
-      }
-    }
-  }
-  
-  /**
-   * Loads all dependency jars from the default path.
-   * @param providerResources map of provider resources to add these entries to
-   * @param sliderFileSystem target filesystem
-   * @param tempPath path in the cluster FS for temp files
-   * @param libDir relative directory to place resources
-   * @param libLocalSrcDir explicitly supplied local libs dir
-   * @throws IOException trouble copying to HDFS
-   * @throws SliderException trouble copying to HDFS
-   */
-  public static void addAllDependencyJars(
-      Map<String, LocalResource> providerResources,
-      SliderFileSystem sliderFileSystem,
-      Path tempPath,
-      String libDir,
-      String libLocalSrcDir)
-      throws IOException, SliderException {
-    if (ServiceUtils.isSet(libLocalSrcDir)) {
-      File file = new File(libLocalSrcDir);
-      if (!file.exists() || !file.isDirectory()) {
-        throw new BadCommandArgumentsException(
-            "Supplied lib src dir %s is not valid", libLocalSrcDir);
-      }
-    }
-    ServiceUtils.putAllJars(providerResources, sliderFileSystem, tempPath,
-        libDir, libLocalSrcDir);
-  }
-
-  public static String substituteStrWithTokens(String content,
-      Map<String, String> tokensForSubstitution) {
-    for (Map.Entry<String, String> token : tokensForSubstitution.entrySet()) {
-      content =
-          content.replaceAll(Pattern.quote(token.getKey()), token.getValue());
-    }
-    return content;
-  }
-
-  public static String replaceSpacesWithDelimiter(String content,
-      String delimiter) {
-    List<String> parts = new ArrayList<String>();
-    Matcher m = Pattern.compile("([^\"]\\S*|\".+?\")\\s*").matcher(content);
-    while (m.find()) {
-      String part = m.group(1);
-      if(part.startsWith("\"") && part.endsWith("\"")) {
-        part = part.replaceAll("^\"|\"$", "");
-      }
-      parts.add(part);
-    }
-    return String.join(delimiter, parts);
-  }
-
-  // configs will be substituted by corresponding env in tokenMap
-  public static void substituteMapWithTokens(Map<String, String> configs,
-      Map<String, String> tokenMap) {
-    for (Map.Entry<String, String> entry : configs.entrySet()) {
-      String value = entry.getValue();
-      if (tokenMap != null) {
-        for (Map.Entry<String, String> token : tokenMap.entrySet()) {
-          value =
-              value.replaceAll(Pattern.quote(token.getKey()), token.getValue());
-        }
-      }
-      entry.setValue(value);
-    }
-  }
-
-  public static Path initCompInstanceDir(SliderFileSystem fs,
-      ContainerLaunchService.ComponentLaunchContext compLaunchContext,
-      ComponentInstance instance) {
-    Path compDir = fs.getComponentDir(compLaunchContext.getServiceVersion(),
-        compLaunchContext.getName());
-    Path compInstanceDir = new Path(compDir, instance.getCompInstanceName());
-    instance.setCompInstanceDir(compInstanceDir);
-    return compInstanceDir;
-  }
-
-  public static Path initCompPublicResourceDir(SliderFileSystem fs,
-      ContainerLaunchService.ComponentLaunchContext compLaunchContext,
-      ComponentInstance instance) {
-    Path compDir = fs.getComponentPublicResourceDir(
-        compLaunchContext.getServiceVersion(), compLaunchContext.getName());
-    Path compPublicResourceDir = new Path(compDir,
-        instance.getCompInstanceName());
-    return compPublicResourceDir;
-  }
-
-
-  // 1. Create all config files for a component on hdfs for localization
-  // 2. Add the config file to localResource
-  public static synchronized void createConfigFileAndAddLocalResource(
-      AbstractLauncher launcher, SliderFileSystem fs,
-      ContainerLaunchService.ComponentLaunchContext compLaunchContext,
-      Map<String, String> tokensForSubstitution, ComponentInstance instance,
-      ServiceContext context, ProviderService.ResolvedLaunchParams
-      resolvedParams)
-      throws IOException {
-
-    Path compInstanceDir = initCompInstanceDir(fs, compLaunchContext, instance);
-    if (!fs.getFileSystem().exists(compInstanceDir)) {
-      log.info("{} version {} : Creating dir on hdfs: {}",
-          instance.getCompInstanceId(), compLaunchContext.getServiceVersion(),
-          compInstanceDir);
-      fs.getFileSystem().mkdirs(compInstanceDir,
-          new FsPermission(FsAction.ALL, FsAction.NONE, FsAction.NONE));
-    } else {
-      log.info("Component instance conf dir already exists: " + compInstanceDir);
-    }
-
-    Path compPublicResourceDir = initCompPublicResourceDir(fs,
-        compLaunchContext, instance);
-    if (!fs.getFileSystem().exists(compPublicResourceDir)) {
-      log.info("{} version {} : Creating Public Resource dir on hdfs: {}",
-          instance.getCompInstanceId(), compLaunchContext.getServiceVersion(),
-          compPublicResourceDir);
-      fs.getFileSystem().mkdirs(compPublicResourceDir,
-          new FsPermission(FsAction.ALL, FsAction.READ_EXECUTE,
-          FsAction.EXECUTE));
-    } else {
-      log.info("Component instance public resource dir already exists: "
-          + compPublicResourceDir);
-    }
-
-    log.debug("Tokens substitution for component instance: {}{}{}" + instance
-        .getCompInstanceName(), System.lineSeparator(), tokensForSubstitution);
-
-    for (ConfigFile originalFile : compLaunchContext.getConfiguration()
-        .getFiles()) {
-
-      if (isStaticFile(originalFile)) {
-        continue;
-      }
-      ConfigFile configFile = originalFile.copy();
-      String fileName = new Path(configFile.getDestFile()).getName();
-
-      // substitute file name
-      for (Map.Entry<String, String> token : tokensForSubstitution.entrySet()) {
-        configFile.setDestFile(configFile.getDestFile()
-            .replaceAll(Pattern.quote(token.getKey()), token.getValue()));
-      }
-
-      /* When source file is not specified, write new configs
-       * to compInstanceDir/fileName
-       * When source file is specified, it reads and performs variable
-       * substitution and merges in new configs, and writes a new file to
-       * compInstanceDir/fileName.
-       */
-      Path remoteFile = null;
-      LocalResourceVisibility visibility = configFile.getVisibility();
-      if (visibility != null &&
-          visibility.equals(LocalResourceVisibility.PUBLIC)) {
-        remoteFile = new Path(compPublicResourceDir, fileName);
-      } else {
-        remoteFile = new Path(compInstanceDir, fileName);
-      }
-
-      if (!fs.getFileSystem().exists(remoteFile)) {
-        log.info("Saving config file on hdfs for component " + instance
-            .getCompInstanceName() + ": " + configFile);
-
-        if (configFile.getSrcFile() != null) {
-          // Load config file template
-          switch (configFile.getType()) {
-          case HADOOP_XML:
-            // Hadoop_xml_template
-            resolveHadoopXmlTemplateAndSaveOnHdfs(fs.getFileSystem(),
-                tokensForSubstitution, configFile, remoteFile, context);
-            break;
-          case TEMPLATE:
-            // plain-template
-            resolvePlainTemplateAndSaveOnHdfs(fs.getFileSystem(),
-                tokensForSubstitution, configFile, remoteFile, context);
-            break;
-          default:
-            log.info("Not supporting loading src_file for " + configFile);
-            break;
-          }
-        } else {
-          // If src_file is not specified
-          resolvePropsInConfigFileAndSaveOnHdfs(fs, tokensForSubstitution,
-              instance, configFile, fileName, remoteFile);
-        }
-      }
-
-      // Add resource for localization
-      LocalResource configResource =
-          fs.createAmResource(remoteFile, LocalResourceType.FILE,
-          configFile.getVisibility());
-      Path destFile = new Path(configFile.getDestFile());
-      String symlink = APP_CONF_DIR + "/" + fileName;
-      addLocalResource(launcher, symlink, configResource, destFile,
-          resolvedParams);
-    }
-  }
-
-  public static synchronized void handleStaticFilesForLocalization(
-      AbstractLauncher launcher, SliderFileSystem fs, ContainerLaunchService
-      .ComponentLaunchContext componentLaunchCtx,
-      ProviderService.ResolvedLaunchParams resolvedParams)
-      throws IOException {
-    for (ConfigFile staticFile :
-        componentLaunchCtx.getConfiguration().getFiles()) {
-      // Only handle static file here.
-      if (!isStaticFile(staticFile)) {
-        continue;
-      }
-
-      if (staticFile.getSrcFile() == null) {
-        // This should not happen, AbstractClientProvider should have checked
-        // this.
-        throw new IOException("srcFile is null, please double check.");
-      }
-      Path sourceFile = new Path(staticFile.getSrcFile());
-
-      // Output properties to sourceFile if not existed
-      if (!fs.getFileSystem().exists(sourceFile)) {
-        throw new IOException(
-            "srcFile=" + sourceFile + " doesn't exist, please double check.");
-      }
-
-      FileStatus fileStatus = fs.getFileSystem().getFileStatus(sourceFile);
-      if (fileStatus.isDirectory()) {
-        throw new IOException("srcFile=" + sourceFile +
-            " is a directory, which is not supported.");
-      }
-
-      // Add resource for localization
-      LocalResource localResource = fs.createAmResource(sourceFile,
-          (staticFile.getType() == ConfigFile.TypeEnum.ARCHIVE ?
-              LocalResourceType.ARCHIVE :
-              LocalResourceType.FILE), staticFile.getVisibility());
-
-      Path destFile = new Path(sourceFile.getName());
-      if (staticFile.getDestFile() != null && !staticFile.getDestFile()
-          .isEmpty()) {
-        destFile = new Path(staticFile.getDestFile());
-      }
-      addLocalResource(launcher, destFile.getName(), localResource, destFile,
-          resolvedParams);
-    }
-  }
-
-  private static void addLocalResource(AbstractLauncher launcher,
-      String symlink, LocalResource localResource, Path destFile,
-      ProviderService.ResolvedLaunchParams resolvedParams) {
-    if (destFile.isAbsolute()) {
-      launcher.addLocalResource(symlink, localResource, destFile.toString());
-      log.info("Added file for localization: "+ symlink +" -> " +
-          localResource.getResource().getFile() + ", dest mount path: " +
-          destFile);
-    } else{
-      launcher.addLocalResource(symlink, localResource);
-      log.info("Added file for localization: " + symlink+ " -> " +
-          localResource.getResource().getFile());
-    }
-    resolvedParams.addResolvedRsrcPath(symlink, destFile.toString());
-  }
-
-  // Static file is files uploaded by users before launch the service. Which
-  // should be localized to container local disk without any changes.
-  private static boolean isStaticFile(ConfigFile file) {
-    return file.getType().equals(ConfigFile.TypeEnum.ARCHIVE) || file.getType()
-        .equals(ConfigFile.TypeEnum.STATIC);
-  }
-
-  private static void resolvePropsInConfigFileAndSaveOnHdfs(SliderFileSystem fs,
-      Map<String, String> tokensForSubstitution, ComponentInstance instance,
-      ConfigFile configFile, String fileName, Path remoteFile)
-      throws IOException {
-    // substitute non-template configs
-    substituteMapWithTokens(configFile.getProperties(), tokensForSubstitution);
-
-    // write configs onto hdfs
-    PublishedConfiguration publishedConfiguration =
-        new PublishedConfiguration(fileName,
-            configFile.getProperties().entrySet());
-    if (!fs.getFileSystem().exists(remoteFile)) {
-      PublishedConfigurationOutputter configurationOutputter =
-          PublishedConfigurationOutputter.createOutputter(
-              ConfigFormat.resolve(configFile.getType().toString()),
-              publishedConfiguration);
-      try (FSDataOutputStream os = fs.getFileSystem().create(remoteFile)) {
-        configurationOutputter.save(os);
-        os.flush();
-      }
-    } else {
-      log.info("Component instance = " + instance.getCompInstanceName()
-              + ", config file already exists: " + remoteFile);
-    }
-  }
-
-  // 1. substitute config template - only handle hadoop_xml format
-  // 2. save on hdfs
-  @SuppressWarnings("unchecked")
-  private static void resolveHadoopXmlTemplateAndSaveOnHdfs(FileSystem fs,
-      Map<String, String> tokensForSubstitution, ConfigFile configFile,
-      Path remoteFile, ServiceContext context) throws IOException {
-    Map<String, String> conf;
-    try {
-      conf = (Map<String, String>) context.configCache.get(configFile);
-    } catch (ExecutionException e) {
-      log.info("Failed to load config file: " + configFile, e);
-      return;
-    }
-    // make a copy for substitution
-    org.apache.hadoop.conf.Configuration confCopy =
-        new org.apache.hadoop.conf.Configuration(false);
-    for (Map.Entry<String, String> entry : conf.entrySet()) {
-      confCopy.set(entry.getKey(), entry.getValue());
-    }
-    // substitute properties
-    for (Map.Entry<String, String> entry : configFile.getProperties().entrySet()) {
-      confCopy.set(entry.getKey(), entry.getValue());
-    }
-    // substitute env variables
-    for (Map.Entry<String, String> entry : confCopy) {
-      String val = entry.getValue();
-      if (val != null) {
-        for (Map.Entry<String, String> token : tokensForSubstitution
-            .entrySet()) {
-          val = val.replaceAll(Pattern.quote(token.getKey()), token.getValue());
-          confCopy.set(entry.getKey(), val);
-        }
-      }
-    }
-    // save on hdfs
-    try (OutputStream output = fs.create(remoteFile)) {
-      confCopy.writeXml(output);
-      log.info("Reading config from: " + configFile.getSrcFile()
-          + ", writing to: " + remoteFile);
-    }
-  }
-
-  // 1) read the template as a string
-  // 2) do token substitution
-  // 3) save on hdfs
-  private static void resolvePlainTemplateAndSaveOnHdfs(FileSystem fs,
-      Map<String, String> tokensForSubstitution, ConfigFile configFile,
-      Path remoteFile, ServiceContext context) {
-    String content;
-    try {
-      content = (String) context.configCache.get(configFile);
-    } catch (ExecutionException e) {
-      log.info("Failed to load config file: " + configFile, e);
-      return;
-    }
-    // substitute tokens
-    content = substituteStrWithTokens(content, tokensForSubstitution);
-
-    try (OutputStream output = fs.create(remoteFile)) {
-      org.apache.commons.io.IOUtils.write(content, output, StandardCharsets.UTF_8);
-    } catch (IOException e) {
-      log.info("Failed to create " + remoteFile);
-    }
-  }
-
-  /**
-   * Get initial component token map to be substituted into config values.
-   * @return tokens to replace
-   */
-  public static Map<String, String> initCompTokensForSubstitute(
-      ComponentInstance instance, Container container,
-      ContainerLaunchService.ComponentLaunchContext componentLaunchContext) {
-    Map<String, String> tokens = new HashMap<>();
-    tokens.put(COMPONENT_NAME, componentLaunchContext.getName());
-    tokens
-        .put(COMPONENT_NAME_LC, componentLaunchContext.getName().toLowerCase());
-    tokens.put(COMPONENT_INSTANCE_NAME, instance.getCompInstanceName());
-    tokens.put(CONTAINER_ID, container.getId().toString());
-    tokens.put(COMPONENT_ID,
-        String.valueOf(instance.getCompInstanceId().getId()));
-    tokens.putAll(instance.getComponent().getDependencyHostIpTokens());
-    return tokens;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/defaultImpl/DefaultClientProvider.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/defaultImpl/DefaultClientProvider.java
deleted file mode 100644
index 2c9cf091456..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/defaultImpl/DefaultClientProvider.java
+++ /dev/null
@@ -1,52 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.provider.defaultImpl;
-
-import java.io.IOException;
-import java.nio.file.Paths;
-
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.yarn.service.api.records.Artifact;
-import org.apache.hadoop.yarn.service.api.records.ConfigFile;
-import org.apache.hadoop.yarn.service.exceptions.RestApiErrorMessages;
-import org.apache.hadoop.yarn.service.provider.AbstractClientProvider;
-
-import org.apache.hadoop.classification.VisibleForTesting;
-
-public class DefaultClientProvider extends AbstractClientProvider {
-
-  public DefaultClientProvider() {
-  }
-
-  @Override
-  public void validateArtifact(Artifact artifact, String compName,
-      FileSystem fileSystem) {
-  }
-
-  @Override
-  @VisibleForTesting
-  public void validateConfigFile(ConfigFile configFile, String compName,
-      FileSystem fileSystem) throws IOException {
-    // validate dest_file is not absolute
-    if (Paths.get(configFile.getDestFile()).isAbsolute()) {
-      throw new IllegalArgumentException(String.format(
-          RestApiErrorMessages.ERROR_CONFIGFILE_DEST_FILE_FOR_COMP_NOT_ABSOLUTE,
-          compName, "no", configFile.getDestFile()));
-    }
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/defaultImpl/DefaultProviderFactory.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/defaultImpl/DefaultProviderFactory.java
deleted file mode 100644
index 868bba8f8dc..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/defaultImpl/DefaultProviderFactory.java
+++ /dev/null
@@ -1,51 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.provider.defaultImpl;
-
-import org.apache.hadoop.yarn.service.provider.AbstractClientProvider;
-import org.apache.hadoop.yarn.service.provider.ProviderService;
-import org.apache.hadoop.yarn.service.provider.ProviderFactory;
-
-public final class DefaultProviderFactory extends ProviderFactory {
-  private static final ProviderFactory FACTORY = new
-      DefaultProviderFactory();
-
-  private DefaultProviderFactory() {}
-
-  private static class Client {
-    static final AbstractClientProvider PROVIDER = new DefaultClientProvider();
-  }
-
-  private static class Server {
-    static final ProviderService PROVIDER = new DefaultProviderService();
-  }
-
-  @Override
-  public AbstractClientProvider createClientProvider() {
-    return Client.PROVIDER;
-  }
-
-  @Override
-  public ProviderService createServerProvider() {
-    return Server.PROVIDER;
-  }
-
-  public static ProviderFactory getInstance() {
-    return FACTORY;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/defaultImpl/DefaultProviderService.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/defaultImpl/DefaultProviderService.java
deleted file mode 100644
index 790fe20c5c9..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/defaultImpl/DefaultProviderService.java
+++ /dev/null
@@ -1,38 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.provider.defaultImpl;
-
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.apache.hadoop.yarn.service.containerlaunch.ContainerLaunchService;
-import org.apache.hadoop.yarn.service.provider.AbstractProviderService;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-import org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher;
-
-import java.io.IOException;
-
-public class DefaultProviderService extends AbstractProviderService {
-
-  @Override
-  public void processArtifact(AbstractLauncher launcher,
-      ComponentInstance compInstance, SliderFileSystem fileSystem,
-      Service service,
-      ContainerLaunchService.ComponentLaunchContext compLaunchCtx)
-      throws IOException {
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/docker/DockerClientProvider.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/docker/DockerClientProvider.java
deleted file mode 100644
index 901d779b3b1..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/docker/DockerClientProvider.java
+++ /dev/null
@@ -1,54 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.provider.docker;
-
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.yarn.service.api.records.Artifact;
-import org.apache.hadoop.yarn.service.api.records.ConfigFile;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConstants;
-import org.apache.hadoop.yarn.service.provider.AbstractClientProvider;
-import org.apache.hadoop.yarn.service.exceptions.RestApiErrorMessages;
-
-import java.io.IOException;
-
-public class DockerClientProvider extends AbstractClientProvider
-    implements YarnServiceConstants {
-
-  public DockerClientProvider() {
-    super();
-  }
-
-  @Override
-  public void validateArtifact(Artifact artifact, String compName,
-      FileSystem fileSystem) {
-    if (artifact == null) {
-      throw new IllegalArgumentException(String.format(
-          RestApiErrorMessages.ERROR_ARTIFACT_FOR_COMP_INVALID, compName));
-    }
-    if (StringUtils.isEmpty(artifact.getId())) {
-      throw new IllegalArgumentException(String.format(
-          RestApiErrorMessages.ERROR_ARTIFACT_ID_FOR_COMP_INVALID, compName));
-    }
-  }
-
-  @Override
-  protected void validateConfigFile(ConfigFile configFile, String compName,
-      FileSystem fileSystem) throws IOException {
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/docker/DockerKeys.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/docker/DockerKeys.java
deleted file mode 100644
index 992a40cebac..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/docker/DockerKeys.java
+++ /dev/null
@@ -1,23 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.provider.docker;
-
-public interface DockerKeys {
-  String DOCKER_PREFIX = "docker.";
-  String DOCKER_NETWORK = DOCKER_PREFIX + "network";
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/docker/DockerProviderFactory.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/docker/DockerProviderFactory.java
deleted file mode 100644
index 57330ab6ad0..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/docker/DockerProviderFactory.java
+++ /dev/null
@@ -1,52 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.provider.docker;
-
-import org.apache.hadoop.yarn.service.provider.AbstractClientProvider;
-import org.apache.hadoop.yarn.service.provider.ProviderService;
-import org.apache.hadoop.yarn.service.provider.ProviderFactory;
-
-public class DockerProviderFactory extends ProviderFactory {
-  private static final ProviderFactory FACTORY = new
-      DockerProviderFactory();
-
-  private DockerProviderFactory() {
-  }
-
-  private static class Client {
-    static final AbstractClientProvider PROVIDER = new DockerClientProvider();
-  }
-
-  private static class Server {
-    static final ProviderService PROVIDER = new DockerProviderService();
-  }
-
-  @Override
-  public AbstractClientProvider createClientProvider() {
-    return Client.PROVIDER;
-  }
-
-  @Override
-  public ProviderService createServerProvider() {
-    return Server.PROVIDER;
-  }
-
-  public static ProviderFactory getInstance() {
-    return FACTORY;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/docker/DockerProviderService.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/docker/DockerProviderService.java
deleted file mode 100644
index 9b4138e57d6..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/docker/DockerProviderService.java
+++ /dev/null
@@ -1,110 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.provider.docker;
-
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.apache.hadoop.yarn.service.provider.AbstractProviderService;
-import org.apache.hadoop.yarn.service.provider.ProviderUtils;
-import org.apache.hadoop.yarn.api.records.Container;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-
-import org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher;
-import org.apache.hadoop.yarn.service.containerlaunch.CommandLineBuilder;
-import org.apache.hadoop.yarn.service.containerlaunch.ContainerLaunchService;
-import org.apache.hadoop.yarn.service.exceptions.SliderException;
-import org.apache.hadoop.yarn.api.ApplicationConstants.Environment;
-
-import java.io.IOException;
-import java.util.Map;
-
-public class DockerProviderService extends AbstractProviderService
-    implements DockerKeys {
-
-  @Override
-  public void processArtifact(AbstractLauncher launcher,
-      ComponentInstance compInstance, SliderFileSystem fileSystem,
-      Service service, ContainerLaunchService.ComponentLaunchContext
-      compLaunchCtx) throws IOException{
-    launcher.setYarnDockerMode(true);
-    launcher.setDockerImage(compLaunchCtx.getArtifact().getId());
-    launcher.setDockerNetwork(compLaunchCtx.getConfiguration()
-        .getProperty(DOCKER_NETWORK));
-    launcher.setDockerHostname(compInstance.getHostname());
-    launcher.setRunPrivilegedContainer(
-        compLaunchCtx.isRunPrivilegedContainer());
-  }
-
-  /**
-   * Check if system is default to disable docker override or
-   * user requested a Docker container with ENTRY_POINT support.
-   *
-   * @param compLaunchContext - launch context for the component.
-   * @return true if Docker launch command override is disabled
-   */
-  private boolean checkUseEntryPoint(
-      ContainerLaunchService.ComponentLaunchContext compLaunchContext) {
-    boolean overrideDisable = false;
-    String overrideDisableKey = Environment.
-        YARN_CONTAINER_RUNTIME_DOCKER_RUN_OVERRIDE_DISABLE.
-            name();
-    String overrideDisableValue = (
-        compLaunchContext.getConfiguration().getEnv(overrideDisableKey)
-            != null) ?
-            compLaunchContext.getConfiguration().getEnv(
-                overrideDisableKey) : System.getenv(overrideDisableKey);
-    overrideDisable = Boolean.parseBoolean(overrideDisableValue);
-    return overrideDisable;
-  }
-
-  @Override
-  public void buildContainerLaunchCommand(AbstractLauncher launcher,
-      Service service, ComponentInstance instance,
-      SliderFileSystem fileSystem, Configuration yarnConf, Container container,
-      ContainerLaunchService.ComponentLaunchContext compLaunchContext,
-      Map<String, String> tokensForSubstitution)
-          throws IOException, SliderException {
-    boolean useEntryPoint = checkUseEntryPoint(compLaunchContext);
-    if (useEntryPoint) {
-      String launchCommand = compLaunchContext.getLaunchCommand();
-      if (!StringUtils.isEmpty(launchCommand)) {
-        if(launchCommand.contains(" ")) {
-          // convert space delimiter command to exec format
-          launchCommand = ProviderUtils
-              .replaceSpacesWithDelimiter(launchCommand, ",");
-        }
-        launcher.addCommand(launchCommand);
-      }
-    } else {
-      // substitute launch command
-      String launchCommand = compLaunchContext.getLaunchCommand();
-      // docker container may have empty commands
-      if (!StringUtils.isEmpty(launchCommand)) {
-        launchCommand = ProviderUtils
-            .substituteStrWithTokens(launchCommand, tokensForSubstitution);
-        CommandLineBuilder operation = new CommandLineBuilder();
-        operation.add(launchCommand);
-        operation.addOutAndErrFiles(OUT_FILE, ERR_FILE);
-        launcher.addCommand(operation.build());
-      }
-    }
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/tarball/TarballClientProvider.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/tarball/TarballClientProvider.java
deleted file mode 100644
index b801e0caa31..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/tarball/TarballClientProvider.java
+++ /dev/null
@@ -1,68 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.provider.tarball;
-
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.yarn.service.api.records.Artifact;
-import org.apache.hadoop.yarn.service.api.records.ConfigFile;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConstants;
-import org.apache.hadoop.yarn.service.provider.AbstractClientProvider;
-import org.apache.hadoop.yarn.service.exceptions.RestApiErrorMessages;
-
-import java.io.IOException;
-import java.nio.file.Paths;
-
-public class TarballClientProvider extends AbstractClientProvider
-    implements YarnServiceConstants {
-
-  public TarballClientProvider() {
-  }
-
-  @Override
-  public void validateArtifact(Artifact artifact, String compName,
-      FileSystem fs) throws IOException {
-    if (artifact == null) {
-      throw new IllegalArgumentException(String.format(
-          RestApiErrorMessages.ERROR_ARTIFACT_FOR_COMP_INVALID, compName));
-    }
-    if (StringUtils.isEmpty(artifact.getId())) {
-      throw new IllegalArgumentException(String.format(
-          RestApiErrorMessages.ERROR_ARTIFACT_ID_FOR_COMP_INVALID, compName));
-    }
-    Path p = new Path(artifact.getId());
-    if (!fs.exists(p)) {
-      throw new IllegalArgumentException(String.format(
-          RestApiErrorMessages.ERROR_ARTIFACT_PATH_FOR_COMP_INVALID, compName,
-          Artifact.TypeEnum.TARBALL.name(), artifact.getId()));
-    }
-  }
-
-  @Override
-  protected void validateConfigFile(ConfigFile configFile, String compName,
-      FileSystem fileSystem) throws IOException {
-    // validate dest_file is not absolute
-    if (Paths.get(configFile.getDestFile()).isAbsolute()) {
-      throw new IllegalArgumentException(String.format(
-          RestApiErrorMessages.ERROR_CONFIGFILE_DEST_FILE_FOR_COMP_NOT_ABSOLUTE,
-          compName, Artifact.TypeEnum.TARBALL.name(),
-          configFile.getDestFile()));
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/tarball/TarballProviderFactory.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/tarball/TarballProviderFactory.java
deleted file mode 100644
index 9d81f66e6b2..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/tarball/TarballProviderFactory.java
+++ /dev/null
@@ -1,52 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.provider.tarball;
-
-import org.apache.hadoop.yarn.service.provider.AbstractClientProvider;
-import org.apache.hadoop.yarn.service.provider.ProviderService;
-import org.apache.hadoop.yarn.service.provider.ProviderFactory;
-
-public class TarballProviderFactory extends ProviderFactory {
-  private static final ProviderFactory FACTORY = new
-      TarballProviderFactory();
-
-  private TarballProviderFactory() {
-  }
-
-  private static class Client {
-    static final AbstractClientProvider PROVIDER = new TarballClientProvider();
-  }
-
-  private static class Server {
-    static final ProviderService PROVIDER = new TarballProviderService();
-  }
-
-  @Override
-  public AbstractClientProvider createClientProvider() {
-    return Client.PROVIDER;
-  }
-
-  @Override
-  public ProviderService createServerProvider() {
-    return Server.PROVIDER;
-  }
-
-  public static ProviderFactory getInstance() {
-    return FACTORY;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/tarball/TarballProviderService.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/tarball/TarballProviderService.java
deleted file mode 100644
index cd783e77f76..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/provider/tarball/TarballProviderService.java
+++ /dev/null
@@ -1,51 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.provider.tarball;
-
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.yarn.api.records.LocalResource;
-import org.apache.hadoop.yarn.api.records.LocalResourceType;
-import org.apache.hadoop.yarn.api.records.LocalResourceVisibility;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.apache.hadoop.yarn.service.containerlaunch.ContainerLaunchService;
-import org.apache.hadoop.yarn.service.provider.AbstractProviderService;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-import org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher;
-
-import java.io.IOException;
-
-public class TarballProviderService extends AbstractProviderService {
-
-  @Override
-  public void processArtifact(AbstractLauncher launcher,
-      ComponentInstance instance, SliderFileSystem fileSystem,
-      Service service, ContainerLaunchService.ComponentLaunchContext
-      compLaunchCtx) throws IOException {
-    Path artifact = new Path(compLaunchCtx.getArtifact().getId());
-    if (!fileSystem.isFile(artifact)) {
-      throw new IOException(
-          "Package doesn't exist as a resource: " + artifact);
-    }
-    log.info("Adding resource {}", artifact);
-    LocalResourceType type = LocalResourceType.ARCHIVE;
-    LocalResource packageResource = fileSystem.createAmResource(artifact, type,
-        LocalResourceVisibility.APPLICATION);
-    launcher.addLocalResource(APP_LIB_DIR, packageResource);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/registry/CustomRegistryConstants.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/registry/CustomRegistryConstants.java
deleted file mode 100644
index 56634f678c9..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/registry/CustomRegistryConstants.java
+++ /dev/null
@@ -1,57 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.registry;
-
-/**
- * These are constants unique to the Slider AM
- */
-public class CustomRegistryConstants {
-
-  public static final String MANAGEMENT_REST_API =
-      "classpath:org.apache.slider.management";
-  
-  public static final String REGISTRY_REST_API =
-      "classpath:org.apache.slider.registry";
-  
-  public static final String PUBLISHER_REST_API =
-      "classpath:org.apache.slider.publisher";
-
-  public static final String PUBLISHER_CONFIGURATIONS_API =
-      "classpath:org.apache.slider.publisher.configurations";
-
-  public static final String PUBLISHER_EXPORTS_API =
-      "classpath:org.apache.slider.publisher.exports";
-
-  public static final String PUBLISHER_DOCUMENTS_API =
-      "classpath:org.apache.slider.publisher.documents";
-
-  public static final String AGENT_SECURE_REST_API =
-      "classpath:org.apache.slider.agents.secure";
-
-  public static final String AGENT_ONEWAY_REST_API =
-      "classpath:org.apache.slider.agents.oneway";
-
-  public static final String AM_IPC_PROTOCOL =
-      "classpath:org.apache.slider.appmaster.ipc";
-
-  public static final String AM_REST_BASE =
-      "classpath:org.apache.slider.client.rest";
-
-  public static final String WEB_UI = "http://";
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/registry/YarnRegistryViewForProviders.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/registry/YarnRegistryViewForProviders.java
deleted file mode 100644
index 2b13cf0cae8..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/registry/YarnRegistryViewForProviders.java
+++ /dev/null
@@ -1,252 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.registry;
-
-import org.apache.hadoop.util.Preconditions;
-import org.apache.hadoop.fs.PathNotFoundException;
-import org.apache.hadoop.registry.client.api.RegistryConstants;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
-import org.apache.hadoop.registry.client.api.BindFlags;
-import org.apache.hadoop.registry.client.api.RegistryOperations;
-import org.apache.hadoop.registry.client.binding.RegistryUtils;
-import org.apache.hadoop.registry.client.binding.RegistryPathUtils;
-
-import org.apache.hadoop.registry.client.types.ServiceRecord;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceId;
-import org.apache.hadoop.yarn.service.utils.ServiceUtils;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.util.List;
-
-import static org.apache.hadoop.registry.client.binding.RegistryPathUtils.join;
-
-/**
- * Registry view for providers. This tracks where the service
- * is registered, offers access to the record and other things.
- */
-public class YarnRegistryViewForProviders {
-  private static final Logger LOG =
-      LoggerFactory.getLogger(YarnRegistryViewForProviders.class);
-
-  private final RegistryOperations registryOperations;
-  private final String user;
-  private final String serviceClass;
-  private final String instanceName;
-  /**
-   * Record used where the service registered itself.
-   * Null until the service is registered
-   */
-  private ServiceRecord selfRegistration;
-
-  /**
-   * Path where record was registered.
-   * Null until the service is registered
-   */
-  private String selfRegistrationPath;
-
-  public YarnRegistryViewForProviders(RegistryOperations registryOperations,
-      String user,
-      String serviceClass,
-      String instanceName,
-      ApplicationAttemptId applicationAttemptId) {
-    Preconditions.checkArgument(registryOperations != null,
-        "null registry operations");
-    Preconditions.checkArgument(user != null, "null user");
-    Preconditions.checkArgument(ServiceUtils.isSet(serviceClass),
-        "unset service class");
-    Preconditions.checkArgument(ServiceUtils.isSet(instanceName),
-        "instanceName");
-    Preconditions.checkArgument(applicationAttemptId != null,
-        "null applicationAttemptId");
-    this.registryOperations = registryOperations;
-    this.user = user;
-    this.serviceClass = serviceClass;
-    this.instanceName = instanceName;
-  }
-
-  public String getUser() {
-    return user;
-  }
-
-
-  private void setSelfRegistration(ServiceRecord selfRegistration) {
-    this.selfRegistration = selfRegistration;
-  }
-
-  /**
-   * Get the path to where the service has registered itself.
-   * Null until the service is registered
-   * @return the service registration path.
-   */
-  public String getSelfRegistrationPath() {
-    return selfRegistrationPath;
-  }
-
-  /**
-   * Get the absolute path to where the service has registered itself.
-   * This includes the base registry path
-   * Null until the service is registered
-   * @return the service registration path.
-   */
-  public String getAbsoluteSelfRegistrationPath() {
-    if (selfRegistrationPath == null) {
-      return null;
-    }
-    String root = registryOperations.getConfig().getTrimmed(
-        RegistryConstants.KEY_REGISTRY_ZK_ROOT,
-        RegistryConstants.DEFAULT_ZK_REGISTRY_ROOT);
-    return RegistryPathUtils.join(root, selfRegistrationPath);
-  }
-
-  /**
-   * Add a component under the slider name/entry.
-   * @param componentName component name
-   * @param record record to put
-   * @throws IOException
-   */
-  public void putComponent(String componentName,
-      ServiceRecord record) throws
-      IOException {
-    putComponent(serviceClass, instanceName,
-        componentName,
-        record);
-  }
-
-  /**
-   * Add a component.
-   * @param serviceClass service class to use under ~user
-   * @param componentName component name
-   * @param record record to put
-   * @throws IOException
-   */
-  public void putComponent(String serviceClass,
-      String serviceName,
-      String componentName,
-      ServiceRecord record) throws IOException {
-    String path = RegistryUtils.componentPath(
-        user, serviceClass, serviceName, componentName);
-    String parentPath = RegistryPathUtils.parentOf(path);
-    if (!registryOperations.exists(parentPath)) {
-      registryOperations.mknode(parentPath, true);
-    }
-    registryOperations.bind(path, record, BindFlags.OVERWRITE);
-  }
-
-  /**
-   * Get a component.
-   * @param componentName component name
-   * @return the service record
-   * @throws IOException
-   */
-  public ServiceRecord getComponent(String componentName) throws IOException {
-    String path = RegistryUtils.componentPath(
-        user, serviceClass, instanceName, componentName);
-    LOG.info("Resolving path {}", path);
-    return registryOperations.resolve(path);
-  }
-
-  /**
-   * List components.
-   * @return a list of components
-   * @throws IOException
-   */
-  public List<String> listComponents() throws IOException {
-    String path = RegistryUtils.componentListPath(
-        user, serviceClass, instanceName);
-    return registryOperations.list(path);
-  }
-
-  /**
-   * Add a service under a path, optionally purging any history.
-   * @param username user
-   * @param serviceClass service class to use under ~user
-   * @param serviceName name of the service
-   * @param record service record
-   * @param deleteTreeFirst perform recursive delete of the path first.
-   * @return the path the service was created at
-   * @throws IOException
-   */
-  public String putService(String username,
-      String serviceClass,
-      String serviceName,
-      ServiceRecord record,
-      boolean deleteTreeFirst) throws IOException {
-    String path = RegistryUtils.servicePath(
-        username, serviceClass, serviceName);
-    if (deleteTreeFirst) {
-      registryOperations.delete(path, true);
-    }
-    registryOperations.mknode(RegistryPathUtils.parentOf(path), true);
-    registryOperations.bind(path, record, BindFlags.OVERWRITE);
-    return path;
-  }
-
-  /**
-   * Add a service under a path for the current user.
-   * @param record service record
-   * @param deleteTreeFirst perform recursive delete of the path first
-   * @return the path the service was created at
-   * @throws IOException
-   */
-  public String registerSelf(
-      ServiceRecord record,
-      boolean deleteTreeFirst) throws IOException {
-    selfRegistrationPath =
-        putService(user, serviceClass, instanceName, record, deleteTreeFirst);
-    setSelfRegistration(record);
-    return selfRegistrationPath;
-  }
-
-  /**
-   * Delete a component.
-   * @param containerId component name
-   * @throws IOException
-   */
-  public void deleteComponent(ComponentInstanceId instanceId,
-      String containerId) throws IOException {
-    String path = RegistryUtils.componentPath(
-        user, serviceClass, instanceName,
-        containerId);
-    LOG.info(instanceId + ": Deleting registry path " + path);
-    registryOperations.delete(path, false);
-  }
-
-  /**
-   * Delete the children of a path -but not the path itself.
-   * It is not an error if the path does not exist
-   * @param path path to delete
-   * @param recursive flag to request recursive deletes
-   * @throws IOException IO problems
-   */
-  public void deleteChildren(String path, boolean recursive) throws IOException {
-    List<String> childNames = null;
-    try {
-      childNames = registryOperations.list(path);
-    } catch (PathNotFoundException e) {
-      return;
-    }
-    for (String childName : childNames) {
-      String child = join(path, childName);
-      registryOperations.delete(child, recursive);
-    }
-  }
-  
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceMetricsSink.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceMetricsSink.java
deleted file mode 100644
index ff4556f7cd7..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceMetricsSink.java
+++ /dev/null
@@ -1,98 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.timelineservice;
-
-import org.apache.commons.configuration2.SubsetConfiguration;
-import org.apache.hadoop.metrics2.MetricsRecord;
-import org.apache.hadoop.metrics2.MetricsSink;
-import org.apache.hadoop.metrics2.MetricsTag;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * Write the metrics to a ATSv2. Generally, this class is instantiated via
- * hadoop-metrics2 property files. Specifically, you would create this class by
- * adding the following to by This would actually be set as: <code>
- * [prefix].sink.[some instance name].class
- * =org.apache.hadoop.yarn.service.timelineservice.ServiceMetricsSink
- * </code>, where <tt>prefix</tt> is "atsv2": and <tt>some instance name</tt> is
- * just any unique name, so properties can be differentiated if there are
- * multiple sinks of the same type created
- */
-public class ServiceMetricsSink implements MetricsSink {
-
-  private static final Logger log =
-      LoggerFactory.getLogger(ServiceMetricsSink.class);
-
-  private ServiceTimelinePublisher serviceTimelinePublisher;
-
-  public ServiceMetricsSink() {
-
-  }
-
-  public ServiceMetricsSink(ServiceTimelinePublisher publisher) {
-    serviceTimelinePublisher = publisher;
-  }
-
-  /**
-   * Publishes service and component metrics to ATS.
-   */
-  @Override
-  public void putMetrics(MetricsRecord record) {
-    if (serviceTimelinePublisher.isStopped()) {
-      log.warn("ServiceTimelinePublisher has stopped. "
-          + "Not publishing any more metrics to ATS.");
-      return;
-    }
-
-    boolean isServiceMetrics = false;
-    boolean isComponentMetrics = false;
-    String appId = null;
-    for (MetricsTag tag : record.tags()) {
-      if (tag.name().equals("type") && tag.value().equals("service")) {
-        isServiceMetrics = true;
-      } else if (tag.name().equals("type") && tag.value().equals("component")) {
-        isComponentMetrics = true;
-        break; // if component metrics, no more information required from tag so
-               // break the loop
-      } else if (tag.name().equals("appId")) {
-        appId = tag.value();
-      }
-    }
-
-    if (isServiceMetrics && appId != null) {
-      log.debug("Publishing service metrics. {}", record);
-      serviceTimelinePublisher.publishMetrics(record.metrics(), appId,
-          ServiceTimelineEntityType.SERVICE_ATTEMPT.toString(),
-          record.timestamp());
-    } else if (isComponentMetrics) {
-      log.debug("Publishing Component metrics. {}", record);
-      serviceTimelinePublisher.publishMetrics(record.metrics(), record.name(),
-          ServiceTimelineEntityType.COMPONENT.toString(), record.timestamp());
-    }
-  }
-
-  @Override
-  public void init(SubsetConfiguration conf) {
-  }
-
-  @Override
-  public void flush() {
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceTimelineEntityType.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceTimelineEntityType.java
deleted file mode 100644
index d5c95394aa4..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceTimelineEntityType.java
+++ /dev/null
@@ -1,39 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.timelineservice;
-
-/**
- * Slider entities that are published to ATS.
- */
-public enum ServiceTimelineEntityType {
-  /**
-   * Used for publishing service entity information.
-   */
-  SERVICE_ATTEMPT,
-
-  /**
-   * Used for publishing component entity information.
-   */
-  COMPONENT,
-
-  /**
-   * Used for publishing component instance entity information.
-   */
-  COMPONENT_INSTANCE
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceTimelineEvent.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceTimelineEvent.java
deleted file mode 100644
index 832dad729ca..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceTimelineEvent.java
+++ /dev/null
@@ -1,39 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.timelineservice;
-
-/**
- * Events that are used to store in ATS.
- */
-public enum ServiceTimelineEvent {
-  SERVICE_ATTEMPT_REGISTERED,
-
-  SERVICE_ATTEMPT_UNREGISTERED,
-
-  COMPONENT_INSTANCE_REGISTERED,
-
-  COMPONENT_INSTANCE_UNREGISTERED,
-
-  COMPONENT_INSTANCE_IP_HOST_UPDATE,
-
-  COMPONENT_INSTANCE_BECOME_READY,
-
-  COMPONENT_FINISHED
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceTimelineMetricsConstants.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceTimelineMetricsConstants.java
deleted file mode 100644
index a5ef2b82534..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceTimelineMetricsConstants.java
+++ /dev/null
@@ -1,94 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.timelineservice;
-
-/**
- * Constants which are stored as key in ATS
- */
-public final class ServiceTimelineMetricsConstants {
-
-  public static final String URI = "URI";
-
-  public static final String NAME = "NAME";
-
-  public static final String STATE = "STATE";
-
-  public static final String EXIT_STATUS_CODE = "EXIT_STATUS_CODE";
-
-  public static final String EXIT_REASON = "EXIT_REASON";
-
-  public static final String DIAGNOSTICS_INFO = "DIAGNOSTICS_INFO";
-
-  public static final String LAUNCH_TIME = "LAUNCH_TIME";
-
-  public static final String QUICK_LINKS = "QUICK_LINKS";
-
-  public static final String LAUNCH_COMMAND = "LAUNCH_COMMAND";
-
-  public static final String TOTAL_CONTAINERS = "NUMBER_OF_CONTAINERS";
-
-  public static final String RUNNING_CONTAINERS =
-      "NUMBER_OF_RUNNING_CONTAINERS";
-
-  /**
-   * Artifacts constants.
-   */
-  public static final String ARTIFACT_ID = "ARTIFACT_ID";
-
-  public static final String ARTIFACT_TYPE = "ARTIFACT_TYPE";
-
-  public static final String ARTIFACT_URI = "ARTIFACT_URI";
-
-  /**
-   * Resource constants.
-   */
-  public static final String RESOURCE_CPU = "RESOURCE_CPU";
-
-  public static final String RESOURCE_MEMORY = "RESOURCE_MEMORY";
-
-  public static final String RESOURCE_PROFILE = "RESOURCE_PROFILE";
-
-  /**
-   * component instance constants.
-   */
-  public static final String IP = "IP";
-
-  public static final String EXPOSED_PORTS = "EXPOSED_PORTS";
-
-  public static final String HOSTNAME = "HOSTNAME";
-
-  public static final String BARE_HOST = "BARE_HOST";
-
-  public static final String COMPONENT_NAME = "COMPONENT_NAME";
-
-  public static final String COMPONENT_INSTANCE_NAME = "COMPONENT_INSTANCE_NAME";
-
-  /**
-   * component constants.
-   */
-  public static final String DEPENDENCIES = "DEPENDENCIES";
-
-  public static final String DESCRIPTION = "DESCRIPTION";
-
-  public static final String RUN_PRIVILEGED_CONTAINER =
-      "RUN_PRIVILEGED_CONTAINER";
-
-  public static final String PLACEMENT_POLICY = "PLACEMENT_POLICY";
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceTimelinePublisher.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceTimelinePublisher.java
deleted file mode 100644
index 0982b66b673..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/ServiceTimelinePublisher.java
+++ /dev/null
@@ -1,401 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.timelineservice;
-
-import org.apache.hadoop.metrics2.AbstractMetric;
-import org.apache.hadoop.service.CompositeService;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;
-import org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity;
-import org.apache.hadoop.yarn.api.records.timelineservice.TimelineEvent;
-import org.apache.hadoop.yarn.api.records.timelineservice.TimelineMetric;
-import org.apache.hadoop.yarn.client.api.TimelineV2Client;
-import org.apache.hadoop.yarn.service.ServiceContext;
-import org.apache.hadoop.yarn.service.api.records.*;
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.api.records.ComponentState;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.apache.hadoop.yarn.util.timeline.TimelineUtils;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Map.Entry;
-import java.util.Set;
-
-import static org.apache.hadoop.yarn.service.api.records.ContainerState.READY;
-import static org.apache.hadoop.yarn.service.timelineservice.ServiceTimelineMetricsConstants.DIAGNOSTICS_INFO;
-
-/**
- * A single service that publishes all the Timeline Entities.
- */
-public class ServiceTimelinePublisher extends CompositeService {
-
-  // Number of bytes of config which can be published in one shot to ATSv2.
-  public static final int ATS_CONFIG_PUBLISH_SIZE_BYTES = 10 * 1024;
-
-  private TimelineV2Client timelineClient;
-
-  private volatile boolean stopped = false;
-
-  private static final Logger log =
-      LoggerFactory.getLogger(ServiceTimelinePublisher.class);
-
-  @Override
-  protected void serviceInit(org.apache.hadoop.conf.Configuration configuration)
-      throws Exception {
-    addService(timelineClient);
-    super.serviceInit(configuration);
-  }
-
-
-  @Override
-  protected void serviceStop() throws Exception {
-    stopped = true;
-    super.serviceStop();
-  }
-
-  public boolean isStopped() {
-    return stopped;
-  }
-
-  public ServiceTimelinePublisher(TimelineV2Client client) {
-    super(ServiceTimelinePublisher.class.getName());
-    timelineClient = client;
-  }
-
-  public void serviceAttemptRegistered(Service service,
-      org.apache.hadoop.conf.Configuration systemConf) {
-    long currentTimeMillis = service.getLaunchTime() == null
-        ? System.currentTimeMillis() : service.getLaunchTime().getTime();
-
-    TimelineEntity entity = createServiceAttemptEntity(service.getId());
-    entity.setCreatedTime(currentTimeMillis);
-
-    // create info keys
-    Map<String, Object> entityInfos = new HashMap<String, Object>();
-    entityInfos.put(ServiceTimelineMetricsConstants.NAME, service.getName());
-    entityInfos.put(ServiceTimelineMetricsConstants.STATE,
-        ServiceState.STARTED.toString());
-    entityInfos.put(ServiceTimelineMetricsConstants.LAUNCH_TIME,
-        currentTimeMillis);
-    entity.addInfo(ServiceTimelineMetricsConstants.QUICK_LINKS,
-        service.getQuicklinks());
-    entity.addInfo(entityInfos);
-
-    // add an event
-    TimelineEvent startEvent = new TimelineEvent();
-    startEvent.setId(ServiceTimelineEvent.SERVICE_ATTEMPT_REGISTERED.toString());
-    startEvent.setTimestamp(currentTimeMillis);
-    entity.addEvent(startEvent);
-
-    // publish before configurations published
-    putEntity(entity);
-
-    // publish system config - YarnConfiguration
-    populateTimelineEntity(systemConf.iterator(), service.getId(),
-        ServiceTimelineEntityType.SERVICE_ATTEMPT.toString());
-    // publish container conf
-    publishContainerConf(service.getConfiguration(), service.getId(),
-        ServiceTimelineEntityType.SERVICE_ATTEMPT.toString());
-
-    // publish component as separate entity.
-    publishComponents(service.getComponents());
-  }
-
-  public void serviceAttemptUpdated(Service service) {
-    TimelineEntity entity = createServiceAttemptEntity(service.getId());
-    entity.addInfo(ServiceTimelineMetricsConstants.QUICK_LINKS,
-        service.getQuicklinks());
-    putEntity(entity);
-  }
-
-  public void serviceAttemptUnregistered(ServiceContext context,
-      FinalApplicationStatus status, String diagnostics) {
-    TimelineEntity entity = createServiceAttemptEntity(
-        context.attemptId.getApplicationId().toString());
-    Map<String, Object> entityInfos = new HashMap<String, Object>();
-    entityInfos.put(ServiceTimelineMetricsConstants.STATE, status);
-    entityInfos.put(DIAGNOSTICS_INFO, diagnostics);
-    entity.addInfo(entityInfos);
-
-    // add an event
-    TimelineEvent finishEvent = new TimelineEvent();
-    finishEvent
-        .setId(ServiceTimelineEvent.SERVICE_ATTEMPT_UNREGISTERED.toString());
-    finishEvent.setTimestamp(System.currentTimeMillis());
-    entity.addEvent(finishEvent);
-
-    putEntity(entity);
-  }
-
-  public void componentInstanceStarted(Container container,
-      ComponentInstance instance) {
-
-    TimelineEntity entity = createComponentInstanceEntity(container.getId());
-    entity.setCreatedTime(container.getLaunchTime().getTime());
-
-    // create info keys
-    Map<String, Object> entityInfos = new HashMap<String, Object>();
-    entityInfos.put(ServiceTimelineMetricsConstants.BARE_HOST,
-        container.getBareHost());
-    entityInfos.put(ServiceTimelineMetricsConstants.STATE,
-        container.getState().toString());
-    entityInfos.put(ServiceTimelineMetricsConstants.LAUNCH_TIME,
-        container.getLaunchTime().getTime());
-    entityInfos.put(ServiceTimelineMetricsConstants.COMPONENT_NAME,
-        instance.getCompName());
-    entityInfos.put(ServiceTimelineMetricsConstants.COMPONENT_INSTANCE_NAME,
-        instance.getCompInstanceName());
-    entity.addInfo(entityInfos);
-
-    // add an event
-    TimelineEvent startEvent = new TimelineEvent();
-    startEvent
-        .setId(ServiceTimelineEvent.COMPONENT_INSTANCE_REGISTERED.toString());
-    startEvent.setTimestamp(container.getLaunchTime().getTime());
-    entity.addEvent(startEvent);
-
-    putEntity(entity);
-  }
-
-  public void componentInstanceFinished(ContainerId containerId,
-      int exitCode, ContainerState state, String diagnostics) {
-    TimelineEntity entity = createComponentInstanceEntity(
-        containerId.toString());
-
-    // create info keys
-    Map<String, Object> entityInfos = new HashMap<String, Object>();
-    entityInfos.put(ServiceTimelineMetricsConstants.EXIT_STATUS_CODE,
-        exitCode);
-    entityInfos.put(DIAGNOSTICS_INFO, diagnostics);
-    entityInfos.put(ServiceTimelineMetricsConstants.STATE, state);
-    entity.addInfo(entityInfos);
-
-    // add an event
-    TimelineEvent startEvent = new TimelineEvent();
-    startEvent
-        .setId(ServiceTimelineEvent.COMPONENT_INSTANCE_UNREGISTERED.toString());
-    startEvent.setTimestamp(System.currentTimeMillis());
-    entity.addEvent(startEvent);
-
-    putEntity(entity);
-  }
-
-  public void componentInstanceIPHostUpdated(Container container) {
-    TimelineEntity entity = createComponentInstanceEntity(container.getId());
-
-    // create info keys
-    Map<String, Object> entityInfos = new HashMap<String, Object>();
-    entityInfos.put(ServiceTimelineMetricsConstants.IP, container.getIp());
-    entityInfos.put(ServiceTimelineMetricsConstants.EXPOSED_PORTS,
-        container.getExposedPorts());
-    entityInfos.put(ServiceTimelineMetricsConstants.HOSTNAME,
-        container.getHostname());
-    entityInfos.put(ServiceTimelineMetricsConstants.STATE,
-        container.getState().toString());
-    entity.addInfo(entityInfos);
-
-    TimelineEvent updateEvent = new TimelineEvent();
-    updateEvent.setId(ServiceTimelineEvent.COMPONENT_INSTANCE_IP_HOST_UPDATE
-        .toString());
-    updateEvent.setTimestamp(System.currentTimeMillis());
-    entity.addEvent(updateEvent);
-
-    putEntity(entity);
-  }
-
-  public void componentInstanceBecomeReady(Container container) {
-    TimelineEntity entity = createComponentInstanceEntity(container.getId());
-    Map<String, Object> entityInfo = new HashMap<>();
-    entityInfo.put(ServiceTimelineMetricsConstants.STATE, READY);
-    entity.addInfo(entityInfo);
-    TimelineEvent updateEvent = new TimelineEvent();
-    updateEvent.setId(ServiceTimelineEvent.COMPONENT_INSTANCE_BECOME_READY
-        .toString());
-    updateEvent.setTimestamp(System.currentTimeMillis());
-    entity.addEvent(updateEvent);
-    putEntity(entity);
-  }
-
-  private void publishComponents(List<Component> components) {
-    long currentTimeMillis = System.currentTimeMillis();
-    for (Component component : components) {
-      TimelineEntity entity = createComponentEntity(component.getName());
-      entity.setCreatedTime(currentTimeMillis);
-
-      // create info keys
-      Map<String, Object> entityInfos = new HashMap<String, Object>();
-      if (component.getArtifact() != null) {
-        entityInfos.put(ServiceTimelineMetricsConstants.ARTIFACT_ID,
-            component.getArtifact().getId());
-        entityInfos.put(ServiceTimelineMetricsConstants.ARTIFACT_TYPE,
-            component.getArtifact().getType().toString());
-      }
-
-      if (component.getResource() != null) {
-        entityInfos.put(ServiceTimelineMetricsConstants.RESOURCE_CPU,
-            component.getResource().getCpus());
-        entityInfos.put(ServiceTimelineMetricsConstants.RESOURCE_MEMORY,
-            component.getResource().getMemory());
-        if (component.getResource().getProfile() != null) {
-          entityInfos.put(ServiceTimelineMetricsConstants.RESOURCE_PROFILE,
-              component.getResource().getProfile());
-        }
-      }
-
-      if (component.getLaunchCommand() != null) {
-        entityInfos.put(ServiceTimelineMetricsConstants.LAUNCH_COMMAND,
-            component.getLaunchCommand());
-      }
-      entityInfos.put(ServiceTimelineMetricsConstants.RUN_PRIVILEGED_CONTAINER,
-          component.getRunPrivilegedContainer().toString());
-      entity.addInfo(entityInfos);
-
-      putEntity(entity);
-
-      // publish container specific configurations
-      publishContainerConf(component.getConfiguration(), component.getName(),
-          ServiceTimelineEntityType.COMPONENT.toString());
-    }
-  }
-
-  private void publishContainerConf(Configuration configuration,
-      String entityId, String entityType) {
-    populateTimelineEntity(configuration.getEnv().entrySet().iterator(),
-        entityId, entityType);
-
-    for (ConfigFile configFile : configuration.getFiles()) {
-      populateTimelineEntity(configFile.getProperties().entrySet().iterator(),
-          entityId, entityType);
-    }
-  }
-
-  private void populateTimelineEntity(Iterator<Entry<String, String>> iterator,
-      String entityId, String entityType) {
-    int configSize = 0;
-    TimelineEntity entity = createTimelineEntity(entityId, entityType);
-    while (iterator.hasNext()) {
-      Entry<String, String> entry = iterator.next();
-      int size = entry.getKey().length() + entry.getValue().length();
-      configSize += size;
-      // Configs are split into multiple entities if they exceed 100kb in size.
-      if (configSize > ATS_CONFIG_PUBLISH_SIZE_BYTES) {
-        if (entity.getConfigs().size() > 0) {
-          putEntity(entity);
-          entity = createTimelineEntity(entityId, entityType);
-        }
-        configSize = size;
-      }
-      entity.addConfig(entry.getKey(), entry.getValue());
-    }
-    if (configSize > 0) {
-      putEntity(entity);
-    }
-  }
-
-  /**
-   * Called from ServiceMetricsSink at regular interval of time.
-   * @param metrics of service or components
-   * @param entityId Id of entity
-   * @param entityType Type of entity
-   * @param timestamp
-   */
-  public void publishMetrics(Iterable<AbstractMetric> metrics, String entityId,
-      String entityType, long timestamp) {
-    TimelineEntity entity = createTimelineEntity(entityId, entityType);
-    Set<TimelineMetric> entityMetrics = new HashSet<TimelineMetric>();
-    for (AbstractMetric metric : metrics) {
-      TimelineMetric timelineMetric = new TimelineMetric();
-      timelineMetric.setId(metric.name());
-      timelineMetric.addValue(timestamp, metric.value());
-      entityMetrics.add(timelineMetric);
-    }
-    entity.setMetrics(entityMetrics);
-    putEntity(entity);
-  }
-
-  private TimelineEntity createServiceAttemptEntity(String serviceId) {
-    TimelineEntity entity = createTimelineEntity(serviceId,
-        ServiceTimelineEntityType.SERVICE_ATTEMPT.toString());
-    return entity;
-  }
-
-  private TimelineEntity createComponentInstanceEntity(String instanceId) {
-    TimelineEntity entity = createTimelineEntity(instanceId,
-        ServiceTimelineEntityType.COMPONENT_INSTANCE.toString());
-    return entity;
-  }
-
-  private TimelineEntity createComponentEntity(String componentId) {
-    TimelineEntity entity = createTimelineEntity(componentId,
-        ServiceTimelineEntityType.COMPONENT.toString());
-    return entity;
-  }
-
-  private TimelineEntity createTimelineEntity(String entityId,
-      String entityType) {
-    TimelineEntity entity = new TimelineEntity();
-    entity.setId(entityId);
-    entity.setType(entityType);
-    return entity;
-  }
-
-  private void putEntity(TimelineEntity entity) {
-    try {
-      if (log.isDebugEnabled()) {
-        log.debug("Publishing the entity " + entity + ", JSON-style content: "
-            + TimelineUtils.dumpTimelineRecordtoJSON(entity));
-      }
-      if (timelineClient != null) {
-        timelineClient.putEntitiesAsync(entity);
-      } else {
-        log.error("Seems like client has been removed before the entity "
-            + "could be published for " + entity);
-      }
-    } catch (Exception e) {
-      log.error("Error when publishing entity " + entity, e);
-    }
-  }
-
-  public void componentFinished(
-      Component comp,
-      ComponentState state, long finishTime) {
-    createComponentEntity(comp.getName());
-    TimelineEntity entity = createComponentEntity(comp.getName());
-
-    // create info keys
-    Map<String, Object> entityInfos = new HashMap<String, Object>();
-    entityInfos.put(ServiceTimelineMetricsConstants.STATE, state);
-    entity.addInfo(entityInfos);
-
-    // add an event
-    TimelineEvent startEvent = new TimelineEvent();
-    startEvent
-        .setId(ServiceTimelineEvent.COMPONENT_FINISHED.toString());
-    startEvent.setTimestamp(finishTime);
-    entity.addEvent(startEvent);
-
-    putEntity(entity);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/package-info.java
deleted file mode 100644
index 72f7842b836..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/timelineservice/package-info.java
+++ /dev/null
@@ -1,27 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/**
- * ATS implementation
- */
-@InterfaceAudience.Private
-@InterfaceStability.Unstable
-package org.apache.hadoop.yarn.service.timelineservice;
-
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ApplicationReportSerDeser.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ApplicationReportSerDeser.java
deleted file mode 100644
index ffaf27f1298..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ApplicationReportSerDeser.java
+++ /dev/null
@@ -1,50 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import com.fasterxml.jackson.core.JsonProcessingException;
-
-/**
- * Persistence of {@link SerializedApplicationReport}
- * 
- */
-public class ApplicationReportSerDeser
-    extends JsonSerDeser<SerializedApplicationReport> {
-  public ApplicationReportSerDeser() {
-    super(SerializedApplicationReport.class);
-  }
-
-
-  private static final ApplicationReportSerDeser
-      staticinstance = new ApplicationReportSerDeser();
-
-  /**
-   * Convert an instance to a JSON string -sync access to a shared ser/deser
-   * object instance
-   * @param instance object to convert
-   * @return a JSON string description
-   * @throws JsonProcessingException parse problems
-   */
-  public static String toString(SerializedApplicationReport instance)
-      throws JsonProcessingException {
-    synchronized (staticinstance) {
-      return staticinstance.toJson(instance);
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ClientRegistryBinder.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ClientRegistryBinder.java
deleted file mode 100644
index 25cab87d231..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ClientRegistryBinder.java
+++ /dev/null
@@ -1,201 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import org.apache.hadoop.util.Preconditions;
-import org.apache.hadoop.fs.PathNotFoundException;
-import org.apache.hadoop.registry.client.api.RegistryConstants;
-import org.apache.hadoop.registry.client.api.RegistryOperations;
-import org.apache.hadoop.registry.client.binding.RegistryPathUtils;
-import org.apache.hadoop.registry.client.binding.RegistryTypeUtils;
-import org.apache.hadoop.registry.client.exceptions.InvalidRecordException;
-import org.apache.hadoop.registry.client.impl.zk.RegistryInternalConstants;
-import org.apache.hadoop.registry.client.types.Endpoint;
-import org.apache.hadoop.registry.client.types.ServiceRecord;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.util.List;
-
-import static org.apache.hadoop.registry.client.binding.RegistryPathUtils.encodeForRegistry;
-import static org.apache.hadoop.registry.client.binding.RegistryUtils.convertUsername;
-import static org.apache.hadoop.registry.client.binding.RegistryUtils.getCurrentUsernameUnencoded;
-import static org.apache.hadoop.registry.client.binding.RegistryUtils.servicePath;
-
-/**
- * Generic code to get the URLs for clients via the registry
- */
-public class ClientRegistryBinder {
-  private static final Logger log =
-      LoggerFactory.getLogger(ClientRegistryBinder.class);
-
-  private final RegistryOperations operations;
-
-  public ClientRegistryBinder(RegistryOperations operations) {
-    this.operations = operations;
-  }
-
-  /**
-   * Buld the user path -switches to the system path if the user is "".
-   * It also cross-converts the username to ascii via punycode
-   * @param username username or ""
-   * @return the path to the user
-   */
-  public static String homePathForUser(String username) {
-    Preconditions.checkArgument(username != null, "null user");
-
-    // catch recursion
-    if (username.startsWith(RegistryConstants.PATH_USERS)) {
-      return username;
-    }
-
-    if (username.isEmpty()) {
-      return RegistryConstants.PATH_SYSTEM_SERVICES;
-    }
-
-    // convert username to registry name
-    String convertedName = convertUsername(username);
-
-    return RegistryPathUtils.join(RegistryConstants.PATH_USERS,
-        encodeForRegistry(convertedName));
-  }
-
-  /**
-   * Get the current username, before any encoding has been applied.
-   * @return the current user from the kerberos identity, falling back
-   * to the user and/or env variables.
-   */
-  public static String currentUsernameUnencoded() {
-    String env_hadoop_username = System.getenv(
-        RegistryInternalConstants.HADOOP_USER_NAME);
-    return getCurrentUsernameUnencoded(env_hadoop_username);
-  }
-
-  /**
-   * Qualify a user.
-   * <ol>
-   *   <li> <code>"~"</code> maps to user home path home</li>
-   *   <li> <code>"~user"</code> maps to <code>/users/$user</code></li>
-   *   <li> <code>"/"</code> maps to <code>/services/</code></li>
-   * </ol>
-   * @param user the username
-   * @return the base path
-   */
-  public static String qualifyUser(String user) {
-    // qualify the user
-    String t = user.trim();
-    if (t.startsWith("/")) {
-      // already resolved
-      return t;
-    } else if (t.equals("~")) {
-      // self
-      return currentUsernameUnencoded();
-    } else if (t.startsWith("~")) {
-      // another user
-      // convert username to registry name
-      String convertedName = convertUsername(t.substring(1));
-
-      return RegistryPathUtils.join(RegistryConstants.PATH_USERS,
-          encodeForRegistry(convertedName));
-    } else {
-      return "/" + t;
-    }
-  }
-
-  /**
-   * Look up an external REST API
-   * @param user user which will be qualified as per {@link #qualifyUser(String)}
-   * @param serviceClass service class
-   * @param instance instance name
-   * @param api API
-   * @return the API, or an exception is raised.
-   * @throws IOException
-   */
-  public String lookupExternalRestAPI(String user,
-      String serviceClass,
-      String instance,
-      String api)
-      throws IOException {
-    String qualified = qualifyUser(user);
-    String path = servicePath(qualified, serviceClass, instance);
-    String restAPI = resolveExternalRestAPI(api, path);
-    if (restAPI == null) {
-      throw new PathNotFoundException(path + " API " + api);
-    }
-    return restAPI;
-  }
-
-  /**
-   * Resolve a service record then return an external REST API exported it.
-   *
-   * @param api API to resolve
-   * @param path path of the service record
-   * @return null if the record exists but the API is absent or it has no
-   * REST endpoints.
-   * @throws IOException resolution problems, as covered in
-   * {@link RegistryOperations#resolve(String)}
-   */
-  protected String resolveExternalRestAPI(String api, String path) throws
-      IOException {
-    ServiceRecord record = operations.resolve(path);
-    return lookupRestAPI(record, api, true);
-  }
-
-  /**
-   * Look up an external REST API endpoint
-   * @param record service record
-   * @param api URI of api
-   * @param external flag to indicate this is an external record
-   * @return the first endpoint of the implementation, or null if there
-   * is no entry for the API, implementation or it's the wrong type.
-   */
-  public static String lookupRestAPI(ServiceRecord record,
-      String api, boolean external) throws InvalidRecordException {
-    try {
-      String url = null;
-      Endpoint endpoint = getEndpoint(record, api, external);
-      List<String> addresses =
-          RegistryTypeUtils.retrieveAddressesUriType(endpoint);
-      if (addresses != null && !addresses.isEmpty()) {
-        url = addresses.get(0);
-      }
-      return url;
-    } catch (InvalidRecordException e) {
-      log.debug("looking for API {}", api, e);
-      return null;
-    }
-  }
-
-  /**
-   * Get an endpont by API
-   * @param record service record
-   * @param api API
-   * @param external flag to indicate this is an external record
-   * @return the endpoint or null
-   */
-  public static Endpoint getEndpoint(ServiceRecord record,
-      String api,
-      boolean external) {
-    return external ? record.getExternalEndpoint(api)
-                    : record.getInternalEndpoint(api);
-  }
-
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/Comparators.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/Comparators.java
deleted file mode 100644
index 9f0e5d40a57..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/Comparators.java
+++ /dev/null
@@ -1,62 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import java.io.Serializable;
-import java.util.Comparator;
-
-/**
- * Some general comparators
- */
-public class Comparators {
-
-  public static class LongComparator implements Comparator<Long>, Serializable {
-    @Override
-    public int compare(Long o1, Long o2) {
-      return o1.compareTo(o2);
-    }
-  }
-
-  public static class InvertedLongComparator
-      implements Comparator<Long>, Serializable {
-    @Override
-    public int compare(Long o1, Long o2) {
-      return o2.compareTo(o1);
-    }
-  }
-
-  /**
-   * Little template class to reverse any comparitor
-   * @param <CompareType> the type that is being compared
-   */
-  public static class ComparatorReverser<CompareType> implements Comparator<CompareType>,
-      Serializable {
-
-    final Comparator<CompareType> instance;
-
-    public ComparatorReverser(Comparator<CompareType> instance) {
-      this.instance = instance;
-    }
-
-    @Override
-    public int compare(CompareType first, CompareType second) {
-      return instance.compare(second, first);
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ConfigHelper.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ConfigHelper.java
deleted file mode 100644
index c5ff20a6090..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ConfigHelper.java
+++ /dev/null
@@ -1,157 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import org.apache.hadoop.util.Preconditions;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.service.exceptions.BadConfigException;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.io.StringWriter;
-import java.net.URL;
-import java.util.Map;
-
-/**
- * Methods to aid in config, both in the Configuration class and
- * with other parts of setting up Slider-initated processes.
- *
- * Some of the methods take an argument of a map iterable for their sources; this allows
- * the same method
- */
-public class ConfigHelper {
-  private static final Logger log = LoggerFactory.getLogger(ConfigHelper.class);
-
-  /**
-   * Set an entire map full of values
-   *
-   * @param config config to patch
-   * @param map map of data
-   * @param origin origin data
-   */
-  public static void addConfigMap(Configuration config,
-                                  Map<String, String> map,
-                                  String origin) throws BadConfigException {
-    addConfigMap(config, map.entrySet(), origin);
-  }
-
-  /**
-   * Set an entire map full of values
-   *
-   * @param config config to patch
-   * @param map map of data
-   * @param origin origin data
-   */
-  public static void addConfigMap(Configuration config,
-                                  Iterable<Map.Entry<String, String>> map,
-                                  String origin) throws BadConfigException {
-    for (Map.Entry<String, String> mapEntry : map) {
-      String key = mapEntry.getKey();
-      String value = mapEntry.getValue();
-      if (value == null) {
-        throw new BadConfigException("Null value for property " + key);
-      }
-      config.set(key, value, origin);
-    }
-  }
-
-  /**
-   * Convert to an XML string
-   * @param conf configuration
-   * @return conf
-   * @throws IOException
-   */
-  public static String toXml(Configuration conf) throws IOException {
-    StringWriter writer = new StringWriter();
-    conf.writeXml(writer);
-    return writer.toString();
-  }
-
-
-  /**
-   * Register a resource as a default resource.
-   * Do not attempt to use this unless you understand that the
-   * order in which default resources are loaded affects the outcome,
-   * and that subclasses of Configuration often register new default
-   * resources
-   * @param resource the resource name
-   * @return the URL or null
-   */
-  public static URL registerDefaultResource(String resource) {
-    URL resURL = getResourceUrl(resource);
-    if (resURL != null) {
-      Configuration.addDefaultResource(resource);
-    }
-    return resURL;
-  }
-
-  /**
-   * Load a configuration from a resource on this classpath.
-   * If the resource is not found, an empty configuration is returned
-   * @param resource the resource name
-   * @return the loaded configuration.
-   */
-  public static Configuration loadFromResource(String resource) {
-    Configuration conf = new Configuration(false);
-    URL resURL = getResourceUrl(resource);
-    if (resURL != null) {
-      log.debug("loaded resources from {}", resURL);
-      conf.addResource(resource);
-    } else{
-      log.debug("failed to find {} on the classpath", resource);
-    }
-    return conf;
-
-  }
-
-  /**
-   * Get the URL to a resource, null if not on the CP
-   * @param resource resource to look for
-   * @return the URL or null
-   */
-  public static URL getResourceUrl(String resource) {
-    return ConfigHelper.class.getClassLoader()
-                                  .getResource(resource);
-  }
-
-  /**
-   * This goes through the keyset of one configuration and retrieves each value
-   * from a value source -a different or the same configuration. This triggers
-   * the property resolution process of the value, resolving any variables against
-   * in-config or inherited configurations
-   * @param keysource source of keys
-   * @param valuesource the source of values
-   * @return a new configuration where <code>foreach key in keysource, get(key)==valuesource.get(key)</code>
-   */
-  public static Configuration resolveConfiguration(
-      Iterable<Map.Entry<String, String>> keysource,
-      Configuration valuesource) {
-    Configuration result = new Configuration(false);
-    for (Map.Entry<String, String> entry : keysource) {
-      String key = entry.getKey();
-      String value = valuesource.get(key);
-      Preconditions.checkState(value != null,
-          "no reference for \"%s\" in values", key);
-      result.set(key, value);
-    }
-    return result;
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ConfigUtils.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ConfigUtils.java
deleted file mode 100644
index 1bc7b0833c8..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ConfigUtils.java
+++ /dev/null
@@ -1,41 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.utils;
-
-import java.util.HashMap;
-import java.util.Map;
-import java.util.Map.Entry;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
-public class ConfigUtils {
-
-  public static String replaceProps(Map<String, String> config, String content) {
-    Map<String, String> tokens = new HashMap<>();
-    for (Entry<String, String> entry : config.entrySet()) {
-      tokens.put("${" + entry.getKey() + "}", entry.getValue());
-      tokens.put("{{" + entry.getKey() + "}}", entry.getValue());
-    }
-    String value = content;
-    for (Map.Entry<String,String> token : tokens.entrySet()) {
-      value = value.replaceAll(Pattern.quote(token.getKey()),
-          Matcher.quoteReplacement(token.getValue()));
-    }
-    return value;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/CoreFileSystem.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/CoreFileSystem.java
deleted file mode 100644
index 6978a02a098..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/CoreFileSystem.java
+++ /dev/null
@@ -1,556 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import org.apache.hadoop.util.Preconditions;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.CommonConfigurationKeys;
-import org.apache.hadoop.fs.FSDataInputStream;
-import org.apache.hadoop.fs.FSDataOutputStream;
-import org.apache.hadoop.fs.FileStatus;
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.fs.permission.FsPermission;
-import org.apache.hadoop.io.IOUtils;
-import org.apache.hadoop.util.VersionInfo;
-import org.apache.hadoop.yarn.api.records.LocalResource;
-import org.apache.hadoop.yarn.api.records.LocalResourceType;
-import org.apache.hadoop.yarn.api.records.LocalResourceVisibility;
-import org.apache.hadoop.yarn.api.records.URL;
-import org.apache.hadoop.yarn.service.conf.SliderExitCodes;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConstants;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConf;
-import org.apache.hadoop.yarn.service.exceptions.BadClusterStateException;
-import org.apache.hadoop.yarn.service.exceptions.ErrorStrings;
-import org.apache.hadoop.yarn.service.exceptions.SliderException;
-import org.apache.hadoop.yarn.util.Records;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.File;
-import java.io.FileNotFoundException;
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-
-public class CoreFileSystem {
-  private static final Logger
-    log = LoggerFactory.getLogger(CoreFileSystem.class);
-
-  private static final String UTF_8 = "UTF-8";
-
-  protected final FileSystem fileSystem;
-  protected final Configuration configuration;
-
-  public CoreFileSystem(FileSystem fileSystem, Configuration configuration) {
-    Preconditions.checkNotNull(fileSystem,
-                               "Cannot create a CoreFileSystem with a null FileSystem");
-    Preconditions.checkNotNull(configuration,
-                               "Cannot create a CoreFileSystem with a null Configuration");
-    this.fileSystem = fileSystem;
-    this.configuration = configuration;
-  }
-
-  public CoreFileSystem(Configuration configuration) throws IOException {
-    Preconditions.checkNotNull(configuration,
-                               "Cannot create a CoreFileSystem with a null Configuration");
-    this.fileSystem = FileSystem.get(configuration);
-    this.configuration = configuration;
-  }
-  
-  /**
-   * Get the temp path for this cluster
-   * @param clustername name of the cluster
-   * @return path for temp files (is not purged)
-   */
-  public Path getTempPathForCluster(String clustername) {
-    Path clusterDir = buildClusterDirPath(clustername);
-    return new Path(clusterDir, YarnServiceConstants.TMP_DIR_PREFIX);
-  }
-
-  /**
-   * Returns the underlying FileSystem for this object.
-   *
-   * @return filesystem
-   */
-  public FileSystem getFileSystem() {
-    return fileSystem;
-  }
-
-  @Override
-  public String toString() {
-    final StringBuilder sb =
-      new StringBuilder("CoreFileSystem{");
-    sb.append("fileSystem=").append(fileSystem.getUri())
-        .append('}');
-    return sb.toString();
-  }
-
-  /**
-   * Build up the path string for a cluster instance -no attempt to
-   * create the directory is made
-   *
-   * @param clustername name of the cluster
-   * @return the path for persistent data
-   */
-  public Path buildClusterDirPath(String clustername) {
-    Preconditions.checkNotNull(clustername);
-    Path path = getBaseApplicationPath();
-    return new Path(path, YarnServiceConstants.SERVICES_DIRECTORY + "/"
-        + clustername);
-  }
-
-  /**
-   * Build up the upgrade path string for a cluster. No attempt to
-   * create the directory is made.
-   *
-   * @param clusterName name of the cluster
-   * @param version version of the cluster
-   * @return the upgrade path to the cluster
-   */
-  public Path buildClusterUpgradeDirPath(String clusterName, String version) {
-    Preconditions.checkNotNull(clusterName);
-    Preconditions.checkNotNull(version);
-    return new Path(buildClusterDirPath(clusterName),
-        YarnServiceConstants.UPGRADE_DIR + "/" + version);
-  }
-
-  /**
-   * Delete the upgrade cluster directory.
-   * @param clusterName name of the cluster
-   * @param version     version of the cluster
-   * @throws IOException
-   */
-  public void deleteClusterUpgradeDir(String clusterName, String version)
-      throws IOException {
-    Preconditions.checkNotNull(clusterName);
-    Preconditions.checkNotNull(version);
-    Path upgradeCluster = buildClusterUpgradeDirPath(clusterName, version);
-    fileSystem.delete(upgradeCluster, true);
-  }
-  /**
-   * Build up the path string for keytab install location -no attempt to
-   * create the directory is made
-   *
-   * @return the path for keytab
-   */
-  public Path buildKeytabInstallationDirPath(String keytabFolder) {
-    Preconditions.checkNotNull(keytabFolder);
-    Path path = getBaseApplicationPath();
-    return new Path(path, YarnServiceConstants.KEYTAB_DIR + "/" + keytabFolder);
-  }
-
-  /**
-   * Build up the path string for keytab install location -no attempt to
-   * create the directory is made
-   *
-   * @return the path for keytab installation location
-   */
-  public Path buildKeytabPath(String keytabDir, String keytabName, String clusterName) {
-    Path homePath = getHomeDirectory();
-    Path baseKeytabDir;
-    if (keytabDir != null) {
-      baseKeytabDir = new Path(homePath, keytabDir);
-    } else {
-      baseKeytabDir = new Path(buildClusterDirPath(clusterName),
-                               YarnServiceConstants.KEYTAB_DIR);
-    }
-    return keytabName == null ? baseKeytabDir :
-        new Path(baseKeytabDir, keytabName);
-  }
-
-  /**
-   * Build up the path string for resource install location -no attempt to
-   * create the directory is made
-   *
-   * @return the path for resource
-   */
-  public Path buildResourcePath(String resourceFolder) {
-    Preconditions.checkNotNull(resourceFolder);
-    Path path = getBaseApplicationPath();
-    return new Path(path, YarnServiceConstants.RESOURCE_DIR + "/" + resourceFolder);
-  }
-
-  /**
-   * Build up the path string for resource install location -no attempt to
-   * create the directory is made
-   *
-   * @return the path for resource
-   */
-  public Path buildResourcePath(String dirName, String fileName) {
-    Preconditions.checkNotNull(dirName);
-    Preconditions.checkNotNull(fileName);
-    Path path = getBaseApplicationPath();
-    return new Path(path, YarnServiceConstants.RESOURCE_DIR + "/" + dirName + "/" + fileName);
-  }
-
-  /**
-   * Create a directory with the given permissions.
-   *
-   * @param dir          directory
-   * @param clusterPerms cluster permissions
-   * @throws IOException  IO problem
-   * @throws BadClusterStateException any cluster state problem
-   */
-  @SuppressWarnings("deprecation")
-  public void createWithPermissions(Path dir, FsPermission clusterPerms) throws
-          IOException,
-          BadClusterStateException {
-    if (fileSystem.isFile(dir)) {
-      // HADOOP-9361 shows some filesystems don't correctly fail here
-      throw new BadClusterStateException(
-              "Cannot create a directory over a file %s", dir);
-    }
-    log.debug("mkdir {} with perms {}", dir, clusterPerms);
-    //no mask whatoever
-    fileSystem.getConf().set(CommonConfigurationKeys.FS_PERMISSIONS_UMASK_KEY, "000");
-    fileSystem.mkdirs(dir, clusterPerms);
-    //and force set it anyway just to make sure
-    fileSystem.setPermission(dir, clusterPerms);
-  }
-
-  /**
-   * Verify that the cluster directory is not present
-   *
-   * @param clustername      name of the cluster
-   * @param clusterDirectory actual directory to look for
-   * @throws IOException trouble with FS
-   * @throws SliderException If the directory exists
-   */
-  public void verifyClusterDirectoryNonexistent(String clustername,
-                                                Path clusterDirectory)
-      throws IOException, SliderException {
-    if (fileSystem.exists(clusterDirectory)) {
-      throw new SliderException(SliderExitCodes.EXIT_INSTANCE_EXISTS,
-              ErrorStrings.PRINTF_E_INSTANCE_ALREADY_EXISTS, clustername,
-              clusterDirectory);
-    }
-  }
-  /**
-   * Verify that the given directory is not present
-   *
-   * @param clusterDirectory actual directory to look for
-   * @throws IOException    trouble with FS
-   * @throws SliderException If the directory exists
-   */
-  public void verifyDirectoryNonexistent(Path clusterDirectory) throws
-          IOException,
-      SliderException {
-    if (fileSystem.exists(clusterDirectory)) {
-      
-      log.error("Dir {} exists: {}",
-                clusterDirectory,
-                listFSDir(clusterDirectory));
-      throw new SliderException(SliderExitCodes.EXIT_INSTANCE_EXISTS,
-              ErrorStrings.PRINTF_E_INSTANCE_DIR_ALREADY_EXISTS,
-              clusterDirectory);
-    }
-  }
-
-  /**
-   * Verify that a user has write access to a directory.
-   * It does this by creating then deleting a temp file
-   *
-   * @param dirPath actual directory to look for
-   * @throws FileNotFoundException file not found
-   * @throws IOException  trouble with FS
-   * @throws BadClusterStateException if the directory is not writeable
-   */
-  public void verifyDirectoryWriteAccess(Path dirPath) throws IOException,
-      SliderException {
-    verifyPathExists(dirPath);
-    Path tempFile = new Path(dirPath, "tmp-file-for-checks");
-    try {
-      FSDataOutputStream out ;
-      out = fileSystem.create(tempFile, true);
-      IOUtils.closeStream(out);
-      fileSystem.delete(tempFile, false);
-    } catch (IOException e) {
-      log.warn("Failed to create file {}: {}", tempFile, e);
-      throw new BadClusterStateException(e,
-              "Unable to write to directory %s : %s", dirPath, e.toString());
-    }
-  }
-
-  /**
-   * Verify that a path exists
-   * @param path path to check
-   * @throws FileNotFoundException file not found
-   * @throws IOException  trouble with FS
-   */
-  public void verifyPathExists(Path path) throws IOException {
-    if (!fileSystem.exists(path)) {
-      throw new FileNotFoundException(path.toString());
-    }
-  }
-
-  /**
-   * Verify that a path exists
-   * @param path path to check
-   * @throws FileNotFoundException file not found or is not a file
-   * @throws IOException  trouble with FS
-   */
-  public void verifyFileExists(Path path) throws IOException {
-    FileStatus status = fileSystem.getFileStatus(path);
-
-    if (!status.isFile()) {
-      throw new FileNotFoundException("Not a file: " + path.toString());
-    }
-  }
-
-  /**
-   * Given a path, check if it exists and is a file
-   * 
-   * @param path
-   *          absolute path to the file to check
-   * @return true if and only if path exists and is a file, false for all other
-   *          reasons including if file check throws IOException
-   */
-  public boolean isFile(Path path) {
-    if (path == null) {
-      return false;
-    }
-    boolean isFile = false;
-    try {
-      FileStatus status = fileSystem.getFileStatus(path);
-      if (status.isFile()) {
-        isFile = true;
-      }
-    } catch (IOException e) {
-      // ignore, isFile is already set to false
-    }
-    return isFile;
-  }
-
-  /**
-   * Get the base path
-   *
-   * @return the base path optionally configured by 
-   * {@link YarnServiceConf#YARN_SERVICE_BASE_PATH}
-   */
-  public Path getBaseApplicationPath() {
-    String configuredBasePath = configuration
-        .get(YarnServiceConf.YARN_SERVICE_BASE_PATH,
-            getHomeDirectory() + "/" + YarnServiceConstants.SERVICE_BASE_DIRECTORY);
-    return new Path(configuredBasePath);
-  }
-
-  /**
-   * Get service dependency absolute filepath in HDFS used for application
-   * submission.
-   * 
-   * @return the absolute path to service dependency tarball in HDFS
-   */
-  public Path getDependencyTarGzip() {
-    Path dependencyLibTarGzip = null;
-    String configuredDependencyTarballPath = configuration
-        .get(YarnServiceConf.DEPENDENCY_TARBALL_PATH);
-    if (configuredDependencyTarballPath != null) {
-      dependencyLibTarGzip = new Path(configuredDependencyTarballPath);
-    }
-    if (dependencyLibTarGzip == null) {
-      dependencyLibTarGzip = new Path(String.format(YarnServiceConstants
-          .DEPENDENCY_DIR, VersionInfo.getVersion()),
-          YarnServiceConstants.DEPENDENCY_TAR_GZ_FILE_NAME
-              + YarnServiceConstants.DEPENDENCY_TAR_GZ_FILE_EXT);
-    }
-    return dependencyLibTarGzip;
-  }
-
-  public Path getHomeDirectory() {
-    return fileSystem.getHomeDirectory();
-  }
-
-  /**
-   * Create an AM resource from the
-   *
-   * @param destPath     dest path in filesystem
-   * @param resourceType resource type
-   * @return the local resource for AM
-   */
-  public LocalResource createAmResource(Path destPath,
-      LocalResourceType resourceType,
-      LocalResourceVisibility visibility) throws IOException {
-
-    FileStatus destStatus = fileSystem.getFileStatus(destPath);
-    LocalResource amResource = Records.newRecord(LocalResource.class);
-    amResource.setType(resourceType);
-    // Set visibility of the resource
-    // Setting to most private option
-    if (visibility == null) {
-      visibility = LocalResourceVisibility.APPLICATION;
-    }
-    amResource.setVisibility(visibility);
-    // Set the resource to be copied over
-    amResource.setResource(
-        URL.fromPath(fileSystem.resolvePath(destStatus.getPath())));
-    // Set timestamp and length of file so that the framework
-    // can do basic sanity checks for the local resource
-    // after it has been copied over to ensure it is the same
-    // resource the client intended to use with the service
-    amResource.setTimestamp(destStatus.getModificationTime());
-    amResource.setSize(destStatus.getLen());
-    return amResource;
-  }
-
-  /**
-   * Register all files under a fs path as a directory to push out
-   *
-   * @param srcDir          src dir
-   * @param destRelativeDir dest dir (no trailing /)
-   * @return the map of entries
-   */
-  public Map<String, LocalResource> submitDirectory(Path srcDir, String destRelativeDir) throws IOException {
-    //now register each of the files in the directory to be
-    //copied to the destination
-    FileStatus[] fileset = fileSystem.listStatus(srcDir);
-    Map<String, LocalResource> localResources =
-            new HashMap<String, LocalResource>(fileset.length);
-    for (FileStatus entry : fileset) {
-
-      LocalResource resource = createAmResource(entry.getPath(),
-              LocalResourceType.FILE, LocalResourceVisibility.APPLICATION);
-      String relativePath = destRelativeDir + "/" + entry.getPath().getName();
-      localResources.put(relativePath, resource);
-    }
-    return localResources;
-  }
-
-  /**
-   * Submit a JAR containing a specific class, returning
-   * the resource to be mapped in
-   *
-   * @param clazz   class to look for
-   * @param subdir  subdirectory (expected to end in a "/")
-   * @param jarName <i>At the destination</i>
-   * @return the local resource ref
-   * @throws IOException trouble copying to HDFS
-   */
-  public LocalResource submitJarWithClass(Class clazz, Path tempPath, String subdir, String jarName)
-          throws IOException, SliderException {
-    File localFile = ServiceUtils.findContainingJarOrFail(clazz);
-    return submitFile(localFile, tempPath, subdir, jarName);
-  }
-
-  /**
-   * Submit a local file to the filesystem references by the instance's cluster
-   * filesystem
-   *
-   * @param localFile    filename
-   * @param subdir       subdirectory (expected to end in a "/")
-   * @param destFileName destination filename
-   * @return the local resource ref
-   * @throws IOException trouble copying to HDFS
-   */
-  public LocalResource submitFile(File localFile, Path tempPath, String subdir, String destFileName)
-      throws IOException {
-    Path src = new Path(localFile.toString());
-    Path subdirPath = new Path(tempPath, subdir);
-    fileSystem.mkdirs(subdirPath);
-    Path destPath = new Path(subdirPath, destFileName);
-    log.debug("Copying {} (size={} bytes) to {}", localFile, localFile.length(), destPath);
-
-    fileSystem.copyFromLocalFile(false, true, src, destPath);
-
-    // Set the type of resource - file or archive
-    // archives are untarred at destination
-    // we don't need the jar file to be untarred for now
-    return createAmResource(destPath, LocalResourceType.FILE,
-        LocalResourceVisibility.APPLICATION);
-  }
-
-  /**
-   * Submit the AM tar.gz resource referenced by the instance's cluster
-   * filesystem. Also, update the providerResources object with the new
-   * resource.
-   * 
-   * @param providerResources
-   *          the provider resource map to be updated
-   * @throws IOException
-   *           trouble copying to HDFS
-   */
-  public void submitTarGzipAndUpdate(
-      Map<String, LocalResource> providerResources) throws IOException,
-      BadClusterStateException {
-    Path dependencyLibTarGzip = getDependencyTarGzip();
-    LocalResource lc = createAmResource(dependencyLibTarGzip,
-        LocalResourceType.ARCHIVE, LocalResourceVisibility.APPLICATION);
-    providerResources.put(YarnServiceConstants.DEPENDENCY_LOCALIZED_DIR_LINK, lc);
-  }
-
-  public void copyLocalFileToHdfs(File localPath,
-      Path destPath, FsPermission fp)
-      throws IOException {
-    if (localPath == null || destPath == null) {
-      throw new IOException("Either localPath or destPath is null");
-    }
-    fileSystem.getConf().set(CommonConfigurationKeys.FS_PERMISSIONS_UMASK_KEY,
-        "000");
-    fileSystem.mkdirs(destPath.getParent(), fp);
-    log.info("Copying file {} to {}", localPath.toURI(), destPath);
-    
-    fileSystem.copyFromLocalFile(false, true, new Path(localPath.getPath()),
-        destPath);
-    // set file permissions of the destPath
-    fileSystem.setPermission(destPath, fp);
-  }
-
-  public void copyHdfsFileToLocal(Path hdfsPath, File destFile)
-      throws IOException {
-    if (hdfsPath == null || destFile == null) {
-      throw new IOException("Either hdfsPath or destPath is null");
-    }
-    log.info("Copying file {} to {}", hdfsPath.toUri(), destFile.toURI());
-
-    Path destPath = new Path(destFile.getPath());
-    fileSystem.copyToLocalFile(hdfsPath, destPath);
-  }
-
-  /**
-   * list entries in a filesystem directory
-   *
-   * @param path directory
-   * @return a listing, one to a line
-   * @throws IOException
-   */
-  public String listFSDir(Path path) throws IOException {
-    FileStatus[] stats = fileSystem.listStatus(path);
-    StringBuilder builder = new StringBuilder();
-    for (FileStatus stat : stats) {
-      builder.append(stat.getPath().toString())
-              .append("\t")
-              .append(stat.getLen())
-              .append("\n");
-    }
-    return builder.toString();
-  }
-
-  public String cat(Path path) throws IOException {
-    FileStatus status = fileSystem.getFileStatus(path);
-    byte[] b = new byte[(int) status.getLen()];
-    FSDataInputStream in = null;
-    try {
-      in = fileSystem.open(path);
-      int count = in.read(b);
-      return new String(b, 0, count, UTF_8);
-    } finally {
-      IOUtils.closeStream(in);
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/Duration.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/Duration.java
deleted file mode 100644
index 6fadfd3af22..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/Duration.java
+++ /dev/null
@@ -1,109 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import java.io.Closeable;
-
-/**
- * A duration in milliseconds. This class can be used
- * to count time, and to be polled to see if a time limit has
- * passed.
- */
-public class Duration implements Closeable {
-  public long start, finish;
-  public final long limit;
-
-  /**
-   * Create a duration instance with a limit of 0
-   */
-  public Duration() {
-    this(0);
-  }
-
-  /**
-   * Create a duration with a limit specified in millis
-   * @param limit duration in milliseconds
-   */
-  public Duration(long limit) {
-    this.limit = limit;
-  }
-
-  /**
-   * Start
-   * @return self
-   */
-  public Duration start() {
-    start = now();
-    return this;
-  }
-
-  /**
-   * The close operation relays to {@link #finish()}.
-   * Implementing it allows Duration instances to be automatically
-   * finish()'d in Java7 try blocks for when used in measuring durations.
-   */
-  @Override
-  public final void close() {
-    finish();
-  }
-
-  public void finish() {
-    finish = now();
-  }
-
-  protected long now() {
-    return System.nanoTime()/1000000;
-  }
-
-  public long getInterval() {
-    return finish - start;
-  }
-
-  /**
-   * return true if the limit has been exceeded
-   * @return true if a limit was set and the current time
-   * exceeds it.
-   */
-  public boolean getLimitExceeded() {
-    return limit >= 0 && ((now() - start) > limit);
-  }
-
-  @Override
-  public String toString() {
-    StringBuilder builder = new StringBuilder();
-    builder.append("Duration");
-     if (finish >= start) {
-       builder.append(" finished at ").append(getInterval()).append(" millis;");
-     } else {
-       if (start > 0) {
-         builder.append(" started but not yet finished;");
-       } else {
-         builder.append(" unstarted;");
-       }
-     }
-    if (limit > 0) {
-      builder.append(" limit: ").append(limit).append(" millis");
-      if (getLimitExceeded()) {
-        builder.append(" -  exceeded");
-      }
-    }
-    return  builder.toString();
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/FilterUtils.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/FilterUtils.java
deleted file mode 100644
index b9b2ceec880..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/FilterUtils.java
+++ /dev/null
@@ -1,94 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol;
-import org.apache.hadoop.yarn.service.ServiceContext;
-import org.apache.hadoop.yarn.service.api.records.ComponentContainers;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
-public class FilterUtils {
-
-  /**
-   * Returns containers filtered by requested fields.
-   *
-   * @param context   service context
-   * @param filterReq filter request
-   */
-  public static List<ComponentContainers> filterInstances(
-      ServiceContext context,
-      ClientAMProtocol.GetCompInstancesRequestProto filterReq) {
-    Map<String, ComponentContainers> containersByComp = new HashMap<>();
-
-    Map<ContainerId, ComponentInstance> instances =
-        context.scheduler.getLiveInstances();
-
-    instances.forEach(((containerId, instance) -> {
-      boolean include = true;
-      if (filterReq.getComponentNamesList() != null &&
-          !filterReq.getComponentNamesList().isEmpty()) {
-        // filter by component name
-        if (!filterReq.getComponentNamesList().contains(
-            instance.getComponent().getName())) {
-          include = false;
-        }
-      }
-
-      if (filterReq.getVersion() != null && !filterReq.getVersion().isEmpty()) {
-        // filter by version
-        String instanceServiceVersion = instance.getServiceVersion();
-        if (instanceServiceVersion == null || !instanceServiceVersion.equals(
-            filterReq.getVersion())) {
-          include = false;
-        }
-      }
-
-      if (filterReq.getContainerStatesList() != null &&
-          !filterReq.getContainerStatesList().isEmpty()) {
-        // filter by state
-        if (!filterReq.getContainerStatesList().contains(
-            instance.getContainerState().toString())) {
-          include = false;
-        }
-      }
-
-      if (include) {
-        ComponentContainers compContainers =
-            containersByComp.computeIfAbsent(instance.getCompName(),
-                k -> {
-                  ComponentContainers result = new ComponentContainers();
-                  result.setContainers(new ArrayList<>());
-                  result.setComponentName(instance.getCompName());
-                  return result;
-                });
-
-        compContainers.addContainer(instance.getContainerSpec());
-      }
-    }));
-    List<ComponentContainers> result = new ArrayList<>();
-    result.addAll(containersByComp.values());
-    return result;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/HttpUtil.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/HttpUtil.java
deleted file mode 100644
index 11190ebb535..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/HttpUtil.java
+++ /dev/null
@@ -1,119 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import java.io.IOException;
-import java.net.URI;
-import java.net.URISyntaxException;
-import java.nio.charset.StandardCharsets;
-import java.security.PrivilegedExceptionAction;
-
-import javax.ws.rs.core.HttpHeaders;
-import javax.ws.rs.core.MediaType;
-
-import org.apache.commons.codec.binary.Base64;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.security.authentication.client.AuthenticationException;
-import org.ietf.jgss.GSSContext;
-import org.ietf.jgss.GSSException;
-import org.ietf.jgss.GSSManager;
-import org.ietf.jgss.GSSName;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import com.sun.jersey.api.client.Client;
-import com.sun.jersey.api.client.WebResource.Builder;
-
-/**
- * Http connection utilities.
- *
- */
-public class HttpUtil {
-  private static final Logger LOG =
-      LoggerFactory.getLogger(HttpUtil.class);
-  private static final Base64 BASE_64_CODEC = new Base64(0);
-
-  protected HttpUtil() {
-    // prevents calls from subclass
-    throw new UnsupportedOperationException();
-  }
-
-  /**
-   * Generate SPNEGO challenge request token.
-   *
-   * @param server - hostname to contact
-   * @throws IOException
-   * @throws InterruptedException
-   */
-  public static String generateToken(String server) throws
-      IOException, InterruptedException {
-    UserGroupInformation currentUser = UserGroupInformation.getCurrentUser();
-    LOG.debug("The user credential is {}", currentUser);
-    String challenge = currentUser
-        .doAs(new PrivilegedExceptionAction<String>() {
-          @Override
-          public String run() throws Exception {
-            try {
-              GSSManager manager = GSSManager.getInstance();
-              // GSS name for server
-              GSSName serverName = manager.createName("HTTP@" + server,
-                  GSSName.NT_HOSTBASED_SERVICE);
-              // Create a GSSContext for authentication with the service.
-              // We're passing client credentials as null since we want them to
-              // be read from the Subject.
-              // We're passing Oid as null to use the default.
-              GSSContext gssContext = manager.createContext(
-                  serverName.canonicalize(null), null, null,
-                  GSSContext.DEFAULT_LIFETIME);
-              gssContext.requestMutualAuth(true);
-              gssContext.requestCredDeleg(true);
-              // Establish context
-              byte[] inToken = new byte[0];
-              byte[] outToken = gssContext.initSecContext(inToken, 0,
-                  inToken.length);
-              gssContext.dispose();
-              // Base64 encoded and stringified token for server
-              LOG.debug("Got valid challenge for host {}", serverName);
-              return new String(BASE_64_CODEC.encode(outToken),
-                  StandardCharsets.US_ASCII);
-            } catch (GSSException e) {
-              LOG.error("Error: ", e);
-              throw new AuthenticationException(e);
-            }
-          }
-        });
-    return challenge;
-  }
-
-  public static Builder connect(String url) throws URISyntaxException,
-      IOException, InterruptedException {
-    boolean useKerberos = UserGroupInformation.isSecurityEnabled();
-    URI resource = new URI(url);
-    Client client = Client.create();
-    Builder builder = client
-        .resource(url).type(MediaType.APPLICATION_JSON);
-    if (useKerberos) {
-      String challenge = generateToken(resource.getHost());
-      builder.header(HttpHeaders.AUTHORIZATION, "Negotiate " +
-          challenge);
-      LOG.debug("Authorization: Negotiate {}", challenge);
-    }
-    return builder;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/JsonSerDeser.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/JsonSerDeser.java
deleted file mode 100644
index 254d6c5d379..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/JsonSerDeser.java
+++ /dev/null
@@ -1,238 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import com.fasterxml.jackson.core.JsonParseException;
-import com.fasterxml.jackson.core.JsonProcessingException;
-import com.fasterxml.jackson.databind.DeserializationFeature;
-import com.fasterxml.jackson.databind.JsonMappingException;
-import com.fasterxml.jackson.databind.ObjectMapper;
-import com.fasterxml.jackson.databind.PropertyNamingStrategy;
-import com.fasterxml.jackson.databind.SerializationFeature;
-import org.apache.hadoop.fs.FSDataInputStream;
-import org.apache.hadoop.fs.FSDataOutputStream;
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.io.IOUtils;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.File;
-import java.io.FileNotFoundException;
-import java.io.FileOutputStream;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.OutputStream;
-import java.nio.charset.StandardCharsets;
-
-/**
- * Support for marshalling objects to and from JSON.
- * This class is NOT thread safe; it constructs an object mapper
- * as an instance field.
- * @param <T>
- */
-public class JsonSerDeser<T> {
-
-  private static final Logger log = LoggerFactory.getLogger(JsonSerDeser.class);
-
-  private final Class<T> classType;
-  private final ObjectMapper mapper;
-
-  /**
-   * Create an instance bound to a specific type
-   * @param classType class type
-   */
-  @SuppressWarnings("deprecation")
-  public JsonSerDeser(Class<T> classType) {
-    this.classType = classType;
-    this.mapper = new ObjectMapper();
-    mapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);
-    mapper.configure(SerializationFeature.WRITE_NULL_MAP_VALUES, false);
-  }
-
-  public JsonSerDeser(Class<T> classType, PropertyNamingStrategy namingStrategy) {
-    this(classType);
-    mapper.setPropertyNamingStrategy(namingStrategy);
-  }
-
-  /**
-   * Convert from JSON
-   * @param json input
-   * @return the parsed JSON
-   * @throws IOException IO
-   * @throws JsonMappingException failure to map from the JSON to this class
-   */
-  public T fromJson(String json)
-    throws IOException, JsonParseException, JsonMappingException {
-    try {
-      return mapper.readValue(json, classType);
-    } catch (IOException e) {
-      log.error("Exception while parsing json : " + e + "\n" + json, e);
-      throw e;
-    }
-  }
-
-  /**
-   * Convert from a JSON file
-   * @param jsonFile input file
-   * @return the parsed JSON
-   * @throws IOException IO problems
-   * @throws JsonMappingException failure to map from the JSON to this class
-   */
-  public T fromFile(File jsonFile)
-    throws IOException, JsonParseException, JsonMappingException {
-    File absoluteFile = jsonFile.getAbsoluteFile();
-    try {
-      return mapper.readValue(absoluteFile, classType);
-    } catch (IOException e) {
-      log.error("Exception while parsing json file {}", absoluteFile, e);
-      throw e;
-    }
-  }
-
-  /**
-   * Convert from a JSON file
-   * @param resource input file
-   * @return the parsed JSON
-   * @throws IOException IO problems
-   * @throws JsonMappingException failure to map from the JSON to this class
-   */
- public T fromResource(String resource)
-    throws IOException, JsonParseException, JsonMappingException {
-    try(InputStream resStream = this.getClass().getResourceAsStream(resource)) {
-      if (resStream == null) {
-        throw new FileNotFoundException(resource);
-      }
-      return (T) (mapper.readValue(resStream, classType));
-    } catch (IOException e) {
-      log.error("Exception while parsing json resource {}", resource, e);
-      throw e;
-    }
-  }
-
-  /**
-   * Convert from an input stream, closing the stream afterwards.
-   * @param stream
-   * @return the parsed JSON
-   * @throws IOException IO problems
-   */
-  public T fromStream(InputStream stream) throws IOException {
-    try {
-      return (T) (mapper.readValue(stream, classType));
-    } catch (IOException e) {
-      log.error("Exception while parsing json input stream", e);
-      throw e;
-    } finally {
-      IOUtils.closeStream(stream);
-    }
-  }
-
-  /**
-   * clone by converting to JSON and back again.
-   * This is much less efficient than any Java clone process.
-   * @param instance instance to duplicate
-   * @return a new instance
-   * @throws IOException problems.
-   */
-  public T fromInstance(T instance) throws IOException {
-    return fromJson(toJson(instance));
-  }
-
-  /**
-   * Deserialize from a byte array
-   * @param b
-   * @return the deserialized value
-   * @throws IOException parse problems
-   */
-  public T fromBytes(byte[] b) throws IOException {
-    String json = new String(b, 0, b.length, StandardCharsets.UTF_8);
-    return fromJson(json);
-  }
-  
-  /**
-   * Load from a Hadoop filesystem
-   * @param fs filesystem
-   * @param path path
-   * @return a loaded CD
-   * @throws IOException IO problems
-   * @throws JsonParseException parse problems
-   * @throws JsonMappingException O/J mapping problems
-   */
-  public T load(FileSystem fs, Path path) throws IOException {
-    FSDataInputStream dataInputStream = fs.open(path);
-    return fromStream(dataInputStream);
-  }
-
-
-  /**
-   * Save to a hadoop filesystem
-   * @param fs filesystem
-   * @param path path
-   * @param instance instance to save
-   * @param overwrite should any existing file be overwritten
-   * @throws IOException IO exception
-   */
-  public void save(FileSystem fs, Path path, T instance,
-                   boolean overwrite) throws
-                                      IOException {
-    FSDataOutputStream dataOutputStream = fs.create(path, overwrite);
-    writeJsonAsBytes(instance, dataOutputStream);
-  }
-
-  /**
-   * Save an instance to a file
-   * @param instance instance to save
-   * @param file file
-   * @throws IOException
-   */
-  public void save(T instance, File file) throws
-      IOException {
-    writeJsonAsBytes(instance, new FileOutputStream(file.getAbsoluteFile()));
-  }
-
-  /**
-   * Write the json as bytes -then close the file
-   * @param dataOutputStream an outout stream that will always be closed
-   * @throws IOException on any failure
-   */
-  private void writeJsonAsBytes(T instance,
-      OutputStream dataOutputStream) throws IOException {
-    try {
-      String json = toJson(instance);
-      byte[] b = json.getBytes(StandardCharsets.UTF_8);
-      dataOutputStream.write(b);
-      dataOutputStream.flush();
-      dataOutputStream.close();
-    } finally {
-      IOUtils.closeStream(dataOutputStream);
-    }
-  }
-
-  /**
-   * Convert an object to a JSON string
-   * @param instance instance to convert
-   * @return a JSON string description
-   * @throws JsonProcessingException parse problems
-   */
-  public String toJson(T instance) throws JsonProcessingException {
-    mapper.configure(SerializationFeature.INDENT_OUTPUT, true);
-    return mapper.writeValueAsString(instance);
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/PatternValidator.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/PatternValidator.java
deleted file mode 100644
index 108ca22defe..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/PatternValidator.java
+++ /dev/null
@@ -1,58 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import java.util.regex.Pattern;
-
-/**
- * Utility class to validate strings against a predefined pattern.
- */
-public class PatternValidator {
-
-  public static final String E_INVALID_NAME =
-      "Invalid name %s does not match the pattern %s ";
-  private final Pattern valid;
-  private final String pattern;
-
-  public PatternValidator(String pattern) {
-    this.pattern = pattern;
-    valid = Pattern.compile(pattern);
-  }
-
-  /**
-   * Validate the name -restricting it to the set defined in 
-   * @param name name to validate
-   * @throws IllegalArgumentException if not a valid name
-   */
-  public void validate(String name) {
-    if (!matches(name)) {
-      throw new IllegalArgumentException(
-          String.format(E_INVALID_NAME, name, pattern));
-    }
-  }
-
-  /**
-   * Query to see if the pattern matches
-   * @param name name to validate
-   * @return true if the string matches the pattern
-   */
-  public boolean matches(String name) {
-    return valid.matcher(name).matches();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/PortScanner.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/PortScanner.java
deleted file mode 100644
index 1d64ed65e3f..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/PortScanner.java
+++ /dev/null
@@ -1,113 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the "License"); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.utils;
-
-import org.apache.hadoop.yarn.service.conf.SliderExitCodes;
-import org.apache.hadoop.yarn.service.exceptions.BadConfigException;
-import org.apache.hadoop.yarn.service.exceptions.SliderException;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Set;
-import java.util.TreeSet;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
-/**
- * a scanner which can take an input string for a range or scan the lot.
- */
-public class PortScanner {
-  private static Pattern NUMBER_RANGE = Pattern.compile("^(\\d+)\\s*-\\s*(\\d+)$");
-  private static Pattern SINGLE_NUMBER = Pattern.compile("^\\d+$");
-
-  private List<Integer> remainingPortsToCheck;
-
-  public PortScanner() {
-  }
-
-  public void setPortRange(String input) throws BadConfigException {
-    // first split based on commas
-    Set<Integer> inputPorts= new TreeSet<Integer>();
-    String[] ranges = input.split(",");
-    for ( String range : ranges ) {
-      if (range.trim().isEmpty()) {
-        continue;
-      }
-      Matcher m = SINGLE_NUMBER.matcher(range.trim());
-      if (m.find()) {
-        inputPorts.add(Integer.parseInt(m.group()));
-        continue;
-      }
-      m = NUMBER_RANGE.matcher(range.trim());
-      if (m.find()) {
-        String[] boundaryValues = m.group(0).split("-");
-        int start = Integer.parseInt(boundaryValues[0].trim());
-        int end = Integer.parseInt(boundaryValues[1].trim());
-        if (end < start) {
-          throw new BadConfigException("End of port range is before start: "
-              + range + " in input: " + input);
-        }
-        for (int i = start; i < end + 1; i++) {
-          inputPorts.add(i);
-        }
-        continue;
-      }
-      throw new BadConfigException("Bad port range: " + range + " in input: "
-          + input);
-    }
-    if (inputPorts.size() == 0) {
-      throw new BadConfigException("No ports found in range: " + input);
-    }
-    this.remainingPortsToCheck = new ArrayList<Integer>(inputPorts);
-  }
-
-  public List<Integer> getRemainingPortsToCheck() {
-    return remainingPortsToCheck;
-  }
-
-  public int getAvailablePort() throws SliderException, IOException {
-    if (remainingPortsToCheck != null) {
-      return getAvailablePortViaPortArray();
-    } else {
-      return ServiceUtils.getOpenPort();
-    }
-  }
-
-  private int getAvailablePortViaPortArray() throws SliderException {
-    boolean found = false;
-    int availablePort = -1;
-    Iterator<Integer> portsToCheck = this.remainingPortsToCheck.iterator();
-    while (portsToCheck.hasNext() && !found) {
-      int portToCheck = portsToCheck.next();
-      found = ServiceUtils.isPortAvailable(portToCheck);
-      if (found) {
-        availablePort = portToCheck;
-        portsToCheck.remove();
-      }
-    }
-
-    if (availablePort < 0) {
-      throw new SliderException(SliderExitCodes.EXIT_BAD_CONFIGURATION,
-        "No available ports found in configured range {}",
-        remainingPortsToCheck);
-    }
-
-    return availablePort;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/PublishedConfiguration.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/PublishedConfiguration.java
deleted file mode 100644
index e7ec2d6f5e7..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/PublishedConfiguration.java
+++ /dev/null
@@ -1,187 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
-import com.fasterxml.jackson.annotation.JsonInclude;
-import com.fasterxml.jackson.databind.ObjectMapper;
-import com.fasterxml.jackson.databind.SerializationFeature;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.service.exceptions.BadConfigException;
-
-import java.io.IOException;
-import java.util.Date;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.Properties;
-
-/**
- * JSON-serializable description of a published key-val configuration.
- * 
- * The values themselves are not serialized in the external view; they have
- * to be served up by the far end
- */
-@JsonIgnoreProperties(ignoreUnknown = true)
-@JsonInclude(value = JsonInclude.Include.NON_NULL)
-public class PublishedConfiguration {
-
-  public String description;
-  public long updated;
-  
-  public String updatedTime;
-
-  public Map<String, String> entries = new HashMap<>();
-
-  public PublishedConfiguration() {
-  }
-
-  /**
-   * build an empty published configuration 
-   * @param description configuration description
-   */
-  public PublishedConfiguration(String description) {
-    this.description = description;
-  }
-
-  /**
-   * Build a configuration from the entries
-   * @param description configuration description
-   * @param entries entries to put
-   */
-  public PublishedConfiguration(String description,
-      Iterable<Map.Entry<String, String>> entries) {
-    this.description = description;
-    putValues(entries);
-  }
-
-  /**
-   * Build a published configuration, using the keys from keysource,
-   * but resolving the values from the value source, via Configuration.get()
-   * @param description configuration description
-   * @param keysource source of keys
-   * @param valuesource source of values
-   */
-  public PublishedConfiguration(String description,
-      Iterable<Map.Entry<String, String>> keysource,
-      Configuration valuesource) {
-    this.description = description;
-    putValues(ConfigHelper.resolveConfiguration(keysource, valuesource));
-  }
-
-  
-  /**
-   * Is the configuration empty. This means either that it has not
-   * been given any values, or it is stripped down copy set down over the
-   * wire.
-   * @return true if it is empty
-   */
-  public boolean isEmpty() {
-    return entries.isEmpty();
-  }
-
-
-  public void setUpdated(long updated) {
-    this.updated = updated;
-    this.updatedTime = new Date(updated).toString();
-  }
-
-  public long getUpdated() {
-    return updated;
-  }
-
-  /**
-   * Set the values from an iterable (this includes a Hadoop Configuration
-   * and Java properties object).
-   * Any existing value set is discarded
-   * @param entries entries to put
-   */
-  public void putValues(Iterable<Map.Entry<String, String>> entries) {
-    this.entries = new HashMap<String, String>();
-    for (Map.Entry<String, String> entry : entries) {
-      this.entries.put(entry.getKey(), entry.getValue());
-    }
-    
-  }
-
-  /**
-   * Convert to Hadoop XML
-   * @return the configuration as a Hadoop Configuratin
-   */
-  public Configuration asConfiguration() {
-    Configuration conf = new Configuration(false);
-    try {
-      ConfigHelper.addConfigMap(conf, entries, "");
-    } catch (BadConfigException e) {
-      // triggered on a null value; switch to a runtime (and discard the stack)
-      throw new RuntimeException(e.toString());
-    }
-    return conf;
-  }
-  
-  public String asConfigurationXML() throws IOException {
-    return ConfigHelper.toXml(asConfiguration());
-  }
-
-  /**
-   * Convert values to properties
-   * @return a property file
-   */
-  public Properties asProperties() {
-    Properties props = new Properties();
-    props.putAll(entries);
-    return props;
-  }
-
-  /**
-   * Return the values as json string
-   * @return the JSON representation
-   * @throws IOException marshalling failure
-   */
-  public String asJson() throws IOException {
-    ObjectMapper mapper = new ObjectMapper();
-    mapper.configure(SerializationFeature.INDENT_OUTPUT, true);
-    String json = mapper.writeValueAsString(entries);
-    return json;
-  }
-
-
-  /**
-   * This makes a copy without the nested content -so is suitable
-   * for returning as part of the list of a parent's values
-   * @return the copy
-   */
-  public PublishedConfiguration shallowCopy() {
-    PublishedConfiguration that = new PublishedConfiguration();
-    that.description = this.description;
-    that.updated = this.updated;
-    that.updatedTime = this.updatedTime;
-    return that;
-  }
-
-  @Override
-  public String toString() {
-    final StringBuilder sb =
-        new StringBuilder("PublishedConfiguration{");
-    sb.append("description='").append(description).append('\'')
-        .append(" entries = ").append(entries.size())
-        .append('}');
-    return sb.toString();
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/PublishedConfigurationOutputter.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/PublishedConfigurationOutputter.java
deleted file mode 100644
index 3b39c10bf89..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/PublishedConfigurationOutputter.java
+++ /dev/null
@@ -1,210 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import org.apache.hadoop.util.Preconditions;
-import org.apache.commons.io.FileUtils;
-import org.apache.commons.io.IOUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.service.api.records.ConfigFormat;
-import org.yaml.snakeyaml.DumperOptions;
-import org.yaml.snakeyaml.DumperOptions.FlowStyle;
-import org.yaml.snakeyaml.Yaml;
-
-import java.io.File;
-import java.io.IOException;
-import java.io.OutputStream;
-import java.io.StringWriter;
-import java.nio.charset.StandardCharsets;
-import java.util.Properties;
-
-/**
- * Output a published configuration
- */
-public abstract class PublishedConfigurationOutputter {
-
-  private static final String COMMENTS = "Generated by Apache Slider";
-
-  protected final PublishedConfiguration owner;
-
-  protected PublishedConfigurationOutputter(PublishedConfiguration owner) {
-    this.owner = owner;
-  }
-
-  /**
-   * Save the config to a destination file, in the format of this outputter
-   * @param dest destination file
-   * @throws IOException
-   */
-/* JDK7
-  public void save(File dest) throws IOException {
-    try(FileOutputStream out = new FileOutputStream(dest)) {
-      save(out);
-      out.close();
-    }
-  }
-*/
-  public void save(File dest) throws IOException {
-    FileUtils.writeStringToFile(dest, asString(), StandardCharsets.UTF_8);
-  }
-
-  /**
-   * Save the content. The default saves the asString() value
-   * to the output stream
-   * @param out output stream
-   * @throws IOException
-   */
-  public void save(OutputStream out) throws IOException {
-    IOUtils.write(asString(), out, StandardCharsets.UTF_8);
-  }
-  /**
-   * Convert to a string
-   * @return the string form
-   * @throws IOException
-   */
-  public abstract String asString() throws IOException;
-
-  /**
-   * Create an outputter for the chosen format
-   * @param format format enumeration
-   * @param owner owning config
-   * @return the outputter
-   */
-
-  public static PublishedConfigurationOutputter createOutputter(ConfigFormat format,
-      PublishedConfiguration owner) {
-    Preconditions.checkNotNull(owner);
-    switch (format) {
-      case XML:
-      case HADOOP_XML:
-        return new XmlOutputter(owner);
-      case PROPERTIES:
-        return new PropertiesOutputter(owner);
-      case JSON:
-        return new JsonOutputter(owner);
-      case TEMPLATE:
-        return new TemplateOutputter(owner);
-      case YAML:
-        return new YamlOutputter(owner);
-      default:
-        throw new RuntimeException("Unsupported format :" + format);
-    }
-  }
-
-  public static class XmlOutputter extends PublishedConfigurationOutputter {
-
-
-    private final Configuration configuration;
-
-    public XmlOutputter(PublishedConfiguration owner) {
-      super(owner);
-      configuration = owner.asConfiguration();
-    }
-
-    @Override
-    public void save(OutputStream out) throws IOException {
-      configuration.writeXml(out);
-    }
-
-    @Override
-    public String asString() throws IOException {
-      return ConfigHelper.toXml(configuration);
-    }
-
-    public Configuration getConfiguration() {
-      return configuration;
-    }
-  }
-
-  public static class PropertiesOutputter extends PublishedConfigurationOutputter {
-
-    private final Properties properties;
-
-    public PropertiesOutputter(PublishedConfiguration owner) {
-      super(owner);
-      properties = owner.asProperties();
-    }
-
-    @Override
-    public void save(OutputStream out) throws IOException {
-      properties.store(out, COMMENTS);
-    }
-
-
-    public String asString() throws IOException {
-      StringWriter sw = new StringWriter();
-      properties.store(sw, COMMENTS);
-      return sw.toString();
-    }
-  }
-
-
-  public static class JsonOutputter extends PublishedConfigurationOutputter {
-
-    public JsonOutputter(PublishedConfiguration owner) {
-      super(owner);
-    }
-
-    @Override
-    public String asString() throws IOException {
-      return owner.asJson();
-    }
-  }
-
-
-  public static class EnvOutputter extends PublishedConfigurationOutputter {
-
-    public EnvOutputter(PublishedConfiguration owner) {
-      super(owner);
-    }
-
-    @Override
-    public String asString() throws IOException {
-      if (!owner.entries.containsKey("content")) {
-        throw new IOException("Configuration has no content field and cannot " +
-            "be retrieved as type 'env'");
-      }
-      String content = owner.entries.get("content");
-      return ConfigUtils.replaceProps(owner.entries, content);
-    }
-  }
-
-  public static class TemplateOutputter extends EnvOutputter {
-    public TemplateOutputter(PublishedConfiguration owner) {
-      super(owner);
-    }
-  }
-
-  public static class YamlOutputter extends PublishedConfigurationOutputter {
-
-    private final Yaml yaml;
-
-    public YamlOutputter(PublishedConfiguration owner) {
-      super(owner);
-      DumperOptions options = new DumperOptions();
-      options.setDefaultFlowStyle(FlowStyle.BLOCK);
-      yaml = new Yaml(options);
-    }
-
-    public String asString() throws IOException {
-      return yaml.dump(owner.entries);
-    }
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/SerializedApplicationReport.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/SerializedApplicationReport.java
deleted file mode 100644
index 953f4c48ee4..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/SerializedApplicationReport.java
+++ /dev/null
@@ -1,96 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
-import com.fasterxml.jackson.annotation.JsonInclude;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
-import org.apache.hadoop.yarn.api.records.ApplicationReport;
-import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;
-
-import java.io.IOException;
-
-/**
- * Serialized form of an service report which can be persisted
- * and then parsed. It can not be converted back into a
- * real YARN service report
- * 
- * Useful for testing
- */
-
-@JsonIgnoreProperties(ignoreUnknown = true)
-@JsonInclude(value = JsonInclude.Include.NON_NULL)
-public class SerializedApplicationReport {
-
-  public String applicationId;
-  public String applicationAttemptId;
-  public String name;
-  public String applicationType;
-  public String user;
-  public String queue;
-  public String host;
-  public Integer rpcPort;
-  public String state;
-  public String diagnostics;
-  public String url;
-  /**
-   * This value is non-null only when a report is generated from a submission context.
-   * The YARN {@link ApplicationReport} structure does not propagate this value
-   * from the RM.
-   */
-  public Long submitTime;
-  public Long startTime;
-  public Long finishTime;
-  public String finalStatus;
-  public String origTrackingUrl;
-  public Float progress;
-  
-  public SerializedApplicationReport() {
-  }
-  
-  public SerializedApplicationReport(ApplicationReport report) {
-    this.applicationId = report.getApplicationId().toString();
-    ApplicationAttemptId attemptId = report.getCurrentApplicationAttemptId();
-    this.applicationAttemptId = attemptId != null ? attemptId.toString() : "N/A";
-    this.name = report.getName();
-    this.applicationType = report.getApplicationType();
-    this.user = report.getUser();
-    this.queue = report.getQueue();
-    this.host = report.getHost();
-    this.rpcPort = report.getRpcPort();
-    this.state = report.getYarnApplicationState().toString();
-    this.diagnostics = report.getDiagnostics();
-    this.startTime = report.getStartTime();
-    this.finishTime = report.getFinishTime();
-    FinalApplicationStatus appStatus = report.getFinalApplicationStatus();
-    this.finalStatus = appStatus == null ? "" : appStatus.toString();
-    this.progress = report.getProgress();
-    this.url = report.getTrackingUrl();
-    this.origTrackingUrl= report.getOriginalTrackingUrl();
-  }
-
-  @Override
-  public String toString() {
-    try {
-      return ApplicationReportSerDeser.toString(this);
-    } catch (IOException e) {
-      return super.toString();
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ServiceApiUtil.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ServiceApiUtil.java
deleted file mode 100644
index b96d04a98e0..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ServiceApiUtil.java
+++ /dev/null
@@ -1,786 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import com.fasterxml.jackson.databind.PropertyNamingStrategies;
-import org.apache.hadoop.classification.VisibleForTesting;
-import org.apache.hadoop.util.Preconditions;
-import org.apache.hadoop.thirdparty.com.google.common.collect.ArrayListMultimap;
-import org.apache.hadoop.thirdparty.com.google.common.collect.Multimap;
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.fs.permission.FsPermission;
-import org.apache.hadoop.registry.client.api.RegistryConstants;
-import org.apache.hadoop.registry.client.binding.RegistryUtils;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.util.Sets;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.service.api.records.ComponentContainers;
-import org.apache.hadoop.yarn.service.api.records.ComponentState;
-import org.apache.hadoop.yarn.service.api.records.Container;
-import org.apache.hadoop.yarn.service.api.records.ContainerState;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.client.ServiceClient;
-import org.apache.hadoop.yarn.service.api.records.Artifact;
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.api.records.Configuration;
-import org.apache.hadoop.yarn.service.api.records.KerberosPrincipal;
-import org.apache.hadoop.yarn.service.api.records.PlacementConstraint;
-import org.apache.hadoop.yarn.service.api.records.PlacementPolicy;
-import org.apache.hadoop.yarn.service.api.records.Resource;
-import org.apache.hadoop.yarn.service.exceptions.SliderException;
-import org.apache.hadoop.yarn.service.conf.RestApiConstants;
-import org.apache.hadoop.yarn.service.exceptions.RestApiErrorMessages;
-import org.apache.hadoop.yarn.service.monitor.probe.MonitorUtils;
-import org.apache.hadoop.yarn.service.provider.AbstractClientProvider;
-import org.apache.hadoop.yarn.service.provider.ProviderFactory;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.text.MessageFormat;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.HashSet;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
-import static org.apache.hadoop.yarn.service.exceptions.RestApiErrorMessages.ERROR_COMP_DOES_NOT_NEED_UPGRADE;
-import static org.apache.hadoop.yarn.service.exceptions.RestApiErrorMessages.ERROR_COMP_INSTANCE_DOES_NOT_NEED_UPGRADE;
-
-public class ServiceApiUtil {
-  private static final Logger LOG =
-      LoggerFactory.getLogger(ServiceApiUtil.class);
-  public static JsonSerDeser<Service> jsonSerDeser =
-      new JsonSerDeser<>(Service.class,
-          PropertyNamingStrategies.SNAKE_CASE);
-
-  public static final JsonSerDeser<Container[]> CONTAINER_JSON_SERDE =
-      new JsonSerDeser<>(Container[].class,
-          PropertyNamingStrategies.SNAKE_CASE);
-
-  public static final JsonSerDeser<ComponentContainers[]>
-      COMP_CONTAINERS_JSON_SERDE = new JsonSerDeser<>(
-          ComponentContainers[].class,
-          PropertyNamingStrategies.SNAKE_CASE);
-
-  public static final JsonSerDeser<Component[]> COMP_JSON_SERDE =
-      new JsonSerDeser<>(Component[].class,
-          PropertyNamingStrategies.SNAKE_CASE);
-
-  private static final PatternValidator namePattern
-      = new PatternValidator("[a-z][a-z0-9-]*");
-
-  private static final PatternValidator userNamePattern
-      = new PatternValidator("[a-z][a-z0-9-.]*");
-
-  @VisibleForTesting
-  public static void setJsonSerDeser(JsonSerDeser jsd) {
-    jsonSerDeser = jsd;
-  }
-
-  @VisibleForTesting
-  public static void validateAndResolveService(Service service,
-      SliderFileSystem fs, org.apache.hadoop.conf.Configuration conf) throws
-      IOException {
-    boolean dnsEnabled = conf.getBoolean(RegistryConstants.KEY_DNS_ENABLED,
-        RegistryConstants.DEFAULT_DNS_ENABLED);
-    if (dnsEnabled) {
-      if (RegistryUtils.currentUser().length()
-          > RegistryConstants.MAX_FQDN_LABEL_LENGTH) {
-        throw new IllegalArgumentException(
-            RestApiErrorMessages.ERROR_USER_NAME_INVALID);
-      }
-      userNamePattern.validate(RegistryUtils.currentUser());
-    }
-
-    if (StringUtils.isEmpty(service.getName())) {
-      throw new IllegalArgumentException(
-          RestApiErrorMessages.ERROR_APPLICATION_NAME_INVALID);
-    }
-
-    if (StringUtils.isEmpty(service.getVersion())) {
-      throw new IllegalArgumentException(String.format(
-          RestApiErrorMessages.ERROR_APPLICATION_VERSION_INVALID,
-          service.getName()));
-    }
-
-    validateNameFormat(service.getName(), conf);
-
-    // If the service has no components, throw error
-    if (!hasComponent(service)) {
-      throw new IllegalArgumentException(
-          "No component specified for " + service.getName());
-    }
-
-    if (UserGroupInformation.isSecurityEnabled()) {
-      validateKerberosPrincipal(service.getKerberosPrincipal());
-    }
-
-    // Validate the Docker client config.
-    try {
-      validateDockerClientConfiguration(service, conf);
-    } catch (IOException e) {
-      throw new IllegalArgumentException(e);
-    }
-
-    // Validate there are no component name collisions (collisions are not
-    // currently supported) and add any components from external services
-    Configuration globalConf = service.getConfiguration();
-    Set<String> componentNames = new HashSet<>();
-    List<Component> componentsToRemove = new ArrayList<>();
-    List<Component> componentsToAdd = new ArrayList<>();
-    for (Component comp : service.getComponents()) {
-      int maxCompLength = RegistryConstants.MAX_FQDN_LABEL_LENGTH;
-      maxCompLength = maxCompLength - Long.toString(Long.MAX_VALUE).length();
-      if (dnsEnabled && comp.getName().length() > maxCompLength) {
-        throw new IllegalArgumentException(String.format(RestApiErrorMessages
-            .ERROR_COMPONENT_NAME_INVALID, maxCompLength, comp.getName()));
-      }
-      if (service.getName().equals(comp.getName())) {
-        throw new IllegalArgumentException(String.format(RestApiErrorMessages
-                .ERROR_COMPONENT_NAME_CONFLICTS_WITH_SERVICE_NAME,
-            comp.getName(), service.getName()));
-      }
-      if (componentNames.contains(comp.getName())) {
-        throw new IllegalArgumentException("Component name collision: " +
-            comp.getName());
-      }
-      // If artifact is of type SERVICE (which cannot be filled from global),
-      // read external service and add its components to this service
-      if (comp.getArtifact() != null && comp.getArtifact().getType() ==
-          Artifact.TypeEnum.SERVICE) {
-        if (StringUtils.isEmpty(comp.getArtifact().getId())) {
-          throw new IllegalArgumentException(
-              RestApiErrorMessages.ERROR_ARTIFACT_ID_INVALID);
-        }
-        LOG.info("Marking {} for removal", comp.getName());
-        componentsToRemove.add(comp);
-        List<Component> externalComponents = getComponents(fs,
-            comp.getArtifact().getId());
-        for (Component c : externalComponents) {
-          Component override = service.getComponent(c.getName());
-          if (override != null && override.getArtifact() == null) {
-            // allow properties from external components to be overridden /
-            // augmented by properties in this component, except for artifact
-            // which must be read from external component
-            override.mergeFrom(c);
-            LOG.info("Merging external component {} from external {}", c
-                .getName(), comp.getName());
-          } else {
-            if (componentNames.contains(c.getName())) {
-              throw new IllegalArgumentException("Component name collision: " +
-                  c.getName());
-            }
-            componentNames.add(c.getName());
-            componentsToAdd.add(c);
-            LOG.info("Adding component {} from external {}", c.getName(),
-                comp.getName());
-          }
-        }
-      } else {
-        // otherwise handle as a normal component
-        componentNames.add(comp.getName());
-        // configuration
-        comp.getConfiguration().mergeFrom(globalConf);
-      }
-    }
-    service.getComponents().removeAll(componentsToRemove);
-    service.getComponents().addAll(componentsToAdd);
-
-    // Validate components and let global values take effect if component level
-    // values are not provided
-    Artifact globalArtifact = service.getArtifact();
-    Resource globalResource = service.getResource();
-    for (Component comp : service.getComponents()) {
-      // fill in global artifact unless it is type SERVICE
-      if (comp.getArtifact() == null && service.getArtifact() != null
-          && service.getArtifact().getType() != Artifact.TypeEnum
-          .SERVICE) {
-        comp.setArtifact(globalArtifact);
-      }
-      // fill in global resource
-      if (comp.getResource() == null) {
-        comp.setResource(globalResource);
-      }
-      // validate dependency existence
-      if (comp.getDependencies() != null) {
-        for (String dependency : comp.getDependencies()) {
-          if (!componentNames.contains(dependency)) {
-            throw new IllegalArgumentException(String.format(
-                RestApiErrorMessages.ERROR_DEPENDENCY_INVALID, dependency,
-                comp.getName()));
-          }
-        }
-      }
-      validateComponent(comp, fs.getFileSystem(), conf);
-    }
-    validatePlacementPolicy(service.getComponents(), componentNames);
-
-    // validate dependency tree
-    sortByDependencies(service.getComponents());
-
-    // Service lifetime if not specified, is set to unlimited lifetime
-    if (service.getLifetime() == null) {
-      service.setLifetime(RestApiConstants.DEFAULT_UNLIMITED_LIFETIME);
-    }
-  }
-
-  public static void validateJvmOpts(String jvmOpts)
-      throws IllegalArgumentException {
-    Pattern pattern = Pattern.compile("[!~#?@*&%${}()<>\\[\\]|\",`;]");
-    Matcher matcher = pattern.matcher(jvmOpts);
-    if (matcher.find()) {
-      throw new IllegalArgumentException(
-          RestApiErrorMessages.ERROR_JVM_OPTS);
-    }
-  }
-
-  public static void validateKerberosPrincipal(
-      KerberosPrincipal kerberosPrincipal) throws IOException {
-    if (!StringUtils.isEmpty(kerberosPrincipal.getPrincipalName())) {
-      if (!kerberosPrincipal.getPrincipalName().contains("/")) {
-        throw new IllegalArgumentException(String.format(
-            RestApiErrorMessages.ERROR_KERBEROS_PRINCIPAL_NAME_FORMAT,
-            kerberosPrincipal.getPrincipalName()));
-      }
-    }
-  }
-
-  private static void validateDockerClientConfiguration(Service service,
-      org.apache.hadoop.conf.Configuration conf) throws IOException {
-    String dockerClientConfig = service.getDockerClientConfig();
-    if (!StringUtils.isEmpty(dockerClientConfig)) {
-      Path dockerClientConfigPath = new Path(dockerClientConfig);
-      FileSystem fs = dockerClientConfigPath.getFileSystem(conf);
-      LOG.info("The supplied Docker client config is " + dockerClientConfig);
-      if (!fs.exists(dockerClientConfigPath)) {
-        throw new IOException(
-            "The supplied Docker client config does not exist: "
-                + dockerClientConfig);
-      }
-    }
-  }
-
-  private static void validateComponent(Component comp, FileSystem fs,
-      org.apache.hadoop.conf.Configuration conf)
-      throws IOException {
-    validateNameFormat(comp.getName(), conf);
-
-    AbstractClientProvider compClientProvider = ProviderFactory
-        .getClientProvider(comp.getArtifact());
-    compClientProvider.validateArtifact(comp.getArtifact(), comp.getName(), fs);
-
-    if (comp.getLaunchCommand() == null && (comp.getArtifact() == null || comp
-        .getArtifact().getType() != Artifact.TypeEnum.DOCKER)) {
-      throw new IllegalArgumentException(RestApiErrorMessages
-          .ERROR_ABSENT_LAUNCH_COMMAND);
-    }
-
-    validateServiceResource(comp.getResource(), comp);
-
-    if (comp.getNumberOfContainers() == null
-        || comp.getNumberOfContainers() < 0) {
-      throw new IllegalArgumentException(String.format(
-          RestApiErrorMessages.ERROR_CONTAINERS_COUNT_FOR_COMP_INVALID
-              + ": " + comp.getNumberOfContainers(), comp.getName()));
-    }
-    compClientProvider.validateConfigFiles(comp.getConfiguration()
-        .getFiles(), comp.getName(), fs);
-
-    MonitorUtils.getProbe(comp.getReadinessCheck());
-  }
-
-  // Check component or service name format and transform to lower case.
-  public static void validateNameFormat(String name,
-      org.apache.hadoop.conf.Configuration conf) {
-    if (StringUtils.isEmpty(name)) {
-      throw new IllegalArgumentException("Name can not be empty!");
-    }
-    // validate component name
-    if (name.contains("_")) {
-      throw new IllegalArgumentException(
-          "Invalid format: " + name
-              + ", can not use '_', as DNS hostname does not allow '_'. Use '-' Instead. ");
-    }
-    boolean dnsEnabled = conf.getBoolean(RegistryConstants.KEY_DNS_ENABLED,
-        RegistryConstants.DEFAULT_DNS_ENABLED);
-    if (dnsEnabled && name.length() > RegistryConstants.MAX_FQDN_LABEL_LENGTH) {
-      throw new IllegalArgumentException(String
-          .format("Invalid format %s, must be no more than 63 characters ",
-              name));
-    }
-    namePattern.validate(name);
-  }
-
-  private static void validatePlacementPolicy(List<Component> components,
-      Set<String> componentNames) {
-    for (Component comp : components) {
-      PlacementPolicy placementPolicy = comp.getPlacementPolicy();
-      if (placementPolicy != null) {
-        for (PlacementConstraint constraint : placementPolicy
-            .getConstraints()) {
-          if (constraint.getType() == null) {
-            throw new IllegalArgumentException(String.format(
-              RestApiErrorMessages.ERROR_PLACEMENT_POLICY_CONSTRAINT_TYPE_NULL,
-              constraint.getName() == null ? "" : constraint.getName() + " ",
-              comp.getName()));
-          }
-          if (constraint.getScope() == null) {
-            throw new IllegalArgumentException(String.format(
-              RestApiErrorMessages.ERROR_PLACEMENT_POLICY_CONSTRAINT_SCOPE_NULL,
-              constraint.getName() == null ? "" : constraint.getName() + " ",
-              comp.getName()));
-          }
-        }
-      }
-    }
-  }
-
-  @VisibleForTesting
-  public static List<Component> getComponents(SliderFileSystem
-      fs, String serviceName) throws IOException {
-    return loadService(fs, serviceName).getComponents();
-  }
-
-  public static Service loadService(SliderFileSystem fs, String
-      serviceName) throws IOException {
-    Path serviceJson = getServiceJsonPath(fs, serviceName);
-    LOG.info("Loading service definition from " + serviceJson);
-    return jsonSerDeser.load(fs.getFileSystem(), serviceJson);
-  }
-
-  public static Service loadServiceUpgrade(SliderFileSystem fs,
-      String serviceName, String version) throws IOException {
-    Path versionPath = fs.buildClusterUpgradeDirPath(serviceName, version);
-    Path versionedDef = new Path(versionPath, serviceName + ".json");
-    LOG.info("Loading service definition from {}", versionedDef);
-    return jsonSerDeser.load(fs.getFileSystem(), versionedDef);
-  }
-
-  public static Service loadServiceFrom(SliderFileSystem fs,
-      Path appDefPath) throws IOException {
-    LOG.info("Loading service definition from " + appDefPath);
-    return jsonSerDeser.load(fs.getFileSystem(), appDefPath);
-  }
-
-  public static Path getServiceJsonPath(SliderFileSystem fs, String serviceName) {
-    Path serviceDir = fs.buildClusterDirPath(serviceName);
-    return new Path(serviceDir, serviceName + ".json");
-  }
-
-  private static void validateServiceResource(Resource resource,
-      Component comp) {
-    // Only services/components of type SERVICE can skip resource requirement
-    if (resource == null) {
-      throw new IllegalArgumentException(
-          comp == null ? RestApiErrorMessages.ERROR_RESOURCE_INVALID : String
-              .format(RestApiErrorMessages.ERROR_RESOURCE_FOR_COMP_INVALID,
-                  comp.getName()));
-    }
-    // One and only one of profile OR cpus & memory can be specified. Specifying
-    // both raises validation error.
-    if (StringUtils.isNotEmpty(resource.getProfile()) && (
-        resource.getCpus() != null || StringUtils
-            .isNotEmpty(resource.getMemory()))) {
-      throw new IllegalArgumentException(comp == null ?
-          RestApiErrorMessages.ERROR_RESOURCE_PROFILE_MULTIPLE_VALUES_NOT_SUPPORTED :
-          String.format(
-              RestApiErrorMessages.ERROR_RESOURCE_PROFILE_MULTIPLE_VALUES_FOR_COMP_NOT_SUPPORTED,
-              comp.getName()));
-    }
-    // Currently resource profile is not supported yet, so we will raise
-    // validation error if only resource profile is specified
-    if (StringUtils.isNotEmpty(resource.getProfile())) {
-      throw new IllegalArgumentException(
-          RestApiErrorMessages.ERROR_RESOURCE_PROFILE_NOT_SUPPORTED_YET);
-    }
-
-    String memory = resource.getMemory();
-    Integer cpus = resource.getCpus();
-    if (StringUtils.isEmpty(memory)) {
-      throw new IllegalArgumentException(
-          comp == null ? RestApiErrorMessages.ERROR_RESOURCE_MEMORY_INVALID :
-              String.format(
-                  RestApiErrorMessages.ERROR_RESOURCE_MEMORY_FOR_COMP_INVALID,
-                  comp.getName()));
-    }
-    if (cpus == null) {
-      throw new IllegalArgumentException(
-          comp == null ? RestApiErrorMessages.ERROR_RESOURCE_CPUS_INVALID :
-              String.format(
-                  RestApiErrorMessages.ERROR_RESOURCE_CPUS_FOR_COMP_INVALID,
-                  comp.getName()));
-    }
-    if (cpus <= 0) {
-      throw new IllegalArgumentException(comp == null ?
-          RestApiErrorMessages.ERROR_RESOURCE_CPUS_INVALID_RANGE : String
-          .format(
-              RestApiErrorMessages.ERROR_RESOURCE_CPUS_FOR_COMP_INVALID_RANGE,
-              comp.getName()));
-    }
-  }
-
-  // check if comp mem size exceeds cluster limit
-  public static void validateCompResourceSize(
-      org.apache.hadoop.yarn.api.records.Resource maxResource,
-      Service service) throws YarnException {
-    for (Component component : service.getComponents()) {
-      long mem = Long.parseLong(component.getResource().getMemory());
-      if (mem > maxResource.getMemorySize()) {
-        throw new YarnException(
-            "Component " + component.getName() + ": specified memory size ("
-                + mem + ") is larger than configured max container memory " +
-                "size (" + maxResource.getMemorySize() + ")");
-      }
-      int cpu = component.getResource().getCpus();
-      if (cpu > maxResource.getVirtualCores()) {
-        throw new YarnException(
-            "Component " + component.getName() + ": specified number of " +
-                "virtual core (" + cpu + ") is larger than configured max " +
-                "virtual core size (" + maxResource.getVirtualCores() + ")");
-      }
-    }
-  }
-
-  private static boolean hasComponent(Service service) {
-    if (service.getComponents() == null || service.getComponents()
-        .isEmpty()) {
-      return false;
-    }
-    return true;
-  }
-
-  public static Collection<Component> sortByDependencies(List<Component>
-      components) {
-    Map<String, Component> sortedComponents =
-        sortByDependencies(components, null);
-    return sortedComponents.values();
-  }
-
-  /**
-   * Each internal call of sortByDependencies will identify all of the
-   * components with the same dependency depth (the lowest depth that has not
-   * been processed yet) and add them to the sortedComponents list, preserving
-   * their original ordering in the components list.
-   *
-   * So the first time it is called, all components with no dependencies
-   * (depth 0) will be identified. The next time it is called, all components
-   * that have dependencies only on the the depth 0 components will be
-   * identified (depth 1). This will be repeated until all components have
-   * been added to the sortedComponents list. If no new components are
-   * identified but the sortedComponents list is not complete, an error is
-   * thrown.
-   */
-  private static Map<String, Component> sortByDependencies(List<Component>
-      components, Map<String, Component> sortedComponents) {
-    if (sortedComponents == null) {
-      sortedComponents = new LinkedHashMap<>();
-    }
-
-    Map<String, Component> componentsToAdd = new LinkedHashMap<>();
-    List<Component> componentsSkipped = new ArrayList<>();
-    for (Component component : components) {
-      String name = component.getName();
-      if (sortedComponents.containsKey(name)) {
-        continue;
-      }
-      boolean dependenciesAlreadySorted = true;
-      if (!ServiceUtils.isEmpty(component.getDependencies())) {
-        for (String dependency : component.getDependencies()) {
-          if (!sortedComponents.containsKey(dependency)) {
-            dependenciesAlreadySorted = false;
-            break;
-          }
-        }
-      }
-      if (dependenciesAlreadySorted) {
-        componentsToAdd.put(name, component);
-      } else {
-        componentsSkipped.add(component);
-      }
-    }
-
-    if (componentsToAdd.size() == 0) {
-      throw new IllegalArgumentException(String.format(RestApiErrorMessages
-          .ERROR_DEPENDENCY_CYCLE, componentsSkipped));
-    }
-    sortedComponents.putAll(componentsToAdd);
-    if (sortedComponents.size() == components.size()) {
-      return sortedComponents;
-    }
-    return sortByDependencies(components, sortedComponents);
-  }
-
-  public static void createDirAndPersistApp(SliderFileSystem fs, Path appDir,
-      Service service)
-      throws IOException, SliderException {
-    FsPermission appDirPermission = new FsPermission("750");
-    fs.createWithPermissions(appDir, appDirPermission);
-    Path appJson = writeAppDefinition(fs, appDir, service);
-    LOG.info("Persisted service {} version {} at {}", service.getName(),
-        service.getVersion(), appJson);
-  }
-
-  public static Path writeAppDefinition(SliderFileSystem fs, Path appDir,
-      Service service) throws IOException {
-    Path appJson = new Path(appDir, service.getName() + ".json");
-    jsonSerDeser.save(fs.getFileSystem(), appJson, service, true);
-    return appJson;
-  }
-
-  public static Path writeAppDefinition(SliderFileSystem fs, Service service)
-      throws IOException {
-    Path appJson = getServiceJsonPath(fs, service.getName());
-    jsonSerDeser.save(fs.getFileSystem(), appJson, service, true);
-    return appJson;
-  }
-
-  public static List<Container> getLiveContainers(Service service,
-      List<String> componentInstances)
-      throws YarnException {
-    List<Container> result = new ArrayList<>();
-
-    // In order to avoid iterating over all the containers of all components,
-    // first find the affected components by parsing the instance name.
-    Multimap<String, String> affectedComps = ArrayListMultimap.create();
-    for (String instanceName : componentInstances) {
-      affectedComps.put(
-          ServiceApiUtil.parseComponentName(instanceName), instanceName);
-    }
-
-    service.getComponents().forEach(comp -> {
-      // Iterating once over the containers of the affected component to
-      // find all the containers. Avoiding multiple calls to
-      // service.getComponent(...) and component.getContainer(...) because they
-      // iterate over all the components of the service and all the containers
-      // of the components respectively.
-      if (affectedComps.get(comp.getName()) != null) {
-        Collection<String> instanceNames = affectedComps.get(comp.getName());
-        comp.getContainers().forEach(container -> {
-          if (instanceNames.contains(container.getComponentInstanceName())) {
-            result.add(container);
-          }
-        });
-      }
-    });
-    return result;
-  }
-
-  /**
-   * Validates that the component instances that are requested to upgrade
-   * require an upgrade.
-   */
-  public static void validateInstancesUpgrade(List<Container>
-      liveContainers) throws YarnException {
-    for (Container liveContainer : liveContainers) {
-      if (!isUpgradable(liveContainer)) {
-        // Nothing to upgrade
-        throw new YarnException(String.format(
-            ERROR_COMP_INSTANCE_DOES_NOT_NEED_UPGRADE,
-            liveContainer.getComponentInstanceName()));
-      }
-    }
-  }
-
-  /**
-   * Returns whether the container can be upgraded in the current state.
-   */
-  public static boolean isUpgradable(Container container) {
-
-    return container.getState() != null &&
-        (container.getState().equals(ContainerState.NEEDS_UPGRADE) ||
-            container.getState().equals(ContainerState.FAILED_UPGRADE));
-  }
-
-  /**
-   * Validates the components that are requested to upgrade require an upgrade.
-   * It returns the instances of the components which need upgrade.
-   */
-  public static List<Container> validateAndResolveCompsUpgrade(
-      Service liveService, Collection<String> compNames) throws YarnException {
-    Preconditions.checkNotNull(compNames);
-    HashSet<String> requestedComps = Sets.newHashSet(compNames);
-    List<Container> containerNeedUpgrade = new ArrayList<>();
-    for (Component liveComp : liveService.getComponents()) {
-      if (requestedComps.contains(liveComp.getName())) {
-        if (!liveComp.getState().equals(ComponentState.NEEDS_UPGRADE)) {
-          // Nothing to upgrade
-          throw new YarnException(String.format(
-              ERROR_COMP_DOES_NOT_NEED_UPGRADE, liveComp.getName()));
-        }
-        liveComp.getContainers().forEach(liveContainer -> {
-          if (isUpgradable(liveContainer)) {
-            containerNeedUpgrade.add(liveContainer);
-          }
-        });
-      }
-    }
-    return containerNeedUpgrade;
-  }
-
-  /**
-   * Validates the components that are requested are stable for upgrade.
-   * It returns the instances of the components which are in ready state.
-   */
-  public static List<Container> validateAndResolveCompsStable(
-      Service liveService, Collection<String> compNames) throws YarnException {
-    Preconditions.checkNotNull(compNames);
-    HashSet<String> requestedComps = Sets.newHashSet(compNames);
-    List<Container> containerNeedUpgrade = new ArrayList<>();
-    for (Component liveComp : liveService.getComponents()) {
-      if (requestedComps.contains(liveComp.getName())) {
-        if (!liveComp.getState().equals(ComponentState.STABLE)) {
-          // Nothing to upgrade
-          throw new YarnException(String.format(
-              ERROR_COMP_DOES_NOT_NEED_UPGRADE, liveComp.getName()));
-        }
-        liveComp.getContainers().forEach(liveContainer -> {
-          if (liveContainer.getState().equals(ContainerState.READY)) {
-            containerNeedUpgrade.add(liveContainer);
-          }
-        });
-      }
-    }
-    return containerNeedUpgrade;
-  }
-
-  public static String getHostnameSuffix(String serviceName, org.apache
-      .hadoop.conf.Configuration conf) {
-    String domain = conf.get(RegistryConstants.KEY_DNS_DOMAIN);
-    String hostnameSuffix;
-    if (domain == null || domain.isEmpty()) {
-      hostnameSuffix = MessageFormat
-          .format(".{0}.{1}", serviceName, RegistryUtils.currentUser());
-    } else {
-      hostnameSuffix = MessageFormat
-          .format(".{0}.{1}.{2}", serviceName,
-              RegistryUtils.currentUser(), domain);
-    }
-    return hostnameSuffix;
-  }
-
-  public static String parseAndValidateComponentInstanceName(String
-      instanceOrHostname, String serviceName, org.apache.hadoop.conf
-      .Configuration conf) throws IllegalArgumentException {
-    int idx = instanceOrHostname.indexOf('.');
-    String hostnameSuffix = getHostnameSuffix(serviceName, conf);
-    if (idx != -1) {
-      if (!instanceOrHostname.endsWith(hostnameSuffix)) {
-        throw new IllegalArgumentException("Specified hostname " +
-            instanceOrHostname + " does not have the expected format " +
-            "componentInstanceName" +
-            hostnameSuffix);
-      }
-      instanceOrHostname = instanceOrHostname.substring(0, instanceOrHostname
-          .length() - hostnameSuffix.length());
-    }
-    idx = instanceOrHostname.indexOf('.');
-    if (idx != -1) {
-      throw new IllegalArgumentException("Specified hostname " +
-          instanceOrHostname + " does not have the expected format " +
-          "componentInstanceName" +
-          hostnameSuffix);
-    }
-    return instanceOrHostname;
-  }
-
-  public static String parseComponentName(String componentInstanceName)
-      throws YarnException {
-    int idx = componentInstanceName.indexOf('.');
-    if (idx != -1) {
-      componentInstanceName = componentInstanceName.substring(0, idx);
-    }
-    idx = componentInstanceName.lastIndexOf('-');
-    if (idx == -1) {
-      throw new YarnException("Invalid component instance (" +
-          componentInstanceName + ") name.");
-    }
-    return componentInstanceName.substring(0, idx);
-  }
-
-  public static String $(String s) {
-    return "${" + s +"}";
-  }
-
-  public static List<String> resolveCompsDependency(Service service) {
-    List<String> components = new ArrayList<String>();
-    for (Component component : service.getComponents()) {
-      int depSize = component.getDependencies().size();
-      if (!components.contains(component.getName())) {
-        components.add(component.getName());
-      }
-      if (depSize != 0) {
-        for (String depComp : component.getDependencies()) {
-          if (!components.contains(depComp)) {
-            components.add(0, depComp);
-          }
-        }
-      }
-    }
-    return components;
-  }
-
-  private static boolean serviceDependencySatisfied(Service service) {
-    boolean result = true;
-    try {
-      List<String> dependencies = service
-          .getDependencies();
-      org.apache.hadoop.conf.Configuration conf =
-          new org.apache.hadoop.conf.Configuration();
-      if (dependencies != null && dependencies.size() > 0) {
-        ServiceClient sc = new ServiceClient();
-        sc.init(conf);
-        sc.start();
-        for (String dependent : dependencies) {
-          Service dependentService = sc.getStatus(dependent);
-          if (dependentService.getState() == null ||
-              !dependentService.getState().equals(ServiceState.STABLE)) {
-            result = false;
-            LOG.info("Service dependency is not satisfied for " +
-                "service: {} state: {}", dependent,
-                dependentService.getState());
-          }
-        }
-        sc.close();
-      }
-    } catch (IOException | YarnException e) {
-      LOG.warn("Caught exception: ", e);
-      LOG.info("Service dependency is not satisified.");
-      result = false;
-    }
-    return result;
-  }
-
-  public static void checkServiceDependencySatisified(Service service) {
-    while (!serviceDependencySatisfied(service)) {
-      try {
-        LOG.info("Waiting for service dependencies.");
-        Thread.sleep(15000L);
-      } catch (InterruptedException e) {
-      }
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ServiceRegistryUtils.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ServiceRegistryUtils.java
deleted file mode 100644
index 30ba503732d..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ServiceRegistryUtils.java
+++ /dev/null
@@ -1,116 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import org.apache.hadoop.registry.client.binding.RegistryUtils;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConstants;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import javax.naming.Context;
-import javax.naming.NameNotFoundException;
-import javax.naming.NamingException;
-import javax.naming.directory.Attributes;
-import javax.naming.directory.DirContext;
-import javax.naming.directory.InitialDirContext;
-import java.net.InetAddress;
-import java.net.UnknownHostException;
-import java.util.Hashtable;
-
-
-public class ServiceRegistryUtils {
-  private static final Logger LOG =
-      LoggerFactory.getLogger(ServiceRegistryUtils.class);
-
-  public static final String SVC_USERS = "/services/yarn/users";
-
-  /**
-   * Get the registry path for an instance under the user's home node
-   * @param instanceName application instance
-   * @return a path to the registry location for this application instance.
-   */
-  public static String registryPathForInstance(String instanceName) {
-    return RegistryUtils.servicePath(
-        RegistryUtils.currentUser(), YarnServiceConstants.APP_TYPE, instanceName
-    );
-  }
-
-  /**
- * Build the path to a service folder
- * @param username user name
- * @param serviceName service name
- * @return the home path to the service
- */
-  public static String mkServiceHomePath(String username, String serviceName) {
-    return mkUserHomePath(username) + "/" + serviceName;
-  }
-
-  /**
-   * Build the path to a user home folder;
-   */
-  public static String mkUserHomePath(String username) {
-    return SVC_USERS + "/" + username;
-  }
-
-  /**
-   * Determine whether a DNS lookup exists for a given name. If a DNS server
-   * address is provided, the lookup will be performed against this DNS
-   * server. This option is provided because it may be desirable to perform
-   * the lookup against Registry DNS directly to avoid caching of negative
-   * responses that may be performed by other DNS servers, thereby allowing the
-   * lookup to succeed sooner.
-   *
-   * @param addr host:port dns address, or null
-   * @param name name to look up
-   * @return true if a lookup succeeds for the specified name
-   */
-  public static boolean registryDNSLookupExists(String addr, String
-      name) {
-    if (addr == null) {
-      try {
-        InetAddress.getByName(name);
-        return true;
-      } catch (UnknownHostException e) {
-        return false;
-      }
-    }
-
-    String dnsURI = String.format("dns://%s", addr);
-    Hashtable<String, Object> env = new Hashtable<>();
-    env.put(Context.INITIAL_CONTEXT_FACTORY,
-        "com.sun.jndi.dns.DnsContextFactory");
-    env.put(Context.PROVIDER_URL, dnsURI);
-
-    try {
-      DirContext ictx = new InitialDirContext(env);
-      Attributes attrs = ictx.getAttributes(name, new String[]{"A"});
-
-      if (attrs.size() > 0) {
-        return true;
-      }
-    } catch (NameNotFoundException e) {
-      // this doesn't need to be logged
-    } catch (NamingException e) {
-      LOG.error("Got exception when performing DNS lookup", e);
-    }
-
-    return false;
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ServiceUtils.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ServiceUtils.java
deleted file mode 100644
index 2034cc3b5d5..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ServiceUtils.java
+++ /dev/null
@@ -1,599 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import org.apache.hadoop.util.Preconditions;
-import org.apache.commons.compress.archivers.tar.TarArchiveEntry;
-import org.apache.commons.compress.archivers.tar.TarArchiveOutputStream;
-import org.apache.commons.lang3.ArrayUtils;
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.FileUtil;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.net.DNS;
-import org.apache.hadoop.util.ExitUtil;
-import org.apache.hadoop.yarn.api.ApplicationConstants;
-import org.apache.hadoop.yarn.api.records.LocalResource;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConstants;
-import org.apache.hadoop.yarn.service.containerlaunch.ClasspathConstructor;
-import org.apache.hadoop.yarn.service.exceptions.BadClusterStateException;
-import org.apache.hadoop.yarn.service.exceptions.SliderException;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import javax.annotation.Nullable;
-import java.io.BufferedOutputStream;
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.FileNotFoundException;
-import java.io.FileOutputStream;
-import java.io.FilenameFilter;
-import java.io.IOException;
-import java.net.*;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Enumeration;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Locale;
-import java.util.Map;
-import java.util.regex.Pattern;
-import java.util.zip.GZIPOutputStream;
-
-import static org.apache.hadoop.fs.CommonConfigurationKeysPublic
-    .HADOOP_SECURITY_DNS_INTERFACE_KEY;
-import static org.apache.hadoop.fs.CommonConfigurationKeysPublic
-    .HADOOP_SECURITY_DNS_NAMESERVER_KEY;
-
-/**
- * These are slider-specific Util methods
- */
-public final class ServiceUtils {
-
-  private static final Logger log = LoggerFactory.getLogger(ServiceUtils.class);
-
-  private ServiceUtils() {
-  }
-
-  /**
-   * Implementation of set-ness, groovy definition of true/false for a string
-   * @param s string
-   * @return true iff the string is neither null nor empty
-   */
-  public static boolean isUnset(String s) {
-    return s == null || s.isEmpty();
-  }
-
-  public static boolean isSet(String s) {
-    return !isUnset(s);
-  }
-
-  public static boolean isEmpty(Collection l) {
-    return l == null || l.isEmpty();
-  }
-
-  /**
-   * Find a containing JAR
-   * @param clazz class to find
-   * @return the file
-   * @throws IOException any IO problem, including the class not having a
-   * classloader
-   * @throws FileNotFoundException if the class did not resolve to a file
-   */
-  public static File findContainingJarOrFail(Class clazz) throws IOException {
-    File localFile = ServiceUtils.findContainingJar(clazz);
-    if (null == localFile) {
-      throw new FileNotFoundException("Could not find JAR containing " + clazz);
-    }
-    return localFile;
-  }
-
-
-  /**
-   * Find a containing JAR
-   * @param my_class class to find
-   * @return the file or null if it is not found
-   * @throws IOException any IO problem, including the class not having a
-   * classloader
-   */
-  public static File findContainingJar(Class my_class) throws IOException {
-    ClassLoader loader = my_class.getClassLoader();
-    if (loader == null) {
-      throw new IOException(
-          "Class " + my_class + " does not have a classloader!");
-    }
-    String class_file = my_class.getName().replaceAll("\\.", "/") + ".class";
-    Enumeration<URL> urlEnumeration = loader.getResources(class_file);
-    for (; urlEnumeration.hasMoreElements(); ) {
-      URL url = urlEnumeration.nextElement();
-      if ("jar".equals(url.getProtocol())) {
-        String toReturn = url.getPath();
-        if (toReturn.startsWith("file:")) {
-          toReturn = toReturn.substring("file:".length());
-        }
-        // URLDecoder is a misnamed class, since it actually decodes
-        // x-www-form-urlencoded MIME type rather than actual
-        // URL encoding (which the file path has). Therefore it would
-        // decode +s to ' 's which is incorrect (spaces are actually
-        // either unencoded or encoded as "%20"). Replace +s first, so
-        // that they are kept sacred during the decoding process.
-        toReturn = toReturn.replaceAll("\\+", "%2B");
-        toReturn = URLDecoder.decode(toReturn, "UTF-8");
-        String jarFilePath = toReturn.replaceAll("!.*$", "");
-        return new File(jarFilePath);
-      } else {
-        log.info("could not locate JAR containing {} URL={}", my_class, url);
-      }
-    }
-    return null;
-  }
-
-  /**
-   * Copy a file to a new FS -both paths must be qualified.
-   * @param conf conf file
-   * @param srcFile src file
-   * @param destFile dest file
-   */
-  @SuppressWarnings("deprecation")
-  public static void copy(Configuration conf,
-      Path srcFile,
-      Path destFile) throws
-      IOException,
-      BadClusterStateException {
-    FileSystem srcFS = FileSystem.get(srcFile.toUri(), conf);
-    //list all paths in the src.
-    if (!srcFS.exists(srcFile)) {
-      throw new FileNotFoundException("Source file not found " + srcFile);
-    }
-    if (!srcFS.isFile(srcFile)) {
-      throw new FileNotFoundException(
-          "Source file not a file " + srcFile);
-    }
-    FileSystem destFS = FileSystem.get(destFile.toUri(), conf);
-    FileUtil.copy(srcFS, srcFile, destFS, destFile, false, true, conf);
-  }
-
-  /**
-   * Take a collection, return a list containing the string value of every
-   * element in the collection.
-   * @param c collection
-   * @return a stringified list
-   */
-  public static List<String> collectionToStringList(Collection c) {
-    List<String> l = new ArrayList<>(c.size());
-    for (Object o : c) {
-      l.add(o.toString());
-    }
-    return l;
-  }
-
-  /**
-   * Join an collection of objects with a separator that appears after every
-   * instance in the list -including at the end
-   * @param collection collection to call toString() on each element
-   * @param separator separator string
-   * @return the joined entries
-   */
-  public static String join(Collection collection, String separator) {
-    return join(collection, separator, true);
-  }
-
-  /**
-   * Join an collection of objects with a separator that appears after every
-   * instance in the list -optionally at the end
-   * @param collection collection to call toString() on each element
-   * @param separator separator string
-   * @param trailing add a trailing entry or not
-   * @return the joined entries
-   */
-  public static String join(Collection collection,
-      String separator,
-      boolean trailing) {
-    StringBuilder b = new StringBuilder();
-    // fast return on empty collection
-    if (collection.isEmpty()) {
-      return trailing ? separator : "";
-    }
-    for (Object o : collection) {
-      b.append(o)
-          .append(separator);
-    }
-    int length = separator.length();
-    String s = b.toString();
-    return (trailing || s.isEmpty()) ?
-           s : (b.substring(0, b.length() - length));
-  }
-
-  /**
-   * Join an array of strings with a separator that appears after every
-   * instance in the list -optionally at the end
-   * @param collection strings
-   * @param separator separator string
-   * @param trailing add a trailing entry or not
-   * @return the joined entries
-   */
-  public static String join(String[] collection, String separator,
-      boolean trailing) {
-    return join(Arrays.asList(collection), separator, trailing);
-  }
-
-  /**
-   * Resolve a mandatory environment variable
-   * @param key env var
-   * @return the resolved value
-   * @throws BadClusterStateException
-   */
-  public static String mandatoryEnvVariable(String key) throws
-      BadClusterStateException {
-    String v = System.getenv(key);
-    if (v == null) {
-      throw new BadClusterStateException("Missing Environment variable " + key);
-    }
-    return v;
-  }
-
-  /**
-   * Generic map merge logic
-   * @param first first map
-   * @param second second map
-   * @param <T1> key type
-   * @param <T2> value type
-   * @return 'first' merged with the second
-   */
-  public static <T1, T2> Map<T1, T2> mergeMapsIgnoreDuplicateKeys(Map<T1, T2> first,
-      Map<T1, T2> second) {
-    Preconditions.checkArgument(first != null, "Null 'first' value");
-    Preconditions.checkArgument(second != null, "Null 'second' value");
-    for (Map.Entry<T1, T2> entry : second.entrySet()) {
-      T1 key = entry.getKey();
-      if (!first.containsKey(key)) {
-        first.put(key, entry.getValue());
-      }
-    }
-    return first;
-  }
-
-  /**
-   * Convert a map to a multi-line string for printing
-   * @param map map to stringify
-   * @return a string representation of the map
-   */
-  public static String stringifyMap(Map<String, String> map) {
-    StringBuilder builder = new StringBuilder();
-    for (Map.Entry<String, String> entry : map.entrySet()) {
-      builder.append(entry.getKey())
-             .append("=\"")
-             .append(entry.getValue())
-             .append("\"\n");
-
-    }
-    return builder.toString();
-  }
-
-  /**
-   * Convert a YARN URL into a string value of a normal URL
-   * @param url URL
-   * @return string representatin
-   */
-  public static String stringify(org.apache.hadoop.yarn.api.records.URL url) {
-    StringBuilder builder = new StringBuilder();
-    builder.append(url.getScheme()).append("://");
-    if (url.getHost() != null) {
-      builder.append(url.getHost()).append(":").append(url.getPort());
-    }
-    builder.append(url.getFile());
-    return builder.toString();
-  }
-
-  /**
-   * Get a random open port
-   * @return true if the port was available for listening on
-   */
-  public static int getOpenPort() throws IOException {
-    ServerSocket socket = null;
-    try {
-      socket = new ServerSocket(0);
-      return socket.getLocalPort();
-    } finally {
-      if (socket != null) {
-        socket.close();
-      }
-    }
-  }
-
-  /**
-   * See if a port is available for listening on by trying to listen
-   * on it and seeing if that works or fails.
-   * @param port port to listen to
-   * @return true if the port was available for listening on
-   */
-  public static boolean isPortAvailable(int port) {
-    try {
-      ServerSocket socket = new ServerSocket(port);
-      socket.close();
-      return true;
-    } catch (IOException e) {
-      return false;
-    }
-  }
-
-  // Build env map: key -> value;
-  // value will be replaced by the corresponding value in tokenMap, if any.
-  public static Map<String, String> buildEnvMap(
-      org.apache.hadoop.yarn.service.api.records.Configuration conf,
-      Map<String,String> tokenMap) {
-    if (tokenMap == null) {
-      return conf.getEnv();
-    }
-    Map<String, String> env = new HashMap<>();
-    for (Map.Entry<String, String> entry : conf.getEnv().entrySet()) {
-      String key = entry.getKey();
-      String val = entry.getValue();
-      for (Map.Entry<String,String> token : tokenMap.entrySet()) {
-        val = val.replaceAll(Pattern.quote(token.getKey()),
-            token.getValue());
-      }
-      env.put(key,val);
-    }
-    return env;
-  }
-
-  public static String[] getLibDirs() {
-    String libDirStr = System.getProperty(YarnServiceConstants.PROPERTY_LIB_DIR);
-    if (isUnset(libDirStr)) {
-      return ArrayUtils.EMPTY_STRING_ARRAY;
-    }
-    return StringUtils.split(libDirStr, ',');
-  }
-
-  /**
-   * Submit a JAR containing a specific class and map it
-   * @param providerResources provider map to build up
-   * @param sliderFileSystem remote fs
-   * @param clazz class to look for
-   * @param libdir lib directory
-   * @param jarName <i>At the destination</i>
-   * @return the local resource ref
-   * @throws IOException trouble copying to HDFS
-   */
-  public static LocalResource putJar(Map<String, LocalResource> providerResources,
-      SliderFileSystem sliderFileSystem,
-      Class clazz,
-      Path tempPath,
-      String libdir,
-      String jarName
-  )
-      throws IOException, SliderException {
-    LocalResource res = sliderFileSystem.submitJarWithClass(
-        clazz,
-        tempPath,
-        libdir,
-        jarName);
-    providerResources.put(libdir + "/" + jarName, res);
-    return res;
-  }
-
-  /**
-   * Submit a JAR containing and map it
-   * @param providerResources provider map to build up
-   * @param sliderFileSystem remote fs
-   * @param libDir lib directory
-   * @param srcPath copy jars from
-   */
-  public static void putAllJars(Map<String, LocalResource> providerResources,
-                                SliderFileSystem sliderFileSystem,
-                                Path tempPath,
-                                String libDir,
-                                String srcPath) throws IOException, SliderException {
-    log.debug("Loading all dependencies from {}", srcPath);
-    if (ServiceUtils.isSet(srcPath)) {
-      File srcFolder = new File(srcPath);
-      FilenameFilter jarFilter = createJarFilter();
-      File[] listOfJars = srcFolder.listFiles(jarFilter);
-      if (listOfJars == null || listOfJars.length == 0) {
-        return;
-      }
-      for (File jarFile : listOfJars) {
-        if (!jarFile.exists()) {
-          log.debug("File does not exist, skipping: " + jarFile);
-          continue;
-        }
-        LocalResource res = sliderFileSystem.submitFile(jarFile, tempPath, libDir, jarFile.getName());
-        providerResources.put(libDir + "/" + jarFile.getName(), res);
-      }
-    }
-  }
-
-  /**
-   * Accept all filenames ending with {@code .jar}
-   * @return a filename filter
-   */
-  public static FilenameFilter createJarFilter() {
-    return new FilenameFilter() {
-      public boolean accept(File dir, String name) {
-        return name.toLowerCase(Locale.ENGLISH).endsWith(".jar");
-      }
-    };
-  }
-
-  /**
-   * Create a file:// path from a local file
-   * @param file file to point the path
-   * @return a new Path
-   */
-  public static Path createLocalPath(File file) {
-    return new Path(file.toURI());
-  }
-
-  /**
-   * Build up the classpath for execution
-   * -behaves very differently on a mini test cluster vs a production
-   * production one.
-   *
-   * @param sliderConfDir relative path to the dir containing slider config
-   *                      options to put on the classpath -or null
-   * @param libdir directory containing the JAR files
-   * @param configClassPath extra class path configured in yarn-site.xml
-   * @param usingMiniMRCluster flag to indicate the MiniMR cluster is in use
-   * (and hence the current classpath should be used, not anything built up)
-   * @return a classpath
-   */
-  public static ClasspathConstructor buildClasspath(String sliderConfDir,
-      String libdir,
-      SliderFileSystem sliderFileSystem,
-      String configClassPath,
-      boolean usingMiniMRCluster) {
-
-    ClasspathConstructor classpath = new ClasspathConstructor();
-    classpath.append(YarnServiceConstants.YARN_SERVICE_LOG4J_FILENAME);
-
-    // add the runtime classpath needed for tests to work
-    if (usingMiniMRCluster) {
-      // for mini cluster we pass down the java CP properties
-      // and nothing else
-      classpath.appendAll(classpath.localJVMClasspath());
-    } else {
-      if (sliderConfDir != null) {
-        classpath.addClassDirectory(sliderConfDir);
-      }
-      classpath.addLibDir(libdir);
-      if (sliderFileSystem.isFile(sliderFileSystem.getDependencyTarGzip())) {
-        classpath.addLibDir(YarnServiceConstants.DEPENDENCY_LOCALIZED_DIR_LINK);
-      }
-      classpath.addRemoteClasspathEnvVar();
-      classpath.append(ApplicationConstants.Environment.HADOOP_CONF_DIR.$$());
-    }
-
-    if (!configClassPath.isEmpty()) {
-      classpath.appendAll(Arrays.asList(configClassPath.split(",")));
-    }
-
-    return classpath;
-  }
-
-  /**
-   * Given a source folder create a tar.gz file
-   * 
-   * @param libDirs
-   * @param tarGzipFile
-   * 
-   * @throws IOException
-   */
-  public static void tarGzipFolder(String[] libDirs, File tarGzipFile,
-      FilenameFilter filter) throws IOException {
-    log.info("Tar-gzipping folders {} to {}", libDirs,
-        tarGzipFile.getAbsolutePath());
-
-    try(TarArchiveOutputStream taos =
-            new TarArchiveOutputStream(new GZIPOutputStream(
-        new BufferedOutputStream(new FileOutputStream(tarGzipFile))))) {
-      for (String libDir : libDirs) {
-        File srcFolder = new File(libDir);
-        List<String> files = new ArrayList<>();
-        generateFileList(files, srcFolder, srcFolder, true, filter);
-        for (String file : files) {
-          File srcFile = new File(srcFolder, file);
-          TarArchiveEntry tarEntry = new TarArchiveEntry(
-              srcFile, file);
-          taos.putArchiveEntry(tarEntry);
-          try(FileInputStream in = new FileInputStream(srcFile)) {
-            org.apache.commons.io.IOUtils.copy(in, taos);
-          }
-          taos.flush();
-          taos.closeArchiveEntry();
-        }
-      }
-    }
-  }
-
-  private static void generateFileList(List<String> fileList, File node,
-      File rootFolder, Boolean relative, FilenameFilter filter) {
-    if (node.isFile()) {
-      String fileFullPath = node.toString();
-      if (relative) {
-        fileList.add(fileFullPath.substring(rootFolder.toString().length() + 1,
-            fileFullPath.length()));
-      } else {
-        fileList.add(fileFullPath);
-      }
-    }
-
-    if (node.isDirectory()) {
-      String[] subNode = node.list(filter);
-      if (subNode == null || subNode.length == 0) {
-          return;
-      }
-      for (String filename : subNode) {
-        generateFileList(fileList, new File(node, filename), rootFolder,
-            relative, filter);
-      }
-    }
-  }
-
-  public static String createNameTag(String name) {
-    return "Name: " + name;
-  }
-
-  public static String createVersionTag(String version) {
-    return "Version: " + version;
-  }
-
-  public static String createDescriptionTag(String description) {
-    return "Description: " + description;
-  }
-
-  // Copied from SecurityUtil because it is not public
-  public static String getLocalHostName(@Nullable Configuration conf)
-      throws UnknownHostException {
-    if (conf != null) {
-      String dnsInterface = conf.get(HADOOP_SECURITY_DNS_INTERFACE_KEY);
-      String nameServer = conf.get(HADOOP_SECURITY_DNS_NAMESERVER_KEY);
-
-      if (dnsInterface != null) {
-        return DNS.getDefaultHost(dnsInterface, nameServer, true);
-      } else if (nameServer != null) {
-        throw new IllegalArgumentException(HADOOP_SECURITY_DNS_NAMESERVER_KEY +
-            " requires " + HADOOP_SECURITY_DNS_INTERFACE_KEY + ". Check your" +
-            "configuration.");
-      }
-    }
-
-    // Fallback to querying the default hostname as we did before.
-    return InetAddress.getLocalHost().getCanonicalHostName();
-  }
-
-  /**
-   * Process termination handler - exist with specified exit code after
-   * waiting a while for ATS state to be in sync.
-   */
-  public static class ProcessTerminationHandler {
-    public void terminate(int exitCode) {
-      // Sleep for 5 seconds in hope that the state can be recorded in ATS.
-      // in case there's a client polling the comp state, it can be notified.
-      try {
-        Thread.sleep(5000);
-      } catch (InterruptedException e) {
-        log.info("Interrupted on sleep while exiting.", e);
-      }
-      ExitUtil.terminate(exitCode);
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/SliderFileSystem.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/SliderFileSystem.java
deleted file mode 100644
index 4af97502269..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/SliderFileSystem.java
+++ /dev/null
@@ -1,134 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConstants;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-
-/**
- * Extends Core Filesystem with operations to manipulate ClusterDescription
- * persistent state
- */
-public class SliderFileSystem extends CoreFileSystem {
-
-  Path appDir = null;
-
-  public SliderFileSystem(FileSystem fileSystem,
-      Configuration configuration) {
-    super(fileSystem, configuration);
-  }
-
-  public SliderFileSystem(Configuration configuration) throws IOException {
-    super(configuration);
-  }
-
-  public void setAppDir(Path appDir) {
-    this.appDir = appDir;
-  }
-
-  public Path getAppDir() {
-    return this.appDir;
-  }
-
-  /**
-   * Returns the component directory path.
-   *
-   * @param serviceVersion service version
-   * @param compName       component name
-   * @return component directory
-   */
-  public Path getComponentDir(String serviceVersion, String compName) {
-    return new Path(new Path(getAppDir(), "components"),
-        serviceVersion + "/" + compName);
-  }
-
-  public Path getBasePath() {
-    String tmpDir = configuration.get("hadoop.tmp.dir");
-    String basePath = YarnServiceConstants.SERVICE_BASE_DIRECTORY
-        + "/" + YarnServiceConstants.SERVICES_DIRECTORY;
-    return new Path(tmpDir, basePath);
-  }
-
-  /**
-   * Returns the component public resource directory path.
-   *
-   * @param serviceVersion service version
-   * @param compName       component name
-   * @return component public resource directory
-   */
-  public Path getComponentPublicResourceDir(String serviceVersion,
-      String compName) {
-    return new Path(new Path(getBasePath(), getAppDir().getName() + "/"
-        + "components"), serviceVersion + "/" + compName);
-  }
-
-  /**
-   * Deletes the component directory.
-   *
-   * @param serviceVersion
-   * @param compName
-   * @throws IOException
-   */
-  public void deleteComponentDir(String serviceVersion, String compName)
-      throws IOException {
-    Path path = getComponentDir(serviceVersion, compName);
-    if (fileSystem.exists(path)) {
-      fileSystem.delete(path, true);
-      LOG.debug("deleted dir {}", path);
-    }
-    Path publicResourceDir = getComponentPublicResourceDir(serviceVersion,
-        compName);
-    if (fileSystem.exists(publicResourceDir)) {
-      fileSystem.delete(publicResourceDir, true);
-      LOG.debug("deleted public resource dir {}", publicResourceDir);
-    }
-  }
-
-  /**
-   * Deletes the components version directory.
-   *
-   * @param serviceVersion
-   * @throws IOException
-   */
-  public void deleteComponentsVersionDirIfEmpty(String serviceVersion)
-      throws IOException {
-    Path path = new Path(new Path(getAppDir(), "components"), serviceVersion);
-    if (fileSystem.exists(path) && fileSystem.listStatus(path).length == 0) {
-      fileSystem.delete(path, true);
-      LOG.info("deleted dir {}", path);
-    }
-    Path publicResourceDir = new Path(new Path(getBasePath(),
-        getAppDir().getName() + "/" + "components"), serviceVersion);
-    if (fileSystem.exists(publicResourceDir)
-        && fileSystem.listStatus(publicResourceDir).length == 0) {
-      fileSystem.delete(publicResourceDir, true);
-      LOG.info("deleted public resource dir {}", publicResourceDir);
-    }
-  }
-
-
-  private static final Logger LOG = LoggerFactory.getLogger(
-      SliderFileSystem.class);
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ZookeeperUtils.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ZookeeperUtils.java
deleted file mode 100644
index aa669878b5e..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/java/org/apache/hadoop/yarn/service/utils/ZookeeperUtils.java
+++ /dev/null
@@ -1,146 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import org.apache.hadoop.thirdparty.com.google.common.net.HostAndPort;
-import org.apache.hadoop.util.StringUtils;
-import org.apache.hadoop.yarn.service.exceptions.BadConfigException;
-
-import java.util.ArrayList;
-import java.util.List;
-
-public class ZookeeperUtils {
-  public static final int DEFAULT_PORT = 2181;
-
-  public static String buildConnectionString(String zkHosts, int port) {
-    String zkPort = Integer.toString(port);
-    //parse the hosts
-    String[] hostlist = zkHosts.split(",", 0);
-    String quorum = ServiceUtils.join(hostlist, ":" + zkPort + ",", false);
-    return quorum;
-  }
-
-  /**
-   * Take a quorum list and split it to (trimmed) pairs
-   * @param hostPortQuorumList list of form h1:port, h2:port2,...
-   * @return a possibly empty list of values between commas. They may not be
-   * valid hostname:port pairs
-   */
-  public static List<String> splitToPairs(String hostPortQuorumList) {
-    // split an address hot
-    String[] strings = StringUtils.getStrings(hostPortQuorumList);
-    int len = 0;
-    if (strings != null) {
-      len = strings.length;
-    }
-    List<String> tuples = new ArrayList<String>(len);
-    if (strings != null) {
-      for (String s : strings) {
-        tuples.add(s.trim());
-      }
-    }
-    return tuples;
-  }
-
-  /**
-   * Split a quorum list into a list of hostnames and ports
-   * @param hostPortQuorumList split to a list of hosts and ports
-   * @return a list of values
-   */
-  public static List<HostAndPort> splitToHostsAndPorts(String hostPortQuorumList) {
-    // split an address hot
-    String[] strings = StringUtils.getStrings(hostPortQuorumList);
-    int len = 0;
-    if (strings != null) {
-      len = strings.length;
-    }
-    List<HostAndPort> list = new ArrayList<HostAndPort>(len);
-    if (strings != null) {
-      for (String s : strings) {
-        list.add(HostAndPort.fromString(s.trim()).withDefaultPort(DEFAULT_PORT));
-      }
-    }
-    return list;
-  }
-
-  /**
-   * Build up to a hosts only list
-   * @param hostAndPorts
-   * @return a list of the hosts only
-   */
-  public static String buildHostsOnlyList(List<HostAndPort> hostAndPorts) {
-    StringBuilder sb = new StringBuilder();
-    for (HostAndPort hostAndPort : hostAndPorts) {
-      sb.append(hostAndPort.getHost()).append(",");
-    }
-    if (sb.length() > 0) {
-      sb.delete(sb.length() - 1, sb.length());
-    }
-    return sb.toString();
-  }
-
-  public static String buildQuorumEntry(HostAndPort hostAndPort,
-    int defaultPort) {
-    String s = hostAndPort.toString();
-    if (hostAndPort.hasPort()) {
-      return s;
-    } else {
-      return s + ":" + defaultPort;
-    }
-  }
-
-  /**
-   * Build a quorum list, injecting a ":defaultPort" ref if needed on
-   * any entry without one
-   * @param hostAndPorts
-   * @param defaultPort
-   * @return
-   */
-  public static String buildQuorum(List<HostAndPort> hostAndPorts, int defaultPort) {
-    List<String> entries = new ArrayList<String>(hostAndPorts.size());
-    for (HostAndPort hostAndPort : hostAndPorts) {
-      entries.add(buildQuorumEntry(hostAndPort, defaultPort));
-    }
-    return ServiceUtils.join(entries, ",", false);
-  }
-  
-  public static String convertToHostsOnlyList(String quorum) throws
-      BadConfigException {
-    List<HostAndPort> hostAndPorts = splitToHostsAndPortsStrictly(quorum);
-    return ZookeeperUtils.buildHostsOnlyList(hostAndPorts);
-  }
-
-  public static List<HostAndPort> splitToHostsAndPortsStrictly(String quorum) throws
-      BadConfigException {
-    List<HostAndPort> hostAndPorts =
-        ZookeeperUtils.splitToHostsAndPorts(quorum);
-    if (hostAndPorts.isEmpty()) {
-      throw new BadConfigException("empty zookeeper quorum");
-    }
-    return hostAndPorts;
-  }
-  
-  public static int getFirstPort(String quorum, int defVal) throws
-      BadConfigException {
-    List<HostAndPort> hostAndPorts = splitToHostsAndPortsStrictly(quorum);
-    int port = hostAndPorts.get(0).getPortOrDefault(defVal);
-    return port;
-
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/proto/ClientAMProtocol.proto b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/proto/ClientAMProtocol.proto
deleted file mode 100644
index 0a84517d7c1..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/proto/ClientAMProtocol.proto
+++ /dev/null
@@ -1,115 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-syntax = "proto2";
-option java_package = "org.apache.hadoop.yarn.proto";
-option java_outer_classname = "ClientAMProtocol";
-option java_generic_services = true;
-option java_generate_equals_and_hash = true;
-package hadoop.yarn;
-
-service ClientAMProtocolService {
-  rpc flexComponents(FlexComponentsRequestProto) returns (FlexComponentsResponseProto);
-  rpc getStatus(GetStatusRequestProto) returns (GetStatusResponseProto);
-  rpc stop(StopRequestProto) returns (StopResponseProto);
-  rpc upgradeService(UpgradeServiceRequestProto)
-    returns (UpgradeServiceResponseProto);
-  rpc cancelUpgrade(CancelUpgradeRequestProto)
-    returns (CancelUpgradeResponseProto);
-  rpc restartService(RestartServiceRequestProto)
-    returns (RestartServiceResponseProto);
-  rpc upgrade(CompInstancesUpgradeRequestProto) returns
-    (CompInstancesUpgradeResponseProto);
-  rpc getCompInstances(GetCompInstancesRequestProto) returns
-    (GetCompInstancesResponseProto);
-  rpc decommissionCompInstances(DecommissionCompInstancesRequestProto)
-    returns (DecommissionCompInstancesResponseProto);
-}
-
-message FlexComponentsRequestProto {
-  repeated ComponentCountProto components = 1;
-}
-
-message ComponentCountProto {
-  optional string name = 1;
-  optional int64 numberOfContainers = 2;
-}
-
-message FlexComponentsResponseProto {
-}
-
-message GetStatusRequestProto {
-
-}
-message GetStatusResponseProto {
-  optional string status = 1;
-}
-
-message StopRequestProto {
-
-}
-
-message StopResponseProto {
-
-}
-
-message UpgradeServiceRequestProto {
-  optional string version = 1;
-  optional bool autoFinalize = 2;
-  optional bool expressUpgrade = 3;
-}
-
-message UpgradeServiceResponseProto {
-  optional string error = 1;
-}
-
-message CancelUpgradeRequestProto {
-}
-
-message CancelUpgradeResponseProto {
-}
-
-message RestartServiceRequestProto {
-}
-
-message RestartServiceResponseProto {
-}
-
-message CompInstancesUpgradeRequestProto {
-    repeated string containerIds = 1;
-}
-
-message CompInstancesUpgradeResponseProto {
-}
-
-message GetCompInstancesRequestProto {
-  repeated string componentNames = 1;
-  optional string version = 2;
-  repeated string containerStates = 3;
-}
-
-message GetCompInstancesResponseProto {
-  optional string compInstances = 1;
-}
-
-message DecommissionCompInstancesRequestProto {
-  repeated string compInstances = 1;
-}
-
-message DecommissionCompInstancesResponseProto {
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/resources/META-INF/services/org.apache.hadoop.security.SecurityInfo b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/resources/META-INF/services/org.apache.hadoop.security.SecurityInfo
deleted file mode 100644
index 14cdf68bc61..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/main/resources/META-INF/services/org.apache.hadoop.security.SecurityInfo
+++ /dev/null
@@ -1,14 +0,0 @@
-#
-#   Licensed under the Apache License, Version 2.0 (the "License");
-#   you may not use this file except in compliance with the License.
-#   You may obtain a copy of the License at
-#
-#       http://www.apache.org/licenses/LICENSE-2.0
-#
-#   Unless required by applicable law or agreed to in writing, software
-#   distributed under the License is distributed on an "AS IS" BASIS,
-#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-#   See the License for the specific language governing permissions and
-#   limitations under the License.
-#
-org.apache.hadoop.yarn.service.ClientAMSecurityInfo
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/MockRunningServiceContext.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/MockRunningServiceContext.java
deleted file mode 100644
index 4e3fc0999ee..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/MockRunningServiceContext.java
+++ /dev/null
@@ -1,205 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.Futures;
-import org.apache.hadoop.registry.client.api.RegistryOperations;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.Container;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.api.records.ContainerStatus;
-import org.apache.hadoop.yarn.api.records.NodeId;
-import org.apache.hadoop.yarn.client.api.NMClient;
-import org.apache.hadoop.yarn.client.api.async.NMClientAsync;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.component.Component;
-import org.apache.hadoop.yarn.service.component.ComponentEvent;
-import org.apache.hadoop.yarn.service.component.ComponentEventType;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEvent;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEventType;
-import org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher;
-import org.apache.hadoop.yarn.service.containerlaunch.ContainerLaunchService;
-import org.apache.hadoop.yarn.service.exceptions.SliderException;
-import org.apache.hadoop.yarn.service.provider.ProviderService;
-import org.apache.hadoop.yarn.service.provider.ProviderUtils;
-import org.apache.hadoop.yarn.service.registry.YarnRegistryViewForProviders;
-import org.apache.hadoop.yarn.service.utils.ServiceUtils;
-import org.mockito.invocation.InvocationOnMock;
-import org.mockito.stubbing.Answer;
-
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.concurrent.Future;
-
-import static org.mockito.ArgumentMatchers.any;
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.when;
-
-/**
- * Mocked service context for a running service.
- */
-public class MockRunningServiceContext extends ServiceContext {
-
-  public MockRunningServiceContext(ServiceTestUtils.ServiceFSWatcher fsWatcher,
-      Service serviceDef) throws Exception {
-    super();
-    this.service = serviceDef;
-    this.fs = fsWatcher.getFs();
-
-    ContainerLaunchService mockLaunchService = mock(
-        ContainerLaunchService.class);
-
-    this.scheduler = new ServiceScheduler(this) {
-      @Override
-      protected YarnRegistryViewForProviders
-      createYarnRegistryOperations(
-          ServiceContext context, RegistryOperations registryClient) {
-        return mock(YarnRegistryViewForProviders.class);
-      }
-
-      @Override
-      public NMClientAsync createNMClient() {
-        NMClientAsync nmClientAsync = super.createNMClient();
-        NMClient nmClient = mock(NMClient.class);
-        try {
-          when(nmClient.getContainerStatus(any(), any()))
-              .thenAnswer(
-                  (Answer<ContainerStatus>) invocation -> ContainerStatus
-                      .newInstance((ContainerId) invocation.getArguments()[0],
-                          org.apache.hadoop.yarn.api.records.ContainerState
-                              .RUNNING,
-                          "", 0));
-        } catch (YarnException | IOException e) {
-          throw new RuntimeException(e);
-        }
-        nmClientAsync.setClient(nmClient);
-        return nmClientAsync;
-      }
-
-      @Override
-      public ContainerLaunchService getContainerLaunchService() {
-        return mockLaunchService;
-      }
-
-      @Override
-      public ServiceUtils.ProcessTerminationHandler getTerminationHandler() {
-        return new
-            ServiceUtils.ProcessTerminationHandler() {
-              public void terminate(int exitCode) {
-              }
-            };
-      }
-
-      @Override
-      protected ServiceManager createServiceManager() {
-        return ServiceTestUtils.createServiceManager(
-            MockRunningServiceContext.this);
-      }
-    };
-
-
-    this.scheduler.init(fsWatcher.getConf());
-    when(mockLaunchService.launchCompInstance(any(), any(),
-        any(), any())).thenAnswer(
-        (Answer<Future<ProviderService.ResolvedLaunchParams>>)
-            this::launchAndReinitHelper);
-
-    when(mockLaunchService.reInitCompInstance(any(), any(),
-        any(), any())).thenAnswer((
-        Answer<Future<ProviderService.ResolvedLaunchParams>>)
-        this::launchAndReinitHelper);
-    stabilizeComponents(this);
-  }
-
-  private Future<ProviderService.ResolvedLaunchParams> launchAndReinitHelper(
-      InvocationOnMock invocation) throws IOException, SliderException {
-    AbstractLauncher launcher = new AbstractLauncher(
-        scheduler.getContext());
-    ComponentInstance instance = (ComponentInstance)
-        invocation.getArguments()[1];
-    Container container = (Container) invocation.getArguments()[2];
-    ContainerLaunchService.ComponentLaunchContext clc =
-        (ContainerLaunchService.ComponentLaunchContext)
-            invocation.getArguments()[3];
-
-    ProviderService.ResolvedLaunchParams resolvedParams =
-        new ProviderService.ResolvedLaunchParams();
-    ProviderUtils.createConfigFileAndAddLocalResource(launcher, fs, clc,
-        new HashMap<>(), instance, scheduler.getContext(), resolvedParams);
-    ProviderUtils.handleStaticFilesForLocalization(launcher, fs, clc,
-        resolvedParams);
-    return Futures.immediateFuture(resolvedParams);
-  }
-
-  private void stabilizeComponents(ServiceContext context) {
-
-    ApplicationId appId = ApplicationId.fromString(context.service.getId());
-    ApplicationAttemptId attemptId = ApplicationAttemptId.newInstance(appId, 1);
-    context.attemptId = attemptId;
-    Map<String, Component>
-        componentState = context.scheduler.getAllComponents();
-
-    int counter = 0;
-    for (org.apache.hadoop.yarn.service.api.records.Component componentSpec :
-        context.service.getComponents()) {
-      Component component = new org.apache.hadoop.yarn.service.component.
-          Component(componentSpec, 1L, context);
-      componentState.put(component.getName(), component);
-      component.handle(
-          new ComponentEvent(component.getName(), ComponentEventType.FLEX)
-              .setDesired(
-                  component.getComponentSpec().getNumberOfContainers()));
-
-      for (int i = 0; i < componentSpec.getNumberOfContainers(); i++) {
-        counter++;
-        assignNewContainer(attemptId, counter, component);
-      }
-
-      component.handle(new ComponentEvent(component.getName(),
-          ComponentEventType.CHECK_STABLE));
-    }
-  }
-
-  public void assignNewContainer(ApplicationAttemptId attemptId,
-      long containerNum, Component component) {
-
-    Container container = org.apache.hadoop.yarn.api.records.Container
-        .newInstance(ContainerId.newContainerId(attemptId, containerNum),
-            NODE_ID, "localhost", null, null,
-            null);
-    component.handle(new ComponentEvent(component.getName(),
-        ComponentEventType.CONTAINER_ALLOCATED)
-        .setContainer(container).setContainerId(container.getId()));
-    ComponentInstance instance = this.scheduler.getLiveInstances().get(
-        container.getId());
-    ComponentInstanceEvent startEvent = new ComponentInstanceEvent(
-        container.getId(), ComponentInstanceEventType.START);
-    instance.handle(startEvent);
-
-    ComponentInstanceEvent readyEvent = new ComponentInstanceEvent(
-        container.getId(), ComponentInstanceEventType.BECOME_READY);
-    instance.handle(readyEvent);
-  }
-
-  private static final NodeId NODE_ID = NodeId.fromString("localhost:0");
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/MockServiceAM.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/MockServiceAM.java
deleted file mode 100644
index 848120b29d5..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/MockServiceAM.java
+++ /dev/null
@@ -1,468 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import java.util.function.Supplier;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.io.DataOutputBuffer;
-import org.apache.hadoop.registry.client.api.RegistryOperations;
-import org.apache.hadoop.registry.client.binding.RegistryPathUtils;
-import org.apache.hadoop.registry.client.types.ServiceRecord;
-import org.apache.hadoop.registry.client.types.yarn.PersistencePolicies;
-import org.apache.hadoop.registry.client.types.yarn.YarnRegistryAttributes;
-import org.apache.hadoop.security.Credentials;
-import org.apache.hadoop.test.GenericTestUtils;
-import org.apache.hadoop.util.Lists;
-import org.apache.hadoop.yarn.api.protocolrecords.AllocateResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.RegisterApplicationMasterResponse;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.Container;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.api.records.ContainerState;
-import org.apache.hadoop.yarn.api.records.ContainerStatus;
-import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;
-import org.apache.hadoop.yarn.api.records.NodeId;
-import org.apache.hadoop.yarn.api.records.Priority;
-import org.apache.hadoop.yarn.api.records.Resource;
-import org.apache.hadoop.yarn.client.api.AMRMClient;
-import org.apache.hadoop.yarn.client.api.NMClient;
-import org.apache.hadoop.yarn.client.api.async.AMRMClientAsync;
-import org.apache.hadoop.yarn.client.api.async.NMClientAsync;
-import org.apache.hadoop.yarn.client.api.impl.AMRMClientImpl;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.component.Component;
-import org.apache.hadoop.yarn.service.component.ComponentState;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceState;
-import org.apache.hadoop.yarn.service.exceptions.BadClusterStateException;
-import org.apache.hadoop.yarn.service.registry.YarnRegistryViewForProviders;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-import org.apache.hadoop.yarn.util.Records;
-import org.apache.hadoop.yarn.util.resource.ResourceUtils;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.util.Collections;
-import java.util.Iterator;
-import java.util.LinkedList;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.concurrent.TimeoutException;
-
-import static org.mockito.ArgumentMatchers.any;
-import static org.mockito.ArgumentMatchers.anyString;
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.when;
-
-public class MockServiceAM extends ServiceMaster {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(MockServiceAM.class);
-
-  Service service;
-  // The list of containers fed by tests to be returned on
-  // AMRMClientCallBackHandler#onContainersAllocated
-  final List<Container> feedContainers =
-      Collections.synchronizedList(new LinkedList<>());
-
-  final List<ContainerStatus> failedContainers =
-      Collections.synchronizedList(new LinkedList<>());
-
-  private final List<Container> recoveredContainers =
-      Collections.synchronizedList(new LinkedList<>());
-
-  private final Map<String, ServiceRecord> registryComponents =
-      new ConcurrentHashMap<>();
-
-  private Map<ContainerId, ContainerStatus> containerStatuses =
-      new ConcurrentHashMap<>();
-
-  private Set<ContainerId> releasedContainers = ConcurrentHashMap.newKeySet();
-
-  private Credentials amCreds;
-
-  public MockServiceAM(Service service) {
-    super(service.getName());
-    this.service = service;
-  }
-
-  public MockServiceAM(Service service, Credentials amCreds) {
-    super(service.getName());
-    this.service = service;
-    this.amCreds = amCreds;
-  }
-
-  @Override
-  protected ContainerId getAMContainerId()
-      throws BadClusterStateException {
-    return ContainerId.newContainerId(ApplicationAttemptId
-        .newInstance(ApplicationId.fromString(service.getId()), 1), 1);
-  }
-
-  @Override
-  protected Path getAppDir() {
-    Path path = new Path(new Path("target", "apps"), service.getName());
-    LOG.info("Service path: {}", path);
-    return path;
-  }
-
-  @Override
-  protected ClientAMService createClientAMService() {
-    return new ClientAMService(context) {
-      @Override
-      String getNMHostName() {
-        return "0.0.0.0";
-      }
-    };
-  }
-
-  @Override
-  protected ServiceScheduler createServiceScheduler(ServiceContext context)
-      throws IOException, YarnException {
-    return new ServiceScheduler(context) {
-
-      @SuppressWarnings("SuspiciousMethodCalls")
-      @Override
-      protected YarnRegistryViewForProviders createYarnRegistryOperations(
-          ServiceContext context, RegistryOperations registryClient) {
-        YarnRegistryViewForProviders yarnRegistryView = mock(
-            YarnRegistryViewForProviders.class);
-        if (!registryComponents.isEmpty()) {
-          try {
-            when(yarnRegistryView.listComponents())
-                .thenReturn(new LinkedList<>(registryComponents.keySet()));
-            when(yarnRegistryView.getComponent(anyString())).thenAnswer(
-                invocation ->
-                    registryComponents.get(invocation.getArguments()[0]));
-          } catch (IOException e) {
-            throw new RuntimeException(e);
-          }
-        }
-        return yarnRegistryView;
-      }
-
-      @Override
-      protected AMRMClientAsync<AMRMClient.ContainerRequest> createAMRMClient() {
-        AMRMClientImpl client1 = new AMRMClientImpl() {
-          @Override public AllocateResponse allocate(float progressIndicator)
-              throws YarnException, IOException {
-
-            AllocateResponse.AllocateResponseBuilder builder =
-                AllocateResponse.newBuilder();
-            // add new containers if any
-            synchronized (feedContainers) {
-              if (feedContainers.isEmpty()) {
-                LOG.info("Allocating........ no containers");
-              } else {
-                // The AMRMClient will return containers for compoenent that are
-                // at FLEXING state
-                List<Container> allocatedContainers = new LinkedList<>();
-                Iterator<Container> itor = feedContainers.iterator();
-                while (itor.hasNext()) {
-                  Container c = itor.next();
-                  org.apache.hadoop.yarn.service.component.Component component =
-                      componentsById.get(c.getAllocationRequestId());
-                  if (component.getState() == ComponentState.FLEXING) {
-                    LOG.info("Allocated container {} ", c.getId());
-                    allocatedContainers.add(c);
-                    itor.remove();
-                  }
-                }
-                builder.allocatedContainers(allocatedContainers);
-              }
-            }
-
-            // add recovered containers if any
-            synchronized (recoveredContainers) {
-              if (!recoveredContainers.isEmpty()) {
-                List<Container> containersFromPrevAttempt = new LinkedList<>();
-                containersFromPrevAttempt.addAll(recoveredContainers);
-                recoveredContainers.clear();
-                builder.containersFromPreviousAttempt(
-                    containersFromPrevAttempt);
-              }
-            }
-
-            // add failed containers if any
-            synchronized (failedContainers) {
-              if (!failedContainers.isEmpty()) {
-                List<ContainerStatus> failed =
-                    new LinkedList<>(failedContainers);
-                failedContainers.clear();
-                builder.completedContainersStatuses(failed);
-              }
-            }
-            return builder.build();
-          }
-
-          @Override
-          public RegisterApplicationMasterResponse registerApplicationMaster(
-              String appHostName, int appHostPort, String appTrackingUrl,
-              Map placementConstraintsMap) throws YarnException, IOException {
-            return this.registerApplicationMaster(appHostName, appHostPort,
-                appTrackingUrl);
-          }
-
-          @Override
-            public RegisterApplicationMasterResponse registerApplicationMaster(
-                String appHostName, int appHostPort, String appTrackingUrl) {
-            RegisterApplicationMasterResponse response = mock(
-                RegisterApplicationMasterResponse.class);
-            when(response.getResourceTypes()).thenReturn(
-                ResourceUtils.getResourcesTypeInfo());
-            return response;
-          }
-
-          @Override
-          public synchronized void releaseAssignedContainer(
-              ContainerId containerId) {
-            releasedContainers.add(containerId);
-            super.releaseAssignedContainer(containerId);
-          }
-
-          @Override public void unregisterApplicationMaster(
-              FinalApplicationStatus appStatus, String appMessage,
-              String appTrackingUrl) {
-            // DO nothing
-          }
-        };
-
-        AMRMClientAsync<AMRMClient.ContainerRequest> amrmClientAsync =
-            AMRMClientAsync.createAMRMClientAsync(client1, 1000,
-                this.new AMRMClientCallback());
-
-        return amrmClientAsync;
-      }
-
-      @SuppressWarnings("SuspiciousMethodCalls")
-      @Override
-      public NMClientAsync createNMClient() {
-        NMClientAsync nmClientAsync = super.createNMClient();
-        NMClient nmClient = mock(NMClient.class);
-        try {
-          when(nmClient.getContainerStatus(any(), any()))
-              .thenAnswer(invocation ->
-                  containerStatuses.get(invocation.getArguments()[0]));
-        } catch (YarnException | IOException e) {
-          throw new RuntimeException(e);
-        }
-        nmClientAsync.setClient(nmClient);
-        return nmClientAsync;
-      }
-    };
-  }
-
-  @Override protected void loadApplicationJson(ServiceContext context,
-      SliderFileSystem fs) throws IOException {
-    context.service = service;
-  }
-
-  public void feedRegistryComponent(ContainerId containerId, String compName,
-      String compInstName) {
-    ServiceRecord record = new ServiceRecord();
-    record.set(YarnRegistryAttributes.YARN_ID, containerId.toString());
-    record.description = compInstName;
-    record.set(YarnRegistryAttributes.YARN_PERSISTENCE,
-        PersistencePolicies.CONTAINER);
-    record.set(YarnRegistryAttributes.YARN_IP, "localhost");
-    record.set(YarnRegistryAttributes.YARN_HOSTNAME, "localhost");
-    record.set(YarnRegistryAttributes.YARN_COMPONENT, compName);
-    registryComponents.put(RegistryPathUtils.encodeYarnID(
-        containerId.toString()), record);
-  }
-
-  /**
-   * Simulates a recovered container that is sent to the AM in the heartbeat
-   * response.
-   *
-   * @param containerId The ID for the container
-   * @param compName    The component to which the recovered container is fed.
-   */
-  public void feedRecoveredContainer(ContainerId containerId, String compName) {
-    Container container = createContainer(containerId, compName);
-    recoveredContainers.add(container);
-    addContainerStatus(container, ContainerState.RUNNING);
-  }
-
-  /**
-   * Creates a mock container and container ID and feeds to the component.
-   * @param service The service for the component
-   * @param id The id for the container
-   * @param compName The component to which the container is fed
-   * @return
-   */
-  public Container feedContainerToComp(Service service, int id,
-      String compName) {
-    ContainerId containerId = createContainerId(id);
-    return feedContainerToComp(service, containerId, compName);
-  }
-
-  /**
-   * Feeds the container to the component.
-   * @param service The service for the component
-   * @param containerId container id
-   * @param compName The component to which the container is fed
-   * @return
-   */
-  public Container feedContainerToComp(Service service, ContainerId containerId,
-      String compName) {
-    Container container = createContainer(containerId, compName);
-    synchronized (feedContainers) {
-      feedContainers.add(container);
-    }
-    addContainerStatus(container, ContainerState.RUNNING);
-    return container;
-  }
-
-  public void feedFailedContainerToComp(Service service, int id, String
-      compName) {
-    ApplicationId applicationId = ApplicationId.fromString(service.getId());
-    ContainerId containerId = ContainerId
-        .newContainerId(ApplicationAttemptId.newInstance(applicationId, 1), id);
-    ContainerStatus status = Records.newRecord(ContainerStatus.class);
-    status.setContainerId(containerId);
-    synchronized (failedContainers) {
-      failedContainers.add(status);
-    }
-  }
-
-  public Container updateContainerStatus(Service service, int id,
-      String compName, String host) {
-    ContainerId containerId = createContainerId(id);
-    Container container = createContainer(containerId, compName);
-    addContainerStatus(container, ContainerState.RUNNING, host);
-    return container;
-  }
-
-  public ContainerId createContainerId(int id) {
-    ApplicationId applicationId = ApplicationId.fromString(service.getId());
-    return ContainerId.newContainerId(
-        ApplicationAttemptId.newInstance(applicationId, 1), id);
-  }
-
-  private Container createContainer(ContainerId containerId, String compName) {
-    NodeId nodeId = NodeId.newInstance("localhost", 1234);
-    Container container = Container.newInstance(
-        containerId, nodeId, "localhost",
-        Resource.newInstance(100, 1),
-        Priority.newInstance(0), null);
-    long allocateId =
-        context.scheduler.getAllComponents().get(compName).getAllocateId();
-    container.setAllocationRequestId(allocateId);
-    return container;
-  }
-
-  public void flexComponent(String compName, long numberOfContainers)
-      throws IOException {
-    ClientAMProtocol.ComponentCountProto componentCountProto =
-        ClientAMProtocol.ComponentCountProto.newBuilder().setName(compName)
-            .setNumberOfContainers(numberOfContainers).build();
-    ClientAMProtocol.FlexComponentsRequestProto requestProto =
-        ClientAMProtocol.FlexComponentsRequestProto.newBuilder()
-            .addComponents(componentCountProto).build();
-    context.clientAMService.flexComponents(requestProto);
-  }
-
-  public Component getComponent(String compName) {
-    return context.scheduler.getAllComponents().get(compName);
-  }
-
-  public void waitForDependenciesSatisfied(String compName)
-      throws TimeoutException, InterruptedException {
-    GenericTestUtils.waitFor(new Supplier<Boolean>() {
-      @Override public Boolean get() {
-        return context.scheduler.getAllComponents().get(compName)
-            .areDependenciesReady();
-      }
-    }, 1000, 20000);
-  }
-
-  public void waitForNumDesiredContainers(String compName,
-      int numDesiredContainers) throws TimeoutException, InterruptedException {
-    GenericTestUtils.waitFor(new Supplier<Boolean>() {
-      @Override public Boolean get() {
-        return context.scheduler.getAllComponents().get(compName)
-            .getNumDesiredInstances() == numDesiredContainers;
-      }
-    }, 1000, 20000);
-  }
-
-
-  public ComponentInstance getCompInstance(String compName, String
-      instanceName) {
-    return context.scheduler.getAllComponents().get(compName)
-        .getComponentInstance(instanceName);
-  }
-
-  public void waitForCompInstanceState(ComponentInstance instance,
-      ComponentInstanceState state)
-      throws TimeoutException, InterruptedException {
-    GenericTestUtils.waitFor(new Supplier<Boolean>() {
-      @Override
-      public Boolean get() {
-        return instance.getState().equals(state);
-      }
-    }, 1000, 20000);
-  }
-
-  private void addContainerStatus(Container container, ContainerState state) {
-    addContainerStatus(container, state, container.getNodeId().getHost());
-  }
-
-  private void addContainerStatus(Container container, ContainerState state,
-      String host) {
-    ContainerStatus status = ContainerStatus.newInstance(container.getId(),
-        state, "", 0);
-    status.setHost(host);
-    status.setIPs(Lists.newArrayList(host));
-    containerStatuses.put(container.getId(), status);
-  }
-
-  @Override
-  protected ByteBuffer recordTokensForContainers()
-      throws IOException {
-    DataOutputBuffer dob = new DataOutputBuffer();
-    if (amCreds == null) {
-      return ByteBuffer.wrap(dob.getData(), 0, dob.getLength());
-    }
-    try {
-      amCreds.writeTokenStorageToStream(dob);
-    } finally {
-      dob.close();
-    }
-    return ByteBuffer.wrap(dob.getData(), 0, dob.getLength());
-  }
-
-  /**
-   * Waits for the container to get released
-   * @param containerId           ContainerId
-   */
-  public void waitForContainerToRelease(ContainerId containerId)
-      throws TimeoutException, InterruptedException {
-    GenericTestUtils.waitFor(() -> releasedContainers.contains(containerId),
-        1000, 30000);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/ServiceTestUtils.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/ServiceTestUtils.java
deleted file mode 100644
index b5ce0f17ac9..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/ServiceTestUtils.java
+++ /dev/null
@@ -1,584 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import com.fasterxml.jackson.databind.PropertyNamingStrategies;
-import org.apache.hadoop.thirdparty.com.google.common.base.Throwables;
-import org.apache.hadoop.thirdparty.com.google.common.collect.HashMultimap;
-import org.apache.hadoop.thirdparty.com.google.common.collect.Multimap;
-import org.apache.commons.io.FileUtils;
-import org.apache.curator.test.TestingCluster;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.hdfs.HdfsConfiguration;
-import org.apache.hadoop.hdfs.MiniDFSCluster;
-import org.apache.hadoop.http.HttpServer2;
-import org.apache.hadoop.registry.client.impl.zk.CuratorService;
-import org.apache.hadoop.service.ServiceOperations;
-import org.apache.hadoop.test.GenericTestUtils;
-import org.apache.hadoop.yarn.api.records.LocalResource;
-import org.apache.hadoop.yarn.client.api.YarnClient;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.server.MiniYARNCluster;
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.api.records.Container;
-import org.apache.hadoop.yarn.service.api.records.ContainerState;
-import org.apache.hadoop.yarn.service.api.records.Resource;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.client.ServiceClient;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConf;
-import org.apache.hadoop.yarn.service.exceptions.SliderException;
-import org.apache.hadoop.yarn.service.utils.JsonSerDeser;
-import org.apache.hadoop.yarn.service.utils.ServiceApiUtil;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-import org.apache.hadoop.yarn.util.LinuxResourceCalculatorPlugin;
-import org.apache.hadoop.yarn.util.ProcfsBasedProcessTree;
-import org.junit.rules.TestWatcher;
-import org.junit.runner.Description;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.ByteArrayOutputStream;
-import java.io.File;
-import java.io.FileOutputStream;
-import java.io.IOException;
-import java.io.OutputStream;
-import java.net.URL;
-import java.nio.file.Files;
-import java.nio.file.Paths;
-import java.util.List;
-import java.util.Map;
-import java.util.concurrent.TimeoutException;
-
-import static org.apache.hadoop.registry.client.api.RegistryConstants.KEY_REGISTRY_ZK_QUORUM;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.DEBUG_NM_DELETE_DELAY_SEC;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.NM_PMEM_CHECK_ENABLED;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.NM_VMEM_CHECK_ENABLED;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.TIMELINE_SERVICE_ENABLED;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.AM_RESOURCE_MEM;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.YARN_SERVICE_BASE_PATH;
-
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConstants
-    .CONTAINER_STATE_REPORT_AS_SERVICE_STATE;
-import static org.mockito.ArgumentMatchers.any;
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.when;
-
-public class ServiceTestUtils {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(ServiceTestUtils.class);
-
-  private MiniYARNCluster yarnCluster = null;
-  private MiniDFSCluster hdfsCluster = null;
-  private TestingCluster zkCluster;
-  private CuratorService curatorService;
-  private FileSystem fs = null;
-  private Configuration conf = null;
-  public static final int NUM_NMS = 1;
-  private File basedir;
-
-  public static final JsonSerDeser<Service> JSON_SER_DESER =
-      new JsonSerDeser<>(Service.class,
-          PropertyNamingStrategies.SNAKE_CASE);
-
-  // Example service definition
-  // 2 components, each of which has 2 containers.
-  public static Service createExampleApplication() {
-    Service exampleApp = new Service();
-    exampleApp.setName("example-app");
-    exampleApp.setVersion("v1");
-    exampleApp.addComponent(createComponent("compa"));
-    exampleApp.addComponent(createComponent("compb"));
-    return exampleApp;
-  }
-
-  // Example service definition
-  // 2 components, each of which has 2 containers.
-  public static Service createTerminatingJobExample(String serviceName) {
-    Service exampleApp = new Service();
-    exampleApp.setName(serviceName);
-    exampleApp.setVersion("v1");
-    exampleApp.addComponent(
-        createComponent("terminating-comp1", 2, "sleep 1000",
-            Component.RestartPolicyEnum.NEVER, null));
-    exampleApp.addComponent(
-        createComponent("terminating-comp2", 2, "sleep 1000",
-            Component.RestartPolicyEnum.ON_FAILURE, null));
-    exampleApp.addComponent(
-        createComponent("terminating-comp3", 2, "sleep 1000",
-            Component.RestartPolicyEnum.ON_FAILURE, null));
-
-    return exampleApp;
-  }
-
-  public static Service createTerminatingDominantComponentJobExample(
-      String serviceName) {
-    Service exampleApp = new Service();
-    exampleApp.setName(serviceName);
-    exampleApp.setVersion("v1");
-    Component serviceStateComponent = createComponent("terminating-comp1", 2,
-        "sleep 1000", Component.RestartPolicyEnum.NEVER, null);
-    serviceStateComponent.getConfiguration().setProperty(
-        CONTAINER_STATE_REPORT_AS_SERVICE_STATE, "true");
-    exampleApp.addComponent(serviceStateComponent);
-    exampleApp.addComponent(
-        createComponent("terminating-comp2", 2, "sleep 60000",
-            Component.RestartPolicyEnum.ON_FAILURE, null));
-
-    return exampleApp;
-  }
-
-  public static Component createComponent(String name) {
-    return createComponent(name, 2L, "sleep 1000",
-        Component.RestartPolicyEnum.ALWAYS, null);
-  }
-
-  protected static Component createComponent(String name, long numContainers,
-      String command) {
-    Component comp1 = new Component();
-    comp1.setNumberOfContainers(numContainers);
-    comp1.setLaunchCommand(command);
-    comp1.setName(name);
-    Resource resource = new Resource();
-    comp1.setResource(resource);
-    resource.setMemory("128");
-    resource.setCpus(1);
-    return comp1;
-  }
-
-  protected static Component createComponent(String name, long numContainers,
-      String command, Component.RestartPolicyEnum restartPolicyEnum,
-      List<String> dependencies) {
-    Component comp = createComponent(name, numContainers, command);
-    comp.setRestartPolicy(restartPolicyEnum);
-
-    if (dependencies != null) {
-      comp.dependencies(dependencies);
-    }
-    return comp;
-  }
-
-  public static SliderFileSystem initMockFs() throws IOException {
-    return initMockFs(null);
-  }
-
-  public static SliderFileSystem initMockFs(Service ext) throws IOException {
-    SliderFileSystem sfs = mock(SliderFileSystem.class);
-    FileSystem mockFs = mock(FileSystem.class);
-    JsonSerDeser<Service> jsonSerDeser = mock(JsonSerDeser.class);
-    when(sfs.getFileSystem()).thenReturn(mockFs);
-    when(sfs.buildClusterDirPath(any())).thenReturn(
-        new Path("cluster_dir_path"));
-    if (ext != null) {
-      when(jsonSerDeser.load(any(), any())).thenReturn(ext);
-    }
-    ServiceApiUtil.setJsonSerDeser(jsonSerDeser);
-    return sfs;
-  }
-
-  protected void setConf(YarnConfiguration conf) {
-    this.conf = conf;
-  }
-
-  protected Configuration getConf() {
-    return conf;
-  }
-
-  protected FileSystem getFS() {
-    return fs;
-  }
-
-  protected MiniYARNCluster getYarnCluster() {
-    return yarnCluster;
-  }
-
-  protected void setupInternal(int numNodeManager)
-      throws Exception {
-    LOG.info("Starting up YARN cluster");
-    if (conf == null) {
-      setConf(new YarnConfiguration());
-      conf.setBoolean(YarnConfiguration.YARN_MINICLUSTER_FIXED_PORTS, false);
-      conf.setBoolean(YarnConfiguration.YARN_MINICLUSTER_USE_RPC, false);
-      conf.setInt(YarnConfiguration.RM_MAX_COMPLETED_APPLICATIONS,
-          YarnConfiguration.DEFAULT_RM_MAX_COMPLETED_APPLICATIONS);
-    }
-    conf.setInt(YarnConfiguration.RM_SCHEDULER_MINIMUM_ALLOCATION_MB, 128);
-    // reduce the teardown waiting time
-    conf.setLong(YarnConfiguration.DISPATCHER_DRAIN_EVENTS_TIMEOUT, 1000);
-    conf.set("yarn.log.dir", "target");
-    // mark if we need to launch the v1 timeline server
-    // disable aux-service based timeline aggregators
-    conf.set(YarnConfiguration.NM_AUX_SERVICES, "");
-    conf.set(YarnConfiguration.NM_VMEM_PMEM_RATIO, "8");
-    // Enable ContainersMonitorImpl
-    conf.set(YarnConfiguration.NM_CONTAINER_MON_RESOURCE_CALCULATOR,
-        LinuxResourceCalculatorPlugin.class.getName());
-    conf.set(YarnConfiguration.NM_CONTAINER_MON_PROCESS_TREE,
-        ProcfsBasedProcessTree.class.getName());
-    conf.setBoolean(
-        YarnConfiguration.YARN_MINICLUSTER_CONTROL_RESOURCE_MONITORING, true);
-    conf.setBoolean(TIMELINE_SERVICE_ENABLED, false);
-    conf.setInt(YarnConfiguration.NM_MAX_PER_DISK_UTILIZATION_PERCENTAGE, 100);
-    conf.setLong(DEBUG_NM_DELETE_DELAY_SEC, 60000);
-    conf.setLong(AM_RESOURCE_MEM, 526);
-    conf.setLong(YarnServiceConf.READINESS_CHECK_INTERVAL, 5);
-    // Disable vmem check to disallow NM killing the container
-    conf.setBoolean(NM_VMEM_CHECK_ENABLED, false);
-    conf.setBoolean(NM_PMEM_CHECK_ENABLED, false);
-    // set auth filters
-    conf.set(HttpServer2.FILTER_INITIALIZER_PROPERTY,
-        "org.apache.hadoop.security.AuthenticationFilterInitializer,"
-            + "org.apache.hadoop.security.HttpCrossOriginFilterInitializer");
-    // setup zk cluster
-    zkCluster = new TestingCluster(1);
-    zkCluster.start();
-    conf.set(YarnConfiguration.RM_ZK_ADDRESS, zkCluster.getConnectString());
-    conf.set(KEY_REGISTRY_ZK_QUORUM, zkCluster.getConnectString());
-    LOG.info("ZK cluster: " + zkCluster.getConnectString());
-
-    curatorService = new CuratorService("testCuratorService");
-    curatorService.init(conf);
-    curatorService.start();
-
-    fs = FileSystem.get(conf);
-    basedir = new File("target", "apps");
-    if (basedir.exists()) {
-      FileUtils.deleteDirectory(basedir);
-    } else {
-      basedir.mkdirs();
-    }
-
-    conf.set(YARN_SERVICE_BASE_PATH, basedir.getAbsolutePath());
-
-    if (yarnCluster == null) {
-      yarnCluster =
-          new MiniYARNCluster(this.getClass().getSimpleName(), 1,
-              numNodeManager, 1, 1);
-      yarnCluster.init(conf);
-      yarnCluster.start();
-
-      waitForNMsToRegister();
-
-      URL url = Thread.currentThread().getContextClassLoader()
-          .getResource("yarn-site.xml");
-      if (url == null) {
-        throw new RuntimeException(
-            "Could not find 'yarn-site.xml' dummy file in classpath");
-      }
-      Configuration yarnClusterConfig = yarnCluster.getConfig();
-      yarnClusterConfig.set(YarnConfiguration.YARN_APPLICATION_CLASSPATH,
-          new File(url.getPath()).getParent());
-      //write the document to a buffer (not directly to the file, as that
-      //can cause the file being written to get read -which will then fail.
-      ByteArrayOutputStream bytesOut = new ByteArrayOutputStream();
-      yarnClusterConfig.writeXml(bytesOut);
-      bytesOut.close();
-      //write the bytes to the file in the classpath
-      OutputStream os = new FileOutputStream(new File(url.getPath()));
-      os.write(bytesOut.toByteArray());
-      os.close();
-      LOG.info("Write yarn-site.xml configs to: " + url);
-    }
-    if (hdfsCluster == null) {
-      HdfsConfiguration hdfsConfig = new HdfsConfiguration();
-      hdfsCluster = new MiniDFSCluster.Builder(hdfsConfig)
-          .numDataNodes(1).build();
-    }
-
-    try {
-      Thread.sleep(2000);
-    } catch (InterruptedException e) {
-      LOG.info("setup thread sleep interrupted. message=" + e.getMessage());
-    }
-  }
-
-  public void shutdown() throws IOException {
-    if (yarnCluster != null) {
-      try {
-        yarnCluster.stop();
-      } finally {
-        yarnCluster = null;
-      }
-    }
-    if (hdfsCluster != null) {
-      try {
-        hdfsCluster.shutdown();
-      } finally {
-        hdfsCluster = null;
-      }
-    }
-    if (curatorService != null) {
-      ServiceOperations.stop(curatorService);
-    }
-    if (zkCluster != null) {
-      zkCluster.stop();
-    }
-    if (basedir != null) {
-      FileUtils.deleteDirectory(basedir);
-    }
-    SliderFileSystem sfs = new SliderFileSystem(conf);
-    Path appDir = sfs.getBaseApplicationPath();
-    sfs.getFileSystem().delete(appDir, true);
-  }
-
-  private void waitForNMsToRegister() throws Exception {
-    int sec = 60;
-    while (sec >= 0) {
-      if (yarnCluster.getResourceManager().getRMContext().getRMNodes().size()
-          >= NUM_NMS) {
-        break;
-      }
-      Thread.sleep(1000);
-      sec--;
-    }
-  }
-
-  /**
-   * Creates a {@link ServiceClient} for test purposes.
-   */
-  public static ServiceClient createClient(Configuration conf)
-      throws Exception {
-    ServiceClient client = new ServiceClient() {
-      @Override
-      protected Path addJarResource(String appName,
-          Map<String, LocalResource> localResources)
-          throws IOException, SliderException {
-        // do nothing, the Unit test will use local jars
-        return null;
-      }
-    };
-    client.init(conf);
-    client.start();
-    return client;
-  }
-
-  public static ServiceManager createServiceManager(ServiceContext context) {
-    ServiceManager serviceManager = new ServiceManager(context);
-    context.setServiceManager(serviceManager);
-    return serviceManager;
-  }
-
-  /**
-   * Creates a YarnClient for test purposes.
-   */
-  public static YarnClient createYarnClient(Configuration conf) {
-    YarnClient client = YarnClient.createYarnClient();
-    client.init(conf);
-    client.start();
-    return client;
-  }
-
-  protected CuratorService getCuratorService() throws IOException {
-    return curatorService;
-  }
-
-  /**
-   * Watcher to initialize yarn service base path under target and deletes the
-   * the test directory when finishes.
-   */
-  public static class ServiceFSWatcher extends TestWatcher {
-    private YarnConfiguration conf;
-    private SliderFileSystem fs;
-    private java.nio.file.Path serviceBasePath;
-
-    @Override
-    protected void starting(Description description) {
-      conf = new YarnConfiguration();
-      delete(description);
-      serviceBasePath = Paths.get("target",
-          description.getClassName(), description.getMethodName());
-      conf.set(YARN_SERVICE_BASE_PATH, serviceBasePath.toString());
-      try {
-        Files.createDirectories(serviceBasePath);
-        fs = new SliderFileSystem(conf);
-        fs.setAppDir(new Path(serviceBasePath.toString()));
-      } catch (IOException e) {
-        Throwables.throwIfUnchecked(e);
-        throw new RuntimeException(e);
-      }
-    }
-
-    @Override
-    protected void finished(Description description) {
-      delete(description);
-    }
-
-    private void delete(Description description) {
-      FileUtils.deleteQuietly(Paths.get("target",
-          description.getClassName()).toFile());
-    }
-
-    /**
-     * Returns the yarn conf.
-     */
-    public YarnConfiguration getConf() {
-      return conf;
-    }
-
-    /**
-     * Returns the file system.
-     */
-    public SliderFileSystem getFs() {
-      return fs;
-    }
-
-    /**
-     * Returns the test service base path.
-     */
-    public java.nio.file.Path getServiceBasePath() {
-      return serviceBasePath;
-    }
-  }
-
-  /**
-   * Wait until all the containers for all components become ready state.
-   *
-   * @param client
-   * @param exampleApp
-   * @return all ready containers of a service.
-   * @throws TimeoutException
-   * @throws InterruptedException
-   */
-  protected Multimap<String, String> waitForAllCompToBeReady(ServiceClient
-      client, Service exampleApp) throws TimeoutException,
-      InterruptedException {
-    int expectedTotalContainers = countTotalContainers(exampleApp);
-
-    Multimap<String, String> allContainers = HashMultimap.create();
-
-    GenericTestUtils.waitFor(() -> {
-      try {
-        Service retrievedApp = client.getStatus(exampleApp.getName());
-        int totalReadyContainers = 0;
-        allContainers.clear();
-        LOG.info("Num Components " + retrievedApp.getComponents().size());
-        for (Component component : retrievedApp.getComponents()) {
-          LOG.info("looking for  " + component.getName());
-          LOG.info(component.toString());
-          if (component.getContainers() != null) {
-            if (component.getContainers().size() == exampleApp
-                .getComponent(component.getName()).getNumberOfContainers()) {
-              for (Container container : component.getContainers()) {
-                LOG.info(
-                    "Container state " + container.getState() + ", component "
-                        + component.getName());
-                if (container.getState() == ContainerState.READY) {
-                  totalReadyContainers++;
-                  allContainers.put(component.getName(), container.getId());
-                  LOG.info("Found 1 ready container " + container.getId());
-                }
-              }
-            } else {
-              LOG.info(component.getName() + " Expected number of containers "
-                  + exampleApp.getComponent(component.getName())
-                  .getNumberOfContainers() + ", current = " + component
-                  .getContainers());
-            }
-          }
-        }
-        LOG.info("Exit loop, totalReadyContainers= " + totalReadyContainers
-            + " expected = " + expectedTotalContainers);
-        return totalReadyContainers == expectedTotalContainers;
-      } catch (Exception e) {
-        e.printStackTrace();
-        return false;
-      }
-    }, 2000, 200000);
-    return allContainers;
-  }
-
-  /**
-   * Wait until service state becomes stable. A service is stable when all
-   * requested containers of all components are running and in ready state.
-   *
-   * @param client
-   * @param exampleApp
-   * @throws TimeoutException
-   * @throws InterruptedException
-   */
-  protected void waitForServiceToBeStable(ServiceClient client,
-      Service exampleApp) throws TimeoutException, InterruptedException {
-    waitForServiceToBeStable(client, exampleApp, 200000);
-  }
-
-  protected void waitForServiceToBeStable(ServiceClient client,
-      Service exampleApp, int waitForMillis)
-      throws TimeoutException, InterruptedException {
-    waitForServiceToBeInState(client, exampleApp, ServiceState.STABLE,
-        waitForMillis);
-  }
-
-  /**
-   * Wait until service is started. It does not have to reach a stable state.
-   *
-   * @param client
-   * @param exampleApp
-   * @throws TimeoutException
-   * @throws InterruptedException
-   */
-  protected void waitForServiceToBeStarted(ServiceClient client,
-      Service exampleApp) throws TimeoutException, InterruptedException {
-    waitForServiceToBeInState(client, exampleApp, ServiceState.STARTED);
-  }
-
-  protected void waitForServiceToBeExpressUpgrading(ServiceClient client,
-      Service exampleApp) throws TimeoutException, InterruptedException {
-    waitForServiceToBeInState(client, exampleApp,
-        ServiceState.EXPRESS_UPGRADING);
-  }
-
-  protected void waitForServiceToBeInState(ServiceClient client,
-      Service exampleApp, ServiceState desiredState) throws TimeoutException,
-      InterruptedException {
-    waitForServiceToBeInState(client, exampleApp, desiredState, 200000);
-  }
-
-  /**
-   * Wait until service is started. It does not have to reach a stable state.
-   *
-   * @param client
-   * @param exampleApp
-   * @throws TimeoutException
-   * @throws InterruptedException
-   */
-  protected void waitForServiceToBeInState(ServiceClient client,
-      Service exampleApp, ServiceState desiredState, int waitForMillis) throws
-      TimeoutException, InterruptedException {
-    GenericTestUtils.waitFor(() -> {
-      try {
-        Service retrievedApp = client.getStatus(exampleApp.getName());
-        return retrievedApp.getState() == desiredState;
-      } catch (Exception e) {
-        e.printStackTrace();
-        return false;
-      }
-    }, 2000, waitForMillis);
-  }
-
-  private int countTotalContainers(Service service) {
-    int totalContainers = 0;
-    for (Component component : service.getComponents()) {
-      totalContainers += component.getNumberOfContainers();
-    }
-    return totalContainers;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/TestDefaultUpgradeComponentsFinder.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/TestDefaultUpgradeComponentsFinder.java
deleted file mode 100644
index 012f204239b..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/TestDefaultUpgradeComponentsFinder.java
+++ /dev/null
@@ -1,123 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service;
-
-import org.apache.hadoop.util.Lists;
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.api.records.ConfigFile;
-import org.apache.hadoop.yarn.service.api.records.Configuration;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.junit.Assert;
-import org.junit.Test;
-
-import java.util.*;
-
-import static org.junit.Assert.assertEquals;
-
-/**
- * Tests for {@link UpgradeComponentsFinder.DefaultUpgradeComponentsFinder}.
- */
-public class TestDefaultUpgradeComponentsFinder {
-
-  private UpgradeComponentsFinder.DefaultUpgradeComponentsFinder finder =
-      new UpgradeComponentsFinder.DefaultUpgradeComponentsFinder();
-
-  @Test
-  public void testServiceArtifactChange() {
-    Service currentDef = ServiceTestUtils.createExampleApplication();
-    Service targetDef =  ServiceTestUtils.createExampleApplication();
-    targetDef.getComponents().forEach(x -> x.setArtifact(
-        TestServiceManager.createTestArtifact("v1")));
-
-    assertEquals("all components need upgrade",
-        targetDef.getComponents(), finder.findTargetComponentSpecs(currentDef,
-            targetDef));
-  }
-
-  @Test
-  public void testServiceUpgradeWithNewComponentAddition() {
-    Service currentDef = ServiceTestUtils.createExampleApplication();
-    Service targetDef = ServiceTestUtils.createExampleApplication();
-    Iterator<Component> targetComponentsIter =
-        targetDef.getComponents().iterator();
-    Component firstComponent = targetComponentsIter.next();
-    firstComponent.setName("newComponentA");
-
-    try {
-      finder.findTargetComponentSpecs(currentDef, targetDef);
-      Assert.fail("Expected error since component does not exist in service "
-          + "definition");
-    } catch (UnsupportedOperationException usoe) {
-      assertEquals(
-          "addition/deletion of components not supported by upgrade. Could "
-              + "not find component newComponentA in current service "
-              + "definition.",
-          usoe.getMessage());
-      //Expected
-    }
-  }
-
-  @Test
-  public void testComponentArtifactChange() {
-    Service currentDef = TestServiceManager.createBaseDef("test");
-    Service targetDef =  TestServiceManager.createBaseDef("test");
-
-    targetDef.getComponents().get(0).setArtifact(
-        TestServiceManager.createTestArtifact("v2"));
-
-    List<Component> expected = new ArrayList<>();
-    expected.add(targetDef.getComponents().get(0));
-
-    assertEquals("single components needs upgrade",
-        expected, finder.findTargetComponentSpecs(currentDef,
-            targetDef));
-  }
-
-  @Test
-  public void testChangeInConfigFileProperty() {
-    ConfigFile file = new ConfigFile().srcFile("src").destFile("dest")
-        .type(ConfigFile.TypeEnum.HADOOP_XML);
-
-    Map<String, String> props = new HashMap<>();
-    props.put("k1", "v1");
-    file.setProperties(props);
-
-    Configuration conf = new Configuration().files(Lists.newArrayList(file));
-
-    Service currentDef = TestServiceManager.createBaseDef("test");
-    currentDef.setConfiguration(conf);
-
-    // new spec has changes in config file property
-    file = new ConfigFile().srcFile("src").destFile("dest")
-        .type(ConfigFile.TypeEnum.HADOOP_XML);
-    Map<String, String> changedProps = new HashMap<>();
-    changedProps.put("k1", "v2");
-    file.setProperties(changedProps);
-
-    conf = new Configuration().files(Lists.newArrayList(file));
-
-    Service targetDef =  TestServiceManager.createBaseDef("test");
-    targetDef.setConfiguration(conf);
-
-    List<Component> expected = new ArrayList<>();
-    expected.addAll(targetDef.getComponents());
-
-    assertEquals("all components needs upgrade",
-        expected, finder.findTargetComponentSpecs(currentDef, targetDef));
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/TestServiceAM.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/TestServiceAM.java
deleted file mode 100644
index 69c0c2cee57..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/TestServiceAM.java
+++ /dev/null
@@ -1,607 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import org.apache.hadoop.thirdparty.com.google.common.collect.ImmutableMap;
-import org.apache.commons.io.FileUtils;
-import org.apache.curator.test.TestingCluster;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.metrics2.lib.DefaultMetricsSystem;
-import org.apache.hadoop.security.Credentials;
-import org.apache.hadoop.security.token.Token;
-import org.apache.hadoop.security.token.TokenIdentifier;
-import org.apache.hadoop.test.GenericTestUtils;
-import org.apache.hadoop.yarn.api.protocolrecords.ResourceTypes;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.api.records.ContainerStatus;
-import org.apache.hadoop.yarn.api.records.ResourceTypeInfo;
-import org.apache.hadoop.yarn.client.api.AMRMClient;
-import org.apache.hadoop.yarn.client.api.async.AMRMClientAsync;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.event.AsyncDispatcher;
-import org.apache.hadoop.yarn.event.Event;
-import org.apache.hadoop.yarn.event.EventHandler;
-import org.apache.hadoop.yarn.security.DockerCredentialTokenIdentifier;
-import org.apache.hadoop.yarn.service.api.records.Artifact;
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.api.records.ResourceInformation;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.component.ComponentState;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceState;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConf;
-import org.apache.hadoop.yarn.util.DockerClientConfigHandler;
-import org.apache.hadoop.yarn.util.resource.ResourceUtils;
-import org.junit.After;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Rule;
-import org.junit.Test;
-import org.mockito.Mockito;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.BufferedWriter;
-import java.io.File;
-import java.io.FileWriter;
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.List;
-import java.util.concurrent.TimeoutException;
-
-import static org.apache.hadoop.registry.client.api.RegistryConstants.KEY_REGISTRY_ZK_QUORUM;
-import static org.junit.Assert.assertEquals;
-import static org.mockito.Mockito.times;
-import static org.mockito.Mockito.verify;
-
-public class TestServiceAM extends ServiceTestUtils{
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestServiceAM.class);
-
-  private File basedir;
-  YarnConfiguration conf = new YarnConfiguration();
-  TestingCluster zkCluster;
-  @Rule
-  public ServiceTestUtils.ServiceFSWatcher rule =
-      new ServiceTestUtils.ServiceFSWatcher();
-
-  @Before
-  public void setup() throws Exception {
-    basedir = new File("target", "apps");
-    if (basedir.exists()) {
-      FileUtils.deleteDirectory(basedir);
-    } else {
-      basedir.mkdirs();
-    }
-    zkCluster = new TestingCluster(1);
-    zkCluster.start();
-    conf.set(KEY_REGISTRY_ZK_QUORUM, zkCluster.getConnectString());
-    LOG.info("ZK cluster: {}", zkCluster.getConnectString());
-  }
-
-  @After
-  public void tearDown() throws IOException {
-    if (basedir != null) {
-      FileUtils.deleteDirectory(basedir);
-    }
-    if (zkCluster != null) {
-      zkCluster.stop();
-    }
-  }
-
-  // Race condition YARN-7486
-  // 1. Allocate 1 container to compa and wait it to be started
-  // 2. Fail this container, and in the meanwhile allocate the 2nd container.
-  // 3. The 2nd container should not be assigned to compa-0 instance, because
-  //   the compa-0 instance is not stopped yet.
-  // 4. check compa still has the instance in the pending list.
-  @Test
-  public void testContainerCompleted() throws TimeoutException,
-      InterruptedException {
-    ApplicationId applicationId = ApplicationId.newInstance(123456, 1);
-    Service exampleApp = new Service();
-    exampleApp.setId(applicationId.toString());
-    exampleApp.setVersion("v1");
-    exampleApp.setName("testContainerCompleted");
-    exampleApp.addComponent(createComponent("compa", 1, "pwd"));
-
-    MockServiceAM am = new MockServiceAM(exampleApp);
-    am.init(conf);
-    am.start();
-
-    ComponentInstance compa0 = am.getCompInstance("compa", "compa-0");
-    // allocate a container
-    am.feedContainerToComp(exampleApp, 1, "compa");
-    am.waitForCompInstanceState(compa0, ComponentInstanceState.STARTED);
-
-    LOG.info("Fail the container 1");
-    // fail the container
-    am.feedFailedContainerToComp(exampleApp, 1, "compa");
-
-    // allocate the second container immediately, this container will not be
-    // assigned to comp instance
-    // because the instance is not yet added to the pending list.
-    am.feedContainerToComp(exampleApp, 2, "compa");
-
-    am.waitForCompInstanceState(compa0, ComponentInstanceState.INIT);
-    // still 1 pending instance
-    Assert.assertEquals(1,
-        am.getComponent("compa").getPendingInstances().size());
-    am.stop();
-  }
-
-  // Test to verify that the containers of previous attempt are not prematurely
-  // released. These containers are sent by the RM to the AM in the
-  // heartbeat response.
-  @Test(timeout = 200000)
-  public void testContainersFromPreviousAttemptsWithRMRestart()
-      throws Exception {
-    ApplicationId applicationId = ApplicationId.newInstance(
-        System.currentTimeMillis(), 1);
-    Service exampleApp = new Service();
-    exampleApp.setId(applicationId.toString());
-    exampleApp.setVersion("v1");
-    exampleApp.setName("testContainersRecovers");
-    String comp1Name = "comp1";
-    String comp1InstName = "comp1-0";
-
-    org.apache.hadoop.yarn.service.api.records.Component compA =
-        createComponent(comp1Name, 1, "sleep");
-    exampleApp.addComponent(compA);
-
-    MockServiceAM am = new MockServiceAM(exampleApp);
-    ContainerId containerId = am.createContainerId(1);
-    am.feedRegistryComponent(containerId, comp1Name, comp1InstName);
-    am.init(conf);
-    am.start();
-
-    ComponentInstance comp10 = am.getCompInstance(comp1Name, comp1InstName);
-    am.feedRecoveredContainer(containerId, comp1Name);
-    am.waitForCompInstanceState(comp10, ComponentInstanceState.STARTED);
-
-    // 0 pending instance
-    Assert.assertEquals(0,
-        am.getComponent(comp1Name).getPendingInstances().size());
-
-    GenericTestUtils.waitFor(() -> am.getCompInstance(comp1Name, comp1InstName)
-        .getContainerStatus() != null, 2000, 200000);
-
-    Assert.assertEquals("container state",
-        org.apache.hadoop.yarn.api.records.ContainerState.RUNNING,
-        am.getCompInstance(comp1Name, comp1InstName).getContainerStatus()
-            .getState());
-    am.stop();
-  }
-
-  // Test to verify that the containers of previous attempt are released and the
-  // component instance is added to the pending queue when the recovery wait
-  // time interval elapses.
-  @Test(timeout = 200000)
-  public void testContainersReleasedWhenExpired()
-      throws Exception {
-    ApplicationId applicationId = ApplicationId.newInstance(
-        System.currentTimeMillis(), 1);
-    Service exampleApp = new Service();
-    exampleApp.setId(applicationId.toString());
-    exampleApp.setName("testContainersRecovers");
-    exampleApp.setVersion("v1");
-    String comp1Name = "comp1";
-    String comp1InstName = "comp1-0";
-
-    org.apache.hadoop.yarn.service.api.records.Component compA =
-        createComponent(comp1Name, 1, "sleep");
-    exampleApp.addComponent(compA);
-
-    MockServiceAM am = new MockServiceAM(exampleApp);
-    ContainerId containerId = am.createContainerId(1);
-    am.feedRegistryComponent(containerId, comp1Name, comp1InstName);
-    conf.setLong(YarnServiceConf.CONTAINER_RECOVERY_TIMEOUT_MS, 10);
-    am.init(conf);
-    am.start();
-    Thread.sleep(100);
-    GenericTestUtils.waitFor(() -> am.getComponent(comp1Name).getState()
-        .equals(ComponentState.FLEXING), 100, 2000);
-
-    // 1 pending instance
-    Assert.assertEquals(1, am.getComponent(comp1Name).getPendingInstances()
-        .size());
-
-    am.feedContainerToComp(exampleApp, 2, comp1Name);
-
-    GenericTestUtils.waitFor(() -> am.getCompInstance(comp1Name, comp1InstName)
-        .getContainerStatus() != null, 2000, 200000);
-    Assert.assertEquals("container state",
-        org.apache.hadoop.yarn.api.records.ContainerState.RUNNING,
-        am.getCompInstance(comp1Name, comp1InstName).getContainerStatus()
-            .getState());
-  }
-
-  // Test to verify that the AM doesn't wait for containers of a different app
-  // even though it corresponds to the same service.
-  @Test(timeout = 200000)
-  public void testContainersFromDifferentApp()
-      throws Exception {
-    ApplicationId applicationId = ApplicationId.newInstance(
-        System.currentTimeMillis(), 1);
-    Service exampleApp = new Service();
-    exampleApp.setId(applicationId.toString());
-    exampleApp.setName("testContainersFromDifferentApp");
-    exampleApp.setVersion("v1");
-    String comp1Name = "comp1";
-    String comp1InstName = "comp1-0";
-
-    org.apache.hadoop.yarn.service.api.records.Component compA =
-        createComponent(comp1Name, 1, "sleep");
-    exampleApp.addComponent(compA);
-
-    MockServiceAM am = new MockServiceAM(exampleApp);
-    ContainerId containerId = am.createContainerId(1);
-    // saves the container in the registry
-    am.feedRegistryComponent(containerId, comp1Name, comp1InstName);
-
-    ApplicationId changedAppId = ApplicationId.newInstance(
-        System.currentTimeMillis(), 2);
-    exampleApp.setId(changedAppId.toString());
-    am.init(conf);
-    am.start();
-    // 1 pending instance since the container in registry belongs to a different
-    // app.
-    Assert.assertEquals(1,
-        am.getComponent(comp1Name).getPendingInstances().size());
-
-    am.feedContainerToComp(exampleApp, 1, comp1Name);
-    GenericTestUtils.waitFor(() -> am.getCompInstance(comp1Name, comp1InstName)
-        .getContainerStatus() != null, 2000, 200000);
-
-    Assert.assertEquals("container state",
-        org.apache.hadoop.yarn.api.records.ContainerState.RUNNING,
-        am.getCompInstance(comp1Name, comp1InstName).getContainerStatus()
-            .getState());
-    am.stop();
-  }
-
-  @Test
-  public void testScheduleWithMultipleResourceTypes()
-      throws TimeoutException, InterruptedException, IOException {
-    ApplicationId applicationId = ApplicationId.newInstance(123456, 1);
-    Service exampleApp = new Service();
-    exampleApp.setId(applicationId.toString());
-    exampleApp.setName("testScheduleWithMultipleResourceTypes");
-    exampleApp.setVersion("v1");
-
-    List<ResourceTypeInfo> resourceTypeInfos = new ArrayList<>(
-        ResourceUtils.getResourcesTypeInfo());
-    // Add 3rd resource type.
-    resourceTypeInfos.add(ResourceTypeInfo
-        .newInstance("resource-1", "", ResourceTypes.COUNTABLE));
-    // Reinitialize resource types
-    ResourceUtils.reinitializeResources(resourceTypeInfos);
-
-    Component serviceCompoent = createComponent("compa", 1, "pwd");
-    serviceCompoent.getResource().setResourceInformations(ImmutableMap
-        .of("resource-1", new ResourceInformation().value(3333L).unit("Gi")));
-    exampleApp.addComponent(serviceCompoent);
-
-    MockServiceAM am = new MockServiceAM(exampleApp);
-    am.init(conf);
-    am.start();
-
-    ServiceScheduler serviceScheduler = am.context.scheduler;
-    AMRMClientAsync<AMRMClient.ContainerRequest> amrmClientAsync =
-        serviceScheduler.getAmRMClient();
-
-    Collection<AMRMClient.ContainerRequest> rr =
-        amrmClientAsync.getMatchingRequests(0);
-    Assert.assertEquals(1, rr.size());
-
-    org.apache.hadoop.yarn.api.records.Resource capability =
-        rr.iterator().next().getCapability();
-    Assert.assertEquals(3333L, capability.getResourceValue("resource-1"));
-    Assert.assertEquals("Gi",
-        capability.getResourceInformation("resource-1").getUnits());
-
-    am.stop();
-  }
-
-  @Test
-  public void testContainerCompletedEventProcessed() throws Exception {
-    ServiceContext context = createServiceContext("abc");
-    MockServiceScheduler scheduler = new MockServiceScheduler(context);
-    scheduler.init(conf);
-    ApplicationId appId = ApplicationId.newInstance(0, 0);
-    ApplicationAttemptId appAttemptId = ApplicationAttemptId.newInstance(appId,
-        1);
-    ContainerId containerId1 = ContainerId.newContainerId(appAttemptId, 0);
-    ContainerStatus containerStatus1 = ContainerStatus.newInstance(containerId1,
-        org.apache.hadoop.yarn.api.records.ContainerState.COMPLETE,
-        "successful", 0);
-    ContainerId containerId2 = ContainerId.newContainerId(appAttemptId, 1);
-    ContainerStatus containerStatus2 = ContainerStatus.newInstance(containerId2,
-        org.apache.hadoop.yarn.api.records.ContainerState.COMPLETE,
-        "successful", 0);
-    ComponentInstance instance = Mockito.mock(ComponentInstance.class);
-    Mockito.doReturn("componentInstance").when(instance).getCompName();
-    scheduler.addLiveCompInstance(containerId2, instance);
-    List<ContainerStatus> statuses = new ArrayList<>();
-    // First container instance will be null
-    statuses.add(containerStatus1);
-    // Second container instance is added
-    scheduler.addLiveCompInstance(containerId2, instance);
-    statuses.add(containerStatus2);
-    scheduler.callbackHandler.onContainersCompleted(statuses);
-    // For second container event should be dispatched.
-    verify(scheduler.dispatcher, times(1)).getEventHandler();
-    DefaultMetricsSystem.shutdown();
-  }
-
-  private ServiceContext createServiceContext(String name)
-      throws Exception {
-    Artifact artifact = new Artifact();
-    artifact.setId("1");
-    artifact.setType(Artifact.TypeEnum.TARBALL);
-    Service serviceDef = ServiceTestUtils.createExampleApplication();
-    ApplicationId applicationId = ApplicationId.newInstance(
-        System.currentTimeMillis(), 1);
-    serviceDef.setId(applicationId.toString());
-    serviceDef.setName(name);
-    serviceDef.setState(ServiceState.STARTED);
-    serviceDef.getComponents().forEach(component ->
-        component.setArtifact(artifact));
-    ServiceContext context = new MockRunningServiceContext(rule,
-        serviceDef);
-    context.scheduler.getDispatcher().setDrainEventsOnStop();
-    context.scheduler.getDispatcher().start();
-    return context;
-  }
-
-  class MockServiceScheduler extends ServiceScheduler {
-    private AsyncDispatcher dispatcher;
-    private AMRMClientCallback callbackHandler = new AMRMClientCallback();
-
-    MockServiceScheduler(ServiceContext context) {
-      super(context);
-    }
-
-    @Override
-    protected AsyncDispatcher createAsyncDispatcher() {
-      dispatcher = Mockito.mock(AsyncDispatcher.class);
-      EventHandler<Event> handler = Mockito.mock(EventHandler.class);
-      Mockito.doReturn(handler).when(dispatcher).getEventHandler();
-      return dispatcher;
-    }
-
-    @Override
-    protected AMRMClientAsync<AMRMClient.ContainerRequest> createAMRMClient() {
-      return AMRMClientAsync.createAMRMClientAsync(1000, callbackHandler);
-    }
-
-  }
-
-  @Test
-  public void testRecordTokensForContainers() throws Exception {
-    ApplicationId applicationId = ApplicationId.newInstance(123456, 1);
-    Service exampleApp = new Service();
-    exampleApp.setId(applicationId.toString());
-    exampleApp.setName("testContainerCompleted");
-    exampleApp.addComponent(createComponent("compa", 1, "pwd"));
-
-    String json = "{\"auths\": "
-        + "{\"https://index.docker.io/v1/\": "
-        + "{\"auth\": \"foobarbaz\"},"
-        + "\"registry.example.com\": "
-        + "{\"auth\": \"bazbarfoo\"}}}";
-    File dockerTmpDir = new File("target", "docker-tmp");
-    FileUtils.deleteQuietly(dockerTmpDir);
-    dockerTmpDir.mkdirs();
-    String dockerConfig = dockerTmpDir + "/config.json";
-    BufferedWriter bw = new BufferedWriter(new FileWriter(dockerConfig));
-    bw.write(json);
-    bw.close();
-    Credentials dockerCred =
-        DockerClientConfigHandler.readCredentialsFromConfigFile(
-            new Path(dockerConfig), conf, applicationId.toString());
-
-
-    MockServiceAM am = new MockServiceAM(exampleApp, dockerCred);
-    ByteBuffer amCredBuffer = am.recordTokensForContainers();
-    Credentials amCreds =
-        DockerClientConfigHandler.getCredentialsFromTokensByteBuffer(
-            amCredBuffer);
-
-    assertEquals(2, amCreds.numberOfTokens());
-    for (Token<? extends TokenIdentifier> tk : amCreds.getAllTokens()) {
-      Assert.assertTrue(
-          tk.getKind().equals(DockerCredentialTokenIdentifier.KIND));
-    }
-
-    am.stop();
-  }
-
-  @Test
-  public void testIPChange() throws TimeoutException,
-      InterruptedException {
-    ApplicationId applicationId = ApplicationId.newInstance(123456, 1);
-    String comp1Name = "comp1";
-    String comp1InstName = "comp1-0";
-    Service exampleApp = new Service();
-    exampleApp.setId(applicationId.toString());
-    exampleApp.setVersion("v1");
-    exampleApp.setName("testIPChange");
-    Component comp1 = createComponent(comp1Name, 1, "sleep 60");
-    comp1.setArtifact(new Artifact().type(Artifact.TypeEnum.DOCKER));
-    exampleApp.addComponent(comp1);
-
-    MockServiceAM am = new MockServiceAM(exampleApp);
-    am.init(conf);
-    am.start();
-
-    ComponentInstance comp1inst0 = am.getCompInstance(comp1Name, comp1InstName);
-    // allocate a container
-    am.feedContainerToComp(exampleApp, 1, comp1Name);
-    GenericTestUtils.waitFor(() -> comp1inst0.getContainerStatus() != null,
-        2000, 200000);
-    // first host status will match the container nodeId
-    Assert.assertEquals("localhost",
-        comp1inst0.getContainerStatus().getHost());
-
-    LOG.info("Change the IP and host");
-    // change the container status
-    am.updateContainerStatus(exampleApp, 1, comp1Name, "new.host");
-    GenericTestUtils.waitFor(() -> comp1inst0.getContainerStatus().getHost()
-        .equals("new.host"), 2000, 200000);
-
-    LOG.info("Change the IP and host again");
-    // change the container status
-    am.updateContainerStatus(exampleApp, 1, comp1Name, "newer.host");
-    GenericTestUtils.waitFor(() -> comp1inst0.getContainerStatus().getHost()
-        .equals("newer.host"), 2000, 200000);
-    am.stop();
-  }
-
-  /**
-   This test verifies that the containers are released and the
-   component instance is added to the pending queue when building the launch
-   context fails.
-   Here, we intentionally have an artifact that doesn't have an id.
-   This will cause TarballProviderService.processArtifact
-   to throw an IllegalArgumentException because the Path object is
-   constructed from the id of the artifact.
-   In case the id is set to null or unset so it is effectively null,
-   Path.checkPathArg throws an IllegalArgumentException.
-  **/
-  @Test(timeout = 30000)
-  public void testContainersReleasedWhenPreLaunchFails()
-      throws Exception {
-    ApplicationId applicationId = ApplicationId.newInstance(
-        System.currentTimeMillis(), 1);
-    Service exampleApp = new Service();
-    exampleApp.setId(applicationId.toString());
-    exampleApp.setVersion("v1");
-    exampleApp.setName("testContainersReleasedWhenPreLaunchFails");
-
-    Component compA = createComponent("compa", 1, "pwd");
-    Artifact artifact = new Artifact();
-    artifact.setType(Artifact.TypeEnum.TARBALL);
-    compA.artifact(artifact);
-    exampleApp.addComponent(compA);
-
-    MockServiceAM am = new MockServiceAM(exampleApp);
-    am.init(conf);
-    am.start();
-
-    ContainerId containerId = am.createContainerId(1);
-
-    // allocate a container
-    am.feedContainerToComp(exampleApp, containerId, "compa");
-    am.waitForContainerToRelease(containerId);
-    ComponentInstance compAinst0 = am.getCompInstance(compA.getName(),
-        "compa-0");
-    GenericTestUtils.waitFor(() ->
-        am.getComponent(compA.getName()).getPendingInstances()
-        .contains(compAinst0), 2000, 30000);
-
-    Assert.assertEquals(1,
-        am.getComponent("compa").getPendingInstances().size());
-    am.stop();
-  }
-
-  @Test(timeout = 30000)
-  public void testSyncSysFS() {
-    ApplicationId applicationId = ApplicationId.newInstance(
-        System.currentTimeMillis(), 1);
-    Service exampleApp = new Service();
-    exampleApp.setId(applicationId.toString());
-    exampleApp.setVersion("v1");
-    exampleApp.setName("tensorflow");
-
-    Component compA = createComponent("compa", 1, "pwd");
-    compA.getConfiguration().getEnv().put(
-        "YARN_CONTAINER_RUNTIME_YARN_SYSFS_ENABLE", "true");
-    Artifact artifact = new Artifact();
-    artifact.setType(Artifact.TypeEnum.TARBALL);
-    compA.artifact(artifact);
-    exampleApp.addComponent(compA);
-    try {
-      MockServiceAM am = new MockServiceAM(exampleApp);
-      am.init(conf);
-      am.start();
-      ServiceScheduler scheduler = am.context.scheduler;
-      scheduler.syncSysFs(exampleApp);
-      scheduler.close();
-      am.stop();
-      am.close();
-    } catch (Exception e) {
-      LOG.error("Fail to sync sysfs.", e);
-      Assert.fail("Fail to sync sysfs.");
-    }
-  }
-
-  @Test
-  public void testScheduleWithResourceAttributes() throws Exception {
-    ApplicationId applicationId = ApplicationId.newInstance(123456, 1);
-    Service exampleApp = new Service();
-    exampleApp.setId(applicationId.toString());
-    exampleApp.setName("testScheduleWithResourceAttributes");
-    exampleApp.setVersion("v1");
-
-    List<ResourceTypeInfo> resourceTypeInfos = new ArrayList<>(
-        ResourceUtils.getResourcesTypeInfo());
-    // Add 3rd resource type.
-    resourceTypeInfos.add(ResourceTypeInfo
-        .newInstance("test-resource", "", ResourceTypes.COUNTABLE));
-    // Reinitialize resource types
-    ResourceUtils.reinitializeResources(resourceTypeInfos);
-
-    Component serviceCompoent = createComponent("compa", 1, "pwd");
-    serviceCompoent.getResource().setResourceInformations(
-        ImmutableMap.of("test-resource",
-            new ResourceInformation()
-                .value(1234L)
-                .unit("Gi")
-                .attributes(ImmutableMap.of("k1", "v1", "k2", "v2"))));
-    exampleApp.addComponent(serviceCompoent);
-
-    MockServiceAM am = new MockServiceAM(exampleApp);
-    am.init(conf);
-    am.start();
-
-    ServiceScheduler serviceScheduler = am.context.scheduler;
-    AMRMClientAsync<AMRMClient.ContainerRequest> amrmClientAsync =
-        serviceScheduler.getAmRMClient();
-
-    Collection<AMRMClient.ContainerRequest> rr =
-        amrmClientAsync.getMatchingRequests(0);
-    Assert.assertEquals(1, rr.size());
-
-    org.apache.hadoop.yarn.api.records.Resource capability =
-        rr.iterator().next().getCapability();
-    Assert.assertEquals(1234L, capability.getResourceValue("test-resource"));
-    Assert.assertEquals("Gi",
-        capability.getResourceInformation("test-resource").getUnits());
-    Assert.assertEquals(2, capability.getResourceInformation("test-resource")
-        .getAttributes().size());
-    am.stop();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/TestServiceManager.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/TestServiceManager.java
deleted file mode 100644
index 1d8ccff4f6f..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/TestServiceManager.java
+++ /dev/null
@@ -1,431 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.test.GenericTestUtils;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.service.api.records.Artifact;
-import org.apache.hadoop.yarn.service.api.records.ComponentState;
-import org.apache.hadoop.yarn.service.api.records.ContainerState;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.component.Component;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEvent;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEventType;
-import org.apache.hadoop.yarn.service.exceptions.SliderException;
-import org.apache.hadoop.yarn.service.utils.ServiceApiUtil;
-import org.junit.Assert;
-import org.junit.Rule;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.Collection;
-import java.util.List;
-import java.util.concurrent.TimeoutException;
-
-/**
- * Tests for {@link ServiceManager}.
- */
-public class TestServiceManager {
-
-  @Rule
-  public ServiceTestUtils.ServiceFSWatcher rule =
-      new ServiceTestUtils.ServiceFSWatcher();
-
-  @Test (timeout = TIMEOUT)
-  public void testUpgrade() throws Exception {
-    ServiceContext context = createServiceContext("testUpgrade");
-    initUpgrade(context, "v2", false, false, false);
-    Assert.assertEquals("service not upgraded", ServiceState.UPGRADING,
-        context.getServiceManager().getServiceSpec().getState());
-  }
-
-  @Test (timeout = TIMEOUT)
-  public void testRestartNothingToUpgrade()
-      throws Exception {
-    ServiceContext context = createServiceContext(
-        "testRestartNothingToUpgrade");
-    initUpgrade(context, "v2", false, false, false);
-    ServiceManager manager = context.getServiceManager();
-    //make components stable by upgrading all instances
-    upgradeAndReadyAllInstances(context);
-
-    context.scheduler.getDispatcher().getEventHandler().handle(
-        new ServiceEvent(ServiceEventType.START));
-    GenericTestUtils.waitFor(()->
-        context.service.getState().equals(ServiceState.STABLE),
-        CHECK_EVERY_MILLIS, TIMEOUT);
-    Assert.assertEquals("service not re-started", ServiceState.STABLE,
-        manager.getServiceSpec().getState());
-  }
-
-  @Test(timeout = TIMEOUT)
-  public void testAutoFinalizeNothingToUpgrade() throws Exception {
-    ServiceContext context = createServiceContext(
-        "testAutoFinalizeNothingToUpgrade");
-    initUpgrade(context, "v2", false, true, false);
-    ServiceManager manager = context.getServiceManager();
-    //make components stable by upgrading all instances
-    upgradeAndReadyAllInstances(context);
-
-    GenericTestUtils.waitFor(()->
-        context.service.getState().equals(ServiceState.STABLE),
-        CHECK_EVERY_MILLIS, TIMEOUT);
-    Assert.assertEquals("service stable", ServiceState.STABLE,
-        manager.getServiceSpec().getState());
-  }
-
-  @Test(timeout = TIMEOUT)
-  public void testRestartWithPendingUpgrade()
-      throws Exception {
-    ServiceContext context = createServiceContext("testRestart");
-    initUpgrade(context, "v2", true, false, false);
-    ServiceManager manager = context.getServiceManager();
-
-    context.scheduler.getDispatcher().getEventHandler().handle(
-        new ServiceEvent(ServiceEventType.START));
-    context.scheduler.getDispatcher().stop();
-    Assert.assertEquals("service should still be upgrading",
-        ServiceState.UPGRADING, manager.getServiceSpec().getState());
-  }
-
-  @Test(timeout = TIMEOUT)
-  public void testFinalize() throws Exception {
-    ServiceContext context = createServiceContext("testCheckState");
-    initUpgrade(context, "v2", true, false, false);
-    ServiceManager manager = context.getServiceManager();
-    Assert.assertEquals("service not upgrading", ServiceState.UPGRADING,
-        manager.getServiceSpec().getState());
-
-    //make components stable by upgrading all instances
-    upgradeAndReadyAllInstances(context);
-
-    // finalize service
-    context.scheduler.getDispatcher().getEventHandler().handle(
-        new ServiceEvent(ServiceEventType.START));
-    GenericTestUtils.waitFor(()->
-        context.service.getState().equals(ServiceState.STABLE),
-        CHECK_EVERY_MILLIS, TIMEOUT);
-    Assert.assertEquals("service not re-started", ServiceState.STABLE,
-        manager.getServiceSpec().getState());
-
-    validateUpgradeFinalization(manager.getName(), "v2");
-  }
-
-  @Test(timeout = TIMEOUT)
-  public void testAutoFinalize() throws Exception {
-    ServiceContext context = createServiceContext("testCheckStateAutoFinalize");
-    ServiceManager manager = context.getServiceManager();
-    manager.getServiceSpec().setState(
-        ServiceState.UPGRADING_AUTO_FINALIZE);
-    initUpgrade(context, "v2", true, true, false);
-
-    // make components stable
-    upgradeAndReadyAllInstances(context);
-
-    GenericTestUtils.waitFor(() ->
-        context.service.getState().equals(ServiceState.STABLE),
-        CHECK_EVERY_MILLIS, TIMEOUT);
-    Assert.assertEquals("service not stable",
-        ServiceState.STABLE, manager.getServiceSpec().getState());
-
-    validateUpgradeFinalization(manager.getName(), "v2");
-  }
-
-  @Test
-  public void testInvalidUpgrade() throws Exception {
-    ServiceContext serviceContext = createServiceContext("testInvalidUpgrade");
-    ServiceManager manager = serviceContext.getServiceManager();
-    manager.getServiceSpec().setState(
-        ServiceState.UPGRADING_AUTO_FINALIZE);
-    Service upgradedDef = ServiceTestUtils.createExampleApplication();
-    upgradedDef.setName(manager.getName());
-    upgradedDef.setVersion("v2");
-    upgradedDef.setLifetime(2L);
-    writeUpgradedDef(upgradedDef);
-
-    try {
-      manager.processUpgradeRequest("v2", true, false);
-    } catch (Exception ex) {
-      Assert.assertTrue(ex instanceof UnsupportedOperationException);
-      return;
-    }
-    Assert.fail();
-  }
-
-  @Test(timeout = TIMEOUT)
-  public void testExpressUpgrade() throws Exception {
-    ServiceContext context = createServiceContext("testExpressUpgrade");
-    ServiceManager manager = context.getServiceManager();
-    manager.getServiceSpec().setState(ServiceState.EXPRESS_UPGRADING);
-    initUpgrade(context, "v2", true, true, true);
-
-    List<String> comps = ServiceApiUtil.resolveCompsDependency(context.service);
-    // wait till instances of first component are upgraded and ready
-    String compA = comps.get(0);
-    makeInstancesReadyAfterUpgrade(context, compA);
-
-    // wait till instances of second component are upgraded and ready
-    String compB = comps.get(1);
-    makeInstancesReadyAfterUpgrade(context, compB);
-
-    GenericTestUtils.waitFor(() ->
-            context.service.getState().equals(ServiceState.STABLE),
-        CHECK_EVERY_MILLIS, TIMEOUT);
-
-    Assert.assertEquals("service not stable",
-        ServiceState.STABLE, manager.getServiceSpec().getState());
-    validateUpgradeFinalization(manager.getName(), "v2");
-  }
-
-  @Test(timeout = TIMEOUT)
-  public void testCancelUpgrade() throws Exception {
-    ServiceContext context = createServiceContext("testCancelUpgrade");
-    writeInitialDef(context.service);
-    initUpgrade(context, "v2", true, false, false);
-    ServiceManager manager = context.getServiceManager();
-    Assert.assertEquals("service not upgrading", ServiceState.UPGRADING,
-        manager.getServiceSpec().getState());
-
-    List<String> comps = ServiceApiUtil.resolveCompsDependency(context.service);
-    // wait till instances of first component are upgraded and ready
-    String compA = comps.get(0);
-    // upgrade the instances
-    upgradeInstances(context, compA);
-    makeInstancesReadyAfterUpgrade(context, compA);
-
-    // cancel upgrade
-    context.scheduler.getDispatcher().getEventHandler().handle(
-        new ServiceEvent(ServiceEventType.CANCEL_UPGRADE));
-    makeInstancesReadyAfterUpgrade(context, compA);
-
-    GenericTestUtils.waitFor(()->
-            context.service.getState().equals(ServiceState.STABLE),
-        CHECK_EVERY_MILLIS, TIMEOUT);
-    Assert.assertEquals("service upgrade not cancelled", ServiceState.STABLE,
-        manager.getServiceSpec().getState());
-
-    validateUpgradeFinalization(manager.getName(), "v1");
-  }
-
-  @Test(timeout = TIMEOUT)
-  public void testCancelUpgradeAfterInitiate() throws Exception {
-    ServiceContext context = createServiceContext("testCancelUpgrade");
-    writeInitialDef(context.service);
-    initUpgrade(context, "v2", true, false, false);
-    ServiceManager manager = context.getServiceManager();
-    Assert.assertEquals("service not upgrading", ServiceState.UPGRADING,
-        manager.getServiceSpec().getState());
-
-    // cancel upgrade
-    context.scheduler.getDispatcher().getEventHandler().handle(
-        new ServiceEvent(ServiceEventType.CANCEL_UPGRADE));
-    GenericTestUtils.waitFor(()->
-            context.service.getState().equals(ServiceState.STABLE),
-        CHECK_EVERY_MILLIS, TIMEOUT);
-    Assert.assertEquals("service upgrade not cancelled", ServiceState.STABLE,
-        manager.getServiceSpec().getState());
-
-    validateUpgradeFinalization(manager.getName(), "v1");
-  }
-
-  private void validateUpgradeFinalization(String serviceName,
-      String expectedVersion) throws IOException {
-    Service savedSpec = ServiceApiUtil.loadService(rule.getFs(), serviceName);
-    Assert.assertEquals("service def not re-written", expectedVersion,
-        savedSpec.getVersion());
-    Assert.assertNotNull("app id not present", savedSpec.getId());
-    Assert.assertEquals("state not stable", ServiceState.STABLE,
-        savedSpec.getState());
-    savedSpec.getComponents().forEach(compSpec ->
-        Assert.assertEquals("comp not stable", ComponentState.STABLE,
-        compSpec.getState()));
-  }
-
-  private void initUpgrade(ServiceContext context, String version,
-      boolean upgradeArtifact, boolean autoFinalize, boolean expressUpgrade)
-      throws IOException, SliderException, TimeoutException,
-      InterruptedException {
-    ServiceManager serviceManager = context.getServiceManager();
-    Service upgradedDef = ServiceTestUtils.createExampleApplication();
-    upgradedDef.setName(serviceManager.getName());
-    upgradedDef.setVersion(version);
-    if (upgradeArtifact) {
-      Artifact upgradedArtifact = createTestArtifact("2");
-      upgradedDef.getComponents().forEach(component -> {
-        component.setArtifact(upgradedArtifact);
-      });
-    }
-    writeUpgradedDef(upgradedDef);
-    serviceManager.processUpgradeRequest(version, autoFinalize, expressUpgrade);
-    GenericTestUtils.waitFor(() -> {
-      for (Component comp : context.scheduler.getAllComponents().values()) {
-        if (!comp.getComponentSpec().getState().equals(
-            ComponentState.NEEDS_UPGRADE)) {
-          return false;
-        }
-      }
-      return true;
-    }, CHECK_EVERY_MILLIS, TIMEOUT);
-  }
-
-  private void upgradeAndReadyAllInstances(ServiceContext context) throws
-      TimeoutException, InterruptedException {
-    upgradeAllInstances(context);
-    makeAllInstancesReady(context);
-  }
-
-  private void upgradeAllInstances(ServiceContext context) throws
-      TimeoutException, InterruptedException {
-    // upgrade the instances
-    context.scheduler.getLiveInstances().forEach(((containerId, instance) -> {
-      ComponentInstanceEvent event = new ComponentInstanceEvent(containerId,
-          ComponentInstanceEventType.UPGRADE);
-      context.scheduler.getDispatcher().getEventHandler().handle(event);
-    }));
-  }
-
-  private void makeAllInstancesReady(ServiceContext context)
-      throws TimeoutException, InterruptedException {
-    context.scheduler.getLiveInstances().forEach(((containerId, instance) -> {
-      ComponentInstanceEvent startEvent = new ComponentInstanceEvent(
-          containerId, ComponentInstanceEventType.START);
-      context.scheduler.getDispatcher().getEventHandler().handle(startEvent);
-
-      ComponentInstanceEvent becomeReadyEvent = new ComponentInstanceEvent(
-          containerId, ComponentInstanceEventType.BECOME_READY);
-      context.scheduler.getDispatcher().getEventHandler().handle(
-          becomeReadyEvent);
-    }));
-    GenericTestUtils.waitFor(()-> {
-      for (ComponentInstance instance:
-          context.scheduler.getLiveInstances().values()) {
-        if (!instance.getContainerState().equals(ContainerState.READY)) {
-          return false;
-        }
-      }
-      return true;
-    }, CHECK_EVERY_MILLIS, TIMEOUT);
-  }
-
-  private void upgradeInstances(ServiceContext context, String compName) {
-    Collection<ComponentInstance> compInstances = context.scheduler
-        .getAllComponents().get(compName).getAllComponentInstances();
-    compInstances.forEach(instance -> {
-      ComponentInstanceEvent event = new ComponentInstanceEvent(
-          instance.getContainer().getId(),
-          ComponentInstanceEventType.UPGRADE);
-      context.scheduler.getDispatcher().getEventHandler().handle(event);
-    });
-  }
-
-  private void makeInstancesReadyAfterUpgrade(ServiceContext context,
-      String compName)
-      throws TimeoutException, InterruptedException {
-    Collection<ComponentInstance> compInstances = context.scheduler
-        .getAllComponents().get(compName).getAllComponentInstances();
-    GenericTestUtils.waitFor(() -> {
-      for (ComponentInstance instance : compInstances) {
-        if (!instance.getContainerState().equals(ContainerState.UPGRADING)) {
-          return false;
-        }
-      }
-      return true;
-    }, CHECK_EVERY_MILLIS, TIMEOUT);
-
-    // instances of comp1 get upgraded and become ready event is triggered
-    // become ready
-    compInstances.forEach(instance -> {
-      ComponentInstanceEvent startEvent = new ComponentInstanceEvent(
-          instance.getContainer().getId(),
-          ComponentInstanceEventType.START);
-      context.scheduler.getDispatcher().getEventHandler().handle(startEvent);
-
-      ComponentInstanceEvent becomeReadyEvent = new ComponentInstanceEvent(
-          instance.getContainer().getId(),
-          ComponentInstanceEventType.BECOME_READY);
-
-      context.scheduler.getDispatcher().getEventHandler().handle(
-          becomeReadyEvent);
-    });
-
-    GenericTestUtils.waitFor(() -> {
-      for (ComponentInstance instance : compInstances) {
-        if (!instance.getContainerState().equals(ContainerState.READY)) {
-          return false;
-        }
-      }
-      return true;
-    }, CHECK_EVERY_MILLIS, TIMEOUT);
-  }
-
-  private ServiceContext createServiceContext(String name)
-      throws Exception {
-    Service service  = createBaseDef(name);
-    ServiceContext context = new MockRunningServiceContext(rule,
-        service);
-    context.scheduler.getDispatcher().setDrainEventsOnStop();
-    context.scheduler.getDispatcher().start();
-    return context;
-  }
-
-  public static Service createBaseDef(String name) {
-    return createDef(name, ServiceTestUtils.createExampleApplication());
-  }
-
-  public static Service createDef(String name, Service serviceDef) {
-    ApplicationId applicationId = ApplicationId.newInstance(
-        System.currentTimeMillis(), 1);
-    serviceDef.setId(applicationId.toString());
-    serviceDef.setName(name);
-    serviceDef.setState(ServiceState.STARTED);
-    Artifact artifact = createTestArtifact("1");
-    serviceDef.getComponents().forEach(component ->
-        component.setArtifact(artifact));
-    return serviceDef;
-  }
-
-  static Artifact createTestArtifact(String artifactId) {
-    Artifact artifact = new Artifact();
-    artifact.setId(artifactId);
-    artifact.setType(Artifact.TypeEnum.TARBALL);
-    return artifact;
-  }
-
-  private void writeInitialDef(Service service)
-      throws IOException, SliderException {
-    Path servicePath = rule.getFs().buildClusterDirPath(
-        service.getName());
-    ServiceApiUtil.createDirAndPersistApp(rule.getFs(), servicePath,
-        service);
-  }
-
-  private void writeUpgradedDef(Service upgradedDef)
-      throws IOException, SliderException {
-    Path upgradePath = rule.getFs().buildClusterUpgradeDirPath(
-        upgradedDef.getName(), upgradedDef.getVersion());
-    ServiceApiUtil.createDirAndPersistApp(rule.getFs(), upgradePath,
-        upgradedDef);
-  }
-
-  private static final int TIMEOUT = 10000;
-  private static final int CHECK_EVERY_MILLIS = 100;
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/TestYarnNativeServices.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/TestYarnNativeServices.java
deleted file mode 100644
index 56aca5c89ab..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/TestYarnNativeServices.java
+++ /dev/null
@@ -1,1028 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service;
-
-import org.apache.commons.io.FileUtils;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.registry.client.binding.RegistryPathUtils;
-import org.apache.hadoop.registry.client.binding.RegistryUtils;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.test.GenericTestUtils;
-import org.apache.hadoop.util.Lists;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest;
-import org.apache.hadoop.yarn.api.records.*;
-import org.apache.hadoop.yarn.client.api.YarnClient;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.ApplicationNotFoundException;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.resourcemanager.ResourceManager;
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.api.records.ComponentState;
-import org.apache.hadoop.yarn.service.api.records.Configuration;
-import org.apache.hadoop.yarn.service.api.records.Container;
-import org.apache.hadoop.yarn.service.api.records.PlacementConstraint;
-import org.apache.hadoop.yarn.service.api.records.PlacementPolicy;
-import org.apache.hadoop.yarn.service.api.records.PlacementScope;
-import org.apache.hadoop.yarn.service.api.records.PlacementType;
-import org.apache.hadoop.yarn.service.api.records.Resource;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.client.ServiceClient;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConstants;
-import org.apache.hadoop.yarn.service.exceptions.SliderException;
-import org.apache.hadoop.yarn.service.utils.ServiceApiUtil;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-
-import org.hamcrest.CoreMatchers;
-import org.junit.After;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Rule;
-import org.junit.Test;
-import org.junit.rules.TemporaryFolder;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import org.apache.hadoop.thirdparty.com.google.common.collect.Multimap;
-
-import java.io.File;
-import java.io.IOException;
-import java.util.*;
-import java.util.concurrent.TimeoutException;
-
-import static org.assertj.core.api.Assertions.assertThat;
-import static org.apache.hadoop.yarn.api.records.YarnApplicationState.FINISHED;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.*;
-import static org.apache.hadoop.yarn.service.exceptions.LauncherExitCodes.EXIT_COMMAND_ARGUMENT_ERROR;
-import static org.apache.hadoop.yarn.service.exceptions.LauncherExitCodes.EXIT_NOT_FOUND;
-
-/**
- * End to end tests to test deploying services with MiniYarnCluster and a in-JVM
- * ZK testing cluster.
- */
-public class TestYarnNativeServices extends ServiceTestUtils {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestYarnNativeServices.class);
-
-  @Rule
-  public TemporaryFolder tmpFolder = new TemporaryFolder();
-
-  @Before
-  public void setup() throws Exception {
-    File tmpYarnDir = new File("target", "tmp");
-    FileUtils.deleteQuietly(tmpYarnDir);
-  }
-
-  @After
-  public void tearDown() throws IOException {
-    shutdown();
-  }
-
-  // End-to-end test to use ServiceClient to deploy a service.
-  // 1. Create a service with 2 components, each of which has 2 containers
-  // 2. Flex up each component to 3 containers and check the component instance names
-  // 3. Flex down each component to 1 container and check the component instance names
-  // 4. Flex up each component to 2 containers and check the component instance names
-  // 5. Stop the service
-  // 6. Destroy the service
-  @Test (timeout = 200000)
-  public void testCreateFlexStopDestroyService() throws Exception {
-    setupInternal(NUM_NMS);
-    ServiceClient client = createClient(getConf());
-    Service exampleApp = createExampleApplication();
-    client.actionCreate(exampleApp);
-    SliderFileSystem fileSystem = new SliderFileSystem(getConf());
-    Path appDir = fileSystem.buildClusterDirPath(exampleApp.getName());
-    // check app.json is persisted.
-    Assert.assertTrue(
-        getFS().exists(new Path(appDir, exampleApp.getName() + ".json")));
-    waitForServiceToBeStable(client, exampleApp);
-
-    // Flex two components, each from 2 container to 3 containers.
-    flexComponents(client, exampleApp, 3L);
-    // wait for flex to be completed, increase from 2 to 3 containers.
-    waitForServiceToBeStable(client, exampleApp);
-    // check all instances name for each component are in sequential order.
-    checkCompInstancesInOrder(client, exampleApp);
-
-    // flex down to 1
-    flexComponents(client, exampleApp, 1L);
-    waitForServiceToBeStable(client, exampleApp);
-    checkCompInstancesInOrder(client, exampleApp);
-
-    // check component dir and registry are cleaned up.
-
-    // flex up again to 2
-    flexComponents(client, exampleApp, 2L);
-    waitForServiceToBeStable(client, exampleApp);
-    checkCompInstancesInOrder(client, exampleApp);
-
-    // stop the service
-    LOG.info("Stop the service");
-    client.actionStop(exampleApp.getName(), true);
-    ApplicationReport report = client.getYarnClient()
-        .getApplicationReport(ApplicationId.fromString(exampleApp.getId()));
-    // AM unregisters with RM successfully
-    Assert.assertEquals(FINISHED, report.getYarnApplicationState());
-    Assert.assertEquals(FinalApplicationStatus.ENDED,
-        report.getFinalApplicationStatus());
-    String serviceZKPath = RegistryUtils.servicePath(RegistryUtils
-        .currentUser(), YarnServiceConstants.APP_TYPE, exampleApp.getName());
-    Assert.assertFalse("Registry ZK service path still exists after stop",
-        getCuratorService().zkPathExists(serviceZKPath));
-
-    LOG.info("Destroy the service");
-    // destroy the service and check the app dir is deleted from fs.
-    Assert.assertEquals(0, client.actionDestroy(exampleApp.getName()));
-    // check the service dir on hdfs (in this case, local fs) are deleted.
-    Assert.assertFalse(getFS().exists(appDir));
-
-    // check that destroying again does not succeed
-    Assert.assertEquals(EXIT_NOT_FOUND, client.actionDestroy(exampleApp.getName()));
-  }
-
-  // Save a service without starting it and ensure that stop does not NPE and
-  // that service can be successfully destroyed
-  @Test (timeout = 200000)
-  public void testStopDestroySavedService() throws Exception {
-    setupInternal(NUM_NMS);
-    ServiceClient client = createClient(getConf());
-    Service exampleApp = createExampleApplication();
-    client.actionBuild(exampleApp);
-    Assert.assertEquals(EXIT_COMMAND_ARGUMENT_ERROR, client.actionStop(
-        exampleApp.getName()));
-    Assert.assertEquals(0, client.actionDestroy(exampleApp.getName()));
-  }
-
-  // Create compa with 2 containers
-  // Create compb with 2 containers which depends on compa
-  // Create compc with 2 containers which depends on compb
-  // Check containers for compa started before containers for compb before
-  // containers for compc
-  @Test (timeout = 200000)
-  public void testComponentStartOrder() throws Exception {
-    setupInternal(NUM_NMS);
-    ServiceClient client = createClient(getConf());
-    Service exampleApp = new Service();
-    exampleApp.setName("teststartorder");
-    exampleApp.setVersion("v1");
-    exampleApp.addComponent(createComponent("compa", 2, "sleep 1000"));
-
-    // Let compb depend on compa
-    Component compb = createComponent("compb", 2, "sleep 1000");
-    compb.setDependencies(Collections.singletonList("compa"));
-    exampleApp.addComponent(compb);
-
-    // Let compc depend on compb
-    Component compc = createComponent("compc", 2, "sleep 1000");
-    compc.setDependencies(Collections.singletonList("compb"));
-    exampleApp.addComponent(compc);
-
-    client.actionCreate(exampleApp);
-    waitForServiceToBeStable(client, exampleApp);
-
-    // check that containers for compa are launched before containers for compb
-    checkContainerLaunchDependencies(client, exampleApp, "compa", "compb",
-        "compc");
-
-    client.actionStop(exampleApp.getName(), true);
-    client.actionDestroy(exampleApp.getName());
-  }
-
-  @Test(timeout = 200000)
-  public void testCreateServiceSameNameDifferentUser() throws Exception {
-    String sameAppName = "same-name";
-    String userA = "usera";
-    String userB = "userb";
-
-    setupInternal(NUM_NMS);
-    ServiceClient client = createClient(getConf());
-    String origBasePath = getConf().get(YARN_SERVICE_BASE_PATH);
-
-    Service userAApp = new Service();
-    userAApp.setName(sameAppName);
-    userAApp.setVersion("v1");
-    userAApp.addComponent(createComponent("comp", 1, "sleep 1000"));
-
-    Service userBApp = new Service();
-    userBApp.setName(sameAppName);
-    userBApp.setVersion("v1");
-    userBApp.addComponent(createComponent("comp", 1, "sleep 1000"));
-
-    File userABasePath = null, userBBasePath = null;
-    try {
-      userABasePath = new File(origBasePath, userA);
-      userABasePath.mkdirs();
-      getConf().set(YARN_SERVICE_BASE_PATH, userABasePath.getAbsolutePath());
-      client.actionCreate(userAApp);
-      waitForServiceToBeStarted(client, userAApp);
-
-      userBBasePath = new File(origBasePath, userB);
-      userBBasePath.mkdirs();
-      getConf().set(YARN_SERVICE_BASE_PATH, userBBasePath.getAbsolutePath());
-      client.actionBuild(userBApp);
-    } catch (Exception e) {
-      Assert
-          .fail("Exception should not be thrown - " + e.getLocalizedMessage());
-    } finally {
-      if (userABasePath != null) {
-        getConf().set(YARN_SERVICE_BASE_PATH, userABasePath.getAbsolutePath());
-        client.actionStop(sameAppName, true);
-        client.actionDestroy(sameAppName);
-      }
-      if (userBBasePath != null) {
-        getConf().set(YARN_SERVICE_BASE_PATH, userBBasePath.getAbsolutePath());
-        client.actionDestroy(sameAppName);
-      }
-    }
-
-    // Need to extend this test to validate that different users can create
-    // apps of exact same name. So far only create followed by build is tested.
-    // Need to test create followed by create.
-  }
-
-  @Test(timeout = 200000)
-  public void testCreateServiceSameNameSameUser() throws Exception {
-    String sameAppName = "same-name";
-    String user = UserGroupInformation.getCurrentUser().getUserName();
-    System.setProperty("user.name", user);
-
-    setupInternal(NUM_NMS);
-    ServiceClient client = createClient(getConf());
-
-    Service appA = new Service();
-    appA.setName(sameAppName);
-    appA.setVersion("v1");
-    appA.addComponent(createComponent("comp", 1, "sleep 1000"));
-
-    Service appB = new Service();
-    appB.setName(sameAppName);
-    appB.setVersion("v1");
-    appB.addComponent(createComponent("comp", 1, "sleep 1000"));
-
-    try {
-      client.actionBuild(appA);
-      client.actionBuild(appB);
-    } catch (Exception e) {
-      String expectedMsg = "Service Instance dir already exists:";
-      if (e.getLocalizedMessage() != null) {
-        Assert.assertThat(e.getLocalizedMessage(),
-            CoreMatchers.containsString(expectedMsg));
-      } else {
-        Assert.fail("Message cannot be null. It has to say - " + expectedMsg);
-      }
-    } finally {
-      // cleanup
-      client.actionDestroy(sameAppName);
-    }
-
-    try {
-      client.actionCreate(appA);
-      waitForServiceToBeStarted(client, appA);
-
-      client.actionCreate(appB);
-      waitForServiceToBeStarted(client, appB);
-    } catch (Exception e) {
-      String expectedMsg = "Failed to create service " + sameAppName
-          + ", because it already exists.";
-      if (e.getLocalizedMessage() != null) {
-        Assert.assertThat(e.getLocalizedMessage(),
-            CoreMatchers.containsString(expectedMsg));
-      } else {
-        Assert.fail("Message cannot be null. It has to say - " + expectedMsg);
-      }
-    } finally {
-      // cleanup
-      client.actionStop(sameAppName, true);
-      client.actionDestroy(sameAppName);
-    }
-  }
-
-  // Test to verify recovery of SeviceMaster after RM is restarted.
-  // 1. Create an example service.
-  // 2. Restart RM.
-  // 3. Fail the application attempt.
-  // 4. Verify ServiceMaster recovers.
-  @Test(timeout = 200000)
-  public void testRecoverComponentsAfterRMRestart() throws Exception {
-    YarnConfiguration conf = new YarnConfiguration();
-    conf.setBoolean(YarnConfiguration.RECOVERY_ENABLED, true);
-    conf.setBoolean(
-        YarnConfiguration.RM_WORK_PRESERVING_RECOVERY_ENABLED, true);
-    conf.setLong(YarnConfiguration.NM_RESOURCEMANAGER_CONNECT_RETRY_INTERVAL_MS,
-        500L);
-
-    conf.setBoolean(YarnConfiguration.YARN_MINICLUSTER_FIXED_PORTS, true);
-    conf.setBoolean(YarnConfiguration.YARN_MINICLUSTER_USE_RPC, true);
-    conf.setInt(YarnConfiguration.RM_MAX_COMPLETED_APPLICATIONS,
-        YarnConfiguration.DEFAULT_RM_MAX_COMPLETED_APPLICATIONS);
-    setConf(conf);
-    setupInternal(NUM_NMS);
-
-    ServiceClient client = createClient(getConf());
-    Service exampleApp = createExampleApplication();
-    client.actionCreate(exampleApp);
-    Multimap<String, String> containersBeforeFailure =
-        waitForAllCompToBeReady(client, exampleApp);
-
-    LOG.info("Restart the resource manager");
-    getYarnCluster().restartResourceManager(
-        getYarnCluster().getActiveRMIndex());
-    GenericTestUtils.waitFor(() ->
-        getYarnCluster().getResourceManager().getServiceState() ==
-            org.apache.hadoop.service.Service.STATE.STARTED, 2000, 200000);
-    Assert.assertTrue("node managers connected",
-        getYarnCluster().waitForNodeManagersToConnect(5000));
-
-    ApplicationId exampleAppId = ApplicationId.fromString(exampleApp.getId());
-    ApplicationAttemptId applicationAttemptId = client.getYarnClient()
-        .getApplicationReport(exampleAppId).getCurrentApplicationAttemptId();
-
-    LOG.info("Fail the application attempt {}", applicationAttemptId);
-    client.getYarnClient().failApplicationAttempt(applicationAttemptId);
-    //wait until attempt 2 is running
-    GenericTestUtils.waitFor(() -> {
-      try {
-        ApplicationReport ar = client.getYarnClient()
-            .getApplicationReport(exampleAppId);
-        return ar.getCurrentApplicationAttemptId().getAttemptId() == 2 &&
-            ar.getYarnApplicationState() == YarnApplicationState.RUNNING;
-      } catch (YarnException | IOException e) {
-        throw new RuntimeException("while waiting", e);
-      }
-    }, 2000, 200000);
-
-    Multimap<String, String> containersAfterFailure = waitForAllCompToBeReady(
-        client, exampleApp);
-    containersBeforeFailure.keys().forEach(compName -> {
-      Assert.assertEquals("num containers after by restart for " + compName,
-          containersBeforeFailure.get(compName).size(),
-          containersAfterFailure.get(compName) == null ? 0 :
-              containersAfterFailure.get(compName).size());
-    });
-
-    LOG.info("Stop/destroy service {}", exampleApp);
-    client.actionStop(exampleApp.getName(), true);
-    client.actionDestroy(exampleApp.getName());
-  }
-
-  @Test(timeout = 200000)
-  public void testUpgrade() throws Exception {
-    setupInternal(NUM_NMS);
-    getConf().setBoolean(YARN_SERVICE_UPGRADE_ENABLED, true);
-    ServiceClient client = createClient(getConf());
-
-    Service service = createExampleApplication();
-    client.actionCreate(service);
-    waitForServiceToBeStable(client, service);
-
-    // upgrade the service
-    Component component = service.getComponents().iterator().next();
-    service.setState(ServiceState.UPGRADING);
-    service.setVersion("v2");
-    component.getConfiguration().getEnv().put("key1", "val1");
-    client.initiateUpgrade(service);
-
-    // wait for service to be in upgrade state
-    waitForServiceToBeInState(client, service, ServiceState.UPGRADING);
-    SliderFileSystem fs = new SliderFileSystem(getConf());
-    Service fromFs = ServiceApiUtil.loadServiceUpgrade(fs,
-        service.getName(), service.getVersion());
-    Assert.assertEquals(service.getName(), fromFs.getName());
-    Assert.assertEquals(service.getVersion(), fromFs.getVersion());
-
-    // upgrade containers
-    Service liveService = client.getStatus(service.getName());
-    client.actionUpgrade(service,
-        liveService.getComponent(component.getName()).getContainers());
-    waitForAllCompToBeReady(client, service);
-
-    // finalize the upgrade
-    client.actionStart(service.getName());
-    waitForServiceToBeStable(client, service);
-    Service active = client.getStatus(service.getName());
-    Assert.assertEquals("component not stable", ComponentState.STABLE,
-        active.getComponent(component.getName()).getState());
-    Assert.assertEquals("comp does not have new env", "val1",
-        active.getComponent(component.getName()).getConfiguration()
-            .getEnv("key1"));
-    LOG.info("Stop/destroy service {}", service);
-    client.actionStop(service.getName(), true);
-    client.actionDestroy(service.getName());
-  }
-
-  @Test(timeout = 200000)
-  public void testExpressUpgrade() throws Exception {
-    setupInternal(NUM_NMS);
-    getConf().setBoolean(YARN_SERVICE_UPGRADE_ENABLED, true);
-    ServiceClient client = createClient(getConf());
-
-    Service service = createExampleApplication();
-    client.actionCreate(service);
-    waitForServiceToBeStable(client, service);
-
-    // upgrade the service
-    Component component = service.getComponents().iterator().next();
-    service.setState(ServiceState.EXPRESS_UPGRADING);
-    service.setVersion("v2");
-    component.getConfiguration().getEnv().put("key1", "val1");
-    Component component2 = service.getComponent("compb");
-    component2.getConfiguration().getEnv().put("key2", "val2");
-    client.actionUpgradeExpress(service);
-
-    waitForServiceToBeExpressUpgrading(client, service);
-
-    // wait for upgrade to complete
-    waitForServiceToBeStable(client, service);
-    Service active = client.getStatus(service.getName());
-    Assert.assertEquals("version mismatch", service.getVersion(),
-        active.getVersion());
-    Assert.assertEquals("component not stable", ComponentState.STABLE,
-        active.getComponent(component.getName()).getState());
-    Assert.assertEquals("compa does not have new env", "val1",
-        active.getComponent(component.getName()).getConfiguration()
-            .getEnv("key1"));
-    Assert.assertEquals("compb does not have new env", "val2",
-        active.getComponent(component2.getName()).getConfiguration()
-            .getEnv("key2"));
-    LOG.info("Stop/destroy service {}", service);
-    client.actionStop(service.getName(), true);
-    client.actionDestroy(service.getName());
-  }
-
-  @Test(timeout = 200000)
-  public void testCancelUpgrade() throws Exception {
-    setupInternal(NUM_NMS);
-    getConf().setBoolean(YARN_SERVICE_UPGRADE_ENABLED, true);
-    ServiceClient client = createClient(getConf());
-
-    Service service = createExampleApplication();
-    Component component = service.getComponents().iterator().next();
-    component.getConfiguration().getEnv().put("key1", "val0");
-
-    client.actionCreate(service);
-    waitForServiceToBeStable(client, service);
-
-    // upgrade the service
-    service.setState(ServiceState.UPGRADING);
-    service.setVersion("v2");
-    component.getConfiguration().getEnv().put("key1", "val1");
-    client.initiateUpgrade(service);
-
-    // wait for service to be in upgrade state
-    waitForServiceToBeInState(client, service, ServiceState.UPGRADING);
-
-    // upgrade 1 container
-    Service liveService = client.getStatus(service.getName());
-    Container container = liveService.getComponent(component.getName())
-        .getContainers().iterator().next();
-    client.actionUpgrade(service, Lists.newArrayList(container));
-
-    Thread.sleep(500);
-    // cancel the upgrade
-    client.actionCancelUpgrade(service.getName());
-    waitForServiceToBeStable(client, service);
-    Service active = client.getStatus(service.getName());
-    Assert.assertEquals("component not stable", ComponentState.STABLE,
-        active.getComponent(component.getName()).getState());
-    Assert.assertEquals("comp does not have new env", "val0",
-        active.getComponent(component.getName()).getConfiguration()
-            .getEnv("key1"));
-    LOG.info("Stop/destroy service {}", service);
-    client.actionStop(service.getName(), true);
-    client.actionDestroy(service.getName());
-  }
-
-  // Test to verify ANTI_AFFINITY placement policy
-  // 1. Start mini cluster
-  // with 3 NMs and scheduler placement-constraint handler
-  // 2. Create an example service with 3 containers
-  // 3. Verify no more than 1 container comes up in each of the 3 NMs
-  // 4. Flex the component to 4 containers
-  // 5. Verify that the 4th container does not even get allocated since there
-  //    are only 3 NMs
-  @Test (timeout = 200000)
-  public void testCreateServiceWithPlacementPolicy() throws Exception {
-    // We need to enable scheduler placement-constraint at the cluster level to
-    // let apps use placement policies.
-    YarnConfiguration conf = new YarnConfiguration();
-    conf.set(YarnConfiguration.RM_PLACEMENT_CONSTRAINTS_HANDLER,
-        YarnConfiguration.SCHEDULER_RM_PLACEMENT_CONSTRAINTS_HANDLER);
-    conf.setInt(YarnConfiguration.RM_MAX_COMPLETED_APPLICATIONS,
-        YarnConfiguration.DEFAULT_RM_MAX_COMPLETED_APPLICATIONS);
-    setConf(conf);
-    setupInternal(3);
-    ServiceClient client = createClient(getConf());
-    Service exampleApp = new Service();
-    exampleApp.setName("example-app");
-    exampleApp.setVersion("v1");
-    Component comp = createComponent("compa", 3L, "sleep 1000");
-    PlacementPolicy pp = new PlacementPolicy();
-    PlacementConstraint pc = new PlacementConstraint();
-    pc.setName("CA1");
-    pc.setTargetTags(Collections.singletonList("compa"));
-    pc.setScope(PlacementScope.NODE);
-    pc.setType(PlacementType.ANTI_AFFINITY);
-    pp.setConstraints(Collections.singletonList(pc));
-    comp.setPlacementPolicy(pp);
-    exampleApp.addComponent(comp);
-    client.actionCreate(exampleApp);
-    waitForServiceToBeStable(client, exampleApp);
-
-    // Check service is stable and all 3 containers are running
-    Service service = client.getStatus(exampleApp.getName());
-    Component component = service.getComponent("compa");
-    Assert.assertEquals("Service state should be STABLE", ServiceState.STABLE,
-        service.getState());
-    Assert.assertEquals("3 containers are expected to be running", 3,
-        component.getContainers().size());
-    // Prepare a map of non-AM containers for later lookup
-    Set<String> nonAMContainerIdSet = new HashSet<>();
-    for (Container cont : component.getContainers()) {
-      nonAMContainerIdSet.add(cont.getId());
-    }
-
-    // Verify that no more than 1 non-AM container came up on each of the 3 NMs
-    Set<String> hosts = new HashSet<>();
-    ApplicationReport report = client.getYarnClient()
-        .getApplicationReport(ApplicationId.fromString(exampleApp.getId()));
-    GetContainersRequest req = GetContainersRequest
-        .newInstance(report.getCurrentApplicationAttemptId());
-    ResourceManager rm = getYarnCluster().getResourceManager();
-    for (ContainerReport contReport : rm.getClientRMService().getContainers(req)
-        .getContainerList()) {
-      if (!nonAMContainerIdSet
-          .contains(contReport.getContainerId().toString())) {
-        continue;
-      }
-      if (hosts.contains(contReport.getNodeHttpAddress())) {
-        Assert.fail("Container " + contReport.getContainerId()
-            + " came up in the same host as another container.");
-      } else {
-        hosts.add(contReport.getNodeHttpAddress());
-      }
-    }
-
-    // Flex compa up to 5, which is more containers than the no of NMs
-    Map<String, Long> compCounts = new HashMap<>();
-    compCounts.put("compa", 5L);
-    exampleApp.getComponent("compa").setNumberOfContainers(5L);
-    client.flexByRestService(exampleApp.getName(), compCounts);
-    try {
-      // 10 secs is enough for the container to be started. The down side of
-      // this test is that it has to wait that long. Setting a higher wait time
-      // will add to the total time taken by tests to run.
-      waitForServiceToBeStable(client, exampleApp, 10000);
-      Assert.fail("Service should not be in a stable state. It should throw "
-          + "a timeout exception.");
-    } catch (Exception e) {
-      // Check that service state is not STABLE and only 3 containers are
-      // running and the fourth one should not get allocated.
-      service = client.getStatus(exampleApp.getName());
-      component = service.getComponent("compa");
-      Assert.assertNotEquals("Service state should not be STABLE",
-          ServiceState.STABLE, service.getState());
-      Assert.assertEquals("Component state should be FLEXING",
-          ComponentState.FLEXING, component.getState());
-      Assert.assertEquals("3 containers are expected to be running", 3,
-          component.getContainers().size());
-    }
-
-    // Flex compa down to 4 now, which is still more containers than the no of
-    // NMs. This tests the usecase that flex down does not kill any of the
-    // currently running containers since the required number of containers are
-    // still higher than the currently running number of containers. However,
-    // component state will still be FLEXING and service state not STABLE.
-    compCounts = new HashMap<>();
-    compCounts.put("compa", 4L);
-    exampleApp.getComponent("compa").setNumberOfContainers(4L);
-    client.flexByRestService(exampleApp.getName(), compCounts);
-    try {
-      // 10 secs is enough for the container to be started. The down side of
-      // this test is that it has to wait that long. Setting a higher wait time
-      // will add to the total time taken by tests to run.
-      waitForServiceToBeStable(client, exampleApp, 10000);
-      Assert.fail("Service should not be in a stable state. It should throw "
-          + "a timeout exception.");
-    } catch (Exception e) {
-      // Check that service state is not STABLE and only 3 containers are
-      // running and the fourth one should not get allocated.
-      service = client.getStatus(exampleApp.getName());
-      component = service.getComponent("compa");
-      Assert.assertNotEquals("Service state should not be STABLE",
-          ServiceState.STABLE, service.getState());
-      Assert.assertEquals("Component state should be FLEXING",
-          ComponentState.FLEXING, component.getState());
-      Assert.assertEquals("3 containers are expected to be running", 3,
-          component.getContainers().size());
-    }
-
-    // Finally flex compa down to 3, which is exactly the number of containers
-    // currently running. This will bring the component and service states to
-    // STABLE.
-    compCounts = new HashMap<>();
-    compCounts.put("compa", 3L);
-    exampleApp.getComponent("compa").setNumberOfContainers(3L);
-    client.flexByRestService(exampleApp.getName(), compCounts);
-    waitForServiceToBeStable(client, exampleApp);
-
-    LOG.info("Stop/destroy service {}", exampleApp);
-    client.actionStop(exampleApp.getName(), true);
-    client.actionDestroy(exampleApp.getName());
-  }
-
-  @Test(timeout = 200000)
-  public void testAMSigtermDoesNotKillApplication() throws Exception {
-    runAMSignalTest(SignalContainerCommand.GRACEFUL_SHUTDOWN);
-  }
-
-  @Test(timeout = 200000)
-  public void testAMSigkillDoesNotKillApplication() throws Exception {
-    runAMSignalTest(SignalContainerCommand.FORCEFUL_SHUTDOWN);
-  }
-
-  public void runAMSignalTest(SignalContainerCommand signal) throws Exception {
-    setupInternal(NUM_NMS);
-    ServiceClient client = createClient(getConf());
-    Service exampleApp = createExampleApplication();
-    client.actionCreate(exampleApp);
-    waitForServiceToBeStable(client, exampleApp);
-    Service appStatus1 = client.getStatus(exampleApp.getName());
-    ApplicationId exampleAppId = ApplicationId.fromString(appStatus1.getId());
-
-    YarnClient yarnClient = createYarnClient(getConf());
-    ApplicationReport applicationReport = yarnClient.getApplicationReport(
-        exampleAppId);
-
-    ApplicationAttemptId firstAttemptId = applicationReport
-        .getCurrentApplicationAttemptId();
-    ApplicationAttemptReport attemptReport = yarnClient
-        .getApplicationAttemptReport(firstAttemptId);
-
-    // the AM should not perform a graceful shutdown since the operation was not
-    // initiated through the service client
-    yarnClient.signalToContainer(attemptReport.getAMContainerId(), signal);
-
-    GenericTestUtils.waitFor(() -> {
-      try {
-        ApplicationReport ar = client.getYarnClient()
-            .getApplicationReport(exampleAppId);
-        YarnApplicationState state = ar.getYarnApplicationState();
-        Assert.assertTrue(state == YarnApplicationState.RUNNING ||
-            state == YarnApplicationState.ACCEPTED);
-        if (state != YarnApplicationState.RUNNING) {
-          return false;
-        }
-        if (ar.getCurrentApplicationAttemptId() == null ||
-            ar.getCurrentApplicationAttemptId().equals(firstAttemptId)) {
-          return false;
-        }
-        Service appStatus2 = client.getStatus(exampleApp.getName());
-        if (appStatus2.getState() != ServiceState.STABLE) {
-          return false;
-        }
-        Assert.assertEquals(getSortedContainerIds(appStatus1).toString(),
-            getSortedContainerIds(appStatus2).toString());
-        return true;
-      } catch (YarnException | IOException e) {
-        throw new RuntimeException("while waiting", e);
-      }
-    }, 2000, 200000);
-  }
-
-  private static List<String> getSortedContainerIds(Service s) {
-    List<String> containerIds = new ArrayList<>();
-    for (Component component : s.getComponents()) {
-      for (Container container : component.getContainers()) {
-        containerIds.add(container.getId());
-      }
-    }
-    Collections.sort(containerIds);
-    return containerIds;
-  }
-
-  // Test to verify component health threshold monitor. It uses anti-affinity
-  // placement policy to make it easier to simulate container failure by
-  // allocating more containers than the no of NMs.
-  // 1. Start mini cluster with 3 NMs and scheduler placement-constraint handler
-  // 2. Create an example service of 3 containers with anti-affinity placement
-  //    policy and health threshold = 65%, window = 3 secs, init-delay = 0 secs,
-  //    poll-frequency = 1 secs
-  // 3. Flex the component to 4 containers. This makes health = 75%, so based on
-  //    threshold the service will continue to run beyond the window of 3 secs.
-  // 4. Flex the component to 5 containers. This makes health = 60%, so based on
-  //    threshold the service will be stopped after the window of 3 secs.
-  @Test (timeout = 200000)
-  public void testComponentHealthThresholdMonitor() throws Exception {
-    // We need to enable scheduler placement-constraint at the cluster level to
-    // let apps use placement policies.
-    YarnConfiguration conf = new YarnConfiguration();
-    conf.set(YarnConfiguration.RM_PLACEMENT_CONSTRAINTS_HANDLER,
-        YarnConfiguration.SCHEDULER_RM_PLACEMENT_CONSTRAINTS_HANDLER);
-    conf.setInt(YarnConfiguration.RM_MAX_COMPLETED_APPLICATIONS,
-        YarnConfiguration.DEFAULT_RM_MAX_COMPLETED_APPLICATIONS);
-    conf.setInt(YarnConfiguration.NM_VCORES, 1);
-    setConf(conf);
-    setupInternal(3);
-    ServiceClient client = createClient(getConf());
-    Service exampleApp = new Service();
-    exampleApp.setName("example-app");
-    exampleApp.setVersion("v1");
-    Component comp = createComponent("compa", 3L, "sleep 1000");
-    PlacementPolicy pp = new PlacementPolicy();
-    PlacementConstraint pc = new PlacementConstraint();
-    pc.setName("CA1");
-    pc.setTargetTags(Collections.singletonList("compa"));
-    pc.setScope(PlacementScope.NODE);
-    pc.setType(PlacementType.ANTI_AFFINITY);
-    pp.setConstraints(Collections.singletonList(pc));
-    comp.setPlacementPolicy(pp);
-    Configuration config = new Configuration();
-    config.setProperty(CONTAINER_HEALTH_THRESHOLD_PERCENT, "65");
-    config.setProperty(CONTAINER_HEALTH_THRESHOLD_WINDOW_SEC, "3");
-    config.setProperty(CONTAINER_HEALTH_THRESHOLD_INIT_DELAY_SEC, "0");
-    config.setProperty(CONTAINER_HEALTH_THRESHOLD_POLL_FREQUENCY_SEC, "1");
-    config.setProperty(DEFAULT_READINESS_CHECK_ENABLED, "false");
-    comp.setConfiguration(config);
-    exampleApp.addComponent(comp);
-    // Make sure AM does not come up after service is killed for this test
-    Configuration serviceConfig = new Configuration();
-    serviceConfig.setProperty(AM_RESTART_MAX, "1");
-    exampleApp.setConfiguration(serviceConfig);
-    client.actionCreate(exampleApp);
-    waitForServiceToBeStable(client, exampleApp);
-
-    // Check service is stable and all 3 containers are running
-    Service service = client.getStatus(exampleApp.getName());
-    Component component = service.getComponent("compa");
-    Assert.assertEquals("Service state should be STABLE", ServiceState.STABLE,
-        service.getState());
-    Assert.assertEquals("3 containers are expected to be running", 3,
-        component.getContainers().size());
-
-    // Flex compa up to 4 - will make health 75% (3 out of 4 running), but still
-    // above threshold of 65%, so service will continue to run.
-    Map<String, Long> compCounts = new HashMap<>();
-    compCounts.put("compa", 4L);
-    exampleApp.getComponent("compa").setNumberOfContainers(4L);
-    client.flexByRestService(exampleApp.getName(), compCounts);
-    try {
-      // Wait for 6 secs (window 3 secs + 1 for next poll + 2 for buffer). Since
-      // the service will never go to stable state (because of anti-affinity the
-      // 4th container will never be allocated) it will timeout. However, after
-      // the timeout the service should continue to run since health is 75%
-      // which is above the threshold of 65%.
-      waitForServiceToBeStable(client, exampleApp, 6000);
-      Assert.fail("Service should not be in a stable state. It should throw "
-          + "a timeout exception.");
-    } catch (Exception e) {
-      // Check that service state is STARTED and only 3 containers are running
-      service = client.getStatus(exampleApp.getName());
-      component = service.getComponent("compa");
-      Assert.assertEquals("Service state should be STARTED",
-          ServiceState.STARTED, service.getState());
-      Assert.assertEquals("Component state should be FLEXING",
-          ComponentState.FLEXING, component.getState());
-      Assert.assertEquals("3 containers are expected to be running", 3,
-          component.getContainers().size());
-    }
-
-    // Flex compa up to 5 - will make health 60% (3 out of 5 running), so
-    // service will stop since it is below threshold of 65%.
-    compCounts.put("compa", 5L);
-    exampleApp.getComponent("compa").setNumberOfContainers(5L);
-    client.flexByRestService(exampleApp.getName(), compCounts);
-    try {
-      // Wait for 14 secs (window 3 secs + 1 for next poll + 2 for buffer + 5
-      // secs of service wait before shutting down + 3 secs app cleanup so that
-      // API returns that service is in FAILED state). Note, because of
-      // anti-affinity the 4th and 5th container will never be allocated.
-      waitForServiceToBeInState(client, exampleApp, ServiceState.FAILED,
-          14000);
-    } catch (Exception e) {
-      Assert.fail("Should not have thrown exception");
-    }
-
-    LOG.info("Destroy service {}", exampleApp);
-    client.actionDestroy(exampleApp.getName());
-  }
-
-  // Check containers launched are in dependency order
-  // Get all containers into a list and sort based on container launch time e.g.
-  // compa-c1, compa-c2, compb-c1, compb-c2;
-  // check that the container's launch time are align with the dependencies.
-  private void checkContainerLaunchDependencies(ServiceClient client,
-      Service exampleApp, String... compOrder)
-      throws IOException, YarnException {
-    Service retrievedApp = client.getStatus(exampleApp.getName());
-    List<Container> containerList = new ArrayList<>();
-    for (Component component : retrievedApp.getComponents()) {
-      containerList.addAll(component.getContainers());
-    }
-    // sort based on launchTime
-    containerList
-        .sort((o1, o2) -> o1.getLaunchTime().compareTo(o2.getLaunchTime()));
-    LOG.info("containerList: " + containerList);
-    // check the containers are in the dependency order.
-    int index = 0;
-    for (String comp : compOrder) {
-      long num = retrievedApp.getComponent(comp).getNumberOfContainers();
-      for (int i = 0; i < num; i++) {
-        String compInstanceName = containerList.get(index).getComponentInstanceName();
-        String compName =
-            compInstanceName.substring(0, compInstanceName.lastIndexOf('-'));
-        Assert.assertEquals(comp, compName);
-        index++;
-      }
-    }
-  }
-
-
-  private Map<String, Long> flexComponents(ServiceClient client,
-      Service exampleApp, long count) throws YarnException, IOException {
-    Map<String, Long> compCounts = new HashMap<>();
-    compCounts.put("compa", count);
-    compCounts.put("compb", count);
-    // flex will update the persisted conf to reflect latest number of containers.
-    exampleApp.getComponent("compa").setNumberOfContainers(count);
-    exampleApp.getComponent("compb").setNumberOfContainers(count);
-    client.flexByRestService(exampleApp.getName(), compCounts);
-    return compCounts;
-  }
-
-  // Check each component's comp instances name are in sequential order.
-  // E.g. If there are two instances compA-1 and compA-2
-  // When flex up to 4 instances, it should be compA-1 , compA-2, compA-3, compA-4
-  // When flex down to 3 instances,  it should be compA-1 , compA-2, compA-3.
-  private void checkCompInstancesInOrder(ServiceClient client,
-      Service exampleApp) throws IOException, YarnException,
-      TimeoutException, InterruptedException {
-    waitForContainers(client, exampleApp);
-    Service service = client.getStatus(exampleApp.getName());
-    for (Component comp : service.getComponents()) {
-      checkEachCompInstancesInOrder(comp, exampleApp.getName());
-    }
-  }
-
-  private void waitForContainers(ServiceClient client, Service exampleApp)
-      throws TimeoutException, InterruptedException {
-    GenericTestUtils.waitFor(() -> {
-      try {
-        Service service = client.getStatus(exampleApp.getName());
-        for (Component comp : service.getComponents()) {
-          if (comp.getContainers().size() != comp.getNumberOfContainers()) {
-            return false;
-          }
-        }
-        return true;
-      } catch (Exception e) {
-        return false;
-      }
-    }, 2000, 200000);
-  }
-
-  private void checkEachCompInstancesInOrder(Component component, String
-      serviceName) throws TimeoutException, InterruptedException {
-    TreeSet<String> instances = new TreeSet<>();
-    for (Container container : component.getContainers()) {
-      instances.add(container.getComponentInstanceName());
-      String componentZKPath = RegistryUtils.componentPath(RegistryUtils
-          .currentUser(), YarnServiceConstants.APP_TYPE, serviceName,
-          RegistryPathUtils.encodeYarnID(container.getId()));
-      GenericTestUtils.waitFor(() -> {
-        try {
-          return getCuratorService().zkPathExists(componentZKPath);
-        } catch (IOException e) {
-          return false;
-        }
-      }, 1000, 60000);
-    }
-
-    int i = 0;
-    for (String s : instances) {
-      assertThat(s).isEqualTo(component.getName() + "-" + i);
-      i++;
-    }
-  }
-
-  @Test (timeout = 200000)
-  public void testRestartServiceForNonExistingInRM() throws Exception {
-    YarnConfiguration conf = new YarnConfiguration();
-    conf.setInt(YarnConfiguration.RM_MAX_COMPLETED_APPLICATIONS, 0);
-    setConf(conf);
-    setupInternal(NUM_NMS);
-    ServiceClient client = createClient(getConf());
-    Service exampleApp = createExampleApplication();
-    client.actionCreate(exampleApp);
-    waitForServiceToBeStable(client, exampleApp);
-    try {
-      client.actionStop(exampleApp.getName(), true);
-    } catch (ApplicationNotFoundException e) {
-      LOG.info("ignore ApplicationNotFoundException during stopping");
-    }
-    client.actionStart(exampleApp.getName());
-    waitForServiceToBeStable(client, exampleApp);
-    Service service = client.getStatus(exampleApp.getName());
-    Assert.assertEquals("Restarted service state should be STABLE",
-        ServiceState.STABLE, service.getState());
-  }
-
-  @Test(timeout = 200000)
-  public void testAMFailureValidity() throws Exception {
-    setupInternal(NUM_NMS);
-    ServiceClient client = createClient(getConf());
-    Service exampleApp = new Service();
-    exampleApp.setName("example-app");
-    exampleApp.setVersion("v1");
-    exampleApp.addComponent(createComponent("compa", 2, "sleep 1000"));
-    Configuration serviceConfig = new Configuration();
-    serviceConfig.setProperty(AM_RESTART_MAX, "2");
-    serviceConfig.setProperty(AM_FAILURES_VALIDITY_INTERVAL, "1000");
-    exampleApp.setConfiguration(serviceConfig);
-    client.actionCreate(exampleApp);
-    waitForServiceToBeStable(client, exampleApp);
-
-    Service appStatus1 = client.getStatus(exampleApp.getName());
-    ApplicationId exampleAppId = ApplicationId.fromString(appStatus1.getId());
-    YarnClient yarnClient = createYarnClient(getConf());
-
-    // kill AM1
-    ApplicationReport applicationReport = yarnClient.getApplicationReport(
-        exampleAppId);
-    ApplicationAttemptReport attemptReport = yarnClient
-        .getApplicationAttemptReport(applicationReport
-            .getCurrentApplicationAttemptId());
-    yarnClient.signalToContainer(attemptReport.getAMContainerId(),
-        SignalContainerCommand.GRACEFUL_SHUTDOWN);
-    waitForServiceToBeStable(client, exampleApp);
-    Assert.assertEquals(ServiceState.STABLE, client.getStatus(
-        exampleApp.getName()).getState());
-
-    // kill AM2 after 'yarn.service.am-failure.validity-interval-ms'
-    Thread.sleep(2000);
-    applicationReport = yarnClient.getApplicationReport(exampleAppId);
-    attemptReport = yarnClient.getApplicationAttemptReport(applicationReport
-        .getCurrentApplicationAttemptId());
-    yarnClient.signalToContainer(attemptReport.getAMContainerId(),
-        SignalContainerCommand.GRACEFUL_SHUTDOWN);
-    waitForServiceToBeStable(client, exampleApp);
-    Assert.assertEquals(ServiceState.STABLE, client.getStatus(
-        exampleApp.getName()).getState());
-  }
-
-  public Service createServiceWithSingleComp(int memory){
-    Service service = new Service();
-    service.setName("example-app");
-    service.setVersion("v1");
-    Component component = new Component();
-    component.setName("sleep");
-    component.setNumberOfContainers(1L);
-    component.setLaunchCommand("sleep 1000");
-    org.apache.hadoop.yarn.service.api.records.Resource resource = new Resource();
-    resource.setMemory(Integer.toString(memory));
-    resource.setCpus(1);
-    component.setResource(resource);
-    service.addComponent(component);
-    return service;
-  }
-
-  @Test(timeout = 200000)
-  public void testServiceSameNameWithFailure() throws Exception{
-    setupInternal(NUM_NMS);
-    ServiceClient client = createClient(getConf());
-    try {
-      client.actionCreate(createServiceWithSingleComp(1024000));
-      Assert.fail("Service should throw YarnException as memory is " +
-          "configured as 1000GB, which is more than allowed");
-    } catch (YarnException e) {
-      Assert.assertTrue(true);
-    }
-    Service service = createServiceWithSingleComp(128);
-    try {
-      client.actionCreate(service);
-    } catch (SliderException e){
-      Assert.fail("Not able to submit service as the files related to" +
-          " failed service with same name are not cleared");
-    }
-    waitForServiceToBeStable(client,service);
-    client.actionStop(service.getName(), true);
-    client.actionDestroy(service.getName());
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/client/TestBuildExternalComponents.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/client/TestBuildExternalComponents.java
deleted file mode 100644
index 6d5bb205cb1..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/client/TestBuildExternalComponents.java
+++ /dev/null
@@ -1,119 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.client;
-
-import org.apache.commons.io.FileUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.client.api.AppAdminClient;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.conf.ExampleAppJson;
-import org.apache.hadoop.yarn.service.utils.ServiceApiUtil;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-import org.junit.After;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Test;
-
-import java.io.File;
-import java.io.IOException;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.YARN_SERVICE_BASE_PATH;
-
-/**
- * Test for building / resolving components of type SERVICE.
- */
-public class TestBuildExternalComponents {
-
-  protected Configuration conf = new YarnConfiguration();
-  private File basedir;
-
-  // Check component names match with expected
-  private static void checkComponentNames(List<Component> components,
-      Set<String> expectedComponents) {
-    Assert.assertEquals(expectedComponents.size(), components.size());
-    for (Component comp : components) {
-      Assert.assertTrue(expectedComponents.contains(comp.getName()));
-    }
-  }
-
-  // 1. Build the def file and store on fs
-  // 2. check component names
-  private void buildAndCheckComponents(String appName, String appDef,
-      SliderFileSystem sfs, Set<String> names) throws Throwable {
-    AppAdminClient client = AppAdminClient.createAppAdminClient(AppAdminClient
-        .UNIT_TEST_TYPE, conf);
-    client.actionSave(ExampleAppJson.resourceName(appDef), null, null,
-        null);
-
-    // verify generated conf
-    List<Component> components =
-        ServiceApiUtil.getComponents(sfs, appName);
-    checkComponentNames(components, names);
-  }
-
-  @Before
-  public void setup() throws IOException {
-    basedir = new File("target", "apps");
-    if (basedir.exists()) {
-      FileUtils.deleteDirectory(basedir);
-    } else {
-      basedir.mkdirs();
-    }
-    conf.set(YARN_SERVICE_BASE_PATH, basedir.getAbsolutePath());
-  }
-
-  @After
-  public void tearDown() throws IOException {
-    if (basedir != null) {
-      FileUtils.deleteDirectory(basedir);
-    }
-  }
-
-  // Test applications defining external components(SERVICE type)
-  // can be resolved correctly
-  @Test
-  public void testExternalComponentBuild() throws Throwable {
-    SliderFileSystem sfs = new SliderFileSystem(conf);
-
-    Set<String> nameSet = new HashSet<>();
-    nameSet.add("simple");
-    nameSet.add("master");
-    nameSet.add("worker");
-
-    // app-1 has 3 components: simple, master, worker
-    buildAndCheckComponents("app-1", ExampleAppJson.APP_JSON, sfs, nameSet);
-    buildAndCheckComponents("external-0", ExampleAppJson.EXTERNAL_JSON_0, sfs,
-        nameSet);
-
-    nameSet.add("other");
-
-    // external1 has 3 components: simple(SERVICE - app1), master and other
-    buildAndCheckComponents("external-1", ExampleAppJson.EXTERNAL_JSON_1, sfs,
-        nameSet);
-
-    nameSet.add("another");
-
-    // external2 has 2 components: ext(SERVICE - external1), another
-    buildAndCheckComponents("external-2", ExampleAppJson.EXTERNAL_JSON_2, sfs,
-        nameSet);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/client/TestServiceCLI.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/client/TestServiceCLI.java
deleted file mode 100644
index f75c0afdbeb..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/client/TestServiceCLI.java
+++ /dev/null
@@ -1,354 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.client;
-
-import org.apache.commons.io.FileUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.fs.permission.FsPermission;
-import org.apache.hadoop.hdfs.DFSConfigKeys;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.util.ToolRunner;
-import org.apache.hadoop.yarn.client.cli.ApplicationCLI;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.conf.ExampleAppJson;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConstants;
-import org.apache.hadoop.yarn.service.utils.ServiceApiUtil;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-import org.junit.After;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Rule;
-import org.junit.Test;
-import org.junit.rules.TemporaryFolder;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.ByteArrayOutputStream;
-import java.io.File;
-import java.io.IOException;
-import java.io.PrintStream;
-import java.util.Arrays;
-import java.util.List;
-
-import static org.assertj.core.api.Assertions.assertThat;
-import static org.apache.hadoop.yarn.client.api.AppAdminClient.YARN_APP_ADMIN_CLIENT_PREFIX;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.DEPENDENCY_TARBALL_PATH;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf.YARN_SERVICE_BASE_PATH;
-import static org.apache.hadoop.yarn.service.exceptions.LauncherExitCodes.EXIT_SUCCESS;
-import static org.apache.hadoop.yarn.service.exceptions.LauncherExitCodes.EXIT_UNAUTHORIZED;
-import static org.mockito.Mockito.spy;
-
-public class TestServiceCLI {
-  private static final Logger LOG = LoggerFactory.getLogger(TestServiceCLI
-      .class);
-
-  @Rule
-  public TemporaryFolder tmpFolder = new TemporaryFolder();
-
-  private Configuration conf = new YarnConfiguration();
-  private SliderFileSystem fs;
-  private ApplicationCLI cli;
-  private File basedir;
-  private String basedirProp;
-  private File dependencyTarGzBaseDir;
-  private Path dependencyTarGz;
-  private String dependencyTarGzProp;
-  private String yarnAdminNoneAclProp;
-  private String dfsAdminAclProp;
-
-  private void createCLI() {
-    cli = new ApplicationCLI();
-    PrintStream sysOut = spy(new PrintStream(new ByteArrayOutputStream()));
-    PrintStream sysErr = spy(new PrintStream(new ByteArrayOutputStream()));
-    cli.setSysOutPrintStream(sysOut);
-    cli.setSysErrPrintStream(sysErr);
-    conf.set(YARN_APP_ADMIN_CLIENT_PREFIX + DUMMY_APP_TYPE,
-        DummyServiceClient.class.getName());
-    cli.setConf(conf);
-  }
-
-  private int runCLI(String[] args) throws Exception {
-    LOG.info("running CLI: yarn {}", Arrays.asList(args));
-    return ToolRunner.run(cli, ApplicationCLI.preProcessArgs(args));
-  }
-
-  private void buildApp(String serviceName, String appDef) throws Throwable {
-    String[] args = {"app",
-        "-D", basedirProp, "-save", serviceName,
-        ExampleAppJson.resourceName(appDef),
-        "-appTypes", DUMMY_APP_TYPE};
-    Assert.assertEquals(EXIT_SUCCESS, runCLI(args));
-  }
-
-  private void buildApp(String serviceName, String appDef,
-      String lifetime, String queue) throws Throwable {
-    String[] args = {"app",
-        "-D", basedirProp, "-save", serviceName,
-        ExampleAppJson.resourceName(appDef),
-        "-appTypes", DUMMY_APP_TYPE,
-        "-updateLifetime", lifetime,
-        "-changeQueue", queue};
-    Assert.assertEquals(EXIT_SUCCESS, runCLI(args));
-  }
-
-  private static Path getDependencyTarGz(File dir) {
-    return new Path(new File(dir, YarnServiceConstants
-        .DEPENDENCY_TAR_GZ_FILE_NAME + YarnServiceConstants
-        .DEPENDENCY_TAR_GZ_FILE_EXT).getAbsolutePath());
-  }
-
-  @Before
-  public void setup() throws Throwable {
-    basedir = new File("target", "apps");
-    basedirProp = YARN_SERVICE_BASE_PATH + "=" + basedir.getAbsolutePath();
-    conf.set(YARN_SERVICE_BASE_PATH, basedir.getAbsolutePath());
-    fs = new SliderFileSystem(conf);
-    dependencyTarGzBaseDir = tmpFolder.getRoot();
-    fs.getFileSystem()
-        .setPermission(new Path(dependencyTarGzBaseDir.getAbsolutePath()),
-            new FsPermission("755"));
-    dependencyTarGz = getDependencyTarGz(dependencyTarGzBaseDir);
-    dependencyTarGzProp = DEPENDENCY_TARBALL_PATH + "=" + dependencyTarGz
-        .toString();
-    conf.set(DEPENDENCY_TARBALL_PATH, dependencyTarGz.toString());
-
-    if (basedir.exists()) {
-      FileUtils.deleteDirectory(basedir);
-    } else {
-      basedir.mkdirs();
-    }
-    yarnAdminNoneAclProp = YarnConfiguration.YARN_ADMIN_ACL + "=none";
-    dfsAdminAclProp = DFSConfigKeys.DFS_ADMIN + "=" +
-        UserGroupInformation.getCurrentUser();
-    System.setProperty(YarnServiceConstants.PROPERTY_LIB_DIR, basedir
-        .getAbsolutePath());
-    createCLI();
-  }
-
-  @After
-  public void tearDown() throws IOException {
-    if (basedir != null) {
-      FileUtils.deleteDirectory(basedir);
-    }
-    cli.stop();
-  }
-
-  @Test (timeout = 180000)
-  public void testFlexComponents() throws Throwable {
-    // currently can only test building apps, since that is the only
-    // operation that doesn't require an RM
-    // TODO: expand CLI test to try other commands
-    String serviceName = "app-1";
-    buildApp(serviceName, ExampleAppJson.APP_JSON);
-    checkApp(serviceName, "master", 1L, 3600L, null);
-
-    serviceName = "app-2";
-    buildApp(serviceName, ExampleAppJson.APP_JSON, "1000", "qname");
-    checkApp(serviceName, "master", 1L, 1000L, "qname");
-  }
-
-  @Test
-  public void testInitiateServiceUpgrade() throws Exception {
-    String[] args = {"app", "-upgrade", "app-1",
-        "-initiate", ExampleAppJson.resourceName(ExampleAppJson.APP_JSON),
-        "-appTypes", DUMMY_APP_TYPE};
-    int result = cli.run(ApplicationCLI.preProcessArgs(args));
-    assertThat(result).isEqualTo(0);
-  }
-
-  @Test (timeout = 180000)
-  public void testInitiateAutoFinalizeServiceUpgrade() throws Exception {
-    String[] args =  {"app", "-upgrade", "app-1",
-        "-initiate", ExampleAppJson.resourceName(ExampleAppJson.APP_JSON),
-        "-autoFinalize",
-        "-appTypes", DUMMY_APP_TYPE};
-    int result = cli.run(ApplicationCLI.preProcessArgs(args));
-    assertThat(result).isEqualTo(0);
-  }
-
-  @Test
-  public void testUpgradeInstances() throws Exception {
-    conf.set(YARN_APP_ADMIN_CLIENT_PREFIX + DUMMY_APP_TYPE,
-        DummyServiceClient.class.getName());
-    cli.setConf(conf);
-    String[] args = {"app", "-upgrade", "app-1",
-        "-instances", "comp1-0,comp1-1",
-        "-appTypes", DUMMY_APP_TYPE};
-    int result = cli.run(ApplicationCLI.preProcessArgs(args));
-    assertThat(result).isEqualTo(0);
-  }
-
-  @Test
-  public void testUpgradeComponents() throws Exception {
-    conf.set(YARN_APP_ADMIN_CLIENT_PREFIX + DUMMY_APP_TYPE,
-        DummyServiceClient.class.getName());
-    cli.setConf(conf);
-    String[] args = {"app", "-upgrade", "app-1",
-        "-components", "comp1,comp2",
-        "-appTypes", DUMMY_APP_TYPE};
-    int result = cli.run(ApplicationCLI.preProcessArgs(args));
-    assertThat(result).isEqualTo(0);
-  }
-
-  @Test
-  public void testGetInstances() throws Exception {
-    conf.set(YARN_APP_ADMIN_CLIENT_PREFIX + DUMMY_APP_TYPE,
-        DummyServiceClient.class.getName());
-    cli.setConf(conf);
-    String[] args = {"container", "-list", "app-1",
-        "-components", "comp1,comp2",
-        "-appTypes", DUMMY_APP_TYPE};
-    int result = cli.run(ApplicationCLI.preProcessArgs(args));
-    assertThat(result).isEqualTo(0);
-  }
-
-  @Test
-  public void testCancelUpgrade() throws Exception {
-    conf.set(YARN_APP_ADMIN_CLIENT_PREFIX + DUMMY_APP_TYPE,
-        DummyServiceClient.class.getName());
-    cli.setConf(conf);
-    String[] args = {"app", "-upgrade", "app-1",
-        "-cancel", "-appTypes", DUMMY_APP_TYPE};
-    int result = cli.run(ApplicationCLI.preProcessArgs(args));
-    assertThat(result).isEqualTo(0);
-  }
-
-  @Test (timeout = 180000)
-  public void testEnableFastLaunch() throws Exception {
-    fs.getFileSystem().create(new Path(basedir.getAbsolutePath(), "test.jar"))
-        .close();
-
-    Path defaultPath = new Path(dependencyTarGz.toString());
-    Assert.assertFalse("Dependency tarball should not exist before the test",
-        fs.isFile(defaultPath));
-    String[] args = {"app", "-D", dependencyTarGzProp, "-enableFastLaunch",
-        "-appTypes", DUMMY_APP_TYPE};
-    Assert.assertEquals(EXIT_SUCCESS, runCLI(args));
-    Assert.assertTrue("Dependency tarball did not exist after the test",
-        fs.isFile(defaultPath));
-
-    File secondBaseDir = new File(dependencyTarGzBaseDir, "2");
-    Path secondTarGz = getDependencyTarGz(secondBaseDir);
-    Assert.assertFalse("Dependency tarball should not exist before the test",
-        fs.isFile(secondTarGz));
-    String[] args2 = {"app", "-D", yarnAdminNoneAclProp, "-D",
-        dfsAdminAclProp, "-D", dependencyTarGzProp, "-enableFastLaunch",
-        secondBaseDir.getAbsolutePath(), "-appTypes", DUMMY_APP_TYPE};
-    Assert.assertEquals(EXIT_SUCCESS, runCLI(args2));
-    Assert.assertTrue("Dependency tarball did not exist after the test",
-        fs.isFile(secondTarGz));
-  }
-
-  @Test (timeout = 180000)
-  public void testEnableFastLaunchUserPermissions() throws Exception {
-    String[] args = {"app", "-D", yarnAdminNoneAclProp, "-D",
-        dependencyTarGzProp, "-enableFastLaunch", "-appTypes", DUMMY_APP_TYPE};
-    Assert.assertEquals(EXIT_UNAUTHORIZED, runCLI(args));
-  }
-
-  @Test (timeout = 180000)
-  public void testEnableFastLaunchFilePermissions() throws Exception {
-    File badDir = new File(dependencyTarGzBaseDir, "bad");
-    badDir.mkdir();
-    fs.getFileSystem().setPermission(new Path(badDir.getAbsolutePath()),
-        new FsPermission("751"));
-
-    String[] args = {"app", "-D", dependencyTarGzProp, "-enableFastLaunch",
-        badDir.getAbsolutePath(), "-appTypes", DUMMY_APP_TYPE};
-    Assert.assertEquals(EXIT_UNAUTHORIZED, runCLI(args));
-
-    badDir = new File(badDir, "child");
-    badDir.mkdir();
-    fs.getFileSystem().setPermission(new Path(badDir.getAbsolutePath()),
-        new FsPermission("755"));
-
-    String[] args2 = {"app", "-D", dependencyTarGzProp, "-enableFastLaunch",
-        badDir.getAbsolutePath(), "-appTypes", DUMMY_APP_TYPE};
-    Assert.assertEquals(EXIT_UNAUTHORIZED, runCLI(args2));
-
-    badDir = new File(dependencyTarGzBaseDir, "badx");
-    badDir.mkdir();
-    fs.getFileSystem().setPermission(new Path(badDir.getAbsolutePath()),
-        new FsPermission("754"));
-
-    String[] args3 = {"app", "-D", dependencyTarGzProp, "-enableFastLaunch",
-        badDir.getAbsolutePath(), "-appTypes", DUMMY_APP_TYPE};
-    Assert.assertEquals(EXIT_UNAUTHORIZED, runCLI(args3));
-  }
-
-  private void checkApp(String serviceName, String compName, long count, Long
-      lifetime, String queue) throws IOException {
-    Service service = ServiceApiUtil.loadService(fs, serviceName);
-    Assert.assertEquals(serviceName, service.getName());
-    Assert.assertEquals(lifetime, service.getLifetime());
-    Assert.assertEquals(queue, service.getQueue());
-    List<Component> components = service.getComponents();
-    for (Component component : components) {
-      if (component.getName().equals(compName)) {
-        Assert.assertEquals(count, component.getNumberOfContainers()
-            .longValue());
-        return;
-      }
-    }
-    Assert.fail();
-  }
-
-  private static final String DUMMY_APP_TYPE = "dummy";
-
-  /**
-   * Dummy service client for test purpose.
-   */
-  public static class DummyServiceClient extends ServiceClient {
-
-    @Override
-    public int initiateUpgrade(String appName, String fileName,
-        boolean autoFinalize) throws IOException, YarnException {
-      return 0;
-    }
-
-    @Override
-    public int actionUpgradeInstances(String appName,
-        List<String> componentInstances) throws IOException, YarnException {
-      return 0;
-    }
-
-    @Override
-    public int actionUpgradeComponents(String appName, List<String> components)
-        throws IOException, YarnException {
-      return 0;
-    }
-
-    @Override
-    public String getInstances(String appName, List<String> components,
-        String version, List<String> containerStates)
-        throws IOException, YarnException {
-      return "";
-    }
-
-    @Override
-    public int actionCancelUpgrade(String appName) throws IOException,
-        YarnException {
-      return 0;
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/client/TestServiceClient.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/client/TestServiceClient.java
deleted file mode 100644
index 85da12f4d0a..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/client/TestServiceClient.java
+++ /dev/null
@@ -1,334 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.client;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.util.Lists;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptReport;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.ApplicationReport;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState;
-import org.apache.hadoop.yarn.api.records.YarnApplicationState;
-import org.apache.hadoop.yarn.client.api.YarnClient;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.service.ClientAMProtocol;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CompInstancesUpgradeRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.CompInstancesUpgradeResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetCompInstancesRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetCompInstancesResponseProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.UpgradeServiceRequestProto;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.UpgradeServiceResponseProto;
-import org.apache.hadoop.yarn.service.MockRunningServiceContext;
-import org.apache.hadoop.yarn.service.ServiceContext;
-import org.apache.hadoop.yarn.service.ServiceTestUtils;
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.api.records.ComponentContainers;
-import org.apache.hadoop.yarn.service.api.records.Container;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConf;
-import org.apache.hadoop.yarn.service.exceptions.ErrorStrings;
-import org.apache.hadoop.yarn.service.utils.FilterUtils;
-import org.apache.hadoop.yarn.service.utils.ServiceApiUtil;
-import org.junit.Assert;
-import org.junit.Rule;
-import org.junit.Test;
-import org.mockito.stubbing.Answer;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-
-import static org.mockito.ArgumentMatchers.any;
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.when;
-
-/**
- * Tests for {@link ServiceClient}.
- */
-public class TestServiceClient {
-
-  private static final Logger LOG = LoggerFactory.getLogger(
-      TestServiceClient.class);
-
-  @Rule
-  public ServiceTestUtils.ServiceFSWatcher rule =
-      new ServiceTestUtils.ServiceFSWatcher();
-
-  @Test
-  public void testAMEnvCustomClasspath() throws Exception {
-    Service service = createService();
-    service.getComponents().forEach(comp ->
-            comp.setRestartPolicy(Component.RestartPolicyEnum.NEVER));
-    ServiceClient client = MockServiceClient.create(rule, service, true);
-    //saving the original value of the param, for restoration purposes
-    String oldParam = client.getConfig().get("yarn.service.classpath", "");
-    String originalPath = client.addAMEnv().get("CLASSPATH");
-
-    client.getConfig().set("yarn.service.classpath", "{{VAR_1}},{{VAR_2}}");
-    String newPath = client.addAMEnv().get("CLASSPATH");
-
-    Assert.assertEquals(originalPath + "<CPS>{{VAR_1}}<CPS>{{VAR_2}}", newPath);
-    //restoring the original value for service classpath
-    client.getConfig().set("yarn.service.classpath", oldParam);
-
-    newPath = client.addAMEnv().get("CLASSPATH");
-    Assert.assertEquals(originalPath, newPath);
-
-    client.stop();
-  }
-
-  @Test
-  public void testUpgradeDisabledByDefault() throws Exception {
-    Service service = createService();
-    ServiceClient client = MockServiceClient.create(rule, service, false);
-
-    //upgrade the service
-    service.setVersion("v2");
-    try {
-      client.initiateUpgrade(service);
-    } catch (YarnException ex) {
-      Assert.assertEquals(ErrorStrings.SERVICE_UPGRADE_DISABLED,
-          ex.getMessage());
-      return;
-    }
-    Assert.fail();
-  }
-
-  @Test
-  public void testActionServiceUpgrade() throws Exception {
-    Service service = createService();
-    ServiceClient client = MockServiceClient.create(rule, service, true);
-
-    //upgrade the service
-    service.setVersion("v2");
-    client.initiateUpgrade(service);
-
-    Service fromFs = ServiceApiUtil.loadServiceUpgrade(rule.getFs(),
-        service.getName(), service.getVersion());
-    Assert.assertEquals(service.getName(), fromFs.getName());
-    Assert.assertEquals(service.getVersion(), fromFs.getVersion());
-    client.stop();
-  }
-
-  @Test
-  public void testActionCompInstanceUpgrade() throws Exception {
-    Service service = createService();
-    MockServiceClient client = MockServiceClient.create(rule, service, true);
-
-    //upgrade the service
-    service.setVersion("v2");
-    client.initiateUpgrade(service);
-
-    //add containers to the component that needs to be upgraded.
-    Component comp = service.getComponents().iterator().next();
-    ContainerId containerId = ContainerId.newContainerId(client.attemptId, 1L);
-    comp.addContainer(new Container().id(containerId.toString()));
-
-    client.actionUpgrade(service, comp.getContainers());
-    CompInstancesUpgradeResponseProto response = client.getLastProxyResponse(
-        CompInstancesUpgradeResponseProto.class);
-    Assert.assertNotNull("upgrade did not complete", response);
-    client.stop();
-  }
-
-  @Test
-  public void testGetCompInstances() throws Exception {
-    Service service = createService();
-    MockServiceClient client = MockServiceClient.create(rule, service, true);
-
-    //upgrade the service
-    service.setVersion("v2");
-    client.initiateUpgrade(service);
-
-    //add containers to the component that needs to be upgraded.
-    Component comp = service.getComponents().iterator().next();
-    ContainerId containerId = ContainerId.newContainerId(client.attemptId, 1L);
-    comp.addContainer(new Container().id(containerId.toString()));
-
-    ComponentContainers[] compContainers = client.getContainers(
-        service.getName(), Lists.newArrayList("compa"), "v1", null);
-    Assert.assertEquals("num comp", 1, compContainers.length);
-    Assert.assertEquals("comp name", "compa",
-        compContainers[0].getComponentName());
-    Assert.assertEquals("num containers", 2,
-        compContainers[0].getContainers().size());
-    client.stop();
-  }
-
-  @Test
-  public void testUpgradeDisabledWhenAllCompsHaveNeverRestartPolicy()
-      throws Exception {
-    Service service = createService();
-    service.getComponents().forEach(comp ->
-        comp.setRestartPolicy(Component.RestartPolicyEnum.NEVER));
-
-    ServiceClient client = MockServiceClient.create(rule, service, true);
-
-    //upgrade the service
-    service.setVersion("v2");
-    try {
-      client.initiateUpgrade(service);
-    } catch (YarnException ex) {
-      Assert.assertEquals("All the components of the service " +
-              service.getName() + " have " + Component.RestartPolicyEnum.NEVER
-              + " restart policy, so it cannot be upgraded.",
-          ex.getMessage());
-      return;
-    }
-    Assert.fail();
-  }
-
-  private Service createService() throws IOException,
-      YarnException {
-    Service service = ServiceTestUtils.createExampleApplication();
-    service.setVersion("v1");
-    service.setState(ServiceState.UPGRADING);
-    return service;
-  }
-
-  private static final class MockServiceClient extends ServiceClient {
-
-    private final ApplicationId appId;
-    private final ApplicationAttemptId attemptId;
-    private final ClientAMProtocol amProxy;
-    private Object proxyResponse;
-    private Service service;
-    private ServiceContext context;
-
-    private MockServiceClient()  {
-      amProxy = mock(ClientAMProtocol.class);
-      appId = ApplicationId.newInstance(System.currentTimeMillis(), 1);
-      LOG.debug("mocking service client for {}", appId);
-      attemptId = ApplicationAttemptId.newInstance(appId, 1);
-    }
-
-    static MockServiceClient create(ServiceTestUtils.ServiceFSWatcher rule,
-        Service service, boolean enableUpgrade)
-        throws Exception {
-      MockServiceClient client = new MockServiceClient();
-      ApplicationId applicationId = ApplicationId.newInstance(
-          System.currentTimeMillis(), 1);
-      service.setId(applicationId.toString());
-      client.context = new MockRunningServiceContext(rule, service);
-
-      YarnClient yarnClient = createMockYarnClient();
-      ApplicationReport appReport = mock(ApplicationReport.class);
-      when(appReport.getHost()).thenReturn("localhost");
-      when(appReport.getYarnApplicationState()).thenReturn(
-          YarnApplicationState.RUNNING);
-
-      ApplicationAttemptReport attemptReport =
-          ApplicationAttemptReport.newInstance(client.attemptId, "localhost", 0,
-              null, null, null,
-              YarnApplicationAttemptState.RUNNING, null);
-      when(yarnClient.getApplicationAttemptReport(any()))
-          .thenReturn(attemptReport);
-      when(yarnClient.getApplicationReport(client.appId)).thenReturn(appReport);
-      when(client.amProxy.upgrade(
-          any(UpgradeServiceRequestProto.class))).thenAnswer(
-          (Answer<UpgradeServiceResponseProto>) invocation -> {
-              UpgradeServiceResponseProto response =
-                  UpgradeServiceResponseProto.newBuilder().build();
-              client.proxyResponse = response;
-              return response;
-            });
-      when(client.amProxy.upgrade(any(
-          CompInstancesUpgradeRequestProto.class))).thenAnswer(
-          (Answer<CompInstancesUpgradeResponseProto>) invocation -> {
-              CompInstancesUpgradeResponseProto response =
-                  CompInstancesUpgradeResponseProto.newBuilder().build();
-              client.proxyResponse = response;
-              return response;
-            });
-
-      when(client.amProxy.getCompInstances(any(
-          GetCompInstancesRequestProto.class))).thenAnswer(
-          (Answer<GetCompInstancesResponseProto>) invocation -> {
-
-              GetCompInstancesRequestProto req = (GetCompInstancesRequestProto)
-                  invocation.getArguments()[0];
-
-              List<ComponentContainers> compContainers =
-                  FilterUtils.filterInstances(client.context, req);
-              GetCompInstancesResponseProto response =
-                  GetCompInstancesResponseProto.newBuilder().setCompInstances(
-                      ServiceApiUtil.COMP_CONTAINERS_JSON_SERDE.toJson(
-                          compContainers.toArray(
-                              new ComponentContainers[compContainers.size()])))
-                      .build();
-
-              client.proxyResponse = response;
-              return response;
-          });
-
-      client.setFileSystem(rule.getFs());
-      client.setYarnClient(yarnClient);
-      client.service = service;
-      rule.getConf().setBoolean(YarnServiceConf.YARN_SERVICE_UPGRADE_ENABLED,
-          enableUpgrade);
-      client.init(rule.getConf());
-      client.start();
-      client.actionCreate(service);
-      return client;
-    }
-
-    @Override
-    protected void serviceInit(Configuration configuration) throws Exception {
-    }
-
-    @Override
-    protected ClientAMProtocol createAMProxy(String serviceName,
-        ApplicationReport appReport) throws IOException, YarnException {
-      return amProxy;
-    }
-
-    @Override
-    ApplicationId submitApp(Service app) throws IOException, YarnException {
-      return appId;
-    }
-
-    @Override
-    public Service getStatus(String serviceName) throws IOException,
-        YarnException {
-      service.setState(ServiceState.STABLE);
-      return service;
-    }
-
-    private <T> T getLastProxyResponse(Class<T> clazz) {
-      if (clazz.isInstance(proxyResponse)) {
-        return clazz.cast(proxyResponse);
-      }
-      return null;
-    }
-  }
-
-  private static YarnClient createMockYarnClient() throws IOException,
-      YarnException {
-    YarnClient yarnClient = mock(YarnClient.class);
-    when(yarnClient.getApplications(any(
-        GetApplicationsRequest.class))).thenReturn(new ArrayList<>());
-    return yarnClient;
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/component/TestComponent.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/component/TestComponent.java
deleted file mode 100644
index f8f948dd88f..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/component/TestComponent.java
+++ /dev/null
@@ -1,517 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.component;
-
-import org.apache.hadoop.yarn.api.records.Container;
-import org.apache.hadoop.yarn.api.records.ContainerStatus;
-import org.apache.hadoop.yarn.service.MockRunningServiceContext;
-import org.apache.hadoop.yarn.service.ServiceContext;
-import org.apache.hadoop.yarn.service.ServiceTestUtils;
-import org.apache.hadoop.yarn.service.TestServiceManager;
-import org.apache.hadoop.yarn.service.api.records.ComponentState;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEvent;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEventType;
-import org.apache.log4j.Logger;
-import org.junit.Assert;
-import org.junit.Rule;
-import org.junit.Test;
-
-import java.util.Iterator;
-
-import static org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEventType.BECOME_READY;
-import static org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEventType.START;
-import static org.apache.hadoop.yarn.service.component.instance.ComponentInstanceEventType.STOP;
-
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConstants
-    .CONTAINER_STATE_REPORT_AS_SERVICE_STATE;
-
-/**
- * Tests for {@link Component}.
- */
-public class TestComponent {
-
-  static final Logger LOG = Logger.getLogger(TestComponent.class);
-
-  @Rule
-  public ServiceTestUtils.ServiceFSWatcher rule =
-      new ServiceTestUtils.ServiceFSWatcher();
-
-  @Test
-  public void testComponentUpgrade() throws Exception {
-    ServiceContext context = createTestContext(rule, "testComponentUpgrade");
-    Component comp = context.scheduler.getAllComponents().entrySet().iterator()
-        .next().getValue();
-
-    ComponentEvent upgradeEvent = new ComponentEvent(comp.getName(),
-        ComponentEventType.UPGRADE);
-    comp.handle(upgradeEvent);
-    Assert.assertEquals("component not in need upgrade state",
-        ComponentState.NEEDS_UPGRADE, comp.getComponentSpec().getState());
-  }
-
-  @Test
-  public void testCheckState() throws Exception {
-    String serviceName = "testCheckState";
-    ServiceContext context = createTestContext(rule, serviceName);
-    Component comp = context.scheduler.getAllComponents().entrySet().iterator()
-        .next().getValue();
-
-    comp.handle(new ComponentEvent(comp.getName(), ComponentEventType.UPGRADE)
-        .setTargetSpec(createSpecWithEnv(serviceName, comp.getName(), "key1",
-            "val1")).setUpgradeVersion("v2"));
-
-    // one instance finished upgrading
-    comp.getUpgradeStatus().decContainersThatNeedUpgrade();
-    comp.handle(new ComponentEvent(comp.getName(),
-        ComponentEventType.CHECK_STABLE));
-    Assert.assertEquals("component not in need upgrade state",
-        ComponentState.NEEDS_UPGRADE, comp.getComponentSpec().getState());
-
-    // second instance finished upgrading
-    comp.getUpgradeStatus().decContainersThatNeedUpgrade();
-    comp.handle(new ComponentEvent(comp.getName(),
-        ComponentEventType.CHECK_STABLE));
-
-    Assert.assertEquals("component not in stable state",
-        ComponentState.STABLE, comp.getComponentSpec().getState());
-    Assert.assertEquals("component did not upgrade successfully", "val1",
-        comp.getComponentSpec().getConfiguration().getEnv("key1"));
-  }
-
-  @Test
-  public void testContainerCompletedWhenUpgrading() throws Exception {
-    String serviceName = "testContainerCompletedWhenUpgrading";
-    MockRunningServiceContext context = createTestContext(rule, serviceName);
-    Component comp = context.scheduler.getAllComponents().entrySet().iterator()
-        .next().getValue();
-
-    comp.handle(new ComponentEvent(comp.getName(), ComponentEventType.UPGRADE)
-        .setTargetSpec(createSpecWithEnv(serviceName, comp.getName(), "key1",
-            "val1")).setUpgradeVersion("v2"));
-    comp.getAllComponentInstances().forEach(instance ->
-        instance.handle(new ComponentInstanceEvent(
-        instance.getContainer().getId(), ComponentInstanceEventType.UPGRADE)));
-
-    // reinitialization of a container failed
-    for(ComponentInstance instance : comp.getAllComponentInstances()) {
-      ComponentEvent stopEvent = new ComponentEvent(comp.getName(),
-          ComponentEventType.CONTAINER_COMPLETED)
-          .setInstance(instance)
-          .setContainerId(instance.getContainer().getId());
-      comp.handle(stopEvent);
-      instance.handle(new ComponentInstanceEvent(
-          instance.getContainer().getId(), STOP));
-    }
-    comp.handle(new ComponentEvent(comp.getName(),
-        ComponentEventType.CHECK_STABLE));
-
-    Assert.assertEquals("component not in needs upgrade state",
-        ComponentState.NEEDS_UPGRADE, comp.getComponentSpec().getState());
-  }
-
-  @Test
-  public void testCancelUpgrade() throws Exception {
-    ServiceContext context = createTestContext(rule, "testCancelUpgrade");
-    Component comp = context.scheduler.getAllComponents().entrySet().iterator()
-        .next().getValue();
-
-    ComponentEvent upgradeEvent = new ComponentEvent(comp.getName(),
-        ComponentEventType.CANCEL_UPGRADE);
-    comp.handle(upgradeEvent);
-    Assert.assertEquals("component not in need upgrade state",
-        ComponentState.NEEDS_UPGRADE, comp.getComponentSpec().getState());
-
-    Assert.assertEquals(
-        org.apache.hadoop.yarn.service.component.ComponentState
-            .CANCEL_UPGRADING, comp.getState());
-  }
-
-  @Test
-  public void testContainerCompletedCancelUpgrade() throws Exception {
-    String serviceName = "testContainerCompletedCancelUpgrade";
-    MockRunningServiceContext context = createTestContext(rule, serviceName);
-    Component comp = context.scheduler.getAllComponents().entrySet().iterator()
-        .next().getValue();
-
-    // upgrade completes
-    comp.handle(new ComponentEvent(comp.getName(), ComponentEventType.UPGRADE)
-        .setTargetSpec(createSpecWithEnv(serviceName, comp.getName(), "key1",
-            "val1")).setUpgradeVersion("v2"));
-    comp.getAllComponentInstances().forEach(instance ->
-        instance.handle(new ComponentInstanceEvent(
-            instance.getContainer().getId(),
-            ComponentInstanceEventType.UPGRADE)));
-
-    // reinitialization of a container done
-    for(ComponentInstance instance : comp.getAllComponentInstances()) {
-      instance.handle(new ComponentInstanceEvent(
-          instance.getContainer().getId(), START));
-      instance.handle(new ComponentInstanceEvent(
-          instance.getContainer().getId(), BECOME_READY));
-    }
-
-    comp.handle(new ComponentEvent(comp.getName(),
-        ComponentEventType.CANCEL_UPGRADE)
-        .setTargetSpec(createSpecWithEnv(serviceName, comp.getName(), "key1",
-            "val0")).setUpgradeVersion("v1"));
-    comp.getAllComponentInstances().forEach(instance ->
-        instance.handle(new ComponentInstanceEvent(
-            instance.getContainer().getId(),
-            ComponentInstanceEventType.CANCEL_UPGRADE)));
-
-    Iterator<ComponentInstance> iter = comp.getAllComponentInstances()
-        .iterator();
-
-    // cancel upgrade failed of a container
-    ComponentInstance instance1 = iter.next();
-    ComponentEvent stopEvent = new ComponentEvent(comp.getName(),
-        ComponentEventType.CONTAINER_COMPLETED)
-        .setInstance(instance1)
-        .setContainerId(instance1.getContainer().getId());
-    comp.handle(stopEvent);
-    instance1.handle(new ComponentInstanceEvent(
-        instance1.getContainer().getId(), STOP));
-    Assert.assertEquals(
-        org.apache.hadoop.yarn.service.component.ComponentState
-            .CANCEL_UPGRADING, comp.getState());
-
-    comp.handle(new ComponentEvent(comp.getName(),
-        ComponentEventType.CHECK_STABLE));
-
-    Assert.assertEquals("component not in needs upgrade state",
-        ComponentState.NEEDS_UPGRADE, comp.getComponentSpec().getState());
-    Assert.assertEquals(
-        org.apache.hadoop.yarn.service.component.ComponentState
-            .CANCEL_UPGRADING, comp.getState());
-
-    // second instance finished upgrading
-    ComponentInstance instance2 = iter.next();
-    instance2.handle(new ComponentInstanceEvent(
-        instance2.getContainer().getId(), ComponentInstanceEventType.START));
-    instance2.handle(new ComponentInstanceEvent(
-        instance2.getContainer().getId(),
-        ComponentInstanceEventType.BECOME_READY));
-
-    comp.handle(new ComponentEvent(comp.getName(),
-        ComponentEventType.CHECK_STABLE));
-
-    Assert.assertEquals("component not in flexing state",
-        ComponentState.FLEXING, comp.getComponentSpec().getState());
-    // new container get allocated
-    context.assignNewContainer(context.attemptId, 10, comp);
-
-    comp.handle(new ComponentEvent(comp.getName(),
-            ComponentEventType.CHECK_STABLE));
-
-    Assert.assertEquals("component not in stable state",
-        ComponentState.STABLE, comp.getComponentSpec().getState());
-    Assert.assertEquals("cancel upgrade failed", "val0",
-        comp.getComponentSpec().getConfiguration().getEnv("key1"));
-  }
-
-  @Test
-  public void testCancelUpgradeSuccessWhileUpgrading() throws Exception {
-    String serviceName = "testCancelUpgradeWhileUpgrading";
-    MockRunningServiceContext context = createTestContext(rule, serviceName);
-    Component comp = context.scheduler.getAllComponents().entrySet().iterator()
-        .next().getValue();
-    cancelUpgradeWhileUpgrading(context, comp);
-
-    // cancel upgrade successful for both instances
-    for(ComponentInstance instance : comp.getAllComponentInstances()) {
-      instance.handle(new ComponentInstanceEvent(
-          instance.getContainer().getId(),
-          ComponentInstanceEventType.START));
-      instance.handle(new ComponentInstanceEvent(
-          instance.getContainer().getId(),
-          ComponentInstanceEventType.BECOME_READY));
-    }
-
-    comp.handle(new ComponentEvent(comp.getName(),
-        ComponentEventType.CHECK_STABLE));
-
-    Assert.assertEquals("component not in stable state",
-        ComponentState.STABLE, comp.getComponentSpec().getState());
-    Assert.assertEquals("cancel upgrade failed", "val0",
-        comp.getComponentSpec().getConfiguration().getEnv("key1"));
-  }
-
-  @Test
-  public void testCancelUpgradeFailureWhileUpgrading() throws Exception {
-    String serviceName = "testCancelUpgradeFailureWhileUpgrading";
-    MockRunningServiceContext context = createTestContext(rule, serviceName);
-    Component comp = context.scheduler.getAllComponents().entrySet().iterator()
-        .next().getValue();
-    cancelUpgradeWhileUpgrading(context, comp);
-
-    // cancel upgrade failed for both instances
-    for(ComponentInstance instance : comp.getAllComponentInstances()) {
-      instance.handle(new ComponentInstanceEvent(
-          instance.getContainer().getId(),
-          ComponentInstanceEventType.STOP));
-    }
-    comp.handle(new ComponentEvent(comp.getName(),
-        ComponentEventType.CHECK_STABLE));
-
-    Assert.assertEquals("component not in flexing state",
-        ComponentState.FLEXING, comp.getComponentSpec().getState());
-
-    for (ComponentInstance instance : comp.getAllComponentInstances()) {
-      // new container get allocated
-      context.assignNewContainer(context.attemptId, 10, comp);
-    }
-
-    comp.handle(new ComponentEvent(comp.getName(),
-        ComponentEventType.CHECK_STABLE));
-
-    Assert.assertEquals("component not in stable state",
-        ComponentState.STABLE, comp.getComponentSpec().getState());
-    Assert.assertEquals("cancel upgrade failed", "val0",
-        comp.getComponentSpec().getConfiguration().getEnv("key1"));
-  }
-
-  private void cancelUpgradeWhileUpgrading(
-      MockRunningServiceContext context, Component comp)
-      throws Exception {
-
-    comp.handle(new ComponentEvent(comp.getName(), ComponentEventType.UPGRADE)
-        .setTargetSpec(createSpecWithEnv(context.service.getName(),
-            comp.getName(), "key1", "val1")).setUpgradeVersion("v0"));
-
-    Iterator<ComponentInstance> iter = comp.getAllComponentInstances()
-        .iterator();
-
-    ComponentInstance instance1 = iter.next();
-
-    // instance1 is triggered to upgrade
-    instance1.handle(new ComponentInstanceEvent(
-        instance1.getContainer().getId(), ComponentInstanceEventType.UPGRADE));
-
-    // component upgrade is cancelled
-    comp.handle(new ComponentEvent(comp.getName(),
-        ComponentEventType.CANCEL_UPGRADE)
-        .setTargetSpec(createSpecWithEnv(context.service.getName(),
-            comp.getName(), "key1",
-            "val0")).setUpgradeVersion("v0"));
-
-    // all instances upgrade is cancelled.
-    comp.getAllComponentInstances().forEach(instance ->
-        instance.handle(new ComponentInstanceEvent(
-            instance.getContainer().getId(),
-            ComponentInstanceEventType.CANCEL_UPGRADE)));
-
-    // regular upgrade failed for instance 1
-    comp.handle(new ComponentEvent(comp.getName(),
-        ComponentEventType.CONTAINER_COMPLETED).setInstance(instance1)
-        .setContainerId(instance1.getContainer().getId()));
-    instance1.handle(new ComponentInstanceEvent(
-        instance1.getContainer().getId(), STOP));
-
-    // component should be in cancel upgrade
-    Assert.assertEquals(
-        org.apache.hadoop.yarn.service.component.ComponentState
-            .CANCEL_UPGRADING, comp.getState());
-
-    comp.handle(new ComponentEvent(comp.getName(),
-        ComponentEventType.CHECK_STABLE));
-
-    Assert.assertEquals("component not in needs upgrade state",
-        ComponentState.NEEDS_UPGRADE, comp.getComponentSpec().getState());
-    Assert.assertEquals(
-        org.apache.hadoop.yarn.service.component.ComponentState
-            .CANCEL_UPGRADING, comp.getState());
-  }
-
-  @Test
-  public void testComponentStateReachesStableStateWithTerminatingComponents()
-      throws
-      Exception {
-    final String serviceName =
-        "testComponentStateUpdatesWithTerminatingComponents";
-
-    Service testService = ServiceTestUtils.createTerminatingJobExample(
-        serviceName);
-    TestServiceManager.createDef(serviceName, testService);
-
-    ServiceContext context = new MockRunningServiceContext(rule, testService);
-
-    for (Component comp : context.scheduler.getAllComponents().values()) {
-
-      Iterator<ComponentInstance> instanceIter = comp.
-          getAllComponentInstances().iterator();
-
-      ComponentInstance componentInstance = instanceIter.next();
-      Container instanceContainer = componentInstance.getContainer();
-
-      Assert.assertEquals(0, comp.getNumSucceededInstances());
-      Assert.assertEquals(0, comp.getNumFailedInstances());
-      Assert.assertEquals(2, comp.getNumRunningInstances());
-      Assert.assertEquals(2, comp.getNumReadyInstances());
-      Assert.assertEquals(0, comp.getPendingInstances().size());
-
-      //stop 1 container
-      ContainerStatus containerStatus = ContainerStatus.newInstance(
-          instanceContainer.getId(),
-          org.apache.hadoop.yarn.api.records.ContainerState.COMPLETE,
-          "successful", 0);
-      comp.handle(new ComponentEvent(comp.getName(),
-          ComponentEventType.CONTAINER_COMPLETED).setStatus(containerStatus)
-          .setContainerId(instanceContainer.getId()));
-      componentInstance.handle(
-          new ComponentInstanceEvent(componentInstance.getContainer().getId(),
-              ComponentInstanceEventType.STOP).setStatus(containerStatus));
-
-      Assert.assertEquals(1, comp.getNumSucceededInstances());
-      Assert.assertEquals(0, comp.getNumFailedInstances());
-      Assert.assertEquals(1, comp.getNumRunningInstances());
-      Assert.assertEquals(1, comp.getNumReadyInstances());
-      Assert.assertEquals(0, comp.getPendingInstances().size());
-
-      org.apache.hadoop.yarn.service.component.ComponentState componentState =
-          Component.checkIfStable(comp);
-      Assert.assertEquals(
-          org.apache.hadoop.yarn.service.component.ComponentState.STABLE,
-          componentState);
-    }
-  }
-
-  @Test
-  public void testComponentStateUpdatesWithTerminatingComponents()
-      throws
-      Exception {
-    final String serviceName =
-        "testComponentStateUpdatesWithTerminatingComponents";
-
-    Service testService = ServiceTestUtils.createTerminatingJobExample(
-        serviceName);
-    TestServiceManager.createDef(serviceName, testService);
-
-    ServiceContext context = new MockRunningServiceContext(rule, testService);
-
-    for (Component comp : context.scheduler.getAllComponents().values()) {
-      Iterator<ComponentInstance> instanceIter = comp.
-          getAllComponentInstances().iterator();
-
-      while (instanceIter.hasNext()) {
-
-        ComponentInstance componentInstance = instanceIter.next();
-        Container instanceContainer = componentInstance.getContainer();
-
-        //stop 1 container
-        ContainerStatus containerStatus = ContainerStatus.newInstance(
-            instanceContainer.getId(),
-            org.apache.hadoop.yarn.api.records.ContainerState.COMPLETE,
-            "successful", 0);
-        comp.handle(new ComponentEvent(comp.getName(),
-            ComponentEventType.CONTAINER_COMPLETED).setStatus(containerStatus)
-            .setContainerId(instanceContainer.getId()));
-        componentInstance.handle(
-            new ComponentInstanceEvent(componentInstance.getContainer().getId(),
-                ComponentInstanceEventType.STOP).setStatus(containerStatus));
-      }
-
-      ComponentState componentState =
-          comp.getComponentSpec().getState();
-      Assert.assertEquals(
-          ComponentState.SUCCEEDED,
-          componentState);
-    }
-
-    ServiceState serviceState =
-        testService.getState();
-    Assert.assertEquals(
-        ServiceState.SUCCEEDED,
-        serviceState);
-  }
-
-  @Test
-  public void testComponentStateUpdatesWithTerminatingDominantComponents()
-      throws Exception {
-    final String serviceName =
-        "testComponentStateUpdatesWithTerminatingServiceStateComponents";
-
-    Service testService =
-        ServiceTestUtils.createTerminatingDominantComponentJobExample(
-            serviceName);
-    TestServiceManager.createDef(serviceName, testService);
-
-    ServiceContext context = new MockRunningServiceContext(rule, testService);
-
-    for (Component comp : context.scheduler.getAllComponents().values()) {
-      boolean componentIsDominant = comp.getComponentSpec()
-          .getConfiguration().getPropertyBool(
-              CONTAINER_STATE_REPORT_AS_SERVICE_STATE, false);
-      if (componentIsDominant) {
-        Iterator<ComponentInstance> instanceIter = comp.
-            getAllComponentInstances().iterator();
-
-        while (instanceIter.hasNext()) {
-
-          ComponentInstance componentInstance = instanceIter.next();
-          Container instanceContainer = componentInstance.getContainer();
-
-          //stop 1 container
-          ContainerStatus containerStatus = ContainerStatus.newInstance(
-              instanceContainer.getId(),
-              org.apache.hadoop.yarn.api.records.ContainerState.COMPLETE,
-              "successful", 0);
-          comp.handle(new ComponentEvent(comp.getName(),
-              ComponentEventType.CONTAINER_COMPLETED).setStatus(containerStatus)
-              .setContainerId(instanceContainer.getId()));
-          componentInstance.handle(
-              new ComponentInstanceEvent(componentInstance.getContainer().
-                  getId(), ComponentInstanceEventType.STOP).
-                  setStatus(containerStatus));
-        }
-        ComponentState componentState =
-            comp.getComponentSpec().getState();
-        Assert.assertEquals(
-            ComponentState.SUCCEEDED,
-            componentState);
-      }
-    }
-
-    ServiceState serviceState =
-        testService.getState();
-    Assert.assertEquals(
-        ServiceState.SUCCEEDED,
-        serviceState);
-  }
-
-  private static org.apache.hadoop.yarn.service.api.records.Component
-      createSpecWithEnv(String serviceName, String compName, String key,
-      String val) {
-    Service service = TestServiceManager.createBaseDef(serviceName);
-    org.apache.hadoop.yarn.service.api.records.Component spec =
-        service.getComponent(compName);
-    spec.getConfiguration().getEnv().put(key, val);
-    return spec;
-  }
-
-  public static MockRunningServiceContext createTestContext(
-      ServiceTestUtils.ServiceFSWatcher fsWatcher, String serviceName)
-      throws Exception {
-    return new MockRunningServiceContext(fsWatcher,
-        TestServiceManager.createBaseDef(serviceName));
-  }
-}
-
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/component/TestComponentDecommissionInstances.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/component/TestComponentDecommissionInstances.java
deleted file mode 100644
index e617410b0a6..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/component/TestComponentDecommissionInstances.java
+++ /dev/null
@@ -1,147 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.component;
-
-import org.apache.commons.io.FileUtils;
-import org.apache.hadoop.registry.client.binding.RegistryUtils;
-import org.apache.hadoop.test.GenericTestUtils;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.service.ServiceTestUtils;
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.api.records.Container;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.client.ServiceClient;
-import org.junit.After;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Rule;
-import org.junit.Test;
-import org.junit.rules.TemporaryFolder;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.File;
-import java.io.IOException;
-import java.util.Arrays;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Map;
-import java.util.Set;
-import java.util.concurrent.TimeoutException;
-
-/**
- * Test decommissioning component instances.
- */
-public class TestComponentDecommissionInstances extends ServiceTestUtils {
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestComponentDecommissionInstances.class);
-
-  private static final String APP_NAME = "test-decommission";
-  private static final String COMPA = "compa";
-
-  @Rule
-  public TemporaryFolder tmpFolder = new TemporaryFolder();
-
-  @Before
-  public void setup() throws Exception {
-    File tmpYarnDir = new File("target", "tmp");
-    FileUtils.deleteQuietly(tmpYarnDir);
-  }
-
-  @After
-  public void tearDown() throws IOException {
-    shutdown();
-  }
-
-  @Test
-  public void testDecommissionInstances() throws Exception {
-    setupInternal(3);
-    ServiceClient client = createClient(getConf());
-    Service exampleApp = new Service();
-    exampleApp.setName(APP_NAME);
-    exampleApp.setVersion("v1");
-    Component comp = createComponent(COMPA, 6L, "sleep 1000");
-    exampleApp.addComponent(comp);
-    client.actionCreate(exampleApp);
-    waitForServiceToBeStable(client, exampleApp);
-
-    checkInstances(client, COMPA + "-0", COMPA + "-1", COMPA + "-2",
-        COMPA + "-3", COMPA + "-4", COMPA + "-5");
-    client.actionDecommissionInstances(APP_NAME, Arrays.asList(COMPA + "-1",
-        COMPA + "-5"));
-    waitForNumInstances(client, 4);
-    checkInstances(client, COMPA + "-0", COMPA + "-2", COMPA + "-3",
-        COMPA + "-4");
-
-    // Stop and start service
-    client.actionStop(APP_NAME);
-    waitForServiceToBeInState(client, exampleApp, ServiceState.STOPPED);
-    client.actionStart(APP_NAME);
-    waitForServiceToBeStable(client, exampleApp);
-    checkInstances(client, COMPA + "-0", COMPA + "-2", COMPA + "-3",
-        COMPA + "-4");
-
-    Map<String, String> compCounts = new HashMap<>();
-    compCounts.put(COMPA, "5");
-    client.actionFlex(APP_NAME, compCounts);
-    waitForNumInstances(client, 5);
-    checkInstances(client, COMPA + "-0", COMPA + "-2", COMPA + "-3",
-        COMPA + "-4", COMPA + "-6");
-
-    client.actionDecommissionInstances(APP_NAME, Arrays.asList(COMPA + "-0."
-            + APP_NAME + "." + RegistryUtils.currentUser()));
-    waitForNumInstances(client, 4);
-    checkInstances(client, COMPA + "-2", COMPA + "-3",
-        COMPA + "-4", COMPA + "-6");
-  }
-
-  private static void waitForNumInstances(ServiceClient client, int
-      expectedInstances) throws TimeoutException, InterruptedException {
-    GenericTestUtils.waitFor(() -> {
-      try {
-        Service retrievedApp = client.getStatus(APP_NAME);
-        return retrievedApp.getComponent(COMPA).getContainers().size() ==
-            expectedInstances && retrievedApp.getState() == ServiceState.STABLE;
-      } catch (Exception e) {
-        e.printStackTrace();
-        return false;
-      }
-    }, 2000, 200000);
-  }
-
-  private static void checkInstances(ServiceClient client, String... instances)
-      throws IOException, YarnException {
-    Service service = client.getStatus(APP_NAME);
-    Component component = service.getComponent(COMPA);
-    Assert.assertEquals("Service state should be STABLE", ServiceState.STABLE,
-        service.getState());
-    Assert.assertEquals(instances.length + " containers are expected to be " +
-        "running", instances.length, component.getContainers().size());
-    Set<String> existingInstances = new HashSet<>();
-    for (Container cont : component.getContainers()) {
-      existingInstances.add(cont.getComponentInstanceName());
-    }
-    Assert.assertEquals(instances.length + " instances are expected to be " +
-        "running", instances.length, existingInstances.size());
-    for (String instance : instances) {
-      Assert.assertTrue("Expected instance did not exist " + instance,
-          existingInstances.contains(instance));
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/component/TestComponentRestartPolicy.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/component/TestComponentRestartPolicy.java
deleted file mode 100644
index 3e3b4a1a3dc..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/component/TestComponentRestartPolicy.java
+++ /dev/null
@@ -1,131 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.component;
-
-import org.apache.hadoop.yarn.api.records.ContainerStatus;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.junit.Test;
-
-import static org.junit.Assert.assertEquals;
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.when;
-
-/**
- * Tests for ComponentRestartPolicy implementations.
- */
-public class TestComponentRestartPolicy {
-
-  @Test
-  public void testAlwaysRestartPolicy() throws Exception {
-
-    AlwaysRestartPolicy alwaysRestartPolicy = AlwaysRestartPolicy.getInstance();
-
-    Component component = mock(Component.class);
-    when(component.getNumReadyInstances()).thenReturn(1);
-    when(component.getNumDesiredInstances()).thenReturn(2);
-
-    ComponentInstance instance = mock(ComponentInstance.class);
-    when(instance.getComponent()).thenReturn(component);
-
-    ContainerStatus containerStatus = mock(ContainerStatus.class);
-
-    assertEquals(true, alwaysRestartPolicy.isLongLived());
-    assertEquals(true, alwaysRestartPolicy.allowUpgrades());
-    assertEquals(false, alwaysRestartPolicy.hasCompleted(component));
-    assertEquals(false,
-        alwaysRestartPolicy.hasCompletedSuccessfully(component));
-
-    assertEquals(true,
-        alwaysRestartPolicy.shouldRelaunchInstance(instance, containerStatus));
-
-    assertEquals(false, alwaysRestartPolicy.isReadyForDownStream(component));
-  }
-
-  @Test
-  public void testNeverRestartPolicy() throws Exception {
-
-    NeverRestartPolicy restartPolicy = NeverRestartPolicy.getInstance();
-
-    Component component = mock(Component.class);
-    when(component.getNumSucceededInstances()).thenReturn(new Long(1));
-    when(component.getNumFailedInstances()).thenReturn(new Long(2));
-    when(component.getNumDesiredInstances()).thenReturn(3);
-    when(component.getNumReadyInstances()).thenReturn(3);
-
-    ComponentInstance instance = mock(ComponentInstance.class);
-    when(instance.getComponent()).thenReturn(component);
-
-    ContainerStatus containerStatus = mock(ContainerStatus.class);
-
-    assertEquals(false, restartPolicy.isLongLived());
-    assertEquals(false, restartPolicy.allowUpgrades());
-    assertEquals(true, restartPolicy.hasCompleted(component));
-    assertEquals(false,
-        restartPolicy.hasCompletedSuccessfully(component));
-
-    assertEquals(false,
-        restartPolicy.shouldRelaunchInstance(instance, containerStatus));
-
-    assertEquals(true, restartPolicy.isReadyForDownStream(component));
-  }
-
-  @Test
-  public void testOnFailureRestartPolicy() throws Exception {
-
-    OnFailureRestartPolicy restartPolicy = OnFailureRestartPolicy.getInstance();
-
-    Component component = mock(Component.class);
-    when(component.getNumSucceededInstances()).thenReturn(new Long(3));
-    when(component.getNumFailedInstances()).thenReturn(new Long(0));
-    when(component.getNumDesiredInstances()).thenReturn(3);
-    when(component.getNumReadyInstances()).thenReturn(3);
-
-    ComponentInstance instance = mock(ComponentInstance.class);
-    when(instance.getComponent()).thenReturn(component);
-
-    ContainerStatus containerStatus = mock(ContainerStatus.class);
-    when(containerStatus.getExitStatus()).thenReturn(0);
-
-    assertEquals(false, restartPolicy.isLongLived());
-    assertEquals(false, restartPolicy.allowUpgrades());
-    assertEquals(true, restartPolicy.hasCompleted(component));
-    assertEquals(true,
-        restartPolicy.hasCompletedSuccessfully(component));
-
-    assertEquals(false,
-        restartPolicy.shouldRelaunchInstance(instance, containerStatus));
-
-    assertEquals(true, restartPolicy.isReadyForDownStream(component));
-
-    when(component.getNumSucceededInstances()).thenReturn(new Long(2));
-    when(component.getNumFailedInstances()).thenReturn(new Long(1));
-    when(component.getNumDesiredInstances()).thenReturn(3);
-
-    assertEquals(false, restartPolicy.hasCompleted(component));
-    assertEquals(false,
-        restartPolicy.hasCompletedSuccessfully(component));
-
-    when(containerStatus.getExitStatus()).thenReturn(-1000);
-
-    assertEquals(true,
-        restartPolicy.shouldRelaunchInstance(instance, containerStatus));
-
-    assertEquals(true, restartPolicy.isReadyForDownStream(component));
-
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/component/instance/TestComponentInstance.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/component/instance/TestComponentInstance.java
deleted file mode 100644
index 06bca6f1b00..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/component/instance/TestComponentInstance.java
+++ /dev/null
@@ -1,819 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.component.instance;
-
-import org.apache.hadoop.util.Lists;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.ContainerExitStatus;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.api.records.ContainerStatus;
-import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;
-import org.apache.hadoop.yarn.api.records.LocalizationState;
-import org.apache.hadoop.yarn.api.records.LocalizationStatus;
-import org.apache.hadoop.yarn.service.MockRunningServiceContext;
-import org.apache.hadoop.yarn.service.ServiceContext;
-import org.apache.hadoop.yarn.service.ServiceScheduler;
-import org.apache.hadoop.yarn.service.ServiceTestUtils;
-import org.apache.hadoop.yarn.service.api.records.Configuration;
-import org.apache.hadoop.yarn.service.TestServiceManager;
-import org.apache.hadoop.yarn.service.api.records.ConfigFile;
-import org.apache.hadoop.yarn.service.api.records.Container;
-import org.apache.hadoop.yarn.service.api.records.ContainerState;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.component.Component;
-import org.apache.hadoop.yarn.service.component.ComponentEvent;
-import org.apache.hadoop.yarn.service.component.ComponentEventType;
-import org.apache.hadoop.yarn.service.component.TestComponent;
-import org.apache.hadoop.yarn.service.utils.ServiceUtils;
-import org.junit.Assert;
-import org.junit.Rule;
-import org.junit.Test;
-import org.mockito.Mockito;
-
-import java.nio.file.Files;
-import java.nio.file.Paths;
-import java.nio.file.StandardOpenOption;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.Map;
-import java.util.concurrent.ConcurrentHashMap;
-
-import static org.mockito.ArgumentMatchers.any;
-import static org.mockito.ArgumentMatchers.anyInt;
-import static org.mockito.ArgumentMatchers.eq;
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.never;
-import static org.mockito.Mockito.spy;
-import static org.mockito.Mockito.times;
-import static org.mockito.Mockito.verify;
-import static org.mockito.Mockito.when;
-
-/**
- * Tests for {@link ComponentInstance}.
- */
-public class TestComponentInstance {
-
-  @Rule
-  public ServiceTestUtils.ServiceFSWatcher rule =
-      new ServiceTestUtils.ServiceFSWatcher();
-
-  @Test
-  public void testContainerUpgrade() throws Exception {
-    ServiceContext context = TestComponent.createTestContext(rule,
-        "testContainerUpgrade");
-    Component component = context.scheduler.getAllComponents().entrySet()
-        .iterator().next().getValue();
-    upgradeComponent(component);
-
-    ComponentInstance instance = component.getAllComponentInstances().iterator()
-        .next();
-    ComponentInstanceEvent instanceEvent = new ComponentInstanceEvent(
-        instance.getContainer().getId(), ComponentInstanceEventType.UPGRADE);
-    instance.handle(instanceEvent);
-    Container containerSpec = component.getComponentSpec().getContainer(
-        instance.getContainer().getId().toString());
-    Assert.assertEquals("instance not upgrading", ContainerState.UPGRADING,
-        containerSpec.getState());
-  }
-
-  @Test
-  public void testContainerReadyAfterUpgrade() throws Exception {
-    ServiceContext context = TestComponent.createTestContext(rule,
-        "testContainerReadyAfterUpgrade");
-    Component component = context.scheduler.getAllComponents().entrySet()
-        .iterator().next().getValue();
-    upgradeComponent(component);
-
-    ComponentInstance instance = component.getAllComponentInstances().iterator()
-        .next();
-
-    ComponentInstanceEvent instanceEvent = new ComponentInstanceEvent(
-        instance.getContainer().getId(), ComponentInstanceEventType.UPGRADE);
-    instance.handle(instanceEvent);
-    instance.handle(new ComponentInstanceEvent(instance.getContainer().getId(),
-        ComponentInstanceEventType.START));
-    Assert.assertEquals("instance not running",
-        ContainerState.RUNNING_BUT_UNREADY,
-        component.getComponentSpec().getContainer(instance.getContainer()
-            .getId().toString()).getState());
-    instance.handle(new ComponentInstanceEvent(instance.getContainer().getId(),
-        ComponentInstanceEventType.BECOME_READY));
-    Assert.assertEquals("instance not ready", ContainerState.READY,
-        component.getComponentSpec().getContainer(instance.getContainer()
-            .getId().toString()).getState());
-  }
-
-
-  @Test
-  public void testContainerUpgradeFailed() throws Exception {
-    ServiceContext context = TestComponent.createTestContext(rule,
-        "testContainerUpgradeFailed");
-    Component component = context.scheduler.getAllComponents().entrySet()
-        .iterator().next().getValue();
-    upgradeComponent(component);
-
-    ComponentInstance instance = component.getAllComponentInstances().iterator()
-        .next();
-
-    ComponentInstanceEvent upgradeEvent = new ComponentInstanceEvent(
-        instance.getContainer().getId(), ComponentInstanceEventType.UPGRADE);
-    instance.handle(upgradeEvent);
-
-    ContainerStatus containerStatus = mock(ContainerStatus.class);
-    when(containerStatus.getExitStatus()).thenReturn(
-        ContainerExitStatus.ABORTED);
-    ComponentInstanceEvent stopEvent = new ComponentInstanceEvent(
-        instance.getContainer().getId(), ComponentInstanceEventType.STOP)
-        .setStatus(containerStatus);
-    // this is the call back from NM for the upgrade
-    instance.handle(stopEvent);
-    Assert.assertEquals("instance did not fail", ContainerState.FAILED_UPGRADE,
-        component.getComponentSpec().getContainer(instance.getContainer()
-            .getId().toString()).getState());
-  }
-
-  @Test
-  public void testFailureAfterReinit() throws Exception {
-    ServiceContext context = TestComponent.createTestContext(rule,
-        "testContainerUpgradeFailed");
-    Component component = context.scheduler.getAllComponents().entrySet()
-        .iterator().next().getValue();
-    upgradeComponent(component);
-
-    ComponentInstance instance = component.getAllComponentInstances().iterator()
-        .next();
-
-    ComponentInstanceEvent upgradeEvent = new ComponentInstanceEvent(
-        instance.getContainer().getId(), ComponentInstanceEventType.UPGRADE);
-    instance.handle(upgradeEvent);
-
-    // NM finished updgrae
-    instance.handle(new ComponentInstanceEvent(instance.getContainer().getId(),
-        ComponentInstanceEventType.START));
-    Assert.assertEquals("instance not running",
-        ContainerState.RUNNING_BUT_UNREADY,
-        component.getComponentSpec().getContainer(instance.getContainer()
-            .getId().toString()).getState());
-
-    ContainerStatus containerStatus = mock(ContainerStatus.class);
-    when(containerStatus.getExitStatus()).thenReturn(
-        ContainerExitStatus.ABORTED);
-    ComponentInstanceEvent stopEvent = new ComponentInstanceEvent(
-        instance.getContainer().getId(), ComponentInstanceEventType.STOP)
-        .setStatus(containerStatus);
-    // this is the call back from NM for the upgrade
-    instance.handle(stopEvent);
-    Assert.assertEquals("instance did not fail", ContainerState.FAILED_UPGRADE,
-        component.getComponentSpec().getContainer(instance.getContainer()
-            .getId().toString()).getState());
-  }
-
-  @Test
-  public void testCancelNothingToUpgrade() throws Exception {
-    ServiceContext context = TestComponent.createTestContext(rule,
-        "testCancelUpgradeWhenContainerReady");
-    Component component = context.scheduler.getAllComponents().entrySet()
-        .iterator().next().getValue();
-    cancelCompUpgrade(component);
-
-    ComponentInstance instance = component.getAllComponentInstances().iterator()
-        .next();
-
-    ComponentInstanceEvent cancelEvent = new ComponentInstanceEvent(
-        instance.getContainer().getId(),
-        ComponentInstanceEventType.CANCEL_UPGRADE);
-    instance.handle(cancelEvent);
-
-    Assert.assertEquals("instance not ready", ContainerState.READY,
-        component.getComponentSpec().getContainer(instance.getContainer()
-            .getId().toString()).getState());
-  }
-
-  @Test
-  public void testCancelUpgradeFailed() throws Exception {
-    ServiceContext context = TestComponent.createTestContext(rule,
-        "testCancelUpgradeFailed");
-    Component component = context.scheduler.getAllComponents().entrySet()
-        .iterator().next().getValue();
-    cancelCompUpgrade(component);
-
-    ComponentInstance instance = component.getAllComponentInstances().iterator()
-        .next();
-
-    ComponentInstanceEvent cancelEvent = new ComponentInstanceEvent(
-        instance.getContainer().getId(),
-        ComponentInstanceEventType.CANCEL_UPGRADE);
-    instance.handle(cancelEvent);
-
-    instance.handle(new ComponentInstanceEvent(instance.getContainer().getId(),
-        ComponentInstanceEventType.STOP));
-    Assert.assertEquals("instance not init", ComponentInstanceState.INIT,
-        instance.getState());
-  }
-
-  @Test
-  public void testCancelAfterCompProcessedCancel() throws Exception {
-    ServiceContext context = TestComponent.createTestContext(rule,
-        "testCancelAfterCompProcessedCancel");
-    Component component = context.scheduler.getAllComponents().entrySet()
-        .iterator().next().getValue();
-    upgradeComponent(component);
-    cancelCompUpgrade(component);
-
-    ComponentInstance instance = component.getAllComponentInstances().iterator()
-        .next();
-    ComponentInstanceEvent upgradeEvent = new ComponentInstanceEvent(
-        instance.getContainer().getId(), ComponentInstanceEventType.UPGRADE);
-    instance.handle(upgradeEvent);
-
-    Assert.assertEquals("instance should start upgrading",
-        ContainerState.NEEDS_UPGRADE,
-        component.getComponentSpec().getContainer(instance.getContainer()
-            .getId().toString()).getState());
-  }
-
-  @Test
-  public void testCancelWhileUpgradeWithSuccess() throws Exception {
-    validateCancelWhileUpgrading(true, true);
-  }
-
-  @Test
-  public void testCancelWhileUpgradeWithFailure() throws Exception {
-    validateCancelWhileUpgrading(false, true);
-  }
-
-  @Test
-  public void testCancelFailedWhileUpgradeWithSuccess() throws Exception {
-    validateCancelWhileUpgrading(true, false);
-  }
-
-  @Test
-  public void testCancelFailedWhileUpgradeWithFailure() throws Exception {
-    validateCancelWhileUpgrading(false, false);
-  }
-
-  @Test
-  public void testUpdateLocalizationStatuses() throws Exception {
-    Service def = TestServiceManager.createBaseDef(
-        "testUpdateLocalizationStatuses");
-
-    String file1 = rule.getServiceBasePath().toString() + "/file1";
-    Files.write(Paths.get(file1), "test file".getBytes(),
-        StandardOpenOption.CREATE_NEW);
-
-    org.apache.hadoop.yarn.service.api.records.Component compDef =
-        def.getComponents().iterator().next();
-    ConfigFile configFile1 = new ConfigFile();
-    configFile1.setType(ConfigFile.TypeEnum.STATIC);
-    configFile1.setSrcFile(file1);
-    compDef.setConfiguration(new Configuration().files(
-        Lists.newArrayList(configFile1)));
-
-    ServiceContext context = new MockRunningServiceContext(rule, def);
-    Component component = context.scheduler.getAllComponents().get(
-        compDef.getName());
-    ComponentInstance instance = component.getAllComponentInstances().iterator()
-        .next();
-    LocalizationStatus status = LocalizationStatus.newInstance("file1",
-        LocalizationState.PENDING);
-
-    instance.updateLocalizationStatuses(Lists.newArrayList(status));
-    Assert.assertTrue("retriever should still be active",
-        instance.isLclRetrieverActive());
-
-    Container container = instance.getContainerSpec();
-    Assert.assertTrue(container.getLocalizationStatuses() != null);
-    Assert.assertEquals("dest file",
-        container.getLocalizationStatuses().get(0).getDestFile(),
-        status.getResourceKey());
-    Assert.assertEquals("state",
-        container.getLocalizationStatuses().get(0).getState(),
-        status.getLocalizationState());
-
-    status = LocalizationStatus.newInstance("file1",
-        LocalizationState.COMPLETED);
-    instance.updateLocalizationStatuses(Lists.newArrayList(status));
-    Assert.assertTrue("retriever should not be active",
-        !instance.isLclRetrieverActive());
-    Assert.assertTrue(container.getLocalizationStatuses() != null);
-    Assert.assertEquals("dest file",
-        container.getLocalizationStatuses().get(0).getDestFile(),
-        status.getResourceKey());
-    Assert.assertEquals("state",
-        container.getLocalizationStatuses().get(0).getState(),
-        status.getLocalizationState());
-  }
-
-  private void validateCancelWhileUpgrading(boolean upgradeSuccessful,
-      boolean cancelUpgradeSuccessful)
-      throws Exception {
-    ServiceContext context = TestComponent.createTestContext(rule,
-        "testCancelWhileUpgrading");
-    Component component = context.scheduler.getAllComponents().entrySet()
-        .iterator().next().getValue();
-    upgradeComponent(component);
-
-    ComponentInstance instance = component.getAllComponentInstances().iterator()
-        .next();
-    ComponentInstanceEvent upgradeEvent = new ComponentInstanceEvent(
-        instance.getContainer().getId(), ComponentInstanceEventType.UPGRADE);
-    instance.handle(upgradeEvent);
-
-    Assert.assertEquals("instance should be upgrading",
-        ContainerState.UPGRADING,
-        component.getComponentSpec().getContainer(instance.getContainer()
-            .getId().toString()).getState());
-
-    cancelCompUpgrade(component);
-    ComponentInstanceEvent cancelEvent = new ComponentInstanceEvent(
-        instance.getContainer().getId(),
-        ComponentInstanceEventType.CANCEL_UPGRADE);
-    instance.handle(cancelEvent);
-
-    // either upgrade failed or successful
-    if (upgradeSuccessful) {
-      instance.handle(new ComponentInstanceEvent(
-          instance.getContainer().getId(), ComponentInstanceEventType.START));
-      instance.handle(new ComponentInstanceEvent(
-          instance.getContainer().getId(),
-          ComponentInstanceEventType.BECOME_READY));
-    } else {
-      instance.handle(new ComponentInstanceEvent(
-          instance.getContainer().getId(),
-          ComponentInstanceEventType.STOP));
-    }
-
-    Assert.assertEquals("instance not upgrading", ContainerState.UPGRADING,
-        component.getComponentSpec().getContainer(instance.getContainer()
-            .getId().toString()).getState());
-
-    // response for cancel received
-    if (cancelUpgradeSuccessful) {
-      instance.handle(new ComponentInstanceEvent(
-          instance.getContainer().getId(), ComponentInstanceEventType.START));
-      instance.handle(new ComponentInstanceEvent(
-          instance.getContainer().getId(),
-          ComponentInstanceEventType.BECOME_READY));
-    } else {
-      instance.handle(new ComponentInstanceEvent(
-          instance.getContainer().getId(), ComponentInstanceEventType.STOP));
-    }
-    if (cancelUpgradeSuccessful) {
-      Assert.assertEquals("instance not ready", ContainerState.READY,
-          component.getComponentSpec().getContainer(instance.getContainer()
-              .getId().toString()).getState());
-    } else {
-      Assert.assertEquals("instance not init", ComponentInstanceState.INIT,
-          instance.getState());
-    }
-  }
-
-  private void upgradeComponent(Component component) {
-    component.handle(new ComponentEvent(component.getName(),
-        ComponentEventType.UPGRADE).setTargetSpec(component.getComponentSpec())
-        .setUpgradeVersion("v2"));
-  }
-
-  private void cancelCompUpgrade(Component component) {
-    component.handle(new ComponentEvent(component.getName(),
-        ComponentEventType.CANCEL_UPGRADE)
-        .setTargetSpec(component.getComponentSpec())
-        .setUpgradeVersion("v1"));
-  }
-
-  private Component createComponent(ServiceScheduler scheduler,
-      org.apache.hadoop.yarn.service.api.records.Component.RestartPolicyEnum
-          restartPolicy, int nSucceededInstances, int nFailedInstances,
-      int totalAsk, int componentId) {
-
-    assert (nSucceededInstances + nFailedInstances) <= totalAsk;
-
-    Component comp = mock(Component.class);
-    org.apache.hadoop.yarn.service.api.records.Component componentSpec = mock(
-        org.apache.hadoop.yarn.service.api.records.Component.class);
-    when(componentSpec.getRestartPolicy()).thenReturn(restartPolicy);
-    Configuration conf = new Configuration();
-    when(componentSpec.getConfiguration()).thenReturn(conf);
-    when(comp.getRestartPolicyHandler()).thenReturn(
-        Component.getRestartPolicyHandler(restartPolicy));
-    when(componentSpec.getNumberOfContainers()).thenReturn(
-        Long.valueOf(totalAsk));
-    when(comp.getComponentSpec()).thenReturn(componentSpec);
-    when(comp.getScheduler()).thenReturn(scheduler);
-
-    Map<String, ComponentInstance> succeeded = new ConcurrentHashMap<>();
-    Map<String, ComponentInstance> failed = new ConcurrentHashMap<>();
-    scheduler.getAllComponents().put("comp" + componentId, comp);
-
-    Map<String, ComponentInstance> componentInstances = new HashMap<>();
-
-    for (int i = 0; i < nSucceededInstances; i++) {
-      ComponentInstance componentInstance = createComponentInstance(comp, i);
-      componentInstances.put(componentInstance.getCompInstanceName(),
-          componentInstance);
-      succeeded.put(componentInstance.getCompInstanceName(), componentInstance);
-    }
-
-    for (int i = 0; i < nFailedInstances; i++) {
-      ComponentInstance componentInstance = createComponentInstance(comp,
-          i + nSucceededInstances);
-      componentInstances.put(componentInstance.getCompInstanceName(),
-          componentInstance);
-      failed.put(componentInstance.getCompInstanceName(), componentInstance);
-    }
-
-    int delta = totalAsk - nFailedInstances - nSucceededInstances;
-
-    for (int i = 0; i < delta; i++) {
-      ComponentInstance componentInstance = createComponentInstance(comp,
-          i + nSucceededInstances + nFailedInstances);
-      componentInstances.put(componentInstance.getCompInstanceName(),
-          componentInstance);
-    }
-
-    when(comp.getAllComponentInstances()).thenReturn(
-        componentInstances.values());
-    when(comp.getSucceededInstances()).thenReturn(succeeded.values());
-    when(comp.getFailedInstances()).thenReturn(failed.values());
-    return comp;
-  }
-
-  private Component createComponent(ServiceScheduler scheduler,
-      org.apache.hadoop.yarn.service.api.records.Component.RestartPolicyEnum
-          restartPolicy,
-      int totalAsk, int componentId) {
-
-    Component comp = mock(Component.class);
-    org.apache.hadoop.yarn.service.api.records.Component componentSpec = mock(
-        org.apache.hadoop.yarn.service.api.records.Component.class);
-    when(componentSpec.getRestartPolicy()).thenReturn(restartPolicy);
-    Configuration conf = new Configuration();
-    when(componentSpec.getConfiguration()).thenReturn(conf);
-    when(comp.getRestartPolicyHandler()).thenReturn(
-        Component.getRestartPolicyHandler(restartPolicy));
-    when(componentSpec.getNumberOfContainers()).thenReturn(
-        Long.valueOf(totalAsk));
-    when(comp.getComponentSpec()).thenReturn(componentSpec);
-    when(comp.getScheduler()).thenReturn(scheduler);
-
-    scheduler.getAllComponents().put("comp" + componentId, comp);
-
-    Map<String, ComponentInstance> componentInstances = new HashMap<>();
-
-    for (int i = 0; i < totalAsk; i++) {
-      ComponentInstance componentInstance = createComponentInstance(comp, i);
-      componentInstances.put(componentInstance.getCompInstanceName(),
-          componentInstance);
-    }
-
-    when(comp.getAllComponentInstances()).thenReturn(
-        componentInstances.values());
-    return comp;
-  }
-
-  private ComponentInstance createComponentInstance(Component component,
-      int instanceId) {
-
-    ComponentInstance componentInstance = mock(ComponentInstance.class);
-    when(componentInstance.getComponent()).thenReturn(component);
-    when(componentInstance.getCompInstanceName()).thenReturn(
-        "compInstance" + instanceId);
-    Container container = mock(Container.class);
-    when(componentInstance.getContainerSpec()).thenReturn(container);
-
-    ServiceUtils.ProcessTerminationHandler terminationHandler = mock(
-        ServiceUtils.ProcessTerminationHandler.class);
-    when(component.getScheduler().getTerminationHandler()).thenReturn(
-        terminationHandler);
-
-    return componentInstance;
-  }
-
-  @Test
-  public void testComponentRestartPolicy() {
-
-    Map<String, Component> allComponents = new HashMap<>();
-    Service mockService = mock(Service.class);
-    ServiceContext serviceContext = mock(ServiceContext.class);
-    when(serviceContext.getService()).thenReturn(mockService);
-    ServiceScheduler serviceSchedulerInstance = new ServiceScheduler(
-        serviceContext);
-    ServiceScheduler serviceScheduler = spy(serviceSchedulerInstance);
-    when(serviceScheduler.getAllComponents()).thenReturn(allComponents);
-    Mockito.doNothing().when(serviceScheduler).setGracefulStop(
-        any(FinalApplicationStatus.class));
-
-    final String containerDiag = "Container succeeded";
-
-    ComponentInstanceEvent componentInstanceEvent = mock(
-        ComponentInstanceEvent.class);
-    ContainerId containerId = ContainerId.newContainerId(ApplicationAttemptId
-        .newInstance(ApplicationId.newInstance(1234L, 1), 1), 1);
-    ContainerStatus containerStatus = ContainerStatus.newInstance(containerId,
-        org.apache.hadoop.yarn.api.records.ContainerState.COMPLETE,
-        containerDiag, 0);
-
-    when(componentInstanceEvent.getStatus()).thenReturn(containerStatus);
-
-    // Test case1: one component, one instance, restart policy = ALWAYS, exit=0
-    Component comp = createComponent(serviceScheduler,
-        org.apache.hadoop.yarn.service.api.records.Component
-            .RestartPolicyEnum.ALWAYS,
-        1, 0, 1, 0);
-    ComponentInstance componentInstance =
-        comp.getAllComponentInstances().iterator().next();
-
-    ComponentInstance.handleComponentInstanceRelaunch(componentInstance,
-        componentInstanceEvent, false, containerDiag);
-
-    verify(comp, never()).markAsSucceeded(any(ComponentInstance.class));
-    verify(comp, never()).markAsFailed(any(ComponentInstance.class));
-    verify(comp, times(1)).reInsertPendingInstance(
-        any(ComponentInstance.class));
-    verify(serviceScheduler.getTerminationHandler(), never()).terminate(
-        anyInt());
-
-    // Test case2: one component, one instance, restart policy = ALWAYS, exit=1
-    comp = createComponent(serviceScheduler,
-        org.apache.hadoop.yarn.service.api.records.Component
-            .RestartPolicyEnum.ALWAYS,
-        0, 1, 1, 0);
-    componentInstance = comp.getAllComponentInstances().iterator().next();
-    containerStatus.setExitStatus(1);
-    ComponentInstance.handleComponentInstanceRelaunch(componentInstance,
-        componentInstanceEvent, false, containerDiag);
-    verify(comp, never()).markAsSucceeded(any(ComponentInstance.class));
-    verify(comp, never()).markAsFailed(any(ComponentInstance.class));
-    verify(comp, times(1)).reInsertPendingInstance(
-        any(ComponentInstance.class));
-    verify(serviceScheduler.getTerminationHandler(), never()).terminate(
-        anyInt());
-
-    // Test case3: one component, one instance, restart policy = NEVER, exit=0
-    // Should exit with code=0
-    comp = createComponent(serviceScheduler,
-        org.apache.hadoop.yarn.service.api.records.Component
-            .RestartPolicyEnum.NEVER,
-        1, 0, 1, 0);
-    componentInstance = comp.getAllComponentInstances().iterator().next();
-    containerStatus.setExitStatus(0);
-
-    Map<String, ComponentInstance> succeededInstances = new HashMap<>();
-    succeededInstances.put(componentInstance.getCompInstanceName(),
-        componentInstance);
-    when(comp.getSucceededInstances()).thenReturn(succeededInstances.values());
-    when(comp.getNumSucceededInstances()).thenReturn(new Long(1));
-
-    ComponentInstance.handleComponentInstanceRelaunch(componentInstance,
-        componentInstanceEvent, false, containerDiag);
-    verify(comp, times(1)).markAsSucceeded(any(ComponentInstance.class));
-    verify(comp, never()).markAsFailed(any(ComponentInstance.class));
-    verify(comp, times(0)).reInsertPendingInstance(
-        any(ComponentInstance.class));
-    verify(serviceScheduler.getTerminationHandler(), times(1)).terminate(eq(0));
-
-    // Test case4: one component, one instance, restart policy = NEVER, exit=1
-    // Should exit with code=-1
-    comp = createComponent(serviceScheduler,
-        org.apache.hadoop.yarn.service.api.records.Component
-            .RestartPolicyEnum.NEVER,
-        0, 1, 1, 0);
-    componentInstance = comp.getAllComponentInstances().iterator().next();
-    containerStatus.setExitStatus(-1);
-
-    when(comp.getNumFailedInstances()).thenReturn(new Long(1));
-    ComponentInstance.handleComponentInstanceRelaunch(componentInstance,
-        componentInstanceEvent, false, containerDiag);
-    verify(comp, never()).markAsSucceeded(any(ComponentInstance.class));
-    verify(comp, times(1)).markAsFailed(any(ComponentInstance.class));
-    verify(comp, times(0)).reInsertPendingInstance(
-        any(ComponentInstance.class));
-    verify(serviceScheduler.getTerminationHandler(), times(1)).terminate(
-        eq(-1));
-
-    // Test case5: one component, one instance, restart policy = ON_FAILURE,
-    // exit=1
-    // Should continue run.
-    comp = createComponent(serviceScheduler,
-        org.apache.hadoop.yarn.service.api.records.Component
-            .RestartPolicyEnum.ON_FAILURE,
-        0, 1, 1, 0);
-    componentInstance = comp.getAllComponentInstances().iterator().next();
-    containerStatus.setExitStatus(1);
-    ComponentInstance.handleComponentInstanceRelaunch(componentInstance,
-        componentInstanceEvent, false, containerDiag);
-    verify(comp, never()).markAsSucceeded(any(ComponentInstance.class));
-    verify(comp, never()).markAsFailed(any(ComponentInstance.class));
-    verify(comp, times(1)).reInsertPendingInstance(
-        any(ComponentInstance.class));
-    verify(serviceScheduler.getTerminationHandler(), times(0)).terminate(
-        anyInt());
-
-    // Test case6: one component, 3 instances, restart policy = NEVER, exit=1
-    // 2 of the instances not completed, it should continue run.
-    comp = createComponent(serviceScheduler,
-        org.apache.hadoop.yarn.service.api.records.Component
-            .RestartPolicyEnum.NEVER,
-        0, 1, 3, 0);
-    componentInstance = comp.getAllComponentInstances().iterator().next();
-    containerStatus.setExitStatus(1);
-    ComponentInstance.handleComponentInstanceRelaunch(componentInstance,
-        componentInstanceEvent, false, containerDiag);
-    verify(comp, never()).markAsSucceeded(any(ComponentInstance.class));
-    verify(comp, times(1)).markAsFailed(any(ComponentInstance.class));
-    verify(comp, times(0)).reInsertPendingInstance(
-        any(ComponentInstance.class));
-    verify(serviceScheduler.getTerminationHandler(), times(0)).terminate(
-        anyInt());
-
-    // Test case7: one component, 3 instances, restart policy = ON_FAILURE,
-    // exit=1
-    // 2 of the instances completed, it should continue run.
-
-    comp = createComponent(serviceScheduler,
-        org.apache.hadoop.yarn.service.api.records.Component
-            .RestartPolicyEnum.ON_FAILURE,
-        0, 1, 3, 0);
-
-    Iterator<ComponentInstance> iter =
-        comp.getAllComponentInstances().iterator();
-
-    containerStatus.setExitStatus(1);
-    ComponentInstance commponentInstance = iter.next();
-    ComponentInstance.handleComponentInstanceRelaunch(commponentInstance,
-        componentInstanceEvent, false, containerDiag);
-    verify(comp, never()).markAsSucceeded(any(ComponentInstance.class));
-    verify(comp, never()).markAsFailed(any(ComponentInstance.class));
-    verify(comp, times(1)).reInsertPendingInstance(
-        any(ComponentInstance.class));
-    verify(serviceScheduler.getTerminationHandler(), times(0)).terminate(
-        anyInt());
-
-    // Test case8: 2 components, 2 instances for each
-    // comp2 already finished.
-    // comp1 has a new instance finish, we should terminate the service
-
-    comp = createComponent(serviceScheduler,
-        org.apache.hadoop.yarn.service.api.records.Component
-            .RestartPolicyEnum.NEVER,
-        2, 0);
-    Collection<ComponentInstance> component1Instances =
-        comp.getAllComponentInstances();
-
-    containerStatus.setExitStatus(-1);
-
-    Component comp2 = createComponent(
-        componentInstance.getComponent().getScheduler(),
-        org.apache.hadoop.yarn.service.api.records.Component
-            .RestartPolicyEnum.NEVER,
-        2, 1);
-
-    Collection<ComponentInstance> component2Instances =
-        comp2.getAllComponentInstances();
-
-    Map<String, ComponentInstance> failed2Instances = new HashMap<>();
-
-    for (ComponentInstance component2Instance : component2Instances) {
-      failed2Instances.put(component2Instance.getCompInstanceName(),
-          component2Instance);
-      when(component2Instance.getComponent().getFailedInstances()).thenReturn(
-          failed2Instances.values());
-      when(component2Instance.getComponent().getNumFailedInstances())
-          .thenReturn(new Long(failed2Instances.size()));
-      ComponentInstance.handleComponentInstanceRelaunch(component2Instance,
-          componentInstanceEvent, false, containerDiag);
-    }
-
-    Map<String, ComponentInstance> failed1Instances = new HashMap<>();
-
-    // 2nd component, already finished.
-    for (ComponentInstance component1Instance : component1Instances) {
-      failed1Instances.put(component1Instance.getCompInstanceName(),
-          component1Instance);
-      when(component1Instance.getComponent().getFailedInstances()).thenReturn(
-          failed1Instances.values());
-      when(component1Instance.getComponent().getNumFailedInstances())
-          .thenReturn(new Long(failed1Instances.size()));
-      ComponentInstance.handleComponentInstanceRelaunch(component1Instance,
-          componentInstanceEvent, false, containerDiag);
-    }
-
-    verify(comp, never()).markAsSucceeded(any(ComponentInstance.class));
-    verify(comp, times(2)).markAsFailed(any(ComponentInstance.class));
-    verify(comp, times(0)).reInsertPendingInstance(
-        any(ComponentInstance.class));
-
-    verify(serviceScheduler.getTerminationHandler(), times(1)).terminate(
-        eq(-1));
-
-    // Test case9: 2 components, 2 instances for each
-    // comp2 already finished.
-    // comp1 has a new instance finish, we should terminate the service
-    // All instance finish with 0, service should exit with 0 as well.
-    containerStatus.setExitStatus(0);
-
-    comp = createComponent(serviceScheduler,
-        org.apache.hadoop.yarn.service.api.records.Component
-            .RestartPolicyEnum.ON_FAILURE,
-        2, 0);
-    component1Instances = comp.getAllComponentInstances();
-
-    comp2 = createComponent(componentInstance.getComponent().getScheduler(),
-        org.apache.hadoop.yarn.service.api.records.Component
-            .RestartPolicyEnum.ON_FAILURE,
-        2, 1);
-
-    component2Instances = comp2.getAllComponentInstances();
-
-    Map<String, ComponentInstance> succeeded2Instances = new HashMap<>();
-
-    for (ComponentInstance component2Instance : component2Instances) {
-      succeeded2Instances.put(component2Instance.getCompInstanceName(),
-          component2Instance);
-      when(component2Instance.getComponent().getSucceededInstances())
-          .thenReturn(succeeded2Instances.values());
-      when(component2Instance.getComponent().getNumSucceededInstances())
-          .thenReturn(new Long(succeeded2Instances.size()));
-      ComponentInstance.handleComponentInstanceRelaunch(component2Instance,
-          componentInstanceEvent, false, containerDiag);
-    }
-
-    Map<String, ComponentInstance> succeeded1Instances = new HashMap<>();
-    // 2nd component, already finished.
-    for (ComponentInstance component1Instance : component1Instances) {
-      succeeded1Instances.put(component1Instance.getCompInstanceName(),
-          component1Instance);
-      when(component1Instance.getComponent().getSucceededInstances())
-          .thenReturn(succeeded1Instances.values());
-      when(component1Instance.getComponent().getNumSucceededInstances())
-          .thenReturn(new Long(succeeded1Instances.size()));
-      ComponentInstance.handleComponentInstanceRelaunch(component1Instance,
-          componentInstanceEvent, false, containerDiag);
-    }
-
-    verify(comp, times(2)).markAsSucceeded(any(ComponentInstance.class));
-    verify(comp, never()).markAsFailed(any(ComponentInstance.class));
-    verify(componentInstance.getComponent(), times(0)).reInsertPendingInstance(
-        any(ComponentInstance.class));
-    verify(serviceScheduler.getTerminationHandler(), times(1)).terminate(eq(0));
-
-    // Test case10: 2 components, 2 instances for each
-    // comp2 hasn't finished
-    // comp1 finished.
-    // Service should continue run.
-
-    comp = createComponent(serviceScheduler,
-        org.apache.hadoop.yarn.service.api.records.Component
-            .RestartPolicyEnum.NEVER,
-        2, 0);
-    component1Instances = comp.getAllComponentInstances();
-
-    comp2 = createComponent(componentInstance.getComponent().getScheduler(),
-        org.apache.hadoop.yarn.service.api.records.Component
-            .RestartPolicyEnum.NEVER,
-        2, 1);
-
-    component2Instances = comp2.getAllComponentInstances();
-
-    for (ComponentInstance component2Instance : component2Instances) {
-      ComponentInstance.handleComponentInstanceRelaunch(component2Instance,
-          componentInstanceEvent, false, containerDiag);
-    }
-
-    succeeded1Instances = new HashMap<>();
-    // 2nd component, already finished.
-    for (ComponentInstance component1Instance : component1Instances) {
-      succeeded1Instances.put(component1Instance.getCompInstanceName(),
-          component1Instance);
-      when(component1Instance.getComponent().getSucceededInstances())
-          .thenReturn(succeeded1Instances.values());
-      ComponentInstance.handleComponentInstanceRelaunch(component1Instance,
-          componentInstanceEvent, false, containerDiag);
-    }
-
-    verify(comp, times(2)).markAsSucceeded(any(ComponentInstance.class));
-    verify(comp, never()).markAsFailed(any(ComponentInstance.class));
-    verify(componentInstance.getComponent(), times(0)).reInsertPendingInstance(
-        any(ComponentInstance.class));
-    verify(serviceScheduler.getTerminationHandler(), never()).terminate(eq(0));
-
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/conf/ExampleAppJson.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/conf/ExampleAppJson.java
deleted file mode 100644
index 754b589dce0..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/conf/ExampleAppJson.java
+++ /dev/null
@@ -1,66 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.conf;
-
-
-import org.apache.hadoop.yarn.service.api.records.Service;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-
-import static org.apache.hadoop.yarn.service.ServiceTestUtils.JSON_SER_DESER;
-
-/**
- * Names of the example configs.
- */
-public final class ExampleAppJson {
-
-  public static final String APP_JSON = "app.json";
-  public static final String OVERRIDE_JSON = "app-override.json";
-  public static final String DEFAULT_JSON = "default.json";
-  public static final String EXTERNAL_JSON_0 = "external0.json";
-  public static final String EXTERNAL_JSON_1 = "external1.json";
-  public static final String EXTERNAL_JSON_2 = "external2.json";
-  public static final String EXTERNAL_JSON_3 = "external3.json";
-
-  public static final String PACKAGE = "/org/apache/hadoop/yarn/service/conf/examples/";
-
-
-  private static final String[] ALL_EXAMPLES = {APP_JSON, OVERRIDE_JSON,
-      DEFAULT_JSON};
-
-  public static final List<String> ALL_EXAMPLE_RESOURCES = new ArrayList<>();
-  static {
-    for (String example : ALL_EXAMPLES) {
-      ALL_EXAMPLE_RESOURCES.add(PACKAGE + example);
-    }
-  }
-
-  private ExampleAppJson() {
-  }
-
-  public static Service loadResource(String name) throws IOException {
-    return JSON_SER_DESER.fromResource(PACKAGE + name);
-  }
-
-  public static String resourceName(String name) {
-    return "target/test-classes" + PACKAGE + name;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/conf/TestAppJsonResolve.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/conf/TestAppJsonResolve.java
deleted file mode 100644
index 04c84dc1a2b..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/conf/TestAppJsonResolve.java
+++ /dev/null
@@ -1,236 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.conf;
-
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.service.ServiceTestUtils;
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.api.records.Resource;
-import org.apache.hadoop.yarn.service.api.records.ResourceInformation;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ConfigFile;
-import org.apache.hadoop.yarn.service.api.records.Configuration;
-import org.apache.hadoop.yarn.service.utils.ServiceApiUtil;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-import org.junit.Assert;
-import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Map;
-import java.util.Set;
-
-import static org.apache.hadoop.yarn.service.conf.ExampleAppJson.*;
-
-/**
- * Test global configuration resolution.
- */
-public class TestAppJsonResolve extends Assert {
-  protected static final Logger LOG =
-      LoggerFactory.getLogger(TestAppJsonResolve.class);
-
-  @Test
-  public void testOverride() throws Throwable {
-    Service orig = ExampleAppJson.loadResource(OVERRIDE_JSON);
-
-    Configuration global = orig.getConfiguration();
-    assertEquals("a", global.getProperty("g1"));
-    assertEquals("b", global.getProperty("g2"));
-    assertEquals(2, global.getFiles().size());
-
-    Configuration simple = orig.getComponent("simple").getConfiguration();
-    assertEquals(0, simple.getProperties().size());
-    assertEquals(1, simple.getFiles().size());
-
-    Configuration master = orig.getComponent("master").getConfiguration();
-    assertEquals("m", master.getProperty("name"));
-    assertEquals("overridden", master.getProperty("g1"));
-    assertEquals(0, master.getFiles().size());
-
-    Configuration worker = orig.getComponent("worker").getConfiguration();
-    LOG.info("worker = {}", worker);
-    assertEquals(3, worker.getProperties().size());
-    assertEquals(0, worker.getFiles().size());
-
-    assertEquals("worker", worker.getProperty("name"));
-    assertEquals("overridden-by-worker", worker.getProperty("g1"));
-    assertNull(worker.getProperty("g2"));
-    assertEquals("1000", worker.getProperty("timeout"));
-
-    // here is the resolution
-    SliderFileSystem sfs = ServiceTestUtils.initMockFs();
-    ServiceApiUtil.validateAndResolveService(orig, sfs, new
-        YarnConfiguration());
-
-    global = orig.getConfiguration();
-    LOG.info("global = {}", global);
-    assertEquals("a", global.getProperty("g1"));
-    assertEquals("b", global.getProperty("g2"));
-    assertEquals(2, global.getFiles().size());
-
-    simple = orig.getComponent("simple").getConfiguration();
-    assertEquals(2, simple.getProperties().size());
-    assertEquals("a", simple.getProperty("g1"));
-    assertEquals("b", simple.getProperty("g2"));
-    assertEquals(2, simple.getFiles().size());
-
-    Set<ConfigFile> files = new HashSet<>();
-    Map<String, String> props = new HashMap<>();
-    props.put("k1", "overridden");
-    props.put("k2", "v2");
-    files.add(new ConfigFile().destFile("file1").type(ConfigFile.TypeEnum
-        .PROPERTIES).properties(props));
-    files.add(new ConfigFile().destFile("file2").type(ConfigFile.TypeEnum
-        .XML).properties(Collections.singletonMap("k3", "v3")));
-    assertTrue(files.contains(simple.getFiles().get(0)));
-    assertTrue(files.contains(simple.getFiles().get(1)));
-
-    master = orig.getComponent("master").getConfiguration();
-    LOG.info("master = {}", master);
-    assertEquals(3, master.getProperties().size());
-    assertEquals("m", master.getProperty("name"));
-    assertEquals("overridden", master.getProperty("g1"));
-    assertEquals("b", master.getProperty("g2"));
-    assertEquals(2, master.getFiles().size());
-
-    props.put("k1", "v1");
-    files.clear();
-    files.add(new ConfigFile().destFile("file1").type(ConfigFile.TypeEnum
-        .PROPERTIES).properties(props));
-    files.add(new ConfigFile().destFile("file2").type(ConfigFile.TypeEnum
-        .XML).properties(Collections.singletonMap("k3", "v3")));
-
-    assertTrue(files.contains(master.getFiles().get(0)));
-    assertTrue(files.contains(master.getFiles().get(1)));
-
-    worker = orig.getComponent("worker").getConfiguration();
-    LOG.info("worker = {}", worker);
-    assertEquals(4, worker.getProperties().size());
-
-    assertEquals("worker", worker.getProperty("name"));
-    assertEquals("overridden-by-worker", worker.getProperty("g1"));
-    assertEquals("b", worker.getProperty("g2"));
-    assertEquals("1000", worker.getProperty("timeout"));
-    assertEquals(2, worker.getFiles().size());
-
-    assertTrue(files.contains(worker.getFiles().get(0)));
-    assertTrue(files.contains(worker.getFiles().get(1)));
-  }
-
-  @Test
-  public void testOverrideExternalConfiguration() throws IOException {
-    Service orig = ExampleAppJson.loadResource(EXTERNAL_JSON_1);
-
-    Configuration global = orig.getConfiguration();
-    assertEquals(0, global.getProperties().size());
-
-    assertEquals(3, orig.getComponents().size());
-
-    Configuration simple = orig.getComponent("simple").getConfiguration();
-    assertEquals(0, simple.getProperties().size());
-
-    Configuration master = orig.getComponent("master").getConfiguration();
-    assertEquals(1, master.getProperties().size());
-    assertEquals("is-overridden", master.getProperty("g3"));
-
-    Configuration other = orig.getComponent("other").getConfiguration();
-    assertEquals(0, other.getProperties().size());
-
-    // load the external service
-    SliderFileSystem sfs = ServiceTestUtils.initMockFs();
-    Service ext = ExampleAppJson.loadResource(APP_JSON);
-    ServiceApiUtil.validateAndResolveService(ext, sfs, new
-        YarnConfiguration());
-
-    // perform the resolution on original service
-    sfs = ServiceTestUtils.initMockFs(ext);
-    ServiceApiUtil.validateAndResolveService(orig, sfs, new
-        YarnConfiguration());
-
-    global = orig.getConfiguration();
-    assertEquals(0, global.getProperties().size());
-
-    assertEquals(4, orig.getComponents().size());
-
-    simple = orig.getComponent("simple").getConfiguration();
-    assertEquals(3, simple.getProperties().size());
-    assertEquals("a", simple.getProperty("g1"));
-    assertEquals("b", simple.getProperty("g2"));
-    assertEquals("60",
-        simple.getProperty("yarn.service.failure-count-reset.window"));
-
-    master = orig.getComponent("master").getConfiguration();
-    assertEquals(5, master.getProperties().size());
-    assertEquals("512M", master.getProperty("jvm.heapsize"));
-    assertEquals("overridden", master.getProperty("g1"));
-    assertEquals("b", master.getProperty("g2"));
-    assertEquals("is-overridden", master.getProperty("g3"));
-    assertEquals("60",
-        simple.getProperty("yarn.service.failure-count-reset.window"));
-
-    Configuration worker = orig.getComponent("worker").getConfiguration();
-    LOG.info("worker = {}", worker);
-    assertEquals(4, worker.getProperties().size());
-    assertEquals("512M", worker.getProperty("jvm.heapsize"));
-    assertEquals("overridden-by-worker", worker.getProperty("g1"));
-    assertEquals("b", worker.getProperty("g2"));
-    assertEquals("60",
-        worker.getProperty("yarn.service.failure-count-reset.window"));
-
-    // Validate worker's resources
-    Resource workerResource = orig.getComponent("worker").getResource();
-    Assert.assertEquals(1, workerResource.getCpus().intValue());
-    Assert.assertEquals(1024, workerResource.calcMemoryMB());
-    Assert.assertNotNull(workerResource.getAdditional());
-    Assert.assertEquals(2, workerResource.getAdditional().size());
-    Assert.assertEquals(3333, workerResource.getAdditional().get(
-        "resource-1").getValue().longValue());
-    Assert.assertEquals("Gi", workerResource.getAdditional().get(
-        "resource-1").getUnit());
-
-    Assert.assertEquals(5, workerResource.getAdditional().get(
-        "yarn.io/gpu").getValue().longValue());
-    Assert.assertEquals("", workerResource.getAdditional().get(
-        "yarn.io/gpu").getUnit());
-
-    other = orig.getComponent("other").getConfiguration();
-    assertEquals(0, other.getProperties().size());
-  }
-
-  @Test
-  public void testSetResourceAttributes() throws IOException {
-    Service orig = ExampleAppJson.loadResource(EXTERNAL_JSON_3);
-    Component component = orig.getComponent("volume-service");
-    Assert.assertNotNull(component);
-    Map<String, ResourceInformation> adResource = component
-        .getResource().getAdditional();
-    Assert.assertNotNull(adResource);
-    Assert.assertEquals(1, adResource.size());
-    Map.Entry<String, ResourceInformation> volume = adResource
-        .entrySet().iterator().next();
-    Assert.assertEquals("yarn.io/csi-volume", volume.getKey());
-    Assert.assertEquals(100L, volume.getValue().getValue().longValue());
-    Assert.assertEquals(2, volume.getValue().getAttributes().size());
-    Assert.assertEquals(1, volume.getValue().getTags().size());
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/conf/TestLoadExampleAppJson.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/conf/TestLoadExampleAppJson.java
deleted file mode 100644
index a813da3bff1..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/conf/TestLoadExampleAppJson.java
+++ /dev/null
@@ -1,71 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.conf;
-
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.service.ServiceTestUtils;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.utils.ServiceApiUtil;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-import org.junit.Assert;
-import org.junit.Test;
-import org.junit.runner.RunWith;
-import org.junit.runners.Parameterized;
-
-import java.util.Arrays;
-import java.util.Collection;
-
-import static org.apache.hadoop.yarn.service.ServiceTestUtils.JSON_SER_DESER;
-
-/**
- * Test loading example resources.
- */
-@RunWith(value = Parameterized.class)
-public class TestLoadExampleAppJson extends Assert {
-  private String resource;
-
-  public TestLoadExampleAppJson(String resource) {
-    this.resource = resource;
-  }
-
-  @Parameterized.Parameters
-  public static Collection<String[]> filenames() {
-    String[][] stringArray = new String[ExampleAppJson
-        .ALL_EXAMPLE_RESOURCES.size()][1];
-    int i = 0;
-    for (String s : ExampleAppJson.ALL_EXAMPLE_RESOURCES) {
-      stringArray[i++][0] = s;
-    }
-    return Arrays.asList(stringArray);
-  }
-
-  @Test
-  public void testLoadResource() throws Throwable {
-    try {
-      Service service = JSON_SER_DESER.fromResource(resource);
-
-      SliderFileSystem sfs = ServiceTestUtils.initMockFs();
-
-      ServiceApiUtil.validateAndResolveService(service, sfs,
-          new YarnConfiguration());
-    } catch (Exception e) {
-      throw new Exception("exception loading " + resource + ":" + e.toString());
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/conf/TestValidateServiceNames.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/conf/TestValidateServiceNames.java
deleted file mode 100644
index d7fa9a04dbb..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/conf/TestValidateServiceNames.java
+++ /dev/null
@@ -1,125 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.conf;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.service.utils.ServiceApiUtil;
-import org.junit.Assert;
-import org.junit.Test;
-
-import java.util.Arrays;
-import java.util.List;
-
-/**
- * Test cluster name validation.
- */
-public class TestValidateServiceNames {
-
-  void assertValidName(String name) {
-    ServiceApiUtil.validateNameFormat(name, new Configuration());
-  }
-
-  void assertInvalidName(String name) {
-    try {
-      ServiceApiUtil.validateNameFormat(name, new Configuration());
-      Assert.fail();
-    } catch (IllegalArgumentException e) {
-      //
-    }
-  }
-
-  void assertInvalid(List<String> names) {
-    for (String name : names) {
-      assertInvalidName(name);
-    }
-  }
-
-  void assertValid(List<String> names) {
-    for (String name : names) {
-      assertValidName(name);
-    }
-  }
-
-  @Test
-  public void testEmptyName() throws Throwable {
-    assertInvalidName("");
-  }
-
-  @Test
-  public void testSpaceName() throws Throwable {
-    assertInvalidName(" ");
-  }
-
-
-  @Test
-  public void testLeadingHyphen() throws Throwable {
-    assertInvalidName("-hyphen");
-  }
-
-  @Test
-  public void testTitleLetters() throws Throwable {
-    assertInvalidName("Title");
-  }
-
-  @Test
-  public void testCapitalLetters() throws Throwable {
-    assertInvalidName("UPPER-CASE-CLUSTER");
-  }
-
-  @Test
-  public void testInnerBraced() throws Throwable {
-    assertInvalidName("a[a");
-  }
-
-  @Test
-  public void testLeadingBrace() throws Throwable {
-    assertInvalidName("[");
-  }
-
-  @Test
-  public void testNonalphaLeadingChars() throws Throwable {
-    assertInvalid(Arrays.asList(
-        "[a", "#", "@", "=", "*", "."
-    ));
-  }
-
-  @Test
-  public void testNonalphaInnerChars() throws Throwable {
-    assertInvalid(Arrays.asList(
-        "a[a", "b#", "c@", "d=", "e*", "f.", "g ", "h i"
-    ));
-  }
-
-  @Test
-  public void testClusterValid() throws Throwable {
-    assertValidName("cluster");
-  }
-
-  @Test
-  public void testValidNames() throws Throwable {
-    assertValid(Arrays.asList(
-        "cluster",
-        "cluster1",
-        "very-very-very-long-cluster-name",
-        "c1234567890"
-    ));
-
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/containerlaunch/TestAbstractLauncher.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/containerlaunch/TestAbstractLauncher.java
deleted file mode 100644
index 31ca38297c8..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/containerlaunch/TestAbstractLauncher.java
+++ /dev/null
@@ -1,119 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.containerlaunch;
-
-import org.apache.hadoop.yarn.service.ServiceContext;
-import org.apache.hadoop.yarn.service.api.records.Configuration;
-import org.apache.hadoop.yarn.service.component.AlwaysRestartPolicy;
-import org.apache.hadoop.yarn.service.component.Component;
-import org.apache.hadoop.yarn.service.component.NeverRestartPolicy;
-import org.apache.hadoop.yarn.service.component.OnFailureRestartPolicy;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.apache.hadoop.yarn.service.provider.defaultImpl
-    .DefaultProviderService;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Test;
-
-import java.io.IOException;
-
-import static org.apache.hadoop.fi.FiConfig.getConfig;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf
-    .DEFAULT_CONTAINER_FAILURES_VALIDITY_INTERVAL;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf
-    .DEFAULT_CONTAINER_RETRY_INTERVAL;
-import static org.apache.hadoop.yarn.service.conf.YarnServiceConf
-    .DEFAULT_CONTAINER_RETRY_MAX;
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.reset;
-import static org.mockito.Mockito.verify;
-import static org.mockito.Mockito.verifyZeroInteractions;
-import static org.mockito.Mockito.when;
-
-/**
- * Tests for {@link AbstractLauncher}.
- */
-public class TestAbstractLauncher {
-
-  private AbstractLauncher launcher;
-
-  @Before
-  public void setup() {
-    launcher = new AbstractLauncher(mock(ServiceContext.class));
-  }
-
-  @Test
-  public void testDockerContainerMounts() throws IOException {
-    launcher.yarnDockerMode = true;
-    launcher.envVars.put(AbstractLauncher.ENV_DOCKER_CONTAINER_MOUNTS,
-        "s1:t1:ro");
-    launcher.mountPaths.put("s2", "t2");
-    launcher.completeContainerLaunch();
-    String dockerContainerMounts = launcher.containerLaunchContext
-        .getEnvironment().get(AbstractLauncher.ENV_DOCKER_CONTAINER_MOUNTS);
-
-    Assert.assertEquals("s1:t1:ro,s2:t2:ro", dockerContainerMounts);
-  }
-
-  @Test
-  public void testContainerRetries() throws Exception {
-
-    DefaultProviderService providerService = new DefaultProviderService();
-    AbstractLauncher mockLauncher = mock(AbstractLauncher.class);
-    ContainerLaunchService.ComponentLaunchContext componentLaunchContext =
-        mock(ContainerLaunchService.ComponentLaunchContext.class);
-
-    ComponentInstance componentInstance = mock(ComponentInstance.class);
-
-    //Never Restart Policy
-    Component component = mock(Component.class);
-    when(componentInstance.getComponent()).thenReturn(component);
-
-    when(component.getRestartPolicyHandler()).thenReturn(NeverRestartPolicy
-        .getInstance());
-
-    providerService.buildContainerRetry(mockLauncher, getConfig(),
-        componentLaunchContext, componentInstance);
-    verifyZeroInteractions(mockLauncher);
-
-
-    //OnFailure restart policy
-    when(component.getRestartPolicyHandler()).thenReturn(OnFailureRestartPolicy
-        .getInstance());
-    when(componentLaunchContext.getConfiguration()).thenReturn(new
-        Configuration());
-    providerService.buildContainerRetry(mockLauncher, getConfig(),
-        componentLaunchContext, componentInstance);
-    verify(mockLauncher).setRetryContext(DEFAULT_CONTAINER_RETRY_MAX,
-        DEFAULT_CONTAINER_RETRY_INTERVAL,
-        DEFAULT_CONTAINER_FAILURES_VALIDITY_INTERVAL);
-
-    reset(mockLauncher);
-
-    //Always restart policy
-    when(component.getRestartPolicyHandler()).thenReturn(AlwaysRestartPolicy
-        .getInstance());
-    providerService.buildContainerRetry(mockLauncher, getConfig(),
-        componentLaunchContext, componentInstance);
-
-    verify(mockLauncher).setRetryContext(DEFAULT_CONTAINER_RETRY_MAX,
-        DEFAULT_CONTAINER_RETRY_INTERVAL,
-        DEFAULT_CONTAINER_FAILURES_VALIDITY_INTERVAL);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/monitor/TestServiceMonitor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/monitor/TestServiceMonitor.java
deleted file mode 100644
index c758e6fbeaa..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/monitor/TestServiceMonitor.java
+++ /dev/null
@@ -1,126 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-
-package org.apache.hadoop.yarn.service.monitor;
-
-import org.apache.commons.io.FileUtils;
-import org.apache.curator.test.TestingCluster;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.service.MockServiceAM;
-import org.apache.hadoop.yarn.service.ServiceTestUtils;
-
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConf;
-import org.junit.After;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Test;
-
-import java.io.File;
-import java.io.IOException;
-import java.util.Collections;
-
-import static org.apache.hadoop.registry.client.api.RegistryConstants
-    .KEY_REGISTRY_ZK_QUORUM;
-
-public class TestServiceMonitor extends ServiceTestUtils {
-
-  private File basedir;
-  YarnConfiguration conf = new YarnConfiguration();
-  TestingCluster zkCluster;
-
-  @Before
-  public void setup() throws Exception {
-    basedir = new File("target", "apps");
-    if (basedir.exists()) {
-      FileUtils.deleteDirectory(basedir);
-    } else {
-      basedir.mkdirs();
-    }
-    conf.setLong(YarnServiceConf.READINESS_CHECK_INTERVAL, 2);
-    zkCluster = new TestingCluster(1);
-    zkCluster.start();
-    conf.set(KEY_REGISTRY_ZK_QUORUM, zkCluster.getConnectString());
-    System.out.println("ZK cluster: " +  zkCluster.getConnectString());
-  }
-
-  @After
-  public void tearDown() throws IOException {
-    if (basedir != null) {
-      FileUtils.deleteDirectory(basedir);
-    }
-    if (zkCluster != null) {
-      zkCluster.stop();
-    }
-  }
-
-  // Create compa with 1 container
-  // Create compb with 1 container
-  // Verify compb dependency satisfied
-  // Increase compa to 2 containers
-  // Verify compb dependency becomes unsatisfied.
-  @Test
-  public void testComponentDependency() throws Exception{
-    ApplicationId applicationId = ApplicationId.newInstance(123456, 1);
-    Service exampleApp = new Service();
-    exampleApp.setVersion("v1");
-    exampleApp.setId(applicationId.toString());
-    exampleApp.setName("testComponentDependency");
-    exampleApp.addComponent(createComponent("compa", 1, "sleep 1000"));
-    // Let compb depends on compa;
-    Component compb = createComponent("compb", 1, "sleep 1000", Component
-        .RestartPolicyEnum.ON_FAILURE, Collections.singletonList("compa"));
-    // Let compb depends on compb;
-    Component compc = createComponent("compc", 1, "sleep 1000", Component
-        .RestartPolicyEnum.NEVER, Collections.singletonList("compb"));
-
-    exampleApp.addComponent(compb);
-    exampleApp.addComponent(compc);
-
-    MockServiceAM am = new MockServiceAM(exampleApp);
-    am.init(conf);
-    am.start();
-
-    // compa ready
-    Assert.assertTrue(am.getComponent("compa").areDependenciesReady());
-    //compb not ready
-    Assert.assertFalse(am.getComponent("compb").areDependenciesReady());
-
-    // feed 1 container to compa,
-    am.feedContainerToComp(exampleApp, 1, "compa");
-    // waiting for compb's dependencies are satisfied
-    am.waitForDependenciesSatisfied("compb");
-
-    // feed 1 container to compb,
-    am.feedContainerToComp(exampleApp, 2, "compb");
-    // waiting for compc's dependencies are satisfied
-    am.waitForDependenciesSatisfied("compc");
-
-    // feed 1 container to compb
-    am.feedContainerToComp(exampleApp, 2, "compb");
-    am.flexComponent("compa", 2);
-    am.waitForNumDesiredContainers("compa", 2);
-
-    // compb dependencies not satisfied again.
-    Assert.assertFalse(am.getComponent("compb").areDependenciesReady());
-    am.stop();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/monitor/probe/TestDefaultProbe.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/monitor/probe/TestDefaultProbe.java
deleted file mode 100644
index 8169e67b7c3..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/monitor/probe/TestDefaultProbe.java
+++ /dev/null
@@ -1,155 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.monitor.probe;
-
-import org.apache.hadoop.yarn.api.records.ContainerStatus;
-import org.apache.hadoop.yarn.service.api.records.ReadinessCheck;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.junit.Test;
-import org.junit.runner.RunWith;
-import org.junit.runners.Parameterized;
-import org.mockito.invocation.InvocationOnMock;
-import org.mockito.stubbing.Answer;
-
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.Map;
-
-import static org.junit.Assert.assertFalse;
-import static org.junit.Assert.assertTrue;
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.when;
-
-/**
- * Tests for default probe.
- */
-@RunWith(Parameterized.class)
-public class TestDefaultProbe {
-  private final DefaultProbe probe;
-
-  public TestDefaultProbe(Probe probe) {
-    this.probe = (DefaultProbe) probe;
-  }
-
-  @Parameterized.Parameters
-  public static Collection<Object[]> data() {
-    // test run 1: Default probe checks that container has an IP
-    Probe p1 = MonitorUtils.getProbe(null);
-
-    // test run 2: Default probe with DNS check for component instance hostname
-    ReadinessCheck rc2 = new ReadinessCheck()
-        .type(ReadinessCheck.TypeEnum.DEFAULT)
-        .properties(Collections.singletonMap(
-            MonitorKeys.DEFAULT_PROBE_DNS_CHECK_ENABLED, "true"));
-    Probe p2 = MonitorUtils.getProbe(rc2);
-
-    // test run 3: Default probe with DNS check using specific DNS server
-    Map<String, String> props = new HashMap<>();
-    props.put(MonitorKeys.DEFAULT_PROBE_DNS_CHECK_ENABLED, "true");
-    props.put(MonitorKeys.DEFAULT_PROBE_DNS_ADDRESS, "8.8.8.8");
-    ReadinessCheck rc3 = new ReadinessCheck()
-        .type(ReadinessCheck.TypeEnum.DEFAULT).properties(props);
-    Probe p3 = MonitorUtils.getProbe(rc3);
-
-    return Arrays.asList(new Object[][] {{p1}, {p2}, {p3}});
-  }
-
-  @Test
-  public void testDefaultProbe() {
-    // component instance has a good hostname, so probe will eventually succeed
-    // whether or not DNS checking is enabled
-    ComponentInstance componentInstance =
-        createMockComponentInstance("example.com");
-    checkPingResults(probe, componentInstance, false);
-
-    // component instance has a bad hostname, so probe will fail when DNS
-    // checking is enabled
-    componentInstance = createMockComponentInstance("bad.dns.test");
-    checkPingResults(probe, componentInstance, probe.isDnsCheckEnabled());
-  }
-
-  private static void checkPingResults(Probe probe, ComponentInstance
-      componentInstance, boolean expectDNSCheckFailure) {
-    // on the first ping, null container status results in failure
-    ProbeStatus probeStatus = probe.ping(componentInstance);
-    assertFalse("Expected failure for " + probeStatus.toString(),
-        probeStatus.isSuccess());
-    assertTrue("Expected IP failure for " + probeStatus.toString(),
-        probeStatus.toString().contains(
-        componentInstance.getCompInstanceName() + ": IP is not available yet"));
-
-    // on the second ping, container status is retrieved but there are no
-    // IPs, resulting in failure
-    probeStatus = probe.ping(componentInstance);
-    assertFalse("Expected failure for " + probeStatus.toString(),
-        probeStatus.isSuccess());
-    assertTrue("Expected IP failure for " + probeStatus.toString(),
-        probeStatus.toString().contains(componentInstance
-            .getCompInstanceName() + ": IP is not available yet"));
-
-    // on the third ping, IPs are retrieved and success depends on whether or
-    // not a DNS lookup can be performed for the component instance hostname
-    probeStatus = probe.ping(componentInstance);
-    if (expectDNSCheckFailure) {
-      assertFalse("Expected failure for " + probeStatus.toString(),
-          probeStatus.isSuccess());
-      assertTrue("Expected DNS failure for " + probeStatus.toString(),
-          probeStatus.toString().contains(componentInstance
-              .getCompInstanceName() + ": DNS checking is enabled, but lookup" +
-              " for " + componentInstance.getHostname() + " is not available " +
-              "yet"));
-    } else {
-      assertTrue("Expected success for " + probeStatus.toString(),
-          probeStatus.isSuccess());
-    }
-  }
-
-  private static ComponentInstance createMockComponentInstance(String
-      hostname) {
-    ComponentInstance componentInstance = mock(ComponentInstance.class);
-    when(componentInstance.getHostname()).thenReturn(hostname);
-    when(componentInstance.getCompInstanceName()).thenReturn("comp-0");
-    when(componentInstance.getContainerStatus())
-        .thenAnswer(new Answer<ContainerStatus>() {
-          private int count = 0;
-
-          @Override
-          public ContainerStatus answer(InvocationOnMock invocationOnMock) {
-            count++;
-            if (count == 1) {
-              // first call to getContainerStatus returns null
-              return null;
-            } else if (count == 2) {
-              // second call returns a ContainerStatus with no IPs
-              ContainerStatus containerStatus = mock(ContainerStatus.class);
-              when(containerStatus.getIPs()).thenReturn(null);
-              return containerStatus;
-            } else {
-              // third call returns a ContainerStatus with one IP
-              ContainerStatus containerStatus = mock(ContainerStatus.class);
-              when(containerStatus.getIPs())
-                  .thenReturn(Collections.singletonList("1.2.3.4"));
-              return containerStatus;
-            }
-          }
-        });
-    return componentInstance;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/provider/TestAbstractProviderService.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/provider/TestAbstractProviderService.java
deleted file mode 100644
index b56ccb5cf37..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/provider/TestAbstractProviderService.java
+++ /dev/null
@@ -1,157 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.provider;
-
-import org.apache.commons.io.FileUtils;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.util.Lists;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.Container;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.service.MockRunningServiceContext;
-import org.apache.hadoop.yarn.service.ServiceContext;
-import org.apache.hadoop.yarn.service.ServiceTestUtils;
-import org.apache.hadoop.yarn.service.TestServiceManager;
-import org.apache.hadoop.yarn.service.api.records.Artifact;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.component.Component;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher;
-import org.apache.hadoop.yarn.service.containerlaunch.ContainerLaunchService;
-import org.apache.hadoop.yarn.service.provider.docker.DockerProviderService;
-import org.junit.After;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Rule;
-import org.junit.Test;
-
-import java.io.File;
-import java.util.HashMap;
-import java.util.Map;
-
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.when;
-
-/**
- * Tests for {@link AbstractProviderService}
- */
-public class TestAbstractProviderService {
-
-  private ServiceContext serviceContext;
-  private Service testService;
-  private AbstractLauncher launcher;
-
-  @Rule
-  public ServiceTestUtils.ServiceFSWatcher rule =
-      new ServiceTestUtils.ServiceFSWatcher();
-
-  @Before
-  public void setup() throws Exception {
-    testService = TestServiceManager.createBaseDef("testService");
-    serviceContext = new MockRunningServiceContext(rule, testService);
-    launcher = new AbstractLauncher(serviceContext);
-    rule.getFs().setAppDir(new Path("target/testAbstractProviderService"));
-  }
-
-  @After
-  public void teardown() throws Exception {
-    FileUtils.deleteQuietly(
-        new File(rule.getFs().getAppDir().toUri().getPath()));
-  }
-
-  @Test
-  public void testBuildContainerLaunchCommand() throws Exception {
-    AbstractProviderService providerService = new DockerProviderService();
-    Component component = serviceContext.scheduler.getAllComponents().entrySet()
-        .iterator().next().getValue();
-    ContainerLaunchService.ComponentLaunchContext clc =
-        createEntryPointCLCFor(testService, component, "sleep,9000");
-
-    ComponentInstance instance = component.getAllComponentInstances().iterator()
-        .next();
-    Container container = mock(Container.class);
-    providerService.buildContainerLaunchCommand(launcher, testService, instance,
-        rule.getFs(), serviceContext.scheduler.getConfig(), container, clc,
-        null);
-
-    Assert.assertEquals("commands", Lists.newArrayList(clc.getLaunchCommand()),
-        launcher.getCommands());
-  }
-
-  @Test
-  public void testBuildContainerLaunchCommandWithSpace() throws Exception {
-    AbstractProviderService providerService = new DockerProviderService();
-    Component component = serviceContext.scheduler.getAllComponents().entrySet()
-        .iterator().next().getValue();
-    ContainerLaunchService.ComponentLaunchContext clc =
-        createEntryPointCLCFor(testService, component, "ls -l \" space\"");
-
-    ComponentInstance instance = component.getAllComponentInstances().iterator()
-        .next();
-    Container container = mock(Container.class);
-    providerService.buildContainerLaunchCommand(launcher, testService, instance,
-        rule.getFs(), serviceContext.scheduler.getConfig(), container, clc,
-        null);
-
-    Assert.assertEquals("commands don't match.",
-        Lists.newArrayList("ls,-l, space"), launcher.getCommands());
-  }
-
-  @Test
-  public void testBuildContainerLaunchContext() throws Exception {
-    AbstractProviderService providerService = new DockerProviderService();
-    Component component = serviceContext.scheduler.getAllComponents().entrySet()
-        .iterator().next().getValue();
-    ContainerLaunchService.ComponentLaunchContext clc =
-        createEntryPointCLCFor(testService, component, "sleep,9000");
-
-    ComponentInstance instance = component.getAllComponentInstances().iterator()
-        .next();
-    Container container = mock(Container.class);
-    ContainerId containerId = ContainerId.newContainerId(
-        ApplicationAttemptId.newInstance(ApplicationId.newInstance(
-            System.currentTimeMillis(), 1), 1), 1L);
-    when(container.getId()).thenReturn(containerId);
-    providerService.buildContainerLaunchContext(launcher, testService, instance,
-        rule.getFs(), serviceContext.scheduler.getConfig(), container, clc);
-
-    Assert.assertEquals("artifact", clc.getArtifact().getId(),
-        launcher.getDockerImage());
-  }
-
-  private static ContainerLaunchService.ComponentLaunchContext
-      createEntryPointCLCFor(Service service, Component component,
-          String launchCmd) {
-    Artifact artifact = new Artifact();
-    artifact.setType(Artifact.TypeEnum.DOCKER);
-    artifact.setId("example");
-    Map<String, String> env = new HashMap<>();
-    env.put("YARN_CONTAINER_RUNTIME_DOCKER_DELAYED_REMOVAL", "true");
-    env.put("YARN_CONTAINER_RUNTIME_DOCKER_RUN_OVERRIDE_DISABLE", "true");
-    component.getComponentSpec().getConfiguration().setEnv(env);
-
-    return new ContainerLaunchService.ComponentLaunchContext(
-        component.getName(),
-        service.getVersion())
-        .setArtifact(artifact)
-        .setConfiguration(component.getComponentSpec().getConfiguration())
-        .setLaunchCommand(launchCmd);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/provider/TestProviderUtils.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/provider/TestProviderUtils.java
deleted file mode 100644
index bfdcccd268c..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/provider/TestProviderUtils.java
+++ /dev/null
@@ -1,185 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.provider;
-
-import org.apache.hadoop.fs.FileStatus;
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.yarn.api.records.LocalResource;
-import org.apache.hadoop.yarn.api.records.LocalResourceType;
-import org.apache.hadoop.yarn.api.records.LocalResourceVisibility;
-import org.apache.hadoop.yarn.api.records.URL;
-import org.apache.hadoop.yarn.service.api.records.ConfigFile;
-import org.apache.hadoop.yarn.service.api.records.Configuration;
-import org.apache.hadoop.yarn.service.containerlaunch.AbstractLauncher;
-import org.apache.hadoop.yarn.service.containerlaunch.ContainerLaunchService;
-import org.apache.hadoop.yarn.service.utils.SliderFileSystem;
-import org.junit.Assert;
-import org.junit.Test;
-import org.mockito.Mockito;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-
-import static org.mockito.ArgumentMatchers.any;
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.when;
-
-/**
- * Test functionality of ProviderUtils.
- */
-public class TestProviderUtils {
-  @Test
-  public void testStaticFileLocalization() throws IOException {
-    // A bunch of mocks ...
-    ContainerLaunchService.ComponentLaunchContext compLaunchCtx =
-        mock(ContainerLaunchService.ComponentLaunchContext.class);
-    AbstractLauncher launcher = mock(AbstractLauncher.class);
-    SliderFileSystem sfs = mock(SliderFileSystem.class);
-    FileSystem fs = mock(FileSystem.class);
-    when(fs.getFileStatus(any(Path.class))).thenAnswer(
-        invocationOnMock -> new FileStatus(1L, false, 1, 1L, 1L,
-            (Path) invocationOnMock.getArguments()[0]));
-    when(fs.exists(any(Path.class))).thenReturn(true);
-    when(sfs.getFileSystem()).thenReturn(fs);
-    Configuration conf = mock(Configuration.class);
-    List<ConfigFile> configFileList = new ArrayList<>();
-    when(conf.getFiles()).thenReturn(configFileList);
-    when(compLaunchCtx.getConfiguration()).thenReturn(conf);
-    when(sfs.createAmResource(any(Path.class), any(LocalResourceType.class),
-        any(LocalResourceVisibility.class))).thenAnswer(
-          invocationOnMock -> new LocalResource() {
-            @Override
-            public URL getResource() {
-              return URL.fromPath(((Path) invocationOnMock.getArguments()[0]));
-            }
-
-            @Override
-            public void setResource(URL resource) {
-
-            }
-
-            @Override
-            public long getSize() {
-              return 0;
-            }
-
-            @Override
-            public void setSize(long size) {
-
-            }
-
-            @Override
-            public long getTimestamp() {
-              return 0;
-            }
-
-            @Override
-            public void setTimestamp(long timestamp) {
-
-            }
-
-            @Override
-            public LocalResourceType getType() {
-              return (LocalResourceType) invocationOnMock.getArguments()[1];
-            }
-
-            @Override
-            public void setType(LocalResourceType type) {
-
-            }
-
-            @Override
-            public LocalResourceVisibility getVisibility() {
-              return LocalResourceVisibility.APPLICATION;
-            }
-
-            @Override
-            public void setVisibility(LocalResourceVisibility visibility) {
-
-            }
-
-            @Override
-            public String getPattern() {
-              return null;
-            }
-
-            @Override
-            public void setPattern(String pattern) {
-
-            }
-
-            @Override
-            public boolean getShouldBeUploadedToSharedCache() {
-              return false;
-            }
-
-            @Override
-            public void setShouldBeUploadedToSharedCache(
-                boolean shouldBeUploadedToSharedCache) {
-
-            }
-          });
-
-    // Initialize list of files.
-    //archive
-    configFileList.add(new ConfigFile().srcFile("hdfs://default/sourceFile1")
-        .destFile("destFile1").type(ConfigFile.TypeEnum.ARCHIVE)
-        .visibility(LocalResourceVisibility.APPLICATION));
-
-    //static file
-    configFileList.add(new ConfigFile().srcFile("hdfs://default/sourceFile2")
-        .destFile("folder/destFile_2").type(ConfigFile.TypeEnum.STATIC)
-        .visibility(LocalResourceVisibility.APPLICATION));
-
-    //This will be ignored since type is JSON
-    configFileList.add(new ConfigFile().srcFile("hdfs://default/sourceFile3")
-        .destFile("destFile3").type(ConfigFile.TypeEnum.JSON)
-        .visibility(LocalResourceVisibility.APPLICATION));
-    //No destination file specified
-    configFileList.add(new ConfigFile().srcFile("hdfs://default/sourceFile4")
-        .type(ConfigFile.TypeEnum.STATIC)
-        .visibility(LocalResourceVisibility.APPLICATION));
-
-    ProviderService.ResolvedLaunchParams resolved =
-        new ProviderService.ResolvedLaunchParams();
-    ProviderUtils.handleStaticFilesForLocalization(launcher, sfs,
-        compLaunchCtx, resolved);
-    Mockito.verify(launcher).addLocalResource(Mockito.eq("destFile1"),
-        any(LocalResource.class));
-    Mockito.verify(launcher).addLocalResource(
-        Mockito.eq("destFile_2"), any(LocalResource.class));
-    Mockito.verify(launcher).addLocalResource(
-        Mockito.eq("sourceFile4"), any(LocalResource.class));
-
-    Assert.assertEquals(3, resolved.getResolvedRsrcPaths().size());
-    Assert.assertEquals(resolved.getResolvedRsrcPaths().get("destFile1"),
-        "destFile1");
-  }
-
-  @Test
-  public void testReplaceSpacesWithDelimiter() {
-    String command = "ls  -l \" space\"";
-    String expected = "ls,-l, space";
-    String actual = ProviderUtils.replaceSpacesWithDelimiter(command, ",");
-    Assert.assertEquals("replaceSpaceWithDelimiter produces unexpected result.",
-        expected, actual);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/providers/TestAbstractClientProvider.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/providers/TestAbstractClientProvider.java
deleted file mode 100644
index 8908a1d415b..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/providers/TestAbstractClientProvider.java
+++ /dev/null
@@ -1,163 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.providers;
-
-import org.apache.hadoop.fs.FileStatus;
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.yarn.service.api.records.Artifact;
-import org.apache.hadoop.yarn.service.api.records.ConfigFile;
-import org.apache.hadoop.yarn.service.provider.AbstractClientProvider;
-import org.junit.Assert;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-
-import static org.mockito.ArgumentMatchers.any;
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.when;
-
-/**
- * Test the AbstractClientProvider shared methods.
- */
-public class TestAbstractClientProvider {
-  private static final String EXCEPTION_PREFIX = "Should have thrown " +
-      "exception: ";
-  private static final String NO_EXCEPTION_PREFIX = "Should not have thrown " +
-      "exception: ";
-
-  private static class ClientProvider extends AbstractClientProvider {
-    @Override
-    public void validateArtifact(Artifact artifact, String compName,
-        FileSystem fileSystem) throws IOException {
-    }
-
-    @Override
-    protected void validateConfigFile(ConfigFile configFile, String compName,
-        FileSystem fileSystem) throws IOException {
-    }
-  }
-
-  @Test
-  public void testConfigFiles() throws IOException {
-    ClientProvider clientProvider = new ClientProvider();
-    FileSystem mockFs = mock(FileSystem.class);
-    FileStatus mockFileStatus = mock(FileStatus.class);
-    when(mockFs.exists(any())).thenReturn(true);
-
-    String compName = "sleeper";
-    ConfigFile configFile = new ConfigFile();
-    List<ConfigFile> configFiles = new ArrayList<>();
-    configFiles.add(configFile);
-
-    try {
-      clientProvider.validateConfigFiles(configFiles, compName, mockFs);
-      Assert.fail(EXCEPTION_PREFIX + "null file type");
-    } catch (IllegalArgumentException e) {
-    }
-
-    configFile.setType(ConfigFile.TypeEnum.TEMPLATE);
-    try {
-      clientProvider.validateConfigFiles(configFiles, compName, mockFs);
-      Assert.fail(EXCEPTION_PREFIX + "empty src_file for type template");
-    } catch (IllegalArgumentException e) {
-    }
-
-    configFile.setSrcFile("srcfile");
-    try {
-      clientProvider.validateConfigFiles(configFiles, compName, mockFs);
-      Assert.fail(EXCEPTION_PREFIX + "empty dest file");
-    } catch (IllegalArgumentException e) {
-    }
-
-    configFile.setDestFile("destfile");
-    try {
-      clientProvider.validateConfigFiles(configFiles, compName, mockFs);
-    } catch (IllegalArgumentException e) {
-      Assert.fail(NO_EXCEPTION_PREFIX + e.getMessage());
-    }
-
-    configFile = new ConfigFile();
-    configFile.setType(ConfigFile.TypeEnum.JSON);
-    configFile.setSrcFile(null);
-    configFile.setDestFile("path/destfile2");
-    configFiles.add(configFile);
-    try {
-      clientProvider.validateConfigFiles(configFiles, compName, mockFs);
-      Assert.fail(EXCEPTION_PREFIX + "dest file with multiple path elements");
-    } catch (IllegalArgumentException e) {
-    }
-
-    configFile.setDestFile("/path/destfile2");
-    try {
-      clientProvider.validateConfigFiles(configFiles, compName, mockFs);
-    } catch (IllegalArgumentException e) {
-      Assert.fail(NO_EXCEPTION_PREFIX + e.getMessage());
-    }
-
-    configFile.setDestFile("destfile");
-    try {
-      clientProvider.validateConfigFiles(configFiles, compName, mockFs);
-      Assert.fail(EXCEPTION_PREFIX + "duplicate dest file");
-    } catch (IllegalArgumentException e) {
-    }
-
-    configFiles.clear();
-    configFile = new ConfigFile();
-    configFile.setType(ConfigFile.TypeEnum.STATIC);
-    configFile.setSrcFile(null);
-    configFile.setDestFile("path/destfile3");
-    configFiles.add(configFile);
-    try {
-      clientProvider.validateConfigFiles(configFiles, compName, mockFs);
-      Assert.fail(EXCEPTION_PREFIX + "dest file with multiple path elements");
-    } catch (IllegalArgumentException e) {
-    }
-
-    configFile.setDestFile("/path/destfile3");
-    try {
-      clientProvider.validateConfigFiles(configFiles, compName, mockFs);
-      Assert.fail(EXCEPTION_PREFIX + "src file should be specified");
-    } catch (IllegalArgumentException e) {
-    }
-
-    //should succeed
-    configFile.setSrcFile("srcFile");
-    configFile.setDestFile("destfile3");
-    clientProvider.validateConfigFiles(configFiles, compName, mockFs);
-
-    when(mockFileStatus.isDirectory()).thenReturn(true);
-    when(mockFs.getFileStatus(new Path("srcFile")))
-        .thenReturn(mockFileStatus).thenReturn(mockFileStatus);
-
-    configFiles.clear();
-    configFile = new ConfigFile();
-    configFile.setType(ConfigFile.TypeEnum.STATIC);
-    configFile.setSrcFile("srcFile");
-    configFile.setDestFile("destfile3");
-    configFiles.add(configFile);
-
-    try {
-      clientProvider.validateConfigFiles(configFiles, compName, mockFs);
-      Assert.fail(EXCEPTION_PREFIX + "src file is a directory");
-    } catch (IllegalArgumentException e) {
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/providers/TestDefaultClientProvider.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/providers/TestDefaultClientProvider.java
deleted file mode 100644
index 6d6720bb7e6..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/providers/TestDefaultClientProvider.java
+++ /dev/null
@@ -1,66 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.providers;
-
-import static org.mockito.ArgumentMatchers.any;
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.when;
-
-import java.io.IOException;
-
-import org.apache.hadoop.fs.FileSystem;
-import org.apache.hadoop.yarn.service.api.records.ConfigFile;
-import org.apache.hadoop.yarn.service.exceptions.RestApiErrorMessages;
-import org.apache.hadoop.yarn.service.provider.defaultImpl.DefaultClientProvider;
-import org.junit.Assert;
-import org.junit.Test;
-
-public class TestDefaultClientProvider {
-  private static final String EXCEPTION_PREFIX = "Should have thrown "
-      + "exception: ";
-  private static final String NO_EXCEPTION_PREFIX = "Should not have thrown "
-      + "exception: ";
-
-  @Test
-  public void testConfigFile() throws IOException {
-    DefaultClientProvider defaultClientProvider = new DefaultClientProvider();
-    FileSystem mockFs = mock(FileSystem.class);
-    when(mockFs.exists(any())).thenReturn(true);
-
-    String compName = "sleeper";
-    ConfigFile configFile = new ConfigFile();
-    configFile.setDestFile("/var/tmp/a.txt");
-
-    try {
-      defaultClientProvider.validateConfigFile(configFile, compName, mockFs);
-      Assert.fail(EXCEPTION_PREFIX + " dest_file must be relative");
-    } catch (IllegalArgumentException e) {
-      String actualMsg = String.format(
-          RestApiErrorMessages.ERROR_CONFIGFILE_DEST_FILE_FOR_COMP_NOT_ABSOLUTE,
-          compName, "no", configFile.getDestFile());
-      Assert.assertEquals(actualMsg, e.getLocalizedMessage());
-    }
-
-    configFile.setDestFile("../a.txt");
-    try {
-      defaultClientProvider.validateConfigFile(configFile, compName, mockFs);
-    } catch (IllegalArgumentException e) {
-      Assert.fail(NO_EXCEPTION_PREFIX + e.getLocalizedMessage());
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/providers/TestProviderFactory.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/providers/TestProviderFactory.java
deleted file mode 100644
index 56f4555b16c..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/providers/TestProviderFactory.java
+++ /dev/null
@@ -1,76 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.providers;
-
-import org.apache.hadoop.yarn.service.api.records.Artifact;
-import org.apache.hadoop.yarn.service.api.records.Artifact.TypeEnum;
-import org.apache.hadoop.yarn.service.provider.ProviderFactory;
-import org.apache.hadoop.yarn.service.provider.defaultImpl.DefaultClientProvider;
-import org.apache.hadoop.yarn.service.provider.defaultImpl.DefaultProviderFactory;
-import org.apache.hadoop.yarn.service.provider.defaultImpl.DefaultProviderService;
-import org.apache.hadoop.yarn.service.provider.docker.DockerClientProvider;
-import org.apache.hadoop.yarn.service.provider.docker.DockerProviderFactory;
-import org.apache.hadoop.yarn.service.provider.docker.DockerProviderService;
-import org.apache.hadoop.yarn.service.provider.tarball.TarballClientProvider;
-import org.apache.hadoop.yarn.service.provider.tarball.TarballProviderFactory;
-import org.apache.hadoop.yarn.service.provider.tarball.TarballProviderService;
-
-import org.junit.Test;
-
-import static org.junit.Assert.assertTrue;
-
-/**
- * Test provider factories.
- */
-public class TestProviderFactory {
-  @Test
-  public void testDockerFactory() throws Throwable {
-    ProviderFactory factory = ProviderFactory
-        .createServiceProviderFactory(new Artifact().type(TypeEnum.DOCKER));
-    assertTrue(factory instanceof DockerProviderFactory);
-    assertTrue(factory.createClientProvider() instanceof DockerClientProvider);
-    assertTrue(factory.createServerProvider() instanceof DockerProviderService);
-    assertTrue(ProviderFactory.getProviderService(new Artifact()
-        .type(TypeEnum.DOCKER)) instanceof DockerProviderService);
-  }
-
-  @Test
-  public void testTarballFactory() throws Throwable {
-    ProviderFactory factory = ProviderFactory
-        .createServiceProviderFactory(new Artifact().type(TypeEnum.TARBALL));
-    assertTrue(factory instanceof TarballProviderFactory);
-    assertTrue(factory.createClientProvider() instanceof TarballClientProvider);
-    assertTrue(factory.createServerProvider() instanceof
-        TarballProviderService);
-    assertTrue(ProviderFactory.getProviderService(new Artifact()
-        .type(TypeEnum.TARBALL)) instanceof TarballProviderService);
-  }
-
-  @Test
-  public void testDefaultFactory() throws Throwable {
-    ProviderFactory factory = ProviderFactory
-        .createServiceProviderFactory(null);
-    assertTrue(factory instanceof DefaultProviderFactory);
-    assertTrue(factory.createClientProvider() instanceof DefaultClientProvider);
-    assertTrue(factory.createServerProvider() instanceof DefaultProviderService);
-    assertTrue(ProviderFactory.getProviderService(null) instanceof
-        DefaultProviderService);
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/timelineservice/TestServiceTimelinePublisher.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/timelineservice/TestServiceTimelinePublisher.java
deleted file mode 100644
index a77e6c8d317..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/timelineservice/TestServiceTimelinePublisher.java
+++ /dev/null
@@ -1,297 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- *  or more contributor license agreements.  See the NOTICE file
- *  distributed with this work for additional information
- *  regarding copyright ownership.  The ASF licenses this file
- *  to you under the Apache License, Version 2.0 (the
- *  "License"); you may not use this file except in compliance
- *  with the License.  You may obtain a copy of the License at
- *
- *       http://www.apache.org/licenses/LICENSE-2.0
- *
- *  Unless required by applicable law or agreed to in writing, software
- *  distributed under the License is distributed on an "AS IS" BASIS,
- *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- *  See the License for the specific language governing permissions and
- *  limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.timelineservice;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;
-import org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity;
-import org.apache.hadoop.yarn.api.records.timelineservice.TimelineEntity.Identifier;
-import org.apache.hadoop.yarn.client.api.TimelineV2Client;
-import org.apache.hadoop.yarn.client.api.impl.TimelineV2ClientImpl;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.service.ServiceContext;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.api.records.Artifact;
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.api.records.Container;
-import org.apache.hadoop.yarn.service.api.records.ContainerState;
-import org.apache.hadoop.yarn.service.api.records.PlacementConstraint;
-import org.apache.hadoop.yarn.service.api.records.PlacementPolicy;
-import org.apache.hadoop.yarn.service.api.records.PlacementType;
-import org.apache.hadoop.yarn.service.api.records.Resource;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstance;
-import org.apache.hadoop.yarn.service.component.instance.ComponentInstanceId;
-import org.junit.After;
-import org.junit.Before;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Date;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
-import static org.junit.Assert.assertEquals;
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.when;
-
-/**
- * Test class for ServiceTimelinePublisher.
- */
-public class TestServiceTimelinePublisher {
-  private TimelineV2Client timelineClient;
-  private Configuration config;
-  private ServiceTimelinePublisher serviceTimelinePublisher;
-  private static String SERVICE_NAME = "HBASE";
-  private static String SERVICEID = "application_1490093646524_0005";
-  private static String ARTIFACTID = "ARTIFACTID";
-  private static String COMPONENT_NAME = "DEFAULT";
-  private static String CONTAINER_ID =
-      "container_e02_1490093646524_0005_01_000001";
-  private static String CONTAINER_IP =
-      "localhost";
-  private static String CONTAINER_HOSTNAME =
-      "cnl124-localhost.site";
-  private static String CONTAINER_BAREHOST =
-      "localhost.com";
-
-  @Before
-  public void setUp() throws Exception {
-    config = new Configuration();
-    config.setBoolean(YarnConfiguration.TIMELINE_SERVICE_ENABLED, true);
-    config.setFloat(YarnConfiguration.TIMELINE_SERVICE_VERSION, 2.0f);
-    timelineClient =
-        new DummyTimelineClient(ApplicationId.fromString(SERVICEID));
-    serviceTimelinePublisher = new ServiceTimelinePublisher(timelineClient);
-    serviceTimelinePublisher.init(config);
-    serviceTimelinePublisher.start();
-  }
-
-  @After
-  public void tearDown() throws Exception {
-    if (serviceTimelinePublisher != null) {
-      serviceTimelinePublisher.stop();
-    }
-    if (timelineClient != null) {
-      timelineClient.stop();
-    }
-  }
-
-  @Test
-  public void testServiceAttemptEntity() {
-    Service service = createMockApplication();
-    serviceTimelinePublisher
-        .serviceAttemptRegistered(service, new YarnConfiguration());
-
-    Collection<TimelineEntity> lastPublishedEntities =
-        ((DummyTimelineClient) timelineClient).getLastPublishedEntities();
-    // 2 entities because during registration component also registered.
-    assertEquals(2, lastPublishedEntities.size());
-    for (TimelineEntity timelineEntity : lastPublishedEntities) {
-      if (timelineEntity.getType() == ServiceTimelineEntityType.COMPONENT
-          .toString()) {
-        verifyComponentTimelineEntity(timelineEntity);
-      } else {
-        verifyServiceAttemptTimelineEntity(timelineEntity, null, true);
-      }
-    }
-
-    ServiceContext context = new ServiceContext();
-    context.attemptId = ApplicationAttemptId
-        .newInstance(ApplicationId.fromString(service.getId()), 1);
-    String exitDiags = "service killed";
-    serviceTimelinePublisher.serviceAttemptUnregistered(context,
-        FinalApplicationStatus.ENDED, exitDiags);
-    lastPublishedEntities =
-        ((DummyTimelineClient) timelineClient).getLastPublishedEntities();
-    for (TimelineEntity timelineEntity : lastPublishedEntities) {
-      if (timelineEntity.getType() == ServiceTimelineEntityType.SERVICE_ATTEMPT
-          .toString()) {
-        verifyServiceAttemptTimelineEntity(timelineEntity, exitDiags,
-            false);
-      }
-    }
-  }
-
-  @Test
-  public void testComponentInstanceEntity() {
-    Container container = new Container();
-    container.id(CONTAINER_ID).ip(CONTAINER_IP).bareHost(CONTAINER_BAREHOST)
-        .hostname(CONTAINER_HOSTNAME).state(ContainerState.RUNNING_BUT_UNREADY)
-        .launchTime(new Date());
-    ComponentInstanceId id = new ComponentInstanceId(0, COMPONENT_NAME);
-    ComponentInstance instance = mock(ComponentInstance.class);
-    when(instance.getCompName()).thenReturn(COMPONENT_NAME);
-    when(instance.getCompInstanceName()).thenReturn("comp_instance_name");
-    serviceTimelinePublisher.componentInstanceStarted(container,
-        instance);
-
-    Collection<TimelineEntity> lastPublishedEntities =
-        ((DummyTimelineClient) timelineClient).getLastPublishedEntities();
-    assertEquals(1, lastPublishedEntities.size());
-    TimelineEntity entity = lastPublishedEntities.iterator().next();
-
-    assertEquals(1, entity.getEvents().size());
-    assertEquals(CONTAINER_ID, entity.getId());
-    assertEquals(CONTAINER_BAREHOST,
-        entity.getInfo().get(ServiceTimelineMetricsConstants.BARE_HOST));
-    assertEquals(COMPONENT_NAME,
-        entity.getInfo().get(ServiceTimelineMetricsConstants.COMPONENT_NAME));
-    assertEquals(ContainerState.RUNNING_BUT_UNREADY.toString(),
-        entity.getInfo().get(ServiceTimelineMetricsConstants.STATE));
-
-    // updated container state
-    container.setState(ContainerState.READY);
-    serviceTimelinePublisher.componentInstanceIPHostUpdated(container);
-    lastPublishedEntities =
-        ((DummyTimelineClient) timelineClient).getLastPublishedEntities();
-    assertEquals(1, lastPublishedEntities.size());
-    entity = lastPublishedEntities.iterator().next();
-    assertEquals(2, entity.getEvents().size());
-    assertEquals(ContainerState.READY.toString(),
-        entity.getInfo().get(ServiceTimelineMetricsConstants.STATE));
-
-  }
-
-  private void verifyServiceAttemptTimelineEntity(TimelineEntity timelineEntity,
-      String message, boolean isRegistedEntity) {
-    assertEquals(SERVICEID, timelineEntity.getId());
-    assertEquals(SERVICE_NAME,
-        timelineEntity.getInfo().get(ServiceTimelineMetricsConstants.NAME));
-    if (isRegistedEntity) {
-      assertEquals(ServiceState.STARTED.toString(),
-          timelineEntity.getInfo().get(ServiceTimelineMetricsConstants.STATE));
-      assertEquals(ServiceTimelineEvent.SERVICE_ATTEMPT_REGISTERED.toString(),
-          timelineEntity.getEvents().iterator().next().getId());
-    } else {
-      assertEquals("ENDED",
-          timelineEntity.getInfo().get(ServiceTimelineMetricsConstants.STATE).toString());
-      assertEquals(message, timelineEntity.getInfo()
-          .get(ServiceTimelineMetricsConstants.DIAGNOSTICS_INFO));
-      assertEquals(2, timelineEntity.getEvents().size());
-      assertEquals(ServiceTimelineEvent.SERVICE_ATTEMPT_UNREGISTERED.toString(),
-          timelineEntity.getEvents().iterator().next().getId());
-    }
-  }
-
-  private void verifyComponentTimelineEntity(TimelineEntity entity) {
-    Map<String, Object> info = entity.getInfo();
-    assertEquals("DEFAULT", entity.getId());
-    assertEquals(ARTIFACTID,
-        info.get(ServiceTimelineMetricsConstants.ARTIFACT_ID));
-    assertEquals("DOCKER",
-        info.get(ServiceTimelineMetricsConstants.ARTIFACT_TYPE));
-    assertEquals("medium",
-        info.get(ServiceTimelineMetricsConstants.RESOURCE_PROFILE));
-    assertEquals(1, info.get(ServiceTimelineMetricsConstants.RESOURCE_CPU));
-    assertEquals("1024",
-        info.get(ServiceTimelineMetricsConstants.RESOURCE_MEMORY));
-    assertEquals("sleep 1",
-        info.get(ServiceTimelineMetricsConstants.LAUNCH_COMMAND));
-    assertEquals("false",
-        info.get(ServiceTimelineMetricsConstants.RUN_PRIVILEGED_CONTAINER));
-  }
-
-  private static Service createMockApplication() {
-    Service service = mock(Service.class);
-
-    when(service.getId()).thenReturn(SERVICEID);
-    when(service.getLaunchTime()).thenReturn(new Date());
-    when(service.getState()).thenReturn(ServiceState.STARTED);
-    when(service.getName()).thenReturn(SERVICE_NAME);
-    when(service.getConfiguration()).thenReturn(
-        new org.apache.hadoop.yarn.service.api.records.Configuration());
-
-    Component component = mock(Component.class);
-    Artifact artifact = new Artifact();
-    artifact.setId(ARTIFACTID);
-    Resource resource = new Resource();
-    resource.setCpus(1);
-    resource.setMemory(1024 + "");
-    resource.setProfile("medium");
-    when(component.getArtifact()).thenReturn(artifact);
-    when(component.getName()).thenReturn(COMPONENT_NAME);
-    when(component.getResource()).thenReturn(resource);
-    when(component.getLaunchCommand()).thenReturn("sleep 1");
-    PlacementPolicy placementPolicy = new PlacementPolicy();
-    PlacementConstraint placementConstraint = new PlacementConstraint();
-    placementConstraint.setType(PlacementType.ANTI_AFFINITY);
-    placementPolicy
-        .setConstraints(Collections.singletonList(placementConstraint));
-    when(component.getPlacementPolicy()).thenReturn(placementPolicy);
-    when(component.getConfiguration()).thenReturn(
-        new org.apache.hadoop.yarn.service.api.records.Configuration());
-    List<Component> components = new ArrayList<Component>();
-    components.add(component);
-
-    when(service.getComponents()).thenReturn(components);
-    return service;
-  }
-
-  protected static class DummyTimelineClient extends TimelineV2ClientImpl {
-    private Map<Identifier, TimelineEntity> lastPublishedEntities =
-        new HashMap<>();
-
-    public DummyTimelineClient(ApplicationId appId) {
-      super(appId);
-    }
-
-    @Override
-    public void putEntitiesAsync(TimelineEntity... entities)
-        throws IOException, YarnException {
-      putEntities(entities);
-    }
-
-    @Override
-    public void putEntities(TimelineEntity... entities)
-        throws IOException, YarnException {
-      for (TimelineEntity timelineEntity : entities) {
-        TimelineEntity entity =
-            lastPublishedEntities.get(timelineEntity.getIdentifier());
-        if (entity == null) {
-          lastPublishedEntities.put(timelineEntity.getIdentifier(),
-              timelineEntity);
-        } else {
-          entity.addMetrics(timelineEntity.getMetrics());
-          entity.addEvents(timelineEntity.getEvents());
-          entity.addInfo(timelineEntity.getInfo());
-          entity.addConfigs(timelineEntity.getConfigs());
-          entity.addRelatesToEntities(timelineEntity.getRelatesToEntities());
-          entity
-              .addIsRelatedToEntities(timelineEntity.getIsRelatedToEntities());
-        }
-      }
-    }
-
-    public Collection<TimelineEntity> getLastPublishedEntities() {
-      return lastPublishedEntities.values();
-    }
-
-    public void reset() {
-      lastPublishedEntities = null;
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/utils/TestCoreFileSystem.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/utils/TestCoreFileSystem.java
deleted file mode 100644
index ba4a65813d2..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/utils/TestCoreFileSystem.java
+++ /dev/null
@@ -1,46 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import org.apache.hadoop.fs.Path;
-import org.apache.hadoop.yarn.service.ServiceTestUtils;
-import org.apache.hadoop.yarn.service.conf.YarnServiceConstants;
-import org.junit.Assert;
-import org.junit.Rule;
-import org.junit.Test;
-
-/**
- * Tests for {@link CoreFileSystem}.
- */
-public class TestCoreFileSystem {
-
-  @Rule
-  public ServiceTestUtils.ServiceFSWatcher rule =
-      new ServiceTestUtils.ServiceFSWatcher();
-
-  @Test
-  public void testClusterUpgradeDirPath() {
-    String serviceName = "testClusterUpgrade";
-    String version = "v1";
-    Path expectedPath = new Path(rule.getFs().buildClusterDirPath(serviceName),
-        YarnServiceConstants.UPGRADE_DIR + "/" + version);
-    Assert.assertEquals("incorrect upgrade path", expectedPath,
-        rule.getFs().buildClusterUpgradeDirPath(serviceName, version));
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/utils/TestFilterUtils.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/utils/TestFilterUtils.java
deleted file mode 100644
index 59cc441818a..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/utils/TestFilterUtils.java
+++ /dev/null
@@ -1,111 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.service.utils;
-
-import org.apache.hadoop.util.Lists;
-import org.apache.hadoop.yarn.proto.ClientAMProtocol.GetCompInstancesRequestProto;
-import org.apache.hadoop.yarn.service.MockRunningServiceContext;
-import org.apache.hadoop.yarn.service.ServiceContext;
-import org.apache.hadoop.yarn.service.ServiceTestUtils;
-import org.apache.hadoop.yarn.service.TestServiceManager;
-import org.apache.hadoop.yarn.service.api.records.ComponentContainers;
-import org.apache.hadoop.yarn.service.api.records.ContainerState;
-import org.junit.Assert;
-import org.junit.Rule;
-import org.junit.Test;
-
-import java.util.List;
-
-public class TestFilterUtils {
-
-  @Rule
-  public ServiceTestUtils.ServiceFSWatcher rule =
-      new ServiceTestUtils.ServiceFSWatcher();
-
-  @Test
-  public void testNoFilter() throws Exception {
-    GetCompInstancesRequestProto req = GetCompInstancesRequestProto.newBuilder()
-        .build();
-    List<ComponentContainers> compContainers = FilterUtils.filterInstances(
-        new MockRunningServiceContext(rule,
-            TestServiceManager.createBaseDef("service")), req);
-    Assert.assertEquals("num comps", 2, compContainers.size());
-    compContainers.forEach(item -> {
-      Assert.assertEquals("num containers", 2, item.getContainers().size());
-    });
-  }
-
-  @Test
-  public void testFilterWithComp() throws Exception {
-    GetCompInstancesRequestProto req = GetCompInstancesRequestProto.newBuilder()
-        .addAllComponentNames(Lists.newArrayList("compa")).build();
-    List<ComponentContainers> compContainers = FilterUtils.filterInstances(
-        new MockRunningServiceContext(rule,
-            TestServiceManager.createBaseDef("service")), req);
-    Assert.assertEquals("num comps", 1, compContainers.size());
-    Assert.assertEquals("comp name", "compa",
-        compContainers.get(0).getComponentName());
-
-    Assert.assertEquals("num containers", 2,
-        compContainers.get(0).getContainers().size());
-  }
-
-  @Test
-  public void testFilterWithVersion() throws Exception {
-    ServiceContext sc = new MockRunningServiceContext(rule,
-        TestServiceManager.createBaseDef("service"));
-    GetCompInstancesRequestProto.Builder reqBuilder =
-        GetCompInstancesRequestProto.newBuilder();
-
-    reqBuilder.setVersion("v2");
-    Assert.assertEquals("num comps", 0,
-        FilterUtils.filterInstances(sc, reqBuilder.build()).size());
-
-    reqBuilder.addAllComponentNames(Lists.newArrayList("compa"))
-        .setVersion("v1").build();
-
-    Assert.assertEquals("num containers", 2,
-        FilterUtils.filterInstances(sc, reqBuilder.build()).get(0)
-            .getContainers().size());
-  }
-
-  @Test
-  public void testFilterWithState() throws Exception {
-    ServiceContext sc = new MockRunningServiceContext(rule,
-        TestServiceManager.createBaseDef("service"));
-    GetCompInstancesRequestProto.Builder reqBuilder =
-        GetCompInstancesRequestProto.newBuilder();
-
-    reqBuilder.addAllContainerStates(Lists.newArrayList(
-        ContainerState.READY.toString()));
-    List<ComponentContainers> compContainers = FilterUtils.filterInstances(sc,
-        reqBuilder.build());
-    Assert.assertEquals("num comps", 2, compContainers.size());
-    compContainers.forEach(item -> {
-      Assert.assertEquals("num containers", 2, item.getContainers().size());
-    });
-
-    reqBuilder.clearContainerStates();
-    reqBuilder.addAllContainerStates(Lists.newArrayList(
-        ContainerState.STOPPED.toString()));
-    Assert.assertEquals("num comps", 0,
-        FilterUtils.filterInstances(sc, reqBuilder.build()).size());
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/utils/TestServiceApiUtil.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/utils/TestServiceApiUtil.java
deleted file mode 100644
index 5c80f85f577..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/java/org/apache/hadoop/yarn/service/utils/TestServiceApiUtil.java
+++ /dev/null
@@ -1,771 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.service.utils;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.registry.client.api.RegistryConstants;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.service.ServiceTestUtils;
-import org.apache.hadoop.yarn.service.api.records.Artifact;
-import org.apache.hadoop.yarn.service.api.records.Component;
-import org.apache.hadoop.yarn.service.api.records.KerberosPrincipal;
-import org.apache.hadoop.yarn.service.api.records.PlacementConstraint;
-import org.apache.hadoop.yarn.service.api.records.PlacementPolicy;
-import org.apache.hadoop.yarn.service.api.records.PlacementScope;
-import org.apache.hadoop.yarn.service.api.records.PlacementType;
-import org.apache.hadoop.yarn.service.api.records.Resource;
-import org.apache.hadoop.yarn.service.api.records.Service;
-import org.apache.hadoop.yarn.service.api.records.ServiceState;
-import org.apache.hadoop.yarn.service.exceptions.RestApiErrorMessages;
-import org.junit.Assert;
-import org.junit.BeforeClass;
-import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.List;
-
-import static org.assertj.core.api.Assertions.assertThat;
-import static org.apache.hadoop.test.LambdaTestUtils.intercept;
-import static org.apache.hadoop.yarn.service.conf.RestApiConstants.DEFAULT_UNLIMITED_LIFETIME;
-import static org.apache.hadoop.yarn.service.exceptions.RestApiErrorMessages.*;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertNotNull;
-import static org.junit.Assert.fail;
-
-/**
- * Test for ServiceApiUtil helper methods.
- */
-public class TestServiceApiUtil extends ServiceTestUtils {
-  private static final Logger LOG = LoggerFactory
-      .getLogger(TestServiceApiUtil.class);
-  private static final String EXCEPTION_PREFIX = "Should have thrown " +
-      "exception: ";
-  private static final String NO_EXCEPTION_PREFIX = "Should not have thrown " +
-      "exception: ";
-
-  private static final String LEN_64_STR =
-      "abcdefghijklmnopqrstuvwxyz0123456789abcdefghijklmnopqrstuvwxyz01";
-
-  private static final YarnConfiguration CONF_DEFAULT_DNS = new
-      YarnConfiguration();
-  private static final YarnConfiguration CONF_DNS_ENABLED = new
-      YarnConfiguration();
-
-  @BeforeClass
-  public static void init() {
-    CONF_DNS_ENABLED.setBoolean(RegistryConstants.KEY_DNS_ENABLED, true);
-  }
-
-  @Test(timeout = 90000)
-  public void testResourceValidation() throws Exception {
-    assertEquals(RegistryConstants.MAX_FQDN_LABEL_LENGTH + 1, LEN_64_STR
-        .length());
-
-    SliderFileSystem sfs = ServiceTestUtils.initMockFs();
-
-    Service app = new Service();
-
-    // no name
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-      Assert.fail(EXCEPTION_PREFIX + "service with no name");
-    } catch (IllegalArgumentException e) {
-      assertEquals(ERROR_APPLICATION_NAME_INVALID, e.getMessage());
-    }
-
-    app.setName("test");
-    // no version
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-      Assert.fail(EXCEPTION_PREFIX + " service with no version");
-    } catch (IllegalArgumentException e) {
-      assertEquals(String.format(ERROR_APPLICATION_VERSION_INVALID,
-          app.getName()), e.getMessage());
-    }
-
-    app.setVersion("v1");
-    // bad format name
-    String[] badNames = {"4finance", "Finance", "finance@home", LEN_64_STR};
-    for (String badName : badNames) {
-      app.setName(badName);
-      try {
-        ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-        Assert.fail(EXCEPTION_PREFIX + "service with bad name " + badName);
-      } catch (IllegalArgumentException e) {
-
-      }
-    }
-
-    // launch command not specified
-    app.setName(LEN_64_STR);
-    Component comp = new Component().name("comp1");
-    app.addComponent(comp);
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DEFAULT_DNS);
-      Assert.fail(EXCEPTION_PREFIX + "service with no launch command");
-    } catch (IllegalArgumentException e) {
-      assertEquals(RestApiErrorMessages.ERROR_ABSENT_LAUNCH_COMMAND,
-          e.getMessage());
-    }
-
-    // launch command not specified
-    app.setName(LEN_64_STR.substring(0, RegistryConstants
-        .MAX_FQDN_LABEL_LENGTH));
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-      Assert.fail(EXCEPTION_PREFIX + "service with no launch command");
-    } catch (IllegalArgumentException e) {
-      assertEquals(RestApiErrorMessages.ERROR_ABSENT_LAUNCH_COMMAND,
-          e.getMessage());
-    }
-
-    // memory not specified
-    comp.setLaunchCommand("sleep 1");
-    Resource res = new Resource();
-    app.setResource(res);
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-      Assert.fail(EXCEPTION_PREFIX + "service with no memory");
-    } catch (IllegalArgumentException e) {
-      assertEquals(String.format(
-          RestApiErrorMessages.ERROR_RESOURCE_MEMORY_FOR_COMP_INVALID,
-          comp.getName()), e.getMessage());
-    }
-
-    // invalid no of cpus
-    res.setMemory("100mb");
-    res.setCpus(-2);
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-      Assert.fail(
-          EXCEPTION_PREFIX + "service with invalid no of cpus");
-    } catch (IllegalArgumentException e) {
-      assertEquals(String.format(
-          RestApiErrorMessages.ERROR_RESOURCE_CPUS_FOR_COMP_INVALID_RANGE,
-          comp.getName()), e.getMessage());
-    }
-
-    // number of containers not specified
-    res.setCpus(2);
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-      Assert.fail(EXCEPTION_PREFIX + "service with no container count");
-    } catch (IllegalArgumentException e) {
-      Assert.assertTrue(e.getMessage()
-          .contains(ERROR_CONTAINERS_COUNT_INVALID));
-    }
-
-    // specifying profile along with cpus/memory raises exception
-    res.setProfile("hbase_finance_large");
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-      Assert.fail(EXCEPTION_PREFIX
-          + "service with resource profile along with cpus/memory");
-    } catch (IllegalArgumentException e) {
-      assertEquals(String.format(RestApiErrorMessages
-              .ERROR_RESOURCE_PROFILE_MULTIPLE_VALUES_FOR_COMP_NOT_SUPPORTED,
-          comp.getName()),
-          e.getMessage());
-    }
-
-    // currently resource profile alone is not supported.
-    // TODO: remove the next test once resource profile alone is supported.
-    res.setCpus(null);
-    res.setMemory(null);
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-      Assert.fail(EXCEPTION_PREFIX + "service with resource profile only");
-    } catch (IllegalArgumentException e) {
-      assertEquals(ERROR_RESOURCE_PROFILE_NOT_SUPPORTED_YET,
-          e.getMessage());
-    }
-
-    // unset profile here and add cpus/memory back
-    res.setProfile(null);
-    res.setCpus(2);
-    res.setMemory("2gb");
-
-    // null number of containers
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-      Assert.fail(EXCEPTION_PREFIX + "null number of containers");
-    } catch (IllegalArgumentException e) {
-      Assert.assertTrue(e.getMessage()
-          .startsWith(ERROR_CONTAINERS_COUNT_INVALID));
-    }
-  }
-
-  @Test
-  public void testArtifacts() throws IOException {
-    SliderFileSystem sfs = ServiceTestUtils.initMockFs();
-
-    Service app = new Service();
-    app.setName("service1");
-    app.setVersion("v1");
-    Resource res = new Resource();
-    app.setResource(res);
-    res.setMemory("512M");
-
-    // no artifact id fails with default type
-    Artifact artifact = new Artifact();
-    app.setArtifact(artifact);
-    String compName = "comp1";
-    Component comp = ServiceTestUtils.createComponent(compName);
-
-    app.setComponents(Collections.singletonList(comp));
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-      Assert.fail(EXCEPTION_PREFIX + "service with no artifact id");
-    } catch (IllegalArgumentException e) {
-      assertEquals(String.format(ERROR_ARTIFACT_ID_FOR_COMP_INVALID, compName),
-          e.getMessage());
-    }
-
-    // no artifact id fails with SERVICE type
-    artifact.setType(Artifact.TypeEnum.SERVICE);
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-      Assert.fail(EXCEPTION_PREFIX + "service with no artifact id");
-    } catch (IllegalArgumentException e) {
-      assertEquals(ERROR_ARTIFACT_ID_INVALID, e.getMessage());
-    }
-
-    // no artifact id fails with TARBALL type
-    artifact.setType(Artifact.TypeEnum.TARBALL);
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-      Assert.fail(EXCEPTION_PREFIX + "service with no artifact id");
-    } catch (IllegalArgumentException e) {
-      assertEquals(String.format(ERROR_ARTIFACT_ID_FOR_COMP_INVALID, compName),
-          e.getMessage());
-    }
-
-    // everything valid here
-    artifact.setType(Artifact.TypeEnum.DOCKER);
-    artifact.setId("docker.io/centos:centos7");
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-    } catch (IllegalArgumentException e) {
-      LOG.error("service attributes specified should be valid here", e);
-      Assert.fail(NO_EXCEPTION_PREFIX + e.getMessage());
-    }
-
-    assertThat(app.getLifetime()).isEqualTo(DEFAULT_UNLIMITED_LIFETIME);
-  }
-
-  private static Resource createValidResource() {
-    Resource res = new Resource();
-    res.setMemory("512M");
-    return res;
-  }
-
-  private static Component createValidComponent(String compName) {
-    Component comp = new Component();
-    comp.setName(compName);
-    comp.setResource(createValidResource());
-    comp.setNumberOfContainers(1L);
-    comp.setLaunchCommand("sleep 1");
-    return comp;
-  }
-
-  private static Service createValidApplication(String compName) {
-    Service app = new Service();
-    app.setName("name");
-    app.setVersion("v1");
-    app.setResource(createValidResource());
-    if (compName != null) {
-      app.addComponent(createValidComponent(compName));
-    }
-    return app;
-  }
-
-  @Test
-  public void testExternalApplication() throws IOException {
-    Service ext = createValidApplication("comp1");
-    SliderFileSystem sfs = ServiceTestUtils.initMockFs(ext);
-
-    Service app = createValidApplication(null);
-
-    Artifact artifact = new Artifact();
-    artifact.setType(Artifact.TypeEnum.SERVICE);
-    artifact.setId("id");
-    app.setArtifact(artifact);
-    app.addComponent(ServiceTestUtils.createComponent("comp2"));
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-    } catch (IllegalArgumentException e) {
-      Assert.fail(NO_EXCEPTION_PREFIX + e.getMessage());
-    }
-
-    assertEquals(1, app.getComponents().size());
-    assertNotNull(app.getComponent("comp2"));
-  }
-
-  @Test
-  public void testDuplicateComponents() throws IOException {
-    SliderFileSystem sfs = ServiceTestUtils.initMockFs();
-
-    String compName = "comp1";
-    Service app = createValidApplication(compName);
-    app.addComponent(createValidComponent(compName));
-
-    // duplicate component name fails
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-      Assert.fail(EXCEPTION_PREFIX + "service with component collision");
-    } catch (IllegalArgumentException e) {
-      assertEquals("Component name collision: " + compName, e.getMessage());
-    }
-  }
-
-  @Test
-  public void testComponentNameSameAsServiceName() throws IOException {
-    SliderFileSystem sfs = ServiceTestUtils.initMockFs();
-    Service app = new Service();
-    app.setName("test");
-    app.setVersion("v1");
-    app.addComponent(createValidComponent("test"));
-
-    //component name same as service name
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-      Assert.fail(EXCEPTION_PREFIX + "component name matches service name");
-    } catch (IllegalArgumentException e) {
-      assertEquals("Component name test must not be same as service name test",
-          e.getMessage());
-    }
-  }
-
-  @Test
-  public void testExternalDuplicateComponent() throws IOException {
-    Service ext = createValidApplication("comp1");
-    SliderFileSystem sfs = ServiceTestUtils.initMockFs(ext);
-
-    Service app = createValidApplication("comp1");
-    Artifact artifact = new Artifact();
-    artifact.setType(Artifact.TypeEnum.SERVICE);
-    artifact.setId("id");
-    app.getComponent("comp1").setArtifact(artifact);
-
-    // duplicate component name okay in the case of SERVICE component
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-    } catch (IllegalArgumentException e) {
-      Assert.fail(NO_EXCEPTION_PREFIX + e.getMessage());
-    }
-  }
-
-  @Test
-  public void testExternalComponent() throws IOException {
-    Service ext = createValidApplication("comp1");
-    SliderFileSystem sfs = ServiceTestUtils.initMockFs(ext);
-
-    Service app = createValidApplication("comp2");
-    Artifact artifact = new Artifact();
-    artifact.setType(Artifact.TypeEnum.SERVICE);
-    artifact.setId("id");
-    app.setArtifact(artifact);
-
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-    } catch (IllegalArgumentException e) {
-      Assert.fail(NO_EXCEPTION_PREFIX + e.getMessage());
-    }
-
-    assertEquals(1, app.getComponents().size());
-    // artifact ID not inherited from global
-    assertNotNull(app.getComponent("comp2"));
-
-    // set SERVICE artifact id on component
-    app.getComponent("comp2").setArtifact(artifact);
-
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-    } catch (IllegalArgumentException e) {
-      Assert.fail(NO_EXCEPTION_PREFIX + e.getMessage());
-    }
-
-    assertEquals(1, app.getComponents().size());
-    // original component replaced by external component
-    assertNotNull(app.getComponent("comp1"));
-  }
-
-  public static void verifyDependencySorting(List<Component> components,
-      Component... expectedSorting) {
-    Collection<Component> actualSorting = ServiceApiUtil.sortByDependencies(
-        components);
-    assertEquals(expectedSorting.length, actualSorting.size());
-    int i = 0;
-    for (Component component : actualSorting) {
-      assertEquals(expectedSorting[i++], component);
-    }
-  }
-
-  @Test
-  public void testDependencySorting() throws IOException {
-    Component a = ServiceTestUtils.createComponent("a");
-    Component b = ServiceTestUtils.createComponent("b");
-    Component c = ServiceTestUtils.createComponent("c");
-    Component d =
-        ServiceTestUtils.createComponent("d").dependencies(Arrays.asList("c"));
-    Component e = ServiceTestUtils.createComponent("e")
-        .dependencies(Arrays.asList("b", "d"));
-
-    verifyDependencySorting(Arrays.asList(a, b, c), a, b, c);
-    verifyDependencySorting(Arrays.asList(c, a, b), c, a, b);
-    verifyDependencySorting(Arrays.asList(a, b, c, d, e), a, b, c, d, e);
-    verifyDependencySorting(Arrays.asList(e, d, c, b, a), c, b, a, d, e);
-
-    c.setDependencies(Arrays.asList("e"));
-    try {
-      verifyDependencySorting(Arrays.asList(a, b, c, d, e));
-      Assert.fail(EXCEPTION_PREFIX + "components with dependency cycle");
-    } catch (IllegalArgumentException ex) {
-      assertEquals(String.format(
-          RestApiErrorMessages.ERROR_DEPENDENCY_CYCLE, Arrays.asList(c, d,
-              e)), ex.getMessage());
-    }
-
-    SliderFileSystem sfs = ServiceTestUtils.initMockFs();
-    Service service = createValidApplication(null);
-    service.setComponents(Arrays.asList(c, d, e));
-    try {
-      ServiceApiUtil.validateAndResolveService(service, sfs,
-          CONF_DEFAULT_DNS);
-      Assert.fail(EXCEPTION_PREFIX + "components with bad dependencies");
-    } catch (IllegalArgumentException ex) {
-      assertEquals(String.format(
-          RestApiErrorMessages.ERROR_DEPENDENCY_INVALID, "b", "e"), ex
-          .getMessage());
-    }
-  }
-
-  @Test
-  public void testInvalidComponent() throws IOException {
-    SliderFileSystem sfs = ServiceTestUtils.initMockFs();
-    testComponent(sfs);
-  }
-
-  @Test
-  public void testValidateCompName() {
-    String[] invalidNames = {
-        "EXAMPLE", // UPPER case not allowed
-        "example_app" // underscore not allowed.
-    };
-    for (String name : invalidNames) {
-      try {
-        ServiceApiUtil.validateNameFormat(name, new Configuration());
-        Assert.fail();
-      } catch (IllegalArgumentException ex) {
-        ex.printStackTrace();
-      }
-    }
-  }
-
-  private static void testComponent(SliderFileSystem sfs)
-      throws IOException {
-    int maxLen = RegistryConstants.MAX_FQDN_LABEL_LENGTH;
-    assertEquals(19, Long.toString(Long.MAX_VALUE).length());
-    maxLen = maxLen - Long.toString(Long.MAX_VALUE).length();
-
-    String compName = LEN_64_STR.substring(0, maxLen + 1);
-    Service app = createValidApplication(null);
-    app.addComponent(createValidComponent(compName));
-
-    // invalid component name fails if dns is enabled
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-      Assert.fail(EXCEPTION_PREFIX + "service with invalid component name");
-    } catch (IllegalArgumentException e) {
-      assertEquals(String.format(RestApiErrorMessages
-          .ERROR_COMPONENT_NAME_INVALID, maxLen, compName), e.getMessage());
-    }
-
-    // does not fail if dns is disabled
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DEFAULT_DNS);
-    } catch (IllegalArgumentException e) {
-      Assert.fail(NO_EXCEPTION_PREFIX + e.getMessage());
-    }
-
-    compName = LEN_64_STR.substring(0, maxLen);
-    app = createValidApplication(null);
-    app.addComponent(createValidComponent(compName));
-
-    // does not fail
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-    } catch (IllegalArgumentException e) {
-      Assert.fail(NO_EXCEPTION_PREFIX + e.getMessage());
-    }
-  }
-
-  @Test
-  public void testPlacementPolicy() throws IOException {
-    SliderFileSystem sfs = ServiceTestUtils.initMockFs();
-    Service app = createValidApplication("comp-a");
-    Component comp = app.getComponents().get(0);
-    PlacementPolicy pp = new PlacementPolicy();
-    PlacementConstraint pc = new PlacementConstraint();
-    pc.setName("CA1");
-    pp.setConstraints(Collections.singletonList(pc));
-    comp.setPlacementPolicy(pp);
-
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-      Assert.fail(EXCEPTION_PREFIX + "constraint with no type");
-    } catch (IllegalArgumentException e) {
-      assertEquals(String.format(
-          RestApiErrorMessages.ERROR_PLACEMENT_POLICY_CONSTRAINT_TYPE_NULL,
-          "CA1 ", "comp-a"), e.getMessage());
-    }
-
-    // Set the type
-    pc.setType(PlacementType.ANTI_AFFINITY);
-
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-      Assert.fail(EXCEPTION_PREFIX + "constraint with no scope");
-    } catch (IllegalArgumentException e) {
-      assertEquals(String.format(
-          RestApiErrorMessages.ERROR_PLACEMENT_POLICY_CONSTRAINT_SCOPE_NULL,
-          "CA1 ", "comp-a"), e.getMessage());
-    }
-
-    // Set the scope
-    pc.setScope(PlacementScope.NODE);
-
-    // Target tag is optional.
-    pc.setTargetTags(Collections.singletonList("comp-a"));
-
-    // Validation can succeed for any arbitrary target, only scheduler knows
-    // if the target tag is valid.
-    try {
-      ServiceApiUtil.validateAndResolveService(app, sfs, CONF_DNS_ENABLED);
-    } catch (IllegalArgumentException e) {
-      Assert.fail(NO_EXCEPTION_PREFIX + e.getMessage());
-    }
-  }
-
-  @Test
-  public void testKerberosPrincipal() throws IOException {
-    SliderFileSystem sfs = ServiceTestUtils.initMockFs();
-    Service app = createValidApplication("comp-a");
-    KerberosPrincipal kp = new KerberosPrincipal();
-    kp.setKeytab("file:///tmp/a.keytab");
-    kp.setPrincipalName("user/_HOST@domain.com");
-    app.setKerberosPrincipal(kp);
-
-    // This should succeed
-    try {
-      ServiceApiUtil.validateKerberosPrincipal(app.getKerberosPrincipal());
-    } catch (IllegalArgumentException e) {
-      Assert.fail(NO_EXCEPTION_PREFIX + e.getMessage());
-    }
-
-    // Keytab with no URI scheme should succeed too
-    kp.setKeytab("/some/path");
-    try {
-      ServiceApiUtil.validateKerberosPrincipal(app.getKerberosPrincipal());
-    } catch (IllegalArgumentException e) {
-      Assert.fail(NO_EXCEPTION_PREFIX + e.getMessage());
-    }
-  }
-
-  @Test
-  public void testKerberosPrincipalNameFormat() throws IOException {
-    Service app = createValidApplication("comp-a");
-    KerberosPrincipal kp = new KerberosPrincipal();
-    kp.setPrincipalName("user@domain.com");
-    app.setKerberosPrincipal(kp);
-
-    try {
-      ServiceApiUtil.validateKerberosPrincipal(app.getKerberosPrincipal());
-      Assert.fail(EXCEPTION_PREFIX + "service with invalid principal name " +
-          "format.");
-    } catch (IllegalArgumentException e) {
-      assertEquals(
-          String.format(
-              RestApiErrorMessages.ERROR_KERBEROS_PRINCIPAL_NAME_FORMAT,
-              kp.getPrincipalName()),
-          e.getMessage());
-    }
-
-    kp.setPrincipalName("user/_HOST@domain.com");
-    try {
-      ServiceApiUtil.validateKerberosPrincipal(app.getKerberosPrincipal());
-    } catch (IllegalArgumentException e) {
-      Assert.fail(NO_EXCEPTION_PREFIX + e.getMessage());
-    }
-
-    kp.setPrincipalName(null);
-    kp.setKeytab(null);
-    try {
-      ServiceApiUtil.validateKerberosPrincipal(app.getKerberosPrincipal());
-    } catch (NullPointerException e) {
-        Assert.fail(NO_EXCEPTION_PREFIX + e.getMessage());
-    }
-  }
-
-  @Test
-  public void testResolveCompsDependency() {
-    Service service = createExampleApplication();
-    List<String> dependencies = new ArrayList<String>();
-    dependencies.add("compb");
-    Component compa = createComponent("compa");
-    compa.setDependencies(dependencies);
-    Component compb = createComponent("compb");
-    service.addComponent(compa);
-    service.addComponent(compb);
-    List<String> order = ServiceApiUtil.resolveCompsDependency(service);
-    List<String> expected = new ArrayList<String>();
-    expected.add("compb");
-    expected.add("compa");
-    for (int i = 0; i < expected.size(); i++) {
-      Assert.assertEquals("Components are not equal.", expected.get(i),
-          order.get(i));
-    }
-  }
-
-  @Test
-  public void testResolveCompsDependencyReversed() {
-    Service service = createExampleApplication();
-    List<String> dependencies = new ArrayList<String>();
-    dependencies.add("compa");
-    Component compa = createComponent("compa");
-    Component compb = createComponent("compb");
-    compb.setDependencies(dependencies);
-    service.addComponent(compa);
-    service.addComponent(compb);
-    List<String> order = ServiceApiUtil.resolveCompsDependency(service);
-    List<String> expected = new ArrayList<String>();
-    expected.add("compa");
-    expected.add("compb");
-    for (int i = 0; i < expected.size(); i++) {
-      Assert.assertEquals("Components are not equal.", expected.get(i),
-          order.get(i));
-    }
-  }
-
-  @Test
-  public void testResolveCompsCircularDependency() {
-    Service service = createExampleApplication();
-    List<String> dependencies = new ArrayList<String>();
-    List<String> dependencies2 = new ArrayList<String>();
-    dependencies.add("compb");
-    dependencies2.add("compa");
-    Component compa = createComponent("compa");
-    compa.setDependencies(dependencies);
-    Component compb = createComponent("compb");
-    compa.setDependencies(dependencies2);
-    service.addComponent(compa);
-    service.addComponent(compb);
-    List<String> order = ServiceApiUtil.resolveCompsDependency(service);
-    List<String> expected = new ArrayList<String>();
-    expected.add("compa");
-    expected.add("compb");
-    for (int i = 0; i < expected.size(); i++) {
-      Assert.assertEquals("Components are not equal.", expected.get(i),
-          order.get(i));
-    }
-  }
-
-  @Test
-  public void testResolveNoCompsDependency() {
-    Service service = createExampleApplication();
-    Component compa = createComponent("compa");
-    Component compb = createComponent("compb");
-    service.addComponent(compa);
-    service.addComponent(compb);
-    List<String> order = ServiceApiUtil.resolveCompsDependency(service);
-    List<String> expected = new ArrayList<String>();
-    expected.add("compa");
-    expected.add("compb");
-    for (int i = 0; i < expected.size(); i++) {
-      Assert.assertEquals("Components are not equal.", expected.get(i),
-          order.get(i));
-    }
-  }
-
-  @Test(timeout = 1500)
-  public void testNoServiceDependencies() {
-    Service service = createExampleApplication();
-    Component compa = createComponent("compa");
-    Component compb = createComponent("compb");
-    service.addComponent(compa);
-    service.addComponent(compb);
-    List<String> dependencies = new ArrayList<String>();
-    service.setDependencies(dependencies);
-    ServiceApiUtil.checkServiceDependencySatisified(service);
-  }
-
-  @Test
-  public void testServiceDependencies() {
-    Thread thread = new Thread() {
-      @Override
-      public void run() {
-        Service service = createExampleApplication();
-        Component compa = createComponent("compa");
-        Component compb = createComponent("compb");
-        service.addComponent(compa);
-        service.addComponent(compb);
-        List<String> dependencies = new ArrayList<String>();
-        dependencies.add("abc");
-        service.setDependencies(dependencies);
-        Service dependent = createExampleApplication();
-        dependent.setState(ServiceState.STOPPED);
-        ServiceApiUtil.checkServiceDependencySatisified(service);
-      }
-    };
-    thread.start();
-    try {
-      Thread.sleep(1000);
-    } catch (InterruptedException e) {
-    }
-    Assert.assertTrue(thread.isAlive());
-  }
-
-  @Test
-  public void testJvmOpts() throws Exception {
-    String invalidJvmOpts = "`ping -c 3 example.com`";
-    intercept(IllegalArgumentException.class,
-        "Invalid character in yarn.service.am.java.opts.",
-        () -> ServiceApiUtil.validateJvmOpts(invalidJvmOpts));
-    String validJvmOpts = "-Dyarn.service.am.java.opts=-Xmx768m "
-        + "-Djava.security.auth.login.config=/opt/hadoop/etc/jaas-zk.conf";
-    try {
-      ServiceApiUtil.validateJvmOpts(validJvmOpts);
-    } catch (Exception ex) {
-      fail("Invalid character in yarn.service.am.java.opts.");
-    }
-  }
-
-  public static Service createExampleApplication() {
-
-    Service exampleApp = new Service();
-    exampleApp.setName("example-app");
-    exampleApp.setVersion("v1");
-    return exampleApp;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/example-app.json b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/example-app.json
deleted file mode 100644
index a2f41cf3cc5..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/example-app.json
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-  "name": "example-app",
-  "version": "1.0.0",
-  "components" :
-  [
-    {
-      "name": "simple",
-      "number_of_containers": 1,
-      "launch_command": "sleep 2",
-      "resource": {
-        "cpus": 1,
-        "memory": "128"
-      }
-    }
-  ]
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/log4j.properties b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/log4j.properties
deleted file mode 100644
index 81a3f6ad5d2..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/log4j.properties
+++ /dev/null
@@ -1,19 +0,0 @@
-#   Licensed under the Apache License, Version 2.0 (the "License");
-#   you may not use this file except in compliance with the License.
-#   You may obtain a copy of the License at
-#
-#       http://www.apache.org/licenses/LICENSE-2.0
-#
-#   Unless required by applicable law or agreed to in writing, software
-#   distributed under the License is distributed on an "AS IS" BASIS,
-#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-#   See the License for the specific language governing permissions and
-#   limitations under the License.
-
-# log4j configuration used during build and unit tests
-
-log4j.rootLogger=info,stdout
-log4j.threshold=ALL
-log4j.appender.stdout=org.apache.log4j.ConsoleAppender
-log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
-log4j.appender.stdout.layout.ConversionPattern=%d{ISO8601} %-5p [%t] %c{2} (%F:%M(%L)) - %m%n
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/app-override.json b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/app-override.json
deleted file mode 100644
index a4062bcd030..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/app-override.json
+++ /dev/null
@@ -1,77 +0,0 @@
-{
-  "name": "app-1",
-  "version": "1.0.0",
-  "lifetime": "3600",
-  "configuration": {
-    "properties": {
-      "g1": "a",
-      "g2": "b"
-    },
-    "files": [
-      {
-        "type": "PROPERTIES",
-        "dest_file": "file1",
-        "properties": {
-          "k1": "v1",
-          "k2": "v2"
-        }
-      },
-      {
-        "type": "XML",
-        "dest_file": "file2",
-        "properties": {
-          "k3": "v3"
-        }
-      }
-    ]
-  },
-  "resource": {
-    "cpus": 1,
-    "memory": "512"
-  },
-  "components": [
-    {
-      "name": "simple",
-      "launch_command": "sleep 3600",
-      "number_of_containers": 2,
-      "configuration": {
-        "files": [
-          {
-            "type": "PROPERTIES",
-            "dest_file": "file1",
-            "properties": {
-              "k1": "overridden"
-            }
-          }
-        ]
-      }
-    },
-    {
-      "name": "master",
-      "launch_command": "sleep 3600",
-      "number_of_containers": 2,
-      "configuration": {
-        "properties": {
-          "name": "m",
-          "g1": "overridden"
-        }
-      }
-    },
-    {
-      "name": "worker",
-      "number_of_containers": 2,
-      "launch_command": "sleep 3600",
-      "resource": {
-        "cpus": 1,
-        "memory": "1024"
-      },
-      "configuration": {
-        "properties": {
-          "name": "worker",
-          "g1": "overridden-by-worker",
-          "timeout": "1000"
-        }
-      }
-    }
-  ]
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/app.json b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/app.json
deleted file mode 100644
index 9765eafebcd..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/app.json
+++ /dev/null
@@ -1,60 +0,0 @@
-{
-  "name": "app-1",
-  "version": "1.0.0",
-  "id" : "application_1503358878042_0011",
-  "lifetime": "3600",
-  "configuration": {
-    "properties": {
-      "g1": "a",
-      "g2": "b",
-      "yarn.service.failure-count-reset.window": "60"
-    }
-  },
-  "resource": {
-    "cpus": 1,
-    "memory": "512"
-  },
-  "components": [
-    {
-      "name": "simple",
-      "number_of_containers": 2,
-      "launch_command": "sleep 3600"
-    },
-    {
-      "name": "master",
-      "number_of_containers": 1,
-      "launch_command": "sleep 3600",
-      "configuration": {
-        "properties": {
-          "g1": "overridden",
-          "g3": "will-be-overridden",
-          "jvm.heapsize": "512M"
-        }
-      }
-    },
-    {
-      "name": "worker",
-      "number_of_containers": 5,
-      "launch_command": "sleep 3600",
-      "resource": {
-        "cpus": 1,
-        "memory": "1024",
-        "additional": {
-          "resource-1": {
-            "value": 3333,
-            "unit": "Gi"
-          },
-          "yarn.io/gpu": {
-            "value": 5
-          }
-        }
-      },
-      "configuration": {
-        "properties": {
-          "g1": "overridden-by-worker",
-          "jvm.heapsize": "512M"
-        }
-      }
-    }
-  ]
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/default.json b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/default.json
deleted file mode 100644
index fc159c0a79a..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/default.json
+++ /dev/null
@@ -1,17 +0,0 @@
-{
-  "name": "default-app-1",
-  "version": "1.0.0",
-  "lifetime": "3600",
-  "components" :
-  [
-    {
-      "name": "sleep",
-      "number_of_containers": 1,
-      "launch_command": "sleep 3600",
-      "resource": {
-        "cpus": 2,
-        "memory": "256"
-      }
-    }
-  ]
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/external0.json b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/external0.json
deleted file mode 100644
index 8c7af45a6a3..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/external0.json
+++ /dev/null
@@ -1,16 +0,0 @@
-{
-  "name": "external-0",
-  "version": "1.0.0",
-  "lifetime": "3600",
-
-  "components" : [
-    {
-      "name" : "comp1",
-      "artifact": {
-        "type": "SERVICE",
-        "id": "app-1"
-      }
-    }
-  ]
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/external1.json b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/external1.json
deleted file mode 100644
index b206a77ad4e..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/external1.json
+++ /dev/null
@@ -1,31 +0,0 @@
-{
-  "name": "external-1",
-  "version": "1.0.0",
-  "lifetime": "3600",
-  "components": [
-    {
-      "name": "simple",
-      "artifact": {
-        "type": "SERVICE",
-        "id": "app-1"
-      }
-    },
-    {
-      "name": "master",
-      "configuration": {
-        "properties": {
-          "g3": "is-overridden"
-        }
-      }
-    },
-    {
-      "name": "other",
-      "launch_command": "sleep 3600",
-      "number_of_containers": 2,
-      "resource": {
-        "cpus": 1,
-        "memory": "512"
-      }
-    }
-  ]
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/external2.json b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/external2.json
deleted file mode 100644
index 01445a1dd55..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/external2.json
+++ /dev/null
@@ -1,23 +0,0 @@
-{
-  "name": "external-2",
-  "version": "1.0.0",
-  "lifetime": "3600",
-  "components": [
-    {
-      "name": "ext",
-      "artifact": {
-        "type": "SERVICE",
-        "id": "external-1"
-      }
-    },
-    {
-      "name": "another",
-      "launch_command": "sleep 3600",
-      "number_of_containers": 1,
-      "resource": {
-        "cpus": 1,
-        "memory": "512"
-      }
-    }
-  ]
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/external3.json b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/external3.json
deleted file mode 100644
index ef8e3238cc6..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/org/apache/hadoop/yarn/service/conf/examples/external3.json
+++ /dev/null
@@ -1,27 +0,0 @@
-{
-  "name": "external-3",
-  "version": "1.0.0",
-  "lifetime": "3600",
-  "components": [
-    {
-      "name": "volume-service",
-      "launch_command": "sleep 3600",
-      "number_of_containers": 1,
-      "resource": {
-        "": 1,
-        "memory": "512",
-        "additional": {
-          "yarn.io/csi-volume": {
-            "value": 100,
-            "unit": "Gi",
-            "tags": ["sample-tag"],
-            "attributes" : {
-              "driver" : "hostpath",
-              "mountPath" : "/mnt/data"
-            }
-          }
-        }
-      }
-    }
-  ]
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/yarn-site.xml b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/yarn-site.xml
deleted file mode 100644
index 266caa9e184..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/hadoop-yarn-services-core/src/test/resources/yarn-site.xml
+++ /dev/null
@@ -1,19 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
-<!--
-  Licensed under the Apache License, Version 2.0 (the "License");
-  you may not use this file except in compliance with the License.
-  You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License. See accompanying LICENSE file.
--->
-
-<configuration>
-  <!-- Dummy (invalid) config file to be overwriten by TestYarnNativeServices with MiniCluster configuration. -->
-</configuration>
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/pom.xml b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/pom.xml
deleted file mode 100644
index e3a1495c6a6..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/hadoop-yarn-services/pom.xml
+++ /dev/null
@@ -1,39 +0,0 @@
-<?xml version="1.0"?>
-<!--
-  Licensed under the Apache License, Version 2.0 (the "License");
-  you may not use this file except in compliance with the License.
-  You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License. See accompanying LICENSE file.
--->
-<project xmlns="http://maven.apache.org/POM/4.0.0"
-         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
-         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0
-                      https://maven.apache.org/xsd/maven-4.0.0.xsd">
-    <parent>
-        <artifactId>hadoop-yarn-applications</artifactId>
-        <groupId>org.apache.hadoop</groupId>
-        <version>3.4.0</version>
-    </parent>
-    <modelVersion>4.0.0</modelVersion>
-    <artifactId>hadoop-yarn-services</artifactId>
-    <name>Apache Hadoop YARN Services</name>
-    <packaging>pom</packaging>
-
-    <properties>
-        <hadoop.common.build.dir>${basedir}/../../../../hadoop-common-project/hadoop-common/target</hadoop.common.build.dir>
-    </properties>
-
-    <!-- Do not add dependencies here, add them to the POM of the leaf module -->
-
-    <modules>
-        <module>hadoop-yarn-services-core</module>
-        <module>hadoop-yarn-services-api</module>
-    </modules>
-</project>
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/pom.xml b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/pom.xml
index 2cde68a34e9..65ea6f55f1d 100644
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/pom.xml
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-applications/pom.xml
@@ -33,10 +33,6 @@
 
   <!-- Do not add dependencies here, add them to the POM of the leaf module -->
 
-  <modules>
-    <module>hadoop-yarn-services</module>
-  </modules>
-
  <profiles>
   <profile>
     <id>clover</id>
diff --git a/hadoop-yarn-project/pom.xml b/hadoop-yarn-project/pom.xml
index a91c83dc424..1b63feee876 100644
--- a/hadoop-yarn-project/pom.xml
+++ b/hadoop-yarn-project/pom.xml
@@ -81,10 +81,6 @@
       <groupId>org.apache.hadoop</groupId>
       <artifactId>hadoop-yarn-server-globalpolicygenerator</artifactId>
     </dependency>
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-services-core</artifactId>
-    </dependency>
   </dependencies>
 
   <build>
