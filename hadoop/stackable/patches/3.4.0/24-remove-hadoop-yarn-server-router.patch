Entirely remove hadoop-yarn-server-router

From: Lars Francke <git@lars-francke.de>


---
 hadoop-project/pom.xml                             |    6 
 .../hadoop-yarn-server-router/pom.xml              |  182 -
 .../delegation/RouterDelegationTokenSupport.java   |   65 
 .../security/token/delegation/package-info.java    |   20 
 .../apache/hadoop/yarn/server/router/Router.java   |  443 ---
 .../yarn/server/router/RouterAuditLogger.java      |  365 --
 .../hadoop/yarn/server/router/RouterMetrics.java   | 2476 --------------
 .../yarn/server/router/RouterServerUtil.java       |  833 -----
 .../server/router/cleaner/SubClusterCleaner.java   |   92 -
 .../yarn/server/router/cleaner/package-info.java   |   20 
 .../clientrm/AbstractClientRequestInterceptor.java |  114 -
 .../ApplicationSubmissionContextInterceptor.java   |   66 
 .../yarn/server/router/clientrm/ClientMethod.java  |   71 
 .../router/clientrm/ClientRequestInterceptor.java  |   80 
 .../clientrm/DefaultClientRequestInterceptor.java  |  362 --
 .../clientrm/FederationClientInterceptor.java      | 2365 --------------
 .../PassThroughClientRequestInterceptor.java       |  315 --
 .../router/clientrm/RouterClientRMService.java     |  667 ----
 .../router/clientrm/RouterYarnClientUtils.java     |  575 ---
 .../yarn/server/router/clientrm/package-info.java  |   20 
 .../hadoop/yarn/server/router/package-info.java    |   20 
 .../rmadmin/AbstractRMAdminRequestInterceptor.java |   96 -
 .../rmadmin/DefaultRMAdminRequestInterceptor.java  |  261 --
 .../rmadmin/FederationRMAdminInterceptor.java      | 1574 ---------
 .../router/rmadmin/RMAdminProtocolMethod.java      |  186 -
 .../router/rmadmin/RMAdminRequestInterceptor.java  |   65 
 .../router/rmadmin/RouterRMAdminService.java       |  449 ---
 .../yarn/server/router/rmadmin/package-info.java   |   20 
 .../RouterDelegationTokenSecretManager.java        |  375 --
 .../security/authorize/RouterPolicyProvider.java   |   66 
 .../router/security/authorize/package-info.java    |   22 
 .../yarn/server/router/security/package-info.java  |   19 
 .../yarn/server/router/webapp/AboutBlock.java      |   86 
 .../yarn/server/router/webapp/AboutPage.java       |   37 
 .../webapp/AbstractRESTRequestInterceptor.java     |  109 -
 .../yarn/server/router/webapp/AppsBlock.java       |  215 -
 .../hadoop/yarn/server/router/webapp/AppsPage.java |   84 
 .../webapp/DefaultRequestInterceptorREST.java      |  620 ----
 .../yarn/server/router/webapp/FederationBlock.java |  268 --
 .../router/webapp/FederationInterceptorREST.java   | 3472 --------------------
 .../yarn/server/router/webapp/FederationPage.java  |   60 
 .../yarn/server/router/webapp/HTTPMethods.java     |   34 
 .../server/router/webapp/MetricsOverviewTable.java |  360 --
 .../hadoop/yarn/server/router/webapp/NavBlock.java |   74 
 .../yarn/server/router/webapp/NodeLabelsBlock.java |  178 -
 .../yarn/server/router/webapp/NodeLabelsPage.java  |   56 
 .../yarn/server/router/webapp/NodesBlock.java      |  206 -
 .../yarn/server/router/webapp/NodesPage.java       |   65 
 .../router/webapp/RESTRequestInterceptor.java      |  140 -
 .../yarn/server/router/webapp/RouterBlock.java     |  357 --
 .../server/router/webapp/RouterController.java     |   64 
 .../yarn/server/router/webapp/RouterView.java      |   52 
 .../yarn/server/router/webapp/RouterWebApp.java    |   57 
 .../server/router/webapp/RouterWebServiceUtil.java |  776 ----
 .../server/router/webapp/RouterWebServices.java    |  964 ------
 .../router/webapp/cache/RouterAppInfoCacheKey.java |  156 -
 .../server/router/webapp/cache/package-info.java   |   18 
 .../webapp/dao/FederationBulkActivitiesInfo.java   |   49 
 .../router/webapp/dao/FederationClusterInfo.java   |   50 
 .../webapp/dao/FederationClusterUserInfo.java      |   49 
 .../router/webapp/dao/FederationConfInfo.java      |   55 
 .../webapp/dao/FederationRMQueueAclInfo.java       |   50 
 .../webapp/dao/FederationSchedulerTypeInfo.java    |   49 
 .../router/webapp/dao/RouterClusterMetrics.java    |  323 --
 .../yarn/server/router/webapp/dao/RouterInfo.java  |  104 -
 .../router/webapp/dao/RouterSchedulerMetrics.java  |  120 -
 .../server/router/webapp/dao/SubClusterResult.java |   59 
 .../server/router/webapp/dao/package-info.java     |   20 
 .../yarn/server/router/webapp/package-info.java    |   20 
 .../hadoop/yarn/server/router/TestRouter.java      |  407 --
 .../yarn/server/router/TestRouterAuditLogger.java  |  253 -
 .../yarn/server/router/TestRouterMetrics.java      | 2382 --------------
 .../yarn/server/router/TestRouterServerUtil.java   |  164 -
 .../server/router/TestRouterStoreCommands.java     |   77 
 .../router/cleaner/TestSubClusterCleaner.java      |  158 -
 .../router/clientrm/BaseRouterClientRMTest.java    |  609 ----
 .../clientrm/MockClientRequestInterceptor.java     |   80 
 .../PassThroughClientRequestInterceptor.java       |  316 --
 ...estApplicationSubmissionContextInterceptor.java |  160 -
 .../clientrm/TestFederationClientInterceptor.java  | 1731 ----------
 .../TestFederationClientInterceptorRetry.java      |  431 --
 .../router/clientrm/TestRouterClientRMService.java |  270 --
 .../router/clientrm/TestRouterYarnClientUtils.java |  768 ----
 .../TestSequentialBroadcastPolicyManager.java      |   54 
 .../clientrm/TestSequentialRouterPolicy.java       |   78 
 .../TestableFederationClientInterceptor.java       |  257 -
 .../router/rmadmin/BaseRouterRMAdminTest.java      |  318 --
 .../rmadmin/MockRMAdminRequestInterceptor.java     |   72 
 .../PassThroughRMAdminRequestInterceptor.java      |  212 -
 .../rmadmin/TestFederationRMAdminInterceptor.java  | 1092 ------
 .../router/rmadmin/TestRouterRMAdminService.java   |  278 --
 .../TestableFederationRMAdminInterceptor.java      |  105 -
 .../router/secure/AbstractSecureRouterTest.java    |  249 -
 .../TestRouterDelegationTokenSecretManager.java    |  201 -
 .../server/router/secure/TestSecureLogins.java     |  156 -
 .../subcluster/TestFederationSubCluster.java       |  345 --
 .../server/router/subcluster/TestMockRouter.java   |   93 -
 .../router/subcluster/TestMockSubCluster.java      |  100 -
 .../TestYarnFederationWithCapacityScheduler.java   |  615 ----
 .../fair/TestYarnFederationWithFairScheduler.java  |  639 ----
 .../router/webapp/BaseRouterWebServicesTest.java   |  419 --
 .../yarn/server/router/webapp/JavaProcess.java     |   86 
 .../webapp/MockDefaultRequestInterceptorREST.java  | 1406 --------
 .../router/webapp/MockRESTRequestInterceptor.java  |  394 --
 .../yarn/server/router/webapp/MockRouter.java      |   99 -
 .../webapp/PassThroughRESTRequestInterceptor.java  |  401 --
 .../webapp/TestFederationInterceptorREST.java      | 2267 -------------
 .../webapp/TestFederationInterceptorRESTRetry.java |  581 ---
 .../server/router/webapp/TestFederationWebApp.java |  135 -
 .../router/webapp/TestRouterWebAppProxy.java       |  298 --
 .../router/webapp/TestRouterWebServiceUtil.java    |  775 ----
 .../router/webapp/TestRouterWebServices.java       |  340 --
 .../router/webapp/TestRouterWebServicesREST.java   | 1477 ---------
 .../webapp/TestableFederationInterceptorREST.java  |  124 -
 .../src/test/resources/capability                  |   21 
 .../src/test/resources/capacity-scheduler.xml      |  156 -
 .../src/test/resources/fair-scheduler.xml          |   43 
 .../src/test/resources/log4j.properties            |   19 
 .../test/resources/profiles/sample-profiles-1.json |   24 
 .../src/test/resources/yarn-site.xml               |   54 
 .../hadoop-yarn/hadoop-yarn-server/pom.xml         |    1 
 hadoop-yarn-project/pom.xml                        |    4 
 122 files changed, 43540 deletions(-)
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/pom.xml
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/security/token/delegation/RouterDelegationTokenSupport.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/security/token/delegation/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/Router.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/RouterAuditLogger.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/RouterMetrics.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/RouterServerUtil.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/cleaner/SubClusterCleaner.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/cleaner/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/AbstractClientRequestInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/ApplicationSubmissionContextInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/ClientMethod.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/ClientRequestInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/DefaultClientRequestInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/FederationClientInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/PassThroughClientRequestInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/RouterClientRMService.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/RouterYarnClientUtils.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/AbstractRMAdminRequestInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/DefaultRMAdminRequestInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/FederationRMAdminInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/RMAdminProtocolMethod.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/RMAdminRequestInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/RouterRMAdminService.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/security/RouterDelegationTokenSecretManager.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/security/authorize/RouterPolicyProvider.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/security/authorize/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/security/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AboutBlock.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AboutPage.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AbstractRESTRequestInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AppsBlock.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AppsPage.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/DefaultRequestInterceptorREST.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/FederationBlock.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/FederationInterceptorREST.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/FederationPage.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/HTTPMethods.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/MetricsOverviewTable.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NavBlock.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NodeLabelsBlock.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NodeLabelsPage.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NodesBlock.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NodesPage.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RESTRequestInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterBlock.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterController.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterView.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterWebApp.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterWebServiceUtil.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterWebServices.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/cache/RouterAppInfoCacheKey.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/cache/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationBulkActivitiesInfo.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationClusterInfo.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationClusterUserInfo.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationConfInfo.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationRMQueueAclInfo.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationSchedulerTypeInfo.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/RouterClusterMetrics.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/RouterInfo.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/RouterSchedulerMetrics.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/SubClusterResult.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/package-info.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouter.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouterAuditLogger.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouterMetrics.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouterServerUtil.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouterStoreCommands.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/cleaner/TestSubClusterCleaner.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/BaseRouterClientRMTest.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/MockClientRequestInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/PassThroughClientRequestInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestApplicationSubmissionContextInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestFederationClientInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestFederationClientInterceptorRetry.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestRouterClientRMService.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestRouterYarnClientUtils.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestSequentialBroadcastPolicyManager.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestSequentialRouterPolicy.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestableFederationClientInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/BaseRouterRMAdminTest.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/MockRMAdminRequestInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/PassThroughRMAdminRequestInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/TestFederationRMAdminInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/TestRouterRMAdminService.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/TestableFederationRMAdminInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/secure/AbstractSecureRouterTest.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/secure/TestRouterDelegationTokenSecretManager.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/secure/TestSecureLogins.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/TestFederationSubCluster.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/TestMockRouter.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/TestMockSubCluster.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/capacity/TestYarnFederationWithCapacityScheduler.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/fair/TestYarnFederationWithFairScheduler.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/BaseRouterWebServicesTest.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/JavaProcess.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/MockDefaultRequestInterceptorREST.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/MockRESTRequestInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/MockRouter.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/PassThroughRESTRequestInterceptor.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestFederationInterceptorREST.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestFederationInterceptorRESTRetry.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestFederationWebApp.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestRouterWebAppProxy.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestRouterWebServiceUtil.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestRouterWebServices.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestRouterWebServicesREST.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestableFederationInterceptorREST.java
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/capability
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/capacity-scheduler.xml
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/fair-scheduler.xml
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/log4j.properties
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/profiles/sample-profiles-1.json
 delete mode 100644 hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/yarn-site.xml

diff --git a/hadoop-project/pom.xml b/hadoop-project/pom.xml
index 460cbf132e2..d365a5c70da 100644
--- a/hadoop-project/pom.xml
+++ b/hadoop-project/pom.xml
@@ -568,12 +568,6 @@
         <version>${hadoop.version}</version>
       </dependency>
 
-      <dependency>
-        <groupId>org.apache.hadoop</groupId>
-        <artifactId>hadoop-yarn-server-router</artifactId>
-        <version>${hadoop.version}</version>
-      </dependency>
-
       <dependency>
         <groupId>org.apache.hadoop</groupId>
         <artifactId>hadoop-yarn-server-globalpolicygenerator</artifactId>
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/pom.xml b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/pom.xml
deleted file mode 100644
index 88c58a8d9fb..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/pom.xml
+++ /dev/null
@@ -1,182 +0,0 @@
-<?xml version="1.0"?>
-<!--
-  Licensed under the Apache License, Version 2.0 (the "License");
-  you may not use this file except in compliance with the License.
-  You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License. See accompanying LICENSE file.
--->
-<project xmlns="http://maven.apache.org/POM/4.0.0"
-  xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
-  xsi:schemaLocation="http://maven.apache.org/POM/4.0.0
-                      https://maven.apache.org/xsd/maven-4.0.0.xsd">
-  <parent>
-    <artifactId>hadoop-yarn-server</artifactId>
-    <groupId>org.apache.hadoop</groupId>
-    <version>3.4.0</version>
-  </parent>
-  <modelVersion>4.0.0</modelVersion>
-  <groupId>org.apache.hadoop</groupId>
-  <artifactId>hadoop-yarn-server-router</artifactId>
-  <version>3.4.0</version>
-  <name>Apache Hadoop YARN Router</name>
-
-  <properties>
-    <!-- Needed for generating FindBugs warnings using parent pom -->
-    <yarn.basedir>${project.parent.parent.basedir}</yarn.basedir>
-  </properties>
-
-  <dependencies>
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-api</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-common</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-common</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-common</artifactId>
-      <type>test-jar</type>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-server-common</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-server-common</artifactId>
-      <type>test-jar</type>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-server-resourcemanager</artifactId>
-      <type>test-jar</type>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.junit.jupiter</groupId>
-      <artifactId>junit-jupiter-api</artifactId>
-      <scope>test</scope>
-    </dependency>
-    <dependency>
-      <groupId>org.junit.jupiter</groupId>
-      <artifactId>junit-jupiter-engine</artifactId>
-      <scope>test</scope>
-    </dependency>
-    <dependency>
-      <groupId>org.junit.jupiter</groupId>
-      <artifactId>junit-jupiter-params</artifactId>
-      <scope>test</scope>
-    </dependency>
-    <dependency>
-      <groupId>org.junit.platform</groupId>
-      <artifactId>junit-platform-launcher</artifactId>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>junit</groupId>
-      <artifactId>junit</artifactId>
-      <scope>test</scope>
-    </dependency>
-
-    <!-- 'mvn dependency:analyze' fails to detect use of this dependency -->
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-common</artifactId>
-      <type>test-jar</type>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-server-resourcemanager</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-server-nodemanager</artifactId>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-server-timelineservice</artifactId>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.mockito</groupId>
-      <artifactId>mockito-core</artifactId>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>com.google.inject</groupId>
-      <artifactId>guice</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-minikdc</artifactId>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-auth</artifactId>
-      <scope>test</scope>
-      <type>test-jar</type>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.curator</groupId>
-      <artifactId>curator-client</artifactId>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.curator</groupId>
-      <artifactId>curator-test</artifactId>
-      <scope>test</scope>
-    </dependency>
-
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-server-tests</artifactId>
-      <scope>test</scope>
-      <type>test-jar</type>
-    </dependency>
-
-  </dependencies>
-
-  <build>
-    <plugins>
-      <plugin>
-        <groupId>org.apache.rat</groupId>
-        <artifactId>apache-rat-plugin</artifactId>
-      </plugin>
-    </plugins>
-  </build>
-
-</project>
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/security/token/delegation/RouterDelegationTokenSupport.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/security/token/delegation/RouterDelegationTokenSupport.java
deleted file mode 100644
index d530f751cb2..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/security/token/delegation/RouterDelegationTokenSupport.java
+++ /dev/null
@@ -1,65 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.security.token.delegation;
-
-import org.apache.hadoop.io.WritableUtils;
-import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager.DelegationTokenInformation;
-
-import java.io.ByteArrayInputStream;
-import java.io.ByteArrayOutputStream;
-import java.io.DataInputStream;
-import java.io.DataOutputStream;
-import java.io.IOException;
-import java.util.Base64;
-
-/**
- * Workaround for serialization of {@link DelegationTokenInformation} through package access.
- * Future version of Hadoop should add this to DelegationTokenInformation itself.
- */
-public final class RouterDelegationTokenSupport {
-
-  private RouterDelegationTokenSupport() {
-  }
-
-  public static String encodeDelegationTokenInformation(DelegationTokenInformation token) {
-    try {
-      ByteArrayOutputStream bos = new ByteArrayOutputStream();
-      DataOutputStream out = new DataOutputStream(bos);
-      WritableUtils.writeVInt(out, token.password.length);
-      out.write(token.password);
-      out.writeLong(token.renewDate);
-      out.flush();
-      byte[] tokenInfoBytes = bos.toByteArray();
-      return Base64.getUrlEncoder().encodeToString(tokenInfoBytes);
-    } catch (IOException ex) {
-      throw new RuntimeException("Failed to encode token.", ex);
-    }
-  }
-
-  public static DelegationTokenInformation decodeDelegationTokenInformation(byte[] tokenBytes)
-      throws IOException {
-    DataInputStream in = new DataInputStream(new ByteArrayInputStream(tokenBytes));
-    DelegationTokenInformation token = new DelegationTokenInformation(0, null);
-    int len = WritableUtils.readVInt(in);
-    token.password = new byte[len];
-    in.readFully(token.password);
-    token.renewDate = in.readLong();
-    return token;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/security/token/delegation/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/security/token/delegation/package-info.java
deleted file mode 100644
index 3a1cb3e69ae..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/security/token/delegation/package-info.java
+++ /dev/null
@@ -1,20 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/** Router security token delegation. **/
-package org.apache.hadoop.security.token.delegation;
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/Router.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/Router.java
deleted file mode 100644
index bb7bfd55413..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/Router.java
+++ /dev/null
@@ -1,443 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router;
-
-import java.io.IOException;
-import java.io.PrintStream;
-import java.net.InetAddress;
-import java.net.URL;
-import java.net.InetSocketAddress;
-import java.net.UnknownHostException;
-import java.util.concurrent.ScheduledThreadPoolExecutor;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.atomic.AtomicBoolean;
-
-import org.apache.commons.cli.CommandLine;
-import org.apache.commons.cli.DefaultParser;
-import org.apache.commons.cli.Option;
-import org.apache.commons.cli.Options;
-import org.apache.commons.cli.ParseException;
-import org.apache.commons.cli.MissingArgumentException;
-import org.apache.commons.lang.time.DurationFormatUtils;
-import org.apache.hadoop.classification.InterfaceAudience.Private;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.metrics2.lib.DefaultMetricsSystem;
-import org.apache.hadoop.metrics2.source.JvmMetrics;
-import org.apache.hadoop.security.HttpCrossOriginFilterInitializer;
-import org.apache.hadoop.security.SecurityUtil;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.service.CompositeService;
-import org.apache.hadoop.util.JvmPauseMonitor;
-import org.apache.hadoop.util.ShutdownHookManager;
-import org.apache.hadoop.util.StringUtils;
-import org.apache.hadoop.util.VersionInfo;
-import org.apache.hadoop.util.GenericOptionsParser;
-import org.apache.hadoop.yarn.YarnUncaughtExceptionHandler;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebAppUtil;
-import org.apache.hadoop.yarn.server.router.cleaner.SubClusterCleaner;
-import org.apache.hadoop.yarn.server.router.clientrm.RouterClientRMService;
-import org.apache.hadoop.yarn.server.router.rmadmin.RouterRMAdminService;
-import org.apache.hadoop.yarn.server.router.webapp.RouterWebApp;
-import org.apache.hadoop.yarn.server.webproxy.FedAppReportFetcher;
-import org.apache.hadoop.yarn.server.webproxy.ProxyUriUtils;
-import org.apache.hadoop.yarn.server.webproxy.WebAppProxy;
-import org.apache.hadoop.yarn.server.webproxy.WebAppProxyServlet;
-import org.apache.hadoop.yarn.webapp.WebApp;
-import org.apache.hadoop.yarn.webapp.WebApps;
-import org.apache.hadoop.yarn.webapp.WebApps.Builder;
-import org.apache.hadoop.yarn.webapp.util.WebAppUtils;
-import org.apache.hadoop.yarn.webapp.util.WebServiceClient;
-import org.eclipse.jetty.webapp.WebAppContext;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import org.apache.hadoop.classification.VisibleForTesting;
-
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.DEFAULT_ROUTER_DEREGISTER_SUBCLUSTER_ENABLED;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.ROUTER_DEREGISTER_SUBCLUSTER_ENABLED;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.ROUTER_SUBCLUSTER_CLEANER_INTERVAL_TIME;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.DEFAULT_ROUTER_SUBCLUSTER_CLEANER_INTERVAL_TIME;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.ROUTER_SCHEDULED_EXECUTOR_THREADS;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.DEFAULT_ROUTER_SCHEDULED_EXECUTOR_THREADS;
-
-/**
- * The router is a stateless YARN component which is the entry point to the
- * cluster. It can be deployed on multiple nodes behind a Virtual IP (VIP) with
- * a LoadBalancer.
- *
- * The Router exposes the ApplicationClientProtocol (RPC and REST) to the
- * outside world, transparently hiding the presence of ResourceManager(s), which
- * allows users to request and update reservations, submit and kill
- * applications, and request status on running applications.
- *
- * In addition, it exposes the ResourceManager Admin API.
- *
- * This provides a placeholder for throttling mis-behaving clients (YARN-1546)
- * and masks the access to multiple RMs (YARN-3659).
- */
-public class Router extends CompositeService {
-
-  private static final Logger LOG = LoggerFactory.getLogger(Router.class);
-  private static CompositeServiceShutdownHook routerShutdownHook;
-  private Configuration conf;
-  private AtomicBoolean isStopping = new AtomicBoolean(false);
-  private JvmPauseMonitor pauseMonitor;
-  @VisibleForTesting
-  protected RouterClientRMService clientRMProxyService;
-  @VisibleForTesting
-  protected RouterRMAdminService rmAdminProxyService;
-  private WebApp webApp;
-  @VisibleForTesting
-  protected String webAppAddress;
-  private static long clusterTimeStamp = System.currentTimeMillis();
-  private FedAppReportFetcher fetcher = null;
-  private static final String CMD_FORMAT_STATE_STORE = "-format-state-store";
-  private static final String CMD_REMOVE_APPLICATION_FROM_STATE_STORE =
-      "-remove-application-from-state-store";
-
-  /**
-   * Priority of the Router shutdown hook.
-   */
-  public static final int SHUTDOWN_HOOK_PRIORITY = 30;
-
-  private static final String METRICS_NAME = "Router";
-
-  private static final String UI2_WEBAPP_NAME = "/ui2";
-
-  private ScheduledThreadPoolExecutor scheduledExecutorService;
-  private SubClusterCleaner subClusterCleaner;
-
-  public Router() {
-    super(Router.class.getName());
-  }
-
-  protected void doSecureLogin() throws IOException {
-    SecurityUtil.login(this.conf, YarnConfiguration.ROUTER_KEYTAB,
-        YarnConfiguration.ROUTER_PRINCIPAL, getHostName(this.conf));
-  }
-
-  @Override
-  protected void serviceInit(Configuration config) throws Exception {
-    this.conf = config;
-    UserGroupInformation.setConfiguration(this.conf);
-    // ClientRM Proxy
-    clientRMProxyService = createClientRMProxyService();
-    addService(clientRMProxyService);
-    // RMAdmin Proxy
-    rmAdminProxyService = createRMAdminProxyService();
-    addService(rmAdminProxyService);
-    // WebService
-    webAppAddress = WebAppUtils.getWebAppBindURL(this.conf,
-        YarnConfiguration.ROUTER_BIND_HOST,
-        WebAppUtils.getRouterWebAppURLWithoutScheme(this.conf));
-    // Metrics
-    DefaultMetricsSystem.initialize(METRICS_NAME);
-    JvmMetrics jm = JvmMetrics.initSingleton("Router", null);
-    pauseMonitor = new JvmPauseMonitor();
-    addService(pauseMonitor);
-    jm.setPauseMonitor(pauseMonitor);
-
-    // Initialize subClusterCleaner
-    this.subClusterCleaner = new SubClusterCleaner(this.conf);
-    int scheduledExecutorThreads = conf.getInt(ROUTER_SCHEDULED_EXECUTOR_THREADS,
-        DEFAULT_ROUTER_SCHEDULED_EXECUTOR_THREADS);
-    this.scheduledExecutorService = new ScheduledThreadPoolExecutor(scheduledExecutorThreads);
-
-    WebServiceClient.initialize(config);
-    super.serviceInit(conf);
-  }
-
-  @Override
-  protected void serviceStart() throws Exception {
-    try {
-      doSecureLogin();
-    } catch (IOException e) {
-      throw new YarnRuntimeException("Failed Router login", e);
-    }
-    boolean isDeregisterSubClusterEnabled = this.conf.getBoolean(
-        ROUTER_DEREGISTER_SUBCLUSTER_ENABLED, DEFAULT_ROUTER_DEREGISTER_SUBCLUSTER_ENABLED);
-    if (isDeregisterSubClusterEnabled) {
-      long scCleanerIntervalMs = this.conf.getTimeDuration(ROUTER_SUBCLUSTER_CLEANER_INTERVAL_TIME,
-          DEFAULT_ROUTER_SUBCLUSTER_CLEANER_INTERVAL_TIME, TimeUnit.MILLISECONDS);
-      this.scheduledExecutorService.scheduleAtFixedRate(this.subClusterCleaner,
-          0, scCleanerIntervalMs, TimeUnit.MILLISECONDS);
-      LOG.info("Scheduled SubClusterCleaner With Interval: {}.",
-          DurationFormatUtils.formatDurationISO(scCleanerIntervalMs));
-    }
-    startWepApp();
-    super.serviceStart();
-  }
-
-  @Override
-  protected void serviceStop() throws Exception {
-    if (webApp != null) {
-      webApp.stop();
-    }
-    if (isStopping.getAndSet(true)) {
-      return;
-    }
-    super.serviceStop();
-    DefaultMetricsSystem.shutdown();
-    WebServiceClient.destroy();
-  }
-
-  protected void shutDown() {
-    new Thread(Router.this::stop).start();
-  }
-
-  protected RouterClientRMService createClientRMProxyService() {
-    return new RouterClientRMService();
-  }
-
-  protected RouterRMAdminService createRMAdminProxyService() {
-    return new RouterRMAdminService();
-  }
-
-  @Private
-  public WebApp getWebapp() {
-    return this.webApp;
-  }
-
-  @VisibleForTesting
-  public void startWepApp() {
-
-    // Initialize RouterWeb's CrossOrigin capability.
-    boolean enableCors = conf.getBoolean(YarnConfiguration.ROUTER_WEBAPP_ENABLE_CORS_FILTER,
-        YarnConfiguration.DEFAULT_ROUTER_WEBAPP_ENABLE_CORS_FILTER);
-    if (enableCors) {
-      conf.setBoolean(HttpCrossOriginFilterInitializer.PREFIX
-          + HttpCrossOriginFilterInitializer.ENABLED_SUFFIX, true);
-    }
-
-    LOG.info("Instantiating RouterWebApp at {}.", webAppAddress);
-
-    RMWebAppUtil.setupSecurityAndFilters(conf, null);
-
-    Builder<Object> builder =
-        WebApps.$for("cluster", null, null, "ws").with(conf).at(webAppAddress);
-    if (RouterServerUtil.isRouterWebProxyEnable(conf)) {
-      fetcher = new FedAppReportFetcher(conf);
-      builder.withServlet(ProxyUriUtils.PROXY_SERVLET_NAME, ProxyUriUtils.PROXY_PATH_SPEC,
-          WebAppProxyServlet.class);
-      builder.withAttribute(WebAppProxy.FETCHER_ATTRIBUTE, fetcher);
-      String proxyHostAndPort = getProxyHostAndPort(conf);
-      String[] proxyParts = proxyHostAndPort.split(":");
-      builder.withAttribute(WebAppProxy.PROXY_HOST_ATTRIBUTE, proxyParts[0]);
-    }
-    webApp = builder.start(new RouterWebApp(this), getUIWebAppContext());
-  }
-
-  private WebAppContext getUIWebAppContext() {
-    WebAppContext uiWebAppContext = null;
-    boolean isWebUI2Enabled = conf.getBoolean(YarnConfiguration.YARN_WEBAPP_UI2_ENABLE,
-        YarnConfiguration.DEFAULT_YARN_WEBAPP_UI2_ENABLE);
-
-    if(isWebUI2Enabled) {
-      String onDiskPath = conf.get(YarnConfiguration.YARN_WEBAPP_UI2_WARFILE_PATH);
-      uiWebAppContext = new WebAppContext();
-      uiWebAppContext.setContextPath(UI2_WEBAPP_NAME);
-
-      if (null == onDiskPath) {
-        String war = "hadoop-yarn-ui-" + VersionInfo.getVersion() + ".war";
-        URL url = getClass().getClassLoader().getResource(war);
-        if (null == url) {
-          onDiskPath = getWebAppsPath("ui2");
-        } else {
-          onDiskPath = url.getFile();
-        }
-      }
-
-      if (onDiskPath == null || onDiskPath.isEmpty()) {
-        LOG.error("No war file or webapps found for yarn federation!");
-      } else {
-        if (onDiskPath.endsWith(".war")) {
-          uiWebAppContext.setWar(onDiskPath);
-          LOG.info("Using war file at: {}.", onDiskPath);
-        } else {
-          uiWebAppContext.setResourceBase(onDiskPath);
-          LOG.info("Using webapps at: {}.", onDiskPath);
-        }
-      }
-    }
-    return uiWebAppContext;
-  }
-
-  private String getWebAppsPath(String appName) {
-    URL url = getClass().getClassLoader().getResource("webapps/" + appName);
-    if (url == null) {
-      return "";
-    }
-    return url.toString();
-  }
-
-  public static String getProxyHostAndPort(Configuration conf) {
-    String addr = conf.get(YarnConfiguration.PROXY_ADDRESS);
-    if(addr == null || addr.isEmpty()) {
-      InetSocketAddress address = conf.getSocketAddr(YarnConfiguration.ROUTER_WEBAPP_ADDRESS,
-          YarnConfiguration.DEFAULT_ROUTER_WEBAPP_ADDRESS,
-          YarnConfiguration.DEFAULT_ROUTER_WEBAPP_PORT);
-      addr = WebAppUtils.getResolvedAddress(address);
-    }
-    return addr;
-  }
-
-  public static void main(String[] argv) {
-    Configuration conf = new YarnConfiguration();
-    Thread.setDefaultUncaughtExceptionHandler(new YarnUncaughtExceptionHandler());
-    StringUtils.startupShutdownMessage(Router.class, argv, LOG);
-    Router router = new Router();
-    try {
-      GenericOptionsParser hParser = new GenericOptionsParser(conf, argv);
-      argv = hParser.getRemainingArgs();
-      if (argv.length > 1) {
-        executeRouterCommand(conf, argv);
-      } else {
-        // Remove the old hook if we are rebooting.
-        if (null != routerShutdownHook) {
-          ShutdownHookManager.get().removeShutdownHook(routerShutdownHook);
-        }
-        routerShutdownHook = new CompositeServiceShutdownHook(router);
-        ShutdownHookManager.get().addShutdownHook(routerShutdownHook, SHUTDOWN_HOOK_PRIORITY);
-        router.init(conf);
-        router.start();
-      }
-    } catch (Throwable t) {
-      LOG.error("Error starting Router", t);
-      System.exit(-1);
-    }
-  }
-
-  @VisibleForTesting
-  public RouterClientRMService getClientRMProxyService() {
-    return clientRMProxyService;
-  }
-
-  @VisibleForTesting
-  public RouterRMAdminService getRmAdminProxyService() {
-    return rmAdminProxyService;
-  }
-
-  /**
-   * Returns the hostname for this Router. If the hostname is not
-   * explicitly configured in the given config, then it is determined.
-   *
-   * @param config configuration
-   * @return the hostname (NB: may not be a FQDN)
-   * @throws UnknownHostException if the hostname cannot be determined
-   */
-  private String getHostName(Configuration config)
-      throws UnknownHostException {
-    String name = config.get(YarnConfiguration.ROUTER_KERBEROS_PRINCIPAL_HOSTNAME_KEY);
-    if (name == null) {
-      name = InetAddress.getLocalHost().getHostName();
-    }
-    return name;
-  }
-
-  public static long getClusterTimeStamp() {
-    return clusterTimeStamp;
-  }
-
-  @VisibleForTesting
-  public FedAppReportFetcher getFetcher() {
-    return fetcher;
-  }
-
-  @VisibleForTesting
-  public static void removeApplication(Configuration conf, String applicationId)
-      throws Exception {
-    FederationStateStoreFacade facade = FederationStateStoreFacade.getInstance(conf);
-    ApplicationId removeAppId = ApplicationId.fromString(applicationId);
-    LOG.info("Deleting application {} from state store.", removeAppId);
-    facade.deleteApplicationHomeSubCluster(removeAppId);
-    LOG.info("Application is deleted from state store");
-  }
-
-  private static void handFormatStateStore(Configuration conf) {
-    try {
-      System.out.println("Deleting Federation state store.");
-      FederationStateStoreFacade facade = FederationStateStoreFacade.getInstance(conf);
-      System.out.println("Federation state store has been cleaned.");
-      facade.deleteStore();
-    } catch (Exception e) {
-      System.err.println("Delete Federation state store error, exception = " + e);
-    }
-  }
-
-  private static void handRemoveApplicationFromStateStore(Configuration conf,
-      String applicationId) {
-    try {
-      removeApplication(conf, applicationId);
-      System.out.println("Application " + applicationId + " is deleted from state store");
-    } catch (Exception e) {
-      System.err.println("Application " + applicationId + " error, exception = " + e);
-    }
-  }
-
-  private static void executeRouterCommand(Configuration conf, String[] args) {
-    // Step1. Define Options.
-    Options opts = new Options();
-    Option formatStateStoreOpt = new Option("format-state-store",  false,
-        " Formats the FederationStateStore. " +
-        "This will clear the FederationStateStore and " +
-        "is useful if past applications are no longer needed. " +
-        "This should be run only when the Router is not running.");
-    Option removeApplicationFromStateStoreOpt = new Option("remove-application-from-state-store",
-        false, " Remove the application from FederationStateStore. " +
-         " This should be run only when the Router is not running. ");
-    opts.addOption(formatStateStoreOpt);
-    opts.addOption(removeApplicationFromStateStoreOpt);
-
-    // Step2. Parse Options.
-    try {
-      String cmd = args[0];
-
-      CommandLine cliParser = new DefaultParser().parse(opts, args);
-
-      if (CMD_FORMAT_STATE_STORE.equals(cmd)) {
-        handFormatStateStore(conf);
-      } else if (CMD_REMOVE_APPLICATION_FROM_STATE_STORE.equals(cmd)) {
-        if (cliParser.hasOption(removeApplicationFromStateStoreOpt)) {
-          String applicationId = cliParser.getOptionValue(removeApplicationFromStateStoreOpt);
-          handRemoveApplicationFromStateStore(conf, applicationId);
-        } else {
-          System.err.println("remove-application-from-state-store requires application arg.");
-        }
-      } else {
-        System.out.println("No related commands found.");
-        printUsage(System.err);
-      }
-    } catch (MissingArgumentException ex) {
-      System.out.println("Missing argument for options.");
-      printUsage(System.err);
-    } catch (ParseException e) {
-      System.out.println("Parsing of a command-line error.");
-      printUsage(System.err);
-    }
-  }
-
-  private static void printUsage(PrintStream out) {
-    out.println("Usage: yarn router [-format-state-store] | " +
-        "[-remove-application-from-state-store <appId>]");
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/RouterAuditLogger.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/RouterAuditLogger.java
deleted file mode 100644
index b0902a5e5c1..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/RouterAuditLogger.java
+++ /dev/null
@@ -1,365 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router;
-
-import org.apache.hadoop.ipc.Server;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.net.InetAddress;
-
-/**
- * Manages Router audit logs.
- * Audit log format is written as key=value pairs. Tab separated.
- */
-public final class RouterAuditLogger {
-  private static final Logger LOG =
-      LoggerFactory.getLogger(RouterAuditLogger.class);
-
-  private RouterAuditLogger() {
-  }
-
-  enum Keys {USER, OPERATION, TARGET, RESULT, IP, PERMISSIONS, DESCRIPTION, APPID, SUBCLUSTERID}
-
-  public static class AuditConstants {
-    static final String SUCCESS = "SUCCESS";
-    static final String FAILURE = "FAILURE";
-    static final String KEY_VAL_SEPARATOR = "=";
-    static final char PAIR_SEPARATOR = '\t';
-
-    public static final String GET_NEW_APP = "Get New App";
-    public static final String SUBMIT_NEW_APP = "Submit New App";
-    public static final String FORCE_KILL_APP = "Force Kill App";
-    public static final String GET_APP_REPORT = "Get Application Report";
-    public static final String TARGET_CLIENT_RM_SERVICE = "RouterClientRMService";
-    public static final String TARGET_WEB_SERVICE = "RouterWebServices";
-    public static final String UNKNOWN = "UNKNOWN";
-    public static final String GET_APPLICATIONS = "Get Applications";
-    public static final String GET_CLUSTERMETRICS = "Get ClusterMetrics";
-    public static final String GET_CLUSTERNODES = "Get ClusterNodes";
-    public static final String GET_QUEUEINFO = "Get QueueInfo";
-    public static final String GET_QUEUE_USER_ACLS = "Get QueueUserAcls";
-    public static final String MOVE_APPLICATION_ACROSS_QUEUES = "Move ApplicationAcrossQueues";
-    public static final String GET_NEW_RESERVATION = "Get NewReservation";
-    public static final String SUBMIT_RESERVATION = "Submit Reservation";
-    public static final String LIST_RESERVATIONS = "List Reservations";
-    public static final String UPDATE_RESERVATION = "Update Reservation";
-    public static final String DELETE_RESERVATION = "Delete Reservation";
-    public static final String GET_NODETOLABELS = "Get NodeToLabels";
-    public static final String GET_LABELSTONODES = "Get LabelsToNodes";
-    public static final String GET_CLUSTERNODELABELS = "Get ClusterNodeLabels";
-    public static final String GET_APPLICATION_ATTEMPT_REPORT = "Get ApplicationAttemptReport";
-    public static final String GET_APPLICATION_ATTEMPTS = "Get ApplicationAttempts";
-    public static final String GET_CONTAINERREPORT = "Get ContainerReport";
-    public static final String GET_CONTAINERS = "Get Containers";
-    public static final String GET_DELEGATIONTOKEN = "Get DelegationToken";
-    public static final String RENEW_DELEGATIONTOKEN = "Renew DelegationToken";
-    public static final String CANCEL_DELEGATIONTOKEN = "Cancel DelegationToken";
-    public static final String FAIL_APPLICATIONATTEMPT = "Fail ApplicationAttempt";
-    public static final String UPDATE_APPLICATIONPRIORITY = "Update ApplicationPriority";
-    public static final String SIGNAL_TOCONTAINER = "Signal ToContainer";
-    public static final String UPDATE_APPLICATIONTIMEOUTS = "Update ApplicationTimeouts";
-    public static final String GET_RESOURCEPROFILES = "Get ResourceProfiles";
-    public static final String GET_RESOURCEPROFILE = "Get ResourceProfile";
-    public static final String GET_RESOURCETYPEINFO = "Get ResourceTypeInfo";
-    public static final String GET_ATTRIBUTESTONODES = "Get AttributesToNodes";
-    public static final String GET_CLUSTERNODEATTRIBUTES = "Get ClusterNodeAttributes";
-    public static final String GET_NODESTOATTRIBUTES = "Get NodesToAttributes";
-    public static final String GET_CLUSTERINFO = "Get ClusterInfo";
-    public static final String GET_CLUSTERUSERINFO = "Get ClusterUserInfo";
-    public static final String GET_SCHEDULERINFO = "Get SchedulerInfo";
-    public static final String DUMP_SCHEDULERLOGS = "Dump SchedulerLogs";
-    public static final String GET_ACTIVITIES = "Get Activities";
-    public static final String GET_BULKACTIVITIES = "Get BulkActivities";
-    public static final String GET_APPACTIVITIES = "Get AppActivities";
-    public static final String GET_APPSTATISTICS = "Get AppStatistics";
-    public static final String GET_RMNODELABELS = "Get RMNodeLabels";
-    public static final String REPLACE_LABELSONNODES = "Replace LabelsOnNodes";
-    public static final String REPLACE_LABELSONNODE = "Replace LabelsOnNode";
-    public static final String GET_CLUSTER_NODELABELS = "Get ClusterNodeLabels";
-    public static final String ADD_TO_CLUSTER_NODELABELS = "Add To ClusterNodeLabels";
-    public static final String REMOVE_FROM_CLUSTERNODELABELS = "Remove From ClusterNodeLabels";
-    public static final String GET_LABELS_ON_NODE = "Get LabelsOnNode";
-    public static final String GET_APP_PRIORITY = "Get AppPriority";
-    public static final String UPDATE_APP_QUEUE = "Update AppQueue";
-    public static final String POST_DELEGATION_TOKEN = "Post DelegationToken";
-    public static final String POST_DELEGATION_TOKEN_EXPIRATION = "Post DelegationTokenExpiration";
-    public static final String GET_APP_TIMEOUT = "Get App Timeout";
-    public static final String GET_APP_TIMEOUTS = "Get App Timeouts";
-    public static final String CHECK_USER_ACCESS_TO_QUEUE = "Check User AccessToQueue";
-    public static final String GET_APP_ATTEMPT = "Get AppAttempt";
-    public static final String GET_CONTAINER = "Get Container";
-    public static final String UPDATE_SCHEDULER_CONFIGURATION = "Update SchedulerConfiguration";
-    public static final String GET_SCHEDULER_CONFIGURATION = "Get SchedulerConfiguration";
-  }
-
-  public static void logSuccess(String user, String operation, String target) {
-    if (LOG.isInfoEnabled()) {
-      LOG.info(createSuccessLog(user, operation, target, null, null));
-    }
-  }
-
-  /**
-   * Create a readable and parseable audit log string for a successful event.
-   *
-   * @param user User who made the service request to the Router
-   * @param operation Operation requested by the user.
-   * @param target The target on which the operation is being performed.
-   * @param appId Application Id in which operation was performed.
-   *
-   * <br><br>
-   * Note that the {@link RouterAuditLogger} uses tabs ('\t') as a key-val
-   * delimiter and hence the value fields should not contains tabs ('\t').
-   */
-  public static void logSuccess(String user, String operation, String target,
-      ApplicationId appId) {
-    if (LOG.isInfoEnabled()) {
-      LOG.info(createSuccessLog(user, operation, target, appId, null));
-    }
-  }
-
-  /**
-   * Create a readable and parseable audit log string for a successful event.
-   *
-   * @param user         User who made the service request to the Router
-   * @param operation    Operation requested by the user.
-   * @param target       The target on which the operation is being performed.
-   * @param appId        Application Id in which operation was performed.
-   * @param subClusterId Subcluster Id in which operation is performed.
-   *
-   * <br><br>
-   * Note that the {@link RouterAuditLogger} uses tabs ('\t') as a key-val
-   * delimiter and hence the value fields should not contains tabs ('\t').
-   */
-  public static void logSuccess(String user, String operation, String target,
-      ApplicationId appId, SubClusterId subClusterId) {
-    if (LOG.isInfoEnabled()) {
-      LOG.info(createSuccessLog(user, operation, target, appId, subClusterId));
-    }
-  }
-
-  /**
-   * A helper api for creating an audit log for a successful event.
-   */
-  static String createSuccessLog(String user, String operation, String target,
-      ApplicationId appId, SubClusterId subClusterID) {
-    StringBuilder b =
-        createStringBuilderForSuccessEvent(user, operation, target);
-    if (appId != null) {
-      add(Keys.APPID, appId.toString(), b);
-    }
-    if (subClusterID != null) {
-      add(Keys.SUBCLUSTERID, subClusterID.toString(), b);
-    }
-    return b.toString();
-  }
-
-  /**
-   * A helper function for creating the common portion of a successful
-   * log message.
-   */
-  private static StringBuilder createStringBuilderForSuccessEvent(String user,
-      String operation, String target) {
-    StringBuilder b = new StringBuilder();
-    start(Keys.USER, user, b);
-    addRemoteIP(b);
-    add(Keys.OPERATION, operation, b);
-    add(Keys.TARGET, target, b);
-    add(Keys.RESULT, AuditConstants.SUCCESS, b);
-    return b;
-  }
-
-  /**
-   * Create a readable and parseable audit log string for a failed event.
-   *
-   * @param user User who made the service request.
-   * @param operation Operation requested by the user.
-   * @param perm Target permissions.
-   * @param target The target on which the operation is being performed.
-   * @param description Some additional information as to why the operation
-   *                    failed.
-   *
-   * <br><br>
-   * Note that the {@link RouterAuditLogger} uses tabs ('\t') as a key-val
-   * delimiter and hence the value fields should not contains tabs ('\t').
-   */
-  public static void logFailure(String user, String operation, String perm,
-      String target, String description) {
-    if (LOG.isInfoEnabled()) {
-      LOG.info(
-          createFailureLog(user, operation, perm, target, description, null,
-              null));
-    }
-  }
-
-  /**
-   * Create a readable and parseable audit log string for a failed event.
-   *
-   * @param user User who made the service request.
-   * @param operation Operation requested by the user.
-   * @param perm Target permissions.
-   * @param target The target on which the operation is being performed.
-   * @param descriptionFormat the description message format string.
-   * @param args format parameter.
-   *
-   * <br><br>
-   * Note that the {@link RouterAuditLogger} uses tabs ('\t') as a key-val
-   * delimiter and hence the value fields should not contains tabs ('\t').
-   */
-  public static void logFailure(String user, String operation, String perm,
-      String target, String descriptionFormat, Object... args) {
-    if (LOG.isInfoEnabled()) {
-      String description = String.format(descriptionFormat, args);
-      LOG.info(createFailureLog(user, operation, perm, target, description, null, null));
-    }
-  }
-
-  /**
-   * Create a readable and parseable audit log string for a failed event.
-   *
-   * @param user User who made the service request.
-   * @param operation Operation requested by the user.
-   * @param perm Target permissions.
-   * @param target The target on which the operation is being performed.
-   * @param description Some additional information as to why the operation
-   *                    failed.
-   * @param appId Application Id in which operation was performed.
-   *
-   * <br><br>
-   * Note that the {@link RouterAuditLogger} uses tabs ('\t') as a key-val
-   * delimiter and hence the value fields should not contains tabs ('\t').
-   */
-  public static void logFailure(String user, String operation, String perm,
-      String target, String description, ApplicationId appId) {
-    if (LOG.isInfoEnabled()) {
-      LOG.info(
-          createFailureLog(user, operation, perm, target, description, appId,
-              null));
-    }
-  }
-
-  /**
-   * Create a readable and parseable audit log string for a failed event.
-   *
-   * @param user User who made the service request.
-   * @param operation Operation requested by the user.
-   * @param perm Target permissions.
-   * @param target The target on which the operation is being performed.
-   * @param description Some additional information as to why the operation
-   *                    failed.
-   * @param appId Application Id in which operation was performed.
-   * @param subClusterId SubCluster Id in which operation was performed.
-   *
-   * <br><br>
-   * Note that the {@link RouterAuditLogger} uses tabs ('\t') as a key-val
-   * delimiter and hence the value fields should not contains tabs ('\t').
-   */
-  public static void logFailure(String user, String operation, String perm,
-      String target, String description, ApplicationId appId,
-      SubClusterId subClusterId) {
-    if (LOG.isInfoEnabled()) {
-      LOG.info(
-          createFailureLog(user, operation, perm, target, description, appId,
-              subClusterId));
-    }
-  }
-
-  /**
-   * Create a readable and parsable audit log string for a failed event.
-   *
-   * @param user User who made the service request.
-   * @param operation Operation requested by the user.
-   * @param perm Target permissions.
-   * @param target The target on which the operation is being performed.
-   * @param description Some additional information as to why the operation failed.
-   * @param subClusterId SubCluster Id in which operation was performed.
-   */
-  public static void logFailure(String user, String operation, String perm,
-      String target, String description, SubClusterId subClusterId) {
-    if (LOG.isInfoEnabled()) {
-      LOG.info(createFailureLog(user, operation, perm, target, description, null,
-          subClusterId));
-    }
-  }
-
-  /**
-   * A helper api for creating an audit log for a failure event.
-   */
-  static String createFailureLog(String user, String operation, String perm,
-      String target, String description, ApplicationId appId,
-      SubClusterId subClusterId) {
-    StringBuilder b =
-        createStringBuilderForFailureLog(user, operation, target, description,
-            perm);
-    if (appId != null) {
-      add(Keys.APPID, appId.toString(), b);
-    }
-    if (subClusterId != null) {
-      add(Keys.SUBCLUSTERID, subClusterId.toString(), b);
-    }
-    return b.toString();
-  }
-
-  /**
-   * A helper function for creating the common portion of a failure
-   * log message.
-   */
-  private static StringBuilder createStringBuilderForFailureLog(String user,
-      String operation, String target, String description, String perm) {
-    StringBuilder b = new StringBuilder();
-    start(Keys.USER, user, b);
-    addRemoteIP(b);
-    add(Keys.OPERATION, operation, b);
-    add(Keys.TARGET, target, b);
-    add(Keys.RESULT, AuditConstants.FAILURE, b);
-    add(Keys.DESCRIPTION, description, b);
-    add(Keys.PERMISSIONS, perm, b);
-    return b;
-  }
-
-  /**
-   * Adds the first key-val pair to the passed builder in the following format
-   * key=value.
-   */
-  static void start(Keys key, String value, StringBuilder b) {
-    b.append(key.name()).append(AuditConstants.KEY_VAL_SEPARATOR).append(value);
-  }
-
-  /**
-   * Appends the key-val pair to the passed builder in the following format
-   * <pair-delim>key=value.
-   */
-  static void add(Keys key, String value, StringBuilder b) {
-    b.append(AuditConstants.PAIR_SEPARATOR).append(key.name())
-        .append(AuditConstants.KEY_VAL_SEPARATOR).append(value);
-  }
-
-  /**
-   * A helper api to add remote IP address.
-   */
-  static void addRemoteIP(StringBuilder b) {
-    InetAddress ip = Server.getRemoteIp();
-    // ip address can be null for testcases
-    if (ip != null) {
-      add(Keys.IP, ip.getHostAddress(), b);
-    }
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/RouterMetrics.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/RouterMetrics.java
deleted file mode 100644
index dfbe5325dea..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/RouterMetrics.java
+++ /dev/null
@@ -1,2476 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router;
-
-import org.apache.hadoop.classification.VisibleForTesting;
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.metrics2.MetricsInfo;
-import org.apache.hadoop.metrics2.annotation.Metric;
-import org.apache.hadoop.metrics2.annotation.Metrics;
-import org.apache.hadoop.metrics2.lib.*;
-
-import java.util.concurrent.atomic.AtomicBoolean;
-
-import static org.apache.hadoop.metrics2.lib.Interns.info;
-
-/**
- * This class is for maintaining the various Router Federation Interceptor
- * activity statistics and publishing them through the metrics interfaces.
- */
-@InterfaceAudience.Private
-@Metrics(about = "Metrics for Router Federation Interceptor", context = "fedr")
-public final class RouterMetrics {
-
-  private static final MetricsInfo RECORD_INFO =
-      info("RouterMetrics", "Router Federation Interceptor");
-  private static AtomicBoolean isInitialized = new AtomicBoolean(false);
-
-  // Metrics for operation failed
-  @Metric("# of applications failed to be submitted")
-  private MutableGaugeInt numAppsFailedSubmitted;
-  @Metric("# of applications failed to be created")
-  private MutableGaugeInt numAppsFailedCreated;
-  @Metric("# of applications failed to be killed")
-  private MutableGaugeInt numAppsFailedKilled;
-  @Metric("# of application reports failed to be retrieved")
-  private MutableGaugeInt numAppsFailedRetrieved;
-  @Metric("# of multiple applications reports failed to be retrieved")
-  private MutableGaugeInt numMultipleAppsFailedRetrieved;
-  @Metric("# of getApplicationAttempts failed to be retrieved")
-  private MutableGaugeInt numAppAttemptsFailedRetrieved;
-  @Metric("# of getClusterMetrics failed to be retrieved")
-  private MutableGaugeInt numGetClusterMetricsFailedRetrieved;
-  @Metric("# of getClusterNodes failed to be retrieved")
-  private MutableGaugeInt numGetClusterNodesFailedRetrieved;
-  @Metric("# of getNodeToLabels failed to be retrieved")
-  private MutableGaugeInt numGetNodeToLabelsFailedRetrieved;
-  @Metric("# of getNodeToLabels failed to be retrieved")
-  private MutableGaugeInt numGetLabelsToNodesFailedRetrieved;
-  @Metric("# of getClusterNodeLabels failed to be retrieved")
-  private MutableGaugeInt numGetClusterNodeLabelsFailedRetrieved;
-  @Metric("# of getApplicationAttemptReports failed to be retrieved")
-  private MutableGaugeInt numAppAttemptReportFailedRetrieved;
-  @Metric("# of getQueueUserAcls failed to be retrieved")
-  private MutableGaugeInt numGetQueueUserAclsFailedRetrieved;
-  @Metric("# of getContainerReport failed to be retrieved")
-  private MutableGaugeInt numGetContainerReportFailedRetrieved;
-  @Metric("# of getContainers failed to be retrieved")
-  private MutableGaugeInt numGetContainersFailedRetrieved;
-  @Metric("# of listReservations failed to be retrieved")
-  private MutableGaugeInt numListReservationsFailedRetrieved;
-  @Metric("# of getResourceTypeInfo failed to be retrieved")
-  private MutableGaugeInt numGetResourceTypeInfo;
-  @Metric("# of failApplicationAttempt failed to be retrieved")
-  private MutableGaugeInt numFailAppAttemptFailedRetrieved;
-  @Metric("# of updateApplicationPriority failed to be retrieved")
-  private MutableGaugeInt numUpdateAppPriorityFailedRetrieved;
-  @Metric("# of updateApplicationPriority failed to be retrieved")
-  private MutableGaugeInt numUpdateAppTimeoutsFailedRetrieved;
-  @Metric("# of signalToContainer failed to be retrieved")
-  private MutableGaugeInt numSignalToContainerFailedRetrieved;
-  @Metric("# of getQueueInfo failed to be retrieved")
-  private MutableGaugeInt numGetQueueInfoFailedRetrieved;
-  @Metric("# of moveApplicationAcrossQueues failed to be retrieved")
-  private MutableGaugeInt numMoveApplicationAcrossQueuesFailedRetrieved;
-  @Metric("# of getResourceProfiles failed to be retrieved")
-  private MutableGaugeInt numGetResourceProfilesFailedRetrieved;
-  @Metric("# of getResourceProfile failed to be retrieved")
-  private MutableGaugeInt numGetResourceProfileFailedRetrieved;
-  @Metric("# of getAttributesToNodes failed to be retrieved")
-  private MutableGaugeInt numGetAttributesToNodesFailedRetrieved;
-  @Metric("# of getClusterNodeAttributes failed to be retrieved")
-  private MutableGaugeInt numGetClusterNodeAttributesFailedRetrieved;
-  @Metric("# of getNodesToAttributes failed to be retrieved")
-  private MutableGaugeInt numGetNodesToAttributesFailedRetrieved;
-  @Metric("# of getNewReservation failed to be retrieved")
-  private MutableGaugeInt numGetNewReservationFailedRetrieved;
-  @Metric("# of submitReservation failed to be retrieved")
-  private MutableGaugeInt numSubmitReservationFailedRetrieved;
-  @Metric("# of submitReservation failed to be retrieved")
-  private MutableGaugeInt numUpdateReservationFailedRetrieved;
-  @Metric("# of deleteReservation failed to be retrieved")
-  private MutableGaugeInt numDeleteReservationFailedRetrieved;
-  @Metric("# of listReservation failed to be retrieved")
-  private MutableGaugeInt numListReservationFailedRetrieved;
-  @Metric("# of getAppActivities failed to be retrieved")
-  private MutableGaugeInt numGetAppActivitiesFailedRetrieved;
-  @Metric("# of getAppStatistics failed to be retrieved")
-  private MutableGaugeInt numGetAppStatisticsFailedRetrieved;
-  @Metric("# of getAppPriority failed to be retrieved")
-  private MutableGaugeInt numGetAppPriorityFailedRetrieved;
-  @Metric("# of getAppQueue failed to be retrieved")
-  private MutableGaugeInt numGetAppQueueFailedRetrieved;
-  @Metric("# of updateAppQueue failed to be retrieved")
-  private MutableGaugeInt numUpdateAppQueueFailedRetrieved;
-  @Metric("# of getAppTimeout failed to be retrieved")
-  private MutableGaugeInt numGetAppTimeoutFailedRetrieved;
-  @Metric("# of getAppTimeouts failed to be retrieved")
-  private MutableGaugeInt numGetAppTimeoutsFailedRetrieved;
-  @Metric("# of refreshQueues failed to be retrieved")
-  private MutableGaugeInt numRefreshQueuesFailedRetrieved;
-  @Metric("# of getRMNodeLabels failed to be retrieved")
-  private MutableGaugeInt numGetRMNodeLabelsFailedRetrieved;
-  @Metric("# of checkUserAccessToQueue failed to be retrieved")
-  private MutableGaugeInt numCheckUserAccessToQueueFailedRetrieved;
-  @Metric("# of refreshNodes failed to be retrieved")
-  private MutableGaugeInt numRefreshNodesFailedRetrieved;
-  @Metric("# of getDelegationToken failed to be retrieved")
-  private MutableGaugeInt numGetDelegationTokenFailedRetrieved;
-  @Metric("# of renewDelegationToken failed to be retrieved")
-  private MutableGaugeInt numRenewDelegationTokenFailedRetrieved;
-  @Metric("# of renewDelegationToken failed to be retrieved")
-  private MutableGaugeInt numCancelDelegationTokenFailedRetrieved;
-  @Metric("# of dumpSchedulerLogs failed to be retrieved")
-  private MutableGaugeInt numDumpSchedulerLogsFailedRetrieved;
-  @Metric("# of getActivities failed to be retrieved")
-  private MutableGaugeInt numGetActivitiesFailedRetrieved;
-  @Metric("# of getBulkActivities failed to be retrieved")
-  private MutableGaugeInt numGetBulkActivitiesFailedRetrieved;
-  @Metric("# of getSchedulerInfo failed to be retrieved")
-  private MutableGaugeInt numGetSchedulerInfoFailedRetrieved;
-  @Metric("# of refreshSuperUserGroupsConfiguration failed to be retrieved")
-  private MutableGaugeInt numRefreshSuperUserGroupsConfigurationFailedRetrieved;
-  @Metric("# of refreshUserToGroupsMappings failed to be retrieved")
-  private MutableGaugeInt numRefreshUserToGroupsMappingsFailedRetrieved;
-  @Metric("# of deregisterSubCluster failed to be retrieved")
-  private MutableGaugeInt numDeregisterSubClusterFailedRetrieved;
-  @Metric("# of saveFederationQueuePolicy failed to be retrieved")
-  private MutableGaugeInt numSaveFederationQueuePolicyFailedRetrieved;
-  @Metric("# of batchSaveFederationQueuePolicies failed to be retrieved")
-  private MutableGaugeInt numBatchSaveFederationQueuePoliciesFailedRetrieved;
-  @Metric("# of listFederationQueuePolicies failed to be retrieved")
-  private MutableGaugeInt numListFederationQueuePoliciesFailedRetrieved;
-  @Metric("# of deleteFederationApplication failed to be retrieved")
-  private MutableGaugeInt numDeleteFederationApplicationFailedRetrieved;
-  @Metric("# of getFederationSubClusters failed to be retrieved")
-  private MutableGaugeInt numGetFederationSubClustersFailedRetrieved;
-  @Metric("# of deleteFederationPoliciesByQueues failed to be retrieved")
-  private MutableGaugeInt numDeleteFederationPoliciesByQueuesRetrieved;
-  @Metric("# of refreshAdminAcls failed to be retrieved")
-  private MutableGaugeInt numRefreshAdminAclsFailedRetrieved;
-  @Metric("# of refreshServiceAcls failed to be retrieved")
-  private MutableGaugeInt numRefreshServiceAclsFailedRetrieved;
-  @Metric("# of replaceLabelsOnNodes failed to be retrieved")
-  private MutableGaugeInt numReplaceLabelsOnNodesFailedRetrieved;
-  @Metric("# of replaceLabelsOnNode failed to be retrieved")
-  private MutableGaugeInt numReplaceLabelsOnNodeFailedRetrieved;
-  @Metric("# of addToClusterNodeLabels failed to be retrieved")
-  private MutableGaugeInt numAddToClusterNodeLabelsFailedRetrieved;
-  @Metric("# of removeFromClusterNodeLabels failed to be retrieved")
-  private MutableGaugeInt numRemoveFromClusterNodeLabelsFailedRetrieved;
-  @Metric("# of numUpdateSchedulerConfiguration failed to be retrieved")
-  private MutableGaugeInt numUpdateSchedulerConfigurationFailedRetrieved;
-  @Metric("# of numGetSchedulerConfiguration failed to be retrieved")
-  private MutableGaugeInt numGetSchedulerConfigurationFailedRetrieved;
-  @Metric("# of getClusterInfo failed to be retrieved")
-  private MutableGaugeInt numGetClusterInfoFailedRetrieved;
-  @Metric("# of getClusterUserInfo failed to be retrieved")
-  private MutableGaugeInt numGetClusterUserInfoFailedRetrieved;
-  @Metric("# of updateNodeResource failed to be retrieved")
-  private MutableGaugeInt numUpdateNodeResourceFailedRetrieved;
-  @Metric("# of refreshNodesResources failed to be retrieved")
-  private MutableGaugeInt numRefreshNodesResourcesFailedRetrieved;
-  @Metric("# of checkForDecommissioningNodes failed to be retrieved")
-  private MutableGaugeInt numCheckForDecommissioningNodesFailedRetrieved;
-  @Metric("# of refreshClusterMaxPriority failed to be retrieved")
-  private MutableGaugeInt numRefreshClusterMaxPriorityFailedRetrieved;
-  @Metric("# of mapAttributesToNodes failed to be retrieved")
-  private MutableGaugeInt numMapAttributesToNodesFailedRetrieved;
-  @Metric("# of getGroupsForUser failed to be retrieved")
-  private MutableGaugeInt numGetGroupsForUserFailedRetrieved;
-
-  // Aggregate metrics are shared, and don't have to be looked up per call
-  @Metric("Total number of successful Submitted apps and latency(ms)")
-  private MutableRate totalSucceededAppsSubmitted;
-  @Metric("Total number of successful Killed apps and latency(ms)")
-  private MutableRate totalSucceededAppsKilled;
-  @Metric("Total number of successful Created apps and latency(ms)")
-  private MutableRate totalSucceededAppsCreated;
-  @Metric("Total number of successful Retrieved app reports and latency(ms)")
-  private MutableRate totalSucceededAppsRetrieved;
-  @Metric("Total number of successful Retrieved multiple apps reports and latency(ms)")
-  private MutableRate totalSucceededMultipleAppsRetrieved;
-  @Metric("Total number of successful Retrieved appAttempt reports and latency(ms)")
-  private MutableRate totalSucceededAppAttemptsRetrieved;
-  @Metric("Total number of successful Retrieved getClusterMetrics and latency(ms)")
-  private MutableRate totalSucceededGetClusterMetricsRetrieved;
-  @Metric("Total number of successful Retrieved getClusterNodes and latency(ms)")
-  private MutableRate totalSucceededGetClusterNodesRetrieved;
-  @Metric("Total number of successful Retrieved getNodeToLabels and latency(ms)")
-  private MutableRate totalSucceededGetNodeToLabelsRetrieved;
-  @Metric("Total number of successful Retrieved getNodeToLabels and latency(ms)")
-  private MutableRate totalSucceededGetLabelsToNodesRetrieved;
-  @Metric("Total number of successful Retrieved getClusterNodeLabels and latency(ms)")
-  private MutableRate totalSucceededGetClusterNodeLabelsRetrieved;
-  @Metric("Total number of successful Retrieved getApplicationAttemptReport and latency(ms)")
-  private MutableRate totalSucceededAppAttemptReportRetrieved;
-  @Metric("Total number of successful Retrieved getQueueUserAcls and latency(ms)")
-  private MutableRate totalSucceededGetQueueUserAclsRetrieved;
-  @Metric("Total number of successful Retrieved getContainerReport and latency(ms)")
-  private MutableRate totalSucceededGetContainerReportRetrieved;
-  @Metric("Total number of successful Retrieved getContainers and latency(ms)")
-  private MutableRate totalSucceededGetContainersRetrieved;
-  @Metric("Total number of successful Retrieved listReservations and latency(ms)")
-  private MutableRate totalSucceededListReservationsRetrieved;
-  @Metric("Total number of successful Retrieved getResourceTypeInfo and latency(ms)")
-  private MutableRate totalSucceededGetResourceTypeInfoRetrieved;
-  @Metric("Total number of successful Retrieved failApplicationAttempt and latency(ms)")
-  private MutableRate totalSucceededFailAppAttemptRetrieved;
-  @Metric("Total number of successful Retrieved updateApplicationPriority and latency(ms)")
-  private MutableRate totalSucceededUpdateAppPriorityRetrieved;
-  @Metric("Total number of successful Retrieved updateApplicationTimeouts and latency(ms)")
-  private MutableRate totalSucceededUpdateAppTimeoutsRetrieved;
-  @Metric("Total number of successful Retrieved signalToContainer and latency(ms)")
-  private MutableRate totalSucceededSignalToContainerRetrieved;
-  @Metric("Total number of successful Retrieved getQueueInfo and latency(ms)")
-  private MutableRate totalSucceededGetQueueInfoRetrieved;
-  @Metric("Total number of successful Retrieved moveApplicationAcrossQueues and latency(ms)")
-  private MutableRate totalSucceededMoveApplicationAcrossQueuesRetrieved;
-  @Metric("Total number of successful Retrieved getResourceProfiles and latency(ms)")
-  private MutableRate totalSucceededGetResourceProfilesRetrieved;
-  @Metric("Total number of successful Retrieved getResourceProfile and latency(ms)")
-  private MutableRate totalSucceededGetResourceProfileRetrieved;
-  @Metric("Total number of successful Retrieved getAttributesToNodes and latency(ms)")
-  private MutableRate totalSucceededGetAttributesToNodesRetrieved;
-  @Metric("Total number of successful Retrieved getClusterNodeAttributes and latency(ms)")
-  private MutableRate totalSucceededGetClusterNodeAttributesRetrieved;
-  @Metric("Total number of successful Retrieved getNodesToAttributes and latency(ms)")
-  private MutableRate totalSucceededGetNodesToAttributesRetrieved;
-  @Metric("Total number of successful Retrieved GetNewReservation and latency(ms)")
-  private MutableRate totalSucceededGetNewReservationRetrieved;
-  @Metric("Total number of successful Retrieved SubmitReservation and latency(ms)")
-  private MutableRate totalSucceededSubmitReservationRetrieved;
-  @Metric("Total number of successful Retrieved UpdateReservation and latency(ms)")
-  private MutableRate totalSucceededUpdateReservationRetrieved;
-  @Metric("Total number of successful Retrieved DeleteReservation and latency(ms)")
-  private MutableRate totalSucceededDeleteReservationRetrieved;
-  @Metric("Total number of successful Retrieved ListReservation and latency(ms)")
-  private MutableRate totalSucceededListReservationRetrieved;
-  @Metric("Total number of successful Retrieved GetAppActivities and latency(ms)")
-  private MutableRate totalSucceededGetAppActivitiesRetrieved;
-  @Metric("Total number of successful Retrieved GetAppStatistics and latency(ms)")
-  private MutableRate totalSucceededGetAppStatisticsRetrieved;
-  @Metric("Total number of successful Retrieved GetAppPriority and latency(ms)")
-  private MutableRate totalSucceededGetAppPriorityRetrieved;
-  @Metric("Total number of successful Retrieved GetAppQueue and latency(ms)")
-  private MutableRate totalSucceededGetAppQueueRetrieved;
-  @Metric("Total number of successful Retrieved UpdateAppQueue and latency(ms)")
-  private MutableRate totalSucceededUpdateAppQueueRetrieved;
-  @Metric("Total number of successful Retrieved GetAppTimeout and latency(ms)")
-  private MutableRate totalSucceededGetAppTimeoutRetrieved;
-  @Metric("Total number of successful Retrieved GetAppTimeouts and latency(ms)")
-  private MutableRate totalSucceededGetAppTimeoutsRetrieved;
-  @Metric("Total number of successful Retrieved RefreshQueues and latency(ms)")
-  private MutableRate totalSucceededRefreshQueuesRetrieved;
-  @Metric("Total number of successful Retrieved GetRMNodeLabels and latency(ms)")
-  private MutableRate totalSucceededGetRMNodeLabelsRetrieved;
-  @Metric("Total number of successful Retrieved CheckUserAccessToQueue and latency(ms)")
-  private MutableRate totalSucceededCheckUserAccessToQueueRetrieved;
-  @Metric("Total number of successful Retrieved RefreshNodes and latency(ms)")
-  private MutableRate totalSucceededRefreshNodesRetrieved;
-  @Metric("Total number of successful Retrieved GetDelegationToken and latency(ms)")
-  private MutableRate totalSucceededGetDelegationTokenRetrieved;
-  @Metric("Total number of successful Retrieved RenewDelegationToken and latency(ms)")
-  private MutableRate totalSucceededRenewDelegationTokenRetrieved;
-  @Metric("Total number of successful Retrieved CancelDelegationToken and latency(ms)")
-  private MutableRate totalSucceededCancelDelegationTokenRetrieved;
-  @Metric("Total number of successful Retrieved DumpSchedulerLogs and latency(ms)")
-  private MutableRate totalSucceededDumpSchedulerLogsRetrieved;
-  @Metric("Total number of successful Retrieved GetActivities and latency(ms)")
-  private MutableRate totalSucceededGetActivitiesRetrieved;
-  @Metric("Total number of successful Retrieved GetBulkActivities and latency(ms)")
-  private MutableRate totalSucceededGetBulkActivitiesRetrieved;
-  @Metric("Total number of successful Retrieved RefreshSuperUserGroupsConfig and latency(ms)")
-  private MutableRate totalSucceededRefreshSuperUserGroupsConfigurationRetrieved;
-  @Metric("Total number of successful Retrieved RefreshUserToGroupsMappings and latency(ms)")
-  private MutableRate totalSucceededRefreshUserToGroupsMappingsRetrieved;
-  @Metric("Total number of successful Retrieved ReplaceLabelsOnNodes and latency(ms)")
-  private MutableRate totalSucceededReplaceLabelsOnNodesRetrieved;
-  @Metric("Total number of successful Retrieved ReplaceLabelsOnNode and latency(ms)")
-  private MutableRate totalSucceededReplaceLabelsOnNodeRetrieved;
-  @Metric("Total number of successful Retrieved GetSchedulerInfo and latency(ms)")
-  private MutableRate totalSucceededGetSchedulerInfoRetrieved;
-  @Metric("Total number of successful Retrieved DeregisterSubCluster and latency(ms)")
-  private MutableRate totalSucceededDeregisterSubClusterRetrieved;
-  @Metric("Total number of successful Retrieved SaveFederationQueuePolicy and latency(ms)")
-  private MutableRate totalSucceededSaveFederationQueuePolicyRetrieved;
-  @Metric("Total number of successful Retrieved BatchSaveFederationQueuePolicies and latency(ms)")
-  private MutableRate totalSucceededBatchSaveFederationQueuePoliciesRetrieved;
-  @Metric("Total number of successful Retrieved ListFederationQueuePolicies and latency(ms)")
-  private MutableRate totalSucceededListFederationQueuePoliciesFailedRetrieved;
-  @Metric("Total number of successful Retrieved DeleteFederationApplication and latency(ms)")
-  private MutableRate totalSucceededDeleteFederationApplicationFailedRetrieved;
-  @Metric("Total number of successful Retrieved getFederationSubClusters and latency(ms)")
-  private MutableRate totalSucceededGetFederationSubClustersRetrieved;
-  @Metric("Total number of successful Retrieved DeleteFederationPoliciesByQueues and latency(ms)")
-  private MutableRate totalSucceededDeleteFederationPoliciesByQueuesRetrieved;
-  @Metric("Total number of successful Retrieved RefreshAdminAcls and latency(ms)")
-  private MutableRate totalSucceededRefreshAdminAclsRetrieved;
-  @Metric("Total number of successful Retrieved RefreshServiceAcls and latency(ms)")
-  private MutableRate totalSucceededRefreshServiceAclsRetrieved;
-  @Metric("Total number of successful Retrieved AddToClusterNodeLabels and latency(ms)")
-  private MutableRate totalSucceededAddToClusterNodeLabelsRetrieved;
-  @Metric("Total number of successful Retrieved RemoveFromClusterNodeLabels and latency(ms)")
-  private MutableRate totalSucceededRemoveFromClusterNodeLabelsRetrieved;
-  @Metric("Total number of successful Retrieved updateSchedulerConfiguration and latency(ms)")
-  private MutableRate totalSucceededUpdateSchedulerConfigurationRetrieved;
-  @Metric("Total number of successful Retrieved getSchedulerConfiguration and latency(ms)")
-  private MutableRate totalSucceededGetSchedulerConfigurationRetrieved;
-  @Metric("Total number of successful Retrieved GetClusterInfoRetrieved and latency(ms)")
-  private MutableRate totalSucceededGetClusterInfoRetrieved;
-  @Metric("Total number of successful Retrieved GetClusterUserInfoRetrieved and latency(ms)")
-  private MutableRate totalSucceededGetClusterUserInfoRetrieved;
-  @Metric("Total number of successful Retrieved UpdateNodeResource and latency(ms)")
-  private MutableRate totalSucceededUpdateNodeResourceRetrieved;
-  @Metric("Total number of successful Retrieved RefreshNodesResources and latency(ms)")
-  private MutableRate totalSucceededRefreshNodesResourcesRetrieved;
-  @Metric("Total number of successful Retrieved CheckForDecommissioningNodes and latency(ms)")
-  private MutableRate totalSucceededCheckForDecommissioningNodesRetrieved;
-  @Metric("Total number of successful Retrieved RefreshClusterMaxPriority and latency(ms)")
-  private MutableRate totalSucceededRefreshClusterMaxPriorityRetrieved;
-  @Metric("Total number of successful Retrieved MapAttributesToNodes and latency(ms)")
-  private MutableRate totalSucceededMapAttributesToNodesRetrieved;
-  @Metric("Total number of successful Retrieved GetGroupsForUser and latency(ms)")
-  private MutableRate totalSucceededGetGroupsForUsersRetrieved;
-
-  /**
-   * Provide quantile counters for all latencies.
-   */
-  private MutableQuantiles submitApplicationLatency;
-  private MutableQuantiles getNewApplicationLatency;
-  private MutableQuantiles killApplicationLatency;
-  private MutableQuantiles getApplicationReportLatency;
-  private MutableQuantiles getApplicationsReportLatency;
-  private MutableQuantiles getApplicationAttemptReportLatency;
-  private MutableQuantiles getClusterMetricsLatency;
-  private MutableQuantiles getClusterNodesLatency;
-  private MutableQuantiles getNodeToLabelsLatency;
-  private MutableQuantiles getLabelToNodesLatency;
-  private MutableQuantiles getClusterNodeLabelsLatency;
-  private MutableQuantiles getApplicationAttemptsLatency;
-  private MutableQuantiles getQueueUserAclsLatency;
-  private MutableQuantiles getContainerReportLatency;
-  private MutableQuantiles getContainerLatency;
-  private MutableQuantiles listReservationsLatency;
-  private MutableQuantiles listResourceTypeInfoLatency;
-  private MutableQuantiles failAppAttemptLatency;
-  private MutableQuantiles updateAppPriorityLatency;
-  private MutableQuantiles updateAppTimeoutsLatency;
-  private MutableQuantiles signalToContainerLatency;
-  private MutableQuantiles getQueueInfoLatency;
-  private MutableQuantiles moveApplicationAcrossQueuesLatency;
-  private MutableQuantiles getResourceProfilesLatency;
-  private MutableQuantiles getResourceProfileLatency;
-  private MutableQuantiles getAttributesToNodesLatency;
-  private MutableQuantiles getClusterNodeAttributesLatency;
-  private MutableQuantiles getNodesToAttributesLatency;
-  private MutableQuantiles getNewReservationLatency;
-  private MutableQuantiles submitReservationLatency;
-  private MutableQuantiles updateReservationLatency;
-  private MutableQuantiles deleteReservationLatency;
-  private MutableQuantiles listReservationLatency;
-  private MutableQuantiles getAppActivitiesLatency;
-  private MutableQuantiles getAppStatisticsLatency;
-  private MutableQuantiles getAppPriorityLatency;
-  private MutableQuantiles getAppQueueLatency;
-  private MutableQuantiles getUpdateQueueLatency;
-  private MutableQuantiles getAppTimeoutLatency;
-  private MutableQuantiles getAppTimeoutsLatency;
-  private MutableQuantiles refreshQueuesLatency;
-  private MutableQuantiles getRMNodeLabelsLatency;
-  private MutableQuantiles checkUserAccessToQueueLatency;
-  private MutableQuantiles refreshNodesLatency;
-  private MutableQuantiles getDelegationTokenLatency;
-  private MutableQuantiles renewDelegationTokenLatency;
-  private MutableQuantiles cancelDelegationTokenLatency;
-  private MutableQuantiles dumpSchedulerLogsLatency;
-  private MutableQuantiles getActivitiesLatency;
-  private MutableQuantiles getBulkActivitiesLatency;
-  private MutableQuantiles getSchedulerInfoRetrievedLatency;
-  private MutableQuantiles refreshSuperUserGroupsConfLatency;
-  private MutableQuantiles refreshUserToGroupsMappingsLatency;
-  private MutableQuantiles refreshDeregisterSubClusterLatency;
-  private MutableQuantiles saveFederationQueuePolicyLatency;
-  private MutableQuantiles batchSaveFederationQueuePoliciesLatency;
-  private MutableQuantiles listFederationQueuePoliciesLatency;
-  private MutableQuantiles deleteFederationApplicationLatency;
-  private MutableQuantiles getFederationSubClustersLatency;
-  private MutableQuantiles deleteFederationPoliciesByQueuesLatency;
-  private MutableQuantiles refreshAdminAclsLatency;
-  private MutableQuantiles refreshServiceAclsLatency;
-  private MutableQuantiles replaceLabelsOnNodesLatency;
-  private MutableQuantiles replaceLabelsOnNodeLatency;
-  private MutableQuantiles addToClusterNodeLabelsLatency;
-  private MutableQuantiles removeFromClusterNodeLabelsLatency;
-  private MutableQuantiles updateSchedulerConfigLatency;
-  private MutableQuantiles getSchedulerConfigurationLatency;
-  private MutableQuantiles getClusterInfoLatency;
-  private MutableQuantiles getClusterUserInfoLatency;
-  private MutableQuantiles updateNodeResourceLatency;
-  private MutableQuantiles refreshNodesResourcesLatency;
-  private MutableQuantiles checkForDecommissioningNodesLatency;
-  private MutableQuantiles refreshClusterMaxPriorityLatency;
-  private MutableQuantiles mapAttributesToNodesLatency;
-  private MutableQuantiles getGroupsForUserLatency;
-
-  private static volatile RouterMetrics instance = null;
-  private static MetricsRegistry registry;
-
-  @SuppressWarnings("checkstyle:MethodLength")
-  private RouterMetrics() {
-    registry = new MetricsRegistry(RECORD_INFO);
-    registry.tag(RECORD_INFO, "Router");
-    getNewApplicationLatency = registry.newQuantiles("getNewApplicationLatency",
-        "latency of get new application", "ops", "latency", 10);
-    submitApplicationLatency = registry.newQuantiles("submitApplicationLatency",
-        "latency of submit application", "ops", "latency", 10);
-    killApplicationLatency = registry.newQuantiles("killApplicationLatency",
-        "latency of kill application", "ops", "latency", 10);
-    getApplicationReportLatency =
-        registry.newQuantiles("getApplicationReportLatency",
-            "latency of get application report", "ops", "latency", 10);
-    getApplicationsReportLatency =
-        registry.newQuantiles("getApplicationsReportLatency",
-            "latency of get applications report", "ops", "latency", 10);
-    getApplicationAttemptReportLatency =
-        registry.newQuantiles("getApplicationAttemptReportLatency",
-                    "latency of get applicationattempt " +
-                            "report", "ops", "latency", 10);
-    getClusterMetricsLatency =
-        registry.newQuantiles("getClusterMetricsLatency",
-            "latency of get cluster metrics", "ops", "latency", 10);
-
-    getClusterNodesLatency =
-        registry.newQuantiles("getClusterNodesLatency",
-            "latency of get cluster nodes", "ops", "latency", 10);
-
-    getNodeToLabelsLatency =
-        registry.newQuantiles("getNodeToLabelsLatency",
-            "latency of get node labels", "ops", "latency", 10);
-
-    getLabelToNodesLatency =
-        registry.newQuantiles("getLabelToNodesLatency",
-            "latency of get label nodes", "ops", "latency", 10);
-
-    getClusterNodeLabelsLatency =
-        registry.newQuantiles("getClusterNodeLabelsLatency",
-            "latency of get cluster node labels", "ops", "latency", 10);
-
-    getApplicationAttemptsLatency =
-        registry.newQuantiles("getApplicationAttemptsLatency",
-            "latency of get application attempts", "ops", "latency", 10);
-
-    getQueueUserAclsLatency =
-        registry.newQuantiles("getQueueUserAclsLatency",
-            "latency of get queue user acls", "ops", "latency", 10);
-
-    getContainerReportLatency =
-        registry.newQuantiles("getContainerReportLatency",
-            "latency of get container report", "ops", "latency", 10);
-
-    getContainerLatency =
-        registry.newQuantiles("getContainerLatency",
-            "latency of get container", "ops", "latency", 10);
-
-    listReservationsLatency =
-        registry.newQuantiles("listReservationsLatency",
-            "latency of list reservations", "ops", "latency", 10);
-
-    listResourceTypeInfoLatency =
-        registry.newQuantiles("getResourceTypeInfoLatency",
-            "latency of get resource type info", "ops", "latency", 10);
-
-    failAppAttemptLatency =
-        registry.newQuantiles("failApplicationAttemptLatency",
-            "latency of fail application attempt", "ops", "latency", 10);
-
-    updateAppPriorityLatency =
-        registry.newQuantiles("updateApplicationPriorityLatency",
-            "latency of update application priority", "ops", "latency", 10);
-
-    updateAppTimeoutsLatency =
-        registry.newQuantiles("updateApplicationTimeoutsLatency",
-            "latency of update application timeouts", "ops", "latency", 10);
-
-    signalToContainerLatency =
-        registry.newQuantiles("signalToContainerLatency",
-            "latency of signal to container timeouts", "ops", "latency", 10);
-
-    getQueueInfoLatency =
-        registry.newQuantiles("getQueueInfoLatency",
-            "latency of get queue info timeouts", "ops", "latency", 10);
-
-    moveApplicationAcrossQueuesLatency =
-        registry.newQuantiles("moveApplicationAcrossQueuesLatency",
-            "latency of move application across queues timeouts", "ops", "latency", 10);
-
-    getResourceProfilesLatency =
-        registry.newQuantiles("getResourceProfilesLatency",
-            "latency of get resource profiles timeouts", "ops", "latency", 10);
-
-    getResourceProfileLatency =
-        registry.newQuantiles("getResourceProfileLatency",
-            "latency of get resource profile timeouts", "ops", "latency", 10);
-
-    getAttributesToNodesLatency =
-        registry.newQuantiles("getAttributesToNodesLatency",
-            "latency of get attributes to nodes timeouts", "ops", "latency", 10);
-
-    getClusterNodeAttributesLatency =
-        registry.newQuantiles("getClusterNodeAttributesLatency",
-            "latency of get cluster node attributes timeouts", "ops", "latency", 10);
-
-    getNodesToAttributesLatency =
-        registry.newQuantiles("getNodesToAttributesLatency",
-            "latency of get nodes to attributes timeouts", "ops", "latency", 10);
-
-    getNewReservationLatency =
-        registry.newQuantiles("getNewReservationLatency",
-            "latency of get new reservation timeouts", "ops", "latency", 10);
-
-    submitReservationLatency =
-        registry.newQuantiles("submitReservationLatency",
-            "latency of submit reservation timeouts", "ops", "latency", 10);
-
-    updateReservationLatency =
-        registry.newQuantiles("updateReservationLatency",
-            "latency of update reservation timeouts", "ops", "latency", 10);
-
-    deleteReservationLatency =
-        registry.newQuantiles("deleteReservationLatency",
-            "latency of delete reservation timeouts", "ops", "latency", 10);
-
-    listReservationLatency =
-        registry.newQuantiles("listReservationLatency",
-            "latency of list reservation timeouts", "ops", "latency", 10);
-
-    getAppActivitiesLatency = registry.newQuantiles("getAppActivitiesLatency",
-         "latency of get app activities timeouts", "ops", "latency", 10);
-
-    getAppStatisticsLatency = registry.newQuantiles("getAppStatisticsLatency",
-         "latency of get app statistics timeouts", "ops", "latency", 10);
-
-    getAppPriorityLatency = registry.newQuantiles("getAppPriorityLatency",
-         "latency of get app priority timeouts", "ops", "latency", 10);
-
-    getAppQueueLatency = registry.newQuantiles("getAppQueueLatency",
-         "latency of get app queue timeouts", "ops", "latency", 10);
-
-    getUpdateQueueLatency = registry.newQuantiles("getUpdateQueueLatency",
-        "latency of update app queue timeouts", "ops", "latency", 10);
-
-    getAppTimeoutLatency = registry.newQuantiles("getAppTimeoutLatency",
-        "latency of get apptimeout timeouts", "ops", "latency", 10);
-
-    getAppTimeoutsLatency = registry.newQuantiles("getAppTimeoutsLatency",
-         "latency of get apptimeouts timeouts", "ops", "latency", 10);
-
-    refreshQueuesLatency = registry.newQuantiles("refreshQueuesLatency",
-         "latency of get refresh queues timeouts", "ops", "latency", 10);
-
-    getRMNodeLabelsLatency = registry.newQuantiles("getRMNodeLabelsLatency",
-        "latency of get rmnodelabels timeouts", "ops", "latency", 10);
-
-    checkUserAccessToQueueLatency = registry.newQuantiles("checkUserAccessToQueueLatency",
-        "latency of get apptimeouts timeouts", "ops", "latency", 10);
-
-    refreshNodesLatency = registry.newQuantiles("refreshNodesLatency",
-        "latency of get refresh nodes timeouts", "ops", "latency", 10);
-
-    getDelegationTokenLatency = registry.newQuantiles("getDelegationTokenLatency",
-        "latency of get delegation token timeouts", "ops", "latency", 10);
-
-    renewDelegationTokenLatency = registry.newQuantiles("renewDelegationTokenLatency",
-       "latency of renew delegation token timeouts", "ops", "latency", 10);
-
-    cancelDelegationTokenLatency = registry.newQuantiles("cancelDelegationTokenLatency",
-        "latency of cancel delegation token timeouts", "ops", "latency", 10);
-
-    dumpSchedulerLogsLatency = registry.newQuantiles("dumpSchedulerLogsLatency",
-        "latency of dump scheduler logs timeouts", "ops", "latency", 10);
-
-    getActivitiesLatency = registry.newQuantiles("getActivitiesLatency",
-        "latency of get activities timeouts", "ops", "latency", 10);
-
-    getBulkActivitiesLatency = registry.newQuantiles("getBulkActivitiesLatency",
-         "latency of get bulk activities timeouts", "ops", "latency", 10);
-
-    getSchedulerInfoRetrievedLatency = registry.newQuantiles("getSchedulerInfoRetrievedLatency",
-        "latency of get scheduler info timeouts", "ops", "latency", 10);
-
-    refreshSuperUserGroupsConfLatency = registry.newQuantiles("refreshSuperUserGroupsConfLatency",
-        "latency of refresh superuser groups configuration timeouts", "ops", "latency", 10);
-
-    refreshUserToGroupsMappingsLatency = registry.newQuantiles("refreshUserToGroupsMappingsLatency",
-        "latency of refresh user to groups mappings timeouts", "ops", "latency", 10);
-
-    refreshDeregisterSubClusterLatency = registry.newQuantiles("refreshDeregisterSubClusterLatency",
-        "latency of deregister subcluster timeouts", "ops", "latency", 10);
-
-    saveFederationQueuePolicyLatency = registry.newQuantiles("saveFederationQueuePolicyLatency",
-        "latency of save federation queue policy timeouts", "ops", "latency", 10);
-
-    batchSaveFederationQueuePoliciesLatency = registry.newQuantiles(
-        "batchSaveFederationQueuePoliciesLatency",
-        "latency of batch save federationqueuepolicies timeouts", "ops", "latency", 10);
-
-    listFederationQueuePoliciesLatency = registry.newQuantiles(
-        "listFederationQueuePoliciesLatency",
-        "latency of list federationqueuepolicies timeouts", "ops", "latency", 10);
-
-    deleteFederationApplicationLatency = registry.newQuantiles(
-        "deleteFederationApplicationLatency",
-        "latency of delete FederationApplication timeouts", "ops", "latency", 10);
-
-    getFederationSubClustersLatency = registry.newQuantiles(
-        "getFederationSubClustersLatency",
-        "latency of get FederationSubClusters timeouts", "ops", "latency", 10);
-
-    deleteFederationPoliciesByQueuesLatency = registry.newQuantiles(
-        "deleteFederationPoliciesByQueuesLatency",
-        "latency of delete FederationPoliciesByQueues timeouts", "ops", "latency", 10);
-
-    refreshAdminAclsLatency = registry.newQuantiles("refreshAdminAclsLatency",
-        "latency of refresh admin acls timeouts", "ops", "latency", 10);
-
-    refreshServiceAclsLatency = registry.newQuantiles("refreshServiceAclsLatency",
-        "latency of refresh service acls timeouts", "ops", "latency", 10);
-
-    replaceLabelsOnNodesLatency = registry.newQuantiles("replaceLabelsOnNodesLatency",
-        "latency of replace labels on nodes timeouts", "ops", "latency", 10);
-
-    replaceLabelsOnNodeLatency = registry.newQuantiles("replaceLabelsOnNodeLatency",
-        "latency of replace labels on node timeouts", "ops", "latency", 10);
-
-    addToClusterNodeLabelsLatency = registry.newQuantiles("addToClusterNodeLabelsLatency",
-        "latency of add cluster nodelabels timeouts", "ops", "latency", 10);
-
-    removeFromClusterNodeLabelsLatency = registry.newQuantiles("removeFromClusterNodeLabelsLatency",
-        "latency of remove cluster nodelabels timeouts", "ops", "latency", 10);
-
-    updateSchedulerConfigLatency = registry.newQuantiles("updateSchedulerConfigurationLatency",
-        "latency of update scheduler configuration timeouts", "ops", "latency", 10);
-
-    getSchedulerConfigurationLatency = registry.newQuantiles("getSchedulerConfigurationLatency",
-        "latency of get scheduler configuration timeouts", "ops", "latency", 10);
-
-    getClusterInfoLatency = registry.newQuantiles("getClusterInfoLatency",
-        "latency of get cluster info timeouts", "ops", "latency", 10);
-
-    getClusterUserInfoLatency = registry.newQuantiles("getClusterUserInfoLatency",
-        "latency of get cluster user info timeouts", "ops", "latency", 10);
-
-    updateNodeResourceLatency = registry.newQuantiles("updateNodeResourceLatency",
-        "latency of update node resource timeouts", "ops", "latency", 10);
-
-    refreshNodesResourcesLatency = registry.newQuantiles("refreshNodesResourcesLatency",
-        "latency of refresh nodes resources timeouts", "ops", "latency", 10);
-
-    checkForDecommissioningNodesLatency = registry.newQuantiles(
-        "checkForDecommissioningNodesLatency", "latency of check for decommissioningnodes timeouts",
-        "ops", "latency", 10);
-
-    refreshClusterMaxPriorityLatency = registry.newQuantiles("refreshClusterMaxPriorityLatency",
-        "latency of refresh cluster max priority timeouts", "ops", "latency", 10);
-
-    mapAttributesToNodesLatency = registry.newQuantiles("mapAttributesToNodesLatency",
-        "latency of map attributes to nodes timeouts", "ops", "latency", 10);
-
-    getGroupsForUserLatency = registry.newQuantiles("getGroupsForUserLatency",
-        "latency of get groups for user timeouts", "ops", "latency", 10);
-  }
-
-  public static RouterMetrics getMetrics() {
-    if (!isInitialized.get()) {
-      synchronized (RouterMetrics.class) {
-        if (instance == null) {
-          instance = DefaultMetricsSystem.instance().register("RouterMetrics",
-              "Metrics for the Yarn Router", new RouterMetrics());
-          isInitialized.set(true);
-        }
-      }
-    }
-    return instance;
-  }
-
-  @VisibleForTesting
-  synchronized static void destroy() {
-    isInitialized.set(false);
-    instance = null;
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededAppsCreated() {
-    return totalSucceededAppsCreated.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededAppsSubmitted() {
-    return totalSucceededAppsSubmitted.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededAppsKilled() {
-    return totalSucceededAppsKilled.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededAppsRetrieved() {
-    return totalSucceededAppsRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededAppAttemptsRetrieved() {
-    return totalSucceededAppAttemptsRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededMultipleAppsRetrieved() {
-    return totalSucceededMultipleAppsRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetClusterMetricsRetrieved(){
-    return totalSucceededGetClusterMetricsRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetClusterNodesRetrieved(){
-    return totalSucceededGetClusterNodesRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetNodeToLabelsRetrieved(){
-    return totalSucceededGetNodeToLabelsRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetLabelsToNodesRetrieved(){
-    return totalSucceededGetLabelsToNodesRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetClusterNodeLabelsRetrieved(){
-    return totalSucceededGetClusterNodeLabelsRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededAppAttemptReportRetrieved(){
-    return totalSucceededAppAttemptReportRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetQueueUserAclsRetrieved(){
-    return totalSucceededGetQueueUserAclsRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetContainerReportRetrieved() {
-    return totalSucceededGetContainerReportRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetContainersRetrieved() {
-    return totalSucceededGetContainersRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededListReservationsRetrieved() {
-    return totalSucceededListReservationsRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetResourceTypeInfoRetrieved() {
-    return totalSucceededGetResourceTypeInfoRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededFailAppAttemptRetrieved() {
-    return totalSucceededFailAppAttemptRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededUpdateAppPriorityRetrieved() {
-    return totalSucceededUpdateAppPriorityRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededUpdateAppTimeoutsRetrieved() {
-    return totalSucceededUpdateAppTimeoutsRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededSignalToContainerRetrieved() {
-    return totalSucceededSignalToContainerRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetQueueInfoRetrieved() {
-    return totalSucceededGetQueueInfoRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededMoveApplicationAcrossQueuesRetrieved() {
-    return totalSucceededMoveApplicationAcrossQueuesRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetResourceProfilesRetrieved() {
-    return totalSucceededGetResourceProfilesRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetResourceProfileRetrieved() {
-    return totalSucceededGetResourceProfileRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetAttributesToNodesRetrieved() {
-    return totalSucceededGetAttributesToNodesRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetClusterNodeAttributesRetrieved() {
-    return totalSucceededGetClusterNodeAttributesRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetNodesToAttributesRetrieved() {
-    return totalSucceededGetNodesToAttributesRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetNewReservationRetrieved() {
-    return totalSucceededGetNewReservationRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededSubmitReservationRetrieved() {
-    return totalSucceededSubmitReservationRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededUpdateReservationRetrieved() {
-    return totalSucceededUpdateReservationRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededDeleteReservationRetrieved() {
-    return totalSucceededDeleteReservationRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededListReservationRetrieved() {
-    return totalSucceededListReservationRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetAppActivitiesRetrieved() {
-    return totalSucceededGetAppActivitiesRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetAppStatisticsRetrieved() {
-    return totalSucceededGetAppStatisticsRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetAppPriorityRetrieved() {
-    return totalSucceededGetAppPriorityRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetAppQueueRetrieved() {
-    return totalSucceededGetAppQueueRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededUpdateAppQueueRetrieved() {
-    return totalSucceededUpdateAppQueueRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetAppTimeoutRetrieved() {
-    return totalSucceededGetAppTimeoutRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetAppTimeoutsRetrieved() {
-    return totalSucceededGetAppTimeoutsRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededRefreshQueuesRetrieved() {
-    return totalSucceededRefreshQueuesRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededRefreshNodesRetrieved() {
-    return totalSucceededRefreshNodesRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetRMNodeLabelsRetrieved() {
-    return totalSucceededGetRMNodeLabelsRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededCheckUserAccessToQueueRetrieved() {
-    return totalSucceededCheckUserAccessToQueueRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetDelegationTokenRetrieved() {
-    return totalSucceededGetDelegationTokenRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededRenewDelegationTokenRetrieved() {
-    return totalSucceededRenewDelegationTokenRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededCancelDelegationTokenRetrieved() {
-    return totalSucceededCancelDelegationTokenRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededDumpSchedulerLogsRetrieved() {
-    return totalSucceededDumpSchedulerLogsRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetActivitiesRetrieved() {
-    return totalSucceededGetActivitiesRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetBulkActivitiesRetrieved() {
-    return totalSucceededGetBulkActivitiesRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetSchedulerInfoRetrieved() {
-    return totalSucceededGetSchedulerInfoRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededDeregisterSubClusterRetrieved() {
-    return totalSucceededDeregisterSubClusterRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededSaveFederationQueuePolicyRetrieved() {
-    return totalSucceededSaveFederationQueuePolicyRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededBatchSaveFederationQueuePoliciesRetrieved() {
-    return totalSucceededBatchSaveFederationQueuePoliciesRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededListFederationQueuePoliciesFailedRetrieved() {
-    return totalSucceededListFederationQueuePoliciesFailedRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededDeleteFederationApplicationFailedRetrieved() {
-    return totalSucceededDeleteFederationApplicationFailedRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetFederationSubClustersRetrieved() {
-    return totalSucceededGetFederationSubClustersRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededDeleteFederationPoliciesByQueuesRetrieved() {
-    return totalSucceededDeleteFederationPoliciesByQueuesRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededRefreshAdminAclsRetrieved() {
-    return totalSucceededRefreshAdminAclsRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededRefreshServiceAclsRetrieved() {
-    return totalSucceededRefreshServiceAclsRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededAddToClusterNodeLabelsRetrieved() {
-    return totalSucceededAddToClusterNodeLabelsRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededRemoveFromClusterNodeLabelsRetrieved() {
-    return totalSucceededRemoveFromClusterNodeLabelsRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededUpdateSchedulerConfigurationRetrieved() {
-    return totalSucceededUpdateSchedulerConfigurationRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetSchedulerConfigurationRetrieved() {
-    return totalSucceededGetSchedulerConfigurationRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetClusterInfoRetrieved() {
-    return totalSucceededGetClusterInfoRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetClusterUserInfoRetrieved() {
-    return totalSucceededGetClusterUserInfoRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededUpdateNodeResourceRetrieved() {
-    return totalSucceededUpdateNodeResourceRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededRefreshNodesResourcesRetrieved() {
-    return totalSucceededRefreshNodesResourcesRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededCheckForDecommissioningNodesRetrieved() {
-    return totalSucceededCheckForDecommissioningNodesRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededRefreshClusterMaxPriorityRetrieved() {
-    return totalSucceededRefreshClusterMaxPriorityRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededMapAttributesToNodesRetrieved() {
-    return totalSucceededMapAttributesToNodesRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededGetGroupsForUsersRetrieved() {
-    return totalSucceededGetGroupsForUsersRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededRefreshSuperUserGroupsConfigurationRetrieved() {
-    return totalSucceededRefreshSuperUserGroupsConfigurationRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededReplaceLabelsOnNodesRetrieved() {
-    return totalSucceededReplaceLabelsOnNodesRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public long getNumSucceededReplaceLabelsOnNodeRetrieved() {
-    return totalSucceededReplaceLabelsOnNodeRetrieved.lastStat().numSamples();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededAppsCreated() {
-    return totalSucceededAppsCreated.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededAppsSubmitted() {
-    return totalSucceededAppsSubmitted.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededAppsKilled() {
-    return totalSucceededAppsKilled.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetAppAttemptReport() {
-    return totalSucceededAppAttemptReportRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetAppReport() {
-    return totalSucceededAppsRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededMultipleGetAppReport() {
-    return totalSucceededMultipleAppsRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetClusterMetricsRetrieved() {
-    return totalSucceededGetClusterMetricsRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetClusterNodesRetrieved() {
-    return totalSucceededGetClusterNodesRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetNodeToLabelsRetrieved() {
-    return totalSucceededGetNodeToLabelsRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetLabelsToNodesRetrieved() {
-    return totalSucceededGetLabelsToNodesRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetClusterNodeLabelsRetrieved() {
-    return totalSucceededGetClusterNodeLabelsRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededAppAttemptRetrieved() {
-    return totalSucceededAppAttemptsRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetQueueUserAclsRetrieved() {
-    return totalSucceededGetQueueUserAclsRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetContainerReportRetrieved() {
-    return totalSucceededGetContainerReportRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetContainersRetrieved() {
-    return totalSucceededGetContainersRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededListReservationsRetrieved() {
-    return totalSucceededListReservationsRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetResourceTypeInfoRetrieved() {
-    return totalSucceededGetResourceTypeInfoRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededFailAppAttemptRetrieved() {
-    return totalSucceededFailAppAttemptRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededUpdateAppPriorityRetrieved() {
-    return totalSucceededUpdateAppPriorityRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededUpdateAppTimeoutsRetrieved() {
-    return totalSucceededUpdateAppTimeoutsRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededSignalToContainerRetrieved() {
-    return totalSucceededSignalToContainerRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetQueueInfoRetrieved() {
-    return totalSucceededGetQueueInfoRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededMoveApplicationAcrossQueuesRetrieved() {
-    return totalSucceededMoveApplicationAcrossQueuesRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetResourceProfilesRetrieved() {
-    return totalSucceededGetResourceProfilesRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetResourceProfileRetrieved() {
-    return totalSucceededGetResourceProfileRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetAttributesToNodesRetrieved() {
-    return totalSucceededGetAttributesToNodesRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetClusterNodeAttributesRetrieved() {
-    return totalSucceededGetClusterNodeAttributesRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetNodesToAttributesRetrieved() {
-    return totalSucceededGetNodesToAttributesRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetNewReservationRetrieved() {
-    return totalSucceededGetNewReservationRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededSubmitReservationRetrieved() {
-    return totalSucceededSubmitReservationRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededUpdateReservationRetrieved() {
-    return totalSucceededUpdateReservationRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededDeleteReservationRetrieved() {
-    return totalSucceededDeleteReservationRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededListReservationRetrieved() {
-    return totalSucceededListReservationRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetAppActivitiesRetrieved() {
-    return totalSucceededGetAppActivitiesRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetAppStatisticsRetrieved() {
-    return totalSucceededGetAppStatisticsRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetAppPriorityRetrieved() {
-    return totalSucceededGetAppPriorityRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetAppQueueRetrieved() {
-    return totalSucceededGetAppQueueRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededUpdateAppQueueRetrieved() {
-    return totalSucceededUpdateAppQueueRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetAppTimeoutRetrieved() {
-    return totalSucceededGetAppTimeoutRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetAppTimeoutsRetrieved() {
-    return totalSucceededGetAppTimeoutsRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededRefreshQueuesRetrieved() {
-    return totalSucceededRefreshQueuesRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededRefreshNodesRetrieved() {
-    return totalSucceededRefreshNodesRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetRMNodeLabelsRetrieved() {
-    return totalSucceededGetRMNodeLabelsRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededCheckUserAccessToQueueRetrieved() {
-    return totalSucceededCheckUserAccessToQueueRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetDelegationTokenRetrieved() {
-    return totalSucceededGetDelegationTokenRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededRenewDelegationTokenRetrieved() {
-    return totalSucceededRenewDelegationTokenRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededCancelDelegationTokenRetrieved() {
-    return totalSucceededCancelDelegationTokenRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededDumpSchedulerLogsRetrieved() {
-    return totalSucceededDumpSchedulerLogsRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetActivitiesRetrieved() {
-    return totalSucceededGetActivitiesRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetBulkActivitiesRetrieved() {
-    return totalSucceededGetBulkActivitiesRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetSchedulerInfoRetrieved() {
-    return totalSucceededGetSchedulerInfoRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededDeregisterSubClusterRetrieved() {
-    return totalSucceededDeregisterSubClusterRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededSaveFederationQueuePolicyRetrieved() {
-    return totalSucceededSaveFederationQueuePolicyRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededBatchSaveFederationQueuePoliciesRetrieved() {
-    return totalSucceededBatchSaveFederationQueuePoliciesRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededListFederationQueuePoliciesRetrieved() {
-    return totalSucceededListFederationQueuePoliciesFailedRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededDeleteFederationApplicationFailedRetrieved() {
-    return totalSucceededDeleteFederationApplicationFailedRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetFederationSubClustersRetrieved() {
-    return totalSucceededGetFederationSubClustersRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededDeleteFederationPoliciesByQueuesRetrieved() {
-    return totalSucceededDeleteFederationPoliciesByQueuesRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededRefreshAdminAclsRetrieved() {
-    return totalSucceededRefreshAdminAclsRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededRefreshServiceAclsRetrieved() {
-    return totalSucceededRefreshServiceAclsRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededAddToClusterNodeLabelsRetrieved() {
-    return totalSucceededAddToClusterNodeLabelsRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededRemoveFromClusterNodeLabelsRetrieved() {
-    return totalSucceededRemoveFromClusterNodeLabelsRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededUpdateSchedulerConfigurationRetrieved() {
-    return totalSucceededUpdateSchedulerConfigurationRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetSchedulerConfigurationRetrieved() {
-    return totalSucceededGetSchedulerConfigurationRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetClusterInfoRetrieved() {
-    return totalSucceededGetClusterInfoRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetClusterUserInfoRetrieved() {
-    return totalSucceededGetClusterUserInfoRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededUpdateNodeResourceRetrieved() {
-    return totalSucceededUpdateNodeResourceRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededRefreshNodesResourcesRetrieved() {
-    return totalSucceededRefreshNodesResourcesRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededCheckForDecommissioningNodesRetrieved() {
-    return totalSucceededCheckForDecommissioningNodesRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededRefreshClusterMaxPriorityRetrieved() {
-    return totalSucceededRefreshClusterMaxPriorityRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededMapAttributesToNodesRetrieved() {
-    return totalSucceededMapAttributesToNodesRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededGetGroupsForUsersRetrieved() {
-    return totalSucceededGetGroupsForUsersRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededRefreshSuperUserGroupsConfigurationRetrieved() {
-    return totalSucceededRefreshSuperUserGroupsConfigurationRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededReplaceLabelsOnNodesRetrieved() {
-    return totalSucceededReplaceLabelsOnNodesRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public double getLatencySucceededReplaceLabelsOnNodeRetrieved() {
-    return totalSucceededReplaceLabelsOnNodeRetrieved.lastStat().mean();
-  }
-
-  @VisibleForTesting
-  public int getAppsFailedCreated() {
-    return numAppsFailedCreated.value();
-  }
-
-  @VisibleForTesting
-  public int getAppsFailedSubmitted() {
-    return numAppsFailedSubmitted.value();
-  }
-
-  @VisibleForTesting
-  public int getAppsFailedKilled() {
-    return numAppsFailedKilled.value();
-  }
-
-  @VisibleForTesting
-  public int getAppsFailedRetrieved() {
-    return numAppsFailedRetrieved.value();
-  }
-
-  @VisibleForTesting
-  public int getAppAttemptsFailedRetrieved() {
-    return numAppAttemptsFailedRetrieved.value();
-  }
-
-  @VisibleForTesting
-  public int getMultipleAppsFailedRetrieved() {
-    return numMultipleAppsFailedRetrieved.value();
-  }
-
-  @VisibleForTesting
-  public int getClusterMetricsFailedRetrieved() {
-    return numGetClusterMetricsFailedRetrieved.value();
-  }
-
-  @VisibleForTesting
-  public int getClusterNodesFailedRetrieved() {
-    return numGetClusterNodesFailedRetrieved.value();
-  }
-
-  @VisibleForTesting
-  public int getNodeToLabelsFailedRetrieved() {
-    return numGetNodeToLabelsFailedRetrieved.value();
-  }
-
-  @VisibleForTesting
-  public int getLabelsToNodesFailedRetrieved() {
-    return numGetLabelsToNodesFailedRetrieved.value();
-  }
-
-  @VisibleForTesting
-  public int getGetClusterNodeLabelsFailedRetrieved() {
-    return numGetClusterNodeLabelsFailedRetrieved.value();
-  }
-
-  @VisibleForTesting
-  public int getAppAttemptReportFailedRetrieved() {
-    return numAppAttemptReportFailedRetrieved.value();
-  }
-
-  @VisibleForTesting
-  public int getQueueUserAclsFailedRetrieved() {
-    return numGetQueueUserAclsFailedRetrieved.value();
-  }
-
-  @VisibleForTesting
-  public int getContainerReportFailedRetrieved() {
-    return numGetContainerReportFailedRetrieved.value();
-  }
-
-  @VisibleForTesting
-  public int getContainersFailedRetrieved() {
-    return numGetContainersFailedRetrieved.value();
-  }
-
-  @VisibleForTesting
-  public int getListReservationsFailedRetrieved() {
-    return numListReservationsFailedRetrieved.value();
-  }
-
-  @VisibleForTesting
-  public int getGetResourceTypeInfoRetrieved() {
-    return numGetResourceTypeInfo.value();
-  }
-
-  @VisibleForTesting
-  public int getFailApplicationAttemptFailedRetrieved() {
-    return numFailAppAttemptFailedRetrieved.value();
-  }
-
-  @VisibleForTesting
-  public int getUpdateApplicationPriorityFailedRetrieved() {
-    return numUpdateAppPriorityFailedRetrieved.value();
-  }
-
-  @VisibleForTesting
-  public int getUpdateApplicationTimeoutsFailedRetrieved() {
-    return numUpdateAppTimeoutsFailedRetrieved.value();
-  }
-
-  @VisibleForTesting
-  public int getSignalToContainerFailedRetrieved() {
-    return numSignalToContainerFailedRetrieved.value();
-  }
-
-  public int getQueueInfoFailedRetrieved() {
-    return numGetQueueInfoFailedRetrieved.value();
-  }
-
-  public int getMoveApplicationAcrossQueuesFailedRetrieved() {
-    return numMoveApplicationAcrossQueuesFailedRetrieved.value();
-  }
-
-  public int getResourceProfilesFailedRetrieved() {
-    return numGetResourceProfilesFailedRetrieved.value();
-  }
-
-  public int getResourceProfileFailedRetrieved() {
-    return numGetResourceProfileFailedRetrieved.value();
-  }
-
-  public int getAttributesToNodesFailedRetrieved() {
-    return numGetAttributesToNodesFailedRetrieved.value();
-  }
-
-  public int getClusterNodeAttributesFailedRetrieved() {
-    return numGetClusterNodeAttributesFailedRetrieved.value();
-  }
-
-  public int getNodesToAttributesFailedRetrieved() {
-    return numGetNodesToAttributesFailedRetrieved.value();
-  }
-
-  public int getNewReservationFailedRetrieved() {
-    return numGetNewReservationFailedRetrieved.value();
-  }
-
-  public int getSubmitReservationFailedRetrieved() {
-    return numSubmitReservationFailedRetrieved.value();
-  }
-
-  public int getUpdateReservationFailedRetrieved() {
-    return numUpdateReservationFailedRetrieved.value();
-  }
-
-  public int getDeleteReservationFailedRetrieved() {
-    return numDeleteReservationFailedRetrieved.value();
-  }
-
-  public int getListReservationFailedRetrieved() {
-    return numListReservationFailedRetrieved.value();
-  }
-
-  public int getAppActivitiesFailedRetrieved() {
-    return numGetAppActivitiesFailedRetrieved.value();
-  }
-
-  public int getAppStatisticsFailedRetrieved() {
-    return numGetAppStatisticsFailedRetrieved.value();
-  }
-
-  public int getAppPriorityFailedRetrieved() {
-    return numGetAppPriorityFailedRetrieved.value();
-  }
-
-  public int getAppQueueFailedRetrieved() {
-    return numGetAppQueueFailedRetrieved.value();
-  }
-
-  public int getUpdateAppQueueFailedRetrieved() {
-    return numUpdateAppQueueFailedRetrieved.value();
-  }
-
-  public int getAppTimeoutFailedRetrieved() {
-    return numGetAppTimeoutFailedRetrieved.value();
-  }
-
-  public int getAppTimeoutsFailedRetrieved() {
-    return numGetAppTimeoutsFailedRetrieved.value();
-  }
-
-
-  public int getRefreshQueuesFailedRetrieved() {
-    return numRefreshQueuesFailedRetrieved.value();
-  }
-
-  public int getRMNodeLabelsFailedRetrieved() {
-    return numGetRMNodeLabelsFailedRetrieved.value();
-  }
-
-  public int getCheckUserAccessToQueueFailedRetrieved() {
-    return numCheckUserAccessToQueueFailedRetrieved.value();
-  }
-
-  public int getNumRefreshNodesFailedRetrieved() {
-    return numRefreshNodesFailedRetrieved.value();
-  }
-
-  public int getNumRefreshSuperUserGroupsConfigurationFailedRetrieved() {
-    return numRefreshSuperUserGroupsConfigurationFailedRetrieved.value();
-  }
-
-  public int getNumRefreshUserToGroupsMappingsFailedRetrieved() {
-    return numRefreshUserToGroupsMappingsFailedRetrieved.value();
-  }
-
-  public int getDeregisterSubClusterFailedRetrieved() {
-    return numDeregisterSubClusterFailedRetrieved.value();
-  }
-
-  public int getSaveFederationQueuePolicyFailedRetrieved() {
-    return numSaveFederationQueuePolicyFailedRetrieved.value();
-  }
-
-  public int getBatchSaveFederationQueuePoliciesFailedRetrieved() {
-    return numBatchSaveFederationQueuePoliciesFailedRetrieved.value();
-  }
-
-  public int getListFederationQueuePoliciesFailedRetrieved() {
-    return numListFederationQueuePoliciesFailedRetrieved.value();
-  }
-
-  public int getDeleteFederationApplicationFailedRetrieved() {
-    return numDeleteFederationApplicationFailedRetrieved.value();
-  }
-
-  public int getFederationSubClustersFailedRetrieved() {
-    return numGetFederationSubClustersFailedRetrieved.value();
-  }
-
-  public int getDeleteFederationPoliciesByQueuesRetrieved() {
-    return numDeleteFederationPoliciesByQueuesRetrieved.value();
-  }
-
-  public int getNumRefreshAdminAclsFailedRetrieved() {
-    return numRefreshAdminAclsFailedRetrieved.value();
-  }
-
-  public int getNumRefreshServiceAclsFailedRetrieved() {
-    return numRefreshServiceAclsFailedRetrieved.value();
-  }
-
-  public int getNumReplaceLabelsOnNodesFailedRetrieved() {
-    return numReplaceLabelsOnNodesFailedRetrieved.value();
-  }
-
-  public int getNumReplaceLabelsOnNodeFailedRetrieved() {
-    return numReplaceLabelsOnNodeFailedRetrieved.value();
-  }
-
-  public int getNumAddToClusterNodeLabelsFailedRetrieved() {
-    return numAddToClusterNodeLabelsFailedRetrieved.value();
-  }
-
-  public int getNumRemoveFromClusterNodeLabelsFailedRetrieved() {
-    return numRemoveFromClusterNodeLabelsFailedRetrieved.value();
-  }
-
-  public int getUpdateSchedulerConfigurationFailedRetrieved() {
-    return numUpdateSchedulerConfigurationFailedRetrieved.value();
-  }
-
-  public int getSchedulerConfigurationFailedRetrieved() {
-    return numGetSchedulerConfigurationFailedRetrieved.value();
-  }
-
-  public int getClusterInfoFailedRetrieved() {
-    return numGetClusterInfoFailedRetrieved.value();
-  }
-
-  public int getClusterUserInfoFailedRetrieved() {
-    return numGetClusterUserInfoFailedRetrieved.value();
-  }
-
-  public int getUpdateNodeResourceFailedRetrieved() {
-    return numUpdateNodeResourceFailedRetrieved.value();
-  }
-
-  public int getRefreshNodesResourcesFailedRetrieved() {
-    return numRefreshNodesResourcesFailedRetrieved.value();
-  }
-
-  public int getCheckForDecommissioningNodesFailedRetrieved() {
-    return numCheckForDecommissioningNodesFailedRetrieved.value();
-  }
-
-  public int getRefreshClusterMaxPriorityFailedRetrieved() {
-    return numRefreshClusterMaxPriorityFailedRetrieved.value();
-  }
-
-  public int getMapAttributesToNodesFailedRetrieved() {
-    return numMapAttributesToNodesFailedRetrieved.value();
-  }
-
-  public int getGroupsForUserFailedRetrieved() {
-    return numGetGroupsForUserFailedRetrieved.value();
-  }
-
-  public int getDelegationTokenFailedRetrieved() {
-    return numGetDelegationTokenFailedRetrieved.value();
-  }
-
-  public int getRenewDelegationTokenFailedRetrieved() {
-    return numRenewDelegationTokenFailedRetrieved.value();
-  }
-
-  public int getCancelDelegationTokenFailedRetrieved() {
-    return numCancelDelegationTokenFailedRetrieved.value();
-  }
-
-  public int getDumpSchedulerLogsFailedRetrieved() {
-    return numDumpSchedulerLogsFailedRetrieved.value();
-  }
-
-  public int getActivitiesFailedRetrieved() {
-    return numGetActivitiesFailedRetrieved.value();
-  }
-
-  public int getBulkActivitiesFailedRetrieved(){
-    return numGetBulkActivitiesFailedRetrieved.value();
-  }
-
-  public int getSchedulerInfoFailedRetrieved() {
-    return numGetSchedulerInfoFailedRetrieved.value();
-  }
-
-  public void succeededAppsCreated(long duration) {
-    totalSucceededAppsCreated.add(duration);
-    getNewApplicationLatency.add(duration);
-  }
-
-  public void succeededAppsSubmitted(long duration) {
-    totalSucceededAppsSubmitted.add(duration);
-    submitApplicationLatency.add(duration);
-  }
-
-  public void succeededAppsKilled(long duration) {
-    totalSucceededAppsKilled.add(duration);
-    killApplicationLatency.add(duration);
-  }
-
-  public void succeededAppsRetrieved(long duration) {
-    totalSucceededAppsRetrieved.add(duration);
-    getApplicationReportLatency.add(duration);
-  }
-
-  public void succeededMultipleAppsRetrieved(long duration) {
-    totalSucceededMultipleAppsRetrieved.add(duration);
-    getApplicationsReportLatency.add(duration);
-  }
-
-  public void succeededAppAttemptsRetrieved(long duration) {
-    totalSucceededAppAttemptsRetrieved.add(duration);
-    getApplicationAttemptsLatency.add(duration);
-  }
-
-  public void succeededGetClusterMetricsRetrieved(long duration) {
-    totalSucceededGetClusterMetricsRetrieved.add(duration);
-    getClusterMetricsLatency.add(duration);
-  }
-
-  public void succeededGetClusterNodesRetrieved(long duration) {
-    totalSucceededGetClusterNodesRetrieved.add(duration);
-    getClusterNodesLatency.add(duration);
-  }
-
-  public void succeededGetNodeToLabelsRetrieved(long duration) {
-    totalSucceededGetNodeToLabelsRetrieved.add(duration);
-    getNodeToLabelsLatency.add(duration);
-  }
-
-  public void succeededGetLabelsToNodesRetrieved(long duration) {
-    totalSucceededGetLabelsToNodesRetrieved.add(duration);
-    getLabelToNodesLatency.add(duration);
-  }
-
-  public void succeededGetClusterNodeLabelsRetrieved(long duration) {
-    totalSucceededGetClusterNodeLabelsRetrieved.add(duration);
-    getClusterNodeLabelsLatency.add(duration);
-  }
-
-  public void succeededAppAttemptReportRetrieved(long duration) {
-    totalSucceededAppAttemptReportRetrieved.add(duration);
-    getApplicationAttemptReportLatency.add(duration);
-  }
-
-  public void succeededGetQueueUserAclsRetrieved(long duration) {
-    totalSucceededGetQueueUserAclsRetrieved.add(duration);
-    getQueueUserAclsLatency.add(duration);
-  }
-
-  public void succeededGetContainerReportRetrieved(long duration) {
-    totalSucceededGetContainerReportRetrieved.add(duration);
-    getContainerReportLatency.add(duration);
-  }
-
-  public void succeededGetContainersRetrieved(long duration) {
-    totalSucceededGetContainersRetrieved.add(duration);
-    getContainerLatency.add(duration);
-  }
-
-  public void succeededListReservationsRetrieved(long duration) {
-    totalSucceededListReservationsRetrieved.add(duration);
-    listReservationsLatency.add(duration);
-  }
-
-  public void succeededGetResourceTypeInfoRetrieved(long duration) {
-    totalSucceededGetResourceTypeInfoRetrieved.add(duration);
-    listResourceTypeInfoLatency.add(duration);
-  }
-
-  public void succeededFailAppAttemptRetrieved(long duration) {
-    totalSucceededFailAppAttemptRetrieved.add(duration);
-    failAppAttemptLatency.add(duration);
-  }
-
-  public void succeededUpdateAppPriorityRetrieved(long duration) {
-    totalSucceededUpdateAppPriorityRetrieved.add(duration);
-    updateAppPriorityLatency.add(duration);
-  }
-
-  public void succeededUpdateAppTimeoutsRetrieved(long duration) {
-    totalSucceededUpdateAppTimeoutsRetrieved.add(duration);
-    updateAppTimeoutsLatency.add(duration);
-  }
-
-  public void succeededSignalToContainerRetrieved(long duration) {
-    totalSucceededSignalToContainerRetrieved.add(duration);
-    signalToContainerLatency.add(duration);
-  }
-
-  public void succeededGetQueueInfoRetrieved(long duration) {
-    totalSucceededGetQueueInfoRetrieved.add(duration);
-    getQueueInfoLatency.add(duration);
-  }
-
-  public void succeededMoveApplicationAcrossQueuesRetrieved(long duration) {
-    totalSucceededMoveApplicationAcrossQueuesRetrieved.add(duration);
-    moveApplicationAcrossQueuesLatency.add(duration);
-  }
-
-  public void succeededGetResourceProfilesRetrieved(long duration) {
-    totalSucceededGetResourceProfilesRetrieved.add(duration);
-    getResourceProfilesLatency.add(duration);
-  }
-
-  public void succeededGetResourceProfileRetrieved(long duration) {
-    totalSucceededGetResourceProfileRetrieved.add(duration);
-    getResourceProfileLatency.add(duration);
-  }
-
-  public void succeededGetAttributesToNodesRetrieved(long duration) {
-    totalSucceededGetAttributesToNodesRetrieved.add(duration);
-    getAttributesToNodesLatency.add(duration);
-  }
-
-  public void succeededGetClusterNodeAttributesRetrieved(long duration) {
-    totalSucceededGetClusterNodeAttributesRetrieved.add(duration);
-    getClusterNodeAttributesLatency.add(duration);
-  }
-
-  public void succeededGetNodesToAttributesRetrieved(long duration) {
-    totalSucceededGetNodesToAttributesRetrieved.add(duration);
-    getNodesToAttributesLatency.add(duration);
-  }
-
-  public void succeededGetNewReservationRetrieved(long duration) {
-    totalSucceededGetNewReservationRetrieved.add(duration);
-    getNewReservationLatency.add(duration);
-  }
-
-  public void succeededSubmitReservationRetrieved(long duration) {
-    totalSucceededSubmitReservationRetrieved.add(duration);
-    submitReservationLatency.add(duration);
-  }
-
-  public void succeededUpdateReservationRetrieved(long duration) {
-    totalSucceededUpdateReservationRetrieved.add(duration);
-    updateReservationLatency.add(duration);
-  }
-
-  public void succeededDeleteReservationRetrieved(long duration) {
-    totalSucceededDeleteReservationRetrieved.add(duration);
-    deleteReservationLatency.add(duration);
-  }
-
-  public void succeededListReservationRetrieved(long duration) {
-    totalSucceededListReservationRetrieved.add(duration);
-    listReservationLatency.add(duration);
-  }
-
-  public void succeededGetAppActivitiesRetrieved(long duration) {
-    totalSucceededGetAppActivitiesRetrieved.add(duration);
-    getAppActivitiesLatency.add(duration);
-  }
-
-  public void succeededGetAppStatisticsRetrieved(long duration) {
-    totalSucceededGetAppStatisticsRetrieved.add(duration);
-    getAppStatisticsLatency.add(duration);
-  }
-
-  public void succeededGetAppPriorityRetrieved(long duration) {
-    totalSucceededGetAppPriorityRetrieved.add(duration);
-    getAppPriorityLatency.add(duration);
-  }
-
-  public void succeededGetAppQueueRetrieved(long duration) {
-    totalSucceededGetAppQueueRetrieved.add(duration);
-    getAppQueueLatency.add(duration);
-  }
-
-  public void succeededUpdateAppQueueRetrieved(long duration) {
-    totalSucceededUpdateAppQueueRetrieved.add(duration);
-    getUpdateQueueLatency.add(duration);
-  }
-
-  public void succeededGetAppTimeoutRetrieved(long duration) {
-    totalSucceededGetAppTimeoutRetrieved.add(duration);
-    getAppTimeoutLatency.add(duration);
-  }
-
-  public void succeededGetAppTimeoutsRetrieved(long duration) {
-    totalSucceededGetAppTimeoutsRetrieved.add(duration);
-    getAppTimeoutsLatency.add(duration);
-  }
-
-  public void succeededRefreshQueuesRetrieved(long duration) {
-    totalSucceededRefreshQueuesRetrieved.add(duration);
-    refreshQueuesLatency.add(duration);
-  }
-
-  public void succeededRefreshNodesRetrieved(long duration) {
-    totalSucceededRefreshNodesRetrieved.add(duration);
-    refreshNodesLatency.add(duration);
-  }
-
-  public void succeededGetRMNodeLabelsRetrieved(long duration) {
-    totalSucceededGetRMNodeLabelsRetrieved.add(duration);
-    getRMNodeLabelsLatency.add(duration);
-  }
-
-  public void succeededCheckUserAccessToQueueRetrieved(long duration) {
-    totalSucceededCheckUserAccessToQueueRetrieved.add(duration);
-    checkUserAccessToQueueLatency.add(duration);
-  }
-
-  public void succeededGetDelegationTokenRetrieved(long duration) {
-    totalSucceededGetDelegationTokenRetrieved.add(duration);
-    getDelegationTokenLatency.add(duration);
-  }
-
-  public void succeededRenewDelegationTokenRetrieved(long duration) {
-    totalSucceededRenewDelegationTokenRetrieved.add(duration);
-    renewDelegationTokenLatency.add(duration);
-  }
-
-  public void succeededCancelDelegationTokenRetrieved(long duration) {
-    totalSucceededCancelDelegationTokenRetrieved.add(duration);
-    cancelDelegationTokenLatency.add(duration);
-  }
-
-  public void succeededDumpSchedulerLogsRetrieved(long duration) {
-    totalSucceededDumpSchedulerLogsRetrieved.add(duration);
-    dumpSchedulerLogsLatency.add(duration);
-  }
-
-  public void succeededGetActivitiesLatencyRetrieved(long duration) {
-    totalSucceededGetActivitiesRetrieved.add(duration);
-    getActivitiesLatency.add(duration);
-  }
-
-  public void succeededGetBulkActivitiesRetrieved(long duration) {
-    totalSucceededGetBulkActivitiesRetrieved.add(duration);
-    getBulkActivitiesLatency.add(duration);
-  }
-
-  public void succeededGetSchedulerInfoRetrieved(long duration) {
-    totalSucceededGetSchedulerInfoRetrieved.add(duration);
-    getSchedulerInfoRetrievedLatency.add(duration);
-  }
-
-  public void succeededDeregisterSubClusterRetrieved(long duration) {
-    totalSucceededDeregisterSubClusterRetrieved.add(duration);
-    refreshDeregisterSubClusterLatency.add(duration);
-  }
-
-  public void succeededSaveFederationQueuePolicyRetrieved(long duration) {
-    totalSucceededSaveFederationQueuePolicyRetrieved.add(duration);
-    saveFederationQueuePolicyLatency.add(duration);
-  }
-
-  public void succeededBatchSaveFederationQueuePoliciesRetrieved(long duration) {
-    totalSucceededBatchSaveFederationQueuePoliciesRetrieved.add(duration);
-    batchSaveFederationQueuePoliciesLatency.add(duration);
-  }
-
-  public void succeededListFederationQueuePoliciesRetrieved(long duration) {
-    totalSucceededListFederationQueuePoliciesFailedRetrieved.add(duration);
-    listFederationQueuePoliciesLatency.add(duration);
-  }
-
-  public void succeededDeleteFederationApplicationFailedRetrieved(long duration) {
-    totalSucceededDeleteFederationApplicationFailedRetrieved.add(duration);
-    deleteFederationApplicationLatency.add(duration);
-  }
-
-  public void succeededGetFederationSubClustersRetrieved(long duration) {
-    totalSucceededGetFederationSubClustersRetrieved.add(duration);
-    getFederationSubClustersLatency.add(duration);
-  }
-
-  public void succeededDeleteFederationPoliciesByQueuesRetrieved(long duration) {
-    totalSucceededDeleteFederationPoliciesByQueuesRetrieved.add(duration);
-    deleteFederationPoliciesByQueuesLatency.add(duration);
-  }
-
-  public void succeededRefreshAdminAclsRetrieved(long duration) {
-    totalSucceededRefreshAdminAclsRetrieved.add(duration);
-    refreshAdminAclsLatency.add(duration);
-  }
-
-  public void succeededRefreshServiceAclsRetrieved(long duration) {
-    totalSucceededRefreshServiceAclsRetrieved.add(duration);
-    refreshServiceAclsLatency.add(duration);
-  }
-
-  public void succeededAddToClusterNodeLabelsRetrieved(long duration) {
-    totalSucceededAddToClusterNodeLabelsRetrieved.add(duration);
-    addToClusterNodeLabelsLatency.add(duration);
-  }
-
-  public void succeededRemoveFromClusterNodeLabelsRetrieved(long duration) {
-    totalSucceededRemoveFromClusterNodeLabelsRetrieved.add(duration);
-    removeFromClusterNodeLabelsLatency.add(duration);
-  }
-
-  public void succeededUpdateSchedulerConfigurationRetrieved(long duration) {
-    totalSucceededUpdateSchedulerConfigurationRetrieved.add(duration);
-    updateSchedulerConfigLatency.add(duration);
-  }
-
-  public void succeededGetSchedulerConfigurationRetrieved(long duration) {
-    totalSucceededGetSchedulerConfigurationRetrieved.add(duration);
-    getSchedulerConfigurationLatency.add(duration);
-  }
-
-  public void succeededGetClusterInfoRetrieved(long duration) {
-    totalSucceededGetClusterInfoRetrieved.add(duration);
-    getClusterInfoLatency.add(duration);
-  }
-
-  public void succeededGetClusterUserInfoRetrieved(long duration) {
-    totalSucceededGetClusterUserInfoRetrieved.add(duration);
-    getClusterUserInfoLatency.add(duration);
-  }
-
-  public void succeededUpdateNodeResourceRetrieved(long duration) {
-    totalSucceededUpdateNodeResourceRetrieved.add(duration);
-    updateNodeResourceLatency.add(duration);
-  }
-
-  public void succeededRefreshNodesResourcesRetrieved(long duration) {
-    totalSucceededRefreshNodesResourcesRetrieved.add(duration);
-    refreshNodesResourcesLatency.add(duration);
-  }
-
-  public void succeededCheckForDecommissioningNodesRetrieved(long duration) {
-    totalSucceededCheckForDecommissioningNodesRetrieved.add(duration);
-    checkForDecommissioningNodesLatency.add(duration);
-  }
-
-  public void succeededRefreshClusterMaxPriorityRetrieved(long duration) {
-    totalSucceededRefreshClusterMaxPriorityRetrieved.add(duration);
-    refreshClusterMaxPriorityLatency.add(duration);
-  }
-
-  public void succeededMapAttributesToNodesRetrieved(long duration) {
-    totalSucceededMapAttributesToNodesRetrieved.add(duration);
-    mapAttributesToNodesLatency.add(duration);
-  }
-
-  public void succeededGetGroupsForUsersRetrieved(long duration) {
-    totalSucceededGetGroupsForUsersRetrieved.add(duration);
-    getGroupsForUserLatency.add(duration);
-  }
-
-  public void succeededRefreshSuperUserGroupsConfRetrieved(long duration) {
-    totalSucceededRefreshSuperUserGroupsConfigurationRetrieved.add(duration);
-    refreshSuperUserGroupsConfLatency.add(duration);
-  }
-
-  public void succeededRefreshUserToGroupsMappingsRetrieved(long duration) {
-    totalSucceededRefreshUserToGroupsMappingsRetrieved.add(duration);
-    refreshUserToGroupsMappingsLatency.add(duration);
-  }
-
-  public void succeededReplaceLabelsOnNodesRetrieved(long duration) {
-    totalSucceededReplaceLabelsOnNodesRetrieved.add(duration);
-    replaceLabelsOnNodesLatency.add(duration);
-  }
-
-  public void succeededReplaceLabelsOnNodeRetrieved(long duration) {
-    totalSucceededReplaceLabelsOnNodeRetrieved.add(duration);
-    replaceLabelsOnNodeLatency.add(duration);
-  }
-
-  public void incrAppsFailedCreated() {
-    numAppsFailedCreated.incr();
-  }
-
-  public void incrAppsFailedSubmitted() {
-    numAppsFailedSubmitted.incr();
-  }
-
-  public void incrAppsFailedKilled() {
-    numAppsFailedKilled.incr();
-  }
-
-  public void incrAppsFailedRetrieved() {
-    numAppsFailedRetrieved.incr();
-  }
-
-  public void incrMultipleAppsFailedRetrieved() {
-    numMultipleAppsFailedRetrieved.incr();
-  }
-
-  public void incrAppAttemptsFailedRetrieved() {
-    numAppAttemptsFailedRetrieved.incr();
-  }
-
-  public void incrGetClusterMetricsFailedRetrieved() {
-    numGetClusterMetricsFailedRetrieved.incr();
-  }
-
-  public void incrClusterNodesFailedRetrieved() {
-    numGetClusterNodesFailedRetrieved.incr();
-  }
-
-  public void incrNodeToLabelsFailedRetrieved() {
-    numGetNodeToLabelsFailedRetrieved.incr();
-  }
-
-  public void incrLabelsToNodesFailedRetrieved() {
-    numGetLabelsToNodesFailedRetrieved.incr();
-  }
-
-  public void incrClusterNodeLabelsFailedRetrieved() {
-    numGetClusterNodeLabelsFailedRetrieved.incr();
-  }
-
-  public void incrAppAttemptReportFailedRetrieved() {
-    numAppAttemptReportFailedRetrieved.incr();
-  }
-
-  public void incrQueueUserAclsFailedRetrieved() {
-    numGetQueueUserAclsFailedRetrieved.incr();
-  }
-
-  public void incrGetContainerReportFailedRetrieved() {
-    numGetContainerReportFailedRetrieved.incr();
-  }
-
-  public void incrGetContainersFailedRetrieved() {
-    numGetContainersFailedRetrieved.incr();
-  }
-
-  public void incrListReservationsFailedRetrieved() {
-    numListReservationsFailedRetrieved.incr();
-  }
-
-  public void incrResourceTypeInfoFailedRetrieved() {
-    numGetResourceTypeInfo.incr();
-  }
-
-  public void incrFailAppAttemptFailedRetrieved() {
-    numFailAppAttemptFailedRetrieved.incr();
-  }
-
-  public void incrUpdateAppPriorityFailedRetrieved() {
-    numUpdateAppPriorityFailedRetrieved.incr();
-  }
-
-  public void incrUpdateApplicationTimeoutsRetrieved() {
-    numUpdateAppTimeoutsFailedRetrieved.incr();
-  }
-
-  public void incrSignalToContainerFailedRetrieved() {
-    numSignalToContainerFailedRetrieved.incr();
-  }
-
-  public void incrGetQueueInfoFailedRetrieved() {
-    numGetQueueInfoFailedRetrieved.incr();
-  }
-
-  public void incrMoveApplicationAcrossQueuesFailedRetrieved() {
-    numMoveApplicationAcrossQueuesFailedRetrieved.incr();
-  }
-
-  public void incrGetResourceProfilesFailedRetrieved() {
-    numGetResourceProfilesFailedRetrieved.incr();
-  }
-
-  public void incrGetResourceProfileFailedRetrieved() {
-    numGetResourceProfileFailedRetrieved.incr();
-  }
-
-  public void incrGetAttributesToNodesFailedRetrieved() {
-    numGetAttributesToNodesFailedRetrieved.incr();
-  }
-
-  public void incrGetClusterNodeAttributesFailedRetrieved() {
-    numGetClusterNodeAttributesFailedRetrieved.incr();
-  }
-
-  public void incrGetNodesToAttributesFailedRetrieved() {
-    numGetNodesToAttributesFailedRetrieved.incr();
-  }
-
-  public void incrGetNewReservationFailedRetrieved() {
-    numGetNewReservationFailedRetrieved.incr();
-  }
-
-  public void incrSubmitReservationFailedRetrieved() {
-    numSubmitReservationFailedRetrieved.incr();
-  }
-
-  public void incrUpdateReservationFailedRetrieved() {
-    numUpdateReservationFailedRetrieved.incr();
-  }
-
-  public void incrDeleteReservationFailedRetrieved() {
-    numDeleteReservationFailedRetrieved.incr();
-  }
-
-  public void incrListReservationFailedRetrieved() {
-    numListReservationFailedRetrieved.incr();
-  }
-
-  public void incrGetAppActivitiesFailedRetrieved() {
-    numGetAppActivitiesFailedRetrieved.incr();
-  }
-
-  public void incrGetAppStatisticsFailedRetrieved() {
-    numGetAppStatisticsFailedRetrieved.incr();
-  }
-
-  public void incrGetAppPriorityFailedRetrieved() {
-    numGetAppPriorityFailedRetrieved.incr();
-  }
-
-  public void incrGetAppQueueFailedRetrieved() {
-    numGetAppQueueFailedRetrieved.incr();
-  }
-
-  public void incrUpdateAppQueueFailedRetrieved() {
-    numUpdateAppQueueFailedRetrieved.incr();
-  }
-
-  public void incrGetAppTimeoutFailedRetrieved() {
-    numGetAppTimeoutFailedRetrieved.incr();
-  }
-
-  public void incrGetAppTimeoutsFailedRetrieved() {
-    numGetAppTimeoutsFailedRetrieved.incr();
-  }
-
-  public void incrRefreshQueuesFailedRetrieved() {
-    numRefreshQueuesFailedRetrieved.incr();
-  }
-
-  public void incrGetRMNodeLabelsFailedRetrieved() {
-    numGetRMNodeLabelsFailedRetrieved.incr();
-  }
-
-  public void incrCheckUserAccessToQueueFailedRetrieved() {
-    numCheckUserAccessToQueueFailedRetrieved.incr();
-  }
-
-  public void incrRefreshNodesFailedRetrieved() {
-    numRefreshNodesFailedRetrieved.incr();
-  }
-
-  public void incrRefreshSuperUserGroupsConfigurationFailedRetrieved() {
-    numRefreshSuperUserGroupsConfigurationFailedRetrieved.incr();
-  }
-
-  public void incrRefreshUserToGroupsMappingsFailedRetrieved() {
-    numRefreshUserToGroupsMappingsFailedRetrieved.incr();
-  }
-
-  public void incrDeregisterSubClusterFailedRetrieved() {
-    numDeregisterSubClusterFailedRetrieved.incr();
-  }
-
-  public void incrSaveFederationQueuePolicyFailedRetrieved() {
-    numSaveFederationQueuePolicyFailedRetrieved.incr();
-  }
-
-  public void incrBatchSaveFederationQueuePoliciesFailedRetrieved() {
-    numBatchSaveFederationQueuePoliciesFailedRetrieved.incr();
-  }
-
-  public void incrListFederationQueuePoliciesFailedRetrieved() {
-    numListFederationQueuePoliciesFailedRetrieved.incr();
-  }
-
-  public void incrDeleteFederationApplicationFailedRetrieved() {
-    numDeleteFederationApplicationFailedRetrieved.incr();
-  }
-
-  public void incrGetFederationSubClustersFailedRetrieved() {
-    numGetFederationSubClustersFailedRetrieved.incr();
-  }
-
-  public void incrDeleteFederationPoliciesByQueuesRetrieved() {
-    numDeleteFederationPoliciesByQueuesRetrieved.incr();
-  }
-
-  public void incrRefreshAdminAclsFailedRetrieved() {
-    numRefreshAdminAclsFailedRetrieved.incr();
-  }
-
-  public void incrRefreshServiceAclsFailedRetrieved() {
-    numRefreshServiceAclsFailedRetrieved.incr();
-  }
-
-  public void incrAddToClusterNodeLabelsFailedRetrieved() {
-    numAddToClusterNodeLabelsFailedRetrieved.incr();
-  }
-
-  public void incrRemoveFromClusterNodeLabelsFailedRetrieved() {
-    numRemoveFromClusterNodeLabelsFailedRetrieved.incr();
-  }
-
-  public void incrUpdateSchedulerConfigurationFailedRetrieved() {
-    numUpdateSchedulerConfigurationFailedRetrieved.incr();
-  }
-
-  public void incrGetSchedulerConfigurationFailedRetrieved() {
-    numGetSchedulerConfigurationFailedRetrieved.incr();
-  }
-
-  public void incrGetClusterInfoFailedRetrieved() {
-    numGetClusterInfoFailedRetrieved.incr();
-  }
-
-  public void incrGetClusterUserInfoFailedRetrieved() {
-    numGetClusterUserInfoFailedRetrieved.incr();
-  }
-
-  public void incrUpdateNodeResourceFailedRetrieved() {
-    numUpdateNodeResourceFailedRetrieved.incr();
-  }
-
-  public void incrRefreshNodesResourcesFailedRetrieved() {
-    numRefreshNodesResourcesFailedRetrieved.incr();
-  }
-
-  public void incrCheckForDecommissioningNodesFailedRetrieved() {
-    numCheckForDecommissioningNodesFailedRetrieved.incr();
-  }
-
-  public void incrRefreshClusterMaxPriorityFailedRetrieved() {
-    numRefreshClusterMaxPriorityFailedRetrieved.incr();
-  }
-
-  public void incrMapAttributesToNodesFailedRetrieved() {
-    numMapAttributesToNodesFailedRetrieved.incr();
-  }
-
-  public void incrGetGroupsForUserFailedRetrieved() {
-    numGetGroupsForUserFailedRetrieved.incr();
-  }
-
-  public void incrGetDelegationTokenFailedRetrieved() {
-    numGetDelegationTokenFailedRetrieved.incr();
-  }
-
-  public void incrRenewDelegationTokenFailedRetrieved() {
-    numRenewDelegationTokenFailedRetrieved.incr();
-  }
-
-  public void incrCancelDelegationTokenFailedRetrieved() {
-    numCancelDelegationTokenFailedRetrieved.incr();
-  }
-
-  public void incrReplaceLabelsOnNodesFailedRetrieved() {
-    numReplaceLabelsOnNodesFailedRetrieved.incr();
-  }
-
-  public void incrReplaceLabelsOnNodeFailedRetrieved() {
-    numReplaceLabelsOnNodeFailedRetrieved.incr();
-  }
-
-  public void incrDumpSchedulerLogsFailedRetrieved() {
-    numDumpSchedulerLogsFailedRetrieved.incr();
-  }
-
-  public void incrGetActivitiesFailedRetrieved() {
-    numGetActivitiesFailedRetrieved.incr();
-  }
-
-  public void incrGetBulkActivitiesFailedRetrieved() {
-    numGetBulkActivitiesFailedRetrieved.incr();
-  }
-
-  public void incrGetSchedulerInfoFailedRetrieved() {
-    numGetSchedulerInfoFailedRetrieved.incr();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/RouterServerUtil.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/RouterServerUtil.java
deleted file mode 100644
index 744ddc87050..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/RouterServerUtil.java
+++ /dev/null
@@ -1,833 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router;
-
-import org.apache.commons.collections.CollectionUtils;
-import org.apache.commons.lang3.math.NumberUtils;
-import org.apache.hadoop.classification.InterfaceAudience.Private;
-import org.apache.hadoop.classification.InterfaceAudience.Public;
-import org.apache.hadoop.classification.InterfaceStability.Unstable;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.conf.StorageUnit;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.security.token.Token;
-import org.apache.hadoop.thirdparty.protobuf.GeneratedMessageV3;
-import org.apache.hadoop.util.ReflectionUtils;
-import org.apache.hadoop.util.StringUtils;
-import org.apache.hadoop.yarn.api.records.ReservationRequest;
-import org.apache.hadoop.yarn.api.records.Priority;
-import org.apache.hadoop.yarn.api.records.ReservationRequestInterpreter;
-import org.apache.hadoop.yarn.api.records.Resource;
-import org.apache.hadoop.yarn.api.records.ReservationRequests;
-import org.apache.hadoop.yarn.api.records.impl.pb.ApplicationSubmissionContextPBImpl;
-import org.apache.hadoop.yarn.api.records.impl.pb.ContainerLaunchContextPBImpl;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto;
-import org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto;
-import org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto;
-import org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestInfo;
-import org.apache.hadoop.yarn.api.records.ReservationDefinition;
-import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;
-import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-import org.apache.hadoop.yarn.security.client.RMDelegationTokenIdentifier;
-import org.apache.hadoop.yarn.util.Records;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.ByteArrayOutputStream;
-import java.io.ObjectOutputStream;
-import java.lang.reflect.InvocationTargetException;
-import java.lang.reflect.Method;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.List;
-import java.util.EnumSet;
-import java.io.IOException;
-
-/**
- * Common utility methods used by the Router server.
- *
- */
-@Private
-@Unstable
-public final class RouterServerUtil {
-
-  private static final String APPLICATION_ID_PREFIX = "application_";
-
-  private static final String APP_ATTEMPT_ID_PREFIX = "appattempt_";
-
-  private static final String CONTAINER_PREFIX = "container_";
-
-  private static final String EPOCH_PREFIX = "e";
-
-  private static final String RESERVEIDSTR_PREFIX = "reservation_";
-
-  /** Disable constructor. */
-  private RouterServerUtil() {
-  }
-
-  public static final Logger LOG =
-      LoggerFactory.getLogger(RouterServerUtil.class);
-
-  /**
-   * Throws an exception due to an error.
-   *
-   * @param t the throwable raised in the called class.
-   * @param errMsgFormat the error message format string.
-   * @param args referenced by the format specifiers in the format string.
-   * @throws YarnException on failure
-   */
-  @Public
-  @Unstable
-  public static void logAndThrowException(Throwable t, String errMsgFormat, Object... args)
-      throws YarnException {
-    String msg = String.format(errMsgFormat, args);
-    if (t != null) {
-      String newErrMsg = getErrorMsg(msg, t);
-      LOG.error(newErrMsg, t);
-      throw new YarnException(newErrMsg, t);
-    } else {
-      LOG.error(msg);
-      throw new YarnException(msg);
-    }
-  }
-
-  /**
-   * Throws an exception due to an error.
-   *
-   * @param errMsg the error message
-   * @param t the throwable raised in the called class.
-   * @throws YarnException on failure
-   */
-  @Public
-  @Unstable
-  public static void logAndThrowException(String errMsg, Throwable t)
-      throws YarnException {
-    if (t != null) {
-      String newErrMsg = getErrorMsg(errMsg, t);
-      LOG.error(newErrMsg, t);
-      throw new YarnException(newErrMsg, t);
-    } else {
-      LOG.error(errMsg);
-      throw new YarnException(errMsg);
-    }
-  }
-
-  /**
-   * Throws an exception due to an error.
-   *
-   * @param errMsg the error message
-   * @throws YarnException on failure
-   */
-  @Public
-  @Unstable
-  public static void logAndThrowException(String errMsg) throws YarnException {
-    LOG.error(errMsg);
-    throw new YarnException(errMsg);
-  }
-
-  private static String getErrorMsg(String errMsg, Throwable t) {
-    if (t.getMessage() != null) {
-      return errMsg + "" + t.getMessage();
-    }
-    return errMsg;
-  }
-
-  public static <R> R createRequestInterceptorChain(Configuration conf, String pipeLineClassName,
-      String interceptorClassName, Class<R> clazz) {
-
-    List<String> interceptorClassNames = getInterceptorClassNames(conf,
-        pipeLineClassName, interceptorClassName);
-
-    R pipeline = null;
-    R current = null;
-
-    for (String className : interceptorClassNames) {
-      try {
-        Class<?> interceptorClass = conf.getClassByName(className);
-        if (clazz.isAssignableFrom(interceptorClass)) {
-          Object interceptorInstance = ReflectionUtils.newInstance(interceptorClass, conf);
-          if (pipeline == null) {
-            pipeline = clazz.cast(interceptorInstance);
-            current = clazz.cast(interceptorInstance);
-            continue;
-          } else {
-            Method method = clazz.getMethod("setNextInterceptor", clazz);
-            method.invoke(current, interceptorInstance);
-            current = clazz.cast(interceptorInstance);
-          }
-        } else {
-          LOG.error("Class: {} not instance of {}.", className, clazz.getCanonicalName());
-          throw new YarnRuntimeException("Class: " + className + " not instance of "
-              + clazz.getCanonicalName());
-        }
-      } catch (ClassNotFoundException e) {
-        LOG.error("Could not instantiate RequestInterceptor: {}", className, e);
-        throw new YarnRuntimeException("Could not instantiate RequestInterceptor: " + className, e);
-      } catch (InvocationTargetException e) {
-        LOG.error("RequestInterceptor {} call setNextInterceptor error.", className, e);
-        throw new YarnRuntimeException("RequestInterceptor " + className
-            + " call setNextInterceptor error.", e);
-      } catch (NoSuchMethodException e) {
-        LOG.error("RequestInterceptor {} does not contain the method setNextInterceptor.",
-            className);
-        throw new YarnRuntimeException("RequestInterceptor " + className +
-            " does not contain the method setNextInterceptor.", e);
-      } catch (IllegalAccessException e) {
-        LOG.error("RequestInterceptor {} call the method setNextInterceptor " +
-            "does not have access.", className);
-        throw new YarnRuntimeException("RequestInterceptor "
-            + className + " call the method setNextInterceptor does not have access.", e);
-      }
-    }
-
-    if (pipeline == null) {
-      throw new YarnRuntimeException(
-          "RequestInterceptor pipeline is not configured in the system.");
-    }
-
-    return pipeline;
-  }
-
-  private static List<String> getInterceptorClassNames(Configuration conf,
-      String pipeLineClass, String interceptorClass) {
-    String configuredInterceptorClassNames = conf.get(pipeLineClass, interceptorClass);
-    List<String> interceptorClassNames = new ArrayList<>();
-    Collection<String> tempList =
-        StringUtils.getStringCollection(configuredInterceptorClassNames);
-    for (String item : tempList) {
-      interceptorClassNames.add(item.trim());
-    }
-    return interceptorClassNames;
-  }
-
-  /**
-   * Throws an IOException due to an error.
-   *
-   * @param errMsg the error message
-   * @param t the throwable raised in the called class.
-   * @throws IOException on failure
-   */
-  @Public
-  @Unstable
-  public static void logAndThrowIOException(String errMsg, Throwable t)
-      throws IOException {
-    if (t != null) {
-      String newErrMsg = getErrorMsg(errMsg, t);
-      LOG.error(newErrMsg, t);
-      throw new IOException(newErrMsg, t);
-    } else {
-      LOG.error(errMsg);
-      throw new IOException(errMsg);
-    }
-  }
-
-  /**
-   * Throws an IOException due to an error.
-   *
-   * @param t the throwable raised in the called class.
-   * @param errMsgFormat the error message format string.
-   * @param args referenced by the format specifiers in the format string.
-   * @throws IOException on failure
-   */
-  @Public
-  @Unstable
-  public static void logAndThrowIOException(Throwable t, String errMsgFormat, Object... args)
-      throws IOException {
-    String msg = String.format(errMsgFormat, args);
-    if (t != null) {
-      String newErrMsg = getErrorMsg(msg, t);
-      LOG.error(newErrMsg, t);
-      throw new IOException(newErrMsg, t);
-    } else {
-      LOG.error(msg);
-      throw new IOException(msg);
-    }
-  }
-
-  /**
-   * Throws an RunTimeException due to an error.
-   *
-   * @param errMsg the error message
-   * @param t the throwable raised in the called class.
-   * @throws RuntimeException on failure
-   */
-  @Public
-  @Unstable
-  public static void logAndThrowRunTimeException(String errMsg, Throwable t)
-      throws RuntimeException {
-    if (t != null) {
-      String newErrMsg = getErrorMsg(errMsg, t);
-      LOG.error(newErrMsg, t);
-      throw new RuntimeException(newErrMsg, t);
-    } else {
-      LOG.error(errMsg);
-      throw new RuntimeException(errMsg);
-    }
-  }
-
-  /**
-   * Throws an RunTimeException due to an error.
-   *
-   * @param t the throwable raised in the called class.
-   * @param errMsgFormat the error message format string.
-   * @param args referenced by the format specifiers in the format string.
-   * @throws RuntimeException on failure
-   */
-  @Public
-  @Unstable
-  public static void logAndThrowRunTimeException(Throwable t, String errMsgFormat, Object... args)
-      throws RuntimeException {
-    String msg = String.format(errMsgFormat, args);
-    if (t != null) {
-      String newErrMsg = getErrorMsg(msg, t);
-      LOG.error(newErrMsg, t);
-      throw new RuntimeException(newErrMsg, t);
-    } else {
-      LOG.error(msg);
-      throw new RuntimeException(msg);
-    }
-  }
-
-  /**
-   * Throws an RunTimeException due to an error.
-   *
-   * @param t the throwable raised in the called class.
-   * @param errMsgFormat the error message format string.
-   * @param args referenced by the format specifiers in the format string.
-   * @return RuntimeException
-   */
-  @Public
-  @Unstable
-  public static RuntimeException logAndReturnRunTimeException(
-      Throwable t, String errMsgFormat, Object... args) {
-    String msg = String.format(errMsgFormat, args);
-    if (t != null) {
-      String newErrMsg = getErrorMsg(msg, t);
-      LOG.error(newErrMsg, t);
-      return new RuntimeException(newErrMsg, t);
-    } else {
-      LOG.error(msg);
-      return new RuntimeException(msg);
-    }
-  }
-
-  /**
-   * Throws an RunTimeException due to an error.
-   *
-   * @param errMsgFormat the error message format string.
-   * @param args referenced by the format specifiers in the format string.
-   * @return RuntimeException
-   */
-  @Public
-  @Unstable
-  public static RuntimeException logAndReturnRunTimeException(
-      String errMsgFormat, Object... args) {
-    return logAndReturnRunTimeException(null, errMsgFormat, args);
-  }
-
-  /**
-   * Throws an YarnRuntimeException due to an error.
-   *
-   * @param t the throwable raised in the called class.
-   * @param errMsgFormat the error message format string.
-   * @param args referenced by the format specifiers in the format string.
-   * @return YarnRuntimeException
-   */
-  @Public
-  @Unstable
-  public static YarnRuntimeException logAndReturnYarnRunTimeException(
-      Throwable t, String errMsgFormat, Object... args) {
-    String msg = String.format(errMsgFormat, args);
-    if (t != null) {
-      String newErrMsg = getErrorMsg(msg, t);
-      LOG.error(newErrMsg, t);
-      return new YarnRuntimeException(newErrMsg, t);
-    } else {
-      LOG.error(msg);
-      return new YarnRuntimeException(msg);
-    }
-  }
-
-  /**
-   * Check applicationId is accurate.
-   *
-   * We need to ensure that applicationId cannot be empty and
-   * can be converted to ApplicationId object normally.
-   *
-   * @param applicationId applicationId of type string
-   * @throws IllegalArgumentException If the format of the applicationId is not accurate,
-   * an IllegalArgumentException needs to be thrown.
-   */
-  @Public
-  @Unstable
-  public static void validateApplicationId(String applicationId)
-      throws IllegalArgumentException {
-
-    // Make Sure applicationId is not empty.
-    if (applicationId == null || applicationId.isEmpty()) {
-      throw new IllegalArgumentException("Parameter error, the appId is empty or null.");
-    }
-
-    // Make sure the prefix information of applicationId is accurate.
-    if (!applicationId.startsWith(APPLICATION_ID_PREFIX)) {
-      throw new IllegalArgumentException("Invalid ApplicationId prefix: "
-          + applicationId + ". The valid ApplicationId should start with prefix application");
-    }
-
-    // Check the split position of the string.
-    int pos1 = APPLICATION_ID_PREFIX.length() - 1;
-    int pos2 = applicationId.indexOf('_', pos1 + 1);
-    if (pos2 < 0) {
-      throw new IllegalArgumentException("Invalid ApplicationId: " + applicationId);
-    }
-
-    // Confirm that the parsed rmId and appId are numeric types.
-    String rmId = applicationId.substring(pos1 + 1, pos2);
-    String appId = applicationId.substring(pos2 + 1);
-    if(!NumberUtils.isDigits(rmId) || !NumberUtils.isDigits(appId)){
-      throw new IllegalArgumentException("Invalid ApplicationId: " + applicationId);
-    }
-  }
-
-  /**
-   * Check appAttemptId is accurate.
-   *
-   * We need to ensure that appAttemptId cannot be empty and
-   * can be converted to ApplicationAttemptId object normally.
-   *
-   * @param appAttemptId appAttemptId of type string.
-   * @throws IllegalArgumentException If the format of the appAttemptId is not accurate,
-   * an IllegalArgumentException needs to be thrown.
-   */
-  @Public
-  @Unstable
-  public static void validateApplicationAttemptId(String appAttemptId)
-      throws IllegalArgumentException {
-
-    // Make Sure appAttemptId is not empty.
-    if (appAttemptId == null || appAttemptId.isEmpty()) {
-      throw new IllegalArgumentException("Parameter error, the appAttemptId is empty or null.");
-    }
-
-    // Make sure the prefix information of appAttemptId is accurate.
-    if (!appAttemptId.startsWith(APP_ATTEMPT_ID_PREFIX)) {
-      throw new IllegalArgumentException("Invalid AppAttemptId prefix: " + appAttemptId);
-    }
-
-    // Check the split position of the string.
-    int pos1 = APP_ATTEMPT_ID_PREFIX.length() - 1;
-    int pos2 = appAttemptId.indexOf('_', pos1 + 1);
-    if (pos2 < 0) {
-      throw new IllegalArgumentException("Invalid AppAttemptId: " + appAttemptId);
-    }
-    int pos3 = appAttemptId.indexOf('_', pos2 + 1);
-    if (pos3 < 0) {
-      throw new IllegalArgumentException("Invalid AppAttemptId: " + appAttemptId);
-    }
-
-    // Confirm that the parsed rmId and appId and attemptId are numeric types.
-    String rmId = appAttemptId.substring(pos1 + 1, pos2);
-    String appId = appAttemptId.substring(pos2 + 1, pos3);
-    String attemptId = appAttemptId.substring(pos3 + 1);
-
-    if (!NumberUtils.isDigits(rmId) || !NumberUtils.isDigits(appId)
-        || !NumberUtils.isDigits(attemptId)) {
-      throw new IllegalArgumentException("Invalid AppAttemptId: " + appAttemptId);
-    }
-  }
-
-  /**
-   * Check containerId is accurate.
-   *
-   * We need to ensure that containerId cannot be empty and
-   * can be converted to ContainerId object normally.
-   *
-   * @param containerId containerId of type string.
-   * @throws IllegalArgumentException If the format of the appAttemptId is not accurate,
-   * an IllegalArgumentException needs to be thrown.
-   */
-  @Public
-  @Unstable
-  public static void validateContainerId(String containerId)
-      throws IllegalArgumentException {
-
-    // Make Sure containerId is not empty.
-    if (containerId == null || containerId.isEmpty()) {
-      throw new IllegalArgumentException("Parameter error, the containerId is empty or null.");
-    }
-
-    // Make sure the prefix information of containerId is accurate.
-    if (!containerId.startsWith(CONTAINER_PREFIX)) {
-      throw new IllegalArgumentException("Invalid ContainerId prefix: " + containerId);
-    }
-
-    // Check the split position of the string.
-    int pos1 = CONTAINER_PREFIX.length() - 1;
-
-    String epoch = "0";
-    if (containerId.regionMatches(pos1 + 1, EPOCH_PREFIX, 0, EPOCH_PREFIX.length())) {
-      int pos2 = containerId.indexOf('_', pos1 + 1);
-      if (pos2 < 0) {
-        throw new IllegalArgumentException("Invalid ContainerId: " + containerId);
-      }
-      String epochStr = containerId.substring(pos1 + 1 + EPOCH_PREFIX.length(), pos2);
-      epoch = epochStr;
-      // rewind the current position
-      pos1 = pos2;
-    }
-
-    int pos2 = containerId.indexOf('_', pos1 + 1);
-    if (pos2 < 0) {
-      throw new IllegalArgumentException("Invalid ContainerId: " + containerId);
-    }
-
-    int pos3 = containerId.indexOf('_', pos2 + 1);
-    if (pos3 < 0) {
-      throw new IllegalArgumentException("Invalid ContainerId: " + containerId);
-    }
-
-    int pos4 = containerId.indexOf('_', pos3 + 1);
-    if (pos4 < 0) {
-      throw new IllegalArgumentException("Invalid ContainerId: " + containerId);
-    }
-
-    // Confirm that the parsed appId and clusterTimestamp and attemptId and cid and epoch
-    // are numeric types.
-    String appId = containerId.substring(pos2 + 1, pos3);
-    String clusterTimestamp = containerId.substring(pos1 + 1, pos2);
-    String attemptId = containerId.substring(pos3 + 1, pos4);
-    String cid = containerId.substring(pos4 + 1);
-
-    if (!NumberUtils.isDigits(appId) || !NumberUtils.isDigits(clusterTimestamp)
-        || !NumberUtils.isDigits(attemptId) || !NumberUtils.isDigits(cid)
-        || !NumberUtils.isDigits(epoch)) {
-      throw new IllegalArgumentException("Invalid ContainerId: " + containerId);
-    }
-  }
-
-  public static boolean isAllowedDelegationTokenOp() throws IOException {
-    if (UserGroupInformation.isSecurityEnabled()) {
-      return EnumSet.of(UserGroupInformation.AuthenticationMethod.KERBEROS,
-          UserGroupInformation.AuthenticationMethod.KERBEROS_SSL,
-          UserGroupInformation.AuthenticationMethod.CERTIFICATE)
-          .contains(UserGroupInformation.getCurrentUser()
-          .getRealAuthenticationMethod());
-    } else {
-      return true;
-    }
-  }
-
-  public static String getRenewerForToken(Token<RMDelegationTokenIdentifier> token)
-      throws IOException {
-    UserGroupInformation user = UserGroupInformation.getCurrentUser();
-    UserGroupInformation loginUser = UserGroupInformation.getLoginUser();
-    // we can always renew our own tokens
-    return loginUser.getUserName().equals(user.getUserName())
-        ? token.decodeIdentifier().getRenewer().toString() : user.getShortUserName();
-  }
-
-  /**
-   * Set User information.
-   *
-   * If the username is empty, we will use the Yarn Router user directly.
-   * Do not create a proxy user if userName matches the userName on current UGI.
-   *
-   * @param userName userName.
-   * @return UserGroupInformation.
-   */
-  public static UserGroupInformation setupUser(final String userName) {
-    UserGroupInformation user = null;
-    try {
-      // If userName is empty, we will return UserGroupInformation.getCurrentUser.
-      // Do not create a proxy user if user name matches the user name on
-      // current UGI
-      if (userName == null || userName.trim().isEmpty()) {
-        user = UserGroupInformation.getCurrentUser();
-      } else if (UserGroupInformation.isSecurityEnabled()) {
-        user = UserGroupInformation.createProxyUser(userName, UserGroupInformation.getLoginUser());
-      } else if (userName.equalsIgnoreCase(UserGroupInformation.getCurrentUser().getUserName())) {
-        user = UserGroupInformation.getCurrentUser();
-      } else {
-        user = UserGroupInformation.createProxyUser(userName,
-            UserGroupInformation.getCurrentUser());
-      }
-      return user;
-    } catch (IOException e) {
-      throw RouterServerUtil.logAndReturnYarnRunTimeException(e,
-          "Error while creating Router Service for user : %s.", user);
-    }
-  }
-
-  /**
-   * Check reservationId is accurate.
-   *
-   * We need to ensure that reservationId cannot be empty and
-   * can be converted to ReservationId object normally.
-   *
-   * @param reservationId reservationId.
-   * @throws IllegalArgumentException If the format of the reservationId is not accurate,
-   * an IllegalArgumentException needs to be thrown.
-   */
-  @Public
-  @Unstable
-  public static void validateReservationId(String reservationId) throws IllegalArgumentException {
-
-    if (reservationId == null || reservationId.isEmpty()) {
-      throw new IllegalArgumentException("Parameter error, the reservationId is empty or null.");
-    }
-
-    if (!reservationId.startsWith(RESERVEIDSTR_PREFIX)) {
-      throw new IllegalArgumentException("Invalid ReservationId: " + reservationId);
-    }
-
-    String[] resFields = reservationId.split("_");
-    if (resFields.length != 3) {
-      throw new IllegalArgumentException("Invalid ReservationId: " + reservationId);
-    }
-
-    String clusterTimestamp = resFields[1];
-    String id = resFields[2];
-    if (!NumberUtils.isDigits(id) || !NumberUtils.isDigits(clusterTimestamp)) {
-      throw new IllegalArgumentException("Invalid ReservationId: " + reservationId);
-    }
-  }
-
-  /**
-   * Convert ReservationDefinitionInfo to ReservationDefinition.
-   *
-   * @param definitionInfo ReservationDefinitionInfo Object.
-   * @return ReservationDefinition.
-   */
-  public static ReservationDefinition convertReservationDefinition(
-      ReservationDefinitionInfo definitionInfo) {
-    if (definitionInfo == null || definitionInfo.getReservationRequests() == null
-        || definitionInfo.getReservationRequests().getReservationRequest() == null
-        || definitionInfo.getReservationRequests().getReservationRequest().isEmpty()) {
-      throw new RuntimeException("definitionInfo Or ReservationRequests is Null.");
-    }
-
-    // basic variable
-    long arrival = definitionInfo.getArrival();
-    long deadline = definitionInfo.getDeadline();
-
-    // ReservationRequests reservationRequests
-    String name = definitionInfo.getReservationName();
-    String recurrenceExpression = definitionInfo.getRecurrenceExpression();
-    Priority priority = Priority.newInstance(definitionInfo.getPriority());
-
-    // reservation requests info
-    List<ReservationRequest> reservationRequestList = new ArrayList<>();
-
-    ReservationRequestsInfo reservationRequestsInfo = definitionInfo.getReservationRequests();
-
-    List<ReservationRequestInfo> reservationRequestInfos =
-        reservationRequestsInfo.getReservationRequest();
-
-    for (ReservationRequestInfo resRequestInfo : reservationRequestInfos) {
-      ResourceInfo resourceInfo = resRequestInfo.getCapability();
-      Resource capability =
-          Resource.newInstance(resourceInfo.getMemorySize(), resourceInfo.getvCores());
-      ReservationRequest reservationRequest = ReservationRequest.newInstance(capability,
-          resRequestInfo.getNumContainers(), resRequestInfo.getMinConcurrency(),
-          resRequestInfo.getDuration());
-      reservationRequestList.add(reservationRequest);
-    }
-
-    ReservationRequestInterpreter[] values = ReservationRequestInterpreter.values();
-    ReservationRequestInterpreter reservationRequestInterpreter =
-        values[reservationRequestsInfo.getReservationRequestsInterpreter()];
-    ReservationRequests reservationRequests = ReservationRequests.newInstance(
-        reservationRequestList, reservationRequestInterpreter);
-
-    ReservationDefinition definition = ReservationDefinition.newInstance(
-        arrival, deadline, reservationRequests, name, recurrenceExpression, priority);
-
-    return definition;
-  }
-
-  /**
-   * Checks if the ApplicationSubmissionContext submitted with the application
-   * is valid.
-   *
-   * Current checks:
-   * - if its size is within limits.
-   *
-   * @param appContext the app context to check.
-   * @param conf Configuration.
-   * @throws IOException if an IO error occurred.
-   * @throws YarnException yarn exception.
-   */
-  @Public
-  @Unstable
-  public static void checkAppSubmissionContext(ApplicationSubmissionContextPBImpl appContext,
-      Configuration conf) throws IOException, YarnException {
-    // Prevents DoS over the ApplicationClientProtocol by checking the context
-    // the application was submitted with for any excessively large fields.
-    double bytesOfMaxAscSize = conf.getStorageSize(
-        YarnConfiguration.ROUTER_ASC_INTERCEPTOR_MAX_SIZE,
-        YarnConfiguration.DEFAULT_ROUTER_ASC_INTERCEPTOR_MAX_SIZE, StorageUnit.BYTES);
-    if (appContext != null) {
-      int bytesOfSerializedSize = appContext.getProto().getSerializedSize();
-      if (bytesOfSerializedSize >= bytesOfMaxAscSize) {
-        logContainerLaunchContext(appContext);
-        String applicationId = appContext.getApplicationId().toString();
-        String limit = StringUtils.byteDesc((long) bytesOfMaxAscSize);
-        String appContentSize = StringUtils.byteDesc(bytesOfSerializedSize);
-        String errMsg = String.format(
-            "The size of the ApplicationSubmissionContext of the application %s is " +
-            "above the limit %s, size = %s.", applicationId, limit, appContentSize);
-        LOG.error(errMsg);
-        throw new YarnException(errMsg);
-      }
-    }
-  }
-
-  /**
-   * Private helper for checkAppSubmissionContext that logs the fields in the
-   * context for debugging.
-   *
-   * @param appContext the app context.
-   * @throws IOException if an IO error occurred.
-   */
-  @Private
-  @Unstable
-  private static void logContainerLaunchContext(ApplicationSubmissionContextPBImpl appContext)
-      throws IOException {
-    if (appContext == null || appContext.getAMContainerSpec() == null ||
-        !(appContext.getAMContainerSpec() instanceof ContainerLaunchContextPBImpl)) {
-      return;
-    }
-
-    ContainerLaunchContext launchContext = appContext.getAMContainerSpec();
-    ContainerLaunchContextPBImpl clc = (ContainerLaunchContextPBImpl) launchContext;
-    LOG.warn("ContainerLaunchContext size: {}.", clc.getProto().getSerializedSize());
-
-    // ContainerLaunchContext contains:
-    // 1) Map<String, LocalResource> localResources,
-    List<StringLocalResourceMapProto> lrs = clc.getProto().getLocalResourcesList();
-    logContainerLaunchContext("LocalResource size: {}. Length: {}.", lrs);
-
-    // 2) Map<String, String> environment, List<String> commands,
-    List<StringStringMapProto> envs = clc.getProto().getEnvironmentList();
-    logContainerLaunchContext("Environment size: {}. Length: {}.", envs);
-
-    List<String> cmds = clc.getCommands();
-    if (CollectionUtils.isNotEmpty(cmds)) {
-      LOG.warn("Commands size: {}. Length: {}.", cmds.size(), serialize(cmds).length);
-    }
-
-    // 3) Map<String, ByteBuffer> serviceData,
-    List<StringBytesMapProto> serviceData = clc.getProto().getServiceDataList();
-    logContainerLaunchContext("ServiceData size: {}. Length: {}.", serviceData);
-
-    // 4) Map<ApplicationAccessType, String> acls
-    List<ApplicationACLMapProto> acls = clc.getProto().getApplicationACLsList();
-    logContainerLaunchContext("ACLs size: {}. Length: {}.", acls);
-  }
-
-  /**
-   * Log ContainerLaunchContext Data SerializedSize.
-   *
-   * @param format format of logging.
-   * @param lists data list.
-   * @param <R> generic type R.
-   */
-  private static <R extends GeneratedMessageV3> void logContainerLaunchContext(String format,
-      List<R> lists) {
-    if (CollectionUtils.isNotEmpty(lists)) {
-      int sumLength = 0;
-      for (R item : lists) {
-        sumLength += item.getSerializedSize();
-      }
-      LOG.warn(format, lists.size(), sumLength);
-    }
-  }
-
-  /**
-   * Serialize an object in ByteArray.
-   *
-   * @return obj ByteArray.
-   * @throws IOException if an IO error occurred.
-   */
-  @Private
-  @Unstable
-  private static byte[] serialize(Object obj) throws IOException {
-    try (ByteArrayOutputStream b = new ByteArrayOutputStream()) {
-      try (ObjectOutputStream o = new ObjectOutputStream(b)) {
-        o.writeObject(obj);
-      }
-      return b.toByteArray();
-    }
-  }
-
-  /**
-   * Get trimmed version of ApplicationSubmissionContext to be saved to
-   * Federation State Store.
-   *
-   * @param actualContext actual ApplicationSubmissionContext.
-   * @return trimmed ApplicationSubmissionContext.
-   */
-  @Private
-  @Unstable
-  public static ApplicationSubmissionContext getTrimmedAppSubmissionContext(
-      ApplicationSubmissionContext actualContext) {
-    if (actualContext == null) {
-      return null;
-    }
-
-    // Set Basic information
-    ApplicationSubmissionContext trimmedContext =
-        Records.newRecord(ApplicationSubmissionContext.class);
-    trimmedContext.setApplicationId(actualContext.getApplicationId());
-    trimmedContext.setApplicationName(actualContext.getApplicationName());
-    trimmedContext.setQueue(actualContext.getQueue());
-    trimmedContext.setPriority(actualContext.getPriority());
-    trimmedContext.setApplicationType(actualContext.getApplicationType());
-    trimmedContext.setNodeLabelExpression(actualContext.getNodeLabelExpression());
-    trimmedContext.setLogAggregationContext(actualContext.getLogAggregationContext());
-    trimmedContext.setApplicationTags(actualContext.getApplicationTags());
-    trimmedContext.setApplicationSchedulingPropertiesMap(
-        actualContext.getApplicationSchedulingPropertiesMap());
-    trimmedContext.setKeepContainersAcrossApplicationAttempts(
-        actualContext.getKeepContainersAcrossApplicationAttempts());
-    trimmedContext.setApplicationTimeouts(actualContext.getApplicationTimeouts());
-
-    return trimmedContext;
-  }
-
-  public static boolean isRouterWebProxyEnable(Configuration conf) {
-    return conf.getBoolean(YarnConfiguration.ROUTER_WEBAPP_PROXY_ENABLE,
-        YarnConfiguration.DEFAULT_ROUTER_WEBAPP_PROXY_ENABLE);
-  }
-
-  public static boolean checkPolicyManagerValid(String policyManager,
-      List<String> supportWeightList) throws YarnException {
-    if (supportWeightList.contains(policyManager)) {
-      return true;
-    }
-    return false;
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/cleaner/SubClusterCleaner.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/cleaner/SubClusterCleaner.java
deleted file mode 100644
index 35e4d7a998e..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/cleaner/SubClusterCleaner.java
+++ /dev/null
@@ -1,92 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.cleaner;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterState;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.util.Date;
-import java.util.Map;
-import java.util.concurrent.TimeUnit;
-
-/**
- * The SubClusterCleaner thread is used to check whether the SubCluster
- * has exceeded the heartbeat time.
- * If the SubCluster heartbeat time exceeds 30 mins, set the SubCluster to LOST.
- * Check the thread every 1 mins, check once.
- */
-public class SubClusterCleaner implements Runnable {
-
-  private static final Logger LOG = LoggerFactory.getLogger(SubClusterCleaner.class);
-  private FederationStateStoreFacade federationFacade;
-  private long heartbeatExpirationMillis;
-
-  public SubClusterCleaner(Configuration conf) {
-    federationFacade = FederationStateStoreFacade.getInstance(conf);
-    this.heartbeatExpirationMillis =
-        conf.getTimeDuration(YarnConfiguration.ROUTER_SUBCLUSTER_EXPIRATION_TIME,
-        YarnConfiguration.DEFAULT_ROUTER_SUBCLUSTER_EXPIRATION_TIME, TimeUnit.MILLISECONDS);
-  }
-
-  @Override
-  public void run() {
-    try {
-      // Step1. Get Current Time.
-      Date now = new Date();
-      LOG.info("SubClusterCleaner at {}.", now);
-
-      Map<SubClusterId, SubClusterInfo> subClusters = federationFacade.getSubClusters(true);
-
-      for (Map.Entry<SubClusterId, SubClusterInfo> subCluster : subClusters.entrySet()) {
-        // Step2. Get information about subClusters.
-        SubClusterId subClusterId = subCluster.getKey();
-        SubClusterInfo subClusterInfo = subCluster.getValue();
-        SubClusterState subClusterState = subClusterInfo.getState();
-        long lastHeartBeatTime = subClusterInfo.getLastHeartBeat();
-
-        // We Only Check SubClusters in NEW and RUNNING states
-        if (subClusterState.isUsable()) {
-          long heartBeatInterval = now.getTime() - lastHeartBeatTime;
-          try {
-            // HeartBeat Interval Exceeds Expiration Time
-            if (heartBeatInterval > heartbeatExpirationMillis) {
-              LOG.info("Deregister SubCluster {} in state {} last heartbeat at {}.",
-                  subClusterId, subClusterState, new Date(lastHeartBeatTime));
-              federationFacade.deregisterSubCluster(subClusterId, SubClusterState.SC_LOST);
-            }
-          } catch (YarnException e) {
-            LOG.error("deregisterSubCluster failed on SubCluster {}.", subClusterId, e);
-          }
-        } else {
-          LOG.debug("SubCluster {} in state {} last heartbeat at {}, " +
-              "heartbeat interval < 30mins, no need for Deregister.",
-              subClusterId, subClusterState, new Date(lastHeartBeatTime));
-        }
-      }
-    } catch (Throwable e) {
-      LOG.error("SubClusterCleaner Fails.", e);
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/cleaner/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/cleaner/package-info.java
deleted file mode 100644
index 75477508cb1..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/cleaner/package-info.java
+++ /dev/null
@@ -1,20 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/** Router Cleaner package. **/
-package org.apache.hadoop.yarn.server.router.cleaner;
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/AbstractClientRequestInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/AbstractClientRequestInterceptor.java
deleted file mode 100644
index 10ed71b6010..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/AbstractClientRequestInterceptor.java
+++ /dev/null
@@ -1,114 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.yarn.server.router.RouterServerUtil;
-import org.apache.hadoop.yarn.server.router.security.RouterDelegationTokenSecretManager;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * Implements the {@link ClientRequestInterceptor} interface and provides common
- * functionality which can can be used and/or extended by other concrete
- * interceptor classes.
- *
- */
-public abstract class AbstractClientRequestInterceptor
-    implements ClientRequestInterceptor {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(AbstractClientRequestInterceptor.class);
-
-  private Configuration conf;
-  private ClientRequestInterceptor nextInterceptor;
-
-  @SuppressWarnings("checkstyle:visibilitymodifier")
-  protected UserGroupInformation user = null;
-
-  private RouterDelegationTokenSecretManager tokenSecretManager = null;
-
-  /**
-   * Sets the {@link ClientRequestInterceptor} in the chain.
-   */
-  @Override
-  public void setNextInterceptor(ClientRequestInterceptor nextInterceptor) {
-    this.nextInterceptor = nextInterceptor;
-  }
-
-  /**
-   * Sets the {@link Configuration}.
-   */
-
-  @Override
-  public void setConf(Configuration conf) {
-    this.conf = conf;
-    if (this.nextInterceptor != null) {
-      this.nextInterceptor.setConf(conf);
-    }
-  }
-
-  /**
-   * Gets the {@link Configuration}.
-   */
-  @Override
-  public Configuration getConf() {
-    return this.conf;
-  }
-
-  /**
-   * Initializes the {@link ClientRequestInterceptor}.
-   */
-  @Override
-  public void init(String userName) {
-    this.user = RouterServerUtil.setupUser(userName);
-    if (this.nextInterceptor != null) {
-      this.nextInterceptor.init(userName);
-    }
-  }
-
-  /**
-   * Disposes the {@link ClientRequestInterceptor}.
-   */
-  @Override
-  public void shutdown() {
-    if (this.nextInterceptor != null) {
-      this.nextInterceptor.shutdown();
-    }
-  }
-
-  /**
-   * Gets the next {@link ClientRequestInterceptor} in the chain.
-   */
-  @Override
-  public ClientRequestInterceptor getNextInterceptor() {
-    return this.nextInterceptor;
-  }
-
-  @Override
-  public RouterDelegationTokenSecretManager getTokenSecretManager() {
-    return tokenSecretManager;
-  }
-
-  @Override
-  public void setTokenSecretManager(RouterDelegationTokenSecretManager tokenSecretManager) {
-    this.tokenSecretManager = tokenSecretManager;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/ApplicationSubmissionContextInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/ApplicationSubmissionContextInterceptor.java
deleted file mode 100644
index 6ec3fe334d3..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/ApplicationSubmissionContextInterceptor.java
+++ /dev/null
@@ -1,66 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import java.io.IOException;
-
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationResponse;
-import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
-import org.apache.hadoop.yarn.api.records.impl.pb.ApplicationSubmissionContextPBImpl;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.router.RouterAuditLogger;
-import org.apache.hadoop.yarn.server.router.RouterMetrics;
-import org.apache.hadoop.yarn.server.router.RouterServerUtil;
-
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.SUBMIT_NEW_APP;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.TARGET_CLIENT_RM_SERVICE;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.UNKNOWN;
-
-/**
- * It prevents DoS attack over the ApplicationClientProtocol. Currently, it
- * checks the size of the ApplicationSubmissionContext. If it exceeds the limit
- * it can cause Zookeeper failures.
- */
-public class ApplicationSubmissionContextInterceptor extends PassThroughClientRequestInterceptor {
-
-  @Override
-  public SubmitApplicationResponse submitApplication(
-      SubmitApplicationRequest request) throws YarnException, IOException {
-
-    if (request == null || request.getApplicationSubmissionContext() == null ||
-        request.getApplicationSubmissionContext().getApplicationId() == null) {
-      RouterMetrics.getMetrics().incrAppsFailedSubmitted();
-      String errMsg =
-          "Missing submitApplication request or applicationSubmissionContext information.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), SUBMIT_NEW_APP, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, errMsg);
-      RouterServerUtil.logAndThrowException(errMsg, null);
-    }
-
-    ApplicationSubmissionContext appContext = request.getApplicationSubmissionContext();
-    ApplicationSubmissionContextPBImpl asc = (ApplicationSubmissionContextPBImpl) appContext;
-
-    // Check for excessively large fields, throw exception if found
-    RouterServerUtil.checkAppSubmissionContext(asc, getConf());
-
-    // Check succeeded - app submit will be passed on to the next interceptor
-    return getNextInterceptor().submitApplication(request);
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/ClientMethod.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/ClientMethod.java
deleted file mode 100644
index 126cf1d1207..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/ClientMethod.java
+++ /dev/null
@@ -1,71 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import java.io.IOException;
-import java.util.Arrays;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * Class to define client method,params and arguments.
- */
-public class ClientMethod {
-
-  private static final Logger LOG = LoggerFactory.getLogger(ClientMethod.class);
-  /**
-   * List of parameters: static and dynamic values, matchings types.
-   */
-  private final Object[] params;
-  /**
-   * List of method parameters types, matches parameters.
-   */
-  private final Class<?>[] types;
-  /**
-   * String name of the method.
-   */
-  private final String methodName;
-
-  public ClientMethod(String method, Class<?>[] pTypes, Object... pParams)
-      throws IOException {
-    if (pParams.length != pTypes.length) {
-      throw new IOException("Invalid parameters for method " + method);
-    }
-
-    this.params = pParams;
-    this.types = Arrays.copyOf(pTypes, pTypes.length);
-    this.methodName = method;
-  }
-
-  public Object[] getParams() {
-    return Arrays.copyOf(this.params, this.params.length);
-  }
-
-  public String getMethodName() {
-    return methodName;
-  }
-
-  /**
-   * Get the calling types for this method.
-   *
-   * @return An array of calling types.
-   */
-  public Class<?>[] getTypes() {
-    return Arrays.copyOf(this.types, this.types.length);
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/ClientRequestInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/ClientRequestInterceptor.java
deleted file mode 100644
index 6e19cbadf9d..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/ClientRequestInterceptor.java
+++ /dev/null
@@ -1,80 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import org.apache.hadoop.conf.Configurable;
-import org.apache.hadoop.yarn.api.ApplicationClientProtocol;
-import org.apache.hadoop.yarn.server.router.security.RouterDelegationTokenSecretManager;
-
-/**
- * Defines the contract to be implemented by the request interceptor classes,
- * that can be used to intercept and inspect messages sent from the client to
- * the resource manager.
- */
-public interface ClientRequestInterceptor
-    extends ApplicationClientProtocol, Configurable {
-  /**
-   * This method is called for initializing the interceptor. This is guaranteed
-   * to be called only once in the lifetime of this instance.
-   *
-   * @param user the name of the client
-   */
-  void init(String user);
-
-  /**
-   * This method is called to release the resources held by the interceptor.
-   * This will be called when the application pipeline is being destroyed. The
-   * concrete implementations should dispose the resources and forward the
-   * request to the next interceptor, if any.
-   */
-  void shutdown();
-
-  /**
-   * Sets the next interceptor in the pipeline. The concrete implementation of
-   * this interface should always pass the request to the nextInterceptor after
-   * inspecting the message. The last interceptor in the chain is responsible to
-   * send the messages to the resource manager service and so the last
-   * interceptor will not receive this method call.
-   *
-   * @param nextInterceptor the ClientRequestInterceptor to set in the pipeline
-   */
-  void setNextInterceptor(ClientRequestInterceptor nextInterceptor);
-
-  /**
-   * Returns the next interceptor in the chain.
-   *
-   * @return the next interceptor in the chain
-   */
-  ClientRequestInterceptor getNextInterceptor();
-
-  /**
-   * Set RouterDelegationTokenSecretManager for specific interceptor to support Token operations,
-   * including create Token, update Token, and delete Token.
-   *
-   * @param tokenSecretManager Router DelegationTokenSecretManager
-   */
-  void setTokenSecretManager(RouterDelegationTokenSecretManager tokenSecretManager);
-
-  /**
-   * Get RouterDelegationTokenSecretManager.
-   *
-   * @return Router DelegationTokenSecretManager.
-   */
-  RouterDelegationTokenSecretManager getTokenSecretManager();
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/DefaultClientRequestInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/DefaultClientRequestInterceptor.java
deleted file mode 100644
index e7cc024b640..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/DefaultClientRequestInterceptor.java
+++ /dev/null
@@ -1,362 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import java.io.IOException;
-import java.security.PrivilegedExceptionAction;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.api.ApplicationClientProtocol;
-import org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainersResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.KillApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationListResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.SignalContainerResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsResponse;
-import org.apache.hadoop.yarn.client.ClientRMProxy;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-
-import org.apache.hadoop.classification.VisibleForTesting;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * Extends the {@code AbstractRequestInterceptorClient} class and provides an
- * implementation that simply forwards the client requests to the cluster
- * resource manager.
- *
- */
-public class DefaultClientRequestInterceptor
-    extends AbstractClientRequestInterceptor {
-  private static final Logger LOG =
-      LoggerFactory.getLogger(DefaultClientRequestInterceptor.class);
-  private ApplicationClientProtocol clientRMProxy;
-
-  @Override
-  public void init(String userName) {
-    super.init(userName);
-    try {
-      final Configuration conf = this.getConf();
-      clientRMProxy = user.doAs(
-          (PrivilegedExceptionAction<ApplicationClientProtocol>) () ->
-               ClientRMProxy.createRMProxy(conf, ApplicationClientProtocol.class));
-    } catch (Exception e) {
-      StringBuilder message = new StringBuilder();
-      message.append("Error while creating Router RMClient Service");
-      if (user != null) {
-        message.append(", user: " + user);
-      }
-      LOG.error(message.toString(), e);
-      throw new YarnRuntimeException(message.toString(), e);
-    }
-  }
-
-  @Override
-  public void setNextInterceptor(ClientRequestInterceptor next) {
-    throw new YarnRuntimeException(
-        "setNextInterceptor is being called on DefaultRequestInterceptor,"
-            + "which should be the last one in the chain "
-            + "Check if the interceptor pipeline configuration is correct");
-  }
-
-  @Override
-  public GetNewApplicationResponse getNewApplication(
-      GetNewApplicationRequest request) throws YarnException, IOException {
-    return clientRMProxy.getNewApplication(request);
-  }
-
-  @Override
-  public SubmitApplicationResponse submitApplication(
-      SubmitApplicationRequest request) throws YarnException, IOException {
-    return clientRMProxy.submitApplication(request);
-  }
-
-  @Override
-  public KillApplicationResponse forceKillApplication(
-      KillApplicationRequest request) throws YarnException, IOException {
-    return clientRMProxy.forceKillApplication(request);
-  }
-
-  @Override
-  public GetClusterMetricsResponse getClusterMetrics(
-      GetClusterMetricsRequest request) throws YarnException, IOException {
-    return clientRMProxy.getClusterMetrics(request);
-  }
-
-  @Override
-  public GetClusterNodesResponse getClusterNodes(GetClusterNodesRequest request)
-      throws YarnException, IOException {
-    return clientRMProxy.getClusterNodes(request);
-  }
-
-  @Override
-  public GetQueueInfoResponse getQueueInfo(GetQueueInfoRequest request)
-      throws YarnException, IOException {
-    return clientRMProxy.getQueueInfo(request);
-  }
-
-  @Override
-  public GetQueueUserAclsInfoResponse getQueueUserAcls(
-      GetQueueUserAclsInfoRequest request) throws YarnException, IOException {
-    return clientRMProxy.getQueueUserAcls(request);
-  }
-
-  @Override
-  public MoveApplicationAcrossQueuesResponse moveApplicationAcrossQueues(
-      MoveApplicationAcrossQueuesRequest request)
-      throws YarnException, IOException {
-    return clientRMProxy.moveApplicationAcrossQueues(request);
-  }
-
-  @Override
-  public GetNewReservationResponse getNewReservation(
-      GetNewReservationRequest request) throws YarnException, IOException {
-    return clientRMProxy.getNewReservation(request);
-  }
-
-  @Override
-  public ReservationSubmissionResponse submitReservation(
-      ReservationSubmissionRequest request) throws YarnException, IOException {
-    return clientRMProxy.submitReservation(request);
-  }
-
-  @Override
-  public ReservationListResponse listReservations(
-      ReservationListRequest request) throws YarnException, IOException {
-    return clientRMProxy.listReservations(request);
-  }
-
-  @Override
-  public ReservationUpdateResponse updateReservation(
-      ReservationUpdateRequest request) throws YarnException, IOException {
-    return clientRMProxy.updateReservation(request);
-  }
-
-  @Override
-  public ReservationDeleteResponse deleteReservation(
-      ReservationDeleteRequest request) throws YarnException, IOException {
-    return clientRMProxy.deleteReservation(request);
-  }
-
-  @Override
-  public GetNodesToLabelsResponse getNodeToLabels(
-      GetNodesToLabelsRequest request) throws YarnException, IOException {
-    return clientRMProxy.getNodeToLabels(request);
-  }
-
-  @Override
-  public GetLabelsToNodesResponse getLabelsToNodes(
-      GetLabelsToNodesRequest request) throws YarnException, IOException {
-    return clientRMProxy.getLabelsToNodes(request);
-  }
-
-  @Override
-  public GetClusterNodeLabelsResponse getClusterNodeLabels(
-      GetClusterNodeLabelsRequest request) throws YarnException, IOException {
-    return clientRMProxy.getClusterNodeLabels(request);
-  }
-
-  @Override
-  public GetApplicationReportResponse getApplicationReport(
-      GetApplicationReportRequest request) throws YarnException, IOException {
-    return clientRMProxy.getApplicationReport(request);
-  }
-
-  @Override
-  public GetApplicationsResponse getApplications(GetApplicationsRequest request)
-      throws YarnException, IOException {
-    return clientRMProxy.getApplications(request);
-  }
-
-  @Override
-  public GetApplicationAttemptReportResponse getApplicationAttemptReport(
-      GetApplicationAttemptReportRequest request)
-      throws YarnException, IOException {
-    return clientRMProxy.getApplicationAttemptReport(request);
-  }
-
-  @Override
-  public GetApplicationAttemptsResponse getApplicationAttempts(
-      GetApplicationAttemptsRequest request) throws YarnException, IOException {
-    return clientRMProxy.getApplicationAttempts(request);
-  }
-
-  @Override
-  public GetContainerReportResponse getContainerReport(
-      GetContainerReportRequest request) throws YarnException, IOException {
-    return clientRMProxy.getContainerReport(request);
-  }
-
-  @Override
-  public GetContainersResponse getContainers(GetContainersRequest request)
-      throws YarnException, IOException {
-    return clientRMProxy.getContainers(request);
-  }
-
-  @Override
-  public GetDelegationTokenResponse getDelegationToken(
-      GetDelegationTokenRequest request) throws YarnException, IOException {
-    return clientRMProxy.getDelegationToken(request);
-  }
-
-  @Override
-  public RenewDelegationTokenResponse renewDelegationToken(
-      RenewDelegationTokenRequest request) throws YarnException, IOException {
-    return clientRMProxy.renewDelegationToken(request);
-  }
-
-  @Override
-  public CancelDelegationTokenResponse cancelDelegationToken(
-      CancelDelegationTokenRequest request) throws YarnException, IOException {
-    return clientRMProxy.cancelDelegationToken(request);
-  }
-
-  @Override
-  public FailApplicationAttemptResponse failApplicationAttempt(
-      FailApplicationAttemptRequest request) throws YarnException, IOException {
-    return clientRMProxy.failApplicationAttempt(request);
-  }
-
-  @Override
-  public UpdateApplicationPriorityResponse updateApplicationPriority(
-      UpdateApplicationPriorityRequest request)
-      throws YarnException, IOException {
-    return clientRMProxy.updateApplicationPriority(request);
-  }
-
-  @Override
-  public SignalContainerResponse signalToContainer(
-      SignalContainerRequest request) throws YarnException, IOException {
-    return clientRMProxy.signalToContainer(request);
-  }
-
-  @Override
-  public UpdateApplicationTimeoutsResponse updateApplicationTimeouts(
-      UpdateApplicationTimeoutsRequest request)
-      throws YarnException, IOException {
-    return clientRMProxy.updateApplicationTimeouts(request);
-  }
-
-  @Override
-  public GetAllResourceProfilesResponse getResourceProfiles(
-      GetAllResourceProfilesRequest request) throws YarnException, IOException {
-    return clientRMProxy.getResourceProfiles(request);
-  }
-
-  @Override
-  public GetResourceProfileResponse getResourceProfile(
-      GetResourceProfileRequest request) throws YarnException, IOException {
-    return clientRMProxy.getResourceProfile(request);
-  }
-
-  @Override
-  public GetAllResourceTypeInfoResponse getResourceTypeInfo(
-      GetAllResourceTypeInfoRequest request) throws YarnException, IOException {
-    return clientRMProxy.getResourceTypeInfo(request);
-  }
-
-  @Override
-  public GetAttributesToNodesResponse getAttributesToNodes(
-      GetAttributesToNodesRequest request) throws YarnException, IOException {
-    return clientRMProxy.getAttributesToNodes(request);
-  }
-
-  @Override
-  public GetClusterNodeAttributesResponse getClusterNodeAttributes(
-      GetClusterNodeAttributesRequest request)
-      throws YarnException, IOException {
-    return clientRMProxy.getClusterNodeAttributes(request);
-  }
-
-  @Override
-  public GetNodesToAttributesResponse getNodesToAttributes(
-      GetNodesToAttributesRequest request) throws YarnException, IOException {
-    return clientRMProxy.getNodesToAttributes(request);
-  }
-
-  @VisibleForTesting
-  public void setRMClient(ApplicationClientProtocol clientRM) {
-    this.clientRMProxy = clientRM;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/FederationClientInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/FederationClientInterceptor.java
deleted file mode 100644
index ab0e1b345e9..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/FederationClientInterceptor.java
+++ /dev/null
@@ -1,2365 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import org.apache.commons.lang3.StringUtils;
-import org.apache.commons.lang3.tuple.Pair;
-import org.apache.hadoop.io.Text;
-import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ThreadFactoryBuilder;
-import java.io.IOException;
-import java.lang.reflect.Method;
-import java.lang.reflect.InvocationTargetException;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.List;
-import java.util.Map;
-import java.util.Random;
-import java.util.TreeMap;
-import java.util.concurrent.BlockingQueue;
-import java.util.concurrent.Callable;
-import java.util.concurrent.ConcurrentHashMap;
-
-import java.util.concurrent.ExecutionException;
-import java.util.concurrent.Future;
-import java.util.concurrent.LinkedBlockingQueue;
-import java.util.concurrent.ThreadFactory;
-import java.util.concurrent.ThreadPoolExecutor;
-import java.util.concurrent.TimeUnit;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.CommonConfigurationKeys;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.yarn.api.ApplicationClientProtocol;
-import org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainersResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.KillApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationListResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.SignalContainerResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsResponse;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
-import org.apache.hadoop.yarn.api.records.ReservationId;
-import org.apache.hadoop.security.token.Token;
-import org.apache.hadoop.yarn.server.utils.BuilderUtils;
-
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-import org.apache.hadoop.yarn.security.client.RMDelegationTokenIdentifier;
-import org.apache.hadoop.yarn.server.federation.failover.FederationProxyProviderUtil;
-import org.apache.hadoop.yarn.server.federation.policies.FederationPolicyUtils;
-import org.apache.hadoop.yarn.server.federation.policies.RouterPolicyFacade;
-import org.apache.hadoop.yarn.server.federation.policies.exceptions.FederationPolicyInitializationException;
-import org.apache.hadoop.yarn.server.federation.retry.FederationActionRetry;
-import org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster;
-import org.apache.hadoop.yarn.server.federation.store.records.ReservationHomeSubCluster;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.router.RouterAuditLogger;
-import org.apache.hadoop.yarn.server.router.RouterMetrics;
-import org.apache.hadoop.yarn.server.router.RouterServerUtil;
-import org.apache.hadoop.yarn.util.Clock;
-import org.apache.hadoop.yarn.util.MonotonicClock;
-import org.apache.hadoop.yarn.util.Records;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import org.apache.hadoop.classification.VisibleForTesting;
-
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_NEW_APP;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.SUBMIT_NEW_APP;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_APP_REPORT;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.FORCE_KILL_APP;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.TARGET_CLIENT_RM_SERVICE;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.UNKNOWN;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_CLUSTERNODES;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_QUEUE_USER_ACLS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_APPLICATIONS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_CLUSTERMETRICS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_QUEUEINFO;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.MOVE_APPLICATION_ACROSS_QUEUES;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_NEW_RESERVATION;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.SUBMIT_RESERVATION;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.LIST_RESERVATIONS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.UPDATE_RESERVATION;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.DELETE_RESERVATION;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_NODETOLABELS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_LABELSTONODES;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_CLUSTERNODELABELS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_APPLICATION_ATTEMPT_REPORT;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_APPLICATION_ATTEMPTS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_CONTAINERREPORT;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_CONTAINERS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_DELEGATIONTOKEN;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.RENEW_DELEGATIONTOKEN;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.CANCEL_DELEGATIONTOKEN;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.FAIL_APPLICATIONATTEMPT;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.UPDATE_APPLICATIONPRIORITY;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.SIGNAL_TOCONTAINER;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.UPDATE_APPLICATIONTIMEOUTS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_RESOURCEPROFILES;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_RESOURCEPROFILE;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_RESOURCETYPEINFO;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_ATTRIBUTESTONODES;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_CLUSTERNODEATTRIBUTES;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_NODESTOATTRIBUTES;
-
-/**
- * Extends the {@code AbstractRequestInterceptorClient} class and provides an
- * implementation for federation of YARN RM and scaling an application across
- * multiple YARN SubClusters. All the federation specific implementation is
- * encapsulated in this class. This is always the last interceptor in the chain.
- */
-public class FederationClientInterceptor
-    extends AbstractClientRequestInterceptor {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(FederationClientInterceptor.class);
-
-  private int numSubmitRetries;
-  private Map<SubClusterId, ApplicationClientProtocol> clientRMProxies;
-  private FederationStateStoreFacade federationFacade;
-  private Random rand;
-  private RouterPolicyFacade policyFacade;
-  private RouterMetrics routerMetrics;
-  private ThreadPoolExecutor executorService;
-  private final Clock clock = new MonotonicClock();
-  private boolean returnPartialReport;
-  private long submitIntervalTime;
-  private boolean allowPartialResult;
-
-  @Override
-  public void init(String userName) {
-    super.init(userName);
-
-    federationFacade = FederationStateStoreFacade.getInstance(getConf());
-    rand = new Random(System.currentTimeMillis());
-
-    int numMinThreads = getNumMinThreads(getConf());
-
-    int numMaxThreads = getNumMaxThreads(getConf());
-
-    long keepAliveTime = getConf().getTimeDuration(
-        YarnConfiguration.ROUTER_USER_CLIENT_THREAD_POOL_KEEP_ALIVE_TIME,
-        YarnConfiguration.DEFAULT_ROUTER_USER_CLIENT_THREAD_POOL_KEEP_ALIVE_TIME, TimeUnit.SECONDS);
-
-    ThreadFactory threadFactory = new ThreadFactoryBuilder()
-        .setNameFormat("RPC Router Client-" + userName + "-%d ").build();
-
-    BlockingQueue<Runnable> workQueue = new LinkedBlockingQueue<>();
-    this.executorService = new ThreadPoolExecutor(numMinThreads, numMaxThreads,
-        keepAliveTime, TimeUnit.MILLISECONDS, workQueue, threadFactory);
-
-    // Adding this line so that unused user threads will exit and be cleaned up if idle for too long
-    boolean allowCoreThreadTimeOut =  getConf().getBoolean(
-        YarnConfiguration.ROUTER_USER_CLIENT_THREAD_POOL_ALLOW_CORE_THREAD_TIMEOUT,
-        YarnConfiguration.DEFAULT_ROUTER_USER_CLIENT_THREAD_POOL_ALLOW_CORE_THREAD_TIMEOUT);
-
-    if (keepAliveTime > 0 && allowCoreThreadTimeOut) {
-      this.executorService.allowCoreThreadTimeOut(allowCoreThreadTimeOut);
-    }
-
-    final Configuration conf = this.getConf();
-
-    try {
-      policyFacade = new RouterPolicyFacade(conf, federationFacade,
-          this.federationFacade.getSubClusterResolver(), null);
-    } catch (FederationPolicyInitializationException e) {
-      LOG.error(e.getMessage());
-    }
-
-    numSubmitRetries = conf.getInt(
-        YarnConfiguration.ROUTER_CLIENTRM_SUBMIT_RETRY,
-        YarnConfiguration.DEFAULT_ROUTER_CLIENTRM_SUBMIT_RETRY);
-
-    submitIntervalTime = conf.getTimeDuration(
-        YarnConfiguration.ROUTER_CLIENTRM_SUBMIT_INTERVAL_TIME,
-        YarnConfiguration.DEFAULT_CLIENTRM_SUBMIT_INTERVAL_TIME, TimeUnit.MILLISECONDS);
-
-    clientRMProxies = new ConcurrentHashMap<>();
-    routerMetrics = RouterMetrics.getMetrics();
-
-    returnPartialReport = conf.getBoolean(
-        YarnConfiguration.ROUTER_CLIENTRM_PARTIAL_RESULTS_ENABLED,
-        YarnConfiguration.DEFAULT_ROUTER_CLIENTRM_PARTIAL_RESULTS_ENABLED);
-
-    allowPartialResult = conf.getBoolean(
-        YarnConfiguration.ROUTER_INTERCEPTOR_ALLOW_PARTIAL_RESULT_ENABLED,
-        YarnConfiguration.DEFAULT_ROUTER_INTERCEPTOR_ALLOW_PARTIAL_RESULT_ENABLED);
-  }
-
-  @Override
-  public void setNextInterceptor(ClientRequestInterceptor next) {
-    throw new YarnRuntimeException("setNextInterceptor is being called on "
-        + "FederationClientRequestInterceptor, which should be the last one "
-        + "in the chain. Check if the interceptor pipeline configuration "
-        + "is correct");
-  }
-
-  @VisibleForTesting
-  protected ApplicationClientProtocol getClientRMProxyForSubCluster(
-      SubClusterId subClusterId) throws YarnException {
-
-    if (clientRMProxies.containsKey(subClusterId)) {
-      return clientRMProxies.get(subClusterId);
-    }
-
-    ApplicationClientProtocol clientRMProxy = null;
-    try {
-      boolean serviceAuthEnabled = getConf().getBoolean(
-          CommonConfigurationKeys.HADOOP_SECURITY_AUTHORIZATION, false);
-      UserGroupInformation realUser = user;
-      if (serviceAuthEnabled) {
-        realUser = UserGroupInformation.createProxyUser(
-            user.getShortUserName(), UserGroupInformation.getLoginUser());
-      }
-      clientRMProxy = FederationProxyProviderUtil.createRMProxy(getConf(),
-          ApplicationClientProtocol.class, subClusterId, realUser);
-    } catch (Exception e) {
-      RouterServerUtil.logAndThrowException(
-          "Unable to create the interface to reach the SubCluster " + subClusterId, e);
-    }
-    clientRMProxies.put(subClusterId, clientRMProxy);
-    return clientRMProxy;
-  }
-
-  private SubClusterId getRandomActiveSubCluster(
-      Map<SubClusterId, SubClusterInfo> activeSubClusters) throws YarnException {
-    if (activeSubClusters == null || activeSubClusters.isEmpty()) {
-      RouterServerUtil.logAndThrowException(
-          FederationPolicyUtils.NO_ACTIVE_SUBCLUSTER_AVAILABLE, null);
-    }
-    List<SubClusterId> list = new ArrayList<>(activeSubClusters.keySet());
-    return list.get(rand.nextInt(list.size()));
-  }
-
-  /**
-   * YARN Router forwards every getNewApplication requests to any RM. During
-   * this operation there will be no communication with the State Store. The
-   * Router will forward the requests to any SubCluster. The Router will retry
-   * to submit the request on #numSubmitRetries different SubClusters. The
-   * SubClusters are randomly chosen from the active ones.
-   *
-   * Possible failures and behaviors:
-   *
-   * Client: identical behavior as {@code ClientRMService}.
-   *
-   * Router: the Client will timeout and resubmit.
-   *
-   * ResourceManager: the Router will timeout and contacts another RM.
-   *
-   * StateStore: not in the execution.
-   */
-  @Override
-  public GetNewApplicationResponse getNewApplication(
-      GetNewApplicationRequest request) throws YarnException, IOException {
-
-    if (request == null) {
-      routerMetrics.incrAppsFailedCreated();
-      String errMsg = "Missing getNewApplication request.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_NEW_APP, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, errMsg);
-      RouterServerUtil.logAndThrowException(errMsg, null);
-    }
-
-    long startTime = clock.getTime();
-    Map<SubClusterId, SubClusterInfo> subClustersActive =
-        federationFacade.getSubClusters(true);
-
-    // Try calling the getNewApplication method
-    List<SubClusterId> blacklist = new ArrayList<>();
-    int activeSubClustersCount = federationFacade.getActiveSubClustersCount();
-    int actualRetryNums = Math.min(activeSubClustersCount, numSubmitRetries);
-
-    try {
-      GetNewApplicationResponse response =
-          ((FederationActionRetry<GetNewApplicationResponse>) (retryCount) ->
-          invokeGetNewApplication(subClustersActive, blacklist, request, retryCount)).
-          runWithRetries(actualRetryNums, submitIntervalTime);
-
-      if (response != null) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededAppsCreated(stopTime - startTime);
-        return response;
-      }
-    } catch (Exception e) {
-      routerMetrics.incrAppsFailedCreated();
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_NEW_APP, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, e.getMessage());
-      RouterServerUtil.logAndThrowException(e.getMessage(), e);
-    }
-
-    routerMetrics.incrAppsFailedCreated();
-    String errMsg = "Failed to create a new application.";
-    RouterAuditLogger.logFailure(user.getShortUserName(), GET_NEW_APP, UNKNOWN,
-        TARGET_CLIENT_RM_SERVICE, errMsg);
-    throw new YarnException(errMsg);
-  }
-
-  /**
-   * Invoke GetNewApplication to different subClusters.
-   *
-   * @param subClustersActive Active SubClusters
-   * @param blackList Blacklist avoid repeated calls to unavailable subCluster.
-   * @param request getNewApplicationRequest.
-   * @param retryCount number of retries.
-   * @return Get NewApplicationResponse response, If the response is empty, the request fails,
-   * if the response is not empty, the request is successful.
-   * @throws YarnException yarn exception.
-   * @throws IOException io error.
-   */
-  private GetNewApplicationResponse invokeGetNewApplication(
-      Map<SubClusterId, SubClusterInfo> subClustersActive,
-      List<SubClusterId> blackList, GetNewApplicationRequest request, int retryCount)
-      throws YarnException, IOException {
-    SubClusterId subClusterId =
-        federationFacade.getRandomActiveSubCluster(subClustersActive, blackList);
-    LOG.info("getNewApplication try #{} on SubCluster {}.", retryCount, subClusterId);
-    ApplicationClientProtocol clientRMProxy = getClientRMProxyForSubCluster(subClusterId);
-    try {
-      GetNewApplicationResponse response = clientRMProxy.getNewApplication(request);
-      if (response != null) {
-        RouterAuditLogger.logSuccess(user.getShortUserName(), GET_NEW_APP,
-            TARGET_CLIENT_RM_SERVICE, response.getApplicationId(), subClusterId);
-        return response;
-      }
-    } catch (Exception e) {
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_NEW_APP, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, e.getMessage(), subClusterId);
-      LOG.warn("Unable to create a new ApplicationId in SubCluster {}.", subClusterId.getId(), e);
-      blackList.add(subClusterId);
-      throw e;
-    }
-    // If SubmitApplicationResponse is empty, the request fails.
-    String msg = String.format("Unable to create a new ApplicationId in SubCluster %s.",
-        subClusterId.getId());
-    throw new YarnException(msg);
-  }
-
-  /**
-   * Today, in YARN there are no checks of any applicationId submitted.
-   *
-   * Base scenarios:
-   *
-   * The Client submits an application to the Router. The Router selects one
-   * SubCluster to forward the request. The Router inserts a tuple into
-   * StateStore with the selected SubCluster (e.g. SC1) and the appId. The
-   * State Store replies with the selected SubCluster (e.g. SC1). The Router
-   * submits the request to the selected SubCluster.
-   *
-   * In case of State Store failure:
-   *
-   * The client submits an application to the Router. The Router selects one
-   * SubCluster to forward the request. The Router inserts a tuple into State
-   * Store with the selected SubCluster (e.g. SC1) and the appId. Due to the
-   * State Store down the Router times out and it will retry depending on the
-   * FederationFacade settings. The Router replies to the client with an error
-   * message.
-   *
-   * If State Store fails after inserting the tuple: identical behavior as
-   * {@code ClientRMService}.
-   *
-   * In case of Router failure:
-   *
-   * Scenario 1  Crash before submission to the ResourceManager
-   *
-   * The Client submits an application to the Router. The Router selects one
-   * SubCluster to forward the request. The Router inserts a tuple into State
-   * Store with the selected SubCluster (e.g. SC1) and the appId. The Router
-   * crashes. The Client timeouts and resubmits the application. The Router
-   * selects one SubCluster to forward the request. The Router inserts a tuple
-   * into State Store with the selected SubCluster (e.g. SC2) and the appId.
-   * Because the tuple is already inserted in the State Store, it returns the
-   * previous selected SubCluster (e.g. SC1). The Router submits the request
-   * to the selected SubCluster (e.g. SC1).
-   *
-   * Scenario 2  Crash after submission to the ResourceManager
-   *
-   * The Client submits an application to the Router. The Router selects one
-   * SubCluster to forward the request. The Router inserts a tuple into State
-   * Store with the selected SubCluster (e.g. SC1) and the appId. The Router
-   * submits the request to the selected SubCluster. The Router crashes. The
-   * Client timeouts and resubmit the application. The Router selects one
-   * SubCluster to forward the request. The Router inserts a tuple into State
-   * Store with the selected SubCluster (e.g. SC2) and the appId. The State
-   * Store replies with the selected SubCluster (e.g. SC1). The Router submits
-   * the request to the selected SubCluster (e.g. SC1). When a client re-submits
-   * the same application to the same RM, it does not raise an exception and
-   * replies with operation successful message.
-   *
-   * In case of Client failure: identical behavior as {@code ClientRMService}.
-   *
-   * In case of ResourceManager failure:
-   *
-   * The Client submits an application to the Router. The Router selects one
-   * SubCluster to forward the request. The Router inserts a tuple into State
-   * Store with the selected SubCluster (e.g. SC1) and the appId. The Router
-   * submits the request to the selected SubCluster. The entire SubCluster is
-   * down  all the RMs in HA or the master RM is not reachable. The Router
-   * times out. The Router selects a new SubCluster to forward the request.
-   * The Router update a tuple into State Store with the selected SubCluster
-   * (e.g. SC2) and the appId. The State Store replies with OK answer. The
-   * Router submits the request to the selected SubCluster (e.g. SC2).
-   */
-  @Override
-  public SubmitApplicationResponse submitApplication(
-      SubmitApplicationRequest request) throws YarnException, IOException {
-
-    if (request == null || request.getApplicationSubmissionContext() == null
-        || request.getApplicationSubmissionContext().getApplicationId() == null) {
-      routerMetrics.incrAppsFailedSubmitted();
-      String errMsg =
-          "Missing submitApplication request or applicationSubmissionContext information.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), SUBMIT_NEW_APP, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, errMsg);
-      RouterServerUtil.logAndThrowException(errMsg, null);
-    }
-
-    long startTime = clock.getTime();
-    ApplicationId applicationId =
-        request.getApplicationSubmissionContext().getApplicationId();
-    List<SubClusterId> blacklist = new ArrayList<>();
-
-    try {
-
-      // We need to handle this situation,
-      // the user will provide us with an expected submitRetries,
-      // but if the number of Active SubClusters is less than this number at this time,
-      // we should provide a high number of retry according to the number of Active SubClusters.
-      int activeSubClustersCount = federationFacade.getActiveSubClustersCount();
-      int actualRetryNums = Math.min(activeSubClustersCount, numSubmitRetries);
-
-      // Try calling the SubmitApplication method
-      SubmitApplicationResponse response =
-          ((FederationActionRetry<SubmitApplicationResponse>) (retryCount) ->
-          invokeSubmitApplication(blacklist, request, retryCount)).
-          runWithRetries(actualRetryNums, submitIntervalTime);
-
-      if (response != null) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededAppsSubmitted(stopTime - startTime);
-        return response;
-      }
-
-    } catch (Exception e) {
-      routerMetrics.incrAppsFailedSubmitted();
-      RouterAuditLogger.logFailure(user.getShortUserName(), SUBMIT_NEW_APP, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, e.getMessage(), applicationId);
-      RouterServerUtil.logAndThrowException(e.getMessage(), e);
-    }
-
-    routerMetrics.incrAppsFailedSubmitted();
-    String msg = String.format("Application %s with appId %s failed to be submitted.",
-        request.getApplicationSubmissionContext().getApplicationName(), applicationId);
-    RouterAuditLogger.logFailure(user.getShortUserName(), SUBMIT_NEW_APP, UNKNOWN,
-        TARGET_CLIENT_RM_SERVICE, msg, applicationId);
-    throw new YarnException(msg);
-  }
-
-  /**
-   * Invoke SubmitApplication to different subClusters.
-   *
-   * Step1. Select homeSubCluster for Application according to Policy.
-   *
-   * Step2. Query homeSubCluster according to ApplicationId,
-   * if homeSubCluster does not exist or first attempt(consider repeated submissions), write;
-   * if homeSubCluster exists, update.
-   *
-   * Step3. Find the clientRMProxy of the corresponding cluster according to homeSubCluster,
-   * and then call the SubmitApplication method.
-   *
-   * Step4. If SubmitApplicationResponse is empty, the request fails,
-   * if SubmitApplicationResponse is not empty, the request is successful.
-   *
-   * @param blackList Blacklist avoid repeated calls to unavailable subCluster.
-   * @param request submitApplicationRequest.
-   * @param retryCount number of retries.
-   * @return submitApplication response, If the response is empty, the request fails,
-   *      if the response is not empty, the request is successful.
-   * @throws YarnException yarn exception.
-   */
-  private SubmitApplicationResponse invokeSubmitApplication(
-      List<SubClusterId> blackList, SubmitApplicationRequest request, int retryCount)
-      throws YarnException, IOException {
-
-    // The request is not checked here,
-    // because the request has been checked before the method is called.
-    // We get applicationId and subClusterId from context.
-    ApplicationSubmissionContext appSubmissionContext = request.getApplicationSubmissionContext();
-    ApplicationId applicationId = appSubmissionContext.getApplicationId();
-    SubClusterId subClusterId = null;
-
-    try {
-
-      // Step1. Select homeSubCluster for Application according to Policy.
-      subClusterId = policyFacade.getHomeSubcluster(appSubmissionContext, blackList);
-      LOG.info("submitApplication appId {} try #{} on SubCluster {}.",
-          applicationId, retryCount, subClusterId);
-
-      // Step2. We Store the mapping relationship
-      // between Application and HomeSubCluster in stateStore.
-      ApplicationSubmissionContext trimmedAppSubmissionContext =
-          RouterServerUtil.getTrimmedAppSubmissionContext(appSubmissionContext);
-      federationFacade.addOrUpdateApplicationHomeSubCluster(
-          applicationId, subClusterId, retryCount, trimmedAppSubmissionContext);
-
-      // Step3. SubmitApplication to the subCluster
-      ApplicationClientProtocol clientRMProxy = getClientRMProxyForSubCluster(subClusterId);
-      SubmitApplicationResponse response = clientRMProxy.submitApplication(request);
-
-      // Step4. if SubmitApplicationResponse is not empty, the request is successful.
-      if (response != null) {
-        LOG.info("Application {} submitted on subCluster {}.", applicationId, subClusterId);
-        RouterAuditLogger.logSuccess(user.getShortUserName(), SUBMIT_NEW_APP,
-            TARGET_CLIENT_RM_SERVICE, applicationId, subClusterId);
-        return response;
-      }
-    } catch (Exception e) {
-      RouterAuditLogger.logFailure(user.getShortUserName(), SUBMIT_NEW_APP, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, e.getMessage(), applicationId, subClusterId);
-      LOG.warn("Unable to submitApplication appId {} try #{} on SubCluster {}.",
-          applicationId, retryCount, subClusterId, e);
-      if (subClusterId != null) {
-        blackList.add(subClusterId);
-      }
-      throw e;
-    }
-
-    // If SubmitApplicationResponse is empty, the request fails.
-    String msg = String.format("Application %s failed to be submitted.", applicationId);
-    throw new YarnException(msg);
-  }
-
-  /**
-   * The YARN Router will forward to the respective YARN RM in which the AM is
-   * running.
-   *
-   * Possible failures and behaviors:
-   *
-   * Client: identical behavior as {@code ClientRMService}.
-   *
-   * Router: the Client will timeout and resubmit the request.
-   *
-   * ResourceManager: the Router will timeout and the call will fail.
-   *
-   * State Store: the Router will timeout and it will retry depending on the
-   * FederationFacade settings - if the failure happened before the select
-   * operation.
-   */
-  @Override
-  public KillApplicationResponse forceKillApplication(
-      KillApplicationRequest request) throws YarnException, IOException {
-
-    if (request == null || request.getApplicationId() == null) {
-      routerMetrics.incrAppsFailedKilled();
-      String msg = "Missing forceKillApplication request or ApplicationId.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), FORCE_KILL_APP, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-
-    long startTime = clock.getTime();
-
-    ApplicationId applicationId = request.getApplicationId();
-    SubClusterId subClusterId = null;
-
-    try {
-      subClusterId = federationFacade
-          .getApplicationHomeSubCluster(request.getApplicationId());
-    } catch (YarnException e) {
-      routerMetrics.incrAppsFailedKilled();
-      String msg =
-          String.format("Application %s does not exist in FederationStateStore.", applicationId);
-      RouterAuditLogger.logFailure(user.getShortUserName(), FORCE_KILL_APP, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg, applicationId);
-      RouterServerUtil.logAndThrowException(msg, e);
-    }
-
-    ApplicationClientProtocol clientRMProxy =
-        getClientRMProxyForSubCluster(subClusterId);
-
-    KillApplicationResponse response = null;
-    try {
-      LOG.info("forceKillApplication {} on SubCluster {}.", applicationId, subClusterId);
-      response = clientRMProxy.forceKillApplication(request);
-    } catch (Exception e) {
-      routerMetrics.incrAppsFailedKilled();
-      String msg = "Unable to kill the application report.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), FORCE_KILL_APP, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg, applicationId, subClusterId);
-      RouterServerUtil.logAndThrowException(msg, e);
-    }
-
-    if (response == null) {
-      LOG.error("No response when attempting to kill the application {} to SubCluster {}.",
-          applicationId, subClusterId.getId());
-    }
-
-    long stopTime = clock.getTime();
-    routerMetrics.succeededAppsKilled(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), FORCE_KILL_APP,
-        TARGET_CLIENT_RM_SERVICE, applicationId);
-    return response;
-  }
-
-  /**
-   * The YARN Router will forward to the respective YARN RM in which the AM is
-   * running.
-   *
-   * Possible failure:
-   *
-   * Client: identical behavior as {@code ClientRMService}.
-   *
-   * Router: the Client will timeout and resubmit the request.
-   *
-   * ResourceManager: the Router will timeout and the call will fail.
-   *
-   * State Store: the Router will timeout and it will retry depending on the
-   * FederationFacade settings - if the failure happened before the select
-   * operation.
-   */
-  @Override
-  public GetApplicationReportResponse getApplicationReport(
-      GetApplicationReportRequest request) throws YarnException, IOException {
-
-    if (request == null || request.getApplicationId() == null) {
-      routerMetrics.incrAppsFailedRetrieved();
-      String errMsg = "Missing getApplicationReport request or applicationId information.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_APP_REPORT, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, errMsg);
-      RouterServerUtil.logAndThrowException(errMsg, null);
-    }
-
-    long startTime = clock.getTime();
-    SubClusterId subClusterId = null;
-
-    try {
-      subClusterId = federationFacade
-          .getApplicationHomeSubCluster(request.getApplicationId());
-    } catch (YarnException e) {
-      routerMetrics.incrAppsFailedRetrieved();
-      String errMsg = String.format("Application %s does not exist in FederationStateStore.",
-          request.getApplicationId());
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_APP_REPORT, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, errMsg, request.getApplicationId());
-      RouterServerUtil.logAndThrowException(errMsg, e);
-    }
-
-    ApplicationClientProtocol clientRMProxy =
-        getClientRMProxyForSubCluster(subClusterId);
-    GetApplicationReportResponse response = null;
-
-    try {
-      response = clientRMProxy.getApplicationReport(request);
-    } catch (Exception e) {
-      routerMetrics.incrAppsFailedRetrieved();
-      String errMsg = String.format("Unable to get the application report for %s to SubCluster %s.",
-          request.getApplicationId(), subClusterId.getId());
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_APP_REPORT, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, errMsg, request.getApplicationId(), subClusterId);
-      RouterServerUtil.logAndThrowException(errMsg, e);
-    }
-
-    if (response == null) {
-      LOG.error("No response when attempting to retrieve the report of "
-          + "the application {} to SubCluster {}.",
-          request.getApplicationId(), subClusterId.getId());
-    }
-    long stopTime = clock.getTime();
-    routerMetrics.succeededAppsRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), GET_APP_REPORT,
-        TARGET_CLIENT_RM_SERVICE, request.getApplicationId());
-    return response;
-  }
-
-  /**
-   * The Yarn Router will forward the request to all the Yarn RMs in parallel,
-   * after that it will group all the ApplicationReports by the ApplicationId.
-   *
-   * Possible failure:
-   *
-   * Client: identical behavior as {@code ClientRMService}.
-   *
-   * Router: the Client will timeout and resubmit the request.
-   *
-   * ResourceManager: the Router calls each Yarn RM in parallel. In case a
-   * Yarn RM fails, a single call will timeout. However, the Router will
-   * merge the ApplicationReports it got, and provides a partial list to
-   * the client.
-   *
-   * State Store: the Router will timeout and it will retry depending on the
-   * FederationFacade settings - if the failure happened before the select
-   * operation.
-   */
-  @Override
-  public GetApplicationsResponse getApplications(GetApplicationsRequest request)
-      throws YarnException, IOException {
-    if (request == null) {
-      routerMetrics.incrMultipleAppsFailedRetrieved();
-      String msg = "Missing getApplications request.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_APPLICATIONS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-    long startTime = clock.getTime();
-    ClientMethod remoteMethod = new ClientMethod("getApplications",
-        new Class[] {GetApplicationsRequest.class}, new Object[] {request});
-    Collection<GetApplicationsResponse> applications = null;
-    try {
-      applications = invokeConcurrent(remoteMethod, GetApplicationsResponse.class);
-    } catch (Exception ex) {
-      routerMetrics.incrMultipleAppsFailedRetrieved();
-      String msg = "Unable to get applications due to exception.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_APPLICATIONS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-    long stopTime = clock.getTime();
-    routerMetrics.succeededMultipleAppsRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), GET_APPLICATIONS,
-        TARGET_CLIENT_RM_SERVICE);
-    // Merge the Application Reports
-    return RouterYarnClientUtils.mergeApplications(applications, returnPartialReport);
-  }
-
-  @Override
-  public GetClusterMetricsResponse getClusterMetrics(
-      GetClusterMetricsRequest request) throws YarnException, IOException {
-    if (request == null) {
-      routerMetrics.incrGetClusterMetricsFailedRetrieved();
-      String msg = "Missing getApplications request.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_CLUSTERMETRICS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-    long startTime = clock.getTime();
-    ClientMethod remoteMethod = new ClientMethod("getClusterMetrics",
-        new Class[] {GetClusterMetricsRequest.class}, new Object[] {request});
-    Collection<GetClusterMetricsResponse> clusterMetrics = null;
-    try {
-      clusterMetrics = invokeConcurrent(remoteMethod, GetClusterMetricsResponse.class);
-    } catch (Exception ex) {
-      routerMetrics.incrGetClusterMetricsFailedRetrieved();
-      String msg = "Unable to get cluster metrics due to exception.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_CLUSTERMETRICS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-    long stopTime = clock.getTime();
-    routerMetrics.succeededGetClusterMetricsRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), GET_CLUSTERMETRICS,
-        TARGET_CLIENT_RM_SERVICE);
-    return RouterYarnClientUtils.merge(clusterMetrics);
-  }
-
-  <R> Collection<R> invokeConcurrent(ClientMethod request, Class<R> clazz)
-      throws YarnException {
-
-    // Get Active SubClusters
-    Map<SubClusterId, SubClusterInfo> subClusterInfo = federationFacade.getSubClusters(true);
-    Collection<SubClusterId> subClusterIds = subClusterInfo.keySet();
-
-    List<Callable<Pair<SubClusterId, Object>>> callables = new ArrayList<>();
-    List<Future<Pair<SubClusterId, Object>>> futures = new ArrayList<>();
-    Map<SubClusterId, Exception> exceptions = new TreeMap<>();
-
-    // Generate parallel Callable tasks
-    for (SubClusterId subClusterId : subClusterIds) {
-      callables.add(() -> {
-        try {
-          ApplicationClientProtocol protocol = getClientRMProxyForSubCluster(subClusterId);
-          String methodName = request.getMethodName();
-          Class<?>[] types = request.getTypes();
-          Object[] params = request.getParams();
-          Method method = ApplicationClientProtocol.class.getMethod(methodName, types);
-          Object result = method.invoke(protocol, params);
-          return Pair.of(subClusterId, result);
-        } catch (Exception e) {
-          Throwable cause = e.getCause();
-          // We use Callable. If the exception thrown here is InvocationTargetException,
-          // it is a wrapped exception. We need to get the real cause of the error.
-          if (cause != null && cause instanceof InvocationTargetException) {
-            cause = cause.getCause();
-          }
-          String errMsg = (cause.getMessage() != null) ? cause.getMessage() : "UNKNOWN";
-          YarnException yarnException =
-              new YarnException(String.format("subClusterId %s exec %s error %s.",
-              subClusterId, request.getMethodName(), errMsg), e);
-          return Pair.of(subClusterId, yarnException);
-        }
-      });
-    }
-
-    // Get results from multiple threads
-    Map<SubClusterId, R> results = new TreeMap<>();
-    try {
-      futures.addAll(executorService.invokeAll(callables));
-      futures.stream().forEach(future -> {
-        SubClusterId subClusterId = null;
-        try {
-          Pair<SubClusterId, Object> pair = future.get();
-          subClusterId = pair.getKey();
-          Object result = pair.getValue();
-          if (result instanceof YarnException) {
-            throw YarnException.class.cast(result);
-          }
-          results.put(subClusterId, clazz.cast(result));
-        } catch (InterruptedException | ExecutionException | YarnException e) {
-          Throwable cause = e.getCause();
-          LOG.error("Cannot execute {} on {} : {}", request.getMethodName(),
-              subClusterId.getId(), cause.getMessage());
-          exceptions.put(subClusterId, e);
-        }
-      });
-    } catch (InterruptedException e) {
-      throw new YarnException("invokeConcurrent Failed.", e);
-    }
-
-    // All sub-clusters return results to be considered successful,
-    // otherwise an exception will be thrown.
-    if (exceptions != null && !exceptions.isEmpty()) {
-      if (!allowPartialResult || exceptions.keySet().size() == subClusterIds.size()) {
-        throw new YarnException("invokeConcurrent Failed = " +
-            StringUtils.join(exceptions.values(), ","));
-      }
-    }
-
-    // return result
-    return results.values();
-  }
-
-  <R> Collection<R> invoke(ClientMethod request, Class<R> clazz, String subClusterId)
-      throws YarnException {
-
-    // Get Active SubClusters
-    Map<SubClusterId, SubClusterInfo> subClusterInfoMap = federationFacade.getSubClusters(true);
-
-    // According to subCluster of string type, convert to SubClusterId type
-    SubClusterId subClusterIdKey = SubClusterId.newInstance(subClusterId);
-
-    // If the provided subCluster is not Active or does not exist,
-    // an exception will be returned directly.
-    if (!subClusterInfoMap.containsKey(subClusterIdKey)) {
-      throw new YarnException("subClusterId = " + subClusterId + " is not an active subCluster.");
-    }
-
-    try {
-      ApplicationClientProtocol protocol = getClientRMProxyForSubCluster(subClusterIdKey);
-      String methodName = request.getMethodName();
-      Class<?>[] types = request.getTypes();
-      Object[] params = request.getParams();
-      Method method = ApplicationClientProtocol.class.getMethod(methodName, types);
-      Object result = method.invoke(protocol, params);
-      if (result != null) {
-        return Collections.singletonList(clazz.cast(result));
-      }
-    } catch (Exception e) {
-      throw new YarnException("invoke Failed, An exception occurred in subClusterId = " +
-          subClusterId, e);
-    }
-
-    throw new YarnException("invoke Failed, An exception occurred in subClusterId = " +
-        subClusterId);
-  }
-
-  @Override
-  public GetClusterNodesResponse getClusterNodes(GetClusterNodesRequest request)
-      throws YarnException, IOException {
-    if (request == null) {
-      routerMetrics.incrClusterNodesFailedRetrieved();
-      String msg = "Missing getClusterNodes request.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_CLUSTERNODES, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-    long startTime = clock.getTime();
-    ClientMethod remoteMethod = new ClientMethod("getClusterNodes",
-        new Class[]{GetClusterNodesRequest.class}, new Object[]{request});
-    try {
-      Collection<GetClusterNodesResponse> clusterNodes =
-          invokeConcurrent(remoteMethod, GetClusterNodesResponse.class);
-      long stopTime = clock.getTime();
-      routerMetrics.succeededGetClusterNodesRetrieved(stopTime - startTime);
-      RouterAuditLogger.logSuccess(user.getShortUserName(), GET_CLUSTERNODES,
-          TARGET_CLIENT_RM_SERVICE);
-      return RouterYarnClientUtils.mergeClusterNodesResponse(clusterNodes);
-    } catch (Exception ex) {
-      routerMetrics.incrClusterNodesFailedRetrieved();
-      String msg = "Unable to get cluster nodes due to exception.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_CLUSTERNODES, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-    throw new YarnException("Unable to get cluster nodes.");
-  }
-
-  /**
-   * <p>The interface used by clients to get information about <em>queues</em>
-   * from the <code>ResourceManager</code>.</p>
-   *
-   * <p>The client, via {@link GetQueueInfoRequest}, can ask for details such
-   * as used/total resources, child queues, running applications etc.</p>
-   *
-   * <p> In secure mode,the <code>ResourceManager</code> verifies access before
-   * providing the information.</p>
-   *
-   * @param request request to get queue information
-   * @return queue information
-   * @throws YarnException exceptions from yarn servers.
-   * @throws IOException io error occur.
-   */
-  @Override
-  public GetQueueInfoResponse getQueueInfo(GetQueueInfoRequest request)
-      throws YarnException, IOException {
-    if (request == null || request.getQueueName() == null) {
-      routerMetrics.incrGetQueueInfoFailedRetrieved();
-      String msg = "Missing getQueueInfo request or queueName.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_QUEUEINFO, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-    String rSubCluster = request.getSubClusterId();
-
-    long startTime = clock.getTime();
-    ClientMethod remoteMethod = new ClientMethod("getQueueInfo",
-        new Class[]{GetQueueInfoRequest.class}, new Object[]{request});
-    Collection<GetQueueInfoResponse> queues = null;
-    try {
-      if (StringUtils.isNotBlank(rSubCluster)) {
-        queues = invoke(remoteMethod, GetQueueInfoResponse.class, rSubCluster);
-      } else {
-        queues = invokeConcurrent(remoteMethod, GetQueueInfoResponse.class);
-      }
-    } catch (Exception ex) {
-      routerMetrics.incrGetQueueInfoFailedRetrieved();
-      String msg = "Unable to get queue [" + request.getQueueName() + "] to exception.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_QUEUEINFO, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-    long stopTime = clock.getTime();
-    routerMetrics.succeededGetQueueInfoRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), GET_QUEUEINFO, TARGET_CLIENT_RM_SERVICE);
-    // Merge the GetQueueInfoResponse
-    return RouterYarnClientUtils.mergeQueues(queues);
-  }
-
-  @Override
-  public GetQueueUserAclsInfoResponse getQueueUserAcls(
-      GetQueueUserAclsInfoRequest request) throws YarnException, IOException {
-    if(request == null){
-      routerMetrics.incrQueueUserAclsFailedRetrieved();
-      String msg = "Missing getQueueUserAcls request.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_QUEUE_USER_ACLS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg);
-    }
-    long startTime = clock.getTime();
-    ClientMethod remoteMethod = new ClientMethod("getQueueUserAcls",
-        new Class[] {GetQueueUserAclsInfoRequest.class}, new Object[] {request});
-    Collection<GetQueueUserAclsInfoResponse> queueUserAcls = null;
-    try {
-      queueUserAcls = invokeConcurrent(remoteMethod, GetQueueUserAclsInfoResponse.class);
-    } catch (Exception ex) {
-      routerMetrics.incrQueueUserAclsFailedRetrieved();
-      String msg = "Unable to get queue user Acls due to exception.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_QUEUE_USER_ACLS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-    long stopTime = clock.getTime();
-    routerMetrics.succeededGetQueueUserAclsRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), GET_QUEUE_USER_ACLS,
-        TARGET_CLIENT_RM_SERVICE);
-    // Merge the QueueUserAclsInfoResponse
-    return RouterYarnClientUtils.mergeQueueUserAcls(queueUserAcls);
-  }
-
-  @Override
-  public MoveApplicationAcrossQueuesResponse moveApplicationAcrossQueues(
-      MoveApplicationAcrossQueuesRequest request)
-      throws YarnException, IOException {
-    if (request == null || request.getApplicationId() == null || request.getTargetQueue() == null) {
-      routerMetrics.incrMoveApplicationAcrossQueuesFailedRetrieved();
-      String msg = "Missing moveApplicationAcrossQueues request or " +
-          "applicationId or target queue.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), MOVE_APPLICATION_ACROSS_QUEUES, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg);
-    }
-
-    long startTime = clock.getTime();
-    SubClusterId subClusterId = null;
-
-    ApplicationId applicationId = request.getApplicationId();
-    try {
-      subClusterId = federationFacade
-          .getApplicationHomeSubCluster(applicationId);
-    } catch (YarnException e) {
-      routerMetrics.incrMoveApplicationAcrossQueuesFailedRetrieved();
-      String errMsgFormat = "Application %s does not exist in FederationStateStore.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), MOVE_APPLICATION_ACROSS_QUEUES, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, String.format(errMsgFormat, applicationId));
-      RouterServerUtil.logAndThrowException(e, errMsgFormat, applicationId);
-    }
-
-    ApplicationClientProtocol clientRMProxy = getClientRMProxyForSubCluster(subClusterId);
-    MoveApplicationAcrossQueuesResponse response = null;
-    try {
-      response = clientRMProxy.moveApplicationAcrossQueues(request);
-    } catch (Exception e) {
-      routerMetrics.incrMoveApplicationAcrossQueuesFailedRetrieved();
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to moveApplicationAcrossQueues for %s to SubCluster %s.", applicationId,
-          subClusterId.getId());
-    }
-
-    if (response == null) {
-      LOG.error("No response when moveApplicationAcrossQueues "
-           + "the applicationId {} to Queue {} In SubCluster {}.",
-           request.getApplicationId(), request.getTargetQueue(), subClusterId.getId());
-    }
-
-    long stopTime = clock.getTime();
-    RouterAuditLogger.logSuccess(user.getShortUserName(), MOVE_APPLICATION_ACROSS_QUEUES,
-        TARGET_CLIENT_RM_SERVICE, applicationId, subClusterId);
-    routerMetrics.succeededMoveApplicationAcrossQueuesRetrieved(stopTime - startTime);
-    return response;
-  }
-
-  @Override
-  public GetNewReservationResponse getNewReservation(
-      GetNewReservationRequest request) throws YarnException, IOException {
-
-    if (request == null) {
-      routerMetrics.incrGetNewReservationFailedRetrieved();
-      String errMsg = "Missing getNewReservation request.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_NEW_RESERVATION, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, errMsg);
-      RouterServerUtil.logAndThrowException(errMsg, null);
-    }
-
-    long startTime = clock.getTime();
-    Map<SubClusterId, SubClusterInfo> subClustersActive = federationFacade.getSubClusters(true);
-
-    for (int i = 0; i < numSubmitRetries; ++i) {
-      SubClusterId subClusterId = getRandomActiveSubCluster(subClustersActive);
-      LOG.info("getNewReservation try #{} on SubCluster {}.", i, subClusterId);
-      ApplicationClientProtocol clientRMProxy = getClientRMProxyForSubCluster(subClusterId);
-      try {
-        GetNewReservationResponse response = clientRMProxy.getNewReservation(request);
-        if (response != null) {
-          long stopTime = clock.getTime();
-          routerMetrics.succeededGetNewReservationRetrieved(stopTime - startTime);
-          RouterAuditLogger.logSuccess(user.getShortUserName(), GET_NEW_RESERVATION,
-              TARGET_CLIENT_RM_SERVICE);
-          return response;
-        }
-      } catch (Exception e) {
-        String logFormatted = "Unable to create a new Reservation in SubCluster {}.";
-        LOG.warn(logFormatted, subClusterId.getId(), e);
-        RouterAuditLogger.logFailure(user.getShortUserName(), GET_NEW_RESERVATION, UNKNOWN,
-            TARGET_CLIENT_RM_SERVICE, logFormatted, subClusterId.getId());
-        subClustersActive.remove(subClusterId);
-      }
-    }
-
-    routerMetrics.incrGetNewReservationFailedRetrieved();
-    String errMsg = "Failed to create a new reservation.";
-    RouterAuditLogger.logFailure(user.getShortUserName(), GET_NEW_RESERVATION, UNKNOWN,
-        TARGET_CLIENT_RM_SERVICE, errMsg);
-    throw new YarnException(errMsg);
-  }
-
-  @Override
-  public ReservationSubmissionResponse submitReservation(
-      ReservationSubmissionRequest request) throws YarnException, IOException {
-
-    if (request == null || request.getReservationId() == null
-        || request.getReservationDefinition() == null || request.getQueue() == null) {
-      routerMetrics.incrSubmitReservationFailedRetrieved();
-      String msg = "Missing submitReservation request or reservationId " +
-          "or reservation definition or queue.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), SUBMIT_RESERVATION, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-
-    long startTime = clock.getTime();
-    ReservationId reservationId = request.getReservationId();
-
-    for (int i = 0; i < numSubmitRetries; i++) {
-      try {
-        // First, Get SubClusterId according to specific strategy.
-        SubClusterId subClusterId = policyFacade.getReservationHomeSubCluster(request);
-        LOG.info("submitReservation ReservationId {} try #{} on SubCluster {}.",
-            reservationId, i, subClusterId);
-        ReservationHomeSubCluster reservationHomeSubCluster =
-            ReservationHomeSubCluster.newInstance(reservationId, subClusterId);
-
-        // Second, determine whether the current ReservationId has a corresponding subCluster.
-        // If it does not exist, add it. If it exists, update it.
-        Boolean exists = existsReservationHomeSubCluster(reservationId);
-
-        // We may encounter the situation of repeated submission of Reservation,
-        // at this time we should try to use the reservation that has been allocated
-        // !exists indicates that the reservation does not exist and needs to be added
-        // i==0, mainly to consider repeated submissions,
-        // so the first time to apply for reservation, try to use the original reservation
-        if (!exists || i == 0) {
-          addReservationHomeSubCluster(reservationId, reservationHomeSubCluster);
-        } else {
-          updateReservationHomeSubCluster(subClusterId, reservationId, reservationHomeSubCluster);
-        }
-
-        // Third, Submit a Reservation request to the subCluster
-        ApplicationClientProtocol clientRMProxy = getClientRMProxyForSubCluster(subClusterId);
-        ReservationSubmissionResponse response = clientRMProxy.submitReservation(request);
-        if (response != null) {
-          LOG.info("Reservation {} submitted on subCluster {}.", reservationId, subClusterId);
-          long stopTime = clock.getTime();
-          routerMetrics.succeededSubmitReservationRetrieved(stopTime - startTime);
-          RouterAuditLogger.logSuccess(user.getShortUserName(), SUBMIT_RESERVATION,
-              TARGET_CLIENT_RM_SERVICE);
-          return response;
-        }
-      } catch (Exception e) {
-        LOG.warn("Unable to submit(try #{}) the Reservation {}.", i, reservationId, e);
-      }
-    }
-
-    routerMetrics.incrSubmitReservationFailedRetrieved();
-    String msg = String.format("Reservation %s failed to be submitted.", reservationId);
-    RouterAuditLogger.logFailure(user.getShortUserName(), SUBMIT_RESERVATION, UNKNOWN,
-        TARGET_CLIENT_RM_SERVICE, msg);
-    throw new YarnException(msg);
-  }
-
-  @Override
-  public ReservationListResponse listReservations(
-      ReservationListRequest request) throws YarnException, IOException {
-    if (request == null || request.getReservationId() == null) {
-      routerMetrics.incrListReservationsFailedRetrieved();
-      String msg = "Missing listReservations request.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), LIST_RESERVATIONS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-    long startTime = clock.getTime();
-    ClientMethod remoteMethod = new ClientMethod("listReservations",
-        new Class[] {ReservationListRequest.class}, new Object[] {request});
-    Collection<ReservationListResponse> listResponses = null;
-    try {
-      listResponses = invokeConcurrent(remoteMethod, ReservationListResponse.class);
-    } catch (Exception ex) {
-      String msg = "Unable to list reservations node due to exception.";
-      routerMetrics.incrListReservationsFailedRetrieved();
-      RouterAuditLogger.logFailure(user.getShortUserName(), LIST_RESERVATIONS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-    long stopTime = clock.getTime();
-    routerMetrics.succeededListReservationsRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), LIST_RESERVATIONS,
-        TARGET_CLIENT_RM_SERVICE);
-    // Merge the ReservationListResponse
-    return RouterYarnClientUtils.mergeReservationsList(listResponses);
-  }
-
-  @Override
-  public ReservationUpdateResponse updateReservation(
-      ReservationUpdateRequest request) throws YarnException, IOException {
-
-    if (request == null || request.getReservationId() == null
-        || request.getReservationDefinition() == null) {
-      routerMetrics.incrUpdateReservationFailedRetrieved();
-      String msg = "Missing updateReservation request or reservationId or reservation definition.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), UPDATE_RESERVATION, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-
-    long startTime = clock.getTime();
-    ReservationId reservationId = request.getReservationId();
-    SubClusterId subClusterId = getReservationHomeSubCluster(reservationId);
-
-    try {
-      ApplicationClientProtocol client = getClientRMProxyForSubCluster(subClusterId);
-      ReservationUpdateResponse response = client.updateReservation(request);
-      if (response != null) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededUpdateReservationRetrieved(stopTime - startTime);
-        RouterAuditLogger.logSuccess(user.getShortUserName(), UPDATE_RESERVATION,
-            TARGET_CLIENT_RM_SERVICE);
-        return response;
-      }
-    } catch (Exception ex) {
-      routerMetrics.incrUpdateReservationFailedRetrieved();
-      String msg = "Unable to reservation update due to exception.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), UPDATE_RESERVATION, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-
-    routerMetrics.incrUpdateReservationFailedRetrieved();
-    String msg = String.format("Reservation %s failed to be update.", reservationId);
-    RouterAuditLogger.logFailure(user.getShortUserName(), UPDATE_RESERVATION, UNKNOWN,
-        TARGET_CLIENT_RM_SERVICE, msg);
-    throw new YarnException(msg);
-  }
-
-  @Override
-  public ReservationDeleteResponse deleteReservation(
-      ReservationDeleteRequest request) throws YarnException, IOException {
-    if (request == null || request.getReservationId() == null) {
-      routerMetrics.incrDeleteReservationFailedRetrieved();
-      String msg = "Missing deleteReservation request or reservationId.";
-      RouterServerUtil.logAndThrowException(msg, null);
-      RouterAuditLogger.logFailure(user.getShortUserName(), DELETE_RESERVATION, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-    }
-
-    long startTime = clock.getTime();
-    ReservationId reservationId = request.getReservationId();
-    SubClusterId subClusterId = getReservationHomeSubCluster(reservationId);
-
-    try {
-      ApplicationClientProtocol client = getClientRMProxyForSubCluster(subClusterId);
-      ReservationDeleteResponse response = client.deleteReservation(request);
-      if (response != null) {
-        federationFacade.deleteReservationHomeSubCluster(reservationId);
-        long stopTime = clock.getTime();
-        routerMetrics.succeededDeleteReservationRetrieved(stopTime - startTime);
-        RouterAuditLogger.logSuccess(user.getShortUserName(), DELETE_RESERVATION,
-            TARGET_CLIENT_RM_SERVICE);
-        return response;
-      }
-    } catch (Exception ex) {
-      routerMetrics.incrUpdateReservationFailedRetrieved();
-      String msg = "Unable to reservation delete due to exception.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), DELETE_RESERVATION, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-
-    routerMetrics.incrDeleteReservationFailedRetrieved();
-    String msg = String.format("Reservation %s failed to be delete.", reservationId);
-    RouterAuditLogger.logFailure(user.getShortUserName(), DELETE_RESERVATION, UNKNOWN,
-        TARGET_CLIENT_RM_SERVICE, msg);
-    throw new YarnException(msg);
-  }
-
-  @Override
-  public GetNodesToLabelsResponse getNodeToLabels(
-      GetNodesToLabelsRequest request) throws YarnException, IOException {
-    if (request == null) {
-      routerMetrics.incrNodeToLabelsFailedRetrieved();
-      String msg = "Missing getNodesToLabels request.";
-      RouterServerUtil.logAndThrowException(msg, null);
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_NODETOLABELS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-    }
-    long startTime = clock.getTime();
-    ClientMethod remoteMethod = new ClientMethod("getNodeToLabels",
-        new Class[] {GetNodesToLabelsRequest.class}, new Object[] {request});
-    Collection<GetNodesToLabelsResponse> clusterNodes = null;
-    try {
-      clusterNodes = invokeConcurrent(remoteMethod, GetNodesToLabelsResponse.class);
-    } catch (Exception ex) {
-      routerMetrics.incrNodeToLabelsFailedRetrieved();
-      String msg = "Unable to get node label due to exception.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_NODETOLABELS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-    long stopTime = clock.getTime();
-    routerMetrics.succeededGetNodeToLabelsRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), GET_NODETOLABELS,
-        TARGET_CLIENT_RM_SERVICE);
-    // Merge the NodesToLabelsResponse
-    return RouterYarnClientUtils.mergeNodesToLabelsResponse(clusterNodes);
-  }
-
-  @Override
-  public GetLabelsToNodesResponse getLabelsToNodes(
-      GetLabelsToNodesRequest request) throws YarnException, IOException {
-    if (request == null) {
-      routerMetrics.incrLabelsToNodesFailedRetrieved();
-      String msg = "Missing getNodesToLabels request.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_LABELSTONODES, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-    long startTime = clock.getTime();
-    ClientMethod remoteMethod = new ClientMethod("getLabelsToNodes",
-         new Class[] {GetLabelsToNodesRequest.class}, new Object[] {request});
-    Collection<GetLabelsToNodesResponse> labelNodes = null;
-    try {
-      labelNodes = invokeConcurrent(remoteMethod, GetLabelsToNodesResponse.class);
-    } catch (Exception ex) {
-      routerMetrics.incrLabelsToNodesFailedRetrieved();
-      String msg = "Unable to get label node due to exception.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_LABELSTONODES, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-    long stopTime = clock.getTime();
-    routerMetrics.succeededGetLabelsToNodesRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), GET_LABELSTONODES,
-        TARGET_CLIENT_RM_SERVICE);
-    // Merge the LabelsToNodesResponse
-    return RouterYarnClientUtils.mergeLabelsToNodes(labelNodes);
-  }
-
-  @Override
-  public GetClusterNodeLabelsResponse getClusterNodeLabels(
-      GetClusterNodeLabelsRequest request) throws YarnException, IOException {
-    if (request == null) {
-      routerMetrics.incrClusterNodeLabelsFailedRetrieved();
-      String msg = "Missing getClusterNodeLabels request.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_CLUSTERNODELABELS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-    long startTime = clock.getTime();
-    ClientMethod remoteMethod = new ClientMethod("getClusterNodeLabels",
-         new Class[] {GetClusterNodeLabelsRequest.class}, new Object[] {request});
-    Collection<GetClusterNodeLabelsResponse> nodeLabels = null;
-    try {
-      nodeLabels = invokeConcurrent(remoteMethod, GetClusterNodeLabelsResponse.class);
-    } catch (Exception ex) {
-      routerMetrics.incrClusterNodeLabelsFailedRetrieved();
-      String msg = "Unable to get cluster nodeLabels due to exception.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_CLUSTERNODELABELS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-    long stopTime = clock.getTime();
-    routerMetrics.succeededGetClusterNodeLabelsRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), GET_CLUSTERNODELABELS,
-        TARGET_CLIENT_RM_SERVICE);
-    // Merge the ClusterNodeLabelsResponse
-    return RouterYarnClientUtils.mergeClusterNodeLabelsResponse(nodeLabels);
-  }
-
-  /**
-   * The YARN Router will forward to the respective YARN RM in which the AM is
-   * running.
-   *
-   * Possible failure:
-   *
-   * Client: identical behavior as {@code ClientRMService}.
-   *
-   * Router: the Client will timeout and resubmit the request.
-   *
-   * ResourceManager: the Router will timeout and the call will fail.
-   *
-   * State Store: the Router will timeout and it will retry depending on the
-   * FederationFacade settings - if the failure happened before the select
-   * operation.
-   */
-  @Override
-  public GetApplicationAttemptReportResponse getApplicationAttemptReport(
-      GetApplicationAttemptReportRequest request)
-      throws YarnException, IOException {
-
-    if (request == null || request.getApplicationAttemptId() == null
-            || request.getApplicationAttemptId().getApplicationId() == null) {
-      routerMetrics.incrAppAttemptReportFailedRetrieved();
-      String msg = "Missing getApplicationAttemptReport request or applicationId " +
-          "or applicationAttemptId information.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_APPLICATION_ATTEMPT_REPORT, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-
-    long startTime = clock.getTime();
-    SubClusterId subClusterId = null;
-    ApplicationId applicationId = request.getApplicationAttemptId().getApplicationId();
-    try {
-      subClusterId = getApplicationHomeSubCluster(applicationId);
-    } catch (YarnException e) {
-      routerMetrics.incrAppAttemptReportFailedRetrieved();
-      String msgFormat = "ApplicationAttempt %s belongs to " +
-          "Application %s does not exist in FederationStateStore.";
-      ApplicationAttemptId applicationAttemptId = request.getApplicationAttemptId();
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_APPLICATION_ATTEMPT_REPORT, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msgFormat, applicationAttemptId, applicationId);
-      RouterServerUtil.logAndThrowException(e, msgFormat, applicationAttemptId, applicationId);
-    }
-
-    ApplicationClientProtocol clientRMProxy =
-        getClientRMProxyForSubCluster(subClusterId);
-
-    GetApplicationAttemptReportResponse response = null;
-    try {
-      response = clientRMProxy.getApplicationAttemptReport(request);
-    } catch (Exception e) {
-      routerMetrics.incrAppAttemptReportFailedRetrieved();
-      String msg = String.format(
-          "Unable to get the applicationAttempt report for %s to SubCluster %s.",
-          request.getApplicationAttemptId(), subClusterId.getId());
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_APPLICATION_ATTEMPT_REPORT, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, e);
-    }
-
-    if (response == null) {
-      LOG.error("No response when attempting to retrieve the report of "
-          + "the applicationAttempt {} to SubCluster {}.",
-          request.getApplicationAttemptId(), subClusterId.getId());
-    }
-
-    long stopTime = clock.getTime();
-    routerMetrics.succeededAppAttemptReportRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), GET_APPLICATION_ATTEMPT_REPORT,
-        TARGET_CLIENT_RM_SERVICE);
-    return response;
-  }
-
-  @Override
-  public GetApplicationAttemptsResponse getApplicationAttempts(
-      GetApplicationAttemptsRequest request) throws YarnException, IOException {
-    if (request == null || request.getApplicationId() == null) {
-      routerMetrics.incrAppAttemptsFailedRetrieved();
-      String msg = "Missing getApplicationAttempts request or application id.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_APPLICATION_ATTEMPTS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg);
-    }
-
-    long startTime = clock.getTime();
-    ApplicationId applicationId = request.getApplicationId();
-    SubClusterId subClusterId = null;
-    try {
-      subClusterId = getApplicationHomeSubCluster(applicationId);
-    } catch (YarnException ex) {
-      routerMetrics.incrAppAttemptsFailedRetrieved();
-      String msg = "Application " + applicationId + " does not exist in FederationStateStore.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_APPLICATION_ATTEMPTS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-
-    ApplicationClientProtocol clientRMProxy = getClientRMProxyForSubCluster(subClusterId);
-    GetApplicationAttemptsResponse response = null;
-    try {
-      response = clientRMProxy.getApplicationAttempts(request);
-    } catch (Exception ex) {
-      routerMetrics.incrAppAttemptsFailedRetrieved();
-      String msg = "Unable to get the application attempts for " +
-          applicationId + " from SubCluster " + subClusterId.getId();
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_APPLICATION_ATTEMPTS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-
-    if (response == null) {
-      LOG.error("No response when attempting to retrieve the attempts list of " +
-           "the application = {} to SubCluster = {}.", applicationId,
-           subClusterId.getId());
-    }
-
-    long stopTime = clock.getTime();
-    RouterAuditLogger.logSuccess(user.getShortUserName(), GET_APPLICATION_ATTEMPTS,
-        TARGET_CLIENT_RM_SERVICE, applicationId);
-    routerMetrics.succeededAppAttemptsRetrieved(stopTime - startTime);
-    return response;
-  }
-
-  @Override
-  public GetContainerReportResponse getContainerReport(
-      GetContainerReportRequest request) throws YarnException, IOException {
-    if(request == null || request.getContainerId() == null){
-      routerMetrics.incrGetContainerReportFailedRetrieved();
-      String msg = "Missing getContainerReport request or containerId";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_CONTAINERREPORT, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-
-    long startTime = clock.getTime();
-    ApplicationId applicationId = request.getContainerId().
-        getApplicationAttemptId().getApplicationId();
-    SubClusterId subClusterId = null;
-    try {
-      subClusterId = getApplicationHomeSubCluster(applicationId);
-    } catch (YarnException ex) {
-      routerMetrics.incrGetContainerReportFailedRetrieved();
-      String msg = "Application " + applicationId + " does not exist in FederationStateStore.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_CONTAINERREPORT, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-
-    ApplicationClientProtocol clientRMProxy = getClientRMProxyForSubCluster(subClusterId);
-    GetContainerReportResponse response = null;
-
-    try {
-      response = clientRMProxy.getContainerReport(request);
-    } catch (Exception ex) {
-      routerMetrics.incrGetContainerReportFailedRetrieved();
-      LOG.error("Unable to get the container report for {} from SubCluster {}.",
-          applicationId, subClusterId.getId(), ex);
-    }
-
-    if (response == null) {
-      LOG.error("No response when attempting to retrieve the container report of " +
-           "the ContainerId = {} From SubCluster = {}.", request.getContainerId(),
-           subClusterId.getId());
-    }
-
-    long stopTime = clock.getTime();
-    RouterAuditLogger.logSuccess(user.getShortUserName(), GET_CONTAINERREPORT,
-        TARGET_CLIENT_RM_SERVICE, applicationId, subClusterId);
-    routerMetrics.succeededGetContainerReportRetrieved(stopTime - startTime);
-    return response;
-  }
-
-  @Override
-  public GetContainersResponse getContainers(GetContainersRequest request)
-      throws YarnException, IOException {
-    if (request == null || request.getApplicationAttemptId() == null) {
-      routerMetrics.incrGetContainersFailedRetrieved();
-      String msg = "Missing getContainers request or ApplicationAttemptId.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_CONTAINERS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-
-    long startTime = clock.getTime();
-    ApplicationId applicationId = request.getApplicationAttemptId().getApplicationId();
-    SubClusterId subClusterId = null;
-    try {
-      subClusterId = getApplicationHomeSubCluster(applicationId);
-    } catch (YarnException ex) {
-      routerMetrics.incrGetContainersFailedRetrieved();
-      String msg = "Application " + applicationId + " does not exist in FederationStateStore.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_CONTAINERS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-
-    ApplicationClientProtocol clientRMProxy = getClientRMProxyForSubCluster(subClusterId);
-    GetContainersResponse response = null;
-
-    try {
-      response = clientRMProxy.getContainers(request);
-    } catch (Exception ex) {
-      routerMetrics.incrGetContainersFailedRetrieved();
-      String msg = "Unable to get the containers for " +
-          applicationId + " from SubCluster " + subClusterId.getId();
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_CONTAINERS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-
-    if (response == null) {
-      LOG.error("No response when attempting to retrieve the container report of " +
-          "the ApplicationId = {} From SubCluster = {}.", applicationId,
-          subClusterId.getId());
-    }
-
-    long stopTime = clock.getTime();
-    RouterAuditLogger.logSuccess(user.getShortUserName(), GET_CONTAINERS,
-        TARGET_CLIENT_RM_SERVICE, applicationId, subClusterId);
-    routerMetrics.succeededGetContainersRetrieved(stopTime - startTime);
-    return response;
-  }
-
-  @Override
-  public GetDelegationTokenResponse getDelegationToken(
-      GetDelegationTokenRequest request) throws YarnException, IOException {
-
-    if (request == null || request.getRenewer() == null) {
-      routerMetrics.incrGetDelegationTokenFailedRetrieved();
-      String msg = "Missing getDelegationToken request or Renewer.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_DELEGATIONTOKEN, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-
-    try {
-      // Verify that the connection is kerberos authenticated
-      if (!RouterServerUtil.isAllowedDelegationTokenOp()) {
-        routerMetrics.incrGetDelegationTokenFailedRetrieved();
-        String msg = "Delegation Token can be issued only with kerberos authentication.";
-        RouterAuditLogger.logFailure(user.getShortUserName(), GET_DELEGATIONTOKEN, UNKNOWN,
-            TARGET_CLIENT_RM_SERVICE, msg);
-        throw new IOException(msg);
-      }
-
-      long startTime = clock.getTime();
-      UserGroupInformation ugi = UserGroupInformation.getCurrentUser();
-      Text owner = new Text(ugi.getUserName());
-      Text realUser = null;
-      if (ugi.getRealUser() != null) {
-        realUser = new Text(ugi.getRealUser().getUserName());
-      }
-
-      RMDelegationTokenIdentifier tokenIdentifier =
-          new RMDelegationTokenIdentifier(owner, new Text(request.getRenewer()), realUser);
-      Token<RMDelegationTokenIdentifier> realRMDToken =
-          new Token<>(tokenIdentifier, this.getTokenSecretManager());
-
-      org.apache.hadoop.yarn.api.records.Token routerRMDTToken =
-          BuilderUtils.newDelegationToken(realRMDToken.getIdentifier(),
-              realRMDToken.getKind().toString(),
-              realRMDToken.getPassword(), realRMDToken.getService().toString());
-
-      long stopTime = clock.getTime();
-      routerMetrics.succeededGetDelegationTokenRetrieved((stopTime - startTime));
-      RouterAuditLogger.logSuccess(user.getShortUserName(), GET_DELEGATIONTOKEN,
-          TARGET_CLIENT_RM_SERVICE);
-      return GetDelegationTokenResponse.newInstance(routerRMDTToken);
-    } catch(IOException e) {
-      routerMetrics.incrGetDelegationTokenFailedRetrieved();
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_DELEGATIONTOKEN, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, "getDelegationToken error, errMsg = " + e.getMessage());
-      throw new YarnException(e);
-    }
-  }
-
-  @Override
-  public RenewDelegationTokenResponse renewDelegationToken(
-      RenewDelegationTokenRequest request) throws YarnException, IOException {
-    try {
-
-      if (!RouterServerUtil.isAllowedDelegationTokenOp()) {
-        routerMetrics.incrRenewDelegationTokenFailedRetrieved();
-        String msg = "Delegation Token can be renewed only with kerberos authentication";
-        RouterAuditLogger.logFailure(user.getShortUserName(), RENEW_DELEGATIONTOKEN, UNKNOWN,
-            TARGET_CLIENT_RM_SERVICE, msg);
-        throw new IOException(msg);
-      }
-
-      long startTime = clock.getTime();
-      org.apache.hadoop.yarn.api.records.Token protoToken = request.getDelegationToken();
-      Token<RMDelegationTokenIdentifier> token = new Token<>(
-          protoToken.getIdentifier().array(), protoToken.getPassword().array(),
-          new Text(protoToken.getKind()), new Text(protoToken.getService()));
-      String renewer = RouterServerUtil.getRenewerForToken(token);
-      long nextExpTime = this.getTokenSecretManager().renewToken(token, renewer);
-      RenewDelegationTokenResponse renewResponse =
-          Records.newRecord(RenewDelegationTokenResponse.class);
-      renewResponse.setNextExpirationTime(nextExpTime);
-      long stopTime = clock.getTime();
-      routerMetrics.succeededRenewDelegationTokenRetrieved((stopTime - startTime));
-      RouterAuditLogger.logSuccess(user.getShortUserName(), RENEW_DELEGATIONTOKEN,
-          TARGET_CLIENT_RM_SERVICE);
-      return renewResponse;
-
-    } catch (IOException e) {
-      routerMetrics.incrRenewDelegationTokenFailedRetrieved();
-      RouterAuditLogger.logFailure(user.getShortUserName(), RENEW_DELEGATIONTOKEN, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, "renewDelegationToken error, errMsg = " + e.getMessage());
-      throw new YarnException(e);
-    }
-  }
-
-  @Override
-  public CancelDelegationTokenResponse cancelDelegationToken(
-      CancelDelegationTokenRequest request) throws YarnException, IOException {
-    try {
-      if (!RouterServerUtil.isAllowedDelegationTokenOp()) {
-        routerMetrics.incrCancelDelegationTokenFailedRetrieved();
-        String msg = "Delegation Token can be cancelled only with kerberos authentication";
-        RouterAuditLogger.logFailure(user.getShortUserName(), CANCEL_DELEGATIONTOKEN, UNKNOWN,
-            TARGET_CLIENT_RM_SERVICE, msg);
-        throw new IOException(msg);
-      }
-
-      long startTime = clock.getTime();
-      org.apache.hadoop.yarn.api.records.Token protoToken = request.getDelegationToken();
-      Token<RMDelegationTokenIdentifier> token = new Token<>(
-          protoToken.getIdentifier().array(), protoToken.getPassword().array(),
-          new Text(protoToken.getKind()), new Text(protoToken.getService()));
-      String currentUser = UserGroupInformation.getCurrentUser().getUserName();
-      this.getTokenSecretManager().cancelToken(token, currentUser);
-      long stopTime = clock.getTime();
-      routerMetrics.succeededCancelDelegationTokenRetrieved((stopTime - startTime));
-      RouterAuditLogger.logSuccess(user.getShortUserName(), CANCEL_DELEGATIONTOKEN,
-          TARGET_CLIENT_RM_SERVICE);
-      return Records.newRecord(CancelDelegationTokenResponse.class);
-    } catch (IOException e) {
-      routerMetrics.incrCancelDelegationTokenFailedRetrieved();
-      RouterAuditLogger.logFailure(user.getShortUserName(), CANCEL_DELEGATIONTOKEN, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, "cancelDelegationToken error, errMsg = " + e.getMessage());
-      throw new YarnException(e);
-    }
-  }
-
-  @Override
-  public FailApplicationAttemptResponse failApplicationAttempt(
-      FailApplicationAttemptRequest request) throws YarnException, IOException {
-    if (request == null || request.getApplicationAttemptId() == null
-          || request.getApplicationAttemptId().getApplicationId() == null) {
-      routerMetrics.incrFailAppAttemptFailedRetrieved();
-      String msg = "Missing failApplicationAttempt request or applicationId " +
-          "or applicationAttemptId information.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), FAIL_APPLICATIONATTEMPT, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-    long startTime = clock.getTime();
-    SubClusterId subClusterId = null;
-    ApplicationAttemptId applicationAttemptId = request.getApplicationAttemptId();
-    ApplicationId applicationId = applicationAttemptId.getApplicationId();
-
-    try {
-      subClusterId = getApplicationHomeSubCluster(applicationId);
-    } catch (YarnException e) {
-      routerMetrics.incrFailAppAttemptFailedRetrieved();
-      String msg = "ApplicationAttempt " +
-          applicationAttemptId + " belongs to Application " + applicationId +
-          " does not exist in FederationStateStore.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), FAIL_APPLICATIONATTEMPT, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, e);
-    }
-
-    ApplicationClientProtocol clientRMProxy = getClientRMProxyForSubCluster(subClusterId);
-    FailApplicationAttemptResponse response = null;
-    try {
-      response = clientRMProxy.failApplicationAttempt(request);
-    } catch (Exception e) {
-      routerMetrics.incrFailAppAttemptFailedRetrieved();
-      String msg = "Unable to get the applicationAttempt report for " +
-          applicationAttemptId + " to SubCluster " + subClusterId;
-      RouterAuditLogger.logFailure(user.getShortUserName(), FAIL_APPLICATIONATTEMPT, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, e);
-    }
-
-    if (response == null) {
-      LOG.error("No response when attempting to retrieve the report of " +
-          "the applicationAttempt {} to SubCluster {}.",
-          request.getApplicationAttemptId(), subClusterId.getId());
-    }
-
-    long stopTime = clock.getTime();
-    routerMetrics.succeededFailAppAttemptRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), FAIL_APPLICATIONATTEMPT,
-        TARGET_CLIENT_RM_SERVICE, applicationId, subClusterId);
-    return response;
-  }
-
-  @Override
-  public UpdateApplicationPriorityResponse updateApplicationPriority(
-      UpdateApplicationPriorityRequest request)
-      throws YarnException, IOException {
-    if (request == null || request.getApplicationId() == null
-            || request.getApplicationPriority() == null) {
-      routerMetrics.incrUpdateAppPriorityFailedRetrieved();
-      String msg = "Missing updateApplicationPriority request or applicationId " +
-          "or applicationPriority information.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), UPDATE_APPLICATIONPRIORITY, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-
-    long startTime = clock.getTime();
-    SubClusterId subClusterId = null;
-    ApplicationId applicationId = request.getApplicationId();
-
-    try {
-      subClusterId = getApplicationHomeSubCluster(applicationId);
-    } catch (YarnException e) {
-      routerMetrics.incrUpdateAppPriorityFailedRetrieved();
-      String msg = "Application " +
-          applicationId + " does not exist in FederationStateStore.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), UPDATE_APPLICATIONPRIORITY, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, e);
-    }
-
-    ApplicationClientProtocol clientRMProxy = getClientRMProxyForSubCluster(subClusterId);
-    UpdateApplicationPriorityResponse response = null;
-    try {
-      response = clientRMProxy.updateApplicationPriority(request);
-    } catch (Exception e) {
-      routerMetrics.incrFailAppAttemptFailedRetrieved();
-      String msg = "Unable to update application priority for " +
-          applicationId + " to SubCluster " + subClusterId;
-      RouterAuditLogger.logFailure(user.getShortUserName(), UPDATE_APPLICATIONPRIORITY, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, e);
-    }
-
-    if (response == null) {
-      LOG.error("No response when update application priority of " +
-           "the applicationId {} to SubCluster {}.",
-           applicationId, subClusterId.getId());
-    }
-
-    long stopTime = clock.getTime();
-    routerMetrics.succeededUpdateAppPriorityRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), UPDATE_APPLICATIONPRIORITY,
-        TARGET_CLIENT_RM_SERVICE, applicationId, subClusterId);
-    return response;
-  }
-
-  @Override
-  public SignalContainerResponse signalToContainer(
-      SignalContainerRequest request) throws YarnException, IOException {
-    if (request == null || request.getContainerId() == null
-            || request.getCommand() == null) {
-      routerMetrics.incrSignalToContainerFailedRetrieved();
-      String msg = "Missing signalToContainer request or containerId or command information.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), SIGNAL_TOCONTAINER, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-
-    long startTime = clock.getTime();
-    SubClusterId subClusterId = null;
-    ApplicationId applicationId =
-        request.getContainerId().getApplicationAttemptId().getApplicationId();
-    try {
-      subClusterId = getApplicationHomeSubCluster(applicationId);
-    } catch (YarnException ex) {
-      routerMetrics.incrSignalToContainerFailedRetrieved();
-      String msg = "Application " + applicationId + " does not exist in FederationStateStore.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), SIGNAL_TOCONTAINER, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-
-    ApplicationClientProtocol clientRMProxy = getClientRMProxyForSubCluster(subClusterId);
-    SignalContainerResponse response = null;
-    try {
-      response = clientRMProxy.signalToContainer(request);
-    } catch (Exception ex) {
-      String msg = "Unable to signal to container for " + applicationId +
-          " from SubCluster " + subClusterId;
-      RouterAuditLogger.logFailure(user.getShortUserName(), SIGNAL_TOCONTAINER, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-
-    if (response == null) {
-      LOG.error("No response when signal to container of " +
-          "the applicationId {} to SubCluster {}.", applicationId, subClusterId);
-    }
-
-    long stopTime = clock.getTime();
-    routerMetrics.succeededSignalToContainerRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), SIGNAL_TOCONTAINER,
-        TARGET_CLIENT_RM_SERVICE, applicationId, subClusterId);
-    return response;
-  }
-
-  @Override
-  public UpdateApplicationTimeoutsResponse updateApplicationTimeouts(
-      UpdateApplicationTimeoutsRequest request)
-      throws YarnException, IOException {
-    if (request == null || request.getApplicationId() == null
-            || request.getApplicationTimeouts() == null) {
-      routerMetrics.incrUpdateApplicationTimeoutsRetrieved();
-      String msg = "Missing updateApplicationTimeouts request or applicationId or " +
-          "applicationTimeouts information.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), UPDATE_APPLICATIONTIMEOUTS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-
-    long startTime = clock.getTime();
-    SubClusterId subClusterId = null;
-    ApplicationId applicationId = request.getApplicationId();
-    try {
-      subClusterId = getApplicationHomeSubCluster(applicationId);
-    } catch (YarnException e) {
-      routerMetrics.incrFailAppAttemptFailedRetrieved();
-      String msg = "Application " + applicationId + " does not exist in FederationStateStore.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), UPDATE_APPLICATIONTIMEOUTS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, e);
-    }
-
-    ApplicationClientProtocol clientRMProxy = getClientRMProxyForSubCluster(subClusterId);
-    UpdateApplicationTimeoutsResponse response = null;
-    try {
-      response = clientRMProxy.updateApplicationTimeouts(request);
-    } catch (Exception e) {
-      routerMetrics.incrFailAppAttemptFailedRetrieved();
-      String msg = "Unable to update application timeout for " + applicationId +
-          " to SubCluster " + subClusterId;
-      RouterAuditLogger.logFailure(user.getShortUserName(), UPDATE_APPLICATIONTIMEOUTS, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, e);
-    }
-
-    if (response == null) {
-      LOG.error("No response when update application timeout of " +
-          "the applicationId {} to SubCluster {}.",
-          applicationId, subClusterId.getId());
-    }
-
-    long stopTime = clock.getTime();
-    routerMetrics.succeededUpdateAppTimeoutsRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), UPDATE_APPLICATIONTIMEOUTS,
-        TARGET_CLIENT_RM_SERVICE, applicationId, subClusterId);
-    return response;
-  }
-
-  @Override
-  public GetAllResourceProfilesResponse getResourceProfiles(
-      GetAllResourceProfilesRequest request) throws YarnException, IOException {
-    if (request == null) {
-      routerMetrics.incrGetResourceProfilesFailedRetrieved();
-      String msg = "Missing getResourceProfiles request.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_RESOURCEPROFILES, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-    long startTime = clock.getTime();
-    ClientMethod remoteMethod = new ClientMethod("getResourceProfiles",
-        new Class[] {GetAllResourceProfilesRequest.class}, new Object[] {request});
-    Collection<GetAllResourceProfilesResponse> resourceProfiles = null;
-    try {
-      resourceProfiles = invokeConcurrent(remoteMethod, GetAllResourceProfilesResponse.class);
-    } catch (Exception ex) {
-      routerMetrics.incrGetResourceProfilesFailedRetrieved();
-      String msg = "Unable to get resource profiles due to exception.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_RESOURCEPROFILES, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException("Unable to get resource profiles due to exception.",
-          ex);
-    }
-    long stopTime = clock.getTime();
-    routerMetrics.succeededGetResourceProfilesRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), GET_RESOURCEPROFILES,
-        TARGET_CLIENT_RM_SERVICE);
-    return RouterYarnClientUtils.mergeClusterResourceProfilesResponse(resourceProfiles);
-  }
-
-  @Override
-  public GetResourceProfileResponse getResourceProfile(
-      GetResourceProfileRequest request) throws YarnException, IOException {
-    if (request == null || request.getProfileName() == null) {
-      routerMetrics.incrGetResourceProfileFailedRetrieved();
-      String msg = "Missing getResourceProfile request or profileName.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_RESOURCEPROFILE, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-    long startTime = clock.getTime();
-    ClientMethod remoteMethod = new ClientMethod("getResourceProfile",
-        new Class[] {GetResourceProfileRequest.class}, new Object[] {request});
-    Collection<GetResourceProfileResponse> resourceProfile = null;
-    try {
-      resourceProfile = invokeConcurrent(remoteMethod, GetResourceProfileResponse.class);
-    } catch (Exception ex) {
-      routerMetrics.incrGetResourceProfileFailedRetrieved();
-      String msg = "Unable to get resource profile due to exception.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_RESOURCEPROFILE, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-    long stopTime = clock.getTime();
-    routerMetrics.succeededGetResourceProfileRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), GET_RESOURCEPROFILE,
-        TARGET_CLIENT_RM_SERVICE);
-    return RouterYarnClientUtils.mergeClusterResourceProfileResponse(resourceProfile);
-  }
-
-  @Override
-  public GetAllResourceTypeInfoResponse getResourceTypeInfo(
-      GetAllResourceTypeInfoRequest request) throws YarnException, IOException {
-    if (request == null) {
-      routerMetrics.incrResourceTypeInfoFailedRetrieved();
-      String msg = "Missing getResourceTypeInfo request.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_RESOURCETYPEINFO, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-    long startTime = clock.getTime();
-    ClientMethod remoteMethod = new ClientMethod("getResourceTypeInfo",
-        new Class[] {GetAllResourceTypeInfoRequest.class}, new Object[] {request});
-    Collection<GetAllResourceTypeInfoResponse> listResourceTypeInfo;
-    try {
-      listResourceTypeInfo = invokeConcurrent(remoteMethod, GetAllResourceTypeInfoResponse.class);
-    } catch (Exception ex) {
-      routerMetrics.incrResourceTypeInfoFailedRetrieved();
-      String msg = "Unable to get all resource type info node due to exception.";
-      LOG.error(msg, ex);
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_RESOURCETYPEINFO, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      throw ex;
-    }
-    long stopTime = clock.getTime();
-    routerMetrics.succeededGetResourceTypeInfoRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), GET_RESOURCETYPEINFO,
-        TARGET_CLIENT_RM_SERVICE);
-    // Merge the GetAllResourceTypeInfoResponse
-    return RouterYarnClientUtils.mergeResourceTypes(listResourceTypeInfo);
-  }
-
-  @Override
-  public void shutdown() {
-    executorService.shutdown();
-    super.shutdown();
-  }
-
-  @Override
-  public GetAttributesToNodesResponse getAttributesToNodes(
-      GetAttributesToNodesRequest request) throws YarnException, IOException {
-    if (request == null || request.getNodeAttributes() == null) {
-      routerMetrics.incrGetAttributesToNodesFailedRetrieved();
-      String msg = "Missing getAttributesToNodes request or nodeAttributes.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_ATTRIBUTESTONODES, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-    long startTime = clock.getTime();
-    ClientMethod remoteMethod = new ClientMethod("getAttributesToNodes",
-        new Class[] {GetAttributesToNodesRequest.class}, new Object[] {request});
-    Collection<GetAttributesToNodesResponse> attributesToNodesResponses = null;
-    try {
-      attributesToNodesResponses =
-          invokeConcurrent(remoteMethod, GetAttributesToNodesResponse.class);
-    } catch (Exception ex) {
-      routerMetrics.incrGetAttributesToNodesFailedRetrieved();
-      String msg = "Unable to get attributes to nodes due to exception.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_ATTRIBUTESTONODES, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-    long stopTime = clock.getTime();
-    routerMetrics.succeededGetAttributesToNodesRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), GET_ATTRIBUTESTONODES,
-        TARGET_CLIENT_RM_SERVICE);
-    return RouterYarnClientUtils.mergeAttributesToNodesResponse(attributesToNodesResponses);
-  }
-
-  @Override
-  public GetClusterNodeAttributesResponse getClusterNodeAttributes(
-      GetClusterNodeAttributesRequest request) throws YarnException, IOException {
-    if (request == null) {
-      routerMetrics.incrGetClusterNodeAttributesFailedRetrieved();
-      String msg = "Missing getClusterNodeAttributes request.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_CLUSTERNODEATTRIBUTES, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-    long startTime = clock.getTime();
-    ClientMethod remoteMethod = new ClientMethod("getClusterNodeAttributes",
-        new Class[] {GetClusterNodeAttributesRequest.class}, new Object[] {request});
-    Collection<GetClusterNodeAttributesResponse> clusterNodeAttributesResponses = null;
-    try {
-      clusterNodeAttributesResponses = invokeConcurrent(remoteMethod,
-          GetClusterNodeAttributesResponse.class);
-    } catch (Exception ex) {
-      routerMetrics.incrGetClusterNodeAttributesFailedRetrieved();
-      String msg = "Unable to get cluster node attributes due to exception.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_CLUSTERNODEATTRIBUTES, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-    long stopTime = clock.getTime();
-    routerMetrics.succeededGetClusterNodeAttributesRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), GET_CLUSTERNODEATTRIBUTES,
-        TARGET_CLIENT_RM_SERVICE);
-    return RouterYarnClientUtils.mergeClusterNodeAttributesResponse(clusterNodeAttributesResponses);
-  }
-
-  @Override
-  public GetNodesToAttributesResponse getNodesToAttributes(
-      GetNodesToAttributesRequest request) throws YarnException, IOException {
-    if (request == null || request.getHostNames() == null) {
-      routerMetrics.incrGetNodesToAttributesFailedRetrieved();
-      String msg = "Missing getNodesToAttributes request or hostNames.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_NODESTOATTRIBUTES, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, null);
-    }
-    long startTime = clock.getTime();
-    ClientMethod remoteMethod = new ClientMethod("getNodesToAttributes",
-        new Class[] {GetNodesToAttributesRequest.class}, new Object[] {request});
-    Collection<GetNodesToAttributesResponse> nodesToAttributesResponses = null;
-    try {
-      nodesToAttributesResponses = invokeConcurrent(remoteMethod,
-          GetNodesToAttributesResponse.class);
-    } catch (Exception ex) {
-      routerMetrics.incrGetNodesToAttributesFailedRetrieved();
-      String msg = "Unable to get nodes to attributes due to exception.";
-      RouterAuditLogger.logFailure(user.getShortUserName(), GET_NODESTOATTRIBUTES, UNKNOWN,
-          TARGET_CLIENT_RM_SERVICE, msg);
-      RouterServerUtil.logAndThrowException(msg, ex);
-    }
-    long stopTime = clock.getTime();
-    routerMetrics.succeededGetNodesToAttributesRetrieved(stopTime - startTime);
-    RouterAuditLogger.logSuccess(user.getShortUserName(), GET_NODESTOATTRIBUTES,
-        TARGET_CLIENT_RM_SERVICE);
-    return RouterYarnClientUtils.mergeNodesToAttributesResponse(nodesToAttributesResponses);
-  }
-
-  protected SubClusterId getApplicationHomeSubCluster(
-      ApplicationId applicationId) throws YarnException {
-    if (applicationId == null) {
-      LOG.error("ApplicationId is Null, Can't find in SubCluster.");
-      return null;
-    }
-
-    SubClusterId resultSubClusterId = null;
-
-    // try looking for applicationId in Home SubCluster
-    try {
-      resultSubClusterId = federationFacade.
-          getApplicationHomeSubCluster(applicationId);
-    } catch (YarnException ex) {
-      if(LOG.isDebugEnabled()){
-        LOG.debug("Can't find applicationId = {} in home sub cluster, " +
-             " try foreach sub clusters.", applicationId);
-      }
-    }
-    if (resultSubClusterId != null) {
-      return resultSubClusterId;
-    }
-
-    // if applicationId not found in Home SubCluster,
-    // foreach Clusters
-    Map<SubClusterId, SubClusterInfo> subClusters =
-        federationFacade.getSubClusters(true);
-    for (SubClusterId subClusterId : subClusters.keySet()) {
-      try {
-        ApplicationClientProtocol clientRMProxy = getClientRMProxyForSubCluster(subClusterId);
-        if(clientRMProxy == null) {
-          continue;
-        }
-        GetApplicationReportRequest appReportRequest =
-            GetApplicationReportRequest.newInstance(applicationId);
-        GetApplicationReportResponse appReportResponse =
-            clientRMProxy.getApplicationReport(appReportRequest);
-
-        if(appReportResponse!=null && applicationId.equals(
-            appReportResponse.getApplicationReport().getApplicationId())){
-          resultSubClusterId = federationFacade.addApplicationHomeSubCluster(
-               ApplicationHomeSubCluster.newInstance(applicationId, subClusterId));
-          return resultSubClusterId;
-        }
-
-      } catch (Exception ex) {
-        if(LOG.isDebugEnabled()){
-          LOG.debug("Can't find applicationId = {} in Sub Cluster!", applicationId);
-        }
-      }
-    }
-
-    String errorMsg =
-        String.format("Can't find applicationId = %s in any sub clusters", applicationId);
-    throw new YarnException(errorMsg);
-  }
-
-  protected SubClusterId getReservationHomeSubCluster(ReservationId reservationId)
-      throws YarnException {
-
-    if (reservationId == null) {
-      LOG.error("ReservationId is Null, Can't find in SubCluster.");
-      return null;
-    }
-
-    // try looking for reservation in Home SubCluster
-    try {
-      SubClusterId resultSubClusterId =
-          federationFacade.getReservationHomeSubCluster(reservationId);
-      if (resultSubClusterId != null) {
-        return resultSubClusterId;
-      }
-    } catch (YarnException e) {
-      RouterServerUtil.logAndThrowException(e,
-          "Can't find reservationId = %s in home sub cluster.", reservationId);
-    }
-
-    String errorMsg =
-        String.format("Can't find reservationId = %s in home sub cluster.", reservationId);
-    throw new YarnException(errorMsg);
-  }
-
-  @VisibleForTesting
-  public FederationStateStoreFacade getFederationFacade() {
-    return federationFacade;
-  }
-
-  @VisibleForTesting
-  public Map<SubClusterId, ApplicationClientProtocol> getClientRMProxies() {
-    return clientRMProxies;
-  }
-
-  private Boolean existsReservationHomeSubCluster(ReservationId reservationId) {
-    try {
-      SubClusterId subClusterId = federationFacade.getReservationHomeSubCluster(reservationId);
-      if (subClusterId != null) {
-        return true;
-      }
-    } catch (YarnException e) {
-      LOG.warn("get homeSubCluster by reservationId = {} error.", reservationId, e);
-    }
-    return false;
-  }
-
-  private void addReservationHomeSubCluster(ReservationId reservationId,
-      ReservationHomeSubCluster homeSubCluster) throws YarnException {
-    try {
-      // persist the mapping of reservationId and the subClusterId which has
-      // been selected as its home
-      federationFacade.addReservationHomeSubCluster(homeSubCluster);
-    } catch (YarnException e) {
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to insert the ReservationId %s into the FederationStateStore.",
-          reservationId);
-    }
-  }
-
-  private void updateReservationHomeSubCluster(SubClusterId subClusterId,
-      ReservationId reservationId, ReservationHomeSubCluster homeSubCluster) throws YarnException {
-    try {
-      // update the mapping of reservationId and the home subClusterId to
-      // the new subClusterId we have selected
-      federationFacade.updateReservationHomeSubCluster(homeSubCluster);
-    } catch (YarnException e) {
-      SubClusterId subClusterIdInStateStore =
-          federationFacade.getReservationHomeSubCluster(reservationId);
-      if (subClusterId == subClusterIdInStateStore) {
-        LOG.info("Reservation {} already submitted on SubCluster {}.",
-            reservationId, subClusterId);
-      } else {
-        RouterServerUtil.logAndThrowException(e,
-            "Unable to update the ReservationId %s into the FederationStateStore.",
-            reservationId);
-      }
-    }
-  }
-
-  protected int getNumMinThreads(Configuration conf) {
-
-    String threadSize = conf.get(YarnConfiguration.ROUTER_USER_CLIENT_THREADS_SIZE);
-
-    // If the user configures YarnConfiguration.ROUTER_USER_CLIENT_THREADS_SIZE,
-    // we will still get the number of threads from this configuration.
-    if (StringUtils.isNotBlank(threadSize)) {
-      LOG.warn("{} is a deprecated property, " +
-          "please remove it, use {} to configure the minimum number of thread pool.",
-          YarnConfiguration.ROUTER_USER_CLIENT_THREADS_SIZE,
-          YarnConfiguration.ROUTER_USER_CLIENT_THREAD_POOL_MINIMUM_POOL_SIZE);
-      return Integer.parseInt(threadSize);
-    }
-
-    int numMinThreads = conf.getInt(
-        YarnConfiguration.ROUTER_USER_CLIENT_THREAD_POOL_MINIMUM_POOL_SIZE,
-        YarnConfiguration.DEFAULT_ROUTER_USER_CLIENT_THREAD_POOL_MINIMUM_POOL_SIZE);
-    return numMinThreads;
-  }
-
-  protected int getNumMaxThreads(Configuration conf) {
-
-    String threadSize = conf.get(YarnConfiguration.ROUTER_USER_CLIENT_THREADS_SIZE);
-
-    // If the user configures YarnConfiguration.ROUTER_USER_CLIENT_THREADS_SIZE,
-    // we will still get the number of threads from this configuration.
-    if (StringUtils.isNotBlank(threadSize)) {
-      LOG.warn("{} is a deprecated property, " +
-          "please remove it, use {} to configure the maximum number of thread pool.",
-          YarnConfiguration.ROUTER_USER_CLIENT_THREADS_SIZE,
-          YarnConfiguration.ROUTER_USER_CLIENT_THREAD_POOL_MAXIMUM_POOL_SIZE);
-      return Integer.parseInt(threadSize);
-    }
-
-    int numMaxThreads = conf.getInt(
-        YarnConfiguration.ROUTER_USER_CLIENT_THREAD_POOL_MAXIMUM_POOL_SIZE,
-        YarnConfiguration.DEFAULT_ROUTER_USER_CLIENT_THREAD_POOL_MAXIMUM_POOL_SIZE);
-    return numMaxThreads;
-  }
-
-  @VisibleForTesting
-  public void setNumSubmitRetries(int numSubmitRetries) {
-    this.numSubmitRetries = numSubmitRetries;
-  }
-
-  @VisibleForTesting
-  public void setAllowPartialResult(boolean allowPartialResult) {
-    this.allowPartialResult = allowPartialResult;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/PassThroughClientRequestInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/PassThroughClientRequestInterceptor.java
deleted file mode 100644
index fa830d38811..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/PassThroughClientRequestInterceptor.java
+++ /dev/null
@@ -1,315 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import java.io.IOException;
-
-import org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainersResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.KillApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationListResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.SignalContainerResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsResponse;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-
-/**
- * Interceptor that does not do anything other than forwarding it to the next
- * Interceptor in the chain.
- */
-public class PassThroughClientRequestInterceptor extends AbstractClientRequestInterceptor {
-
-  @Override
-  public GetNewApplicationResponse getNewApplication(
-      GetNewApplicationRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getNewApplication(request);
-  }
-
-  @Override
-  public SubmitApplicationResponse submitApplication(
-      SubmitApplicationRequest request) throws YarnException, IOException {
-    return getNextInterceptor().submitApplication(request);
-  }
-
-  @Override
-  public KillApplicationResponse forceKillApplication(
-      KillApplicationRequest request) throws YarnException, IOException {
-    return getNextInterceptor().forceKillApplication(request);
-  }
-
-  @Override
-  public GetClusterMetricsResponse getClusterMetrics(
-      GetClusterMetricsRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getClusterMetrics(request);
-  }
-
-  @Override
-  public GetClusterNodesResponse getClusterNodes(GetClusterNodesRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().getClusterNodes(request);
-  }
-
-  @Override
-  public GetQueueInfoResponse getQueueInfo(GetQueueInfoRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().getQueueInfo(request);
-  }
-
-  @Override
-  public GetQueueUserAclsInfoResponse getQueueUserAcls(
-      GetQueueUserAclsInfoRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getQueueUserAcls(request);
-  }
-
-  @Override
-  public MoveApplicationAcrossQueuesResponse moveApplicationAcrossQueues(
-      MoveApplicationAcrossQueuesRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().moveApplicationAcrossQueues(request);
-  }
-
-  @Override
-  public GetNewReservationResponse getNewReservation(
-      GetNewReservationRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getNewReservation(request);
-  }
-
-  @Override
-  public ReservationSubmissionResponse submitReservation(
-      ReservationSubmissionRequest request) throws YarnException, IOException {
-    return getNextInterceptor().submitReservation(request);
-  }
-
-  @Override
-  public ReservationListResponse listReservations(
-      ReservationListRequest request) throws YarnException, IOException {
-    return getNextInterceptor().listReservations(request);
-  }
-
-  @Override
-  public ReservationUpdateResponse updateReservation(
-      ReservationUpdateRequest request) throws YarnException, IOException {
-    return getNextInterceptor().updateReservation(request);
-  }
-
-  @Override
-  public ReservationDeleteResponse deleteReservation(
-      ReservationDeleteRequest request) throws YarnException, IOException {
-    return getNextInterceptor().deleteReservation(request);
-  }
-
-  @Override
-  public GetNodesToLabelsResponse getNodeToLabels(
-      GetNodesToLabelsRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getNodeToLabels(request);
-  }
-
-  @Override
-  public GetLabelsToNodesResponse getLabelsToNodes(
-      GetLabelsToNodesRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getLabelsToNodes(request);
-  }
-
-  @Override
-  public GetClusterNodeLabelsResponse getClusterNodeLabels(
-      GetClusterNodeLabelsRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getClusterNodeLabels(request);
-  }
-
-  @Override
-  public GetApplicationReportResponse getApplicationReport(
-      GetApplicationReportRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getApplicationReport(request);
-  }
-
-  @Override
-  public GetApplicationsResponse getApplications(GetApplicationsRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().getApplications(request);
-  }
-
-  @Override
-  public GetApplicationAttemptReportResponse getApplicationAttemptReport(
-      GetApplicationAttemptReportRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().getApplicationAttemptReport(request);
-  }
-
-  @Override
-  public GetApplicationAttemptsResponse getApplicationAttempts(
-      GetApplicationAttemptsRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getApplicationAttempts(request);
-  }
-
-  @Override
-  public GetContainerReportResponse getContainerReport(
-      GetContainerReportRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getContainerReport(request);
-  }
-
-  @Override
-  public GetContainersResponse getContainers(GetContainersRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().getContainers(request);
-  }
-
-  @Override
-  public GetDelegationTokenResponse getDelegationToken(
-      GetDelegationTokenRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getDelegationToken(request);
-  }
-
-  @Override
-  public RenewDelegationTokenResponse renewDelegationToken(
-      RenewDelegationTokenRequest request) throws YarnException, IOException {
-    return getNextInterceptor().renewDelegationToken(request);
-  }
-
-  @Override
-  public CancelDelegationTokenResponse cancelDelegationToken(
-      CancelDelegationTokenRequest request) throws YarnException, IOException {
-    return getNextInterceptor().cancelDelegationToken(request);
-  }
-
-  @Override
-  public FailApplicationAttemptResponse failApplicationAttempt(
-      FailApplicationAttemptRequest request) throws YarnException, IOException {
-    return getNextInterceptor().failApplicationAttempt(request);
-  }
-
-  @Override
-  public UpdateApplicationPriorityResponse updateApplicationPriority(
-      UpdateApplicationPriorityRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().updateApplicationPriority(request);
-  }
-
-  @Override
-  public SignalContainerResponse signalToContainer(
-      SignalContainerRequest request) throws YarnException, IOException {
-    return getNextInterceptor().signalToContainer(request);
-  }
-
-  @Override
-  public UpdateApplicationTimeoutsResponse updateApplicationTimeouts(
-      UpdateApplicationTimeoutsRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().updateApplicationTimeouts(request);
-  }
-
-  @Override
-  public GetAllResourceProfilesResponse getResourceProfiles(
-      GetAllResourceProfilesRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getResourceProfiles(request);
-  }
-
-  @Override
-  public GetResourceProfileResponse getResourceProfile(
-      GetResourceProfileRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getResourceProfile(request);
-  }
-
-  @Override
-  public GetAllResourceTypeInfoResponse getResourceTypeInfo(
-      GetAllResourceTypeInfoRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getResourceTypeInfo(request);
-  }
-
-  @Override
-  public GetAttributesToNodesResponse getAttributesToNodes(
-      GetAttributesToNodesRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getAttributesToNodes(request);
-  }
-
-  @Override
-  public GetClusterNodeAttributesResponse getClusterNodeAttributes(
-      GetClusterNodeAttributesRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().getClusterNodeAttributes(request);
-  }
-
-  @Override
-  public GetNodesToAttributesResponse getNodesToAttributes(
-      GetNodesToAttributesRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getNodesToAttributes(request);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/RouterClientRMService.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/RouterClientRMService.java
deleted file mode 100644
index 3d45ad207cf..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/RouterClientRMService.java
+++ /dev/null
@@ -1,667 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import java.io.IOException;
-import java.net.InetAddress;
-import java.net.InetSocketAddress;
-import java.net.URL;
-import java.util.Collections;
-import java.util.Map;
-import java.util.concurrent.TimeUnit;
-
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.classification.InterfaceAudience.Private;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.CommonConfigurationKeysPublic;
-import org.apache.hadoop.ipc.Server;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.security.authorize.PolicyProvider;
-import org.apache.hadoop.service.AbstractService;
-import org.apache.hadoop.yarn.api.ApplicationClientProtocol;
-import org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainersResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.KillApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationListResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.SignalContainerResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsResponse;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-import org.apache.hadoop.yarn.ipc.YarnRPC;
-import org.apache.hadoop.yarn.server.router.RouterServerUtil;
-import org.apache.hadoop.yarn.server.router.security.RouterDelegationTokenSecretManager;
-import org.apache.hadoop.yarn.server.router.security.authorize.RouterPolicyProvider;
-import org.apache.hadoop.yarn.util.LRUCacheHashMap;
-import org.apache.hadoop.yarn.webapp.util.WebAppUtils;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import org.apache.hadoop.classification.VisibleForTesting;
-
-/**
- * RouterClientRMService is a service that runs on each router that can be used
- * to intercept and inspect {@link ApplicationClientProtocol} messages from
- * client to the cluster resource manager. It listens
- * {@link ApplicationClientProtocol} messages from the client and creates a
- * request intercepting pipeline instance for each client. The pipeline is a
- * chain of {@link ClientRequestInterceptor} instances that can inspect and
- * modify the request/response as needed. The main difference with
- * AMRMProxyService is the protocol they implement.
- */
-public class RouterClientRMService extends AbstractService
-    implements ApplicationClientProtocol {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(RouterClientRMService.class);
-
-  private Server server;
-  private InetSocketAddress listenerEndpoint;
-
-  // For each user we store an interceptors' pipeline.
-  // For performance issue we use LRU cache to keep in memory the newest ones
-  // and remove the oldest used ones.
-  private Map<String, RequestInterceptorChainWrapper> userPipelineMap;
-
-  private URL redirectURL;
-  private RouterDelegationTokenSecretManager routerDTSecretManager;
-
-  public RouterClientRMService() {
-    super(RouterClientRMService.class.getName());
-  }
-
-  @Override
-  protected void serviceStart() throws Exception {
-    LOG.info("Starting Router ClientRMService.");
-    Configuration conf = getConfig();
-    YarnRPC rpc = YarnRPC.create(conf);
-    UserGroupInformation.setConfiguration(conf);
-
-    this.listenerEndpoint =
-        conf.getSocketAddr(YarnConfiguration.ROUTER_BIND_HOST,
-            YarnConfiguration.ROUTER_CLIENTRM_ADDRESS,
-            YarnConfiguration.DEFAULT_ROUTER_CLIENTRM_ADDRESS,
-            YarnConfiguration.DEFAULT_ROUTER_CLIENTRM_PORT);
-
-    if (RouterServerUtil.isRouterWebProxyEnable(conf)) {
-      redirectURL = getRedirectURL();
-    }
-
-    int maxCacheSize =
-        conf.getInt(YarnConfiguration.ROUTER_PIPELINE_CACHE_MAX_SIZE,
-            YarnConfiguration.DEFAULT_ROUTER_PIPELINE_CACHE_MAX_SIZE);
-    this.userPipelineMap = Collections.synchronizedMap(new LRUCacheHashMap<>(maxCacheSize, true));
-
-    Configuration serverConf = new Configuration(conf);
-
-    int numWorkerThreads =
-        serverConf.getInt(YarnConfiguration.RM_CLIENT_THREAD_COUNT,
-            YarnConfiguration.DEFAULT_RM_CLIENT_THREAD_COUNT);
-
-    // Initialize RouterRMDelegationTokenSecretManager.
-    routerDTSecretManager = createRouterRMDelegationTokenSecretManager(conf);
-    routerDTSecretManager.startThreads();
-
-    this.server = rpc.getServer(ApplicationClientProtocol.class, this,
-        listenerEndpoint, serverConf, routerDTSecretManager, numWorkerThreads);
-
-    // Enable service authorization?
-    if (conf.getBoolean(
-        CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION, false)) {
-      refreshServiceAcls(conf, RouterPolicyProvider.getInstance());
-    }
-
-    this.server.start();
-    LOG.info("Router ClientRMService listening on address: {}.", this.server.getListenerAddress());
-    super.serviceStart();
-  }
-
-  @Override
-  protected void serviceStop() throws Exception {
-    LOG.info("Stopping Router ClientRMService.");
-    if (this.server != null) {
-      this.server.stop();
-    }
-    userPipelineMap.clear();
-    super.serviceStop();
-  }
-
-  @VisibleForTesting
-  public Server getServer() {
-    return this.server;
-  }
-
-  @Override
-  public GetNewApplicationResponse getNewApplication(
-      GetNewApplicationRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getNewApplication(request);
-  }
-
-  @Override
-  public SubmitApplicationResponse submitApplication(
-      SubmitApplicationRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().submitApplication(request);
-  }
-
-  @Override
-  public KillApplicationResponse forceKillApplication(
-      KillApplicationRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().forceKillApplication(request);
-  }
-
-  @Override
-  public GetClusterMetricsResponse getClusterMetrics(
-      GetClusterMetricsRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getClusterMetrics(request);
-  }
-
-  @Override
-  public GetClusterNodesResponse getClusterNodes(GetClusterNodesRequest request)
-      throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getClusterNodes(request);
-  }
-
-  @Override
-  public GetQueueInfoResponse getQueueInfo(GetQueueInfoRequest request)
-      throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getQueueInfo(request);
-  }
-
-  @Override
-  public GetQueueUserAclsInfoResponse getQueueUserAcls(
-      GetQueueUserAclsInfoRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getQueueUserAcls(request);
-  }
-
-  @Override
-  public MoveApplicationAcrossQueuesResponse moveApplicationAcrossQueues(
-      MoveApplicationAcrossQueuesRequest request)
-      throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().moveApplicationAcrossQueues(request);
-  }
-
-  @Override
-  public GetNewReservationResponse getNewReservation(
-      GetNewReservationRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getNewReservation(request);
-  }
-
-  @Override
-  public ReservationSubmissionResponse submitReservation(
-      ReservationSubmissionRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().submitReservation(request);
-  }
-
-  @Override
-  public ReservationListResponse listReservations(
-      ReservationListRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().listReservations(request);
-  }
-
-  @Override
-  public ReservationUpdateResponse updateReservation(
-      ReservationUpdateRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().updateReservation(request);
-  }
-
-  @Override
-  public ReservationDeleteResponse deleteReservation(
-      ReservationDeleteRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().deleteReservation(request);
-  }
-
-  @Override
-  public GetNodesToLabelsResponse getNodeToLabels(
-      GetNodesToLabelsRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getNodeToLabels(request);
-  }
-
-  @Override
-  public GetLabelsToNodesResponse getLabelsToNodes(
-      GetLabelsToNodesRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getLabelsToNodes(request);
-  }
-
-  @Override
-  public GetClusterNodeLabelsResponse getClusterNodeLabels(
-      GetClusterNodeLabelsRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getClusterNodeLabels(request);
-  }
-
-  @Override
-  public GetApplicationReportResponse getApplicationReport(
-      GetApplicationReportRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    GetApplicationReportResponse response = pipeline.getRootInterceptor()
-        .getApplicationReport(request);
-    if (RouterServerUtil.isRouterWebProxyEnable(getConfig())) {
-      // After redirect url, tracking url in application report will
-      // redirect to embeded proxy server of router
-      URL url = new URL(response.getApplicationReport().getTrackingUrl());
-      String redirectUrl = new URL(redirectURL.getProtocol(),
-          redirectURL.getHost(), redirectURL.getPort(), url.getFile())
-          .toString();
-      if (LOG.isDebugEnabled()) {
-        LOG.debug("The tracking url of application {} is redirect from {} to {}",
-            response.getApplicationReport().getApplicationId(), url, redirectUrl);
-      }
-      response.getApplicationReport().setTrackingUrl(redirectUrl);
-    }
-    return response;
-  }
-
-  @Override
-  public GetApplicationsResponse getApplications(GetApplicationsRequest request)
-      throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getApplications(request);
-  }
-
-  @Override
-  public GetApplicationAttemptReportResponse getApplicationAttemptReport(
-      GetApplicationAttemptReportRequest request)
-      throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getApplicationAttemptReport(request);
-  }
-
-  @Override
-  public GetApplicationAttemptsResponse getApplicationAttempts(
-      GetApplicationAttemptsRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getApplicationAttempts(request);
-  }
-
-  @Override
-  public GetContainerReportResponse getContainerReport(
-      GetContainerReportRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getContainerReport(request);
-  }
-
-  @Override
-  public GetContainersResponse getContainers(GetContainersRequest request)
-      throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getContainers(request);
-  }
-
-  @Override
-  public GetDelegationTokenResponse getDelegationToken(
-      GetDelegationTokenRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getDelegationToken(request);
-  }
-
-  @Override
-  public RenewDelegationTokenResponse renewDelegationToken(
-      RenewDelegationTokenRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().renewDelegationToken(request);
-  }
-
-  @Override
-  public CancelDelegationTokenResponse cancelDelegationToken(
-      CancelDelegationTokenRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().cancelDelegationToken(request);
-  }
-
-  @Override
-  public FailApplicationAttemptResponse failApplicationAttempt(
-      FailApplicationAttemptRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().failApplicationAttempt(request);
-  }
-
-  @Override
-  public UpdateApplicationPriorityResponse updateApplicationPriority(
-      UpdateApplicationPriorityRequest request)
-      throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().updateApplicationPriority(request);
-  }
-
-  @Override
-  public SignalContainerResponse signalToContainer(
-      SignalContainerRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().signalToContainer(request);
-  }
-
-  @Override
-  public UpdateApplicationTimeoutsResponse updateApplicationTimeouts(
-      UpdateApplicationTimeoutsRequest request)
-      throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().updateApplicationTimeouts(request);
-  }
-
-  @Override
-  public GetAllResourceProfilesResponse getResourceProfiles(
-      GetAllResourceProfilesRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getResourceProfiles(request);
-  }
-
-  @Override
-  public GetResourceProfileResponse getResourceProfile(
-      GetResourceProfileRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getResourceProfile(request);
-  }
-
-  @Override
-  public GetAllResourceTypeInfoResponse getResourceTypeInfo(
-      GetAllResourceTypeInfoRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getResourceTypeInfo(request);
-  }
-
-  @Override
-  public GetAttributesToNodesResponse getAttributesToNodes(
-      GetAttributesToNodesRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getAttributesToNodes(request);
-  }
-
-  @Override
-  public GetClusterNodeAttributesResponse getClusterNodeAttributes(
-      GetClusterNodeAttributesRequest request)
-      throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getClusterNodeAttributes(request);
-  }
-
-  @Override
-  public GetNodesToAttributesResponse getNodesToAttributes(
-      GetNodesToAttributesRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getNodesToAttributes(request);
-  }
-
-  @VisibleForTesting
-  public RequestInterceptorChainWrapper getInterceptorChain()
-      throws IOException {
-    String user = UserGroupInformation.getCurrentUser().getUserName();
-    RequestInterceptorChainWrapper chain = userPipelineMap.get(user);
-    if (chain != null && chain.getRootInterceptor() != null) {
-      return chain;
-    }
-    return initializePipeline(user);
-  }
-
-  void refreshServiceAcls(Configuration configuration,
-      PolicyProvider policyProvider) {
-    this.server.refreshServiceAcl(configuration, policyProvider);
-  }
-
-  /**
-   * Gets the Request interceptor chains for all the users.
-   *
-   * @return the request interceptor chains.
-   */
-  @VisibleForTesting
-  protected Map<String, RequestInterceptorChainWrapper> getPipelines() {
-    return this.userPipelineMap;
-  }
-
-  /**
-   * This method creates and returns reference of the first interceptor in the
-   * chain of request interceptor instances.
-   *
-   * @return the reference of the first interceptor in the chain
-   */
-  @VisibleForTesting
-  protected ClientRequestInterceptor createRequestInterceptorChain() {
-    Configuration conf = getConfig();
-    return RouterServerUtil.createRequestInterceptorChain(conf,
-        YarnConfiguration.ROUTER_CLIENTRM_INTERCEPTOR_CLASS_PIPELINE,
-        YarnConfiguration.DEFAULT_ROUTER_CLIENTRM_INTERCEPTOR_CLASS,
-        ClientRequestInterceptor.class);
-  }
-
-  /**
-   * Initializes the request interceptor pipeline for the specified application.
-   *
-   * @param user
-   */
-  private RequestInterceptorChainWrapper initializePipeline(String user) {
-    synchronized (this.userPipelineMap) {
-      if (this.userPipelineMap.containsKey(user)) {
-        LOG.info("Request to start an already existing user: {}"
-            + " was received, so ignoring.", user);
-        return userPipelineMap.get(user);
-      }
-
-      RequestInterceptorChainWrapper chainWrapper =
-          new RequestInterceptorChainWrapper();
-      try {
-        // We should init the pipeline instance after it is created and then
-        // add to the map, to ensure thread safe.
-        LOG.info("Initializing request processing pipeline for application for the user: {}.",
-            user);
-
-        ClientRequestInterceptor interceptorChain =
-            this.createRequestInterceptorChain();
-        interceptorChain.init(user);
-
-        // We set the RouterDelegationTokenSecretManager instance to the interceptorChain
-        // and let the interceptor use it.
-        if (routerDTSecretManager != null) {
-          interceptorChain.setTokenSecretManager(routerDTSecretManager);
-        }
-
-        chainWrapper.init(interceptorChain);
-      } catch (Exception e) {
-        LOG.error("Init ClientRequestInterceptor error for user: {}.", user, e);
-        throw e;
-      }
-
-      this.userPipelineMap.put(user, chainWrapper);
-      return chainWrapper;
-    }
-  }
-
-  /**
-   * Private structure for encapsulating RequestInterceptor and user instances.
-   *
-   */
-  @Private
-  public static class RequestInterceptorChainWrapper {
-    private ClientRequestInterceptor rootInterceptor;
-
-    /**
-     * Initializes the wrapper with the specified parameters.
-     *
-     * @param interceptor the first interceptor in the pipeline
-     */
-    public synchronized void init(ClientRequestInterceptor interceptor) {
-      this.rootInterceptor = interceptor;
-    }
-
-    /**
-     * Gets the root request interceptor.
-     *
-     * @return the root request interceptor
-     */
-    public synchronized ClientRequestInterceptor getRootInterceptor() {
-      return rootInterceptor;
-    }
-
-    /**
-     * Shutdown the chain of interceptors when the object is destroyed.
-     */
-    @Override
-    protected void finalize() {
-      rootInterceptor.shutdown();
-    }
-  }
-
-  @VisibleForTesting
-  public Map<String, RequestInterceptorChainWrapper> getUserPipelineMap() {
-    return userPipelineMap;
-  }
-
-  /**
-   * Create RouterRMDelegationTokenSecretManager.
-   * In the YARN federation, the Router will replace the RM to
-   * manage the RMDelegationToken (generate, update, cancel),
-   * so the relevant configuration parameters still obtain the configuration parameters of the RM.
-   *
-   * @param conf Configuration
-   * @return RouterDelegationTokenSecretManager.
-   */
-  protected RouterDelegationTokenSecretManager createRouterRMDelegationTokenSecretManager(
-      Configuration conf) {
-
-    long secretKeyInterval = conf.getLong(
-        YarnConfiguration.RM_DELEGATION_KEY_UPDATE_INTERVAL_KEY,
-        YarnConfiguration.RM_DELEGATION_KEY_UPDATE_INTERVAL_DEFAULT);
-
-    long tokenMaxLifetime = conf.getLong(
-        YarnConfiguration.RM_DELEGATION_TOKEN_MAX_LIFETIME_KEY,
-        YarnConfiguration.RM_DELEGATION_TOKEN_MAX_LIFETIME_DEFAULT);
-
-    long tokenRenewInterval = conf.getLong(
-        YarnConfiguration.RM_DELEGATION_TOKEN_RENEW_INTERVAL_KEY,
-        YarnConfiguration.RM_DELEGATION_TOKEN_RENEW_INTERVAL_DEFAULT);
-
-    long removeScanInterval = conf.getTimeDuration(
-        YarnConfiguration.RM_DELEGATION_TOKEN_REMOVE_SCAN_INTERVAL_KEY,
-        YarnConfiguration.RM_DELEGATION_TOKEN_REMOVE_SCAN_INTERVAL_DEFAULT,
-        TimeUnit.MILLISECONDS);
-
-    return new RouterDelegationTokenSecretManager(secretKeyInterval,
-        tokenMaxLifetime, tokenRenewInterval, removeScanInterval, conf);
-  }
-
-  @VisibleForTesting
-  public RouterDelegationTokenSecretManager getRouterDTSecretManager() {
-    return routerDTSecretManager;
-  }
-
-  @VisibleForTesting
-  public void setRouterDTSecretManager(RouterDelegationTokenSecretManager routerDTSecretManager) {
-    this.routerDTSecretManager = routerDTSecretManager;
-  }
-
-  @VisibleForTesting
-  public void initUserPipelineMap(Configuration conf) {
-    int maxCacheSize = conf.getInt(YarnConfiguration.ROUTER_PIPELINE_CACHE_MAX_SIZE,
-        YarnConfiguration.DEFAULT_ROUTER_PIPELINE_CACHE_MAX_SIZE);
-    this.userPipelineMap = Collections.synchronizedMap(new LRUCacheHashMap<>(maxCacheSize, true));
-  }
-
-  private URL getRedirectURL() throws Exception {
-    Configuration conf = getConfig();
-    String webAppAddress = WebAppUtils.getWebAppBindURL(conf, YarnConfiguration.ROUTER_BIND_HOST,
-        WebAppUtils.getRouterWebAppURLWithoutScheme(conf));
-    String[] hostPort = StringUtils.split(webAppAddress, ':');
-    if (hostPort.length != 2) {
-      throw new YarnRuntimeException("Router can't get valid redirect proxy url");
-    }
-    String host = hostPort[0];
-    int port = Integer.parseInt(hostPort[1]);
-    if (StringUtils.isBlank(host) || host.equals("0.0.0.0")) {
-      host = InetAddress.getLocalHost().getCanonicalHostName();
-    }
-    return new URL(YarnConfiguration.useHttps(this.getConfig()) ? "https" : "http", host, port, "");
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/RouterYarnClientUtils.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/RouterYarnClientUtils.java
deleted file mode 100644
index feba3f0cad1..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/RouterYarnClientUtils.java
+++ /dev/null
@@ -1,575 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.List;
-import java.util.ArrayList;
-import java.util.Set;
-import java.util.HashSet;
-
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationListResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesResponse;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.ApplicationReport;
-import org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport;
-import org.apache.hadoop.yarn.api.records.YarnClusterMetrics;
-import org.apache.hadoop.yarn.api.records.NodeReport;
-import org.apache.hadoop.yarn.api.records.NodeId;
-import org.apache.hadoop.yarn.api.records.NodeLabel;
-import org.apache.hadoop.yarn.api.records.QueueUserACLInfo;
-import org.apache.hadoop.yarn.api.records.ReservationAllocationState;
-import org.apache.hadoop.yarn.api.records.ResourceTypeInfo;
-import org.apache.hadoop.yarn.api.records.QueueInfo;
-import org.apache.hadoop.yarn.api.records.Resource;
-import org.apache.hadoop.yarn.api.records.NodeAttributeKey;
-import org.apache.hadoop.yarn.api.records.NodeToAttributeValue;
-import org.apache.hadoop.yarn.api.records.NodeAttribute;
-import org.apache.hadoop.yarn.api.records.NodeAttributeInfo;
-import org.apache.hadoop.yarn.server.uam.UnmanagedApplicationManager;
-import org.apache.hadoop.yarn.util.Records;
-import org.apache.hadoop.yarn.util.resource.Resources;
-
-/**
- * Util class for Router Yarn client API calls.
- */
-public final class RouterYarnClientUtils {
-
-  private final static String PARTIAL_REPORT = "Partial Report ";
-
-  private RouterYarnClientUtils() {
-
-  }
-
-  public static GetClusterMetricsResponse merge(
-      Collection<GetClusterMetricsResponse> responses) {
-    YarnClusterMetrics tmp = YarnClusterMetrics.newInstance(0);
-    for (GetClusterMetricsResponse response : responses) {
-      YarnClusterMetrics metrics = response.getClusterMetrics();
-      tmp.setNumNodeManagers(
-          tmp.getNumNodeManagers() + metrics.getNumNodeManagers());
-      tmp.setNumActiveNodeManagers(
-          tmp.getNumActiveNodeManagers() + metrics.getNumActiveNodeManagers());
-      tmp.setNumDecommissioningNodeManagers(
-          tmp.getNumDecommissioningNodeManagers() + metrics
-              .getNumDecommissioningNodeManagers());
-      tmp.setNumDecommissionedNodeManagers(
-          tmp.getNumDecommissionedNodeManagers() + metrics
-              .getNumDecommissionedNodeManagers());
-      tmp.setNumLostNodeManagers(
-          tmp.getNumLostNodeManagers() + metrics.getNumLostNodeManagers());
-      tmp.setNumRebootedNodeManagers(tmp.getNumRebootedNodeManagers() + metrics
-          .getNumRebootedNodeManagers());
-      tmp.setNumUnhealthyNodeManagers(
-          tmp.getNumUnhealthyNodeManagers() + metrics
-              .getNumUnhealthyNodeManagers());
-      tmp.setNumShutdownNodeManagers(
-          tmp.getNumShutdownNodeManagers() + metrics
-              .getNumShutdownNodeManagers());
-    }
-    return GetClusterMetricsResponse.newInstance(tmp);
-  }
-
-  /**
-   * Merges a list of ApplicationReports grouping by ApplicationId.
-   * Our current policy is to merge the application reports from the reachable
-   * SubClusters.
-   * @param responses a list of ApplicationResponse to merge
-   * @param returnPartialResult if the merge ApplicationReports should contain
-   * partial result or not
-   * @return the merged ApplicationsResponse
-   */
-  public static GetApplicationsResponse mergeApplications(
-      Collection<GetApplicationsResponse> responses,
-      boolean returnPartialResult){
-    Map<ApplicationId, ApplicationReport> federationAM = new HashMap<>();
-    Map<ApplicationId, ApplicationReport> federationUAMSum = new HashMap<>();
-
-    for (GetApplicationsResponse appResponse : responses){
-      for (ApplicationReport appReport : appResponse.getApplicationList()){
-        ApplicationId appId = appReport.getApplicationId();
-        // Check if this ApplicationReport is an AM
-        if (!appReport.isUnmanagedApp()) {
-          // Insert in the list of AM
-          federationAM.put(appId, appReport);
-          // Check if there are any UAM found before
-          if (federationUAMSum.containsKey(appId)) {
-            // Merge the current AM with the found UAM
-            mergeAMWithUAM(appReport, federationUAMSum.get(appId));
-            // Remove the sum of the UAMs
-            federationUAMSum.remove(appId);
-          }
-          // This ApplicationReport is an UAM
-        } else if (federationAM.containsKey(appId)) {
-          // Merge the current UAM with its own AM
-          mergeAMWithUAM(federationAM.get(appId), appReport);
-        } else if (federationUAMSum.containsKey(appId)) {
-          // Merge the current UAM with its own UAM and update the list of UAM
-          ApplicationReport mergedUAMReport =
-              mergeUAMWithUAM(federationUAMSum.get(appId), appReport);
-          federationUAMSum.put(appId, mergedUAMReport);
-        } else {
-          // Insert in the list of UAM
-          federationUAMSum.put(appId, appReport);
-        }
-      }
-    }
-    // Check the remaining UAMs are depending or not from federation
-    for (ApplicationReport appReport : federationUAMSum.values()) {
-      if (mergeUamToReport(appReport.getName(), returnPartialResult)) {
-        federationAM.put(appReport.getApplicationId(), appReport);
-      }
-    }
-
-    return GetApplicationsResponse.newInstance(federationAM.values());
-  }
-
-  private static ApplicationReport mergeUAMWithUAM(ApplicationReport uam1,
-      ApplicationReport uam2){
-    uam1.setName(PARTIAL_REPORT + uam1.getApplicationId());
-    mergeAMWithUAM(uam1, uam2);
-    return uam1;
-  }
-
-  private static void mergeAMWithUAM(ApplicationReport am,
-      ApplicationReport uam){
-    ApplicationResourceUsageReport amResourceReport =
-        am.getApplicationResourceUsageReport();
-
-    ApplicationResourceUsageReport uamResourceReport =
-        uam.getApplicationResourceUsageReport();
-
-    if (amResourceReport == null) {
-      am.setApplicationResourceUsageReport(uamResourceReport);
-    } else if (uamResourceReport != null) {
-
-      amResourceReport.setNumUsedContainers(
-          amResourceReport.getNumUsedContainers() +
-              uamResourceReport.getNumUsedContainers());
-
-      amResourceReport.setNumReservedContainers(
-          amResourceReport.getNumReservedContainers() +
-              uamResourceReport.getNumReservedContainers());
-
-      amResourceReport.setUsedResources(Resources.add(
-          amResourceReport.getUsedResources(),
-          uamResourceReport.getUsedResources()));
-
-      amResourceReport.setReservedResources(Resources.add(
-          amResourceReport.getReservedResources(),
-          uamResourceReport.getReservedResources()));
-
-      amResourceReport.setNeededResources(Resources.add(
-          amResourceReport.getNeededResources(),
-          uamResourceReport.getNeededResources()));
-
-      amResourceReport.setMemorySeconds(
-          amResourceReport.getMemorySeconds() +
-              uamResourceReport.getMemorySeconds());
-
-      amResourceReport.setVcoreSeconds(
-          amResourceReport.getVcoreSeconds() +
-              uamResourceReport.getVcoreSeconds());
-
-      amResourceReport.setQueueUsagePercentage(
-          amResourceReport.getQueueUsagePercentage() +
-              uamResourceReport.getQueueUsagePercentage());
-
-      amResourceReport.setClusterUsagePercentage(
-          amResourceReport.getClusterUsagePercentage() +
-              uamResourceReport.getClusterUsagePercentage());
-
-      am.setApplicationResourceUsageReport(amResourceReport);
-    }
-  }
-
-  /**
-   * Returns whether or not to add an unmanaged application to the report.
-   * @param appName Application Name
-   * @param returnPartialResult if the merge ApplicationReports should contain
-   * partial result or not
-   */
-  private static boolean mergeUamToReport(String appName,
-      boolean returnPartialResult){
-    if (returnPartialResult) {
-      return true;
-    }
-    if (appName == null) {
-      return false;
-    }
-    return !(appName.startsWith(UnmanagedApplicationManager.APP_NAME) ||
-        appName.startsWith(PARTIAL_REPORT));
-  }
-
-  /**
-   * Merges a list of GetClusterNodesResponse.
-   *
-   * @param responses a list of GetClusterNodesResponse to merge.
-   * @return the merged GetClusterNodesResponse.
-   */
-  public static GetClusterNodesResponse mergeClusterNodesResponse(
-      Collection<GetClusterNodesResponse> responses) {
-    GetClusterNodesResponse clusterNodesResponse = Records.newRecord(GetClusterNodesResponse.class);
-    List<NodeReport> nodeReports = new ArrayList<>();
-    for (GetClusterNodesResponse response : responses) {
-      if (response != null && response.getNodeReports() != null) {
-        nodeReports.addAll(response.getNodeReports());
-      }
-    }
-    clusterNodesResponse.setNodeReports(nodeReports);
-    return clusterNodesResponse;
-  }
-
-  /**
-   * Merges a list of GetNodesToLabelsResponse.
-   *
-   * @param responses a list of GetNodesToLabelsResponse to merge.
-   * @return the merged GetNodesToLabelsResponse.
-   */
-  public static GetNodesToLabelsResponse mergeNodesToLabelsResponse(
-      Collection<GetNodesToLabelsResponse> responses) {
-    GetNodesToLabelsResponse nodesToLabelsResponse = Records.newRecord(
-         GetNodesToLabelsResponse.class);
-    Map<NodeId, Set<String>> nodesToLabelMap = new HashMap<>();
-    for (GetNodesToLabelsResponse response : responses) {
-      if (response != null && response.getNodeToLabels() != null) {
-        nodesToLabelMap.putAll(response.getNodeToLabels());
-      }
-    }
-    nodesToLabelsResponse.setNodeToLabels(nodesToLabelMap);
-    return nodesToLabelsResponse;
-  }
-
-  /**
-   * Merges a list of GetLabelsToNodesResponse.
-   *
-   * @param responses a list of GetLabelsToNodesResponse to merge.
-   * @return the merged GetLabelsToNodesResponse.
-   */
-  public static GetLabelsToNodesResponse mergeLabelsToNodes(
-      Collection<GetLabelsToNodesResponse> responses){
-    GetLabelsToNodesResponse labelsToNodesResponse = Records.newRecord(
-        GetLabelsToNodesResponse.class);
-    Map<String, Set<NodeId>> labelsToNodesMap = new HashMap<>();
-    for (GetLabelsToNodesResponse response : responses) {
-      if (response != null && response.getLabelsToNodes() != null) {
-        Map<String, Set<NodeId>> clusterLabelsToNodesMap = response.getLabelsToNodes();
-        for (Map.Entry<String, Set<NodeId>> entry : clusterLabelsToNodesMap.entrySet()) {
-          String label = entry.getKey();
-          Set<NodeId> clusterNodes = entry.getValue();
-          if (labelsToNodesMap.containsKey(label)) {
-            Set<NodeId> allNodes = labelsToNodesMap.get(label);
-            allNodes.addAll(clusterNodes);
-          } else {
-            labelsToNodesMap.put(label, clusterNodes);
-          }
-        }
-      }
-    }
-    labelsToNodesResponse.setLabelsToNodes(labelsToNodesMap);
-    return labelsToNodesResponse;
-  }
-
-  /**
-   * Merges a list of GetClusterNodeLabelsResponse.
-   *
-   * @param responses a list of GetClusterNodeLabelsResponse to merge.
-   * @return the merged GetClusterNodeLabelsResponse.
-   */
-  public static GetClusterNodeLabelsResponse mergeClusterNodeLabelsResponse(
-      Collection<GetClusterNodeLabelsResponse> responses) {
-    GetClusterNodeLabelsResponse nodeLabelsResponse = Records.newRecord(
-        GetClusterNodeLabelsResponse.class);
-    Set<NodeLabel> nodeLabelsList = new HashSet<>();
-    for (GetClusterNodeLabelsResponse response : responses) {
-      if (response != null && response.getNodeLabelList() != null) {
-        nodeLabelsList.addAll(response.getNodeLabelList());
-      }
-    }
-    nodeLabelsResponse.setNodeLabelList(new ArrayList<>(nodeLabelsList));
-    return nodeLabelsResponse;
-  }
-
-  /**
-   * Merges a list of GetQueueUserAclsInfoResponse.
-   *
-   * @param responses a list of GetQueueUserAclsInfoResponse to merge.
-   * @return the merged GetQueueUserAclsInfoResponse.
-   */
-  public static GetQueueUserAclsInfoResponse mergeQueueUserAcls(
-      Collection<GetQueueUserAclsInfoResponse> responses) {
-    GetQueueUserAclsInfoResponse aclsInfoResponse = Records.newRecord(
-        GetQueueUserAclsInfoResponse.class);
-    Set<QueueUserACLInfo> queueUserACLInfos = new HashSet<>();
-    for (GetQueueUserAclsInfoResponse response : responses) {
-      if (response != null && response.getUserAclsInfoList() != null) {
-        queueUserACLInfos.addAll(response.getUserAclsInfoList());
-      }
-    }
-    aclsInfoResponse.setUserAclsInfoList(new ArrayList<>(queueUserACLInfos));
-    return aclsInfoResponse;
-  }
-
-  /**
-   * Merges a list of ReservationListResponse.
-   *
-   * @param responses a list of ReservationListResponse to merge.
-   * @return the merged ReservationListResponse.
-   */
-  public static ReservationListResponse mergeReservationsList(
-      Collection<ReservationListResponse> responses) {
-    ReservationListResponse reservationListResponse =
-        Records.newRecord(ReservationListResponse.class);
-    List<ReservationAllocationState> reservationAllocationStates =
-        new ArrayList<>();
-    for (ReservationListResponse response : responses) {
-      if (response != null && response.getReservationAllocationState() != null) {
-        reservationAllocationStates.addAll(
-            response.getReservationAllocationState());
-      }
-    }
-    reservationListResponse.setReservationAllocationState(
-        reservationAllocationStates);
-    return reservationListResponse;
-  }
-
-  /**
-   * Merges a list of GetAllResourceTypeInfoResponse.
-   *
-   * @param responses a list of GetAllResourceTypeInfoResponse to merge.
-   * @return the merged GetAllResourceTypeInfoResponse.
-   */
-  public static GetAllResourceTypeInfoResponse mergeResourceTypes(
-      Collection<GetAllResourceTypeInfoResponse> responses) {
-    GetAllResourceTypeInfoResponse resourceTypeInfoResponse =
-        Records.newRecord(GetAllResourceTypeInfoResponse.class);
-    Set<ResourceTypeInfo> resourceTypeInfoSet = new HashSet<>();
-    for (GetAllResourceTypeInfoResponse response : responses) {
-      if (response != null && response.getResourceTypeInfo() != null) {
-        resourceTypeInfoSet.addAll(response.getResourceTypeInfo());
-      }
-    }
-    resourceTypeInfoResponse.setResourceTypeInfo(
-        new ArrayList<>(resourceTypeInfoSet));
-    return resourceTypeInfoResponse;
-  }
-
-  /**
-   * Merges a list of GetQueueInfoResponse.
-   *
-   * @param responses a list of GetQueueInfoResponse to merge.
-   * @return the merged GetQueueInfoResponse.
-   */
-  public static GetQueueInfoResponse mergeQueues(
-      Collection<GetQueueInfoResponse> responses) {
-    GetQueueInfoResponse queueResponse = Records.newRecord(
-        GetQueueInfoResponse.class);
-
-    QueueInfo queueInfo = null;
-    for (GetQueueInfoResponse response : responses) {
-      if (response != null && response.getQueueInfo() != null) {
-        if (queueInfo == null) {
-          queueInfo = response.getQueueInfo();
-        } else {
-          // set Capacity\MaximumCapacity\CurrentCapacity
-          queueInfo.setCapacity(queueInfo.getCapacity() + response.getQueueInfo().getCapacity());
-          queueInfo.setMaximumCapacity(
-              queueInfo.getMaximumCapacity() + response.getQueueInfo().getMaximumCapacity());
-          queueInfo.setCurrentCapacity(
-              queueInfo.getCurrentCapacity() + response.getQueueInfo().getCurrentCapacity());
-
-          // set childQueues
-          List<QueueInfo> childQueues = new ArrayList<>(queueInfo.getChildQueues());
-          childQueues.addAll(response.getQueueInfo().getChildQueues());
-          queueInfo.setChildQueues(childQueues);
-
-          // set applications
-          List<ApplicationReport> applicationReports = new ArrayList<>(queueInfo.getApplications());
-          applicationReports.addAll(response.getQueueInfo().getApplications());
-          queueInfo.setApplications(applicationReports);
-
-          // set accessibleNodeLabels
-          Set<String> accessibleNodeLabels = new HashSet<>();
-          if (queueInfo.getAccessibleNodeLabels() != null) {
-            accessibleNodeLabels.addAll(queueInfo.getAccessibleNodeLabels());
-          }
-
-          // set min resourceVCore
-          queueInfo.setMinResourceVCore(queueInfo.getMinResourceVCore() +
-              response.getQueueInfo().getMinResourceVCore());
-
-          // set min resourceMemory
-          queueInfo.setMinResourceMemory(queueInfo.getMinResourceMemory() +
-              response.getQueueInfo().getMinResourceMemory());
-
-          // set max resourceVCore
-          queueInfo.setMinResourceVCore(queueInfo.getMaxResourceVCore() +
-              response.getQueueInfo().getMaxResourceVCore());
-
-          // set max resourceMemory
-          queueInfo.setMinResourceMemory(queueInfo.getMaxResourceMemory() +
-              response.getQueueInfo().getMaxResourceMemory());
-
-          // set reserved resourceVCore
-          queueInfo.setReservedResourceVCore(queueInfo.getReservedResourceVCore() +
-              response.getQueueInfo().getMaxResourceVCore());
-
-          // set reserved resourceMemory
-          queueInfo.setReservedResourceMemory(queueInfo.getReservedResourceMemory() +
-              response.getQueueInfo().getMaxResourceMemory());
-
-          // set maxRunningApp
-          queueInfo.setMaxRunningApp(queueInfo.getMaxRunningApp() +
-              response.getQueueInfo().getMaxRunningApp());
-
-          // set steadyFairShareVCore
-          queueInfo.setSteadyFairShareVCore(queueInfo.getSteadyFairShareVCore() +
-              response.getQueueInfo().getSteadyFairShareVCore());
-
-          // set steadyFairShareMemory
-          queueInfo.setSteadyFairShareMemory(queueInfo.getSteadyFairShareMemory() +
-              response.getQueueInfo().getSteadyFairShareMemory());
-
-          // set Weight
-          queueInfo.setWeight(queueInfo.getWeight() +
-              response.getQueueInfo().getWeight());
-
-          if (response.getQueueInfo() != null) {
-            accessibleNodeLabels.addAll(response.getQueueInfo().getAccessibleNodeLabels());
-          }
-          queueInfo.setAccessibleNodeLabels(accessibleNodeLabels);
-        }
-      }
-    }
-    queueResponse.setQueueInfo(queueInfo);
-    return queueResponse;
-  }
-
-  /**
-   * Merges a list of GetAllResourceProfilesResponse.
-   *
-   * @param responses a list of GetAllResourceProfilesResponse to merge.
-   * @return the merged GetAllResourceProfilesResponse.
-   */
-  public static GetAllResourceProfilesResponse mergeClusterResourceProfilesResponse(
-      Collection<GetAllResourceProfilesResponse> responses) {
-    GetAllResourceProfilesResponse profilesResponse =
-        Records.newRecord(GetAllResourceProfilesResponse.class);
-    Map<String, Resource> profilesMap = new HashMap<>();
-    for (GetAllResourceProfilesResponse response : responses) {
-      if (response != null && response.getResourceProfiles() != null) {
-        for (Map.Entry<String, Resource> entry : response.getResourceProfiles().entrySet()) {
-          String key = entry.getKey();
-          Resource r1 = profilesMap.getOrDefault(key, null);
-          Resource r2 = entry.getValue();
-          Resource rAdd = r1 == null ? r2 : Resources.add(r1, r2);
-          profilesMap.put(key, rAdd);
-        }
-      }
-    }
-    profilesResponse.setResourceProfiles(profilesMap);
-    return profilesResponse;
-  }
-
-  /**
-   * Merges a list of GetResourceProfileResponse.
-   *
-   * @param responses a list of GetResourceProfileResponse to merge.
-   * @return the merged GetResourceProfileResponse.
-   */
-  public static GetResourceProfileResponse mergeClusterResourceProfileResponse(
-      Collection<GetResourceProfileResponse> responses) {
-    GetResourceProfileResponse profileResponse =
-        Records.newRecord(GetResourceProfileResponse.class);
-    Resource resource = Resource.newInstance(0, 0);
-    for (GetResourceProfileResponse response : responses) {
-      if (response != null && response.getResource() != null) {
-        Resource responseResource = response.getResource();
-        resource = Resources.add(resource, responseResource);
-      }
-    }
-    profileResponse.setResource(resource);
-    return profileResponse;
-  }
-
-  /**
-   * Merges a list of GetAttributesToNodesResponse.
-   *
-   * @param responses a list of GetAttributesToNodesResponse to merge.
-   * @return the merged GetAttributesToNodesResponse.
-   */
-  public static GetAttributesToNodesResponse mergeAttributesToNodesResponse(
-      Collection<GetAttributesToNodesResponse> responses) {
-    Map<NodeAttributeKey, List<NodeToAttributeValue>> nodeAttributeMap = new HashMap<>();
-    for (GetAttributesToNodesResponse response : responses) {
-      if (response != null && response.getAttributesToNodes() != null) {
-        nodeAttributeMap.putAll(response.getAttributesToNodes());
-      }
-    }
-    return GetAttributesToNodesResponse.newInstance(nodeAttributeMap);
-  }
-
-  /**
-   * Merges a list of GetClusterNodeAttributesResponse.
-   *
-   * @param responses a list of GetClusterNodeAttributesResponse to merge.
-   * @return the merged GetClusterNodeAttributesResponse.
-   */
-  public static GetClusterNodeAttributesResponse mergeClusterNodeAttributesResponse(
-      Collection<GetClusterNodeAttributesResponse> responses) {
-    Set<NodeAttributeInfo> nodeAttributeInfo = new HashSet<>();
-    for (GetClusterNodeAttributesResponse response : responses) {
-      if (response != null && response.getNodeAttributes() != null) {
-        nodeAttributeInfo.addAll(response.getNodeAttributes());
-      }
-    }
-    return GetClusterNodeAttributesResponse.newInstance(nodeAttributeInfo);
-  }
-
-  /**
-   * Merges a list of GetNodesToAttributesResponse.
-   *
-   * @param responses a list of GetNodesToAttributesResponse to merge.
-   * @return the merged GetNodesToAttributesResponse.
-   */
-  public static GetNodesToAttributesResponse mergeNodesToAttributesResponse(
-      Collection<GetNodesToAttributesResponse> responses) {
-    Map<String, Set<NodeAttribute>> attributesMap = new HashMap<>();
-    for (GetNodesToAttributesResponse response : responses) {
-      if (response != null && response.getNodeToAttributes() != null) {
-        attributesMap.putAll(response.getNodeToAttributes());
-      }
-    }
-    return GetNodesToAttributesResponse.newInstance(attributesMap);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/package-info.java
deleted file mode 100644
index 7d1dadd373b..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/clientrm/package-info.java
+++ /dev/null
@@ -1,20 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/** Router ClientRM Proxy Service package. **/
-package org.apache.hadoop.yarn.server.router.clientrm;
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/package-info.java
deleted file mode 100644
index bca1f640104..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/package-info.java
+++ /dev/null
@@ -1,20 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/** Router Server package. **/
-package org.apache.hadoop.yarn.server.router;
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/AbstractRMAdminRequestInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/AbstractRMAdminRequestInterceptor.java
deleted file mode 100644
index 8b09d699719..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/AbstractRMAdminRequestInterceptor.java
+++ /dev/null
@@ -1,96 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.rmadmin;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.yarn.server.router.RouterServerUtil;
-
-/**
- * Implements the {@link RMAdminRequestInterceptor} interface and provides
- * common functionality which can can be used and/or extended by other concrete
- * interceptor classes.
- *
- */
-public abstract class AbstractRMAdminRequestInterceptor
-    implements RMAdminRequestInterceptor {
-  private Configuration conf;
-  private RMAdminRequestInterceptor nextInterceptor;
-
-  @SuppressWarnings("checkstyle:visibilitymodifier")
-  protected UserGroupInformation user = null;
-
-  /**
-   * Sets the {@link RMAdminRequestInterceptor} in the chain.
-   */
-  @Override
-  public void setNextInterceptor(RMAdminRequestInterceptor nextInterceptor) {
-    this.nextInterceptor = nextInterceptor;
-  }
-
-  /**
-   * Sets the {@link Configuration}.
-   */
-
-  @Override
-  public void setConf(Configuration conf) {
-    this.conf = conf;
-    if (this.nextInterceptor != null) {
-      this.nextInterceptor.setConf(conf);
-    }
-  }
-
-  /**
-   * Gets the {@link Configuration}.
-   */
-  @Override
-  public Configuration getConf() {
-    return this.conf;
-  }
-
-  /**
-   * Initializes the {@link RMAdminRequestInterceptor}.
-   */
-  @Override
-  public void init(String userName) {
-    this.user = RouterServerUtil.setupUser(userName);
-    if (this.nextInterceptor != null) {
-      this.nextInterceptor.init(userName);
-    }
-  }
-
-  /**
-   * Disposes the {@link RMAdminRequestInterceptor}.
-   */
-  @Override
-  public void shutdown() {
-    if (this.nextInterceptor != null) {
-      this.nextInterceptor.shutdown();
-    }
-  }
-
-  /**
-   * Gets the next {@link RMAdminRequestInterceptor} in the chain.
-   */
-  @Override
-  public RMAdminRequestInterceptor getNextInterceptor() {
-    return this.nextInterceptor;
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/DefaultRMAdminRequestInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/DefaultRMAdminRequestInterceptor.java
deleted file mode 100644
index a5531cd6225..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/DefaultRMAdminRequestInterceptor.java
+++ /dev/null
@@ -1,261 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.rmadmin;
-
-import java.io.IOException;
-import java.security.PrivilegedExceptionAction;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.ipc.StandbyException;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.yarn.client.ClientRMProxy;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-import org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol;
-import org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.CheckForDecommissioningNodesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.CheckForDecommissioningNodesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshAdminAclsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshAdminAclsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshClusterMaxPriorityRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshClusterMaxPriorityResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshQueuesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshQueuesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshSuperUserGroupsConfigurationRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshSuperUserGroupsConfigurationResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshUserToGroupsMappingsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshUserToGroupsMappingsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RemoveFromClusterNodeLabelsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RemoveFromClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeregisterSubClusterRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeregisterSubClusterResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.SaveFederationQueuePolicyRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.SaveFederationQueuePolicyResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.BatchSaveFederationQueuePoliciesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.BatchSaveFederationQueuePoliciesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.QueryFederationQueuePoliciesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.QueryFederationQueuePoliciesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationApplicationRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationApplicationResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.GetSubClustersRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.GetSubClustersResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationQueuePoliciesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationQueuePoliciesResponse;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import org.apache.hadoop.classification.VisibleForTesting;
-
-/**
- * Extends the {@link AbstractRMAdminRequestInterceptor} class and provides an
- * implementation that simply forwards the client requests to the cluster
- * resource manager.
- *
- */
-public class DefaultRMAdminRequestInterceptor
-    extends AbstractRMAdminRequestInterceptor {
-  private static final Logger LOG =
-      LoggerFactory.getLogger(DefaultRMAdminRequestInterceptor.class);
-  private ResourceManagerAdministrationProtocol rmAdminProxy;
-  private UserGroupInformation user = null;
-
-  @Override
-  public void init(String userName) {
-    super.init(userName);
-    try {
-      final Configuration conf = this.getConf();
-      rmAdminProxy = user.doAs(
-          (PrivilegedExceptionAction<ResourceManagerAdministrationProtocol>) () ->
-               ClientRMProxy.createRMProxy(conf, ResourceManagerAdministrationProtocol.class));
-    } catch (Exception e) {
-      StringBuilder message = new StringBuilder();
-      message.append("Error while creating Router RMAdmin Service");
-      if (user != null) {
-        message.append(", user: " + user);
-      }
-      LOG.error(message.toString(), e);
-      throw new YarnRuntimeException(message.toString(), e);
-    }
-  }
-
-  @Override
-  public void setNextInterceptor(RMAdminRequestInterceptor next) {
-    throw new YarnRuntimeException("setNextInterceptor is being called on "
-        + "DefaultRMAdminRequestInterceptor, which should be the last one "
-        + "in the chain. Check if the interceptor pipeline configuration "
-        + "is correct");
-  }
-
-  @VisibleForTesting
-  public void setRMAdmin(ResourceManagerAdministrationProtocol rmAdmin) {
-    this.rmAdminProxy = rmAdmin;
-  }
-
-  @Override
-  public RefreshQueuesResponse refreshQueues(RefreshQueuesRequest request)
-      throws StandbyException, YarnException, IOException {
-    return rmAdminProxy.refreshQueues(request);
-  }
-
-  @Override
-  public RefreshNodesResponse refreshNodes(RefreshNodesRequest request)
-      throws StandbyException, YarnException, IOException {
-    return rmAdminProxy.refreshNodes(request);
-  }
-
-  @Override
-  public RefreshSuperUserGroupsConfigurationResponse refreshSuperUserGroupsConfiguration(
-      RefreshSuperUserGroupsConfigurationRequest request)
-      throws StandbyException, YarnException, IOException {
-    return rmAdminProxy.refreshSuperUserGroupsConfiguration(request);
-  }
-
-  @Override
-  public RefreshUserToGroupsMappingsResponse refreshUserToGroupsMappings(
-      RefreshUserToGroupsMappingsRequest request)
-      throws StandbyException, YarnException, IOException {
-    return rmAdminProxy.refreshUserToGroupsMappings(request);
-  }
-
-  @Override
-  public RefreshAdminAclsResponse refreshAdminAcls(
-      RefreshAdminAclsRequest request) throws YarnException, IOException {
-    return rmAdminProxy.refreshAdminAcls(request);
-  }
-
-  @Override
-  public RefreshServiceAclsResponse refreshServiceAcls(
-      RefreshServiceAclsRequest request) throws YarnException, IOException {
-    return rmAdminProxy.refreshServiceAcls(request);
-  }
-
-  @Override
-  public UpdateNodeResourceResponse updateNodeResource(
-      UpdateNodeResourceRequest request) throws YarnException, IOException {
-    return rmAdminProxy.updateNodeResource(request);
-  }
-
-  @Override
-  public RefreshNodesResourcesResponse refreshNodesResources(
-      RefreshNodesResourcesRequest request) throws YarnException, IOException {
-    return rmAdminProxy.refreshNodesResources(request);
-  }
-
-  @Override
-  public AddToClusterNodeLabelsResponse addToClusterNodeLabels(
-      AddToClusterNodeLabelsRequest request) throws YarnException, IOException {
-    return rmAdminProxy.addToClusterNodeLabels(request);
-  }
-
-  @Override
-  public RemoveFromClusterNodeLabelsResponse removeFromClusterNodeLabels(
-      RemoveFromClusterNodeLabelsRequest request)
-      throws YarnException, IOException {
-    return rmAdminProxy.removeFromClusterNodeLabels(request);
-  }
-
-  @Override
-  public ReplaceLabelsOnNodeResponse replaceLabelsOnNode(
-      ReplaceLabelsOnNodeRequest request) throws YarnException, IOException {
-    return rmAdminProxy.replaceLabelsOnNode(request);
-  }
-
-  @Override
-  public CheckForDecommissioningNodesResponse checkForDecommissioningNodes(
-      CheckForDecommissioningNodesRequest checkForDecommissioningNodesRequest)
-      throws YarnException, IOException {
-    return rmAdminProxy
-        .checkForDecommissioningNodes(checkForDecommissioningNodesRequest);
-  }
-
-  @Override
-  public RefreshClusterMaxPriorityResponse refreshClusterMaxPriority(
-      RefreshClusterMaxPriorityRequest request)
-      throws YarnException, IOException {
-    return rmAdminProxy.refreshClusterMaxPriority(request);
-  }
-
-  @Override
-  public String[] getGroupsForUser(String userName) throws IOException {
-    return rmAdminProxy.getGroupsForUser(userName);
-  }
-
-  @Override
-  public NodesToAttributesMappingResponse mapAttributesToNodes(
-      NodesToAttributesMappingRequest request)
-      throws YarnException, IOException {
-    return rmAdminProxy.mapAttributesToNodes(request);
-  }
-
-  @Override
-  public DeregisterSubClusterResponse deregisterSubCluster(DeregisterSubClusterRequest request)
-      throws YarnException, IOException {
-    return rmAdminProxy.deregisterSubCluster(request);
-  }
-
-  @Override
-  public SaveFederationQueuePolicyResponse saveFederationQueuePolicy(
-      SaveFederationQueuePolicyRequest request) throws YarnException, IOException {
-    return rmAdminProxy.saveFederationQueuePolicy(request);
-  }
-
-  @Override
-  public BatchSaveFederationQueuePoliciesResponse batchSaveFederationQueuePolicies(
-      BatchSaveFederationQueuePoliciesRequest request) throws YarnException, IOException {
-    return rmAdminProxy.batchSaveFederationQueuePolicies(request);
-  }
-
-  @Override
-  public QueryFederationQueuePoliciesResponse listFederationQueuePolicies(
-      QueryFederationQueuePoliciesRequest request) throws YarnException, IOException {
-    return rmAdminProxy.listFederationQueuePolicies(request);
-  }
-
-  @Override
-  public DeleteFederationApplicationResponse deleteFederationApplication(
-      DeleteFederationApplicationRequest request)
-      throws YarnException, IOException {
-    return rmAdminProxy.deleteFederationApplication(request);
-  }
-
-  @Override
-  public GetSubClustersResponse getFederationSubClusters(
-      GetSubClustersRequest request) throws YarnException, IOException {
-    return rmAdminProxy.getFederationSubClusters(request);
-  }
-
-  @Override
-  public DeleteFederationQueuePoliciesResponse deleteFederationPoliciesByQueues(
-      DeleteFederationQueuePoliciesRequest request) throws YarnException, IOException {
-    return rmAdminProxy.deleteFederationPoliciesByQueues(request);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/FederationRMAdminInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/FederationRMAdminInterceptor.java
deleted file mode 100644
index fee734f4fb3..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/FederationRMAdminInterceptor.java
+++ /dev/null
@@ -1,1574 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.rmadmin;
-
-import org.apache.commons.collections.CollectionUtils;
-import org.apache.commons.collections.MapUtils;
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.classification.VisibleForTesting;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.CommonConfigurationKeys;
-import org.apache.hadoop.ipc.StandbyException;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ThreadFactoryBuilder;
-import org.apache.hadoop.util.Time;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.NodeId;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-import org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshQueuesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshQueuesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshSuperUserGroupsConfigurationRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshSuperUserGroupsConfigurationResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshUserToGroupsMappingsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshUserToGroupsMappingsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshAdminAclsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshAdminAclsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RemoveFromClusterNodeLabelsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RemoveFromClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.CheckForDecommissioningNodesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.CheckForDecommissioningNodesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshClusterMaxPriorityRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshClusterMaxPriorityResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeregisterSubClusterRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeregisterSubClusterResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeregisterSubClusters;
-import org.apache.hadoop.yarn.server.api.protocolrecords.FederationQueueWeight;
-import org.apache.hadoop.yarn.server.api.protocolrecords.FederationSubCluster;
-import org.apache.hadoop.yarn.server.api.protocolrecords.SaveFederationQueuePolicyRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.SaveFederationQueuePolicyResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.BatchSaveFederationQueuePoliciesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.BatchSaveFederationQueuePoliciesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.QueryFederationQueuePoliciesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.QueryFederationQueuePoliciesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationQueuePoliciesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationQueuePoliciesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationApplicationRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationApplicationResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.GetSubClustersRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.GetSubClustersResponse;
-import org.apache.hadoop.yarn.server.federation.failover.FederationProxyProviderUtil;
-import org.apache.hadoop.yarn.server.federation.policies.manager.PriorityBroadcastPolicyManager;
-import org.apache.hadoop.yarn.server.federation.policies.manager.WeightedHomePolicyManager;
-import org.apache.hadoop.yarn.server.federation.policies.manager.WeightedLocalityPolicyManager;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterIdInfo;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterState;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration;
-import org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.router.RouterMetrics;
-import org.apache.hadoop.yarn.server.router.RouterServerUtil;
-import org.apache.hadoop.yarn.util.Clock;
-import org.apache.hadoop.yarn.util.MonotonicClock;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.util.List;
-import java.util.Arrays;
-import java.util.ArrayList;
-import java.util.Map;
-import java.util.HashMap;
-import java.util.Collection;
-import java.util.Set;
-import java.util.Date;
-import java.util.HashSet;
-import java.util.concurrent.ThreadPoolExecutor;
-import java.util.concurrent.ThreadFactory;
-import java.util.concurrent.BlockingQueue;
-import java.util.concurrent.LinkedBlockingQueue;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.stream.Collectors;
-
-import static org.apache.hadoop.yarn.server.router.RouterServerUtil.checkPolicyManagerValid;
-
-public class FederationRMAdminInterceptor extends AbstractRMAdminRequestInterceptor {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(FederationRMAdminInterceptor.class);
-
-  private static final String COMMA = ",";
-  private static final String COLON = ":";
-
-  private static final List<String> SUPPORT_WEIGHT_MANAGERS =
-      new ArrayList<>(Arrays.asList(WeightedLocalityPolicyManager.class.getName(),
-      PriorityBroadcastPolicyManager.class.getName(), WeightedHomePolicyManager.class.getName()));
-
-  private Map<SubClusterId, ResourceManagerAdministrationProtocol> adminRMProxies;
-  private FederationStateStoreFacade federationFacade;
-  private final Clock clock = new MonotonicClock();
-  private RouterMetrics routerMetrics;
-  private ThreadPoolExecutor executorService;
-  private Configuration conf;
-  private long heartbeatExpirationMillis;
-
-  @Override
-  public void init(String userName) {
-    super.init(userName);
-
-    int numThreads = getConf().getInt(
-        YarnConfiguration.ROUTER_USER_CLIENT_THREADS_SIZE,
-        YarnConfiguration.DEFAULT_ROUTER_USER_CLIENT_THREADS_SIZE);
-    ThreadFactory threadFactory = new ThreadFactoryBuilder()
-        .setNameFormat("RPC Router RMAdminClient-" + userName + "-%d ").build();
-
-    long keepAliveTime = getConf().getTimeDuration(
-        YarnConfiguration.ROUTER_USER_CLIENT_THREAD_POOL_KEEP_ALIVE_TIME,
-        YarnConfiguration.DEFAULT_ROUTER_USER_CLIENT_THREAD_POOL_KEEP_ALIVE_TIME, TimeUnit.SECONDS);
-
-    BlockingQueue<Runnable> workQueue = new LinkedBlockingQueue<>();
-    this.executorService = new ThreadPoolExecutor(numThreads, numThreads,
-        keepAliveTime, TimeUnit.MILLISECONDS, workQueue, threadFactory);
-
-    boolean allowCoreThreadTimeOut =  getConf().getBoolean(
-        YarnConfiguration.ROUTER_USER_CLIENT_THREAD_POOL_ALLOW_CORE_THREAD_TIMEOUT,
-        YarnConfiguration.DEFAULT_ROUTER_USER_CLIENT_THREAD_POOL_ALLOW_CORE_THREAD_TIMEOUT);
-
-    if (keepAliveTime > 0 && allowCoreThreadTimeOut) {
-      this.executorService.allowCoreThreadTimeOut(allowCoreThreadTimeOut);
-    }
-
-    federationFacade = FederationStateStoreFacade.getInstance(this.getConf());
-    this.conf = this.getConf();
-    this.adminRMProxies = new ConcurrentHashMap<>();
-    routerMetrics = RouterMetrics.getMetrics();
-
-    this.heartbeatExpirationMillis = this.conf.getTimeDuration(
-        YarnConfiguration.ROUTER_SUBCLUSTER_EXPIRATION_TIME,
-        YarnConfiguration.DEFAULT_ROUTER_SUBCLUSTER_EXPIRATION_TIME, TimeUnit.MILLISECONDS);
-  }
-
-  @VisibleForTesting
-  protected ResourceManagerAdministrationProtocol getAdminRMProxyForSubCluster(
-      SubClusterId subClusterId) throws Exception {
-
-    if (adminRMProxies.containsKey(subClusterId)) {
-      return adminRMProxies.get(subClusterId);
-    }
-
-    ResourceManagerAdministrationProtocol adminRMProxy = null;
-    try {
-      boolean serviceAuthEnabled = this.conf.getBoolean(
-          CommonConfigurationKeys.HADOOP_SECURITY_AUTHORIZATION, false);
-      UserGroupInformation realUser = user;
-      if (serviceAuthEnabled) {
-        realUser = UserGroupInformation.createProxyUser(
-            user.getShortUserName(), UserGroupInformation.getLoginUser());
-      }
-      adminRMProxy = FederationProxyProviderUtil.createRMProxy(getConf(),
-          ResourceManagerAdministrationProtocol.class, subClusterId, realUser);
-    } catch (Exception e) {
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to create the interface to reach the SubCluster %s", subClusterId);
-    }
-    adminRMProxies.put(subClusterId, adminRMProxy);
-    return adminRMProxy;
-  }
-
-  @Override
-  public void setNextInterceptor(RMAdminRequestInterceptor next) {
-    throw new YarnRuntimeException("setNextInterceptor is being called on "
-       + "FederationRMAdminRequestInterceptor, which should be the last one "
-       + "in the chain. Check if the interceptor pipeline configuration "
-       + "is correct");
-  }
-
-  /**
-   * Refresh queue requests.
-   *
-   * The Router supports refreshing all SubCluster queues at once,
-   * and also supports refreshing queues by SubCluster.
-   *
-   * @param request RefreshQueuesRequest, If subClusterId is not empty,
-   * it means that we want to refresh the queue of the specified subClusterId.
-   * If subClusterId is empty, it means we want to refresh all queues.
-   *
-   * @return RefreshQueuesResponse, There is no specific information in the response,
-   * as long as it is not empty, it means that the request is successful.
-   *
-   * @throws StandbyException exception thrown by non-active server.
-   * @throws YarnException indicates exceptions from yarn servers.
-   * @throws IOException io error occurs.
-   */
-  @Override
-  public RefreshQueuesResponse refreshQueues(RefreshQueuesRequest request)
-      throws StandbyException, YarnException, IOException {
-
-    // parameter verification.
-    if (request == null) {
-      routerMetrics.incrRefreshQueuesFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing RefreshQueues request.", null);
-    }
-
-    // call refreshQueues of activeSubClusters.
-    try {
-      long startTime = clock.getTime();
-      RMAdminProtocolMethod remoteMethod = new RMAdminProtocolMethod(
-           new Class[] {RefreshQueuesRequest.class}, new Object[] {request});
-
-      String subClusterId = request.getSubClusterId();
-      Collection<RefreshQueuesResponse> refreshQueueResps =
-          remoteMethod.invokeConcurrent(this, RefreshQueuesResponse.class, subClusterId);
-
-      // If we get the return result from refreshQueueResps,
-      // it means that the call has been successful,
-      // and the RefreshQueuesResponse method can be reconstructed and returned.
-      if (CollectionUtils.isNotEmpty(refreshQueueResps)) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededRefreshQueuesRetrieved(stopTime - startTime);
-        return RefreshQueuesResponse.newInstance();
-      }
-    } catch (YarnException e) {
-      routerMetrics.incrRefreshQueuesFailedRetrieved();
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to refreshQueue due to exception. " + e.getMessage());
-    }
-
-    routerMetrics.incrRefreshQueuesFailedRetrieved();
-    throw new YarnException("Unable to refreshQueue.");
-  }
-
-  /**
-   * Refresh node requests.
-   *
-   * The Router supports refreshing all SubCluster nodes at once,
-   * and also supports refreshing node by SubCluster.
-   *
-   * @param request RefreshNodesRequest, If subClusterId is not empty,
-   * it means that we want to refresh the node of the specified subClusterId.
-   * If subClusterId is empty, it means we want to refresh all nodes.
-   *
-   * @return RefreshNodesResponse, There is no specific information in the response,
-   * as long as it is not empty, it means that the request is successful.
-   *
-   * @throws StandbyException exception thrown by non-active server.
-   * @throws YarnException indicates exceptions from yarn servers.
-   * @throws IOException io error occurs.
-   */
-  @Override
-  public RefreshNodesResponse refreshNodes(RefreshNodesRequest request)
-      throws StandbyException, YarnException, IOException {
-
-    // parameter verification.
-    // We will not check whether the DecommissionType is empty,
-    // because this parameter has a default value at the proto level.
-    if (request == null) {
-      routerMetrics.incrRefreshNodesFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing RefreshNodes request.", null);
-    }
-
-    // call refreshNodes of activeSubClusters.
-    try {
-      long startTime = clock.getTime();
-      RMAdminProtocolMethod remoteMethod = new RMAdminProtocolMethod(
-          new Class[] {RefreshNodesRequest.class}, new Object[] {request});
-
-      String subClusterId = request.getSubClusterId();
-      Collection<RefreshNodesResponse> refreshNodesResps =
-          remoteMethod.invokeConcurrent(this, RefreshNodesResponse.class, subClusterId);
-
-      if (CollectionUtils.isNotEmpty(refreshNodesResps)) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededRefreshNodesRetrieved(stopTime - startTime);
-        return RefreshNodesResponse.newInstance();
-      }
-    } catch (YarnException e) {
-      routerMetrics.incrRefreshNodesFailedRetrieved();
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to refreshNodes due to exception. " + e.getMessage());
-    }
-
-    routerMetrics.incrRefreshNodesFailedRetrieved();
-    throw new YarnException("Unable to refreshNodes due to exception.");
-  }
-
-  /**
-   * Refresh SuperUserGroupsConfiguration requests.
-   *
-   * The Router supports refreshing all subCluster SuperUserGroupsConfiguration at once,
-   * and also supports refreshing SuperUserGroupsConfiguration by SubCluster.
-   *
-   * @param request RefreshSuperUserGroupsConfigurationRequest,
-   * If subClusterId is not empty, it means that we want to
-   * refresh the superuser groups configuration of the specified subClusterId.
-   * If subClusterId is empty, it means we want to
-   * refresh all subCluster superuser groups configuration.
-   *
-   * @return RefreshSuperUserGroupsConfigurationResponse,
-   * There is no specific information in the response, as long as it is not empty,
-   * it means that the request is successful.
-   *
-   * @throws StandbyException exception thrown by non-active server.
-   * @throws YarnException indicates exceptions from yarn servers.
-   * @throws IOException io error occurs.
-   */
-  @Override
-  public RefreshSuperUserGroupsConfigurationResponse refreshSuperUserGroupsConfiguration(
-      RefreshSuperUserGroupsConfigurationRequest request)
-      throws StandbyException, YarnException, IOException {
-
-    // parameter verification.
-    if (request == null) {
-      routerMetrics.incrRefreshSuperUserGroupsConfigurationFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing RefreshSuperUserGroupsConfiguration request.",
-          null);
-    }
-
-    // call refreshSuperUserGroupsConfiguration of activeSubClusters.
-    try {
-      long startTime = clock.getTime();
-      RMAdminProtocolMethod remoteMethod = new RMAdminProtocolMethod(
-          new Class[] {RefreshSuperUserGroupsConfigurationRequest.class}, new Object[] {request});
-
-      String subClusterId = request.getSubClusterId();
-      Collection<RefreshSuperUserGroupsConfigurationResponse> refreshSuperUserGroupsConfResps =
-          remoteMethod.invokeConcurrent(this, RefreshSuperUserGroupsConfigurationResponse.class,
-          subClusterId);
-
-      if (CollectionUtils.isNotEmpty(refreshSuperUserGroupsConfResps)) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededRefreshSuperUserGroupsConfRetrieved(stopTime - startTime);
-        return RefreshSuperUserGroupsConfigurationResponse.newInstance();
-      }
-    } catch (YarnException e) {
-      routerMetrics.incrRefreshSuperUserGroupsConfigurationFailedRetrieved();
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to refreshSuperUserGroupsConfiguration due to exception. " + e.getMessage());
-    }
-
-    routerMetrics.incrRefreshSuperUserGroupsConfigurationFailedRetrieved();
-    throw new YarnException("Unable to refreshSuperUserGroupsConfiguration.");
-  }
-
-  /**
-   * Refresh UserToGroupsMappings requests.
-   *
-   * The Router supports refreshing all subCluster UserToGroupsMappings at once,
-   * and also supports refreshing UserToGroupsMappings by subCluster.
-   *
-   * @param request RefreshUserToGroupsMappingsRequest,
-   * If subClusterId is not empty, it means that we want to
-   * refresh the user groups mapping of the specified subClusterId.
-   * If subClusterId is empty, it means we want to
-   * refresh all subCluster user groups mapping.
-   *
-   * @return RefreshUserToGroupsMappingsResponse,
-   * There is no specific information in the response, as long as it is not empty,
-   * it means that the request is successful.
-   *
-   * @throws StandbyException exception thrown by non-active server.
-   * @throws YarnException indicates exceptions from yarn servers.
-   * @throws IOException io error occurs.
-   */
-  @Override
-  public RefreshUserToGroupsMappingsResponse refreshUserToGroupsMappings(
-      RefreshUserToGroupsMappingsRequest request) throws StandbyException, YarnException,
-      IOException {
-
-    // parameter verification.
-    if (request == null) {
-      routerMetrics.incrRefreshUserToGroupsMappingsFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing RefreshUserToGroupsMappings request.", null);
-    }
-
-    // call refreshUserToGroupsMappings of activeSubClusters.
-    try {
-      long startTime = clock.getTime();
-      RMAdminProtocolMethod remoteMethod = new RMAdminProtocolMethod(
-          new Class[] {RefreshUserToGroupsMappingsRequest.class}, new Object[] {request});
-
-      String subClusterId = request.getSubClusterId();
-      Collection<RefreshUserToGroupsMappingsResponse> refreshUserToGroupsMappingsResps =
-          remoteMethod.invokeConcurrent(this, RefreshUserToGroupsMappingsResponse.class,
-          subClusterId);
-
-      if (CollectionUtils.isNotEmpty(refreshUserToGroupsMappingsResps)) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededRefreshUserToGroupsMappingsRetrieved(stopTime - startTime);
-        return RefreshUserToGroupsMappingsResponse.newInstance();
-      }
-    } catch (YarnException e) {
-      routerMetrics.incrRefreshUserToGroupsMappingsFailedRetrieved();
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to refreshUserToGroupsMappings due to exception. " + e.getMessage());
-    }
-
-    routerMetrics.incrRefreshUserToGroupsMappingsFailedRetrieved();
-    throw new YarnException("Unable to refreshUserToGroupsMappings.");
-  }
-
-  @Override
-  public RefreshAdminAclsResponse refreshAdminAcls(RefreshAdminAclsRequest request)
-      throws YarnException, IOException {
-
-    // parameter verification.
-    if (request == null) {
-      routerMetrics.incrRefreshAdminAclsFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing RefreshAdminAcls request.", null);
-    }
-
-    // call refreshAdminAcls of activeSubClusters.
-    try {
-      long startTime = clock.getTime();
-      RMAdminProtocolMethod remoteMethod = new RMAdminProtocolMethod(
-          new Class[] {RefreshAdminAclsRequest.class}, new Object[] {request});
-      String subClusterId = request.getSubClusterId();
-      Collection<RefreshAdminAclsResponse> refreshAdminAclsResps =
-          remoteMethod.invokeConcurrent(this, RefreshAdminAclsResponse.class, subClusterId);
-      if (CollectionUtils.isNotEmpty(refreshAdminAclsResps)) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededRefreshAdminAclsRetrieved(stopTime - startTime);
-        return RefreshAdminAclsResponse.newInstance();
-      }
-    } catch (YarnException e) {
-      routerMetrics.incrRefreshAdminAclsFailedRetrieved();
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to refreshAdminAcls due to exception. " + e.getMessage());
-    }
-
-    routerMetrics.incrRefreshAdminAclsFailedRetrieved();
-    throw new YarnException("Unable to refreshAdminAcls.");
-  }
-
-  @Override
-  public RefreshServiceAclsResponse refreshServiceAcls(RefreshServiceAclsRequest request)
-      throws YarnException, IOException {
-
-    // parameter verification.
-    if (request == null) {
-      routerMetrics.incrRefreshServiceAclsFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing RefreshServiceAcls request.", null);
-    }
-
-    // call refreshAdminAcls of activeSubClusters.
-    try {
-      long startTime = clock.getTime();
-      RMAdminProtocolMethod remoteMethod = new RMAdminProtocolMethod(
-          new Class[]{RefreshServiceAclsRequest.class}, new Object[]{request});
-      String subClusterId = request.getSubClusterId();
-      Collection<RefreshServiceAclsResponse> refreshServiceAclsResps =
-          remoteMethod.invokeConcurrent(this, RefreshServiceAclsResponse.class, subClusterId);
-      if (CollectionUtils.isNotEmpty(refreshServiceAclsResps)) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededRefreshServiceAclsRetrieved(stopTime - startTime);
-        return RefreshServiceAclsResponse.newInstance();
-      }
-    } catch (YarnException e) {
-      routerMetrics.incrRefreshServiceAclsFailedRetrieved();
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to refreshAdminAcls due to exception. " + e.getMessage());
-    }
-
-    routerMetrics.incrRefreshServiceAclsFailedRetrieved();
-    throw new YarnException("Unable to refreshServiceAcls.");
-  }
-
-  @Override
-  public UpdateNodeResourceResponse updateNodeResource(UpdateNodeResourceRequest request)
-      throws YarnException, IOException {
-
-    // parameter verification.
-    if (request == null) {
-      routerMetrics.incrUpdateNodeResourceFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing UpdateNodeResource request.", null);
-    }
-
-    String subClusterId = request.getSubClusterId();
-    if (StringUtils.isBlank(subClusterId)) {
-      routerMetrics.incrUpdateNodeResourceFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing UpdateNodeResource SubClusterId.", null);
-    }
-
-    try {
-      long startTime = clock.getTime();
-      RMAdminProtocolMethod remoteMethod = new RMAdminProtocolMethod(
-          new Class[]{UpdateNodeResourceRequest.class}, new Object[]{request});
-      Collection<UpdateNodeResourceResponse> updateNodeResourceResps =
-          remoteMethod.invokeConcurrent(this, UpdateNodeResourceResponse.class, subClusterId);
-      if (CollectionUtils.isNotEmpty(updateNodeResourceResps)) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededUpdateNodeResourceRetrieved(stopTime - startTime);
-        return UpdateNodeResourceResponse.newInstance();
-      }
-    } catch (YarnException e) {
-      routerMetrics.incrUpdateNodeResourceFailedRetrieved();
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to updateNodeResource due to exception. " + e.getMessage());
-    }
-
-    routerMetrics.incrUpdateNodeResourceFailedRetrieved();
-    throw new YarnException("Unable to updateNodeResource.");
-  }
-
-  @Override
-  public RefreshNodesResourcesResponse refreshNodesResources(RefreshNodesResourcesRequest request)
-      throws YarnException, IOException {
-
-    // parameter verification.
-    if (request == null) {
-      routerMetrics.incrRefreshNodesResourcesFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing RefreshNodesResources request.", null);
-    }
-
-    String subClusterId = request.getSubClusterId();
-    if (StringUtils.isBlank(subClusterId)) {
-      routerMetrics.incrRefreshNodesResourcesFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing RefreshNodesResources SubClusterId.", null);
-    }
-
-    try {
-      long startTime = clock.getTime();
-      RMAdminProtocolMethod remoteMethod = new RMAdminProtocolMethod(
-          new Class[]{RefreshNodesResourcesRequest.class}, new Object[]{request});
-      Collection<RefreshNodesResourcesResponse> refreshNodesResourcesResps =
-          remoteMethod.invokeConcurrent(this, RefreshNodesResourcesResponse.class, subClusterId);
-      if (CollectionUtils.isNotEmpty(refreshNodesResourcesResps)) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededRefreshNodesResourcesRetrieved(stopTime - startTime);
-        return RefreshNodesResourcesResponse.newInstance();
-      }
-    } catch (YarnException e) {
-      routerMetrics.incrRefreshNodesResourcesFailedRetrieved();
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to refreshNodesResources due to exception. " + e.getMessage());
-    }
-
-    routerMetrics.incrRefreshNodesResourcesFailedRetrieved();
-    throw new YarnException("Unable to refreshNodesResources.");
-  }
-
-  @Override
-  public AddToClusterNodeLabelsResponse addToClusterNodeLabels(
-      AddToClusterNodeLabelsRequest request) throws YarnException, IOException {
-    // parameter verification.
-    if (request == null) {
-      routerMetrics.incrAddToClusterNodeLabelsFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing AddToClusterNodeLabels request.", null);
-    }
-
-    String subClusterId = request.getSubClusterId();
-    if (StringUtils.isBlank(subClusterId)) {
-      routerMetrics.incrAddToClusterNodeLabelsFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing AddToClusterNodeLabels SubClusterId.", null);
-    }
-
-    try {
-      long startTime = clock.getTime();
-      RMAdminProtocolMethod remoteMethod = new RMAdminProtocolMethod(
-          new Class[]{AddToClusterNodeLabelsRequest.class}, new Object[]{request});
-      Collection<AddToClusterNodeLabelsResponse> addToClusterNodeLabelsResps =
-          remoteMethod.invokeConcurrent(this, AddToClusterNodeLabelsResponse.class, subClusterId);
-      if (CollectionUtils.isNotEmpty(addToClusterNodeLabelsResps)) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededAddToClusterNodeLabelsRetrieved(stopTime - startTime);
-        return AddToClusterNodeLabelsResponse.newInstance();
-      }
-    } catch (YarnException e) {
-      routerMetrics.incrAddToClusterNodeLabelsFailedRetrieved();
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to addToClusterNodeLabels due to exception. " + e.getMessage());
-    }
-
-    routerMetrics.incrAddToClusterNodeLabelsFailedRetrieved();
-    throw new YarnException("Unable to addToClusterNodeLabels.");
-  }
-
-  @Override
-  public RemoveFromClusterNodeLabelsResponse removeFromClusterNodeLabels(
-      RemoveFromClusterNodeLabelsRequest request)
-      throws YarnException, IOException {
-    // parameter verification.
-    if (request == null) {
-      routerMetrics.incrRemoveFromClusterNodeLabelsFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing RemoveFromClusterNodeLabels request.", null);
-    }
-
-    String subClusterId = request.getSubClusterId();
-    if (StringUtils.isBlank(subClusterId)) {
-      routerMetrics.incrRemoveFromClusterNodeLabelsFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing RemoveFromClusterNodeLabels SubClusterId.",
-          null);
-    }
-
-    try {
-      long startTime = clock.getTime();
-      RMAdminProtocolMethod remoteMethod = new RMAdminProtocolMethod(
-          new Class[]{RemoveFromClusterNodeLabelsRequest.class}, new Object[]{request});
-      Collection<RemoveFromClusterNodeLabelsResponse> refreshNodesResourcesResps =
-          remoteMethod.invokeConcurrent(this, RemoveFromClusterNodeLabelsResponse.class,
-          subClusterId);
-      if (CollectionUtils.isNotEmpty(refreshNodesResourcesResps)) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededRemoveFromClusterNodeLabelsRetrieved(stopTime - startTime);
-        return RemoveFromClusterNodeLabelsResponse.newInstance();
-      }
-    } catch (YarnException e) {
-      routerMetrics.incrRemoveFromClusterNodeLabelsFailedRetrieved();
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to removeFromClusterNodeLabels due to exception. " + e.getMessage());
-    }
-
-    routerMetrics.incrRemoveFromClusterNodeLabelsFailedRetrieved();
-    throw new YarnException("Unable to removeFromClusterNodeLabels.");
-  }
-
-  @Override
-  public ReplaceLabelsOnNodeResponse replaceLabelsOnNode(ReplaceLabelsOnNodeRequest request)
-      throws YarnException, IOException {
-    // parameter verification.
-    if (request == null) {
-      routerMetrics.incrReplaceLabelsOnNodeFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing ReplaceLabelsOnNode request.", null);
-    }
-
-    String subClusterId = request.getSubClusterId();
-    if (StringUtils.isBlank(subClusterId)) {
-      routerMetrics.incrReplaceLabelsOnNodeFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing ReplaceLabelsOnNode SubClusterId.", null);
-    }
-
-    try {
-      long startTime = clock.getTime();
-      RMAdminProtocolMethod remoteMethod = new RMAdminProtocolMethod(
-          new Class[]{ReplaceLabelsOnNodeRequest.class}, new Object[]{request});
-      Collection<ReplaceLabelsOnNodeResponse> replaceLabelsOnNodeResps =
-          remoteMethod.invokeConcurrent(this, ReplaceLabelsOnNodeResponse.class, subClusterId);
-      if (CollectionUtils.isNotEmpty(replaceLabelsOnNodeResps)) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededRemoveFromClusterNodeLabelsRetrieved(stopTime - startTime);
-        return ReplaceLabelsOnNodeResponse.newInstance();
-      }
-    } catch (YarnException e) {
-      routerMetrics.incrReplaceLabelsOnNodeFailedRetrieved();
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to replaceLabelsOnNode due to exception. " + e.getMessage());
-    }
-
-    routerMetrics.incrReplaceLabelsOnNodeFailedRetrieved();
-    throw new YarnException("Unable to replaceLabelsOnNode.");
-  }
-
-  @Override
-  public CheckForDecommissioningNodesResponse checkForDecommissioningNodes(
-      CheckForDecommissioningNodesRequest request) throws YarnException, IOException {
-
-    // Parameter check
-    if (request == null) {
-      RouterServerUtil.logAndThrowException("Missing checkForDecommissioningNodes request.", null);
-      routerMetrics.incrCheckForDecommissioningNodesFailedRetrieved();
-    }
-
-    String subClusterId = request.getSubClusterId();
-    if (StringUtils.isBlank(subClusterId)) {
-      routerMetrics.incrCheckForDecommissioningNodesFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing checkForDecommissioningNodes SubClusterId.",
-          null);
-    }
-
-    try {
-      long startTime = clock.getTime();
-      RMAdminProtocolMethod remoteMethod = new RMAdminProtocolMethod(
-          new Class[]{CheckForDecommissioningNodesRequest.class}, new Object[]{request});
-
-      Collection<CheckForDecommissioningNodesResponse> responses =
-          remoteMethod.invokeConcurrent(this, CheckForDecommissioningNodesResponse.class,
-          subClusterId);
-
-      if (CollectionUtils.isNotEmpty(responses)) {
-        // We selected a subCluster, the list is not empty and size=1.
-        List<CheckForDecommissioningNodesResponse> collects =
-            responses.stream().collect(Collectors.toList());
-        if (!collects.isEmpty() && collects.size() == 1) {
-          CheckForDecommissioningNodesResponse response = collects.get(0);
-          long stopTime = clock.getTime();
-          routerMetrics.succeededCheckForDecommissioningNodesRetrieved((stopTime - startTime));
-          Set<NodeId> nodes = response.getDecommissioningNodes();
-          return CheckForDecommissioningNodesResponse.newInstance(nodes);
-        }
-      }
-    } catch (YarnException e) {
-      routerMetrics.incrCheckForDecommissioningNodesFailedRetrieved();
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to checkForDecommissioningNodes due to exception " + e.getMessage());
-    }
-
-    routerMetrics.incrCheckForDecommissioningNodesFailedRetrieved();
-    throw new YarnException("Unable to checkForDecommissioningNodes.");
-  }
-
-  @Override
-  public RefreshClusterMaxPriorityResponse refreshClusterMaxPriority(
-      RefreshClusterMaxPriorityRequest request) throws YarnException, IOException {
-
-    // parameter verification.
-    if (request == null) {
-      routerMetrics.incrRefreshClusterMaxPriorityFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing RefreshClusterMaxPriority request.", null);
-    }
-
-    String subClusterId = request.getSubClusterId();
-    if (StringUtils.isBlank(subClusterId)) {
-      routerMetrics.incrRefreshClusterMaxPriorityFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing RefreshClusterMaxPriority SubClusterId.",
-          null);
-    }
-
-    try {
-      long startTime = clock.getTime();
-      RMAdminProtocolMethod remoteMethod = new RMAdminProtocolMethod(
-          new Class[]{RefreshClusterMaxPriorityRequest.class}, new Object[]{request});
-      Collection<RefreshClusterMaxPriorityResponse> refreshClusterMaxPriorityResps =
-          remoteMethod.invokeConcurrent(this, RefreshClusterMaxPriorityResponse.class,
-          subClusterId);
-      if (CollectionUtils.isNotEmpty(refreshClusterMaxPriorityResps)) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededRefreshClusterMaxPriorityRetrieved(stopTime - startTime);
-        return RefreshClusterMaxPriorityResponse.newInstance();
-      }
-    } catch (YarnException e) {
-      routerMetrics.incrRefreshClusterMaxPriorityFailedRetrieved();
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to refreshClusterMaxPriority due to exception. " + e.getMessage());
-    }
-
-    routerMetrics.incrRefreshClusterMaxPriorityFailedRetrieved();
-    throw new YarnException("Unable to refreshClusterMaxPriority.");
-  }
-
-  @Override
-  public NodesToAttributesMappingResponse mapAttributesToNodes(
-      NodesToAttributesMappingRequest request) throws YarnException, IOException {
-    // parameter verification.
-    if (request == null) {
-      routerMetrics.incrMapAttributesToNodesFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing mapAttributesToNodes request.", null);
-    }
-
-    String subClusterId = request.getSubClusterId();
-    if (StringUtils.isBlank(subClusterId)) {
-      routerMetrics.incrMapAttributesToNodesFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing mapAttributesToNodes SubClusterId.", null);
-    }
-
-    try {
-      long startTime = clock.getTime();
-      RMAdminProtocolMethod remoteMethod = new RMAdminProtocolMethod(
-          new Class[]{NodesToAttributesMappingRequest.class}, new Object[]{request});
-      Collection<NodesToAttributesMappingResponse> mapAttributesToNodesResps =
-          remoteMethod.invokeConcurrent(this, NodesToAttributesMappingResponse.class,
-          subClusterId);
-      if (CollectionUtils.isNotEmpty(mapAttributesToNodesResps)) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededMapAttributesToNodesRetrieved(stopTime - startTime);
-        return NodesToAttributesMappingResponse.newInstance();
-      }
-    } catch (YarnException e) {
-      routerMetrics.incrMapAttributesToNodesFailedRetrieved();
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to mapAttributesToNodes due to exception. " + e.getMessage());
-    }
-
-    routerMetrics.incrMapAttributesToNodesFailedRetrieved();
-    throw new YarnException("Unable to mapAttributesToNodes.");
-  }
-
-  @Override
-  public String[] getGroupsForUser(String user) throws IOException {
-    // parameter verification.
-    if (StringUtils.isBlank(user)) {
-      routerMetrics.incrGetGroupsForUserFailedRetrieved();
-      RouterServerUtil.logAndThrowIOException("Missing getGroupsForUser user.", null);
-    }
-
-    try {
-      long startTime = clock.getTime();
-      RMAdminProtocolMethod remoteMethod = new RMAdminProtocolMethod(
-          new Class[]{String.class}, new Object[]{user});
-      Collection<String[]> getGroupsForUserResps =
-          remoteMethod.invokeConcurrent(this, String[].class, null);
-      if (CollectionUtils.isNotEmpty(getGroupsForUserResps)) {
-        long stopTime = clock.getTime();
-        Set<String> groups = new HashSet<>();
-        for (String[] groupArr : getGroupsForUserResps) {
-          if (groupArr != null && groupArr.length > 0) {
-            for (String group : groupArr) {
-              groups.add(group);
-            }
-          }
-        }
-        routerMetrics.succeededGetGroupsForUsersRetrieved(stopTime - startTime);
-        return groups.toArray(new String[]{});
-      }
-    } catch (YarnException e) {
-      routerMetrics.incrGetGroupsForUserFailedRetrieved();
-      RouterServerUtil.logAndThrowIOException(e,
-          "Unable to getGroupsForUser due to exception. " + e.getMessage());
-    }
-
-    routerMetrics.incrGetGroupsForUserFailedRetrieved();
-    throw new IOException("Unable to getGroupsForUser.");
-  }
-
-  @VisibleForTesting
-  public FederationStateStoreFacade getFederationFacade() {
-    return federationFacade;
-  }
-
-  @VisibleForTesting
-  public ThreadPoolExecutor getExecutorService() {
-    return executorService;
-  }
-
-  /**
-   * In YARN Federation mode, We allow users to mark subClusters
-   * With no heartbeat for a long time as SC_LOST state.
-   *
-   * If we include a specific subClusterId in the request, check for the specified subCluster.
-   * If subClusterId is empty, all subClusters are checked.
-   *
-   * @param request deregisterSubCluster request.
-   * The request contains the id of to deregister sub-cluster.
-   * @return Response from deregisterSubCluster.
-   * @throws YarnException exceptions from yarn servers.
-   * @throws IOException if an IO error occurred.
-   */
-  @Override
-  public DeregisterSubClusterResponse deregisterSubCluster(DeregisterSubClusterRequest request)
-      throws YarnException, IOException {
-
-    if (request == null) {
-      routerMetrics.incrDeregisterSubClusterFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing DeregisterSubCluster request.", null);
-    }
-
-    try {
-      long startTime = clock.getTime();
-      List<DeregisterSubClusters> deregisterSubClusterList = new ArrayList<>();
-      String reqSubClusterId = request.getSubClusterId();
-      if (StringUtils.isNotBlank(reqSubClusterId)) {
-        // If subCluster is not empty, process the specified subCluster.
-        DeregisterSubClusters deregisterSubClusters = deregisterSubCluster(reqSubClusterId);
-        deregisterSubClusterList.add(deregisterSubClusters);
-      } else {
-        // Traversing all Active SubClusters,
-        // for subCluster whose heartbeat times out, update the status to SC_LOST.
-        Map<SubClusterId, SubClusterInfo> subClusterInfo = federationFacade.getSubClusters(true);
-        for (Map.Entry<SubClusterId, SubClusterInfo> entry : subClusterInfo.entrySet()) {
-          SubClusterId subClusterId = entry.getKey();
-          DeregisterSubClusters deregisterSubClusters = deregisterSubCluster(subClusterId.getId());
-          deregisterSubClusterList.add(deregisterSubClusters);
-        }
-      }
-      long stopTime = clock.getTime();
-      routerMetrics.succeededDeregisterSubClusterRetrieved(stopTime - startTime);
-      return DeregisterSubClusterResponse.newInstance(deregisterSubClusterList);
-    } catch (Exception e) {
-      routerMetrics.incrDeregisterSubClusterFailedRetrieved();
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to deregisterSubCluster due to exception. " + e.getMessage());
-    }
-
-    routerMetrics.incrDeregisterSubClusterFailedRetrieved();
-    throw new YarnException("Unable to deregisterSubCluster.");
-  }
-
-  /**
-   * Save the Queue Policy for the Federation.
-   *
-   * @param request saveFederationQueuePolicy Request.
-   * @return Response from saveFederationQueuePolicy.
-   * @throws YarnException exceptions from yarn servers.
-   * @throws IOException if an IO error occurred.
-   */
-  @Override
-  public SaveFederationQueuePolicyResponse saveFederationQueuePolicy(
-      SaveFederationQueuePolicyRequest request) throws YarnException, IOException {
-
-    // Parameter validation.
-
-    if (request == null) {
-      routerMetrics.incrSaveFederationQueuePolicyFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing SaveFederationQueuePolicy request.", null);
-    }
-
-    FederationQueueWeight federationQueueWeight = request.getFederationQueueWeight();
-    if (federationQueueWeight == null) {
-      routerMetrics.incrSaveFederationQueuePolicyFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing FederationQueueWeight information.", null);
-    }
-
-    String queue = request.getQueue();
-    if (StringUtils.isBlank(queue)) {
-      routerMetrics.incrSaveFederationQueuePolicyFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing Queue information.", null);
-    }
-
-    String policyManagerClassName = request.getPolicyManagerClassName();
-    if (!checkPolicyManagerValid(policyManagerClassName, SUPPORT_WEIGHT_MANAGERS)) {
-      routerMetrics.incrSaveFederationQueuePolicyFailedRetrieved();
-      RouterServerUtil.logAndThrowException(policyManagerClassName +
-          " does not support the use of queue weights.", null);
-    }
-
-    String amRmWeight = federationQueueWeight.getAmrmWeight();
-    FederationQueueWeight.checkSubClusterQueueWeightRatioValid(amRmWeight);
-
-    String routerWeight = federationQueueWeight.getRouterWeight();
-    FederationQueueWeight.checkSubClusterQueueWeightRatioValid(routerWeight);
-
-    String headRoomAlpha = federationQueueWeight.getHeadRoomAlpha();
-    FederationQueueWeight.checkHeadRoomAlphaValid(headRoomAlpha);
-
-    try {
-      long startTime = clock.getTime();
-
-      // Step2, parse amRMPolicyWeights.
-      Map<SubClusterIdInfo, Float> amRMPolicyWeights = getSubClusterWeightMap(amRmWeight);
-      LOG.debug("amRMPolicyWeights = {}.", amRMPolicyWeights);
-
-      // Step3, parse routerPolicyWeights.
-      Map<SubClusterIdInfo, Float> routerPolicyWeights = getSubClusterWeightMap(routerWeight);
-      LOG.debug("routerWeights = {}.", amRMPolicyWeights);
-
-      // Step4, Initialize WeightedPolicyInfo.
-      WeightedPolicyInfo weightedPolicyInfo = new WeightedPolicyInfo();
-      weightedPolicyInfo.setHeadroomAlpha(Float.parseFloat(headRoomAlpha));
-      weightedPolicyInfo.setAMRMPolicyWeights(amRMPolicyWeights);
-      weightedPolicyInfo.setRouterPolicyWeights(routerPolicyWeights);
-
-      // Step5, Set SubClusterPolicyConfiguration.
-      SubClusterPolicyConfiguration policyConfiguration =
-          SubClusterPolicyConfiguration.newInstance(queue, policyManagerClassName,
-          weightedPolicyInfo.toByteBuffer());
-      federationFacade.setPolicyConfiguration(policyConfiguration);
-      long stopTime = clock.getTime();
-      routerMetrics.succeededSaveFederationQueuePolicyRetrieved(stopTime - startTime);
-      return SaveFederationQueuePolicyResponse.newInstance("save policy success.");
-    } catch (Exception e) {
-      routerMetrics.incrSaveFederationQueuePolicyFailedRetrieved();
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to saveFederationQueuePolicy due to exception. " + e.getMessage());
-    }
-
-    routerMetrics.incrSaveFederationQueuePolicyFailedRetrieved();
-    throw new YarnException("Unable to saveFederationQueuePolicy.");
-  }
-
-  /**
-   * Batch Save the Queue Policies for the Federation.
-   *
-   * @param request BatchSaveFederationQueuePolicies Request
-   * @return Response from batchSaveFederationQueuePolicies.
-   * @throws YarnException exceptions from yarn servers.
-   * @throws IOException if an IO error occurred.
-   */
-  @Override
-  public BatchSaveFederationQueuePoliciesResponse batchSaveFederationQueuePolicies(
-      BatchSaveFederationQueuePoliciesRequest request) throws YarnException, IOException {
-
-    // Parameter validation.
-    if (request == null) {
-      routerMetrics.incrBatchSaveFederationQueuePoliciesFailedRetrieved();
-      RouterServerUtil.logAndThrowException(
-          "Missing BatchSaveFederationQueuePoliciesRequest request.", null);
-    }
-
-    List<FederationQueueWeight> federationQueueWeights = request.getFederationQueueWeights();
-    if (federationQueueWeights == null) {
-      routerMetrics.incrBatchSaveFederationQueuePoliciesFailedRetrieved();
-      RouterServerUtil.logAndThrowException("Missing FederationQueueWeights information.", null);
-    }
-
-    try {
-      long startTime = clock.getTime();
-      for (FederationQueueWeight federationQueueWeight : federationQueueWeights) {
-        saveFederationQueuePolicy(federationQueueWeight);
-      }
-      long stopTime = clock.getTime();
-      routerMetrics.succeededBatchSaveFederationQueuePoliciesRetrieved(stopTime - startTime);
-      return BatchSaveFederationQueuePoliciesResponse.newInstance("batch save policies success.");
-    } catch (Exception e) {
-      routerMetrics.incrBatchSaveFederationQueuePoliciesFailedRetrieved();
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to batchSaveFederationQueuePolicies due to exception. " + e.getMessage());
-    }
-
-    routerMetrics.incrBatchSaveFederationQueuePoliciesFailedRetrieved();
-    throw new YarnException("Unable to batchSaveFederationQueuePolicies.");
-  }
-
-  /**
-   * List the Queue Policies for the Federation.
-   *
-   * @param request QueryFederationQueuePolicies Request.
-   * @return QueryFederationQueuePolicies Response.
-   *
-   * @throws YarnException indicates exceptions from yarn servers.
-   * @throws IOException io error occurs.
-   */
-  @Override
-  public QueryFederationQueuePoliciesResponse listFederationQueuePolicies(
-      QueryFederationQueuePoliciesRequest request) throws YarnException, IOException {
-
-    // Parameter validation.
-    if (request == null) {
-      routerMetrics.incrListFederationQueuePoliciesFailedRetrieved();
-      RouterServerUtil.logAndThrowException(
-          "Missing ListFederationQueuePolicies Request.", null);
-    }
-
-    if (request.getPageSize() <= 0) {
-      routerMetrics.incrListFederationQueuePoliciesFailedRetrieved();
-      RouterServerUtil.logAndThrowException(
-          "PageSize cannot be negative or zero.", null);
-    }
-
-    if (request.getCurrentPage() <= 0) {
-      routerMetrics.incrListFederationQueuePoliciesFailedRetrieved();
-      RouterServerUtil.logAndThrowException(
-          "CurrentPage cannot be negative or zero.", null);
-    }
-
-    try {
-      QueryFederationQueuePoliciesResponse response;
-
-      long startTime = clock.getTime();
-      String queue = request.getQueue();
-      List<String> queues = request.getQueues();
-      int currentPage = request.getCurrentPage();
-      int pageSize = request.getPageSize();
-
-      // Print log
-      LOG.info("queue = {}, queues={}, currentPage={}, pageSize={}",
-          queue, queues, currentPage, pageSize);
-
-      Map<String, SubClusterPolicyConfiguration> policiesConfigurations =
-          federationFacade.getPoliciesConfigurations();
-
-      // If the queue is not empty, filter according to the queue.
-      if (StringUtils.isNotBlank(queue)) {
-        response = filterPoliciesConfigurationsByQueue(queue, policiesConfigurations,
-            pageSize, currentPage);
-      } else if(CollectionUtils.isNotEmpty(queues)) {
-        // If queues are not empty, filter by queues, which may return multiple results.
-        // We filter by pagination.
-        response = filterPoliciesConfigurationsByQueues(queues, policiesConfigurations,
-            pageSize, currentPage);
-      } else {
-        // If we don't have any filtering criteria, we should also support paginating the results.
-        response = filterPoliciesConfigurations(policiesConfigurations, pageSize, currentPage);
-      }
-      long stopTime = clock.getTime();
-      routerMetrics.succeededListFederationQueuePoliciesRetrieved(stopTime - startTime);
-      if (response == null) {
-        response = QueryFederationQueuePoliciesResponse.newInstance();
-      }
-      return response;
-    } catch (Exception e) {
-      routerMetrics.incrListFederationQueuePoliciesFailedRetrieved();
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to ListFederationQueuePolicies due to exception. " + e.getMessage());
-    }
-
-    routerMetrics.incrListFederationQueuePoliciesFailedRetrieved();
-    throw new YarnException("Unable to listFederationQueuePolicies.");
-  }
-
-  @Override
-  public DeleteFederationApplicationResponse deleteFederationApplication(
-      DeleteFederationApplicationRequest request) throws YarnException, IOException {
-
-    // Parameter validation.
-    if (request == null) {
-      routerMetrics.incrDeleteFederationApplicationFailedRetrieved();
-      RouterServerUtil.logAndThrowException(
-          "Missing deleteFederationApplication Request.", null);
-    }
-
-    String application = request.getApplication();
-    if (StringUtils.isBlank(application)) {
-      routerMetrics.incrDeleteFederationApplicationFailedRetrieved();
-      RouterServerUtil.logAndThrowException(
-          "ApplicationId cannot be null.", null);
-    }
-
-    // Try calling deleteApplicationHomeSubCluster to delete the application.
-    try {
-      long startTime = clock.getTime();
-      ApplicationId applicationId = ApplicationId.fromString(application);
-      federationFacade.deleteApplicationHomeSubCluster(applicationId);
-      long stopTime = clock.getTime();
-      routerMetrics.succeededDeleteFederationApplicationFailedRetrieved(stopTime - startTime);
-      return DeleteFederationApplicationResponse.newInstance(
-          "applicationId = " + applicationId + " delete success.");
-    } catch (Exception e) {
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to deleteFederationApplication due to exception. " + e.getMessage());
-    }
-
-    throw new YarnException("Unable to deleteFederationApplication.");
-  }
-
-  /**
-   * Get federation subcluster list.
-   *
-   * @param request GetSubClustersRequest Request.
-   * @return SubClusters Response.
-   * @throws YarnException exceptions from yarn servers.
-   * @throws IOException io error occurs.
-   */
-  @Override
-  public GetSubClustersResponse getFederationSubClusters(GetSubClustersRequest request)
-       throws YarnException, IOException {
-
-    // Parameter validation.
-    if (request == null) {
-      routerMetrics.incrGetFederationSubClustersFailedRetrieved();
-      RouterServerUtil.logAndThrowException(
-          "Missing getFederationSubClusters Request.", null);
-    }
-
-    // Step1. Get all subClusters of the cluster.
-    Map<SubClusterId, SubClusterInfo> subClusters =
-        federationFacade.getSubClusters(false);
-
-    // Step2. Get FederationSubCluster data.
-    List<FederationSubCluster> federationSubClusters = new ArrayList<>();
-    long startTime = clock.getTime();
-    for (Map.Entry<SubClusterId, SubClusterInfo> subCluster : subClusters.entrySet()) {
-      SubClusterId subClusterId = subCluster.getKey();
-      try {
-        SubClusterInfo subClusterInfo = subCluster.getValue();
-        long lastHeartBeat = subClusterInfo.getLastHeartBeat();
-        Date lastHeartBeatDate = new Date(lastHeartBeat);
-        FederationSubCluster federationSubCluster = FederationSubCluster.newInstance(
-            subClusterId.getId(), subClusterInfo.getState().name(), lastHeartBeatDate.toString());
-        federationSubClusters.add(federationSubCluster);
-      } catch (Exception e) {
-        routerMetrics.incrGetFederationSubClustersFailedRetrieved();
-        LOG.error("getSubClusters SubClusterId = [%s] error.", subClusterId, e);
-      }
-    }
-    long stopTime = clock.getTime();
-    routerMetrics.succeededGetFederationSubClustersRetrieved(stopTime - startTime);
-
-    // Step3. Return results.
-    return GetSubClustersResponse.newInstance(federationSubClusters);
-  }
-
-  /**
-   * Delete Policies based on the provided queue list.
-   *
-   * @param request DeleteFederationQueuePoliciesRequest Request.
-   * @return If the deletion is successful, the queue deletion success message will be returned.
-   * @throws YarnException indicates exceptions from yarn servers.
-   * @throws IOException io error occurs.
-   */
-  @Override
-  public DeleteFederationQueuePoliciesResponse deleteFederationPoliciesByQueues(
-      DeleteFederationQueuePoliciesRequest request) throws YarnException, IOException {
-
-    // Parameter validation.
-    if (request == null) {
-      routerMetrics.incrDeleteFederationPoliciesByQueuesRetrieved();
-      RouterServerUtil.logAndThrowException(
-          "Missing deleteFederationQueuePoliciesByQueues Request.", null);
-    }
-
-    List<String> queues = request.getQueues();
-    if (CollectionUtils.isEmpty(queues)) {
-      routerMetrics.incrDeleteFederationPoliciesByQueuesRetrieved();
-      RouterServerUtil.logAndThrowException("queues cannot be null.", null);
-    }
-
-    // Try calling deleteApplicationHomeSubCluster to delete the application.
-    try {
-      long startTime = clock.getTime();
-      federationFacade.deletePolicyConfigurations(queues);
-      long stopTime = clock.getTime();
-      routerMetrics.succeededDeleteFederationPoliciesByQueuesRetrieved(stopTime - startTime);
-      return DeleteFederationQueuePoliciesResponse.newInstance(
-         "queues = " + StringUtils.join(queues, ",") + " delete success.");
-    } catch (Exception e) {
-      RouterServerUtil.logAndThrowException(e,
-          "Unable to deleteFederationPoliciesByQueues due to exception. " + e.getMessage());
-    }
-    throw new YarnException("Unable to deleteFederationPoliciesByQueues.");
-  }
-
-  /**
-   * According to the configuration information of the queue filtering queue,
-   * this part should only return 1 result.
-   *
-   * @param queue queueName.
-   * @param policiesConfigurations policy configurations.
-   * @param pageSize Items per page.
-   * @param currentPage The number of pages to be queried.
-   * @return federation queue policies response.
-   * @throws YarnException indicates exceptions from yarn servers.
-   *
-   */
-  private QueryFederationQueuePoliciesResponse filterPoliciesConfigurationsByQueue(String queue,
-      Map<String, SubClusterPolicyConfiguration> policiesConfigurations,
-      int pageSize, int currentPage) throws YarnException {
-
-    // Step1. Check the parameters, if the policy list is empty, return empty directly.
-    if (MapUtils.isEmpty(policiesConfigurations)) {
-      return null;
-    }
-    SubClusterPolicyConfiguration policyConf = policiesConfigurations.getOrDefault(queue, null);
-    if(policyConf == null) {
-      return null;
-    }
-
-    // Step2. Parse the parameters.
-    List<FederationQueueWeight> federationQueueWeights = new ArrayList<>();
-    FederationQueueWeight federationQueueWeight = parseFederationQueueWeight(queue, policyConf);
-    federationQueueWeights.add(federationQueueWeight);
-
-    // Step3. Return result.
-    return QueryFederationQueuePoliciesResponse.newInstance(
-        1, 1, currentPage, pageSize, federationQueueWeights);
-  }
-
-  /**
-   * Filter queue configuration information based on the queue list.
-   *
-   * @param queues The name of the queue.
-   * @param policiesConfigurations policy configurations.
-   * @param pageSize Items per page.
-   * @param currentPage The number of pages to be queried.
-   * @return federation queue policies response.
-   * @throws YarnException indicates exceptions from yarn servers.
-   */
-  private QueryFederationQueuePoliciesResponse filterPoliciesConfigurationsByQueues(
-      List<String> queues, Map<String, SubClusterPolicyConfiguration> policiesConfigurations,
-      int pageSize, int currentPage) throws YarnException {
-
-    // Step1. Check the parameters, if the policy list is empty, return empty directly.
-    if (MapUtils.isEmpty(policiesConfigurations)) {
-      return null;
-    }
-
-    // Step2. Filtering for Queue Policies.
-    List<FederationQueueWeight> federationQueueWeights = new ArrayList<>();
-    for (String queue : queues) {
-      SubClusterPolicyConfiguration policyConf = policiesConfigurations.getOrDefault(queue, null);
-      if(policyConf == null) {
-        continue;
-      }
-      FederationQueueWeight federationQueueWeight = parseFederationQueueWeight(queue, policyConf);
-      if (federationQueueWeight != null) {
-        federationQueueWeights.add(federationQueueWeight);
-      }
-    }
-
-    // Step3. To paginate the returned results.
-    return queryFederationQueuePoliciesPagination(federationQueueWeights, pageSize, currentPage);
-  }
-
-  /**
-   * Filter PoliciesConfigurations, and we paginate Policies within this method.
-   *
-   * @param policiesConfigurations policy configurations.
-   * @param pageSize Items per page.
-   * @param currentPage The number of pages to be queried.
-   * @return federation queue policies response.
-   * @throws YarnException indicates exceptions from yarn servers.
-   */
-  private QueryFederationQueuePoliciesResponse filterPoliciesConfigurations(
-      Map<String, SubClusterPolicyConfiguration> policiesConfigurations,
-      int pageSize, int currentPage) throws YarnException {
-
-    // Step1. Check the parameters, if the policy list is empty, return empty directly.
-    if (MapUtils.isEmpty(policiesConfigurations)) {
-      return null;
-    }
-
-    // Step2. Traverse policiesConfigurations and obtain the FederationQueueWeight list.
-    List<FederationQueueWeight> federationQueueWeights = new ArrayList<>();
-    for (Map.Entry<String, SubClusterPolicyConfiguration> entry :
-        policiesConfigurations.entrySet()) {
-      String queue = entry.getKey();
-      SubClusterPolicyConfiguration policyConf = entry.getValue();
-      if (policyConf == null) {
-        continue;
-      }
-      FederationQueueWeight federationQueueWeight = parseFederationQueueWeight(queue, policyConf);
-      if (federationQueueWeight != null) {
-        federationQueueWeights.add(federationQueueWeight);
-      }
-    }
-
-    // Step3. To paginate the returned results.
-    return queryFederationQueuePoliciesPagination(federationQueueWeights, pageSize, currentPage);
-  }
-
-  /**
-   * Pagination for FederationQueuePolicies.
-   *
-   * @param queueWeights List Of FederationQueueWeight.
-   * @param pageSize Items per page.
-   * @param currentPage The number of pages to be queried.
-   * @return federation queue policies response.
-   * @throws YarnException indicates exceptions from yarn servers.
-   */
-  private QueryFederationQueuePoliciesResponse queryFederationQueuePoliciesPagination(
-      List<FederationQueueWeight> queueWeights, int pageSize, int currentPage)
-      throws YarnException {
-    if (CollectionUtils.isEmpty(queueWeights)) {
-      return null;
-    }
-
-    int startIndex = (currentPage - 1) * pageSize;
-    int endIndex = Math.min(startIndex + pageSize, queueWeights.size());
-
-    if (startIndex > endIndex) {
-      throw new YarnException("The index of the records to be retrieved " +
-          "has exceeded the maximum index.");
-    }
-
-    List<FederationQueueWeight> subFederationQueueWeights =
-        queueWeights.subList(startIndex, endIndex);
-
-    int totalSize = queueWeights.size();
-    int totalPage =
-        (totalSize % pageSize == 0) ? totalSize / pageSize : (totalSize / pageSize) + 1;
-
-    // Step3. Returns the Queue Policies result.
-    return QueryFederationQueuePoliciesResponse.newInstance(
-        totalSize, totalPage, currentPage, pageSize, subFederationQueueWeights);
-  }
-
-  /**
-   * Parses a FederationQueueWeight from the given queue and SubClusterPolicyConfiguration.
-   *
-   * @param queue The name of the queue.
-   * @param policyConf policy configuration.
-   * @return Queue weights for representing Federation.
-   * @throws YarnException YarnException indicates exceptions from yarn servers.
-   */
-  private FederationQueueWeight parseFederationQueueWeight(String queue,
-      SubClusterPolicyConfiguration policyConf) throws YarnException {
-
-    if (policyConf != null) {
-      ByteBuffer params = policyConf.getParams();
-      WeightedPolicyInfo weightedPolicyInfo = WeightedPolicyInfo.fromByteBuffer(params);
-      Map<SubClusterIdInfo, Float> amrmPolicyWeights = weightedPolicyInfo.getAMRMPolicyWeights();
-      Map<SubClusterIdInfo, Float> routerPolicyWeights =
-          weightedPolicyInfo.getRouterPolicyWeights();
-      float headroomAlpha = weightedPolicyInfo.getHeadroomAlpha();
-      String policyManagerClassName = policyConf.getType();
-
-      String amrmPolicyWeight = parsePolicyWeights(amrmPolicyWeights);
-      String routerPolicyWeight = parsePolicyWeights(routerPolicyWeights);
-
-      FederationQueueWeight.checkSubClusterQueueWeightRatioValid(amrmPolicyWeight);
-      FederationQueueWeight.checkSubClusterQueueWeightRatioValid(routerPolicyWeight);
-
-      return FederationQueueWeight.newInstance(routerPolicyWeight, amrmPolicyWeight,
-          String.valueOf(headroomAlpha), queue, policyManagerClassName);
-    }
-
-    return null;
-  }
-
-  /**
-   * Parses the policy weights from the provided policyWeights map.
-   * returns a string similar to the following:
-   * SC-1:0.7,SC-2:0.3
-   *
-   * @param policyWeights
-   *        A map containing SubClusterIdInfo as keys and corresponding weight values.
-   * @return A string representation of the parsed policy weights.
-   */
-  protected String parsePolicyWeights(Map<SubClusterIdInfo, Float> policyWeights) {
-    if (MapUtils.isEmpty(policyWeights)) {
-      return null;
-    }
-    List<String> policyWeightList = new ArrayList<>();
-    for (Map.Entry<SubClusterIdInfo, Float> entry : policyWeights.entrySet()) {
-      SubClusterIdInfo key = entry.getKey();
-      Float value = entry.getValue();
-      policyWeightList.add(key.toId() + ":" + value);
-    }
-    return StringUtils.join(policyWeightList, ",");
-  }
-
-  /**
-   * Save FederationQueuePolicy.
-   *
-   * @param federationQueueWeight queue weight.
-   * @throws YarnException exceptions from yarn servers.
-   */
-  private void saveFederationQueuePolicy(FederationQueueWeight federationQueueWeight)
-      throws YarnException {
-
-    // Step1, Check whether the weight setting of the queue is as expected.
-    String queue = federationQueueWeight.getQueue();
-    String policyManagerClassName = federationQueueWeight.getPolicyManagerClassName();
-
-    if (StringUtils.isBlank(queue)) {
-      RouterServerUtil.logAndThrowException("Missing Queue information.", null);
-    }
-
-    if (StringUtils.isBlank(policyManagerClassName)) {
-      RouterServerUtil.logAndThrowException("Missing PolicyManagerClassName information.", null);
-    }
-
-    if (!checkPolicyManagerValid(policyManagerClassName, SUPPORT_WEIGHT_MANAGERS)) {
-      routerMetrics.incrSaveFederationQueuePolicyFailedRetrieved();
-      RouterServerUtil.logAndThrowException(policyManagerClassName +
-              "does not support the use of queue weights.", null);
-    }
-
-    String amRmWeight = federationQueueWeight.getAmrmWeight();
-    FederationQueueWeight.checkSubClusterQueueWeightRatioValid(amRmWeight);
-
-    String routerWeight = federationQueueWeight.getRouterWeight();
-    FederationQueueWeight.checkSubClusterQueueWeightRatioValid(routerWeight);
-
-    String headRoomAlpha = federationQueueWeight.getHeadRoomAlpha();
-    FederationQueueWeight.checkHeadRoomAlphaValid(headRoomAlpha);
-
-    // Step2, parse amRMPolicyWeights.
-    Map<SubClusterIdInfo, Float> amRMPolicyWeights = getSubClusterWeightMap(amRmWeight);
-    LOG.debug("amRMPolicyWeights = {}.", amRMPolicyWeights);
-
-    // Step3, parse routerPolicyWeights.
-    Map<SubClusterIdInfo, Float> routerPolicyWeights = getSubClusterWeightMap(routerWeight);
-    LOG.debug("routerWeights = {}.", amRMPolicyWeights);
-
-    // Step4, Initialize WeightedPolicyInfo.
-    WeightedPolicyInfo weightedPolicyInfo = new WeightedPolicyInfo();
-    weightedPolicyInfo.setHeadroomAlpha(Float.parseFloat(headRoomAlpha));
-    weightedPolicyInfo.setAMRMPolicyWeights(amRMPolicyWeights);
-    weightedPolicyInfo.setRouterPolicyWeights(routerPolicyWeights);
-
-    // Step5, Set SubClusterPolicyConfiguration.
-    SubClusterPolicyConfiguration policyConfiguration =
-        SubClusterPolicyConfiguration.newInstance(queue, policyManagerClassName,
-        weightedPolicyInfo.toByteBuffer());
-    federationFacade.setPolicyConfiguration(policyConfiguration);
-  }
-
-  /**
-   * Get the Map of SubClusterWeight.
-   *
-   * This method can parse the Weight information of Router and
-   * the Weight information of AMRMProxy.
-   *
-   * An example of a parsed string is as follows:
-   * SC-1:0.7,SC-2:0.3
-   *
-   * @param policyWeight policyWeight.
-   * @return Map of SubClusterWeight.
-   * @throws YarnException exceptions from yarn servers.
-   */
-  protected Map<SubClusterIdInfo, Float> getSubClusterWeightMap(String policyWeight)
-      throws YarnException {
-    FederationQueueWeight.checkSubClusterQueueWeightRatioValid(policyWeight);
-    Map<SubClusterIdInfo, Float> result = new HashMap<>();
-    String[] policyWeights = policyWeight.split(COMMA);
-    for (String policyWeightItem : policyWeights) {
-      String[] subClusterWeight = policyWeightItem.split(COLON);
-      String subClusterId = subClusterWeight[0];
-      SubClusterIdInfo subClusterIdInfo = new SubClusterIdInfo(subClusterId);
-      String weight = subClusterWeight[1];
-      result.put(subClusterIdInfo, Float.valueOf(weight));
-    }
-    return result;
-  }
-
-  /**
-   * deregisterSubCluster by SubClusterId.
-   *
-   * @param reqSubClusterId subClusterId.
-   * @throws YarnException indicates exceptions from yarn servers.
-   */
-  private DeregisterSubClusters deregisterSubCluster(String reqSubClusterId) {
-
-    DeregisterSubClusters deregisterSubClusters;
-
-    try {
-      // Step1. Get subCluster information.
-      SubClusterId subClusterId = SubClusterId.newInstance(reqSubClusterId);
-      SubClusterInfo subClusterInfo = federationFacade.getSubCluster(subClusterId);
-      SubClusterState subClusterState = subClusterInfo.getState();
-      long lastHeartBeat = subClusterInfo.getLastHeartBeat();
-      Date lastHeartBeatDate = new Date(lastHeartBeat);
-      deregisterSubClusters = DeregisterSubClusters.newInstance(
-          reqSubClusterId, "NONE", lastHeartBeatDate.toString(),
-          "Normal Heartbeat", subClusterState.name());
-
-      // Step2. Deregister subCluster.
-      if (subClusterState.isUsable()) {
-        LOG.warn("Deregister SubCluster {} in State {} last heartbeat at {}.",
-            subClusterId, subClusterState, lastHeartBeatDate);
-        // heartbeat interval time.
-        long heartBearTimeInterval = Time.now() - lastHeartBeat;
-        if (heartBearTimeInterval - heartbeatExpirationMillis < 0) {
-          boolean deregisterSubClusterFlag =
-              federationFacade.deregisterSubCluster(subClusterId, SubClusterState.SC_LOST);
-          if (deregisterSubClusterFlag) {
-            deregisterSubClusters.setDeregisterState("SUCCESS");
-            deregisterSubClusters.setSubClusterState("SC_LOST");
-            deregisterSubClusters.setInformation("Heartbeat Time >= " +
-                heartbeatExpirationMillis / (1000 * 60) + "minutes");
-          } else {
-            deregisterSubClusters.setDeregisterState("FAILED");
-            deregisterSubClusters.setInformation("DeregisterSubClusters Failed.");
-          }
-        }
-      } else {
-        deregisterSubClusters.setDeregisterState("FAILED");
-        deregisterSubClusters.setInformation("The subCluster is Unusable, " +
-            "So it can't be Deregistered");
-        LOG.warn("The SubCluster {} is Unusable (SubClusterState:{}), So it can't be Deregistered",
-            subClusterId, subClusterState);
-      }
-      return deregisterSubClusters;
-    } catch (YarnException e) {
-      LOG.error("SubCluster {} DeregisterSubCluster Failed", reqSubClusterId, e);
-      deregisterSubClusters = DeregisterSubClusters.newInstance(
-          reqSubClusterId, "FAILED", "UNKNOWN", e.getMessage(), "UNKNOWN");
-      return deregisterSubClusters;
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/RMAdminProtocolMethod.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/RMAdminProtocolMethod.java
deleted file mode 100644
index 665545ce6ea..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/RMAdminProtocolMethod.java
+++ /dev/null
@@ -1,186 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.rmadmin;
-
-import org.apache.commons.lang3.StringUtils;
-import org.apache.commons.lang3.tuple.Pair;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.utils.FederationMethodWrapper;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.lang.reflect.Method;
-import java.util.Collection;
-import java.util.Map;
-import java.util.Set;
-import java.util.TreeMap;
-import java.util.List;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.concurrent.Callable;
-import java.util.concurrent.ExecutionException;
-import java.util.concurrent.Future;
-import java.util.concurrent.ThreadPoolExecutor;
-
-/**
- * Class to define admin method, params and arguments.
- */
-public class RMAdminProtocolMethod extends FederationMethodWrapper {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(RMAdminProtocolMethod.class);
-
-  private FederationStateStoreFacade federationFacade;
-  private FederationRMAdminInterceptor rmAdminInterceptor;
-  private Configuration configuration;
-
-  public RMAdminProtocolMethod(Class<?>[] pTypes, Object... pParams)
-      throws IOException {
-    super(pTypes, pParams);
-  }
-
-  public <R> Collection<R> invokeConcurrent(FederationRMAdminInterceptor interceptor,
-      Class<R> clazz, String subClusterId) throws YarnException {
-    this.rmAdminInterceptor = interceptor;
-    this.federationFacade = FederationStateStoreFacade.getInstance(interceptor.getConf());
-    this.configuration = interceptor.getConf();
-    if (StringUtils.isNotBlank(subClusterId)) {
-      return invoke(clazz, subClusterId);
-    } else {
-      return invokeConcurrent(clazz);
-    }
-  }
-
-  @Override
-  protected <R> Collection<R> invokeConcurrent(Class<R> clazz) throws YarnException {
-    String methodName = Thread.currentThread().getStackTrace()[3].getMethodName();
-    this.setMethodName(methodName);
-
-    ThreadPoolExecutor executorService = rmAdminInterceptor.getExecutorService();
-
-    // Get Active SubClusters
-    Map<SubClusterId, SubClusterInfo> subClusterInfo =
-        federationFacade.getSubClusters(true);
-    Collection<SubClusterId> subClusterIds = subClusterInfo.keySet();
-
-    List<Callable<Pair<SubClusterId, Object>>> callables = new ArrayList<>();
-    List<Future<Pair<SubClusterId, Object>>> futures = new ArrayList<>();
-    Map<SubClusterId, Exception> exceptions = new TreeMap<>();
-
-    // Generate parallel Callable tasks
-    for (SubClusterId subClusterId : subClusterIds) {
-      callables.add(() -> {
-        ResourceManagerAdministrationProtocol protocol =
-            rmAdminInterceptor.getAdminRMProxyForSubCluster(subClusterId);
-        Class<?>[] types = this.getTypes();
-        Object[] params = this.getParams();
-        Method method = ResourceManagerAdministrationProtocol.class.getMethod(methodName, types);
-        Object result = method.invoke(protocol, params);
-        return Pair.of(subClusterId, result);
-      });
-    }
-
-    // Get results from multiple threads
-    Map<SubClusterId, R> results = new TreeMap<>();
-    try {
-      futures.addAll(executorService.invokeAll(callables));
-      futures.stream().forEach(future -> {
-        SubClusterId subClusterId = null;
-        try {
-          Pair<SubClusterId, Object> pair = future.get();
-          subClusterId = pair.getKey();
-          Object result = pair.getValue();
-          if (result != null) {
-            R rResult = clazz.cast(result);
-            results.put(subClusterId, rResult);
-          }
-        } catch (InterruptedException | ExecutionException e) {
-          Throwable cause = e.getCause();
-          LOG.error("Cannot execute {} on {}: {}", methodName, subClusterId, cause.getMessage());
-          exceptions.put(subClusterId, e);
-        }
-      });
-    } catch (InterruptedException e) {
-      throw new YarnException("invokeConcurrent Failed.", e);
-    }
-
-    // All sub-clusters return results to be considered successful,
-    // otherwise an exception will be thrown.
-    if (exceptions != null && !exceptions.isEmpty()) {
-      Set<SubClusterId> subClusterIdSets = exceptions.keySet();
-      throw new YarnException("invokeConcurrent Failed, An exception occurred in subClusterIds = " +
-          StringUtils.join(subClusterIdSets, ","));
-    }
-
-    // return result
-    return results.values();
-  }
-
-  /**
-   * Call the method in the protocol according to the subClusterId.
-   *
-   * @param clazz return type
-   * @param subClusterId subCluster Id
-   * @param <R> Generic R
-   * @return response collection.
-   * @throws YarnException yarn exception.
-   */
-  protected <R> Collection<R> invoke(Class<R> clazz, String subClusterId) throws YarnException {
-
-    // Get the method name to call
-    String methodName = Thread.currentThread().getStackTrace()[3].getMethodName();
-    this.setMethodName(methodName);
-
-    // Get Active SubClusters
-    Map<SubClusterId, SubClusterInfo> subClusterInfoMap =
-        federationFacade.getSubClusters(true);
-
-    // According to subCluster of string type, convert to SubClusterId type
-    SubClusterId subClusterIdKey = SubClusterId.newInstance(subClusterId);
-
-    // If the provided subCluster is not Active or does not exist,
-    // an exception will be returned directly.
-    if (!subClusterInfoMap.containsKey(subClusterIdKey)) {
-      throw new YarnException("subClusterId = " + subClusterId + " is not an active subCluster.");
-    }
-
-    // Call the method in the protocol and convert it according to clazz.
-    try {
-      ResourceManagerAdministrationProtocol protocol =
-          rmAdminInterceptor.getAdminRMProxyForSubCluster(subClusterIdKey);
-      Class<?>[] types = this.getTypes();
-      Object[] params = this.getParams();
-      Method method = ResourceManagerAdministrationProtocol.class.getMethod(methodName, types);
-      Object result = method.invoke(protocol, params);
-      if (result != null) {
-        return Collections.singletonList(clazz.cast(result));
-      }
-    } catch (Exception e) {
-      throw new YarnException("invoke Failed, An exception occurred in subClusterId = " +
-          subClusterId, e);
-    }
-    throw new YarnException("invoke Failed, An exception occurred in subClusterId = " +
-        subClusterId);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/RMAdminRequestInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/RMAdminRequestInterceptor.java
deleted file mode 100644
index 29ab9e6add2..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/RMAdminRequestInterceptor.java
+++ /dev/null
@@ -1,65 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.rmadmin;
-
-import org.apache.hadoop.conf.Configurable;
-import org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol;
-
-/**
- * Defines the contract to be implemented by the request interceptor classes,
- * that can be used to intercept and inspect messages sent from the client to
- * the resource manager.
- */
-public interface RMAdminRequestInterceptor
-    extends ResourceManagerAdministrationProtocol, Configurable {
-  /**
-   * This method is called for initializing the interceptor. This is guaranteed
-   * to be called only once in the lifetime of this instance.
-   *
-   * @param user the name of the client
-   */
-  void init(String user);
-
-  /**
-   * This method is called to release the resources held by the interceptor.
-   * This will be called when the application pipeline is being destroyed. The
-   * concrete implementations should dispose the resources and forward the
-   * request to the next interceptor, if any.
-   */
-  void shutdown();
-
-  /**
-   * Sets the next interceptor in the pipeline. The concrete implementation of
-   * this interface should always pass the request to the nextInterceptor after
-   * inspecting the message. The last interceptor in the chain is responsible to
-   * send the messages to the resource manager service and so the last
-   * interceptor will not receive this method call.
-   *
-   * @param nextInterceptor the RMAdminRequestInterceptor to set in the pipeline
-   */
-  void setNextInterceptor(RMAdminRequestInterceptor nextInterceptor);
-
-  /**
-   * Returns the next interceptor in the chain.
-   *
-   * @return the next interceptor in the chain
-   */
-  RMAdminRequestInterceptor getNextInterceptor();
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/RouterRMAdminService.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/RouterRMAdminService.java
deleted file mode 100644
index 94e72c4e57a..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/RouterRMAdminService.java
+++ /dev/null
@@ -1,449 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.rmadmin;
-
-import java.io.IOException;
-import java.net.InetSocketAddress;
-import java.util.Collections;
-import java.util.Map;
-
-import org.apache.hadoop.classification.InterfaceAudience.Private;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.CommonConfigurationKeysPublic;
-import org.apache.hadoop.ipc.Server;
-import org.apache.hadoop.ipc.StandbyException;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.security.authorize.PolicyProvider;
-import org.apache.hadoop.service.AbstractService;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.ipc.YarnRPC;
-import org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol;
-import org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.CheckForDecommissioningNodesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.CheckForDecommissioningNodesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshAdminAclsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshAdminAclsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshClusterMaxPriorityRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshClusterMaxPriorityResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshQueuesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshQueuesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshSuperUserGroupsConfigurationRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshSuperUserGroupsConfigurationResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshUserToGroupsMappingsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshUserToGroupsMappingsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RemoveFromClusterNodeLabelsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RemoveFromClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeregisterSubClusterRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeregisterSubClusterResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.SaveFederationQueuePolicyRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.SaveFederationQueuePolicyResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.BatchSaveFederationQueuePoliciesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.BatchSaveFederationQueuePoliciesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.QueryFederationQueuePoliciesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.QueryFederationQueuePoliciesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationApplicationRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationApplicationResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.GetSubClustersRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.GetSubClustersResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationQueuePoliciesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationQueuePoliciesResponse;
-import org.apache.hadoop.yarn.server.router.RouterServerUtil;
-import org.apache.hadoop.yarn.server.router.security.authorize.RouterPolicyProvider;
-import org.apache.hadoop.yarn.util.LRUCacheHashMap;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import org.apache.hadoop.classification.VisibleForTesting;
-
-/**
- * RouterRMAdminService is a service that runs on each router that can be used
- * to intercept and inspect {@code ResourceManagerAdministrationProtocol}
- * messages from client to the cluster resource manager. It listens
- * {@code ResourceManagerAdministrationProtocol} messages from the client and
- * creates a request intercepting pipeline instance for each client. The
- * pipeline is a chain of interceptor instances that can inspect and modify the
- * request/response as needed. The main difference with AMRMProxyService is the
- * protocol they implement.
- */
-public class RouterRMAdminService extends AbstractService
-    implements ResourceManagerAdministrationProtocol {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(RouterRMAdminService.class);
-
-  private Server server;
-  private InetSocketAddress listenerEndpoint;
-
-  // For each user we store an interceptors' pipeline.
-  // For performance issue we use LRU cache to keep in memory the newest ones
-  // and remove the oldest used ones.
-  private Map<String, RequestInterceptorChainWrapper> userPipelineMap;
-
-  public RouterRMAdminService() {
-    super(RouterRMAdminService.class.getName());
-  }
-
-  @Override
-  protected void serviceStart() throws Exception {
-    LOG.info("Starting Router RMAdmin Service.");
-    Configuration conf = getConfig();
-    YarnRPC rpc = YarnRPC.create(conf);
-    UserGroupInformation.setConfiguration(conf);
-
-    this.listenerEndpoint =
-        conf.getSocketAddr(YarnConfiguration.ROUTER_BIND_HOST,
-            YarnConfiguration.ROUTER_RMADMIN_ADDRESS,
-            YarnConfiguration.DEFAULT_ROUTER_RMADMIN_ADDRESS,
-            YarnConfiguration.DEFAULT_ROUTER_RMADMIN_PORT);
-
-    int maxCacheSize =
-        conf.getInt(YarnConfiguration.ROUTER_PIPELINE_CACHE_MAX_SIZE,
-            YarnConfiguration.DEFAULT_ROUTER_PIPELINE_CACHE_MAX_SIZE);
-    this.userPipelineMap = Collections.synchronizedMap(new LRUCacheHashMap<>(maxCacheSize, true));
-
-    Configuration serverConf = new Configuration(conf);
-
-    int numWorkerThreads =
-        serverConf.getInt(YarnConfiguration.RM_ADMIN_CLIENT_THREAD_COUNT,
-            YarnConfiguration.DEFAULT_RM_ADMIN_CLIENT_THREAD_COUNT);
-
-    this.server = rpc.getServer(ResourceManagerAdministrationProtocol.class,
-        this, listenerEndpoint, serverConf, null, numWorkerThreads);
-
-    if (conf.getBoolean(
-        CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION, false)) {
-      refreshServiceAcls(conf, RouterPolicyProvider.getInstance());
-    }
-
-    this.server.start();
-    LOG.info("Router RMAdminService listening on address: {}.", this.server.getListenerAddress());
-    super.serviceStart();
-  }
-
-  @Override
-  protected void serviceStop() throws Exception {
-    LOG.info("Stopping Router RMAdminService.");
-    if (this.server != null) {
-      this.server.stop();
-    }
-    userPipelineMap.clear();
-    super.serviceStop();
-  }
-
-  void refreshServiceAcls(Configuration configuration,
-      PolicyProvider policyProvider) {
-    this.server.refreshServiceAcl(configuration, policyProvider);
-  }
-
-  @VisibleForTesting
-  public Server getServer() {
-    return this.server;
-  }
-
-  @VisibleForTesting
-  public RequestInterceptorChainWrapper getInterceptorChain()
-      throws IOException {
-    String user = UserGroupInformation.getCurrentUser().getUserName();
-    RequestInterceptorChainWrapper chain = userPipelineMap.get(user);
-    if (chain != null && chain.getRootInterceptor() != null) {
-      return chain;
-    }
-    return initializePipeline(user);
-  }
-
-  /**
-   * Gets the Request interceptor chains for all the users.
-   *
-   * @return the request interceptor chains.
-   */
-  @VisibleForTesting
-  protected Map<String, RequestInterceptorChainWrapper> getPipelines() {
-    return this.userPipelineMap;
-  }
-
-  /**
-   * This method creates and returns reference of the first interceptor in the
-   * chain of request interceptor instances.
-   *
-   * @return the reference of the first interceptor in the chain
-   */
-  @VisibleForTesting
-  protected RMAdminRequestInterceptor createRequestInterceptorChain() {
-    Configuration conf = getConfig();
-    return RouterServerUtil.createRequestInterceptorChain(conf,
-        YarnConfiguration.ROUTER_RMADMIN_INTERCEPTOR_CLASS_PIPELINE,
-        YarnConfiguration.DEFAULT_ROUTER_RMADMIN_INTERCEPTOR_CLASS,
-        RMAdminRequestInterceptor.class);
-  }
-
-  /**
-   * Initializes the request interceptor pipeline for the specified user.
-   *
-   * @param user
-   */
-  private RequestInterceptorChainWrapper initializePipeline(String user) {
-    synchronized (this.userPipelineMap) {
-      if (this.userPipelineMap.containsKey(user)) {
-        LOG.info("Request to start an already existing user: {}"
-            + " was received, so ignoring.", user);
-        return userPipelineMap.get(user);
-      }
-
-      RequestInterceptorChainWrapper chainWrapper =
-          new RequestInterceptorChainWrapper();
-      try {
-        // We should init the pipeline instance after it is created and then
-        // add to the map, to ensure thread safe.
-        LOG.info("Initializing request processing pipeline for user: {}.", user);
-
-        RMAdminRequestInterceptor interceptorChain =
-            this.createRequestInterceptorChain();
-        interceptorChain.init(user);
-        chainWrapper.init(interceptorChain);
-      } catch (Exception e) {
-        LOG.error("Init RMAdminRequestInterceptor error for user: {}.", user, e);
-        throw e;
-      }
-
-      this.userPipelineMap.put(user, chainWrapper);
-      return chainWrapper;
-    }
-  }
-
-  /**
-   * Private structure for encapsulating RequestInterceptor and user instances.
-   *
-   */
-  @Private
-  public static class RequestInterceptorChainWrapper {
-    private RMAdminRequestInterceptor rootInterceptor;
-
-    /**
-     * Initializes the wrapper with the specified parameters.
-     *
-     * @param interceptor the first interceptor in the pipeline
-     */
-    public synchronized void init(RMAdminRequestInterceptor interceptor) {
-      this.rootInterceptor = interceptor;
-    }
-
-    /**
-     * Gets the root request interceptor.
-     *
-     * @return the root request interceptor
-     */
-    public synchronized RMAdminRequestInterceptor getRootInterceptor() {
-      return rootInterceptor;
-    }
-
-    /**
-     * Shutdown the chain of interceptors when the object is destroyed.
-     */
-    @Override
-    protected void finalize() {
-      rootInterceptor.shutdown();
-    }
-  }
-
-  @Override
-  public String[] getGroupsForUser(String user) throws IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getGroupsForUser(user);
-  }
-
-  @Override
-  public RefreshQueuesResponse refreshQueues(RefreshQueuesRequest request)
-      throws StandbyException, YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().refreshQueues(request);
-
-  }
-
-  @Override
-  public RefreshNodesResponse refreshNodes(RefreshNodesRequest request)
-      throws StandbyException, YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().refreshNodes(request);
-
-  }
-
-  @Override
-  public RefreshSuperUserGroupsConfigurationResponse refreshSuperUserGroupsConfiguration(
-      RefreshSuperUserGroupsConfigurationRequest request)
-      throws StandbyException, YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor()
-        .refreshSuperUserGroupsConfiguration(request);
-
-  }
-
-  @Override
-  public RefreshUserToGroupsMappingsResponse refreshUserToGroupsMappings(
-      RefreshUserToGroupsMappingsRequest request)
-      throws StandbyException, YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().refreshUserToGroupsMappings(request);
-
-  }
-
-  @Override
-  public RefreshAdminAclsResponse refreshAdminAcls(
-      RefreshAdminAclsRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().refreshAdminAcls(request);
-
-  }
-
-  @Override
-  public RefreshServiceAclsResponse refreshServiceAcls(
-      RefreshServiceAclsRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().refreshServiceAcls(request);
-
-  }
-
-  @Override
-  public UpdateNodeResourceResponse updateNodeResource(
-      UpdateNodeResourceRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().updateNodeResource(request);
-
-  }
-
-  @Override
-  public RefreshNodesResourcesResponse refreshNodesResources(
-      RefreshNodesResourcesRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().refreshNodesResources(request);
-
-  }
-
-  @Override
-  public AddToClusterNodeLabelsResponse addToClusterNodeLabels(
-      AddToClusterNodeLabelsRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().addToClusterNodeLabels(request);
-
-  }
-
-  @Override
-  public RemoveFromClusterNodeLabelsResponse removeFromClusterNodeLabels(
-      RemoveFromClusterNodeLabelsRequest request)
-      throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().removeFromClusterNodeLabels(request);
-
-  }
-
-  @Override
-  public ReplaceLabelsOnNodeResponse replaceLabelsOnNode(
-      ReplaceLabelsOnNodeRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().replaceLabelsOnNode(request);
-
-  }
-
-  @Override
-  public CheckForDecommissioningNodesResponse checkForDecommissioningNodes(
-      CheckForDecommissioningNodesRequest checkForDecommissioningNodesRequest)
-      throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor()
-        .checkForDecommissioningNodes(checkForDecommissioningNodesRequest);
-  }
-
-  @Override
-  public RefreshClusterMaxPriorityResponse refreshClusterMaxPriority(
-      RefreshClusterMaxPriorityRequest request)
-      throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().refreshClusterMaxPriority(request);
-  }
-
-  @Override
-  public NodesToAttributesMappingResponse mapAttributesToNodes(
-      NodesToAttributesMappingRequest request)
-      throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().mapAttributesToNodes(request);
-  }
-
-  @Override
-  public DeregisterSubClusterResponse deregisterSubCluster(
-      DeregisterSubClusterRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().deregisterSubCluster(request);
-  }
-
-  @Override
-  public SaveFederationQueuePolicyResponse saveFederationQueuePolicy(
-      SaveFederationQueuePolicyRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().saveFederationQueuePolicy(request);
-  }
-
-  @Override
-  public BatchSaveFederationQueuePoliciesResponse batchSaveFederationQueuePolicies(
-      BatchSaveFederationQueuePoliciesRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().batchSaveFederationQueuePolicies(request);
-  }
-
-  @Override
-  public QueryFederationQueuePoliciesResponse listFederationQueuePolicies(
-      QueryFederationQueuePoliciesRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().listFederationQueuePolicies(request);
-  }
-
-  @Override
-  public DeleteFederationApplicationResponse deleteFederationApplication(
-      DeleteFederationApplicationRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().deleteFederationApplication(request);
-  }
-
-  @Override
-  public GetSubClustersResponse getFederationSubClusters(
-      GetSubClustersRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().getFederationSubClusters(request);
-  }
-
-  @Override
-  public DeleteFederationQueuePoliciesResponse deleteFederationPoliciesByQueues(
-      DeleteFederationQueuePoliciesRequest request) throws YarnException, IOException {
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain();
-    return pipeline.getRootInterceptor().deleteFederationPoliciesByQueues(request);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/package-info.java
deleted file mode 100644
index 98a7ed0841c..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/rmadmin/package-info.java
+++ /dev/null
@@ -1,20 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/** Router RM Admin Proxy Service package. **/
-package org.apache.hadoop.yarn.server.router.rmadmin;
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/security/RouterDelegationTokenSecretManager.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/security/RouterDelegationTokenSecretManager.java
deleted file mode 100644
index 16a00808a76..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/security/RouterDelegationTokenSecretManager.java
+++ /dev/null
@@ -1,375 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.security;
-
-import org.apache.hadoop.classification.InterfaceAudience.Public;
-import org.apache.hadoop.classification.VisibleForTesting;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.security.token.delegation.AbstractDelegationTokenSecretManager;
-import org.apache.hadoop.security.token.delegation.DelegationKey;
-import org.apache.hadoop.security.token.delegation.RouterDelegationTokenSupport;
-import org.apache.hadoop.util.ExitUtil;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-import org.apache.hadoop.yarn.security.client.RMDelegationTokenIdentifier;
-import org.apache.hadoop.yarn.security.client.YARNDelegationTokenIdentifier;
-import org.apache.hadoop.yarn.server.federation.store.records.RouterMasterKey;
-import org.apache.hadoop.yarn.server.federation.store.records.RouterMasterKeyResponse;
-import org.apache.hadoop.yarn.server.federation.store.records.RouterRMTokenResponse;
-import org.apache.hadoop.yarn.server.federation.store.records.RouterStoreToken;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Map;
-import java.util.Set;
-import java.util.Base64;
-
-/**
- * A Router specific delegation token secret manager.
- * The secret manager is responsible for generating and accepting the password
- * for each token.
- */
-public class RouterDelegationTokenSecretManager
-    extends AbstractDelegationTokenSecretManager<RMDelegationTokenIdentifier> {
-
-  private static final Logger LOG = LoggerFactory
-      .getLogger(RouterDelegationTokenSecretManager.class);
-
-  private FederationStateStoreFacade federationFacade;
-
-  /**
-   * Create a Router Secret manager.
-   *
-   * @param delegationKeyUpdateInterval        the number of milliseconds for rolling
-   *                                           new secret keys.
-   * @param delegationTokenMaxLifetime         the maximum lifetime of the delegation
-   *                                           tokens in milliseconds
-   * @param delegationTokenRenewInterval       how often the tokens must be renewed
-   *                                           in milliseconds
-   * @param delegationTokenRemoverScanInterval how often the tokens are scanned
-   * @param conf Configuration.
-   */
-  public RouterDelegationTokenSecretManager(long delegationKeyUpdateInterval,
-      long delegationTokenMaxLifetime, long delegationTokenRenewInterval,
-      long delegationTokenRemoverScanInterval, Configuration conf) {
-    super(delegationKeyUpdateInterval, delegationTokenMaxLifetime,
-        delegationTokenRenewInterval, delegationTokenRemoverScanInterval);
-    this.federationFacade = FederationStateStoreFacade.getInstance(conf);
-  }
-
-  @Override
-  public RMDelegationTokenIdentifier createIdentifier() {
-    return new RMDelegationTokenIdentifier();
-  }
-
-  private boolean shouldIgnoreException(Exception e) {
-    return !running && e.getCause() instanceof InterruptedException;
-  }
-
-  /**
-   * The Router Supports Store the New Master Key.
-   * During this Process, Facade will call the specific StateStore to store the MasterKey.
-   *
-   * @param newKey DelegationKey
-   */
-  @Override
-  public void storeNewMasterKey(DelegationKey newKey) {
-    try {
-      federationFacade.storeNewMasterKey(newKey);
-    } catch (Exception e) {
-      if (!shouldIgnoreException(e)) {
-        LOG.error("Error in storing master key with KeyID: {}.", newKey.getKeyId());
-        ExitUtil.terminate(1, e);
-      }
-    }
-  }
-
-  /**
-   * The Router Supports Remove the master key.
-   * During this Process, Facade will call the specific StateStore to remove the MasterKey.
-   *
-   * @param delegationKey DelegationKey
-   */
-  @Override
-  public void removeStoredMasterKey(DelegationKey delegationKey) {
-    try {
-      federationFacade.removeStoredMasterKey(delegationKey);
-    } catch (Exception e) {
-      if (!shouldIgnoreException(e)) {
-        LOG.error("Error in removing master key with KeyID: {}.", delegationKey.getKeyId());
-        ExitUtil.terminate(1, e);
-      }
-    }
-  }
-
-  /**
-   * The Router Supports Store new Token.
-   *
-   * @param identifier RMDelegationToken
-   * @param renewDate renewDate
-   * @throws IOException IO exception occurred.
-   */
-  @Override
-  public void storeNewToken(RMDelegationTokenIdentifier identifier,
-      long renewDate) throws IOException {
-    try {
-      federationFacade.storeNewToken(identifier, renewDate);
-    } catch (Exception e) {
-      if (!shouldIgnoreException(e)) {
-        LOG.error("Error in storing RMDelegationToken with sequence number: {}.",
-            identifier.getSequenceNumber());
-        ExitUtil.terminate(1, e);
-      }
-    }
-  }
-
-  /**
-   * The Router Supports Store new Token.
-   *
-   * @param identifier RMDelegationToken.
-   * @param tokenInfo DelegationTokenInformation.
-   */
-  public void storeNewToken(RMDelegationTokenIdentifier identifier,
-      DelegationTokenInformation tokenInfo) {
-    try {
-      String token =
-          RouterDelegationTokenSupport.encodeDelegationTokenInformation(tokenInfo);
-      long renewDate = tokenInfo.getRenewDate();
-
-      federationFacade.storeNewToken(identifier, renewDate, token);
-    } catch (Exception e) {
-      if (!shouldIgnoreException(e)) {
-        LOG.error("Error in storing RMDelegationToken with sequence number: {}.",
-            identifier.getSequenceNumber());
-        ExitUtil.terminate(1, e);
-      }
-    }
-  }
-
-  /**
-   * The Router Supports Update Token.
-   *
-   * @param id RMDelegationToken
-   * @param renewDate renewDate
-   * @throws IOException IO exception occurred
-   */
-  @Override
-  public void updateStoredToken(RMDelegationTokenIdentifier id, long renewDate) throws IOException {
-    try {
-      federationFacade.updateStoredToken(id, renewDate);
-    } catch (Exception e) {
-      if (!shouldIgnoreException(e)) {
-        LOG.error("Error in updating persisted RMDelegationToken with sequence number: {}.",
-            id.getSequenceNumber());
-        ExitUtil.terminate(1, e);
-      }
-    }
-  }
-
-  /**
-   * The Router Supports Update Token.
-   *
-   * @param identifier RMDelegationToken.
-   * @param tokenInfo DelegationTokenInformation.
-   */
-  public void updateStoredToken(RMDelegationTokenIdentifier identifier,
-      DelegationTokenInformation tokenInfo) {
-    try {
-      long renewDate = tokenInfo.getRenewDate();
-      String token = RouterDelegationTokenSupport.encodeDelegationTokenInformation(tokenInfo);
-      federationFacade.updateStoredToken(identifier, renewDate, token);
-    } catch (Exception e) {
-      if (!shouldIgnoreException(e)) {
-        LOG.error("Error in updating persisted RMDelegationToken with sequence number: {}.",
-            identifier.getSequenceNumber());
-        ExitUtil.terminate(1, e);
-      }
-    }
-  }
-
-  /**
-   * The Router Supports Remove Token.
-   *
-   * @param identifier Delegation Token
-   * @throws IOException IO exception occurred.
-   */
-  @Override
-  public void removeStoredToken(RMDelegationTokenIdentifier identifier) throws IOException {
-    try {
-      federationFacade.removeStoredToken(identifier);
-    } catch (Exception e) {
-      if (!shouldIgnoreException(e)) {
-        LOG.error("Error in removing RMDelegationToken with sequence number: {}",
-            identifier.getSequenceNumber());
-        ExitUtil.terminate(1, e);
-      }
-    }
-  }
-
-  /**
-   * The Router supports obtaining the DelegationKey stored in the Router StateStote
-   * according to the DelegationKey.
-   *
-   * @param key Param DelegationKey
-   * @return Delegation Token
-   * @throws YarnException An internal conversion error occurred when getting the Token
-   * @throws IOException IO exception occurred
-   */
-  public DelegationKey getMasterKeyByDelegationKey(DelegationKey key)
-      throws YarnException, IOException {
-    try {
-      RouterMasterKeyResponse response = federationFacade.getMasterKeyByDelegationKey(key);
-      RouterMasterKey masterKey = response.getRouterMasterKey();
-      ByteBuffer keyByteBuf = masterKey.getKeyBytes();
-      byte[] keyBytes = new byte[keyByteBuf.remaining()];
-      keyByteBuf.get(keyBytes);
-      DelegationKey delegationKey =
-          new DelegationKey(masterKey.getKeyId(), masterKey.getExpiryDate(), keyBytes);
-      return delegationKey;
-    } catch (IOException ex) {
-      throw new IOException(ex);
-    } catch (YarnException ex) {
-      throw new YarnException(ex);
-    }
-  }
-
-  /**
-   * Get RMDelegationTokenIdentifier according to RouterStoreToken.
-   *
-   * @param identifier RMDelegationTokenIdentifier
-   * @return RMDelegationTokenIdentifier
-   * @throws YarnException An internal conversion error occurred when getting the Token
-   * @throws IOException IO exception occurred
-   */
-  public RMDelegationTokenIdentifier getTokenByRouterStoreToken(
-      RMDelegationTokenIdentifier identifier) throws YarnException, IOException {
-    try {
-      RouterRMTokenResponse response = federationFacade.getTokenByRouterStoreToken(identifier);
-      YARNDelegationTokenIdentifier responseIdentifier =
-          response.getRouterStoreToken().getTokenIdentifier();
-      return (RMDelegationTokenIdentifier) responseIdentifier;
-    } catch (Exception ex) {
-      throw new YarnException(ex);
-    }
-  }
-
-  public void setFederationFacade(FederationStateStoreFacade federationFacade) {
-    this.federationFacade = federationFacade;
-  }
-
-  @Public
-  @VisibleForTesting
-  public int getLatestDTSequenceNumber() {
-    return delegationTokenSequenceNumber;
-  }
-
-  @Public
-  @VisibleForTesting
-  public synchronized Set<DelegationKey> getAllMasterKeys() {
-    return new HashSet<>(allKeys.values());
-  }
-
-  @Public
-  @VisibleForTesting
-  public synchronized Map<RMDelegationTokenIdentifier, Long> getAllTokens() {
-    Map<RMDelegationTokenIdentifier, Long> allTokens = new HashMap<>();
-    for (Map.Entry<RMDelegationTokenIdentifier,
-         DelegationTokenInformation> entry : currentTokens.entrySet()) {
-      RMDelegationTokenIdentifier keyIdentifier = entry.getKey();
-      DelegationTokenInformation tokenInformation = entry.getValue();
-      allTokens.put(keyIdentifier, tokenInformation.getRenewDate());
-    }
-    return allTokens;
-  }
-
-  public long getRenewDate(RMDelegationTokenIdentifier ident)
-      throws InvalidToken {
-    DelegationTokenInformation info = currentTokens.get(ident);
-    if (info == null) {
-      throw new InvalidToken("token (" + ident.toString()
-          + ") can't be found in cache");
-    }
-    return info.getRenewDate();
-  }
-
-  @Override
-  protected synchronized int incrementDelegationTokenSeqNum() {
-    return federationFacade.incrementDelegationTokenSeqNum();
-  }
-
-  @Override
-  protected void storeToken(RMDelegationTokenIdentifier rmDelegationTokenIdentifier,
-      DelegationTokenInformation tokenInfo) throws IOException {
-    this.currentTokens.put(rmDelegationTokenIdentifier, tokenInfo);
-    this.addTokenForOwnerStats(rmDelegationTokenIdentifier);
-    storeNewToken(rmDelegationTokenIdentifier, tokenInfo);
-  }
-
-  @Override
-  protected void updateToken(RMDelegationTokenIdentifier rmDelegationTokenIdentifier,
-      DelegationTokenInformation tokenInfo) throws IOException {
-    this.currentTokens.put(rmDelegationTokenIdentifier, tokenInfo);
-    updateStoredToken(rmDelegationTokenIdentifier, tokenInfo);
-  }
-
-  @Override
-  protected DelegationTokenInformation getTokenInfo(
-      RMDelegationTokenIdentifier ident) {
-    // First check if I have this..
-    DelegationTokenInformation tokenInfo = currentTokens.get(ident);
-    if (tokenInfo == null) {
-      try {
-        RouterRMTokenResponse response = federationFacade.getTokenByRouterStoreToken(ident);
-        RouterStoreToken routerStoreToken = response.getRouterStoreToken();
-        String tokenStr = routerStoreToken.getTokenInfo();
-        byte[] tokenBytes = Base64.getUrlDecoder().decode(tokenStr);
-        tokenInfo = RouterDelegationTokenSupport.decodeDelegationTokenInformation(tokenBytes);
-      } catch (Exception e) {
-        LOG.error("Error retrieving tokenInfo [" + ident.getSequenceNumber()
-            + "] from StateStore.", e);
-        throw new YarnRuntimeException(e);
-      }
-    }
-    return tokenInfo;
-  }
-
-  @Override
-  protected synchronized int getDelegationTokenSeqNum() {
-    return federationFacade.getDelegationTokenSeqNum();
-  }
-
-  @Override
-  protected synchronized void setDelegationTokenSeqNum(int seqNum) {
-    federationFacade.setDelegationTokenSeqNum(seqNum);
-  }
-
-  @Override
-  protected synchronized int getCurrentKeyId() {
-    return federationFacade.getCurrentKeyId();
-  }
-
-  @Override
-  protected synchronized int incrementCurrentKeyId() {
-    return federationFacade.incrementCurrentKeyId();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/security/authorize/RouterPolicyProvider.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/security/authorize/RouterPolicyProvider.java
deleted file mode 100644
index 917e1855a9e..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/security/authorize/RouterPolicyProvider.java
+++ /dev/null
@@ -1,66 +0,0 @@
-/**
-* Licensed to the Apache Software Foundation (ASF) under one
-* or more contributor license agreements. See the NOTICE file
-* distributed with this work for additional information
-* regarding copyright ownership. The ASF licenses this file
-* to you under the Apache License, Version 2.0 (the
-* "License"); you may not use this file except in compliance
-* with the License. You may obtain a copy of the License at
-*
-* http://www.apache.org/licenses/LICENSE-2.0
-*
-* Unless required by applicable law or agreed to in writing, software
-* distributed under the License is distributed on an "AS IS" BASIS,
-* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-* See the License for the specific language governing permissions and
-* limitations under the License.
-*/
-package org.apache.hadoop.yarn.server.router.security.authorize;
-
-import org.apache.hadoop.classification.InterfaceAudience;
-import org.apache.hadoop.classification.InterfaceStability;
-import org.apache.hadoop.security.authorize.PolicyProvider;
-import org.apache.hadoop.security.authorize.Service;
-import org.apache.hadoop.yarn.api.ApplicationClientProtocolPB;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB;
-
-/**
- * {@link PolicyProvider} for YARN Router server protocols.
- */
-@InterfaceAudience.Private
-@InterfaceStability.Unstable
-public class RouterPolicyProvider extends PolicyProvider {
-
-  private static volatile RouterPolicyProvider routerPolicyProvider = null;
-
-  private RouterPolicyProvider() {
-  }
-
-  @InterfaceAudience.Private
-  @InterfaceStability.Unstable
-  public static RouterPolicyProvider getInstance() {
-    if (routerPolicyProvider == null) {
-      synchronized (RouterPolicyProvider.class) {
-        if (routerPolicyProvider == null) {
-          routerPolicyProvider = new RouterPolicyProvider();
-        }
-      }
-    }
-    return routerPolicyProvider;
-  }
-
-  private static final Service[] ROUTER_SERVICES = new Service[] {
-      new Service(
-          YarnConfiguration.YARN_SECURITY_SERVICE_AUTHORIZATION_APPLICATIONCLIENT_PROTOCOL,
-          ApplicationClientProtocolPB.class),
-      new Service(
-          YarnConfiguration.YARN_SECURITY_SERVICE_AUTHORIZATION_RESOURCEMANAGER_ADMINISTRATION_PROTOCOL,
-          ResourceManagerAdministrationProtocolPB.class), };
-
-  @Override
-  public Service[] getServices() {
-    return ROUTER_SERVICES;
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/security/authorize/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/security/authorize/package-info.java
deleted file mode 100644
index da9c8bcd68b..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/security/authorize/package-info.java
+++ /dev/null
@@ -1,22 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/** Router Security Authorization package. **/
-package org.apache.hadoop.yarn.server.router.security.authorize;
-
-
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/security/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/security/package-info.java
deleted file mode 100644
index 16a7488c071..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/security/package-info.java
+++ /dev/null
@@ -1,19 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.security;
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AboutBlock.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AboutBlock.java
deleted file mode 100644
index 4ae43f01f24..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AboutBlock.java
+++ /dev/null
@@ -1,86 +0,0 @@
-/**
-* Licensed to the Apache Software Foundation (ASF) under one
-* or more contributor license agreements.  See the NOTICE file
-* distributed with this work for additional information
-* regarding copyright ownership.  The ASF licenses this file
-* to you under the Apache License, Version 2.0 (the
-* "License"); you may not use this file except in compliance
-* with the License.  You may obtain a copy of the License at
-*
-*     http://www.apache.org/licenses/LICENSE-2.0
-*
-* Unless required by applicable law or agreed to in writing, software
-* distributed under the License is distributed on an "AS IS" BASIS,
-* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-* See the License for the specific language governing permissions and
-* limitations under the License.
-*/
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import org.apache.commons.lang3.time.DateFormatUtils;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.router.Router;
-import org.apache.hadoop.yarn.server.router.webapp.dao.RouterInfo;
-import org.apache.hadoop.yarn.webapp.view.InfoBlock;
-
-import com.google.inject.Inject;
-
-/**
- * About block for the Router Web UI.
- */
-public class AboutBlock extends RouterBlock {
-
-  private final Router router;
-
-  @Inject
-  AboutBlock(Router router, ViewContext ctx) {
-    super(router, ctx);
-    this.router = router;
-  }
-
-  @Override
-  protected void render(Block html) {
-
-    boolean isEnabled = isYarnFederationEnabled();
-
-    // If Yarn Federation is not enabled, the user needs to be prompted.
-    initUserHelpInformationDiv(html, isEnabled);
-
-    // Metrics Overview Table
-    html.__(MetricsOverviewTable.class);
-
-    // Init Yarn Router Basic Information
-    initYarnRouterBasicInformation(isEnabled);
-
-    // InfoBlock
-    html.__(InfoBlock.class);
-  }
-
-  /**
-   * Init Yarn Router Basic Infomation.
-   * @param isEnabled true, federation is enabled; false, federation is not enabled.
-   */
-  private void initYarnRouterBasicInformation(boolean isEnabled) {
-    FederationStateStoreFacade facade = FederationStateStoreFacade.getInstance(router.getConfig());
-    RouterInfo routerInfo = new RouterInfo(router);
-    String lastStartTime =
-        DateFormatUtils.format(routerInfo.getStartedOn(), DATE_PATTERN);
-    try {
-      info("Yarn Router Overview").
-          __("Federation Enabled:", String.valueOf(isEnabled)).
-          __("Router ID:", routerInfo.getClusterId()).
-          __("Router state:", routerInfo.getState()).
-          __("Router SubCluster Count:", facade.getSubClusters(true).size()).
-          __("Router RMStateStore:", routerInfo.getRouterStateStore()).
-          __("Router started on:", lastStartTime).
-          __("Router version:", routerInfo.getRouterBuildVersion() +
-             " on " + routerInfo.getRouterVersionBuiltOn()).
-          __("Hadoop version:", routerInfo.getHadoopBuildVersion() +
-             " on " + routerInfo.getHadoopVersionBuiltOn());
-    } catch (YarnException e) {
-      LOG.error("initYarnRouterBasicInformation error.", e);
-    }
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AboutPage.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AboutPage.java
deleted file mode 100644
index 3c9f00dbfc6..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AboutPage.java
+++ /dev/null
@@ -1,37 +0,0 @@
-/**
-* Licensed to the Apache Software Foundation (ASF) under one
-* or more contributor license agreements.  See the NOTICE file
-* distributed with this work for additional information
-* regarding copyright ownership.  The ASF licenses this file
-* to you under the Apache License, Version 2.0 (the
-* "License"); you may not use this file except in compliance
-* with the License.  You may obtain a copy of the License at
-*
-*     http://www.apache.org/licenses/LICENSE-2.0
-*
-* Unless required by applicable law or agreed to in writing, software
-* distributed under the License is distributed on an "AS IS" BASIS,
-* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-* See the License for the specific language governing permissions and
-* limitations under the License.
-*/
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import org.apache.hadoop.yarn.webapp.SubView;
-
-/**
- * About page for the Router Web UI.
- */
-public class AboutPage extends RouterView {
-
-  @Override
-  protected void preHead(Page.HTML<__> html) {
-    commonPreHead(html);
-  }
-
-  @Override
-  protected Class<? extends SubView> content() {
-    return AboutBlock.class;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AbstractRESTRequestInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AbstractRESTRequestInterceptor.java
deleted file mode 100644
index ad79addfca4..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AbstractRESTRequestInterceptor.java
+++ /dev/null
@@ -1,109 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.yarn.server.router.clientrm.RouterClientRMService;
-
-import org.apache.hadoop.yarn.server.router.RouterServerUtil;
-
-/**
- * Extends the RequestInterceptor class and provides common functionality which
- * can be used and/or extended by other concrete interceptor classes.
- */
-public abstract class AbstractRESTRequestInterceptor
-    implements RESTRequestInterceptor {
-
-  private Configuration conf;
-  private RESTRequestInterceptor nextInterceptor;
-  private UserGroupInformation user = null;
-  private RouterClientRMService routerClientRMService = null;
-
-  /**
-   * Sets the {@link RESTRequestInterceptor} in the chain.
-   */
-  @Override
-  public void setNextInterceptor(RESTRequestInterceptor nextInterceptor) {
-    this.nextInterceptor = nextInterceptor;
-  }
-
-  /**
-   * Sets the {@link Configuration}.
-   */
-
-  @Override
-  public void setConf(Configuration conf) {
-    this.conf = conf;
-    if (this.nextInterceptor != null) {
-      this.nextInterceptor.setConf(conf);
-    }
-  }
-
-  /**
-   * Gets the {@link Configuration}.
-   */
-  @Override
-  public Configuration getConf() {
-    return this.conf;
-  }
-
-  /**
-   * Initializes the {@link RESTRequestInterceptor}.
-   */
-  @Override
-  public void init(String userName) {
-    this.user = RouterServerUtil.setupUser(userName);
-    if (this.nextInterceptor != null) {
-      this.nextInterceptor.init(userName);
-    }
-  }
-
-  /**
-   * Disposes the {@link RESTRequestInterceptor}.
-   */
-  @Override
-  public void shutdown() {
-    if (this.nextInterceptor != null) {
-      this.nextInterceptor.shutdown();
-    }
-  }
-
-  /**
-   * Gets the next {@link RESTRequestInterceptor} in the chain.
-   */
-  @Override
-  public RESTRequestInterceptor getNextInterceptor() {
-    return this.nextInterceptor;
-  }
-
-  public UserGroupInformation getUser() {
-    return user;
-  }
-
-  @Override
-  public RouterClientRMService getRouterClientRMService() {
-    return routerClientRMService;
-  }
-
-  @Override
-  public void setRouterClientRMService(RouterClientRMService routerClientRMService) {
-    this.routerClientRMService = routerClientRMService;
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AppsBlock.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AppsBlock.java
deleted file mode 100644
index 4fa07b70fa7..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AppsBlock.java
+++ /dev/null
@@ -1,215 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import static org.apache.commons.text.StringEscapeUtils.escapeHtml4;
-import static org.apache.commons.text.StringEscapeUtils.escapeEcmaScript;
-import static org.apache.hadoop.yarn.util.StringHelper.join;
-import static org.apache.hadoop.yarn.webapp.YarnWebParams.APP_SC;
-import static org.apache.hadoop.yarn.webapp.YarnWebParams.APP_STATE;
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.C_PROGRESSBAR;
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.C_PROGRESSBAR_VALUE;
-
-import com.sun.jersey.api.client.Client;
-import org.apache.commons.collections.CollectionUtils;
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppsInfo;
-import org.apache.hadoop.yarn.server.router.Router;
-import org.apache.hadoop.yarn.webapp.hamlet2.Hamlet;
-import org.apache.hadoop.yarn.webapp.hamlet2.Hamlet.TABLE;
-import org.apache.hadoop.yarn.webapp.hamlet2.Hamlet.TBODY;
-import org.apache.hadoop.yarn.webapp.util.WebAppUtils;
-
-import com.google.inject.Inject;
-
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.stream.Collectors;
-
-/**
- * Applications block for the Router Web UI.
- */
-public class AppsBlock extends RouterBlock {
-
-  private final Router router;
-  private final Configuration conf;
-
-  @Inject
-  AppsBlock(Router router, ViewContext ctx) {
-    super(router, ctx);
-    this.router = router;
-    this.conf = this.router.getConfig();
-  }
-
-  @Override
-  protected void render(Block html) {
-
-    boolean isEnabled = isYarnFederationEnabled();
-
-    // Get subClusterName
-    String subClusterName = $(APP_SC);
-    String reqState = $(APP_STATE);
-
-    // We will try to get the subClusterName.
-    // If the subClusterName is not empty,
-    // it means that we need to get the Node list of a subCluster.
-    AppsInfo appsInfo = null;
-    if (subClusterName != null && !subClusterName.isEmpty()) {
-      initSubClusterMetricsOverviewTable(html, subClusterName);
-      appsInfo = getSubClusterAppsInfo(subClusterName, reqState);
-    } else {
-      // Metrics Overview Table
-      html.__(MetricsOverviewTable.class);
-      appsInfo = getYarnFederationAppsInfo(isEnabled);
-    }
-
-    initYarnFederationAppsOfCluster(appsInfo, html);
-  }
-
-  private static String escape(String str) {
-    return escapeEcmaScript(escapeHtml4(str));
-  }
-
-  private AppsInfo getYarnFederationAppsInfo(boolean isEnabled) {
-    String webAddress = null;
-    if (isEnabled) {
-      webAddress = WebAppUtils.getRouterWebAppURLWithScheme(this.conf);
-    } else {
-      webAddress = WebAppUtils.getRMWebAppURLWithScheme(this.conf);
-    }
-    return getSubClusterAppsInfoByWebAddress(webAddress, StringUtils.EMPTY);
-  }
-
-  private AppsInfo getSubClusterAppsInfo(String subCluster, String states) {
-    try {
-      SubClusterId subClusterId = SubClusterId.newInstance(subCluster);
-      FederationStateStoreFacade facade = FederationStateStoreFacade.getInstance(this.conf);
-      SubClusterInfo subClusterInfo = facade.getSubCluster(subClusterId);
-
-      if (subClusterInfo != null) {
-        // Prepare webAddress
-        String webAddress = subClusterInfo.getRMWebServiceAddress();
-        String herfWebAppAddress;
-        if (webAddress != null && !webAddress.isEmpty()) {
-          herfWebAppAddress = WebAppUtils.getHttpSchemePrefix(conf) + webAddress;
-          return getSubClusterAppsInfoByWebAddress(herfWebAppAddress, states);
-        }
-      }
-    } catch (Exception e) {
-      LOG.error("get AppsInfo From SubCluster = {} error.", subCluster, e);
-    }
-    return null;
-  }
-
-  private AppsInfo getSubClusterAppsInfoByWebAddress(String webAddress, String states) {
-    Client client = RouterWebServiceUtil.createJerseyClient(conf);
-    Map<String, String[]> queryParams = new HashMap<>();
-    if (StringUtils.isNotBlank(states)) {
-      queryParams.put("states", new String[]{states});
-    }
-    AppsInfo apps = RouterWebServiceUtil
-        .genericForward(webAddress, null, AppsInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.APPS, null, queryParams, conf,
-        client);
-    client.destroy();
-    return apps;
-  }
-
-  private void initYarnFederationAppsOfCluster(AppsInfo appsInfo, Block html) {
-
-    TBODY<TABLE<Hamlet>> tbody = html.table("#apps").thead()
-        .tr()
-        .th(".id", "ID")
-        .th(".user", "User")
-        .th(".name", "Name")
-        .th(".type", "Application Type")
-        .th(".queue", "Queue")
-        .th(".priority", "Application Priority")
-        .th(".starttime", "StartTime")
-        .th(".finishtime", "FinishTime")
-        .th(".state", "State")
-        .th(".finalstatus", "FinalStatus")
-        .th(".progress", "Progress")
-        .th(".ui", "Tracking UI")
-        .__().__().tbody();
-
-    // Render the applications
-    StringBuilder appsTableData = new StringBuilder("[\n");
-
-    if (appsInfo != null && CollectionUtils.isNotEmpty(appsInfo.getApps())) {
-
-      List<String> appInfoList =
-          appsInfo.getApps().stream().map(this::parseAppInfoData).collect(Collectors.toList());
-
-      if (CollectionUtils.isNotEmpty(appInfoList)) {
-        String formattedAppInfo = StringUtils.join(appInfoList, ",");
-        appsTableData.append(formattedAppInfo);
-      }
-    }
-
-    appsTableData.append("]");
-    html.script().$type("text/javascript")
-        .__("var appsTableData=" + appsTableData).__();
-
-    tbody.__().__();
-  }
-
-  private String parseAppInfoData(AppInfo app) {
-    StringBuilder appsDataBuilder = new StringBuilder();
-    try {
-      String percent = String.format("%.1f", app.getProgress() * 100.0F);
-      String trackingURL = app.getTrackingUrl() == null ? "#" : app.getTrackingUrl();
-
-      // AppID numerical value parsed by parseHadoopID in yarn.dt.plugins.js
-      appsDataBuilder.append("[\"")
-          .append("<a href='").append(trackingURL).append("'>")
-          .append(app.getAppId()).append("</a>\",\"")
-          .append(escape(app.getUser())).append("\",\"")
-          .append(escape(app.getName())).append("\",\"")
-          .append(escape(app.getApplicationType())).append("\",\"")
-          .append(escape(app.getQueue())).append("\",\"")
-          .append(app.getPriority()).append("\",\"")
-          .append(app.getStartTime()).append("\",\"")
-          .append(app.getFinishTime()).append("\",\"")
-          .append(app.getState()).append("\",\"")
-          .append(app.getFinalStatus()).append("\",\"")
-          // Progress bar
-          .append("<br title='").append(percent).append("'> <div class='")
-          .append(C_PROGRESSBAR).append("' title='")
-          .append(join(percent, '%')).append("'> ").append("<div class='")
-          .append(C_PROGRESSBAR_VALUE).append("' style='")
-          .append(join("width:", percent, '%')).append("'> </div> </div>")
-          // History link
-          .append("\",\"<a href='").append(trackingURL).append("'>")
-          .append("History").append("</a>");
-      appsDataBuilder.append("\"]\n");
-
-    } catch (Exception e) {
-      LOG.warn("Cannot add application {}: {}", app.getAppId(), e.getMessage());
-    }
-    return appsDataBuilder.toString();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AppsPage.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AppsPage.java
deleted file mode 100644
index f820aed05f2..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/AppsPage.java
+++ /dev/null
@@ -1,84 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import static org.apache.hadoop.yarn.util.StringHelper.sjoin;
-import static org.apache.hadoop.yarn.webapp.YarnWebParams.APP_STATE;
-import static org.apache.hadoop.yarn.webapp.YarnWebParams.APP_SC;
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.DATATABLES;
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.DATATABLES_ID;
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.initID;
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.tableInit;
-
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.yarn.webapp.SubView;
-
-class AppsPage extends RouterView {
-
-  @Override
-  protected void preHead(Page.HTML<__> html) {
-    commonPreHead(html);
-    set(DATATABLES_ID, "apps");
-    set(initID(DATATABLES, "apps"), appsTableInit());
-    setTableStyles(html, "apps", ".queue {width:6em}", ".ui {width:8em}");
-
-    // Set the correct title.
-    String subClusterName = $(APP_SC);
-    String reqState = $(APP_STATE);
-
-    if(StringUtils.isBlank(subClusterName)){
-      subClusterName = "Federation ";
-    }
-    reqState = (StringUtils.isBlank(reqState) ? "All" : reqState);
-    setTitle(sjoin(subClusterName, reqState,  "Applications"));
-  }
-
-  private String appsTableInit() {
-    // id, user, name, queue, starttime, finishtime, state, status, progress, ui
-    return tableInit()
-      .append(", 'aaData': appsTableData")
-      .append(", bDeferRender: true")
-      .append(", bProcessing: true")
-
-      .append("\n, aoColumnDefs: ")
-      .append(getAppsTableColumnDefs())
-
-      // Sort by id upon page load
-      .append(", aaSorting: [[0, 'desc']]}").toString();
-  }
-
-  protected String getAppsTableColumnDefs() {
-    StringBuilder sb = new StringBuilder();
-    return sb
-      .append("[\n")
-      .append("{'sType':'string', 'aTargets': [0]")
-      .append(", 'mRender': parseHadoopID }")
-
-      .append("\n, {'sType':'numeric', 'aTargets': [6, 7]")
-      .append(", 'mRender': renderHadoopDate }")
-
-      .append("\n, {'sType':'numeric', bSearchable:false, 'aTargets': [10]")
-      .append(", 'mRender': parseHadoopProgress }]").toString();
-  }
-
-  @Override
-  protected Class<? extends SubView> content() {
-    return AppsBlock.class;
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/DefaultRequestInterceptorREST.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/DefaultRequestInterceptorREST.java
deleted file mode 100644
index 9d3e3be6f6e..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/DefaultRequestInterceptorREST.java
+++ /dev/null
@@ -1,620 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import java.io.IOException;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.Set;
-
-import javax.servlet.http.HttpServletRequest;
-import javax.servlet.http.HttpServletResponse;
-import javax.ws.rs.core.Response;
-
-import com.sun.jersey.api.client.Client;
-import org.apache.hadoop.classification.VisibleForTesting;
-import org.apache.hadoop.security.authorize.AuthorizationException;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationStatisticsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterUserInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LabelsToNodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntryList;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.RMQueueAclInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceOptionInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.BulkActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerTypeInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.AppAttemptInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainerInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainersInfo;
-import org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo;
-import org.apache.hadoop.yarn.webapp.util.WebAppUtils;
-
-/**
- * Extends the AbstractRequestInterceptorClient class and provides an
- * implementation that simply forwards the client requests to the resource
- * manager.
- */
-public class DefaultRequestInterceptorREST
-    extends AbstractRESTRequestInterceptor {
-
-  private String webAppAddress;
-  private SubClusterId subClusterId = null;
-
-  // It is very expensive to create the client
-  // Jersey will spawn a thread for every client request
-  private Client client = null;
-
-  public void setWebAppAddress(String webAppAddress) {
-    this.webAppAddress = webAppAddress;
-  }
-
-  protected String getWebAppAddress() {
-    return this.webAppAddress;
-  }
-
-  protected void setSubClusterId(SubClusterId scId) {
-    this.subClusterId = scId;
-  }
-
-  protected SubClusterId getSubClusterId() {
-    return this.subClusterId;
-  }
-
-  @Override
-  public void init(String user) {
-    super.init(user);
-    webAppAddress = WebAppUtils.getRMWebAppURLWithScheme(getConf());
-    client = RouterWebServiceUtil.createJerseyClient(getConf());
-  }
-
-  @Override
-  public ClusterInfo get() {
-    return getClusterInfo();
-  }
-
-  @Override
-  public ClusterInfo getClusterInfo() {
-    return RouterWebServiceUtil.genericForward(webAppAddress, null,
-        ClusterInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.INFO, null, null,
-        getConf(), client);
-  }
-
-  @Override
-  public ClusterUserInfo getClusterUserInfo(HttpServletRequest hsr) {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        ClusterUserInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.CLUSTER_USER_INFO, null,
-        null, getConf(), client);
-  }
-
-  @Override
-  public ClusterMetricsInfo getClusterMetricsInfo() {
-    return RouterWebServiceUtil.genericForward(webAppAddress, null,
-        ClusterMetricsInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.METRICS, null, null,
-        getConf(), client);
-  }
-
-  @Override
-  public SchedulerTypeInfo getSchedulerInfo() {
-    return RouterWebServiceUtil.genericForward(webAppAddress, null,
-        SchedulerTypeInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.SCHEDULER, null, null,
-        getConf(), client);
-  }
-
-  @Override
-  public String dumpSchedulerLogs(String time, HttpServletRequest hsr)
-      throws IOException {
-    // time is specified inside hsr
-    return RouterWebServiceUtil.genericForward(webAppAddress, null,
-        String.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.SCHEDULER_LOGS, null, null,
-        getConf(), client);
-  }
-
-  @Override
-  public NodesInfo getNodes(String states) {
-    // states will be part of additionalParam
-    Map<String, String[]> additionalParam = new HashMap<String, String[]>();
-    if (states != null && !states.isEmpty()) {
-      additionalParam.put(RMWSConsts.STATES, new String[] {states});
-    }
-    return RouterWebServiceUtil.genericForward(webAppAddress, null,
-        NodesInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.NODES, null,
-        additionalParam, getConf(), client);
-  }
-
-  @Override
-  public NodeInfo getNode(String nodeId) {
-    return RouterWebServiceUtil.genericForward(webAppAddress, null,
-        NodeInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.NODES + "/" + nodeId, null,
-        null, getConf(), client);
-  }
-
-  @Override
-  public ResourceInfo updateNodeResource(HttpServletRequest hsr,
-      String nodeId, ResourceOptionInfo resourceOption) {
-    final String nodePath =
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.NODES + "/" + nodeId;
-    return RouterWebServiceUtil
-        .genericForward(webAppAddress, hsr, ResourceInfo.class,
-            HTTPMethods.POST, nodePath + "/resource", resourceOption, null,
-            getConf(), client);
-  }
-
-  @Override
-  public AppsInfo getApps(HttpServletRequest hsr, String stateQuery,
-      Set<String> statesQuery, String finalStatusQuery, String userQuery,
-      String queueQuery, String count, String startedBegin, String startedEnd,
-      String finishBegin, String finishEnd, Set<String> applicationTypes,
-      Set<String> applicationTags, String name, Set<String> unselectedFields) {
-    // all the params are specified inside hsr
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        AppsInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.APPS, null, null,
-        getConf(), client);
-  }
-
-  @Override
-  public ActivitiesInfo getActivities(HttpServletRequest hsr, String nodeId,
-      String groupBy) {
-    // nodeId is specified inside hsr
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        ActivitiesInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.SCHEDULER_ACTIVITIES, null,
-        null, getConf(), client);
-  }
-
-  @Override
-  public BulkActivitiesInfo getBulkActivities(HttpServletRequest hsr,
-      String groupBy, int activitiesCount) {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        BulkActivitiesInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.SCHEDULER_BULK_ACTIVITIES,
-        null, null, getConf(), client);
-  }
-
-  @Override
-  public AppActivitiesInfo getAppActivities(HttpServletRequest hsr,
-      String appId, String time, Set<String> requestPriorities,
-      Set<String> allocationRequestIds, String groupBy, String limit,
-      Set<String> actions, boolean summarize) {
-    // time and appId are specified inside hsr
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        AppActivitiesInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.SCHEDULER_APP_ACTIVITIES,
-        null, null, getConf(), client);
-  }
-
-  @Override
-  public ApplicationStatisticsInfo getAppStatistics(HttpServletRequest hsr,
-      Set<String> stateQueries, Set<String> typeQueries) {
-    // stateQueries and typeQueries are specified inside hsr
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        ApplicationStatisticsInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.APP_STATISTICS, null, null,
-        getConf(), client);
-  }
-
-  @Override
-  public AppInfo getApp(HttpServletRequest hsr, String appId,
-      Set<String> unselectedFields) {
-    // unselectedFields is specified inside hsr
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        AppInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.APPS + "/" + appId, null,
-        null, getConf(), client);
-  }
-
-  @Override
-  public AppState getAppState(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        AppState.class, HTTPMethods.GET, RMWSConsts.RM_WEB_SERVICE_PATH
-            + RMWSConsts.APPS + "/" + appId + "/" + RMWSConsts.STATE,
-        null, null, getConf(), client);
-  }
-
-  @Override
-  public Response updateAppState(AppState targetState, HttpServletRequest hsr,
-      String appId) throws AuthorizationException, YarnException,
-      InterruptedException, IOException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        Response.class, HTTPMethods.PUT, RMWSConsts.RM_WEB_SERVICE_PATH
-            + RMWSConsts.APPS + "/" + appId + "/" + RMWSConsts.STATE,
-        targetState, null, getConf(), client);
-  }
-
-  @Override
-  public NodeToLabelsInfo getNodeToLabels(HttpServletRequest hsr)
-      throws IOException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        NodeToLabelsInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.GET_NODE_TO_LABELS, null,
-        null, getConf(), client);
-  }
-
-  @Override
-  public LabelsToNodesInfo getLabelsToNodes(Set<String> labels)
-      throws IOException {
-    // labels will be part of additionalParam
-    Map<String, String[]> additionalParam = new HashMap<>();
-    if (labels != null && !labels.isEmpty()) {
-      additionalParam.put(RMWSConsts.LABELS,
-          labels.toArray(new String[labels.size()]));
-    }
-    return RouterWebServiceUtil.genericForward(webAppAddress, null,
-        LabelsToNodesInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.LABEL_MAPPINGS, null,
-        additionalParam, getConf(), client);
-  }
-
-  @Override
-  public Response replaceLabelsOnNodes(NodeToLabelsEntryList newNodeToLabels,
-      HttpServletRequest hsr) throws IOException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        Response.class, HTTPMethods.POST,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.REPLACE_NODE_TO_LABELS,
-        newNodeToLabels, null, getConf(), client);
-  }
-
-  @Override
-  public Response replaceLabelsOnNode(Set<String> newNodeLabelsName,
-      HttpServletRequest hsr, String nodeId) throws Exception {
-    // newNodeLabelsName is specified inside hsr
-    return RouterWebServiceUtil
-        .genericForward(webAppAddress, hsr,
-            Response.class, HTTPMethods.POST, RMWSConsts.RM_WEB_SERVICE_PATH
-                + RMWSConsts.NODES + "/" + nodeId + "/replace-labels",
-            null, null, getConf(), client);
-  }
-
-  @Override
-  public NodeLabelsInfo getClusterNodeLabels(HttpServletRequest hsr)
-      throws IOException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        NodeLabelsInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.GET_NODE_LABELS, null,
-        null, getConf(), client);
-  }
-
-  @Override
-  public Response addToClusterNodeLabels(NodeLabelsInfo newNodeLabels,
-      HttpServletRequest hsr) throws Exception {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        Response.class, HTTPMethods.POST,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.ADD_NODE_LABELS,
-        newNodeLabels, null, getConf(), client);
-  }
-
-  @Override
-  public Response removeFromClusterNodeLabels(Set<String> oldNodeLabels,
-      HttpServletRequest hsr) throws Exception {
-    // oldNodeLabels is specified inside hsr
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        Response.class, HTTPMethods.POST,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.REMOVE_NODE_LABELS, null,
-        null, getConf(), client);
-  }
-
-  @Override
-  public NodeLabelsInfo getLabelsOnNode(HttpServletRequest hsr, String nodeId)
-      throws IOException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        NodeLabelsInfo.class, HTTPMethods.GET, RMWSConsts.RM_WEB_SERVICE_PATH
-            + RMWSConsts.NODES + "/" + nodeId + "/get-labels",
-        null, null, getConf(), client);
-  }
-
-  @Override
-  public AppPriority getAppPriority(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        AppPriority.class, HTTPMethods.GET, RMWSConsts.RM_WEB_SERVICE_PATH
-            + RMWSConsts.APPS + "/" + appId + "/" + RMWSConsts.PRIORITY,
-        null, null, getConf(), client);
-  }
-
-  @Override
-  public Response updateApplicationPriority(AppPriority targetPriority,
-      HttpServletRequest hsr, String appId) throws AuthorizationException,
-      YarnException, InterruptedException, IOException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        Response.class, HTTPMethods.PUT, RMWSConsts.RM_WEB_SERVICE_PATH
-            + RMWSConsts.APPS + "/" + appId + "/" + RMWSConsts.PRIORITY,
-        targetPriority, null, getConf(), client);
-  }
-
-  @Override
-  public AppQueue getAppQueue(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        AppQueue.class, HTTPMethods.GET, RMWSConsts.RM_WEB_SERVICE_PATH
-            + RMWSConsts.APPS + "/" + appId + "/" + RMWSConsts.QUEUE,
-        null, null, getConf(), client);
-  }
-
-  @Override
-  public Response updateAppQueue(AppQueue targetQueue, HttpServletRequest hsr,
-      String appId) throws AuthorizationException, YarnException,
-      InterruptedException, IOException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        Response.class, HTTPMethods.PUT, RMWSConsts.RM_WEB_SERVICE_PATH
-            + RMWSConsts.APPS + "/" + appId + "/" + RMWSConsts.QUEUE,
-        targetQueue, null, getConf(), client);
-  }
-
-  @Override
-  public Response createNewApplication(HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        Response.class, HTTPMethods.POST,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.APPS_NEW_APPLICATION, null,
-        null, getConf(), client);
-  }
-
-  @Override
-  public Response submitApplication(ApplicationSubmissionContextInfo newApp,
-      HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        Response.class, HTTPMethods.POST,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.APPS, newApp, null,
-        getConf(), client);
-  }
-
-  @Override
-  public Response postDelegationToken(DelegationToken tokenData,
-      HttpServletRequest hsr) throws AuthorizationException, IOException,
-      InterruptedException, Exception {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        Response.class, HTTPMethods.POST,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.DELEGATION_TOKEN, tokenData,
-        null, getConf(), client);
-  }
-
-  @Override
-  public Response postDelegationTokenExpiration(HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException,
-      Exception {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        Response.class, HTTPMethods.POST,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.DELEGATION_TOKEN_EXPIRATION,
-        null, null, getConf(), client);
-  }
-
-  @Override
-  public Response cancelDelegationToken(HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException,
-      Exception {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        Response.class, HTTPMethods.DELETE,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.DELEGATION_TOKEN, null,
-        null, getConf(), client);
-  }
-
-  @Override
-  public Response createNewReservation(HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        Response.class, HTTPMethods.POST,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.RESERVATION_NEW, null,
-        null, getConf(), client);
-  }
-
-  @Override
-  public Response submitReservation(ReservationSubmissionRequestInfo resContext,
-      HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        Response.class, HTTPMethods.POST,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.RESERVATION_SUBMIT,
-        resContext, null, getConf(), client);
-  }
-
-  @Override
-  public Response updateReservation(ReservationUpdateRequestInfo resContext,
-      HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        Response.class, HTTPMethods.POST,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.RESERVATION_UPDATE,
-        resContext, null, getConf(), client);
-  }
-
-  @Override
-  public Response deleteReservation(ReservationDeleteRequestInfo resContext,
-      HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        Response.class, HTTPMethods.POST,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.RESERVATION_DELETE,
-        resContext, null, getConf(), client);
-  }
-
-  @Override
-  public Response listReservation(String queue, String reservationId,
-      long startTime, long endTime, boolean includeResourceAllocations,
-      HttpServletRequest hsr) throws Exception {
-    // queue, reservationId, startTime, endTime, includeResourceAllocations are
-    // specified inside hsr
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        Response.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.RESERVATION_LIST, null,
-        null, getConf(), client);
-  }
-
-  @Override
-  public AppTimeoutInfo getAppTimeout(HttpServletRequest hsr, String appId,
-      String type) throws AuthorizationException {
-    return RouterWebServiceUtil
-        .genericForward(webAppAddress, hsr, AppTimeoutInfo.class,
-            HTTPMethods.GET, RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.APPS
-                + "/" + appId + "/" + RMWSConsts.TIMEOUTS + "/" + type,
-            null, null, getConf(), client);
-  }
-
-  @Override
-  public AppTimeoutsInfo getAppTimeouts(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        AppTimeoutsInfo.class, HTTPMethods.GET, RMWSConsts.RM_WEB_SERVICE_PATH
-            + RMWSConsts.APPS + "/" + appId + "/" + RMWSConsts.TIMEOUTS,
-        null, null, getConf(), client);
-  }
-
-  @Override
-  public Response updateApplicationTimeout(AppTimeoutInfo appTimeout,
-      HttpServletRequest hsr, String appId) throws AuthorizationException,
-      YarnException, InterruptedException, IOException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        Response.class, HTTPMethods.PUT, RMWSConsts.RM_WEB_SERVICE_PATH
-            + RMWSConsts.APPS + "/" + appId + "/" + RMWSConsts.TIMEOUT,
-        appTimeout, null, getConf(), client);
-  }
-
-  @Override
-  public AppAttemptsInfo getAppAttempts(HttpServletRequest hsr, String appId) {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        AppAttemptsInfo.class, HTTPMethods.GET, RMWSConsts.RM_WEB_SERVICE_PATH
-            + RMWSConsts.APPS + "/" + appId + "/" + RMWSConsts.APPATTEMPTS,
-        null, null, getConf(), client);
-  }
-
-  @Override
-  public RMQueueAclInfo checkUserAccessToQueue(String queue, String username,
-      String queueAclType, HttpServletRequest hsr) throws AuthorizationException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        RMQueueAclInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH +  "/" + RMWSConsts.QUEUES + "/" + queue
-            + "/access", null, null, getConf(), client);
-  }
-
-  @Override
-  public AppAttemptInfo getAppAttempt(HttpServletRequest req,
-      HttpServletResponse res, String appId, String appAttemptId) {
-    return RouterWebServiceUtil.genericForward(webAppAddress, req,
-        AppAttemptInfo.class,
-        HTTPMethods.GET, RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.APPS + "/"
-            + appId + "/" + RMWSConsts.APPATTEMPTS + "/" + appAttemptId,
-        null, null, getConf(), client);
-  }
-
-  @Override
-  public ContainersInfo getContainers(HttpServletRequest req,
-      HttpServletResponse res, String appId, String appAttemptId) {
-    return RouterWebServiceUtil.genericForward(webAppAddress, req,
-        ContainersInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.APPS + "/" + appId + "/"
-            + RMWSConsts.APPATTEMPTS + "/" + appAttemptId + "/"
-            + RMWSConsts.CONTAINERS,
-        null, null, getConf(), client);
-  }
-
-  @Override
-  public ContainerInfo getContainer(HttpServletRequest req,
-      HttpServletResponse res, String appId, String appAttemptId,
-      String containerId) {
-    return RouterWebServiceUtil.genericForward(webAppAddress, req,
-        ContainerInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.APPS + "/" + appId + "/"
-            + RMWSConsts.APPATTEMPTS + "/" + appAttemptId + "/"
-            + RMWSConsts.CONTAINERS + "/" + containerId,
-        null, null, getConf(), client);
-  }
-
-  @Override
-  public Response updateSchedulerConfiguration(SchedConfUpdateInfo mutationInfo,
-      HttpServletRequest req)
-      throws AuthorizationException, InterruptedException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, req,
-        Response.class, HTTPMethods.PUT,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.SCHEDULER_CONF,
-        mutationInfo, null, getConf(), client);
-  }
-
-  @Override
-  public Response getSchedulerConfiguration(HttpServletRequest req)
-      throws AuthorizationException {
-    return RouterWebServiceUtil.genericForward(webAppAddress, req,
-        Response.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.SCHEDULER_CONF,
-        null, null, getConf(), client);
-  }
-
-  @Override
-  public void setNextInterceptor(RESTRequestInterceptor next) {
-    throw new YarnRuntimeException("setNextInterceptor is being called on "
-        + "DefaultRequestInterceptorREST, which should be the last one "
-        + "in the chain. Check if the interceptor pipeline configuration "
-        + "is correct");
-  }
-
-  @Override
-  public Response signalToContainer(String containerId, String command,
-      HttpServletRequest req) throws AuthorizationException {
-    return RouterWebServiceUtil
-        .genericForward(webAppAddress, req, Response.class, HTTPMethods.POST,
-            RMWSConsts.RM_WEB_SERVICE_PATH + "/" + RMWSConsts.CONTAINERS + "/"
-                + containerId + "/" + RMWSConsts.SIGNAL + "/" + command, null,
-            null, getConf(), client);
-  }
-
-  @VisibleForTesting
-  public Client getClient() {
-    return client;
-  }
-
-  @Override
-  public NodeLabelsInfo getRMNodeLabels(HttpServletRequest hsr) {
-    return RouterWebServiceUtil.genericForward(webAppAddress, hsr,
-        NodeLabelsInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.GET_RM_NODE_LABELS,
-        null, null, getConf(), client);
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/FederationBlock.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/FederationBlock.java
deleted file mode 100644
index 7876d5d6f1f..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/FederationBlock.java
+++ /dev/null
@@ -1,268 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import java.io.StringReader;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Map;
-import java.util.HashMap;
-import java.util.Date;
-
-import com.google.gson.Gson;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.util.StringUtils;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterState;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.server.router.Router;
-import org.apache.hadoop.yarn.webapp.hamlet2.Hamlet;
-import org.apache.hadoop.yarn.webapp.hamlet2.Hamlet.TABLE;
-import org.apache.hadoop.yarn.webapp.hamlet2.Hamlet.TBODY;
-import org.apache.hadoop.yarn.webapp.util.WebAppUtils;
-
-import com.google.inject.Inject;
-import com.sun.jersey.api.json.JSONConfiguration;
-import com.sun.jersey.api.json.JSONJAXBContext;
-import com.sun.jersey.api.json.JSONUnmarshaller;
-
-class FederationBlock extends RouterBlock {
-
-  private final Router router;
-
-  @Inject
-  FederationBlock(ViewContext ctx, Router router) {
-    super(router, ctx);
-    this.router = router;
-  }
-
-  @Override
-  public void render(Block html) {
-
-    boolean isEnabled = isYarnFederationEnabled();
-
-    // init Html Page Federation
-    initHtmlPageFederation(html, isEnabled);
-  }
-
-  /**
-   * Parse the capability and obtain the metric information of the cluster.
-   *
-   * @param capability metric json obtained from RM.
-   * @return ClusterMetricsInfo Object
-   */
-  protected ClusterMetricsInfo getClusterMetricsInfo(String capability) {
-    try {
-      if (capability != null && !capability.isEmpty()) {
-        JSONJAXBContext jc = new JSONJAXBContext(
-            JSONConfiguration.mapped().rootUnwrapping(false).build(), ClusterMetricsInfo.class);
-        JSONUnmarshaller unmarShaller = jc.createJSONUnmarshaller();
-        StringReader stringReader = new StringReader(capability);
-        ClusterMetricsInfo clusterMetrics =
-            unmarShaller.unmarshalFromJSON(stringReader, ClusterMetricsInfo.class);
-        return clusterMetrics;
-      }
-    } catch (Exception e) {
-      LOG.error("Cannot parse SubCluster info", e);
-    }
-    return null;
-  }
-
-  /**
-   * Initialize the subCluster details JavaScript of the Federation page.
-   *
-   * This part of the js script will control to display or hide the detailed information
-   * of the subCluster when the user clicks on the subClusterId.
-   *
-   * We will obtain the specific information of a SubCluster,
-   * including the information of Applications, Resources, and Nodes.
-   *
-   * @param html html object
-   * @param subClusterDetailMap subCluster Detail Map
-   */
-  private void initFederationSubClusterDetailTableJs(Block html,
-      List<Map<String, String>> subClusterDetailMap) {
-    Gson gson = new Gson();
-    html.script().$type("text/javascript").
-        __(" var scTableData = " + gson.toJson(subClusterDetailMap) + "; ")
-        .__();
-    html.script(root_url("static/federation/federation.js"));
-  }
-
-  /**
-   * Initialize the Html page.
-   *
-   * @param html html object
-   */
-  private void initHtmlPageFederation(Block html, boolean isEnabled) {
-    List<Map<String, String>> lists = new ArrayList<>();
-
-    // Table header
-    TBODY<TABLE<Hamlet>> tbody =
-        html.table("#rms").$class("cell-border").$style("width:100%").thead().tr()
-        .th(".id", "SubCluster")
-        .th(".state", "State")
-        .th(".lastStartTime", "LastStartTime")
-        .th(".lastHeartBeat", "LastHeartBeat")
-        .th(".resources", "Resources")
-        .th(".nodes", "Nodes")
-        .__().__().tbody();
-
-    try {
-      if (isEnabled) {
-        initSubClusterPage(tbody, lists);
-      } else {
-        initLocalClusterPage(tbody, lists);
-      }
-    } catch (Exception e) {
-      LOG.error("Cannot render Router Federation.", e);
-    }
-
-    // Init FederationBlockTableJs
-    initFederationSubClusterDetailTableJs(html, lists);
-
-    // Tips
-    tbody.__().__().div().p().$style("color:red")
-        .__("*The application counts are local per subcluster").__().__();
-  }
-
-  /**
-   * Initialize the Federation page of the local-cluster.
-   *
-   * @param tbody HTML tbody.
-   * @param lists subCluster page data list.
-   */
-  private void initLocalClusterPage(TBODY<TABLE<Hamlet>> tbody, List<Map<String, String>> lists) {
-    Configuration config = this.router.getConfig();
-    SubClusterInfo localCluster = getSubClusterInfoByLocalCluster(config);
-    if (localCluster != null) {
-      try {
-        initSubClusterPageItem(tbody, localCluster, lists);
-      } catch (Exception e) {
-        LOG.error("init LocalCluster = {} page data error.", localCluster, e);
-      }
-    }
-  }
-
-  /**
-   * Initialize the Federation page of the sub-cluster.
-   *
-   * @param tbody HTML tbody.
-   * @param lists subCluster page data list.
-   */
-  private void initSubClusterPage(TBODY<TABLE<Hamlet>> tbody, List<Map<String, String>> lists) {
-    // Sort the SubClusters
-    List<SubClusterInfo> subClusters = getSubClusterInfoList();
-
-    // Iterate through the sub-clusters and display data for each sub-cluster.
-    // If a sub-cluster cannot display data, skip it.
-    for (SubClusterInfo subCluster : subClusters) {
-      try {
-        initSubClusterPageItem(tbody, subCluster, lists);
-      } catch (Exception e) {
-        LOG.error("init subCluster = {} page data error.", subCluster, e);
-      }
-    }
-  }
-
-  /**
-   * We will initialize the specific SubCluster's data within this method.
-   *
-   * @param tbody HTML TBody.
-   * @param subClusterInfo Sub-cluster information.
-   * @param lists Used to record data that needs to be displayed in JS.
-   */
-  private void initSubClusterPageItem(TBODY<TABLE<Hamlet>> tbody,
-      SubClusterInfo subClusterInfo, List<Map<String, String>> lists) {
-
-    Map<String, String> subClusterMap = new HashMap<>();
-
-    // Prepare subCluster
-    SubClusterId subClusterId = subClusterInfo.getSubClusterId();
-    String subClusterIdText = subClusterId.getId();
-
-    // Prepare WebAppAddress
-    String webAppAddress = subClusterInfo.getRMWebServiceAddress();
-    String herfWebAppAddress = "";
-    if (webAppAddress != null && !webAppAddress.isEmpty()) {
-      herfWebAppAddress =
-          WebAppUtils.getHttpSchemePrefix(this.router.getConfig()) + webAppAddress;
-    }
-
-    // Prepare Capability
-    String capability = subClusterInfo.getCapability();
-    ClusterMetricsInfo subClusterMetricsInfo = getClusterMetricsInfo(capability);
-
-    if (subClusterMetricsInfo == null) {
-      return;
-    }
-
-    // Prepare LastStartTime & LastHeartBeat
-    Date lastStartTime = new Date(subClusterInfo.getLastStartTime());
-    Date lastHeartBeat = new Date(subClusterInfo.getLastHeartBeat());
-
-    // Prepare Resource
-    long totalMB = subClusterMetricsInfo.getTotalMB();
-    String totalMBDesc = StringUtils.byteDesc(totalMB * BYTES_IN_MB);
-    long totalVirtualCores = subClusterMetricsInfo.getTotalVirtualCores();
-    String resources = String.format("<memory:%s, vCores:%s>", totalMBDesc, totalVirtualCores);
-
-    // Prepare Node
-    long totalNodes = subClusterMetricsInfo.getTotalNodes();
-    long activeNodes = subClusterMetricsInfo.getActiveNodes();
-    String nodes = String.format("<totalNodes:%s, activeNodes:%s>", totalNodes, activeNodes);
-
-    // Prepare HTML Table
-    String stateStyle = "color:#dc3545;font-weight:bolder";
-    SubClusterState state = subClusterInfo.getState();
-    if (SubClusterState.SC_RUNNING == state) {
-      stateStyle = "color:#28a745;font-weight:bolder";
-    }
-
-    tbody.tr().$id(subClusterIdText)
-        .td().$class("details-control").a(herfWebAppAddress, subClusterIdText).__()
-        .td().$style(stateStyle).__(state.name()).__()
-        .td().__(lastStartTime).__()
-        .td().__(lastHeartBeat).__()
-        .td(resources)
-        .td(nodes)
-        .__();
-
-    // Formatted memory information
-    long allocatedMB = subClusterMetricsInfo.getAllocatedMB();
-    String allocatedMBDesc = StringUtils.byteDesc(allocatedMB * BYTES_IN_MB);
-    long availableMB = subClusterMetricsInfo.getAvailableMB();
-    String availableMBDesc = StringUtils.byteDesc(availableMB * BYTES_IN_MB);
-    long pendingMB = subClusterMetricsInfo.getPendingMB();
-    String pendingMBDesc = StringUtils.byteDesc(pendingMB * BYTES_IN_MB);
-    long reservedMB = subClusterMetricsInfo.getReservedMB();
-    String reservedMBDesc = StringUtils.byteDesc(reservedMB * BYTES_IN_MB);
-
-    subClusterMap.put("totalmemory", totalMBDesc);
-    subClusterMap.put("allocatedmemory", allocatedMBDesc);
-    subClusterMap.put("availablememory", availableMBDesc);
-    subClusterMap.put("pendingmemory", pendingMBDesc);
-    subClusterMap.put("reservedmemory", reservedMBDesc);
-    subClusterMap.put("subcluster", subClusterId.getId());
-    subClusterMap.put("capability", capability);
-    lists.add(subClusterMap);
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/FederationInterceptorREST.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/FederationInterceptorREST.java
deleted file mode 100644
index fcfc7fa300e..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/FederationInterceptorREST.java
+++ /dev/null
@@ -1,3472 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import java.io.IOException;
-import java.lang.reflect.Method;
-import java.security.Principal;
-import java.security.PrivilegedExceptionAction;
-import java.util.ArrayList;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Map.Entry;
-import java.util.Set;
-import java.util.concurrent.CompletionService;
-import java.util.concurrent.ExecutorCompletionService;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Future;
-import java.util.concurrent.TimeUnit;
-import java.util.stream.Collectors;
-import java.util.stream.Stream;
-
-import javax.servlet.http.HttpServletRequest;
-import javax.servlet.http.HttpServletRequestWrapper;
-import javax.servlet.http.HttpServletResponse;
-import javax.ws.rs.core.HttpHeaders;
-import javax.ws.rs.core.Response;
-import javax.ws.rs.core.Response.Status;
-
-import org.apache.commons.collections.CollectionUtils;
-import org.apache.commons.lang3.StringUtils;
-import org.apache.commons.lang3.tuple.Pair;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.impl.prefetch.Validate;
-import org.apache.hadoop.io.Text;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.security.authorize.AuthorizationException;
-import org.apache.hadoop.security.token.Token;
-import org.apache.hadoop.util.ReflectionUtils;
-import org.apache.hadoop.util.Sets;
-import org.apache.hadoop.util.Time;
-import org.apache.hadoop.util.concurrent.HadoopExecutors;
-import org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.api.records.NodeLabel;
-import org.apache.hadoop.yarn.api.records.ReservationId;
-import org.apache.hadoop.yarn.api.records.ReservationDefinition;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-import org.apache.hadoop.yarn.security.client.RMDelegationTokenIdentifier;
-import org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol;
-import org.apache.hadoop.yarn.server.federation.policies.FederationPolicyUtils;
-import org.apache.hadoop.yarn.server.federation.policies.RouterPolicyFacade;
-import org.apache.hadoop.yarn.server.federation.policies.exceptions.FederationPolicyException;
-import org.apache.hadoop.yarn.server.federation.policies.exceptions.FederationPolicyInitializationException;
-import org.apache.hadoop.yarn.server.federation.resolver.SubClusterResolver;
-import org.apache.hadoop.yarn.server.federation.retry.FederationActionRetry;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.NodeIDsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebAppUtil;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationStatisticsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterUserInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LabelsToNodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntryList;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.RMQueueAclInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceOptionInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.BulkActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerTypeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntry;
-import org.apache.hadoop.yarn.server.router.RouterAuditLogger;
-import org.apache.hadoop.yarn.server.router.RouterMetrics;
-import org.apache.hadoop.yarn.server.router.RouterServerUtil;
-import org.apache.hadoop.yarn.server.router.clientrm.ClientMethod;
-import org.apache.hadoop.yarn.server.router.clientrm.RouterClientRMService;
-import org.apache.hadoop.yarn.server.router.security.RouterDelegationTokenSecretManager;
-import org.apache.hadoop.yarn.server.router.webapp.cache.RouterAppInfoCacheKey;
-import org.apache.hadoop.yarn.server.router.webapp.dao.FederationBulkActivitiesInfo;
-import org.apache.hadoop.yarn.server.router.webapp.dao.FederationRMQueueAclInfo;
-import org.apache.hadoop.yarn.server.router.webapp.dao.SubClusterResult;
-import org.apache.hadoop.yarn.server.router.webapp.dao.FederationSchedulerTypeInfo;
-import org.apache.hadoop.yarn.server.router.webapp.dao.FederationConfInfo;
-import org.apache.hadoop.yarn.server.router.webapp.dao.FederationClusterUserInfo;
-import org.apache.hadoop.yarn.server.router.webapp.dao.FederationClusterInfo;
-import org.apache.hadoop.yarn.server.utils.BuilderUtils;
-import org.apache.hadoop.yarn.server.webapp.dao.AppAttemptInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainerInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainersInfo;
-import org.apache.hadoop.yarn.util.LRUCacheHashMap;
-import org.apache.hadoop.yarn.webapp.dao.ConfInfo;
-import org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo;
-import org.apache.hadoop.yarn.util.Clock;
-import org.apache.hadoop.yarn.util.MonotonicClock;
-import org.apache.hadoop.yarn.webapp.NotFoundException;
-import org.apache.hadoop.yarn.webapp.util.WebAppUtils;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import org.apache.hadoop.classification.VisibleForTesting;
-import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ThreadFactoryBuilder;
-
-import static org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade.getRandomActiveSubCluster;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_NEW_APP;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.SUBMIT_NEW_APP;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_CLUSTERINFO;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_CLUSTERUSERINFO;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_SCHEDULERINFO;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.DUMP_SCHEDULERLOGS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_ACTIVITIES;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_BULKACTIVITIES;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_APPACTIVITIES;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_APPSTATISTICS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_NODETOLABELS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_RMNODELABELS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_LABELSTONODES;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.UNKNOWN;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.TARGET_WEB_SERVICE;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.REPLACE_LABELSONNODES;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.REPLACE_LABELSONNODE;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_CLUSTER_NODELABELS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.ADD_TO_CLUSTER_NODELABELS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.REMOVE_FROM_CLUSTERNODELABELS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_LABELS_ON_NODE;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_APP_PRIORITY;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_QUEUEINFO;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.UPDATE_APPLICATIONPRIORITY;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.UPDATE_APP_QUEUE;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.POST_DELEGATION_TOKEN;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.POST_DELEGATION_TOKEN_EXPIRATION;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.CANCEL_DELEGATIONTOKEN;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_NEW_RESERVATION;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.SUBMIT_RESERVATION;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.UPDATE_RESERVATION;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.DELETE_RESERVATION;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.LIST_RESERVATIONS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_APP_TIMEOUT;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_APP_TIMEOUTS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.UPDATE_APPLICATIONTIMEOUTS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_APPLICATION_ATTEMPTS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.CHECK_USER_ACCESS_TO_QUEUE;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_APP_ATTEMPT;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_CONTAINERS;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_CONTAINER;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.UPDATE_SCHEDULER_CONFIGURATION;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.GET_SCHEDULER_CONFIGURATION;
-import static org.apache.hadoop.yarn.server.router.RouterAuditLogger.AuditConstants.SIGNAL_TOCONTAINER;
-import static org.apache.hadoop.yarn.server.router.webapp.RouterWebServiceUtil.extractToken;
-import static org.apache.hadoop.yarn.server.router.webapp.RouterWebServiceUtil.getKerberosUserGroupInformation;
-
-/**
- * Extends the {@code AbstractRESTRequestInterceptor} class and provides an
- * implementation for federation of YARN RM and scaling an application across
- * multiple YARN SubClusters. All the federation specific implementation is
- * encapsulated in this class. This is always the last interceptor in the chain.
- */
-public class FederationInterceptorREST extends AbstractRESTRequestInterceptor {
-
-  private static final Logger LOG = LoggerFactory.getLogger(FederationInterceptorREST.class);
-
-  private int numSubmitRetries;
-  private FederationStateStoreFacade federationFacade;
-  private RouterPolicyFacade policyFacade;
-  private RouterMetrics routerMetrics;
-  private final Clock clock = new MonotonicClock();
-  private boolean returnPartialReport;
-  private boolean appInfosCacheEnabled;
-  private int appInfosCacheCount;
-  private boolean allowPartialResult;
-  private long submitIntervalTime;
-
-  private Map<SubClusterId, DefaultRequestInterceptorREST> interceptors;
-  private LRUCacheHashMap<RouterAppInfoCacheKey, AppsInfo> appInfosCaches;
-
-  /**
-   * Thread pool used for asynchronous operations.
-   */
-  private ExecutorService threadpool;
-
-  @Override
-  public void init(String user) {
-
-    super.init(user);
-
-    federationFacade = FederationStateStoreFacade.getInstance(getConf());
-
-    final Configuration conf = this.getConf();
-
-    try {
-      SubClusterResolver subClusterResolver =
-          this.federationFacade.getSubClusterResolver();
-      policyFacade = new RouterPolicyFacade(
-          conf, federationFacade, subClusterResolver, null);
-    } catch (FederationPolicyInitializationException e) {
-      throw new YarnRuntimeException(e);
-    }
-
-    numSubmitRetries = conf.getInt(
-        YarnConfiguration.ROUTER_CLIENTRM_SUBMIT_RETRY,
-        YarnConfiguration.DEFAULT_ROUTER_CLIENTRM_SUBMIT_RETRY);
-
-    interceptors = new HashMap<>();
-    routerMetrics = RouterMetrics.getMetrics();
-    threadpool = HadoopExecutors.newCachedThreadPool(new ThreadFactoryBuilder()
-        .setNameFormat("FederationInterceptorREST #%d")
-        .build());
-
-    returnPartialReport = conf.getBoolean(
-        YarnConfiguration.ROUTER_WEBAPP_PARTIAL_RESULTS_ENABLED,
-        YarnConfiguration.DEFAULT_ROUTER_WEBAPP_PARTIAL_RESULTS_ENABLED);
-
-    appInfosCacheEnabled = conf.getBoolean(
-        YarnConfiguration.ROUTER_APPSINFO_ENABLED,
-        YarnConfiguration.DEFAULT_ROUTER_APPSINFO_ENABLED);
-
-    if(appInfosCacheEnabled) {
-      appInfosCacheCount = conf.getInt(
-          YarnConfiguration.ROUTER_APPSINFO_CACHED_COUNT,
-          YarnConfiguration.DEFAULT_ROUTER_APPSINFO_CACHED_COUNT);
-      appInfosCaches = new LRUCacheHashMap<>(appInfosCacheCount, true);
-    }
-
-    allowPartialResult = conf.getBoolean(
-        YarnConfiguration.ROUTER_INTERCEPTOR_ALLOW_PARTIAL_RESULT_ENABLED,
-        YarnConfiguration.DEFAULT_ROUTER_INTERCEPTOR_ALLOW_PARTIAL_RESULT_ENABLED);
-
-    submitIntervalTime = conf.getTimeDuration(
-        YarnConfiguration.ROUTER_CLIENTRM_SUBMIT_INTERVAL_TIME,
-        YarnConfiguration.DEFAULT_CLIENTRM_SUBMIT_INTERVAL_TIME, TimeUnit.MILLISECONDS);
-  }
-
-  @VisibleForTesting
-  protected DefaultRequestInterceptorREST getInterceptorForSubCluster(SubClusterId subClusterId) {
-    if (interceptors.containsKey(subClusterId)) {
-      return interceptors.get(subClusterId);
-    } else {
-      LOG.error("The interceptor for SubCluster {} does not exist in the cache.",
-          subClusterId);
-      return null;
-    }
-  }
-
-  private DefaultRequestInterceptorREST createInterceptorForSubCluster(
-      SubClusterId subClusterId, String webAppAddress) {
-
-    final Configuration conf = this.getConf();
-
-    String interceptorClassName = conf.get(
-        YarnConfiguration.ROUTER_WEBAPP_DEFAULT_INTERCEPTOR_CLASS,
-        YarnConfiguration.DEFAULT_ROUTER_WEBAPP_DEFAULT_INTERCEPTOR_CLASS);
-
-    DefaultRequestInterceptorREST interceptorInstance;
-    try {
-      Class<?> interceptorClass = conf.getClassByName(interceptorClassName);
-      if (DefaultRequestInterceptorREST.class.isAssignableFrom(interceptorClass)) {
-        interceptorInstance =
-            (DefaultRequestInterceptorREST) ReflectionUtils.newInstance(interceptorClass, conf);
-        String userName = getUser().getUserName();
-        interceptorInstance.init(userName);
-      } else {
-        throw new YarnRuntimeException("Class: " + interceptorClassName + " not instance of "
-            + DefaultRequestInterceptorREST.class.getCanonicalName());
-      }
-    } catch (ClassNotFoundException e) {
-      throw new YarnRuntimeException("Could not instantiate ApplicationMasterRequestInterceptor: " +
-          interceptorClassName, e);
-    }
-
-    String webAppAddressWithScheme = WebAppUtils.getHttpSchemePrefix(conf) + webAppAddress;
-    interceptorInstance.setWebAppAddress(webAppAddressWithScheme);
-    interceptorInstance.setSubClusterId(subClusterId);
-    interceptors.put(subClusterId, interceptorInstance);
-    return interceptorInstance;
-  }
-
-  protected DefaultRequestInterceptorREST getOrCreateInterceptorForSubCluster(
-      SubClusterInfo subClusterInfo) {
-    if (subClusterInfo != null) {
-      final SubClusterId subClusterId = subClusterInfo.getSubClusterId();
-      final String webServiceAddress = subClusterInfo.getRMWebServiceAddress();
-      return getOrCreateInterceptorForSubCluster(subClusterId, webServiceAddress);
-    }
-    return null;
-  }
-
-  protected DefaultRequestInterceptorREST getOrCreateInterceptorByAppId(String appId)
-      throws YarnException {
-    // We first check the applicationId
-    RouterServerUtil.validateApplicationId(appId);
-
-    // Get homeSubCluster By appId
-    SubClusterInfo subClusterInfo = getHomeSubClusterInfoByAppId(appId);
-    LOG.info("appId = {} : subClusterInfo = {}.", appId, subClusterInfo.getSubClusterId());
-    return getOrCreateInterceptorForSubCluster(subClusterInfo);
-  }
-
-  protected DefaultRequestInterceptorREST getOrCreateInterceptorByNodeId(String nodeId) {
-    SubClusterInfo subClusterInfo = getNodeSubcluster(nodeId);
-    return getOrCreateInterceptorForSubCluster(subClusterInfo);
-  }
-
-  @VisibleForTesting
-  protected DefaultRequestInterceptorREST getOrCreateInterceptorForSubCluster(
-      SubClusterId subClusterId, String webAppAddress) {
-    DefaultRequestInterceptorREST interceptor = getInterceptorForSubCluster(subClusterId);
-    String webAppAddressWithScheme =
-        WebAppUtils.getHttpSchemePrefix(this.getConf()) + webAppAddress;
-    if (interceptor == null || !webAppAddressWithScheme.equals(interceptor.getWebAppAddress())) {
-      interceptor = createInterceptorForSubCluster(subClusterId, webAppAddress);
-    }
-    return interceptor;
-  }
-
-  /**
-   * YARN Router forwards every getNewApplication requests to any RM. During
-   * this operation there will be no communication with the State Store. The
-   * Router will forward the requests to any SubCluster. The Router will retry
-   * to submit the request on #numSubmitRetries different SubClusters. The
-   * SubClusters are randomly chosen from the active ones.
-   * <p>
-   * Possible failures and behaviors:
-   * <p>
-   * Client: identical behavior as {@code RMWebServices}.
-   * <p>
-   * Router: the Client will timeout and resubmit.
-   * <p>
-   * ResourceManager: the Router will timeout and contacts another RM.
-   * <p>
-   * StateStore: not in the execution.
-   */
-  @Override
-  public Response createNewApplication(HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-
-    long startTime = clock.getTime();
-
-    try {
-      Map<SubClusterId, SubClusterInfo> subClustersActive =
-          federationFacade.getSubClusters(true);
-
-      // We declare blackList and retries.
-      List<SubClusterId> blackList = new ArrayList<>();
-      int actualRetryNums = federationFacade.getRetryNumbers(numSubmitRetries);
-      Response response = ((FederationActionRetry<Response>) (retryCount) ->
-          invokeGetNewApplication(subClustersActive, blackList, hsr, retryCount)).
-          runWithRetries(actualRetryNums, submitIntervalTime);
-
-      // If the response is not empty and the status is SC_OK,
-      // this request can be returned directly.
-      if (response != null && response.getStatus() == HttpServletResponse.SC_OK) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededAppsCreated(stopTime - startTime);
-        return response;
-      }
-    } catch (FederationPolicyException e) {
-      // If a FederationPolicyException is thrown, the service is unavailable.
-      routerMetrics.incrAppsFailedCreated();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_NEW_APP, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      return Response.status(Status.SERVICE_UNAVAILABLE).entity(e.getLocalizedMessage()).build();
-    } catch (Exception e) {
-      routerMetrics.incrAppsFailedCreated();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_NEW_APP, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      return Response.status(Status.INTERNAL_SERVER_ERROR).entity(e.getLocalizedMessage()).build();
-    }
-
-    // return error message directly.
-    String errMsg = "Fail to create a new application.";
-    LOG.error(errMsg);
-    routerMetrics.incrAppsFailedCreated();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_NEW_APP, UNKNOWN,
-        TARGET_WEB_SERVICE, errMsg);
-    return Response.status(Status.INTERNAL_SERVER_ERROR).entity(errMsg).build();
-  }
-
-  /**
-   * Invoke GetNewApplication to different subClusters.
-   *
-   * @param subClustersActive Active SubClusters.
-   * @param blackList Blacklist avoid repeated calls to unavailable subCluster.
-   * @param hsr HttpServletRequest.
-   * @param retryCount number of retries.
-   * @return Get response, If the response is empty or status not equal SC_OK, the request fails,
-   * if the response is not empty and status equal SC_OK, the request is successful.
-   * @throws YarnException yarn exception.
-   * @throws IOException io error.
-   * @throws InterruptedException interrupted exception.
-   */
-  private Response invokeGetNewApplication(Map<SubClusterId, SubClusterInfo> subClustersActive,
-      List<SubClusterId> blackList, HttpServletRequest hsr, int retryCount)
-      throws YarnException, IOException, InterruptedException {
-
-    SubClusterId subClusterId = getRandomActiveSubCluster(subClustersActive, blackList);
-
-    LOG.info("getNewApplication try #{} on SubCluster {}.", retryCount, subClusterId);
-
-    DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorForSubCluster(subClusterId,
-        subClustersActive.get(subClusterId).getRMWebServiceAddress());
-
-    try {
-      Response response = interceptor.createNewApplication(hsr);
-      if (response != null && response.getStatus() == HttpServletResponse.SC_OK) {
-        ApplicationId applicationId = ApplicationId.fromString(response.getEntity().toString());
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_NEW_APP,
-            TARGET_WEB_SERVICE, applicationId, subClusterId);
-        return response;
-      }
-    } catch (Exception e) {
-      blackList.add(subClusterId);
-      RouterServerUtil.logAndThrowException(e.getMessage(), e);
-    }
-
-    // We need to throw the exception directly.
-    String msg = String.format("Unable to create a new ApplicationId in SubCluster %s.",
-        subClusterId.getId());
-    throw new YarnException(msg);
-  }
-
-  /**
-   * Today, in YARN there are no checks of any applicationId submitted.
-   * <p>
-   * Base scenarios:
-   * <p>
-   * The Client submits an application to the Router. The Router selects one
-   * SubCluster to forward the request. The Router inserts a tuple into
-   * StateStore with the selected SubCluster (e.g. SC1) and the appId. The
-   * State Store replies with the selected SubCluster (e.g. SC1). The Router
-   * submits the request to the selected SubCluster.
-   * <p>
-   * In case of State Store failure:
-   * <p>
-   * The client submits an application to the Router. The Router selects one
-   * SubCluster to forward the request. The Router inserts a tuple into State
-   * Store with the selected SubCluster (e.g. SC1) and the appId. Due to the
-   * State Store down the Router times out and it will retry depending on the
-   * FederationFacade settings. The Router replies to the client with an error
-   * message.
-   * <p>
-   * If State Store fails after inserting the tuple: identical behavior as
-   * {@code RMWebServices}.
-   * <p>
-   * In case of Router failure:
-   * <p>
-   * Scenario 1  Crash before submission to the ResourceManager
-   * <p>
-   * The Client submits an application to the Router. The Router selects one
-   * SubCluster to forward the request. The Router inserts a tuple into State
-   * Store with the selected SubCluster (e.g. SC1) and the appId. The Router
-   * crashes. The Client timeouts and resubmits the application. The Router
-   * selects one SubCluster to forward the request. The Router inserts a tuple
-   * into State Store with the selected SubCluster (e.g. SC2) and the appId.
-   * Because the tuple is already inserted in the State Store, it returns the
-   * previous selected SubCluster (e.g. SC1). The Router submits the request
-   * to the selected SubCluster (e.g. SC1).
-   * <p>
-   * Scenario 2  Crash after submission to the ResourceManager
-   * <p>
-   * The Client submits an application to the Router. The Router selects one
-   * SubCluster to forward the request. The Router inserts a tuple into State
-   * Store with the selected SubCluster (e.g. SC1) and the appId. The Router
-   * submits the request to the selected SubCluster. The Router crashes. The
-   * Client timeouts and resubmit the application. The Router selects one
-   * SubCluster to forward the request. The Router inserts a tuple into State
-   * Store with the selected SubCluster (e.g. SC2) and the appId. The State
-   * Store replies with the selected SubCluster (e.g. SC1). The Router submits
-   * the request to the selected SubCluster (e.g. SC1). When a client re-submits
-   * the same application to the same RM, it does not raise an exception and
-   * replies with operation successful message.
-   * <p>
-   * In case of Client failure: identical behavior as {@code RMWebServices}.
-   * <p>
-   * In case of ResourceManager failure:
-   * <p>
-   * The Client submits an application to the Router. The Router selects one
-   * SubCluster to forward the request. The Router inserts a tuple into State
-   * Store with the selected SubCluster (e.g. SC1) and the appId. The Router
-   * submits the request to the selected SubCluster. The entire SubCluster is
-   * down  all the RMs in HA or the master RM is not reachable. The Router
-   * times out. The Router selects a new SubCluster to forward the request.
-   * The Router update a tuple into State Store with the selected SubCluster
-   * (e.g. SC2) and the appId. The State Store replies with OK answer. The
-   * Router submits the request to the selected SubCluster (e.g. SC2).
-   */
-  @Override
-  public Response submitApplication(ApplicationSubmissionContextInfo newApp, HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-
-    long startTime = clock.getTime();
-
-    // We verify the parameters to ensure that newApp is not empty and
-    // that the format of applicationId is correct.
-    if (newApp == null || newApp.getApplicationId() == null) {
-      routerMetrics.incrAppsFailedSubmitted();
-      String errMsg = "Missing ApplicationSubmissionContextInfo or "
-          + "applicationSubmissionContext information.";
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), SUBMIT_NEW_APP, UNKNOWN,
-          TARGET_WEB_SERVICE, errMsg);
-      return Response.status(Status.BAD_REQUEST).entity(errMsg).build();
-    }
-
-    try {
-      String applicationId = newApp.getApplicationId();
-      RouterServerUtil.validateApplicationId(applicationId);
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrAppsFailedSubmitted();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), SUBMIT_NEW_APP, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getMessage());
-      return Response.status(Status.BAD_REQUEST).entity(e.getLocalizedMessage()).build();
-    }
-
-    List<SubClusterId> blackList = new ArrayList<>();
-    try {
-      int activeSubClustersCount = federationFacade.getActiveSubClustersCount();
-      int actualRetryNums = Math.min(activeSubClustersCount, numSubmitRetries);
-      Response response = ((FederationActionRetry<Response>) (retryCount) ->
-          invokeSubmitApplication(newApp, blackList, hsr, retryCount)).
-          runWithRetries(actualRetryNums, submitIntervalTime);
-      if (response != null) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededAppsSubmitted(stopTime - startTime);
-        return response;
-      }
-    } catch (Exception e) {
-      routerMetrics.incrAppsFailedSubmitted();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), SUBMIT_NEW_APP, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getMessage());
-      return Response.status(Status.SERVICE_UNAVAILABLE).entity(e.getLocalizedMessage()).build();
-    }
-
-    routerMetrics.incrAppsFailedSubmitted();
-    String errMsg = String.format("Application %s with appId %s failed to be submitted.",
-        newApp.getApplicationName(), newApp.getApplicationId());
-    LOG.error(errMsg);
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), SUBMIT_NEW_APP, UNKNOWN,
-        TARGET_WEB_SERVICE, errMsg);
-    return Response.status(Status.SERVICE_UNAVAILABLE).entity(errMsg).build();
-  }
-
-  /**
-   * Invoke SubmitApplication to different subClusters.
-   *
-   * @param submissionContext application submission context.
-   * @param blackList Blacklist avoid repeated calls to unavailable subCluster.
-   * @param hsr HttpServletRequest.
-   * @param retryCount number of retries.
-   * @return Get response, If the response is empty or status not equal SC_ACCEPTED,
-   * the request fails, if the response is not empty and status equal SC_OK,
-   * the request is successful.
-   * @throws YarnException yarn exception.
-   * @throws IOException io error.
-   */
-  private Response invokeSubmitApplication(ApplicationSubmissionContextInfo submissionContext,
-      List<SubClusterId> blackList, HttpServletRequest hsr, int retryCount)
-      throws YarnException, IOException, InterruptedException {
-
-    // Step1. We convert ApplicationSubmissionContextInfo to ApplicationSubmissionContext
-    // and Prepare parameters.
-    ApplicationSubmissionContext context =
-        RMWebAppUtil.createAppSubmissionContext(submissionContext, this.getConf());
-    ApplicationId applicationId = ApplicationId.fromString(submissionContext.getApplicationId());
-    SubClusterId subClusterId = null;
-
-    try {
-      // Get subClusterId from policy.
-      subClusterId = policyFacade.getHomeSubcluster(context, blackList);
-
-      // Print the log of submitting the submitApplication.
-      LOG.info("submitApplication appId {} try #{} on SubCluster {}.",
-          applicationId, retryCount, subClusterId);
-
-      // Step2. We Store the mapping relationship
-      // between Application and HomeSubCluster in stateStore.
-      ApplicationSubmissionContext trimmedAppSubmissionContext =
-          RouterServerUtil.getTrimmedAppSubmissionContext(context);
-      federationFacade.addOrUpdateApplicationHomeSubCluster(
-          applicationId, subClusterId, retryCount, trimmedAppSubmissionContext);
-
-      // Step3. We get subClusterInfo based on subClusterId.
-      SubClusterInfo subClusterInfo = federationFacade.getSubCluster(subClusterId);
-      if (subClusterInfo == null) {
-        throw new YarnException("Can't Find SubClusterId = " + subClusterId);
-      }
-
-      // Step4. Submit the request, if the response is HttpServletResponse.SC_ACCEPTED,
-      // We return the response, otherwise we throw an exception.
-      Response response = getOrCreateInterceptorForSubCluster(subClusterId,
-          subClusterInfo.getRMWebServiceAddress()).submitApplication(submissionContext, hsr);
-      if (response != null && response.getStatus() == HttpServletResponse.SC_ACCEPTED) {
-        LOG.info("Application {} with appId {} submitted on {}.",
-            context.getApplicationName(), applicationId, subClusterId);
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), SUBMIT_NEW_APP,
-            TARGET_WEB_SERVICE, applicationId, subClusterId);
-        return response;
-      }
-      String msg = String.format("application %s failed to be submitted.", applicationId);
-      throw new YarnException(msg);
-    } catch (Exception e) {
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), SUBMIT_NEW_APP, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getMessage(), applicationId, subClusterId);
-      LOG.warn("Unable to submit the application {} to SubCluster {}.", applicationId,
-          subClusterId, e);
-      if (subClusterId != null) {
-        blackList.add(subClusterId);
-      }
-      throw e;
-    }
-  }
-
-  /**
-   * The YARN Router will forward to the respective YARN RM in which the AM is
-   * running.
-   * <p>
-   * Possible failure:
-   * <p>
-   * Client: identical behavior as {@code RMWebServices}.
-   * <p>
-   * Router: the Client will timeout and resubmit the request.
-   * <p>
-   * ResourceManager: the Router will timeout and the call will fail.
-   * <p>
-   * State Store: the Router will timeout and it will retry depending on the
-   * FederationFacade settings - if the failure happened before the select
-   * operation.
-   */
-  @Override
-  public AppInfo getApp(HttpServletRequest hsr, String appId, Set<String> unselectedFields) {
-
-    try {
-      long startTime = clock.getTime();
-
-      // Get SubClusterInfo according to applicationId
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorByAppId(appId);
-      if (interceptor == null) {
-        routerMetrics.incrAppsFailedRetrieved();
-        return null;
-      }
-      AppInfo response = interceptor.getApp(hsr, appId, unselectedFields);
-      long stopTime = clock.getTime();
-      routerMetrics.succeededAppsRetrieved(stopTime - startTime);
-      return response;
-    } catch (YarnException e) {
-      routerMetrics.incrAppsFailedRetrieved();
-      LOG.error("getApp Error, applicationId = {}.", appId, e);
-      return null;
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrAppsFailedRetrieved();
-      throw e;
-    }
-  }
-
-  /**
-   * The YARN Router will forward to the respective YARN RM in which the AM is
-   * running.
-   * <p>
-   * Possible failures and behaviors:
-   * <p>
-   * Client: identical behavior as {@code RMWebServices}.
-   * <p>
-   * Router: the Client will timeout and resubmit the request.
-   * <p>
-   * ResourceManager: the Router will timeout and the call will fail.
-   * <p>
-   * State Store: the Router will timeout and it will retry depending on the
-   * FederationFacade settings - if the failure happened before the select
-   * operation.
-   */
-  @Override
-  public Response updateAppState(AppState targetState, HttpServletRequest hsr, String appId)
-      throws AuthorizationException, YarnException, InterruptedException, IOException {
-
-    long startTime = clock.getTime();
-
-    ApplicationId applicationId;
-    try {
-      applicationId = ApplicationId.fromString(appId);
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrAppsFailedKilled();
-      return Response
-          .status(Status.BAD_REQUEST)
-          .entity(e.getLocalizedMessage())
-          .build();
-    }
-
-    SubClusterInfo subClusterInfo;
-    SubClusterId subClusterId;
-    try {
-      subClusterId =
-          federationFacade.getApplicationHomeSubCluster(applicationId);
-      subClusterInfo = federationFacade.getSubCluster(subClusterId);
-    } catch (YarnException e) {
-      routerMetrics.incrAppsFailedKilled();
-      return Response
-          .status(Status.BAD_REQUEST)
-          .entity(e.getLocalizedMessage())
-          .build();
-    }
-
-    Response response = getOrCreateInterceptorForSubCluster(subClusterId,
-        subClusterInfo.getRMWebServiceAddress()).updateAppState(targetState,
-            hsr, appId);
-
-    long stopTime = clock.getTime();
-    routerMetrics.succeededAppsRetrieved(stopTime - startTime);
-
-    return response;
-  }
-
-  /**
-   * The YARN Router will forward the request to all the YARN RMs in parallel,
-   * after that it will group all the ApplicationReports by the ApplicationId.
-   * <p>
-   * Possible failure:
-   * <p>
-   * Client: identical behavior as {@code RMWebServices}.
-   * <p>
-   * Router: the Client will timeout and resubmit the request.
-   * <p>
-   * ResourceManager: the Router calls each YARN RM in parallel by using one
-   * thread for each YARN RM. In case a YARN RM fails, a single call will
-   * timeout. However, the Router will merge the ApplicationReports it got, and
-   * provides a partial list to the client.
-   * <p>
-   * State Store: the Router will timeout and it will retry depending on the
-   * FederationFacade settings - if the failure happened before the select
-   * operation.
-   */
-  @Override
-  public AppsInfo getApps(HttpServletRequest hsr, String stateQuery,
-      Set<String> statesQuery, String finalStatusQuery, String userQuery,
-      String queueQuery, String count, String startedBegin, String startedEnd,
-      String finishBegin, String finishEnd, Set<String> applicationTypes,
-      Set<String> applicationTags, String name, Set<String> unselectedFields) {
-
-    RouterAppInfoCacheKey routerAppInfoCacheKey = RouterAppInfoCacheKey.newInstance(
-        hsr, stateQuery, statesQuery, finalStatusQuery, userQuery, queueQuery, count,
-        startedBegin, startedEnd, finishBegin, finishEnd, applicationTypes,
-        applicationTags, name, unselectedFields);
-
-    if (appInfosCacheEnabled && routerAppInfoCacheKey != null) {
-      if (appInfosCaches.containsKey(routerAppInfoCacheKey)) {
-        return appInfosCaches.get(routerAppInfoCacheKey);
-      }
-    }
-
-    AppsInfo apps = new AppsInfo();
-    long startTime = clock.getTime();
-
-    // HttpServletRequest does not work with ExecutorCompletionService.
-    // Create a duplicate hsr.
-    final HttpServletRequest hsrCopy = clone(hsr);
-    Collection<SubClusterInfo> subClusterInfos = federationFacade.getActiveSubClusters();
-
-    List<AppsInfo> appsInfos = subClusterInfos.parallelStream().map(subCluster -> {
-      try {
-        DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorForSubCluster(subCluster);
-        AppsInfo rmApps = interceptor.getApps(hsrCopy, stateQuery, statesQuery, finalStatusQuery,
-            userQuery, queueQuery, count, startedBegin, startedEnd, finishBegin, finishEnd,
-            applicationTypes, applicationTags, name, unselectedFields);
-        if (rmApps != null) {
-          return rmApps;
-        }
-      } catch (Exception e) {
-        LOG.warn("Failed to get application report.", e);
-      }
-      routerMetrics.incrMultipleAppsFailedRetrieved();
-      LOG.error("Subcluster {} failed to return appReport.", subCluster.getSubClusterId());
-      return null;
-    }).collect(Collectors.toList());
-
-    appsInfos.forEach(appsInfo -> {
-      if (appsInfo != null) {
-        apps.addAll(appsInfo.getApps());
-        long stopTime = clock.getTime();
-        routerMetrics.succeededMultipleAppsRetrieved(stopTime - startTime);
-      }
-    });
-
-    if (apps.getApps().isEmpty()) {
-      return new AppsInfo();
-    }
-
-    // Merge all the application reports got from all the available YARN RMs
-    AppsInfo resultAppsInfo = RouterWebServiceUtil.mergeAppsInfo(
-        apps.getApps(), returnPartialReport);
-
-    if (appInfosCacheEnabled && routerAppInfoCacheKey != null) {
-      appInfosCaches.put(routerAppInfoCacheKey, resultAppsInfo);
-    }
-
-    return resultAppsInfo;
-  }
-
-  /**
-   * Get a copy of a HTTP request. This is for thread safety.
-   * @param hsr HTTP servlet request to copy.
-   * @return Copy of the HTTP request.
-   */
-  private HttpServletRequestWrapper clone(final HttpServletRequest hsr) {
-    if (hsr == null) {
-      return null;
-    }
-
-    final Map<String, String[]> parameterMap = hsr.getParameterMap();
-    final String pathInfo = hsr.getPathInfo();
-    final String user = hsr.getRemoteUser();
-    final Principal principal = hsr.getUserPrincipal();
-    final String mediaType = RouterWebServiceUtil.getMediaTypeFromHttpServletRequest(
-        hsr, AppsInfo.class);
-    return new HttpServletRequestWrapper(hsr) {
-        public Map<String, String[]> getParameterMap() {
-          return parameterMap;
-        }
-        public String getPathInfo() {
-          return pathInfo;
-        }
-        public String getRemoteUser() {
-          return user;
-        }
-        public Principal getUserPrincipal() {
-          return principal;
-        }
-        public String getHeader(String value) {
-          // we override only Accept
-          if (value.equals(HttpHeaders.ACCEPT)) {
-            return mediaType;
-          }
-          return null;
-        }
-      };
-  }
-
-  /**
-   * Get the active subcluster in the federation.
-   *
-   * @param subClusterId subClusterId.
-   * @return subClusterInfo.
-   * @throws NotFoundException If the subclusters cannot be found.
-   */
-  private SubClusterInfo getActiveSubCluster(String subClusterId)
-      throws NotFoundException {
-    try {
-      SubClusterId pSubClusterId = SubClusterId.newInstance(subClusterId);
-      return federationFacade.getSubCluster(pSubClusterId);
-    } catch (YarnException e) {
-      throw new NotFoundException(e.getMessage());
-    }
-  }
-
-  /**
-   * The YARN Router will forward to the request to all the SubClusters to find
-   * where the node is running.
-   * <p>
-   * Possible failure:
-   * <p>
-   * Client: identical behavior as {@code RMWebServices}.
-   * <p>
-   * Router: the Client will timeout and resubmit the request.
-   * <p>
-   * ResourceManager: the Router will timeout and the call will fail.
-   * <p>
-   * State Store: the Router will timeout and it will retry depending on the
-   * FederationFacade settings - if the failure happened before the select
-   * operation.
-   */
-  @Override
-  public NodeInfo getNode(String nodeId) {
-
-    final Collection<SubClusterInfo> subClustersActive = federationFacade.getActiveSubClusters();
-
-    if (subClustersActive.isEmpty()) {
-      throw new NotFoundException(FederationPolicyUtils.NO_ACTIVE_SUBCLUSTER_AVAILABLE);
-    }
-
-    final Map<SubClusterInfo, NodeInfo> results = getNode(subClustersActive, nodeId);
-
-    // Collect the responses
-    NodeInfo nodeInfo = null;
-    for (NodeInfo nodeResponse : results.values()) {
-      try {
-        // Check if the node was already found in a different SubCluster and
-        // it has an old health report
-        if (nodeInfo == null || nodeInfo.getLastHealthUpdate() <
-            nodeResponse.getLastHealthUpdate()) {
-          nodeInfo = nodeResponse;
-        }
-      } catch (Throwable e) {
-        LOG.warn("Failed to get node report ", e);
-      }
-    }
-
-    if (nodeInfo == null) {
-      throw new NotFoundException("nodeId, " + nodeId + ", is not found");
-    }
-    return nodeInfo;
-  }
-
-  /**
-   * Get a node and the subcluster where it is.
-   *
-   * @param subClusters Subclusters where to search.
-   * @param nodeId      Identifier of the node we are looking for.
-   * @return Map between subcluster and node.
-   */
-  private Map<SubClusterInfo, NodeInfo> getNode(Collection<SubClusterInfo> subClusters,
-      String nodeId) {
-
-    // Parallel traversal of subClusters
-    Stream<Pair<SubClusterInfo, NodeInfo>> pairStream = subClusters.parallelStream().map(
-        subClusterInfo -> {
-            final SubClusterId subClusterId = subClusterInfo.getSubClusterId();
-            try {
-              DefaultRequestInterceptorREST interceptor =
-                   getOrCreateInterceptorForSubCluster(subClusterInfo);
-              return Pair.of(subClusterInfo, interceptor.getNode(nodeId));
-            } catch (Exception e) {
-              LOG.error("Subcluster {} failed to return nodeInfo.", subClusterId, e);
-              return null;
-            }
-        });
-
-    // Collect the results
-    final Map<SubClusterInfo, NodeInfo> results = new HashMap<>();
-    pairStream.forEach(pair -> {
-      if (pair != null) {
-        SubClusterInfo subCluster = pair.getKey();
-        NodeInfo nodeInfo = pair.getValue();
-        results.put(subCluster, nodeInfo);
-      }
-    });
-
-    return results;
-  }
-
-  /**
-   * Get the subcluster a node belongs to.
-   *
-   * @param nodeId Identifier of the node we are looking for.
-   * @return The subcluster containing the node.
-   * @throws NotFoundException If the node cannot be found.
-   */
-  private SubClusterInfo getNodeSubcluster(String nodeId) throws NotFoundException {
-
-    final Collection<SubClusterInfo> subClusters = federationFacade.getActiveSubClusters();
-    final Map<SubClusterInfo, NodeInfo> results = getNode(subClusters, nodeId);
-
-    SubClusterInfo subcluster = null;
-    NodeInfo nodeInfo = null;
-    for (Entry<SubClusterInfo, NodeInfo> entry : results.entrySet()) {
-      NodeInfo nodeResponse = entry.getValue();
-      if (nodeInfo == null || nodeInfo.getLastHealthUpdate() <
-          nodeResponse.getLastHealthUpdate()) {
-        subcluster = entry.getKey();
-        nodeInfo = nodeResponse;
-      }
-    }
-    if (subcluster == null) {
-      throw new NotFoundException("Cannot find " + nodeId + " in any subcluster");
-    }
-    return subcluster;
-  }
-
-  /**
-   * The YARN Router will forward the request to all the YARN RMs in parallel,
-   * after that it will remove all the duplicated NodeInfo by using the NodeId.
-   * <p>
-   * Possible failure:
-   * <p>
-   * Client: identical behavior as {@code RMWebServices}.
-   * <p>
-   * Router: the Client will timeout and resubmit the request.
-   * <p>
-   * ResourceManager: the Router calls each YARN RM in parallel by using one
-   * thread for each YARN RM. In case a YARN RM fails, a single call will
-   * timeout. However, the Router will use the NodesInfo it got, and provides a
-   * partial list to the client.
-   * <p>
-   * State Store: the Router will timeout and it will retry depending on the
-   * FederationFacade settings - if the failure happened before the select
-   * operation.
-   */
-  @Override
-  public NodesInfo getNodes(String states) {
-
-    NodesInfo nodes = new NodesInfo();
-    try {
-      Collection<SubClusterInfo> subClustersActive = federationFacade.getActiveSubClusters();
-      Class[] argsClasses = new Class[]{String.class};
-      Object[] args = new Object[]{states};
-      ClientMethod remoteMethod = new ClientMethod("getNodes", argsClasses, args);
-      Map<SubClusterInfo, NodesInfo> nodesMap =
-          invokeConcurrent(subClustersActive, remoteMethod, NodesInfo.class);
-      nodesMap.values().forEach(nodesInfo -> nodes.addAll(nodesInfo.getNodes()));
-    } catch (NotFoundException e) {
-      LOG.error("get all active sub cluster(s) error.", e);
-      throw e;
-    } catch (YarnException e) {
-      LOG.error("getNodes by states = {} error.", states, e);
-      throw new YarnRuntimeException(e);
-    } catch (IOException e) {
-      LOG.error("getNodes by states = {} error with io error.", states, e);
-      throw new YarnRuntimeException(e);
-    }
-
-    // Delete duplicate from all the node reports got from all the available
-    // YARN RMs. Nodes can be moved from one subclusters to another. In this
-    // operation they result LOST/RUNNING in the previous SubCluster and
-    // NEW/RUNNING in the new one.
-    return RouterWebServiceUtil.deleteDuplicateNodesInfo(nodes.getNodes());
-  }
-
-  /**
-   * This method changes the resources of a specific node, and it is reachable
-   * by using {@link RMWSConsts#NODE_RESOURCE}.
-   *
-   * @param hsr The servlet request.
-   * @param nodeId The node we want to retrieve the information for.
-   *               It is a PathParam.
-   * @param resourceOption The resource change.
-   * @return the resources of a specific node.
-   */
-  @Override
-  public ResourceInfo updateNodeResource(HttpServletRequest hsr,
-      String nodeId, ResourceOptionInfo resourceOption) {
-    DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorByNodeId(nodeId);
-    return interceptor.updateNodeResource(hsr, nodeId, resourceOption);
-  }
-
-  @Override
-  public ClusterMetricsInfo getClusterMetricsInfo() {
-    ClusterMetricsInfo metrics = new ClusterMetricsInfo();
-
-    Collection<SubClusterInfo> subClusterInfos = federationFacade.getActiveSubClusters();
-
-    Stream<ClusterMetricsInfo> clusterMetricsInfoStream = subClusterInfos.parallelStream()
-        .map(subClusterInfo -> {
-          DefaultRequestInterceptorREST interceptor =
-              getOrCreateInterceptorForSubCluster(subClusterInfo);
-          try {
-            return interceptor.getClusterMetricsInfo();
-          } catch (Exception e) {
-            LOG.error("Subcluster {} failed to return Cluster Metrics.",
-                subClusterInfo.getSubClusterId());
-            return null;
-          }
-        });
-
-    clusterMetricsInfoStream.forEach(clusterMetricsInfo -> {
-      try {
-        if (clusterMetricsInfo != null) {
-          RouterWebServiceUtil.mergeMetrics(metrics, clusterMetricsInfo);
-        }
-      } catch (Throwable e) {
-        LOG.warn("Failed to get nodes report.", e);
-      }
-    });
-
-    return metrics;
-  }
-
-  /**
-   * The YARN Router will forward to the respective YARN RM in which the AM is
-   * running.
-   * <p>
-   * Possible failure:
-   * <p>
-   * Client: identical behavior as {@code RMWebServices}.
-   * <p>
-   * Router: the Client will timeout and resubmit the request.
-   * <p>
-   * ResourceManager: the Router will timeout and the call will fail.
-   * <p>
-   * State Store: the Router will timeout and it will retry depending on the
-   * FederationFacade settings - if the failure happened before the select
-   * operation.
-   */
-  @Override
-  public AppState getAppState(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-    try {
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorByAppId(appId);
-      if (interceptor != null) {
-        return interceptor.getAppState(hsr, appId);
-      }
-    } catch (YarnException | IllegalArgumentException e) {
-      LOG.error("getHomeSubClusterInfoByAppId error, applicationId = {}.", appId, e);
-    }
-    return new AppState();
-  }
-
-  @Override
-  public ClusterInfo get() {
-    return getClusterInfo();
-  }
-
-  /**
-   * This method retrieves the cluster information, and it is reachable by using
-   * {@link RMWSConsts#INFO}.
-   *
-   * In Federation mode, we will return a FederationClusterInfo object,
-   * which contains a set of ClusterInfo.
-   *
-   * @return the cluster information.
-   */
-  @Override
-  public ClusterInfo getClusterInfo() {
-    try {
-      long startTime = Time.now();
-      Collection<SubClusterInfo> subClustersActive = federationFacade.getActiveSubClusters();
-      Class[] argsClasses = new Class[]{};
-      Object[] args = new Object[]{};
-      ClientMethod remoteMethod = new ClientMethod("getClusterInfo", argsClasses, args);
-      Map<SubClusterInfo, ClusterInfo> subClusterInfoMap =
-          invokeConcurrent(subClustersActive, remoteMethod, ClusterInfo.class);
-      FederationClusterInfo federationClusterInfo = new FederationClusterInfo();
-      subClusterInfoMap.forEach((subClusterInfo, clusterInfo) -> {
-        SubClusterId subClusterId = subClusterInfo.getSubClusterId();
-        clusterInfo.setSubClusterId(subClusterId.getId());
-        federationClusterInfo.getList().add(clusterInfo);
-      });
-      long stopTime = Time.now();
-      RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_CLUSTERINFO,
-          TARGET_WEB_SERVICE);
-      routerMetrics.succeededGetClusterInfoRetrieved(stopTime - startTime);
-      return federationClusterInfo;
-    } catch (NotFoundException e) {
-      routerMetrics.incrGetClusterInfoFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_CLUSTERINFO, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("Get all active sub cluster(s) error.", e);
-    } catch (YarnException | IOException e) {
-      routerMetrics.incrGetClusterInfoFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_CLUSTERINFO, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("getClusterInfo error.", e);
-    }
-    routerMetrics.incrGetClusterInfoFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_CLUSTERINFO, UNKNOWN,
-        TARGET_WEB_SERVICE, "getClusterInfo error.");
-    throw new RuntimeException("getClusterInfo error.");
-  }
-
-  /**
-   * This method retrieves the cluster user information, and it is reachable by using
-   * {@link RMWSConsts#CLUSTER_USER_INFO}.
-   *
-   * In Federation mode, we will return a ClusterUserInfo object,
-   * which contains a set of ClusterUserInfo.
-   *
-   * @param hsr the servlet request
-   * @return the cluster user information
-   */
-  @Override
-  public ClusterUserInfo getClusterUserInfo(HttpServletRequest hsr) {
-    try {
-      long startTime = Time.now();
-      Collection<SubClusterInfo> subClustersActive = federationFacade.getActiveSubClusters();
-      final HttpServletRequest hsrCopy = clone(hsr);
-      Class[] argsClasses = new Class[]{HttpServletRequest.class};
-      Object[] args = new Object[]{hsrCopy};
-      ClientMethod remoteMethod = new ClientMethod("getClusterUserInfo", argsClasses, args);
-      Map<SubClusterInfo, ClusterUserInfo> subClusterInfoMap =
-          invokeConcurrent(subClustersActive, remoteMethod, ClusterUserInfo.class);
-      FederationClusterUserInfo federationClusterUserInfo = new FederationClusterUserInfo();
-      subClusterInfoMap.forEach((subClusterInfo, clusterUserInfo) -> {
-        SubClusterId subClusterId = subClusterInfo.getSubClusterId();
-        clusterUserInfo.setSubClusterId(subClusterId.getId());
-        federationClusterUserInfo.getList().add(clusterUserInfo);
-      });
-      long stopTime = Time.now();
-      RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_CLUSTERUSERINFO,
-          TARGET_WEB_SERVICE);
-      routerMetrics.succeededGetClusterUserInfoRetrieved(stopTime - startTime);
-      return federationClusterUserInfo;
-    } catch (NotFoundException e) {
-      routerMetrics.incrGetClusterUserInfoFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_CLUSTERUSERINFO, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("Get all active sub cluster(s) error.", e);
-    } catch (YarnException | IOException e) {
-      routerMetrics.incrGetClusterUserInfoFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_CLUSTERUSERINFO, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("getClusterUserInfo error.", e);
-    }
-    routerMetrics.incrGetClusterUserInfoFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_CLUSTERUSERINFO, UNKNOWN,
-        TARGET_WEB_SERVICE, "getClusterUserInfo error.");
-    throw new RuntimeException("getClusterUserInfo error.");
-  }
-
-  /**
-   * This method retrieves the current scheduler status, and it is reachable by
-   * using {@link RMWSConsts#SCHEDULER}.
-   * For the federation mode, the SchedulerType information of the cluster
-   * cannot be integrated and displayed, and the specific cluster information needs to be marked.
-   *
-   * @return the current scheduler status
-   */
-  @Override
-  public SchedulerTypeInfo getSchedulerInfo() {
-    try {
-      long startTime = Time.now();
-      Collection<SubClusterInfo> subClustersActive = federationFacade.getActiveSubClusters();
-      Class[] argsClasses = new Class[]{};
-      Object[] args = new Object[]{};
-      ClientMethod remoteMethod = new ClientMethod("getSchedulerInfo", argsClasses, args);
-      Map<SubClusterInfo, SchedulerTypeInfo> subClusterInfoMap =
-          invokeConcurrent(subClustersActive, remoteMethod, SchedulerTypeInfo.class);
-      FederationSchedulerTypeInfo federationSchedulerTypeInfo = new FederationSchedulerTypeInfo();
-      subClusterInfoMap.forEach((subClusterInfo, schedulerTypeInfo) -> {
-        SubClusterId subClusterId = subClusterInfo.getSubClusterId();
-        schedulerTypeInfo.setSubClusterId(subClusterId.getId());
-        federationSchedulerTypeInfo.getList().add(schedulerTypeInfo);
-      });
-      long stopTime = Time.now();
-      RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_SCHEDULERINFO,
-          TARGET_WEB_SERVICE);
-      routerMetrics.succeededGetSchedulerInfoRetrieved(stopTime - startTime);
-      return federationSchedulerTypeInfo;
-    } catch (NotFoundException e) {
-      routerMetrics.incrGetSchedulerInfoFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_SCHEDULERINFO, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("Get all active sub cluster(s) error.", e);
-    } catch (YarnException | IOException e) {
-      routerMetrics.incrGetSchedulerInfoFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_SCHEDULERINFO, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("getSchedulerInfo error.", e);
-    }
-    routerMetrics.incrGetSchedulerInfoFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_SCHEDULERINFO, UNKNOWN,
-        TARGET_WEB_SERVICE, "getSchedulerInfo error.");
-    throw new RuntimeException("getSchedulerInfo error.");
-  }
-
-  /**
-   * This method dumps the scheduler logs for the time got in input, and it is
-   * reachable by using {@link RMWSConsts#SCHEDULER_LOGS}.
-   *
-   * @param time the period of time. It is a FormParam.
-   * @param hsr the servlet request
-   * @return the result of the operation
-   * @throws IOException when it cannot create dump log file
-   */
-  @Override
-  public String dumpSchedulerLogs(String time, HttpServletRequest hsr)
-      throws IOException {
-
-    // Step1. We will check the time parameter to
-    // ensure that the time parameter is not empty and greater than 0.
-
-    if (StringUtils.isBlank(time)) {
-      routerMetrics.incrDumpSchedulerLogsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), DUMP_SCHEDULERLOGS, UNKNOWN,
-          TARGET_WEB_SERVICE, "Parameter error, the time is empty or null.");
-      throw new IllegalArgumentException("Parameter error, the time is empty or null.");
-    }
-
-    try {
-      int period = Integer.parseInt(time);
-      if (period <= 0) {
-        throw new IllegalArgumentException("time must be greater than 0.");
-      }
-    } catch (NumberFormatException e) {
-      routerMetrics.incrDumpSchedulerLogsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), DUMP_SCHEDULERLOGS, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      throw new IllegalArgumentException("time must be a number.");
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrDumpSchedulerLogsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), DUMP_SCHEDULERLOGS, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      throw e;
-    }
-
-    // Step2. Call dumpSchedulerLogs of each subcluster.
-    try {
-      long startTime = clock.getTime();
-      Collection<SubClusterInfo> subClustersActive = federationFacade.getActiveSubClusters();
-      final HttpServletRequest hsrCopy = clone(hsr);
-      Class[] argsClasses = new Class[]{String.class, HttpServletRequest.class};
-      Object[] args = new Object[]{time, hsrCopy};
-      ClientMethod remoteMethod = new ClientMethod("dumpSchedulerLogs", argsClasses, args);
-      Map<SubClusterInfo, String> dumpSchedulerLogsMap = invokeConcurrent(
-          subClustersActive, remoteMethod, String.class);
-      StringBuilder stringBuilder = new StringBuilder();
-      dumpSchedulerLogsMap.forEach((subClusterInfo, msg) -> {
-        SubClusterId subClusterId = subClusterInfo.getSubClusterId();
-        stringBuilder.append("subClusterId")
-            .append(subClusterId).append(" : ").append(msg).append("; ");
-      });
-      long stopTime = clock.getTime();
-      RouterAuditLogger.logSuccess(getUser().getShortUserName(), DUMP_SCHEDULERLOGS,
-          TARGET_WEB_SERVICE);
-      routerMetrics.succeededDumpSchedulerLogsRetrieved(stopTime - startTime);
-      return stringBuilder.toString();
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrDumpSchedulerLogsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), DUMP_SCHEDULERLOGS, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e,
-          "Unable to dump SchedulerLogs by time: %s.", time);
-    } catch (YarnException e) {
-      routerMetrics.incrDumpSchedulerLogsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), DUMP_SCHEDULERLOGS, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e,
-          "dumpSchedulerLogs by time = %s error .", time);
-    }
-
-    routerMetrics.incrDumpSchedulerLogsFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), DUMP_SCHEDULERLOGS, UNKNOWN,
-        TARGET_WEB_SERVICE, "dumpSchedulerLogs Failed.");
-    throw new RuntimeException("dumpSchedulerLogs Failed.");
-  }
-
-  /**
-   * This method retrieve all the activities in a specific node, and it is
-   * reachable by using {@link RMWSConsts#SCHEDULER_ACTIVITIES}.
-   *
-   * @param hsr the servlet request
-   * @param nodeId the node we want to retrieve the activities. It is a
-   *          QueryParam.
-   * @param groupBy the groupBy type by which the activities should be
-   *          aggregated. It is a QueryParam.
-   * @return all the activities in the specific node
-   */
-  @Override
-  public ActivitiesInfo getActivities(HttpServletRequest hsr, String nodeId,
-      String groupBy) {
-    try {
-      // Check the parameters to ensure that the parameters are not empty
-      Validate.checkNotNullAndNotEmpty(nodeId, "nodeId");
-      Validate.checkNotNullAndNotEmpty(groupBy, "groupBy");
-
-      // Query SubClusterInfo according to id,
-      // if the nodeId cannot get SubClusterInfo, an exception will be thrown directly.
-      // Call the corresponding subCluster to get ActivitiesInfo.
-      long startTime = clock.getTime();
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorByNodeId(nodeId);
-      final HttpServletRequest hsrCopy = clone(hsr);
-      ActivitiesInfo activitiesInfo = interceptor.getActivities(hsrCopy, nodeId, groupBy);
-      if (activitiesInfo != null) {
-        long stopTime = clock.getTime();
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_ACTIVITIES,
-            TARGET_WEB_SERVICE);
-        routerMetrics.succeededGetActivitiesLatencyRetrieved(stopTime - startTime);
-        return activitiesInfo;
-      }
-    } catch (IllegalArgumentException | NotFoundException e) {
-      routerMetrics.incrGetActivitiesFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_ACTIVITIES, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      throw e;
-    }
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_ACTIVITIES, UNKNOWN,
-        TARGET_WEB_SERVICE, "getActivities Failed.");
-    routerMetrics.incrGetActivitiesFailedRetrieved();
-    throw new RuntimeException("getActivities Failed.");
-  }
-
-  /**
-   * This method retrieve the last n activities inside scheduler, and it is
-   * reachable by using {@link RMWSConsts#SCHEDULER_BULK_ACTIVITIES}.
-   *
-   * @param hsr the servlet request
-   * @param groupBy the groupBy type by which the activities should be
-   *        aggregated. It is a QueryParam.
-   * @param activitiesCount number of activities
-   * @return last n activities
-   */
-  @Override
-  public BulkActivitiesInfo getBulkActivities(HttpServletRequest hsr,
-      String groupBy, int activitiesCount) throws InterruptedException {
-    try {
-      // Step1. Check the parameters to ensure that the parameters are not empty
-      Validate.checkNotNullAndNotEmpty(groupBy, "groupBy");
-      Validate.checkNotNegative(activitiesCount, "activitiesCount");
-
-      // Step2. Call the interface of subCluster concurrently and get the returned result.
-      Collection<SubClusterInfo> subClustersActive = federationFacade.getActiveSubClusters();
-      final HttpServletRequest hsrCopy = clone(hsr);
-      Class[] argsClasses = new Class[]{HttpServletRequest.class, String.class, int.class};
-      Object[] args = new Object[]{hsrCopy, groupBy, activitiesCount};
-      ClientMethod remoteMethod = new ClientMethod("getBulkActivities", argsClasses, args);
-      Map<SubClusterInfo, BulkActivitiesInfo> appStatisticsMap = invokeConcurrent(
-          subClustersActive, remoteMethod, BulkActivitiesInfo.class);
-
-      // Step3. Generate Federation objects and set subCluster information.
-      long startTime = clock.getTime();
-      FederationBulkActivitiesInfo fedBulkActivitiesInfo = new FederationBulkActivitiesInfo();
-      appStatisticsMap.forEach((subClusterInfo, bulkActivitiesInfo) -> {
-        SubClusterId subClusterId = subClusterInfo.getSubClusterId();
-        bulkActivitiesInfo.setSubClusterId(subClusterId.getId());
-        fedBulkActivitiesInfo.getList().add(bulkActivitiesInfo);
-      });
-      RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_BULKACTIVITIES,
-          TARGET_WEB_SERVICE);
-      long stopTime = clock.getTime();
-      routerMetrics.succeededGetBulkActivitiesRetrieved(stopTime - startTime);
-      return fedBulkActivitiesInfo;
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrGetBulkActivitiesFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_BULKACTIVITIES, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      throw e;
-    } catch (NotFoundException e) {
-      routerMetrics.incrGetBulkActivitiesFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_BULKACTIVITIES, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("get all active sub cluster(s) error.", e);
-    } catch (IOException e) {
-      routerMetrics.incrGetBulkActivitiesFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_BULKACTIVITIES, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e,
-          "getBulkActivities by groupBy = %s, activitiesCount = %s with io error.",
-          groupBy, String.valueOf(activitiesCount));
-    } catch (YarnException e) {
-      routerMetrics.incrGetBulkActivitiesFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_BULKACTIVITIES, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e,
-          "getBulkActivities by groupBy = %s, activitiesCount = %s with yarn error.",
-          groupBy, String.valueOf(activitiesCount));
-    }
-
-    routerMetrics.incrGetBulkActivitiesFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_BULKACTIVITIES, UNKNOWN,
-        TARGET_WEB_SERVICE, "getBulkActivities Failed.");
-    throw new RuntimeException("getBulkActivities Failed.");
-  }
-
-  @Override
-  public AppActivitiesInfo getAppActivities(HttpServletRequest hsr,
-      String appId, String time, Set<String> requestPriorities,
-      Set<String> allocationRequestIds, String groupBy, String limit,
-      Set<String> actions, boolean summarize) {
-
-    try {
-      long startTime = clock.getTime();
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorByAppId(appId);
-      final HttpServletRequest hsrCopy = clone(hsr);
-      AppActivitiesInfo appActivitiesInfo = interceptor.getAppActivities(hsrCopy, appId, time,
-          requestPriorities, allocationRequestIds, groupBy, limit, actions, summarize);
-      if (appActivitiesInfo != null) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededGetAppActivitiesRetrieved(stopTime - startTime);
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_APPACTIVITIES,
-            TARGET_WEB_SERVICE);
-        return appActivitiesInfo;
-      }
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrGetAppActivitiesFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APPACTIVITIES, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e,
-          "Unable to get subCluster by appId: %s.", appId);
-    } catch (YarnException e) {
-      routerMetrics.incrGetAppActivitiesFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APPACTIVITIES, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e,
-          "getAppActivities by appId = %s error .", appId);
-    }
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APPACTIVITIES, UNKNOWN,
-        TARGET_WEB_SERVICE, "getAppActivities Failed.");
-    routerMetrics.incrGetAppActivitiesFailedRetrieved();
-    throw new RuntimeException("getAppActivities Failed.");
-  }
-
-  @Override
-  public ApplicationStatisticsInfo getAppStatistics(HttpServletRequest hsr,
-      Set<String> stateQueries, Set<String> typeQueries) {
-    try {
-      long startTime = clock.getTime();
-      Collection<SubClusterInfo> subClustersActive = federationFacade.getActiveSubClusters();
-      final HttpServletRequest hsrCopy = clone(hsr);
-      Class[] argsClasses = new Class[]{HttpServletRequest.class, Set.class, Set.class};
-      Object[] args = new Object[]{hsrCopy, stateQueries, typeQueries};
-      ClientMethod remoteMethod = new ClientMethod("getAppStatistics", argsClasses, args);
-      Map<SubClusterInfo, ApplicationStatisticsInfo> appStatisticsMap = invokeConcurrent(
-          subClustersActive, remoteMethod, ApplicationStatisticsInfo.class);
-      ApplicationStatisticsInfo applicationStatisticsInfo  =
-          RouterWebServiceUtil.mergeApplicationStatisticsInfo(appStatisticsMap.values());
-      if (applicationStatisticsInfo != null) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededGetAppStatisticsRetrieved(stopTime - startTime);
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_APPSTATISTICS,
-            TARGET_WEB_SERVICE);
-        return applicationStatisticsInfo;
-      }
-    } catch (NotFoundException e) {
-      routerMetrics.incrGetAppStatisticsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APPSTATISTICS, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("get all active sub cluster(s) error.", e);
-    } catch (IOException e) {
-      routerMetrics.incrGetAppStatisticsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APPSTATISTICS, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e,
-          "getAppStatistics error by stateQueries = %s, typeQueries = %s with io error.",
-          StringUtils.join(stateQueries, ","), StringUtils.join(typeQueries, ","));
-    } catch (YarnException e) {
-      routerMetrics.incrGetAppStatisticsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APPSTATISTICS, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e,
-          "getAppStatistics by stateQueries = %s, typeQueries = %s with yarn error.",
-          StringUtils.join(stateQueries, ","), StringUtils.join(typeQueries, ","));
-    }
-    routerMetrics.incrGetAppStatisticsFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APPSTATISTICS, UNKNOWN,
-        TARGET_WEB_SERVICE, "getAppStatistics Failed.");
-    throw RouterServerUtil.logAndReturnRunTimeException(
-        "getAppStatistics by stateQueries = %s, typeQueries = %s Failed.",
-        StringUtils.join(stateQueries, ","), StringUtils.join(typeQueries, ","));
-  }
-
-  @Override
-  public NodeToLabelsInfo getNodeToLabels(HttpServletRequest hsr)
-      throws IOException {
-    try {
-      long startTime = clock.getTime();
-      Collection<SubClusterInfo> subClustersActive = federationFacade.getActiveSubClusters();
-      final HttpServletRequest hsrCopy = clone(hsr);
-      Class[] argsClasses = new Class[]{HttpServletRequest.class};
-      Object[] args = new Object[]{hsrCopy};
-      ClientMethod remoteMethod = new ClientMethod("getNodeToLabels", argsClasses, args);
-      Map<SubClusterInfo, NodeToLabelsInfo> nodeToLabelsInfoMap =
-          invokeConcurrent(subClustersActive, remoteMethod, NodeToLabelsInfo.class);
-      NodeToLabelsInfo nodeToLabelsInfo =
-          RouterWebServiceUtil.mergeNodeToLabels(nodeToLabelsInfoMap);
-      if (nodeToLabelsInfo != null) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededGetNodeToLabelsRetrieved(stopTime - startTime);
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_NODETOLABELS,
-            TARGET_WEB_SERVICE);
-        return nodeToLabelsInfo;
-      }
-    } catch (NotFoundException e) {
-      routerMetrics.incrNodeToLabelsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_NODETOLABELS, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowIOException("get all active sub cluster(s) error.", e);
-    } catch (YarnException e) {
-      routerMetrics.incrNodeToLabelsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_NODETOLABELS, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowIOException("getNodeToLabels error.", e);
-    }
-    routerMetrics.incrNodeToLabelsFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_NODETOLABELS, UNKNOWN,
-        TARGET_WEB_SERVICE, "getNodeToLabels Failed.");
-    throw new RuntimeException("getNodeToLabels Failed.");
-  }
-
-  @Override
-  public NodeLabelsInfo getRMNodeLabels(HttpServletRequest hsr) throws IOException {
-    try {
-      long startTime = clock.getTime();
-      Collection<SubClusterInfo> subClustersActive = federationFacade.getActiveSubClusters();
-      final HttpServletRequest hsrCopy = clone(hsr);
-      Class[] argsClasses = new Class[]{HttpServletRequest.class};
-      Object[] args = new Object[]{hsrCopy};
-      ClientMethod remoteMethod = new ClientMethod("getRMNodeLabels", argsClasses, args);
-      Map<SubClusterInfo, NodeLabelsInfo> nodeToLabelsInfoMap =
-          invokeConcurrent(subClustersActive, remoteMethod, NodeLabelsInfo.class);
-      NodeLabelsInfo nodeToLabelsInfo =
-          RouterWebServiceUtil.mergeNodeLabelsInfo(nodeToLabelsInfoMap);
-      if (nodeToLabelsInfo != null) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededGetRMNodeLabelsRetrieved(stopTime - startTime);
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_RMNODELABELS,
-            TARGET_WEB_SERVICE);
-        return nodeToLabelsInfo;
-      }
-    } catch (NotFoundException e) {
-      routerMetrics.incrGetRMNodeLabelsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_RMNODELABELS, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowIOException("get all active sub cluster(s) error.", e);
-    } catch (YarnException e) {
-      routerMetrics.incrGetRMNodeLabelsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_RMNODELABELS, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowIOException("getRMNodeLabels error.", e);
-    }
-    routerMetrics.incrGetRMNodeLabelsFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_RMNODELABELS, UNKNOWN,
-        TARGET_WEB_SERVICE, "getRMNodeLabels Failed.");
-    throw new RuntimeException("getRMNodeLabels Failed.");
-  }
-
-  @Override
-  public LabelsToNodesInfo getLabelsToNodes(Set<String> labels)
-      throws IOException {
-    try {
-      long startTime = clock.getTime();
-      Collection<SubClusterInfo> subClustersActive = federationFacade.getActiveSubClusters();
-      Class[] argsClasses = new Class[]{Set.class};
-      Object[] args = new Object[]{labels};
-      ClientMethod remoteMethod = new ClientMethod("getLabelsToNodes", argsClasses, args);
-      Map<SubClusterInfo, LabelsToNodesInfo> labelsToNodesInfoMap =
-          invokeConcurrent(subClustersActive, remoteMethod, LabelsToNodesInfo.class);
-      Map<NodeLabelInfo, NodeIDsInfo> labelToNodesMap = new HashMap<>();
-      labelsToNodesInfoMap.values().forEach(labelsToNode -> {
-        Map<NodeLabelInfo, NodeIDsInfo> values = labelsToNode.getLabelsToNodes();
-        for (Map.Entry<NodeLabelInfo, NodeIDsInfo> item : values.entrySet()) {
-          NodeLabelInfo key = item.getKey();
-          NodeIDsInfo leftValue = item.getValue();
-          NodeIDsInfo rightValue = labelToNodesMap.getOrDefault(key, null);
-          NodeIDsInfo newValue = NodeIDsInfo.add(leftValue, rightValue);
-          labelToNodesMap.put(key, newValue);
-        }
-      });
-      LabelsToNodesInfo labelsToNodesInfo = new LabelsToNodesInfo(labelToNodesMap);
-      if (labelsToNodesInfo != null) {
-        long stopTime = clock.getTime();
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_LABELSTONODES,
-            TARGET_WEB_SERVICE);
-        routerMetrics.succeededGetLabelsToNodesRetrieved(stopTime - startTime);
-        return labelsToNodesInfo;
-      }
-    } catch (NotFoundException e) {
-      routerMetrics.incrLabelsToNodesFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_LABELSTONODES, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowIOException("get all active sub cluster(s) error.", e);
-    } catch (YarnException e) {
-      routerMetrics.incrLabelsToNodesFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_LABELSTONODES, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowIOException(
-          e, "getLabelsToNodes by labels = %s with yarn error.", StringUtils.join(labels, ","));
-    }
-    routerMetrics.incrLabelsToNodesFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_LABELSTONODES, UNKNOWN,
-        TARGET_WEB_SERVICE, "getLabelsToNodes Failed.");
-    throw RouterServerUtil.logAndReturnRunTimeException(
-        "getLabelsToNodes by labels = %s Failed.", StringUtils.join(labels, ","));
-  }
-
-  /**
-   * This method replaces all the node labels for specific nodes, and it is
-   * reachable by using {@link RMWSConsts#REPLACE_NODE_TO_LABELS}.
-   *
-   * @see ResourceManagerAdministrationProtocol#replaceLabelsOnNode
-   * @param newNodeToLabels the list of new labels. It is a content param.
-   * @param hsr the servlet request
-   * @return Response containing the status code
-   * @throws IOException if an exception happened
-   */
-  @Override
-  public Response replaceLabelsOnNodes(NodeToLabelsEntryList newNodeToLabels,
-      HttpServletRequest hsr) throws IOException {
-
-    // Step1. Check the parameters to ensure that the parameters are not empty.
-    if (newNodeToLabels == null) {
-      routerMetrics.incrReplaceLabelsOnNodesFailedRetrieved();
-      throw new IllegalArgumentException("Parameter error, newNodeToLabels must not be empty.");
-    }
-    List<NodeToLabelsEntry> nodeToLabelsEntries = newNodeToLabels.getNodeToLabels();
-    if (CollectionUtils.isEmpty(nodeToLabelsEntries)) {
-      routerMetrics.incrReplaceLabelsOnNodesFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), REPLACE_LABELSONNODES, UNKNOWN,
-          TARGET_WEB_SERVICE, "Parameter error, " +
-          "nodeToLabelsEntries must not be empty.");
-      throw new IllegalArgumentException("Parameter error, " +
-         "nodeToLabelsEntries must not be empty.");
-    }
-
-    try {
-
-      // Step2. We map the NodeId and NodeToLabelsEntry in the request.
-      Map<String, NodeToLabelsEntry> nodeIdToLabels = new HashMap<>();
-      newNodeToLabels.getNodeToLabels().forEach(nodeIdToLabel -> {
-        String nodeId = nodeIdToLabel.getNodeId();
-        nodeIdToLabels.put(nodeId, nodeIdToLabel);
-      });
-
-      // Step3. We map SubCluster with NodeToLabelsEntryList
-      Map<SubClusterInfo, NodeToLabelsEntryList> subClusterToNodeToLabelsEntryList =
-          new HashMap<>();
-      nodeIdToLabels.forEach((nodeId, nodeToLabelsEntry) -> {
-        SubClusterInfo subClusterInfo = getNodeSubcluster(nodeId);
-        NodeToLabelsEntryList nodeToLabelsEntryList = subClusterToNodeToLabelsEntryList.
-            getOrDefault(subClusterInfo, new NodeToLabelsEntryList());
-        nodeToLabelsEntryList.getNodeToLabels().add(nodeToLabelsEntry);
-        subClusterToNodeToLabelsEntryList.put(subClusterInfo, nodeToLabelsEntryList);
-      });
-
-      // Step4. Traverse the subCluster and call the replaceLabelsOnNodes interface.
-      long startTime = clock.getTime();
-      final HttpServletRequest hsrCopy = clone(hsr);
-      StringBuilder builder = new StringBuilder();
-      subClusterToNodeToLabelsEntryList.forEach((subClusterInfo, nodeToLabelsEntryList) -> {
-        SubClusterId subClusterId = subClusterInfo.getSubClusterId();
-        try {
-          DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorForSubCluster(
-              subClusterInfo);
-          interceptor.replaceLabelsOnNodes(nodeToLabelsEntryList, hsrCopy);
-          builder.append("subCluster-").append(subClusterId.getId()).append(":Success,");
-        } catch (Exception e) {
-          LOG.error("replaceLabelsOnNodes Failed. subClusterId = {}.", subClusterId, e);
-          builder.append("subCluster-").append(subClusterId.getId()).append(":Failed,");
-        }
-      });
-      long stopTime = clock.getTime();
-      RouterAuditLogger.logSuccess(getUser().getShortUserName(), REPLACE_LABELSONNODES,
-          TARGET_WEB_SERVICE);
-      routerMetrics.succeededReplaceLabelsOnNodesRetrieved(stopTime - startTime);
-
-      // Step5. return call result.
-      return Response.status(Status.OK).entity(builder.toString()).build();
-    } catch (Exception e) {
-      routerMetrics.incrReplaceLabelsOnNodesFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), REPLACE_LABELSONNODES, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      throw e;
-    }
-  }
-
-  /**
-   * This method replaces all the node labels for specific node, and it is
-   * reachable by using {@link RMWSConsts#NODES_NODEID_REPLACE_LABELS}.
-   *
-   * @see ResourceManagerAdministrationProtocol#replaceLabelsOnNode
-   * @param newNodeLabelsName the list of new labels. It is a QueryParam.
-   * @param hsr the servlet request
-   * @param nodeId the node we want to replace the node labels. It is a
-   *     PathParam.
-   * @return Response containing the status code
-   * @throws Exception if an exception happened
-   */
-  @Override
-  public Response replaceLabelsOnNode(Set<String> newNodeLabelsName,
-      HttpServletRequest hsr, String nodeId) throws Exception {
-
-    // Step1. Check the parameters to ensure that the parameters are not empty.
-    if (StringUtils.isBlank(nodeId)) {
-      routerMetrics.incrReplaceLabelsOnNodeFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), REPLACE_LABELSONNODE, UNKNOWN,
-          TARGET_WEB_SERVICE, "Parameter error, nodeId must not be null or empty.");
-      throw new IllegalArgumentException("Parameter error, nodeId must not be null or empty.");
-    }
-    if (CollectionUtils.isEmpty(newNodeLabelsName)) {
-      routerMetrics.incrReplaceLabelsOnNodeFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), REPLACE_LABELSONNODE, UNKNOWN,
-          TARGET_WEB_SERVICE, "Parameter error, newNodeLabelsName must not be empty.");
-      throw new IllegalArgumentException("Parameter error, newNodeLabelsName must not be empty.");
-    }
-
-    try {
-      // Step2. We find the subCluster according to the nodeId,
-      // and then call the replaceLabelsOnNode of the subCluster.
-      long startTime = clock.getTime();
-      SubClusterInfo subClusterInfo = getNodeSubcluster(nodeId);
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorByNodeId(nodeId);
-      final HttpServletRequest hsrCopy = clone(hsr);
-      interceptor.replaceLabelsOnNode(newNodeLabelsName, hsrCopy, nodeId);
-
-      // Step3. Return the response result.
-      long stopTime = clock.getTime();
-      RouterAuditLogger.logSuccess(getUser().getShortUserName(), REPLACE_LABELSONNODE,
-          TARGET_WEB_SERVICE);
-      routerMetrics.succeededReplaceLabelsOnNodeRetrieved(stopTime - startTime);
-      String msg = "subCluster#" + subClusterInfo.getSubClusterId().getId() + ":Success;";
-      return Response.status(Status.OK).entity(msg).build();
-    } catch (Exception e) {
-      routerMetrics.incrReplaceLabelsOnNodeFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), REPLACE_LABELSONNODE, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      throw e;
-    }
-  }
-
-  @Override
-  public NodeLabelsInfo getClusterNodeLabels(HttpServletRequest hsr)
-      throws IOException {
-    try {
-      long startTime = clock.getTime();
-      Collection<SubClusterInfo> subClustersActive = federationFacade.getActiveSubClusters();
-      final HttpServletRequest hsrCopy = clone(hsr);
-      Class[] argsClasses = new Class[]{HttpServletRequest.class};
-      Object[] args = new Object[]{hsrCopy};
-      ClientMethod remoteMethod = new ClientMethod("getClusterNodeLabels", argsClasses, args);
-      Map<SubClusterInfo, NodeLabelsInfo> nodeToLabelsInfoMap =
-          invokeConcurrent(subClustersActive, remoteMethod, NodeLabelsInfo.class);
-      Set<NodeLabel> hashSets = Sets.newHashSet();
-      nodeToLabelsInfoMap.values().forEach(item -> hashSets.addAll(item.getNodeLabels()));
-      NodeLabelsInfo nodeLabelsInfo = new NodeLabelsInfo(hashSets);
-      if (nodeLabelsInfo != null) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededGetClusterNodeLabelsRetrieved(stopTime - startTime);
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_CLUSTER_NODELABELS,
-            TARGET_WEB_SERVICE);
-        return nodeLabelsInfo;
-      }
-    } catch (NotFoundException e) {
-      routerMetrics.incrClusterNodeLabelsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_CLUSTER_NODELABELS, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowIOException("get all active sub cluster(s) error.", e);
-    } catch (YarnException e) {
-      routerMetrics.incrClusterNodeLabelsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_CLUSTER_NODELABELS, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowIOException("getClusterNodeLabels with yarn error.", e);
-    }
-    routerMetrics.incrClusterNodeLabelsFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_CLUSTER_NODELABELS, UNKNOWN,
-        TARGET_WEB_SERVICE, "getClusterNodeLabels Failed.");
-    throw new RuntimeException("getClusterNodeLabels Failed.");
-  }
-
-  /**
-   * This method adds specific node labels for specific nodes, and it is
-   * reachable by using {@link RMWSConsts#ADD_NODE_LABELS}.
-   *
-   * @see ResourceManagerAdministrationProtocol#addToClusterNodeLabels
-   * @param newNodeLabels the node labels to add. It is a content param.
-   * @param hsr the servlet request
-   * @return Response containing the status code
-   * @throws Exception in case of bad request
-   */
-  @Override
-  public Response addToClusterNodeLabels(NodeLabelsInfo newNodeLabels,
-      HttpServletRequest hsr) throws Exception {
-
-    if (newNodeLabels == null) {
-      routerMetrics.incrAddToClusterNodeLabelsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), ADD_TO_CLUSTER_NODELABELS, UNKNOWN,
-          TARGET_WEB_SERVICE, "Parameter error, the newNodeLabels is null.");
-      throw new IllegalArgumentException("Parameter error, the newNodeLabels is null.");
-    }
-
-    List<NodeLabelInfo> nodeLabelInfos = newNodeLabels.getNodeLabelsInfo();
-    if (CollectionUtils.isEmpty(nodeLabelInfos)) {
-      routerMetrics.incrAddToClusterNodeLabelsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), ADD_TO_CLUSTER_NODELABELS, UNKNOWN,
-          TARGET_WEB_SERVICE, "Parameter error, the nodeLabelsInfo is null or empty.");
-      throw new IllegalArgumentException("Parameter error, the nodeLabelsInfo is null or empty.");
-    }
-
-    try {
-      long startTime = clock.getTime();
-      Collection<SubClusterInfo> subClustersActives = federationFacade.getActiveSubClusters();
-      final HttpServletRequest hsrCopy = clone(hsr);
-      Class[] argsClasses = new Class[]{NodeLabelsInfo.class, HttpServletRequest.class};
-      Object[] args = new Object[]{newNodeLabels, hsrCopy};
-      ClientMethod remoteMethod = new ClientMethod("addToClusterNodeLabels", argsClasses, args);
-      Map<SubClusterInfo, Response> responseInfoMap =
-          invokeConcurrent(subClustersActives, remoteMethod, Response.class);
-      StringBuffer buffer = new StringBuffer();
-      // SubCluster-0:SUCCESS,SubCluster-1:SUCCESS
-      responseInfoMap.forEach((subClusterInfo, response) ->
-          buildAppendMsg(subClusterInfo, buffer, response));
-      long stopTime = clock.getTime();
-      RouterAuditLogger.logSuccess(getUser().getShortUserName(), ADD_TO_CLUSTER_NODELABELS,
-          TARGET_WEB_SERVICE);
-      routerMetrics.succeededAddToClusterNodeLabelsRetrieved((stopTime - startTime));
-      return Response.status(Status.OK).entity(buffer.toString()).build();
-    } catch (NotFoundException e) {
-      routerMetrics.incrAddToClusterNodeLabelsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), ADD_TO_CLUSTER_NODELABELS, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowIOException("get all active sub cluster(s) error.", e);
-    } catch (YarnException e) {
-      routerMetrics.incrAddToClusterNodeLabelsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), ADD_TO_CLUSTER_NODELABELS, UNKNOWN,
-          TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowIOException("addToClusterNodeLabels with yarn error.", e);
-    }
-
-    routerMetrics.incrAddToClusterNodeLabelsFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), ADD_TO_CLUSTER_NODELABELS, UNKNOWN,
-        TARGET_WEB_SERVICE, "addToClusterNodeLabels Failed.");
-    throw new RuntimeException("addToClusterNodeLabels Failed.");
-  }
-
-  /**
-   * This method removes all the node labels for specific nodes, and it is
-   * reachable by using {@link RMWSConsts#REMOVE_NODE_LABELS}.
-   *
-   * @see ResourceManagerAdministrationProtocol#removeFromClusterNodeLabels
-   * @param oldNodeLabels the node labels to remove. It is a QueryParam.
-   * @param hsr the servlet request
-   * @return Response containing the status code
-   * @throws Exception in case of bad request
-   */
-  @Override
-  public Response removeFromClusterNodeLabels(Set<String> oldNodeLabels,
-      HttpServletRequest hsr) throws Exception {
-
-    if (CollectionUtils.isEmpty(oldNodeLabels)) {
-      routerMetrics.incrRemoveFromClusterNodeLabelsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), REMOVE_FROM_CLUSTERNODELABELS,
-          UNKNOWN, TARGET_WEB_SERVICE, "Parameter error, the oldNodeLabels is null or empty.");
-      throw new IllegalArgumentException("Parameter error, the oldNodeLabels is null or empty.");
-    }
-
-    try {
-      long startTime = clock.getTime();
-      Collection<SubClusterInfo> subClustersActives = federationFacade.getActiveSubClusters();
-      final HttpServletRequest hsrCopy = clone(hsr);
-      Class[] argsClasses = new Class[]{Set.class, HttpServletRequest.class};
-      Object[] args = new Object[]{oldNodeLabels, hsrCopy};
-      ClientMethod remoteMethod =
-          new ClientMethod("removeFromClusterNodeLabels", argsClasses, args);
-      Map<SubClusterInfo, Response> responseInfoMap =
-          invokeConcurrent(subClustersActives, remoteMethod, Response.class);
-      StringBuffer buffer = new StringBuffer();
-      // SubCluster-0:SUCCESS,SubCluster-1:SUCCESS
-      responseInfoMap.forEach((subClusterInfo, response) ->
-          buildAppendMsg(subClusterInfo, buffer, response));
-      long stopTime = clock.getTime();
-      RouterAuditLogger.logSuccess(getUser().getShortUserName(), REMOVE_FROM_CLUSTERNODELABELS,
-          TARGET_WEB_SERVICE);
-      routerMetrics.succeededRemoveFromClusterNodeLabelsRetrieved(stopTime - startTime);
-      return Response.status(Status.OK).entity(buffer.toString()).build();
-    } catch (NotFoundException e) {
-      routerMetrics.incrRemoveFromClusterNodeLabelsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), REMOVE_FROM_CLUSTERNODELABELS,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowIOException("get all active sub cluster(s) error.", e);
-    } catch (YarnException e) {
-      routerMetrics.incrRemoveFromClusterNodeLabelsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), REMOVE_FROM_CLUSTERNODELABELS,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowIOException("removeFromClusterNodeLabels with yarn error.", e);
-    }
-
-    routerMetrics.incrRemoveFromClusterNodeLabelsFailedRetrieved();
-    throw new RuntimeException("removeFromClusterNodeLabels Failed.");
-  }
-
-  /**
-   * Build Append information.
-   *
-   * @param subClusterInfo subCluster information.
-   * @param buffer StringBuffer.
-   * @param response response message.
-   */
-  private void buildAppendMsg(SubClusterInfo subClusterInfo, StringBuffer buffer,
-      Response response) {
-    SubClusterId subClusterId = subClusterInfo.getSubClusterId();
-    String state = response != null &&
-        (response.getStatus() == Status.OK.getStatusCode()) ? "SUCCESS" : "FAILED";
-    buffer.append("SubCluster-")
-        .append(subClusterId.getId())
-        .append(":")
-        .append(state)
-        .append(",");
-  }
-
-  @Override
-  public NodeLabelsInfo getLabelsOnNode(HttpServletRequest hsr, String nodeId)
-      throws IOException {
-    try {
-      long startTime = clock.getTime();
-      Collection<SubClusterInfo> subClustersActive = federationFacade.getActiveSubClusters();
-      final HttpServletRequest hsrCopy = clone(hsr);
-      Class[] argsClasses = new Class[]{HttpServletRequest.class, String.class};
-      Object[] args = new Object[]{hsrCopy, nodeId};
-      ClientMethod remoteMethod = new ClientMethod("getLabelsOnNode", argsClasses, args);
-      Map<SubClusterInfo, NodeLabelsInfo> nodeToLabelsInfoMap =
-          invokeConcurrent(subClustersActive, remoteMethod, NodeLabelsInfo.class);
-      Set<NodeLabel> hashSets = Sets.newHashSet();
-      nodeToLabelsInfoMap.values().forEach(item -> hashSets.addAll(item.getNodeLabels()));
-      NodeLabelsInfo nodeLabelsInfo = new NodeLabelsInfo(hashSets);
-      if (nodeLabelsInfo != null) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededGetLabelsToNodesRetrieved(stopTime - startTime);
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_LABELS_ON_NODE,
-            TARGET_WEB_SERVICE);
-        return nodeLabelsInfo;
-      }
-    } catch (NotFoundException e) {
-      routerMetrics.incrLabelsToNodesFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_LABELS_ON_NODE,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowIOException("get all active sub cluster(s) error.", e);
-    } catch (YarnException e) {
-      routerMetrics.incrLabelsToNodesFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_LABELS_ON_NODE,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowIOException(
-          e, "getLabelsOnNode nodeId = %s with yarn error.", nodeId);
-    }
-    routerMetrics.incrLabelsToNodesFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_LABELS_ON_NODE,
-        UNKNOWN, TARGET_WEB_SERVICE, "getLabelsOnNode by nodeId = " + nodeId + " Failed.");
-    throw RouterServerUtil.logAndReturnRunTimeException(
-        "getLabelsOnNode by nodeId = %s Failed.", nodeId);
-  }
-
-  @Override
-  public AppPriority getAppPriority(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-
-    try {
-      long startTime = clock.getTime();
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorByAppId(appId);
-      AppPriority appPriority = interceptor.getAppPriority(hsr, appId);
-      if (appPriority != null) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededGetAppPriorityRetrieved(stopTime - startTime);
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_APP_PRIORITY,
-            TARGET_WEB_SERVICE);
-        return appPriority;
-      }
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrGetAppPriorityFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APP_PRIORITY,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e,
-          "Unable to get the getAppPriority appId: %s.", appId);
-    } catch (YarnException e) {
-      routerMetrics.incrGetAppPriorityFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APP_PRIORITY,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("getAppPriority error.", e);
-    }
-    routerMetrics.incrGetAppPriorityFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APP_PRIORITY,
-        UNKNOWN, TARGET_WEB_SERVICE, "getAppPriority Failed.");
-    throw new RuntimeException("getAppPriority Failed.");
-  }
-
-  @Override
-  public Response updateApplicationPriority(AppPriority targetPriority,
-      HttpServletRequest hsr, String appId) throws AuthorizationException,
-      YarnException, InterruptedException, IOException {
-
-    if (targetPriority == null) {
-      routerMetrics.incrUpdateAppPriorityFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_APPLICATIONPRIORITY,
-          UNKNOWN, TARGET_WEB_SERVICE, "Parameter error, the targetPriority is empty or null.");
-      throw new IllegalArgumentException("Parameter error, the targetPriority is empty or null.");
-    }
-
-    try {
-      long startTime = clock.getTime();
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorByAppId(appId);
-      Response response = interceptor.updateApplicationPriority(targetPriority, hsr, appId);
-      if (response != null) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededUpdateAppPriorityRetrieved(stopTime - startTime);
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), UPDATE_APPLICATIONPRIORITY,
-            TARGET_WEB_SERVICE);
-        return response;
-      }
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrUpdateAppPriorityFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_APPLICATIONPRIORITY,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e,
-          "Unable to get the updateApplicationPriority appId: %s.", appId);
-    } catch (YarnException e) {
-      routerMetrics.incrUpdateAppPriorityFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_APPLICATIONPRIORITY,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("updateApplicationPriority error.", e);
-    }
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_APPLICATIONPRIORITY,
-        UNKNOWN, TARGET_WEB_SERVICE, "getAppPriority Failed.");
-    routerMetrics.incrUpdateAppPriorityFailedRetrieved();
-    throw new RuntimeException("updateApplicationPriority Failed.");
-  }
-
-  @Override
-  public AppQueue getAppQueue(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-
-    try {
-      long startTime = clock.getTime();
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorByAppId(appId);
-      AppQueue queue = interceptor.getAppQueue(hsr, appId);
-      if (queue != null) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededGetAppQueueRetrieved((stopTime - startTime));
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_QUEUEINFO,
-            TARGET_WEB_SERVICE);
-        return queue;
-      }
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrGetAppQueueFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_QUEUEINFO,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e, "Unable to get queue by appId: %s.", appId);
-    } catch (YarnException e) {
-      routerMetrics.incrGetAppQueueFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_QUEUEINFO,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("getAppQueue error.", e);
-    }
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_QUEUEINFO,
-        UNKNOWN, TARGET_WEB_SERVICE, "getAppQueue Failed.");
-    routerMetrics.incrGetAppQueueFailedRetrieved();
-    throw new RuntimeException("getAppQueue Failed.");
-  }
-
-  @Override
-  public Response updateAppQueue(AppQueue targetQueue, HttpServletRequest hsr,
-      String appId) throws AuthorizationException, YarnException,
-      InterruptedException, IOException {
-
-    if (targetQueue == null) {
-      routerMetrics.incrUpdateAppQueueFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_APP_QUEUE,
-          UNKNOWN, TARGET_WEB_SERVICE, "Parameter error, the targetQueue is null.");
-      throw new IllegalArgumentException("Parameter error, the targetQueue is null.");
-    }
-
-    try {
-      long startTime = clock.getTime();
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorByAppId(appId);
-      Response response = interceptor.updateAppQueue(targetQueue, hsr, appId);
-      if (response != null) {
-        long stopTime = clock.getTime();
-        routerMetrics.succeededUpdateAppQueueRetrieved(stopTime - startTime);
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), UPDATE_APP_QUEUE,
-            TARGET_WEB_SERVICE);
-        return response;
-      }
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrUpdateAppQueueFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_APP_QUEUE,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e,
-          "Unable to update app queue by appId: %s.", appId);
-    } catch (YarnException e) {
-      routerMetrics.incrUpdateAppQueueFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_APP_QUEUE,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("updateAppQueue error.", e);
-    }
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_APP_QUEUE,
-        UNKNOWN, TARGET_WEB_SERVICE, "updateAppQueue Failed.");
-    routerMetrics.incrUpdateAppQueueFailedRetrieved();
-    throw new RuntimeException("updateAppQueue Failed.");
-  }
-
-  /**
-   * This method posts a delegation token from the client.
-   *
-   * @param tokenData the token to delegate. It is a content param.
-   * @param hsr the servlet request.
-   * @return Response containing the status code.
-   * @throws AuthorizationException if Kerberos auth failed.
-   * @throws IOException if the delegation failed.
-   * @throws InterruptedException if interrupted.
-   * @throws Exception in case of bad request.
-   */
-  @Override
-  public Response postDelegationToken(DelegationToken tokenData, HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException, Exception {
-
-    if (tokenData == null || hsr == null) {
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), POST_DELEGATION_TOKEN,
-          UNKNOWN, TARGET_WEB_SERVICE, "Parameter error, the tokenData or hsr is null.");
-      throw new IllegalArgumentException("Parameter error, the tokenData or hsr is null.");
-    }
-
-    try {
-      // get Caller UserGroupInformation
-      Configuration conf = federationFacade.getConf();
-      UserGroupInformation callerUGI = getKerberosUserGroupInformation(conf, hsr);
-
-      // create a delegation token
-      return createDelegationToken(tokenData, callerUGI);
-    } catch (YarnException e) {
-      LOG.error("Create delegation token request failed.", e);
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), POST_DELEGATION_TOKEN,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      return Response.status(Status.FORBIDDEN).entity(e.getMessage()).build();
-    }
-  }
-
-  /**
-   * Create DelegationToken.
-   *
-   * @param dtoken DelegationToken Data.
-   * @param callerUGI UserGroupInformation.
-   * @return Response.
-   * @throws Exception An exception occurred when creating a delegationToken.
-   */
-  private Response createDelegationToken(DelegationToken dtoken, UserGroupInformation callerUGI)
-      throws IOException, InterruptedException {
-
-    String renewer = dtoken.getRenewer();
-
-    GetDelegationTokenResponse resp = callerUGI.doAs(
-        (PrivilegedExceptionAction<GetDelegationTokenResponse>) () -> {
-        GetDelegationTokenRequest createReq = GetDelegationTokenRequest.newInstance(renewer);
-        return this.getRouterClientRMService().getDelegationToken(createReq);
-      });
-
-    DelegationToken respToken = getDelegationToken(renewer, resp);
-    RouterAuditLogger.logSuccess(getUser().getShortUserName(), POST_DELEGATION_TOKEN,
-        TARGET_WEB_SERVICE);
-    return Response.status(Status.OK).entity(respToken).build();
-  }
-
-  /**
-   * Get DelegationToken.
-   *
-   * @param renewer renewer.
-   * @param resp GetDelegationTokenResponse.
-   * @return DelegationToken.
-   * @throws IOException if there are I/O errors.
-   */
-  private DelegationToken getDelegationToken(String renewer, GetDelegationTokenResponse resp)
-      throws IOException {
-    // Step1. Parse token from GetDelegationTokenResponse.
-    Token<RMDelegationTokenIdentifier> tk = getToken(resp);
-    String tokenKind = tk.getKind().toString();
-    RMDelegationTokenIdentifier tokenIdentifier = tk.decodeIdentifier();
-    String owner = tokenIdentifier.getOwner().toString();
-    long maxDate = tokenIdentifier.getMaxDate();
-
-    // Step2. Call the interface to get the expiration time of Token.
-    RouterClientRMService clientRMService = this.getRouterClientRMService();
-    RouterDelegationTokenSecretManager tokenSecretManager =
-        clientRMService.getRouterDTSecretManager();
-    long currentExpiration = tokenSecretManager.getRenewDate(tokenIdentifier);
-
-    // Step3. Generate Delegation token.
-    DelegationToken delegationToken = new DelegationToken(tk.encodeToUrlString(),
-        renewer, owner, tokenKind, currentExpiration, maxDate);
-
-    return delegationToken;
-  }
-
-  /**
-   * GetToken.
-   * We convert RMDelegationToken in GetDelegationTokenResponse to Token.
-   *
-   * @param resp GetDelegationTokenResponse.
-   * @return Token.
-   */
-  private static Token<RMDelegationTokenIdentifier> getToken(GetDelegationTokenResponse resp) {
-    org.apache.hadoop.yarn.api.records.Token token = resp.getRMDelegationToken();
-    byte[] identifier = token.getIdentifier().array();
-    byte[] password = token.getPassword().array();
-    Text kind = new Text(token.getKind());
-    Text service = new Text(token.getService());
-    return new Token<>(identifier, password, kind, service);
-  }
-
-  /**
-   * This method updates the expiration for a delegation token from the client.
-   *
-   * @param hsr the servlet request
-   * @return Response containing the status code.
-   * @throws AuthorizationException if Kerberos auth failed.
-   * @throws IOException if the delegation failed.
-   * @throws InterruptedException  if interrupted.
-   * @throws Exception in case of bad request.
-   */
-  @Override
-  public Response postDelegationTokenExpiration(HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException, Exception {
-
-    if (hsr == null) {
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), POST_DELEGATION_TOKEN_EXPIRATION,
-          UNKNOWN, TARGET_WEB_SERVICE, "Parameter error, the hsr is null.");
-      throw new IllegalArgumentException("Parameter error, the hsr is null.");
-    }
-
-    try {
-      // get Caller UserGroupInformation
-      Configuration conf = federationFacade.getConf();
-      UserGroupInformation callerUGI = getKerberosUserGroupInformation(conf, hsr);
-      return renewDelegationToken(hsr, callerUGI);
-    } catch (YarnException e) {
-      LOG.error("Renew delegation token request failed.", e);
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), POST_DELEGATION_TOKEN_EXPIRATION,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      return Response.status(Status.FORBIDDEN).entity(e.getMessage()).build();
-    }
-  }
-
-  /**
-   * Renew DelegationToken.
-   *
-   * @param hsr HttpServletRequest.
-   * @param callerUGI UserGroupInformation.
-   * @return Response
-   * @throws IOException if there are I/O errors.
-   * @throws InterruptedException if any thread has interrupted.
-   */
-  private Response renewDelegationToken(HttpServletRequest hsr, UserGroupInformation callerUGI)
-      throws IOException, InterruptedException {
-
-    // renew Delegation Token
-    DelegationToken tokenData = new DelegationToken();
-    String encodeToken = extractToken(hsr).encodeToUrlString();
-    tokenData.setToken(encodeToken);
-
-    // Parse token data
-    Token<RMDelegationTokenIdentifier> token = extractToken(tokenData.getToken());
-    org.apache.hadoop.yarn.api.records.Token dToken =
-        BuilderUtils.newDelegationToken(token.getIdentifier(), token.getKind().toString(),
-        token.getPassword(), token.getService().toString());
-
-    // Renew token
-    RenewDelegationTokenResponse resp = callerUGI.doAs(
-        (PrivilegedExceptionAction<RenewDelegationTokenResponse>) () -> {
-        RenewDelegationTokenRequest req = RenewDelegationTokenRequest.newInstance(dToken);
-        return this.getRouterClientRMService().renewDelegationToken(req);
-      });
-
-    // return DelegationToken
-    long renewTime = resp.getNextExpirationTime();
-    DelegationToken respToken = new DelegationToken();
-    respToken.setNextExpirationTime(renewTime);
-    RouterAuditLogger.logSuccess(getUser().getShortUserName(), POST_DELEGATION_TOKEN_EXPIRATION,
-        TARGET_WEB_SERVICE);
-    return Response.status(Status.OK).entity(respToken).build();
-  }
-
-  /**
-   * Cancel DelegationToken.
-   *
-   * @param hsr the servlet request
-   * @return  Response containing the status code.
-   * @throws AuthorizationException if Kerberos auth failed.
-   * @throws IOException if the delegation failed.
-   * @throws InterruptedException if interrupted.
-   * @throws Exception in case of bad request.
-   */
-  @Override
-  public Response cancelDelegationToken(HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException, Exception {
-    try {
-      // get Caller UserGroupInformation
-      Configuration conf = federationFacade.getConf();
-      UserGroupInformation callerUGI = getKerberosUserGroupInformation(conf, hsr);
-
-      // parse Token Data
-      Token<RMDelegationTokenIdentifier> token = extractToken(hsr);
-      org.apache.hadoop.yarn.api.records.Token dToken = BuilderUtils
-          .newDelegationToken(token.getIdentifier(), token.getKind().toString(),
-          token.getPassword(), token.getService().toString());
-
-      // cancelDelegationToken
-      callerUGI.doAs((PrivilegedExceptionAction<CancelDelegationTokenResponse>) () -> {
-        CancelDelegationTokenRequest req = CancelDelegationTokenRequest.newInstance(dToken);
-        return this.getRouterClientRMService().cancelDelegationToken(req);
-      });
-
-      RouterAuditLogger.logSuccess(getUser().getShortUserName(), CANCEL_DELEGATIONTOKEN,
-          TARGET_WEB_SERVICE);
-      return Response.status(Status.OK).build();
-    } catch (YarnException e) {
-      LOG.error("Cancel delegation token request failed.", e);
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), CANCEL_DELEGATIONTOKEN,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      return Response.status(Status.FORBIDDEN).entity(e.getMessage()).build();
-    }
-  }
-
-  @Override
-  public Response createNewReservation(HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    long startTime = clock.getTime();
-    try {
-      Map<SubClusterId, SubClusterInfo> subClustersActive =
-          federationFacade.getSubClusters(true);
-      // We declare blackList and retries.
-      List<SubClusterId> blackList = new ArrayList<>();
-      int actualRetryNums = federationFacade.getRetryNumbers(numSubmitRetries);
-      Response response = ((FederationActionRetry<Response>) (retryCount) ->
-          invokeCreateNewReservation(subClustersActive, blackList, hsr, retryCount)).
-          runWithRetries(actualRetryNums, submitIntervalTime);
-      // If the response is not empty and the status is SC_OK,
-      // this request can be returned directly.
-      if (response != null && response.getStatus() == HttpServletResponse.SC_OK) {
-        long stopTime = clock.getTime();
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_NEW_RESERVATION,
-            TARGET_WEB_SERVICE);
-        routerMetrics.succeededGetNewReservationRetrieved(stopTime - startTime);
-        return response;
-      }
-    } catch (FederationPolicyException e) {
-      // If a FederationPolicyException is thrown, the service is unavailable.
-      routerMetrics.incrGetNewReservationFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_NEW_RESERVATION,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      return Response.status(Status.SERVICE_UNAVAILABLE).entity(e.getLocalizedMessage()).build();
-    } catch (Exception e) {
-      routerMetrics.incrGetNewReservationFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_NEW_RESERVATION,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      return Response.status(Status.INTERNAL_SERVER_ERROR).entity(e.getLocalizedMessage()).build();
-    }
-
-    // return error message directly.
-    String errMsg = "Fail to create a new reservation.";
-    LOG.error(errMsg);
-    routerMetrics.incrGetNewReservationFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_NEW_RESERVATION,
-        UNKNOWN, TARGET_WEB_SERVICE, errMsg);
-    return Response.status(Status.INTERNAL_SERVER_ERROR).entity(errMsg).build();
-  }
-
-  private Response invokeCreateNewReservation(Map<SubClusterId, SubClusterInfo> subClustersActive,
-      List<SubClusterId> blackList, HttpServletRequest hsr, int retryCount)
-      throws YarnException {
-    SubClusterId subClusterId = getRandomActiveSubCluster(subClustersActive, blackList);
-    LOG.info("createNewReservation try #{} on SubCluster {}.", retryCount, subClusterId);
-    SubClusterInfo subClusterInfo = subClustersActive.get(subClusterId);
-    DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorForSubCluster(
-        subClusterId, subClusterInfo.getRMWebServiceAddress());
-    try {
-      Response response = interceptor.createNewReservation(hsr);
-      if (response != null && response.getStatus() == HttpServletResponse.SC_OK) {
-        return response;
-      }
-    } catch (Exception e) {
-      blackList.add(subClusterId);
-      RouterServerUtil.logAndThrowException(e.getMessage(), e);
-    }
-    // We need to throw the exception directly.
-    String msg = String.format("Unable to create a new ReservationId in SubCluster %s.",
-        subClusterId.getId());
-    throw new YarnException(msg);
-  }
-
-  @Override
-  public Response submitReservation(ReservationSubmissionRequestInfo resContext,
-      HttpServletRequest hsr) throws AuthorizationException, IOException, InterruptedException {
-    long startTime = clock.getTime();
-    if (resContext == null || resContext.getReservationId() == null
-        || resContext.getReservationDefinition() == null || resContext.getQueue() == null) {
-      routerMetrics.incrSubmitReservationFailedRetrieved();
-      String errMsg = "Missing submitReservation resContext or reservationId " +
-          "or reservation definition or queue.";
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), SUBMIT_RESERVATION,
-          UNKNOWN, TARGET_WEB_SERVICE, errMsg);
-      return Response.status(Status.BAD_REQUEST).entity(errMsg).build();
-    }
-
-    // Check that the resId format is accurate
-    String resId = resContext.getReservationId();
-    try {
-      RouterServerUtil.validateReservationId(resId);
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrSubmitReservationFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), SUBMIT_RESERVATION,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      throw e;
-    }
-
-    List<SubClusterId> blackList = new ArrayList<>();
-    try {
-      int activeSubClustersCount = federationFacade.getActiveSubClustersCount();
-      int actualRetryNums = Math.min(activeSubClustersCount, numSubmitRetries);
-      Response response = ((FederationActionRetry<Response>) (retryCount) ->
-          invokeSubmitReservation(resContext, blackList, hsr, retryCount)).
-          runWithRetries(actualRetryNums, submitIntervalTime);
-      if (response != null) {
-        long stopTime = clock.getTime();
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), SUBMIT_RESERVATION,
-            TARGET_WEB_SERVICE);
-        routerMetrics.succeededSubmitReservationRetrieved(stopTime - startTime);
-        return response;
-      }
-    } catch (Exception e) {
-      routerMetrics.incrSubmitReservationFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), SUBMIT_RESERVATION,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      return Response.status(Status.SERVICE_UNAVAILABLE).entity(e.getLocalizedMessage()).build();
-    }
-
-    routerMetrics.incrSubmitReservationFailedRetrieved();
-    String msg = String.format("Reservation %s failed to be submitted.", resId);
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), SUBMIT_RESERVATION,
-        UNKNOWN, TARGET_WEB_SERVICE, msg);
-    return Response.status(Status.SERVICE_UNAVAILABLE).entity(msg).build();
-  }
-
-  private Response invokeSubmitReservation(ReservationSubmissionRequestInfo requestContext,
-      List<SubClusterId> blackList, HttpServletRequest hsr, int retryCount)
-      throws YarnException, IOException, InterruptedException {
-    String resId = requestContext.getReservationId();
-    ReservationId reservationId = ReservationId.parseReservationId(resId);
-    ReservationDefinitionInfo definitionInfo = requestContext.getReservationDefinition();
-    ReservationDefinition definition =
-         RouterServerUtil.convertReservationDefinition(definitionInfo);
-
-    // First, Get SubClusterId according to specific strategy.
-    ReservationSubmissionRequest request = ReservationSubmissionRequest.newInstance(
-        definition, requestContext.getQueue(), reservationId);
-    SubClusterId subClusterId = null;
-
-    try {
-      // Get subClusterId from policy.
-      subClusterId = policyFacade.getReservationHomeSubCluster(request);
-
-      // Print the log of submitting the submitApplication.
-      LOG.info("submitReservation ReservationId {} try #{} on SubCluster {}.", reservationId,
-          retryCount, subClusterId);
-
-      // Step2. We Store the mapping relationship
-      // between Application and HomeSubCluster in stateStore.
-      federationFacade.addOrUpdateReservationHomeSubCluster(reservationId,
-          subClusterId, retryCount);
-
-      // Step3. We get subClusterInfo based on subClusterId.
-      SubClusterInfo subClusterInfo = federationFacade.getSubCluster(subClusterId);
-
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorForSubCluster(
-          subClusterInfo.getSubClusterId(), subClusterInfo.getRMWebServiceAddress());
-      HttpServletRequest hsrCopy = clone(hsr);
-      Response response = interceptor.submitReservation(requestContext, hsrCopy);
-      if (response != null && response.getStatus() == HttpServletResponse.SC_ACCEPTED) {
-        LOG.info("Reservation {} submitted on subCluster {}.", reservationId, subClusterId);
-        return response;
-      }
-      String msg = String.format("application %s failed to be submitted.", resId);
-      throw new YarnException(msg);
-    } catch (Exception e) {
-      LOG.warn("Unable to submit the reservation {} to SubCluster {}.", resId,
-          subClusterId, e);
-      if (subClusterId != null) {
-        blackList.add(subClusterId);
-      }
-      throw e;
-    }
-  }
-
-  @Override
-  public Response updateReservation(ReservationUpdateRequestInfo resContext,
-      HttpServletRequest hsr) throws AuthorizationException, IOException, InterruptedException {
-
-    // parameter verification
-    if (resContext == null || resContext.getReservationId() == null
-        || resContext.getReservationDefinition() == null) {
-      routerMetrics.incrUpdateReservationFailedRetrieved();
-      String errMsg = "Missing updateReservation resContext or reservationId " +
-          "or reservation definition.";
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_RESERVATION,
-          UNKNOWN, TARGET_WEB_SERVICE, errMsg);
-      return Response.status(Status.BAD_REQUEST).entity(errMsg).build();
-    }
-
-    // get reservationId
-    String reservationId = resContext.getReservationId();
-
-    // Check that the reservationId format is accurate
-    try {
-      RouterServerUtil.validateReservationId(reservationId);
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrUpdateReservationFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_RESERVATION,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      throw e;
-    }
-
-    try {
-      SubClusterInfo subClusterInfo = getHomeSubClusterInfoByReservationId(reservationId);
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorForSubCluster(
-          subClusterInfo.getSubClusterId(), subClusterInfo.getRMWebServiceAddress());
-      HttpServletRequest hsrCopy = clone(hsr);
-      Response response = interceptor.updateReservation(resContext, hsrCopy);
-      if (response != null) {
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), UPDATE_RESERVATION,
-            TARGET_WEB_SERVICE);
-        return response;
-      }
-    } catch (Exception e) {
-      routerMetrics.incrUpdateReservationFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_RESERVATION,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("updateReservation Failed.", e);
-    }
-
-    // throw an exception
-    routerMetrics.incrUpdateReservationFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_RESERVATION,
-        UNKNOWN, TARGET_WEB_SERVICE, "updateReservation Failed, reservationId = " + reservationId);
-    throw new YarnRuntimeException("updateReservation Failed, reservationId = " + reservationId);
-  }
-
-  @Override
-  public Response deleteReservation(ReservationDeleteRequestInfo resContext,
-      HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-
-    // parameter verification
-    if (resContext == null || resContext.getReservationId() == null) {
-      routerMetrics.incrDeleteReservationFailedRetrieved();
-      String errMsg = "Missing deleteReservation request or reservationId.";
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), DELETE_RESERVATION,
-          UNKNOWN, TARGET_WEB_SERVICE, errMsg);
-      return Response.status(Status.BAD_REQUEST).entity(errMsg).build();
-    }
-
-    // get ReservationId
-    String reservationId = resContext.getReservationId();
-
-    // Check that the reservationId format is accurate
-    try {
-      RouterServerUtil.validateReservationId(reservationId);
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrDeleteReservationFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), DELETE_RESERVATION,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      throw e;
-    }
-
-    try {
-      SubClusterInfo subClusterInfo = getHomeSubClusterInfoByReservationId(reservationId);
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorForSubCluster(
-          subClusterInfo.getSubClusterId(), subClusterInfo.getRMWebServiceAddress());
-      HttpServletRequest hsrCopy = clone(hsr);
-      Response response = interceptor.deleteReservation(resContext, hsrCopy);
-      if (response != null) {
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), DELETE_RESERVATION,
-            TARGET_WEB_SERVICE);
-        return response;
-      }
-    } catch (Exception e) {
-      routerMetrics.incrDeleteReservationFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), DELETE_RESERVATION,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("deleteReservation Failed.", e);
-    }
-
-    // throw an exception
-    routerMetrics.incrDeleteReservationFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), DELETE_RESERVATION,
-        UNKNOWN, TARGET_WEB_SERVICE, "deleteReservation Failed, reservationId = " + reservationId);
-    throw new YarnRuntimeException("deleteReservation Failed, reservationId = " + reservationId);
-  }
-
-  @Override
-  public Response listReservation(String queue, String reservationId,
-      long startTime, long endTime, boolean includeResourceAllocations,
-      HttpServletRequest hsr) throws Exception {
-
-    if (queue == null || queue.isEmpty()) {
-      routerMetrics.incrListReservationFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), LIST_RESERVATIONS,
-          UNKNOWN, TARGET_WEB_SERVICE, "Parameter error, the queue is empty or null.");
-      throw new IllegalArgumentException("Parameter error, the queue is empty or null.");
-    }
-
-    if (reservationId == null || reservationId.isEmpty()) {
-      routerMetrics.incrListReservationFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), LIST_RESERVATIONS,
-          UNKNOWN, TARGET_WEB_SERVICE, "Parameter error, the reservationId is empty or null.");
-      throw new IllegalArgumentException("Parameter error, the reservationId is empty or null.");
-    }
-
-    // Check that the reservationId format is accurate
-    try {
-      RouterServerUtil.validateReservationId(reservationId);
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrListReservationFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), LIST_RESERVATIONS,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      throw e;
-    }
-
-    try {
-      long startTime1 = clock.getTime();
-      SubClusterInfo subClusterInfo = getHomeSubClusterInfoByReservationId(reservationId);
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorForSubCluster(
-          subClusterInfo.getSubClusterId(), subClusterInfo.getRMWebServiceAddress());
-      HttpServletRequest hsrCopy = clone(hsr);
-      Response response = interceptor.listReservation(queue, reservationId, startTime, endTime,
-          includeResourceAllocations, hsrCopy);
-      if (response != null) {
-        long stopTime = clock.getTime();
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), LIST_RESERVATIONS,
-            TARGET_WEB_SERVICE);
-        routerMetrics.succeededListReservationRetrieved(stopTime - startTime1);
-        return response;
-      }
-    } catch (YarnException e) {
-      routerMetrics.incrListReservationFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), LIST_RESERVATIONS,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("listReservation error.", e);
-    }
-
-    routerMetrics.incrListReservationFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), LIST_RESERVATIONS,
-        UNKNOWN, TARGET_WEB_SERVICE, "listReservation Failed.");
-    throw new YarnException("listReservation Failed.");
-  }
-
-  @Override
-  public AppTimeoutInfo getAppTimeout(HttpServletRequest hsr, String appId,
-      String type) throws AuthorizationException {
-
-    if (type == null || type.isEmpty()) {
-      routerMetrics.incrGetAppTimeoutFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APP_TIMEOUT,
-          UNKNOWN, TARGET_WEB_SERVICE, "Parameter error, the type is empty or null.");
-      throw new IllegalArgumentException("Parameter error, the type is empty or null.");
-    }
-
-    try {
-      long startTime = clock.getTime();
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorByAppId(appId);
-      AppTimeoutInfo appTimeoutInfo = interceptor.getAppTimeout(hsr, appId, type);
-      if (appTimeoutInfo != null) {
-        long stopTime = clock.getTime();
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_APP_TIMEOUT,
-            TARGET_WEB_SERVICE);
-        routerMetrics.succeededGetAppTimeoutRetrieved((stopTime - startTime));
-        return appTimeoutInfo;
-      }
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrGetAppTimeoutFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APP_TIMEOUT,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e,
-          "Unable to get the getAppTimeout appId: %s.", appId);
-    } catch (YarnException e) {
-      routerMetrics.incrGetAppTimeoutFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APP_TIMEOUT,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("getAppTimeout error.", e);
-    }
-    routerMetrics.incrGetAppTimeoutFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APP_TIMEOUT,
-        UNKNOWN, TARGET_WEB_SERVICE, "getAppTimeout Failed.");
-    throw new RuntimeException("getAppTimeout Failed.");
-  }
-
-  @Override
-  public AppTimeoutsInfo getAppTimeouts(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-
-    try {
-      long startTime = clock.getTime();
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorByAppId(appId);
-      AppTimeoutsInfo appTimeoutsInfo = interceptor.getAppTimeouts(hsr, appId);
-      if (appTimeoutsInfo != null) {
-        long stopTime = clock.getTime();
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_APP_TIMEOUTS,
-            TARGET_WEB_SERVICE);
-        routerMetrics.succeededGetAppTimeoutsRetrieved((stopTime - startTime));
-        return appTimeoutsInfo;
-      }
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrGetAppTimeoutsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APP_TIMEOUTS,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e,
-          "Unable to get the getAppTimeouts appId: %s.", appId);
-    } catch (YarnException e) {
-      routerMetrics.incrGetAppTimeoutsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APP_TIMEOUTS,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("getAppTimeouts error.", e);
-    }
-
-    routerMetrics.incrGetAppTimeoutsFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APP_TIMEOUTS,
-        UNKNOWN, TARGET_WEB_SERVICE, "getAppTimeouts Failed.");
-    throw new RuntimeException("getAppTimeouts Failed.");
-  }
-
-  @Override
-  public Response updateApplicationTimeout(AppTimeoutInfo appTimeout,
-      HttpServletRequest hsr, String appId) throws AuthorizationException,
-      YarnException, InterruptedException, IOException {
-
-    if (appTimeout == null) {
-      routerMetrics.incrUpdateApplicationTimeoutsRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_APPLICATIONTIMEOUTS,
-          UNKNOWN, TARGET_WEB_SERVICE, "Parameter error, the appTimeout is null.");
-      throw new IllegalArgumentException("Parameter error, the appTimeout is null.");
-    }
-
-    try {
-      long startTime = Time.now();
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorByAppId(appId);
-      Response response = interceptor.updateApplicationTimeout(appTimeout, hsr, appId);
-      if (response != null) {
-        long stopTime = clock.getTime();
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), UPDATE_APPLICATIONTIMEOUTS,
-            TARGET_WEB_SERVICE);
-        routerMetrics.succeededUpdateAppTimeoutsRetrieved((stopTime - startTime));
-        return response;
-      }
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrUpdateApplicationTimeoutsRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_APPLICATIONTIMEOUTS,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e,
-          "Unable to get the updateApplicationTimeout appId: %s.", appId);
-    } catch (YarnException e) {
-      routerMetrics.incrUpdateApplicationTimeoutsRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_APPLICATIONTIMEOUTS,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("updateApplicationTimeout error.", e);
-    }
-
-    routerMetrics.incrUpdateApplicationTimeoutsRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_APPLICATIONTIMEOUTS,
-        UNKNOWN, TARGET_WEB_SERVICE, "updateApplicationTimeout Failed.");
-    throw new RuntimeException("updateApplicationTimeout Failed.");
-  }
-
-  @Override
-  public AppAttemptsInfo getAppAttempts(HttpServletRequest hsr, String appId) {
-
-    try {
-      long startTime = Time.now();
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorByAppId(appId);
-      AppAttemptsInfo appAttemptsInfo = interceptor.getAppAttempts(hsr, appId);
-      if (appAttemptsInfo != null) {
-        long stopTime = Time.now();
-        routerMetrics.succeededAppAttemptsRetrieved(stopTime - startTime);
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_APPLICATION_ATTEMPTS,
-            TARGET_WEB_SERVICE);
-        return appAttemptsInfo;
-      }
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrAppAttemptsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APPLICATION_ATTEMPTS,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e,
-          "Unable to get the AppAttempt appId: %s.", appId);
-    } catch (YarnException e) {
-      routerMetrics.incrAppAttemptsFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APPLICATION_ATTEMPTS,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("getAppAttempts error.", e);
-    }
-
-    routerMetrics.incrAppAttemptsFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APPLICATION_ATTEMPTS,
-        UNKNOWN, TARGET_WEB_SERVICE, "getAppAttempts Failed.");
-    throw new RuntimeException("getAppAttempts Failed.");
-  }
-
-  @Override
-  public RMQueueAclInfo checkUserAccessToQueue(String queue, String username,
-      String queueAclType, HttpServletRequest hsr) throws AuthorizationException {
-
-    // Parameter Verification
-    if (queue == null || queue.isEmpty()) {
-      routerMetrics.incrCheckUserAccessToQueueFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), CHECK_USER_ACCESS_TO_QUEUE,
-          UNKNOWN, TARGET_WEB_SERVICE, "Parameter error, the queue is empty or null.");
-      throw new IllegalArgumentException("Parameter error, the queue is empty or null.");
-    }
-
-    if (username == null || username.isEmpty()) {
-      routerMetrics.incrCheckUserAccessToQueueFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), CHECK_USER_ACCESS_TO_QUEUE,
-          UNKNOWN, TARGET_WEB_SERVICE, "Parameter error, the username is empty or null.");
-      throw new IllegalArgumentException("Parameter error, the username is empty or null.");
-    }
-
-    if (queueAclType == null || queueAclType.isEmpty()) {
-      routerMetrics.incrCheckUserAccessToQueueFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), CHECK_USER_ACCESS_TO_QUEUE,
-          UNKNOWN, TARGET_WEB_SERVICE, "Parameter error, the queueAclType is empty or null.");
-      throw new IllegalArgumentException("Parameter error, the queueAclType is empty or null.");
-    }
-
-    // Traverse SubCluster and call checkUserAccessToQueue Api
-    try {
-      long startTime = Time.now();
-      Collection<SubClusterInfo> subClustersActive = federationFacade.getActiveSubClusters();
-      final HttpServletRequest hsrCopy = clone(hsr);
-      Class[] argsClasses = new Class[]{String.class, String.class, String.class,
-          HttpServletRequest.class};
-      Object[] args = new Object[]{queue, username, queueAclType, hsrCopy};
-      ClientMethod remoteMethod = new ClientMethod("checkUserAccessToQueue", argsClasses, args);
-      Map<SubClusterInfo, RMQueueAclInfo> rmQueueAclInfoMap =
-          invokeConcurrent(subClustersActive, remoteMethod, RMQueueAclInfo.class);
-      FederationRMQueueAclInfo aclInfo = new FederationRMQueueAclInfo();
-      rmQueueAclInfoMap.forEach((subClusterInfo, rMQueueAclInfo) -> {
-        SubClusterId subClusterId = subClusterInfo.getSubClusterId();
-        rMQueueAclInfo.setSubClusterId(subClusterId.getId());
-        aclInfo.getList().add(rMQueueAclInfo);
-      });
-      long stopTime = Time.now();
-      RouterAuditLogger.logSuccess(getUser().getShortUserName(), CHECK_USER_ACCESS_TO_QUEUE,
-          TARGET_WEB_SERVICE);
-      routerMetrics.succeededCheckUserAccessToQueueRetrieved(stopTime - startTime);
-      return aclInfo;
-    } catch (NotFoundException e) {
-      routerMetrics.incrCheckUserAccessToQueueFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), CHECK_USER_ACCESS_TO_QUEUE,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("Get all active sub cluster(s) error.", e);
-    } catch (YarnException | IOException e) {
-      routerMetrics.incrCheckUserAccessToQueueFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), CHECK_USER_ACCESS_TO_QUEUE,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("checkUserAccessToQueue error.", e);
-    }
-
-    routerMetrics.incrCheckUserAccessToQueueFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), CHECK_USER_ACCESS_TO_QUEUE,
-        UNKNOWN, TARGET_WEB_SERVICE, "checkUserAccessToQueue error.");
-    throw new RuntimeException("checkUserAccessToQueue error.");
-  }
-
-  @Override
-  public AppAttemptInfo getAppAttempt(HttpServletRequest req,
-      HttpServletResponse res, String appId, String appAttemptId) {
-
-    // Check that the appId/appAttemptId format is accurate
-    try {
-      RouterServerUtil.validateApplicationAttemptId(appAttemptId);
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrAppAttemptReportFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APP_ATTEMPT,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      throw e;
-    }
-
-    // Call the getAppAttempt method
-    try {
-      long startTime = Time.now();
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorByAppId(appId);
-      AppAttemptInfo appAttemptInfo = interceptor.getAppAttempt(req, res, appId, appAttemptId);
-      if (appAttemptInfo != null) {
-        long stopTime = Time.now();
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_APP_ATTEMPT,
-            TARGET_WEB_SERVICE);
-        routerMetrics.succeededAppAttemptReportRetrieved(stopTime - startTime);
-        return appAttemptInfo;
-      }
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrAppAttemptReportFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APP_ATTEMPT,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e,
-          "Unable to getAppAttempt by appId: %s, appAttemptId: %s.", appId, appAttemptId);
-    } catch (YarnException e) {
-      routerMetrics.incrAppAttemptReportFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APP_ATTEMPT,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e,
-          "getAppAttempt error, appId: %s, appAttemptId: %s.", appId, appAttemptId);
-    }
-
-    routerMetrics.incrAppAttemptReportFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_APP_ATTEMPT,
-        UNKNOWN, TARGET_WEB_SERVICE, "getAppAttempt failed.");
-    throw RouterServerUtil.logAndReturnRunTimeException(
-        "getAppAttempt failed, appId: %s, appAttemptId: %s.", appId, appAttemptId);
-  }
-
-  @Override
-  public ContainersInfo getContainers(HttpServletRequest req,
-      HttpServletResponse res, String appId, String appAttemptId) {
-
-    // Check that the appId/appAttemptId format is accurate
-    try {
-      RouterServerUtil.validateApplicationId(appId);
-      RouterServerUtil.validateApplicationAttemptId(appAttemptId);
-    } catch (IllegalArgumentException e) {
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_CONTAINERS,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      routerMetrics.incrGetContainersFailedRetrieved();
-      throw e;
-    }
-
-    try {
-      long startTime = clock.getTime();
-      ContainersInfo containersInfo = new ContainersInfo();
-      Collection<SubClusterInfo> subClustersActive = federationFacade.getActiveSubClusters();
-      Class[] argsClasses = new Class[]{
-          HttpServletRequest.class, HttpServletResponse.class, String.class, String.class};
-      Object[] args = new Object[]{req, res, appId, appAttemptId};
-      ClientMethod remoteMethod = new ClientMethod("getContainers", argsClasses, args);
-      Map<SubClusterInfo, ContainersInfo> containersInfoMap =
-          invokeConcurrent(subClustersActive, remoteMethod, ContainersInfo.class);
-      if (containersInfoMap != null && !containersInfoMap.isEmpty()) {
-        containersInfoMap.values().forEach(containers ->
-            containersInfo.addAll(containers.getContainers()));
-      }
-      if (containersInfo != null) {
-        long stopTime = clock.getTime();
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_CONTAINERS,
-            TARGET_WEB_SERVICE);
-        routerMetrics.succeededGetContainersRetrieved(stopTime - startTime);
-        return containersInfo;
-      }
-    } catch (NotFoundException e) {
-      routerMetrics.incrGetContainersFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_CONTAINERS,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e, "getContainers error, appId = %s, " +
-          " appAttemptId = %s, Probably getActiveSubclusters error.", appId, appAttemptId);
-    } catch (IOException | YarnException e) {
-      routerMetrics.incrGetContainersFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_CONTAINERS,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e, "getContainers error, appId = %s, " +
-          " appAttemptId = %s.", appId, appAttemptId);
-    }
-
-    routerMetrics.incrGetContainersFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_CONTAINERS,
-        UNKNOWN, TARGET_WEB_SERVICE, "getContainers failed.");
-    throw RouterServerUtil.logAndReturnRunTimeException(
-        "getContainers failed, appId: %s, appAttemptId: %s.", appId, appAttemptId);
-  }
-
-  @Override
-  public ContainerInfo getContainer(HttpServletRequest req,
-      HttpServletResponse res, String appId, String appAttemptId,
-      String containerId) {
-
-    // FederationInterceptorREST#getContainer is logically
-    // the same as FederationClientInterceptor#getContainerReport,
-    // so use the same Metric.
-
-    // Check that the appId/appAttemptId/containerId format is accurate
-    try {
-      RouterServerUtil.validateApplicationAttemptId(appAttemptId);
-      RouterServerUtil.validateContainerId(containerId);
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrGetContainerReportFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_CONTAINER,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      throw e;
-    }
-
-    try {
-      long startTime = Time.now();
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorByAppId(appId);
-      ContainerInfo containerInfo =
-          interceptor.getContainer(req, res, appId, appAttemptId, containerId);
-      if (containerInfo != null) {
-        long stopTime = Time.now();
-        routerMetrics.succeededGetContainerReportRetrieved(stopTime - startTime);
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_CONTAINER,
-            TARGET_WEB_SERVICE);
-        return containerInfo;
-      }
-    } catch (IllegalArgumentException e) {
-      String msg = String.format(
-          "Unable to get the AppAttempt appId: %s, appAttemptId: %s, containerId: %s.", appId,
-          appAttemptId, containerId);
-      routerMetrics.incrGetContainerReportFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_CONTAINER,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(msg, e);
-    } catch (YarnException e) {
-      routerMetrics.incrGetContainerReportFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_CONTAINER,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("getContainer Failed.", e);
-    }
-
-    routerMetrics.incrGetContainerReportFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_CONTAINER,
-        UNKNOWN, TARGET_WEB_SERVICE, "getContainer Failed.");
-    throw new RuntimeException("getContainer Failed.");
-  }
-
-  /**
-   * This method updates the Scheduler configuration, and it is reachable by
-   * using {@link RMWSConsts#SCHEDULER_CONF}.
-   *
-   * @param mutationInfo th information for making scheduler configuration
-   *        changes (supports adding, removing, or updating a queue, as well
-   *        as global scheduler conf changes)
-   * @param hsr the servlet request
-   * @return Response containing the status code
-   * @throws AuthorizationException if the user is not authorized to invoke this
-   *         method
-   * @throws InterruptedException if interrupted
-   */
-  @Override
-  public Response updateSchedulerConfiguration(SchedConfUpdateInfo mutationInfo,
-      HttpServletRequest hsr) throws AuthorizationException, InterruptedException {
-
-    // Make Sure mutationInfo is not null.
-    if (mutationInfo == null) {
-      routerMetrics.incrUpdateSchedulerConfigurationFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_SCHEDULER_CONFIGURATION,
-          UNKNOWN, TARGET_WEB_SERVICE,
-          "Parameter error, the schedConfUpdateInfo is empty or null.");
-      throw new IllegalArgumentException(
-          "Parameter error, the schedConfUpdateInfo is empty or null.");
-    }
-
-    // In federated mode, we may have a mix of multiple schedulers.
-    // In order to ensure accurate update scheduler configuration,
-    // we need users to explicitly set subClusterId.
-    String pSubClusterId = mutationInfo.getSubClusterId();
-    if (StringUtils.isBlank(pSubClusterId)) {
-      routerMetrics.incrUpdateSchedulerConfigurationFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_SCHEDULER_CONFIGURATION,
-          UNKNOWN, TARGET_WEB_SERVICE,
-          "Parameter error, the subClusterId is empty or null.");
-      throw new IllegalArgumentException("Parameter error, " +
-          "the subClusterId is empty or null.");
-    }
-
-    // Get the subClusterInfo , then update the scheduler configuration.
-    try {
-      long startTime = clock.getTime();
-      SubClusterInfo subClusterInfo = getActiveSubCluster(pSubClusterId);
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorForSubCluster(
-          subClusterInfo.getSubClusterId(), subClusterInfo.getRMWebServiceAddress());
-      Response response = interceptor.updateSchedulerConfiguration(mutationInfo, hsr);
-      if (response != null) {
-        long endTime = clock.getTime();
-        routerMetrics.succeededUpdateSchedulerConfigurationRetrieved(endTime - startTime);
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), UPDATE_SCHEDULER_CONFIGURATION,
-            TARGET_WEB_SERVICE);
-        return Response.status(response.getStatus()).entity(response.getEntity()).build();
-      }
-    } catch (NotFoundException e) {
-      routerMetrics.incrUpdateSchedulerConfigurationFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_SCHEDULER_CONFIGURATION,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e,
-          "Get subCluster error. subClusterId = %s", pSubClusterId);
-    } catch (Exception e) {
-      routerMetrics.incrUpdateSchedulerConfigurationFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_SCHEDULER_CONFIGURATION,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException(e,
-          "UpdateSchedulerConfiguration error. subClusterId = %s", pSubClusterId);
-    }
-
-    routerMetrics.incrUpdateSchedulerConfigurationFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), UPDATE_SCHEDULER_CONFIGURATION,
-        UNKNOWN, TARGET_WEB_SERVICE, "UpdateSchedulerConfiguration Failed.");
-    throw new RuntimeException("UpdateSchedulerConfiguration error. subClusterId = "
-        + pSubClusterId);
-  }
-
-  /**
-   * This method retrieves all the Scheduler configuration, and it is reachable
-   * by using {@link RMWSConsts#SCHEDULER_CONF}.
-   *
-   * @param hsr the servlet request
-   * @return Response containing the status code
-   * @throws AuthorizationException if the user is not authorized to invoke this
-   *      method.
-   */
-  @Override
-  public Response getSchedulerConfiguration(HttpServletRequest hsr)
-      throws AuthorizationException {
-    try {
-      long startTime = clock.getTime();
-      FederationConfInfo federationConfInfo = new FederationConfInfo();
-      Collection<SubClusterInfo> subClustersActive = federationFacade.getActiveSubClusters();
-      final HttpServletRequest hsrCopy = clone(hsr);
-      Class[] argsClasses = new Class[]{HttpServletRequest.class};
-      Object[] args = new Object[]{hsrCopy};
-      ClientMethod remoteMethod = new ClientMethod("getSchedulerConfiguration", argsClasses, args);
-      Map<SubClusterInfo, Response> responseMap =
-          invokeConcurrent(subClustersActive, remoteMethod, Response.class);
-      responseMap.forEach((subClusterInfo, response) -> {
-        SubClusterId subClusterId = subClusterInfo.getSubClusterId();
-        if (response == null) {
-          String errorMsg = subClusterId + " Can't getSchedulerConfiguration.";
-          federationConfInfo.getErrorMsgs().add(errorMsg);
-        } else if (response.getStatus() == Status.BAD_REQUEST.getStatusCode()) {
-          String errorMsg = String.valueOf(response.getEntity());
-          federationConfInfo.getErrorMsgs().add(errorMsg);
-        } else if (response.getStatus() == Status.OK.getStatusCode()) {
-          ConfInfo fedConfInfo = (ConfInfo) response.getEntity();
-          fedConfInfo.setSubClusterId(subClusterId.getId());
-          federationConfInfo.getList().add(fedConfInfo);
-        }
-      });
-      long endTime = clock.getTime();
-      routerMetrics.succeededGetSchedulerConfigurationRetrieved(endTime - startTime);
-      RouterAuditLogger.logSuccess(getUser().getShortUserName(), GET_SCHEDULER_CONFIGURATION,
-          TARGET_WEB_SERVICE);
-      return Response.status(Status.OK).entity(federationConfInfo).build();
-    } catch (NotFoundException e) {
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_SCHEDULER_CONFIGURATION,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      routerMetrics.incrGetSchedulerConfigurationFailedRetrieved();
-      RouterServerUtil.logAndThrowRunTimeException("get all active sub cluster(s) error.", e);
-    } catch (Exception e) {
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_SCHEDULER_CONFIGURATION,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      routerMetrics.incrGetSchedulerConfigurationFailedRetrieved();
-      return Response.status(Status.BAD_REQUEST).entity("getSchedulerConfiguration error.").build();
-    }
-
-    routerMetrics.incrGetSchedulerConfigurationFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), GET_SCHEDULER_CONFIGURATION,
-        UNKNOWN, TARGET_WEB_SERVICE, "getSchedulerConfiguration Failed.");
-    throw new RuntimeException("getSchedulerConfiguration Failed.");
-  }
-
-  @Override
-  public void setNextInterceptor(RESTRequestInterceptor next) {
-    throw new YarnRuntimeException("setNextInterceptor is being called on "
-        + "FederationInterceptorREST, which should be the last one "
-        + "in the chain. Check if the interceptor pipeline configuration "
-        + "is correct");
-  }
-
-  @Override
-  public Response signalToContainer(String containerId, String command,
-      HttpServletRequest req) {
-
-    // Check if containerId is empty or null
-    try {
-      RouterServerUtil.validateContainerId(containerId);
-    } catch (IllegalArgumentException e) {
-      routerMetrics.incrSignalToContainerFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), SIGNAL_TOCONTAINER,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      throw e;
-    }
-
-    // Check if command is empty or null
-    if (command == null || command.isEmpty()) {
-      routerMetrics.incrSignalToContainerFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), SIGNAL_TOCONTAINER,
-          UNKNOWN, TARGET_WEB_SERVICE, "Parameter error, the command is empty or null.");
-      throw new IllegalArgumentException("Parameter error, the command is empty or null.");
-    }
-
-    try {
-      long startTime = Time.now();
-
-      ContainerId containerIdObj = ContainerId.fromString(containerId);
-      ApplicationId applicationId = containerIdObj.getApplicationAttemptId().getApplicationId();
-      SubClusterInfo subClusterInfo = getHomeSubClusterInfoByAppId(applicationId.toString());
-      DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorForSubCluster(
-          subClusterInfo.getSubClusterId(), subClusterInfo.getRMWebServiceAddress());
-
-      Response response = interceptor.signalToContainer(containerId, command, req);
-      if (response != null) {
-        long stopTime = Time.now();
-        RouterAuditLogger.logSuccess(getUser().getShortUserName(), SIGNAL_TOCONTAINER,
-            TARGET_WEB_SERVICE);
-        routerMetrics.succeededSignalToContainerRetrieved(stopTime - startTime);
-        return response;
-      }
-    } catch (YarnException e) {
-      routerMetrics.incrSignalToContainerFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), SIGNAL_TOCONTAINER,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("signalToContainer Failed.", e);
-    } catch (AuthorizationException e) {
-      routerMetrics.incrSignalToContainerFailedRetrieved();
-      RouterAuditLogger.logFailure(getUser().getShortUserName(), SIGNAL_TOCONTAINER,
-          UNKNOWN, TARGET_WEB_SERVICE, e.getLocalizedMessage());
-      RouterServerUtil.logAndThrowRunTimeException("signalToContainer Author Failed.", e);
-    }
-
-    routerMetrics.incrSignalToContainerFailedRetrieved();
-    RouterAuditLogger.logFailure(getUser().getShortUserName(), SIGNAL_TOCONTAINER,
-        UNKNOWN, TARGET_WEB_SERVICE, "signalToContainer Failed.");
-    throw new RuntimeException("signalToContainer Failed.");
-  }
-
-  @Override
-  public void shutdown() {
-    if (threadpool != null) {
-      threadpool.shutdown();
-    }
-  }
-
-  private <R> Map<SubClusterInfo, R> invokeConcurrent(Collection<SubClusterInfo> clusterIds,
-      ClientMethod request, Class<R> clazz) throws YarnException {
-
-    Map<SubClusterInfo, R> results = new HashMap<>();
-
-    // If there is a sub-cluster access error,
-    // we should choose whether to throw exception information according to user configuration.
-    // Send the requests in parallel.
-    CompletionService<SubClusterResult<R>> compSvc = new ExecutorCompletionService<>(threadpool);
-
-    // This part of the code should be able to expose the accessed Exception information.
-    // We use Pair to store related information. The left value of the Pair is the response,
-    // and the right value is the exception.
-    // If the request is normal, the response is not empty and the exception is empty;
-    // if the request is abnormal, the response is empty and the exception is not empty.
-    for (final SubClusterInfo info : clusterIds) {
-      compSvc.submit(() -> {
-        DefaultRequestInterceptorREST interceptor = getOrCreateInterceptorForSubCluster(
-            info.getSubClusterId(), info.getRMWebServiceAddress());
-        try {
-          Method method = DefaultRequestInterceptorREST.class.
-              getMethod(request.getMethodName(), request.getTypes());
-          Object retObj = method.invoke(interceptor, request.getParams());
-          R ret = clazz.cast(retObj);
-          return new SubClusterResult<>(info, ret, null);
-        } catch (Exception e) {
-          LOG.error("SubCluster {} failed to call {} method.",
-              info.getSubClusterId(), request.getMethodName(), e);
-          return new SubClusterResult<>(info, null, e);
-        }
-      });
-    }
-
-    for (int i = 0; i < clusterIds.size(); i++) {
-      SubClusterInfo subClusterInfo = null;
-      try {
-        Future<SubClusterResult<R>> future = compSvc.take();
-        SubClusterResult<R> result = future.get();
-        subClusterInfo = result.getSubClusterInfo();
-
-        R response = result.getResponse();
-        if (response != null) {
-          results.put(subClusterInfo, response);
-        }
-
-        Exception exception = result.getException();
-        if (exception != null) {
-          throw exception;
-        }
-      } catch (Throwable e) {
-        String subClusterId = subClusterInfo != null ?
-            subClusterInfo.getSubClusterId().getId() : "UNKNOWN";
-        LOG.error("SubCluster {} failed to {} report.", subClusterId, request.getMethodName(), e);
-        // If allowPartialResult=false, it means that if an exception occurs in a subCluster,
-        // an exception will be thrown directly.
-        if (!allowPartialResult) {
-          throw new YarnException("SubCluster " + subClusterId +
-              " failed to " + request.getMethodName() + " report.", e);
-        }
-      }
-    }
-
-    return results;
-  }
-
-  /**
-   * get the HomeSubCluster according to ApplicationId.
-   *
-   * @param appId applicationId
-   * @return HomeSubCluster
-   * @throws YarnException on failure
-   */
-  private SubClusterInfo getHomeSubClusterInfoByAppId(String appId)
-      throws YarnException {
-
-    if (StringUtils.isBlank(appId)) {
-      throw new IllegalArgumentException("applicationId can't null or empty.");
-    }
-
-    try {
-      ApplicationId applicationId = ApplicationId.fromString(appId);
-      SubClusterId subClusterId = federationFacade.getApplicationHomeSubCluster(applicationId);
-      if (subClusterId == null) {
-        RouterServerUtil.logAndThrowException(null,
-            "Can't get HomeSubCluster by applicationId %s", applicationId);
-      }
-      return federationFacade.getSubCluster(subClusterId);
-    } catch (IllegalArgumentException e){
-      throw new IllegalArgumentException(e);
-    } catch (YarnException e) {
-      RouterServerUtil.logAndThrowException(e,
-          "Get HomeSubClusterInfo by applicationId %s failed.", appId);
-    }
-    throw new YarnException("Unable to get subCluster by applicationId = " + appId);
-  }
-
-  /**
-   * get the HomeSubCluster according to ReservationId.
-   *
-   * @param resId reservationId
-   * @return HomeSubCluster
-   * @throws YarnException on failure
-   */
-  private SubClusterInfo getHomeSubClusterInfoByReservationId(String resId)
-      throws YarnException {
-    try {
-      ReservationId reservationId = ReservationId.parseReservationId(resId);
-      SubClusterId subClusterId = federationFacade.getReservationHomeSubCluster(reservationId);
-      if (subClusterId == null) {
-        RouterServerUtil.logAndThrowException(null,
-            "Can't get HomeSubCluster by reservationId %s", resId);
-      }
-      return federationFacade.getSubCluster(subClusterId);
-    } catch (YarnException | IOException e) {
-      RouterServerUtil.logAndThrowException(e,
-          "Get HomeSubClusterInfo by reservationId %s failed.", resId);
-    }
-    throw new YarnException("Unable to get subCluster by reservationId = " + resId);
-  }
-
-  @VisibleForTesting
-  public LRUCacheHashMap<RouterAppInfoCacheKey, AppsInfo> getAppInfosCaches() {
-    return appInfosCaches;
-  }
-
-  @VisibleForTesting
-  public Map<SubClusterId, DefaultRequestInterceptorREST> getInterceptors() {
-    return interceptors;
-  }
-
-  public void setAllowPartialResult(boolean allowPartialResult) {
-    this.allowPartialResult = allowPartialResult;
-  }
-
-  @VisibleForTesting
-  public Map<SubClusterInfo, NodesInfo> invokeConcurrentGetNodeLabel()
-      throws IOException, YarnException {
-    Collection<SubClusterInfo> subClustersActive = federationFacade.getActiveSubClusters();
-    Class[] argsClasses = new Class[]{String.class};
-    Object[] args = new Object[]{null};
-    ClientMethod remoteMethod = new ClientMethod("getNodes", argsClasses, args);
-    return invokeConcurrent(subClustersActive, remoteMethod, NodesInfo.class);
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/FederationPage.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/FederationPage.java
deleted file mode 100644
index 1a1ae400121..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/FederationPage.java
+++ /dev/null
@@ -1,60 +0,0 @@
-/**
-* Licensed to the Apache Software Foundation (ASF) under one
-* or more contributor license agreements.  See the NOTICE file
-* distributed with this work for additional information
-* regarding copyright ownership.  The ASF licenses this file
-* to you under the Apache License, Version 2.0 (the
-* "License"); you may not use this file except in compliance
-* with the License.  You may obtain a copy of the License at
-*
-*     http://www.apache.org/licenses/LICENSE-2.0
-*
-* Unless required by applicable law or agreed to in writing, software
-* distributed under the License is distributed on an "AS IS" BASIS,
-* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-* See the License for the specific language governing permissions and
-* limitations under the License.
-*/
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.DATATABLES;
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.DATATABLES_ID;
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.initID;
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.tableInit;
-
-import org.apache.hadoop.yarn.webapp.SubView;
-
-/**
- * Renders a block for the applications with metrics information.
- */
-class FederationPage extends RouterView {
-
-  @Override
-  protected void preHead(Page.HTML<__> html) {
-    commonPreHead(html);
-    setTitle("About The YARN Federation");
-    set(DATATABLES_ID, "rms");
-    set("ui.div.id", "div_id");
-    set(initID(DATATABLES, "rms"), rmsTableInit());
-    setTableStyles(html, "rms", ".healthStatus {width:10em}",
-        ".healthReport {width:10em}");
-  }
-
-  @Override
-  protected Class<? extends SubView> content() {
-    return FederationBlock.class;
-  }
-
-  private String rmsTableInit() {
-    StringBuilder builder = tableInit().append(", aoColumnDefs: [");
-    builder
-        .append("{'sName':'State', 'sType':'string', 'bSearchable':false, 'aTargets':[1]},")
-        .append("{'sName':'LastStartTime', 'sType':'string', 'bSearchable':false, 'aTargets':[2]},")
-        .append("{'sName':'lastHeartBeat', 'sType':'string', 'bSearchable':false, 'aTargets':[3]},")
-        .append("{'sName':'resource', 'sType':'string', 'bSearchable':false, 'aTargets':[4]},")
-        .append("{'sName':'nodes', 'sType':'string', 'bSearchable':false, 'aTargets':[5]}")
-        .append("]}");
-    return builder.toString();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/HTTPMethods.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/HTTPMethods.java
deleted file mode 100644
index 45056ca701b..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/HTTPMethods.java
+++ /dev/null
@@ -1,34 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-/**
- * HTTP verbs.
- **/
-public enum HTTPMethods {
-
-  /* to retrieve resource representation/information */
-  GET,
-  /* to update existing resource */
-  PUT,
-  /* to delete resources */
-  DELETE,
-  /* to create new subordinate resources */
-  POST
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/MetricsOverviewTable.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/MetricsOverviewTable.java
deleted file mode 100644
index aeb953915af..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/MetricsOverviewTable.java
+++ /dev/null
@@ -1,360 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import com.google.inject.Inject;
-import com.sun.jersey.api.client.Client;
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerOverviewInfo;
-import org.apache.hadoop.yarn.server.router.Router;
-import org.apache.hadoop.yarn.server.router.webapp.dao.RouterClusterMetrics;
-import org.apache.hadoop.yarn.server.router.webapp.dao.RouterSchedulerMetrics;
-import org.apache.hadoop.yarn.webapp.hamlet2.Hamlet;
-import org.apache.hadoop.yarn.webapp.util.WebAppUtils;
-
-import java.io.IOException;
-import java.util.Collection;
-import java.util.List;
-
-public class MetricsOverviewTable extends RouterBlock {
-
-  private final Router router;
-
-  @Inject
-  MetricsOverviewTable(Router router, ViewContext ctx) {
-    super(router, ctx);
-    this.router = router;
-  }
-
-  @Override
-  protected void render(Block html) {
-    // Initialize page styles
-    html.style(".metrics {margin-bottom:5px}");
-
-    // get routerClusterMetrics Info
-    ClusterMetricsInfo routerClusterMetricsInfo = getRouterClusterMetricsInfo();
-    RouterClusterMetrics routerClusterMetrics = new RouterClusterMetrics(routerClusterMetricsInfo);
-
-    // metrics div
-    Hamlet.DIV<Hamlet> div = html.div().$class("metrics");
-    try {
-      initFederationClusterAppsMetrics(div, routerClusterMetrics);
-      initFederationClusterNodesMetrics(div, routerClusterMetrics);
-      List<SubClusterInfo> subClusters = getSubClusterInfoList();
-      initFederationClusterSchedulersMetrics(div, routerClusterMetrics, subClusters);
-    } catch (Exception e) {
-      LOG.error("MetricsOverviewTable init error.", e);
-    }
-    div.__();
-  }
-
-  protected void render(Block html, String subClusterId) {
-    // Initialize page styles
-    html.style(".metrics {margin-bottom:5px}");
-
-    // get subClusterId ClusterMetrics Info
-    ClusterMetricsInfo clusterMetricsInfo =
-        getClusterMetricsInfoBySubClusterId(subClusterId);
-    RouterClusterMetrics routerClusterMetrics =
-        new RouterClusterMetrics(clusterMetricsInfo, subClusterId);
-
-    // metrics div
-    Hamlet.DIV<Hamlet> div = html.div().$class("metrics");
-    try {
-      initFederationClusterAppsMetrics(div, routerClusterMetrics);
-      initFederationClusterNodesMetrics(div, routerClusterMetrics);
-      Collection<SubClusterInfo> subClusters = getSubClusterInfoList(subClusterId);
-      initFederationClusterSchedulersMetrics(div, routerClusterMetrics, subClusters);
-    } catch (Exception e) {
-      LOG.error("MetricsOverviewTable init error.", e);
-    }
-    div.__();
-  }
-
-  /**
-   * Init Federation Cluster Apps Metrics.
-   * Contains App information, resource usage information.
-   *
-   * @param div data display div.
-   * @param metrics data metric information.
-   */
-  private void initFederationClusterAppsMetrics(Hamlet.DIV<Hamlet> div,
-      RouterClusterMetrics metrics) {
-    div.h3(metrics.getWebPageTitlePrefix() + " Cluster Metrics").
-        table("#metricsoverview").
-        thead().$class("ui-widget-header").
-        // Initialize table header information
-        tr().
-        th().$class("ui-state-default").__("Apps Submitted").__().
-        th().$class("ui-state-default").__("Apps Pending").__().
-        th().$class("ui-state-default").__("Apps Running").__().
-        th().$class("ui-state-default").__("Apps Completed").__().
-        th().$class("ui-state-default").__("Containers Running").__().
-        th().$class("ui-state-default").__("Used Resources").__().
-        th().$class("ui-state-default").__("Total Resources").__().
-        th().$class("ui-state-default").__("Reserved Resources").__().
-        th().$class("ui-state-default").__("Physical Mem Used %").__().
-        th().$class("ui-state-default").__("Physical VCores Used %").__().
-        __().
-        __().
-        // Initialize table data information
-        tbody().$class("ui-widget-content").
-        tr().
-        td(metrics.getAppsSubmitted()).
-        td(metrics.getAppsPending()).
-        td(String.valueOf(metrics.getAppsRunning())).
-        td(metrics.getAppsCompleted()).
-        td(metrics.getAllocatedContainers()).
-        td(metrics.getUsedResources()).
-        td(metrics.getTotalResources()).
-        td(metrics.getReservedResources()).
-        td(metrics.getUtilizedMBPercent()).
-        td(metrics.getUtilizedVirtualCoresPercent()).
-        __().
-        __().__();
-  }
-
-  /**
-   * Init Federation Cluster Nodes Metrics.
-   *
-   * @param div data display div.
-   * @param metrics data metric information.
-   */
-  private void initFederationClusterNodesMetrics(Hamlet.DIV<Hamlet> div,
-      RouterClusterMetrics metrics) {
-    div.h3(metrics.getWebPageTitlePrefix() + " Cluster Nodes Metrics").
-        table("#nodemetricsoverview").
-        thead().$class("ui-widget-header").
-        // Initialize table header information
-        tr().
-        th().$class("ui-state-default").__("Active Nodes").__().
-        th().$class("ui-state-default").__("Decommissioning Nodes").__().
-        th().$class("ui-state-default").__("Decommissioned Nodes").__().
-        th().$class("ui-state-default").__("Lost Nodes").__().
-        th().$class("ui-state-default").__("Unhealthy Nodes").__().
-        th().$class("ui-state-default").__("Rebooted Nodes").__().
-        th().$class("ui-state-default").__("Shutdown Nodes").__().
-        __().
-        __().
-        // Initialize table data information
-        tbody().$class("ui-widget-content").
-        tr().
-        td().a(url("nodes"), String.valueOf(metrics.getActiveNodes())).__().
-        td().a(url("nodes/router/?node.state=decommissioning"),
-            String.valueOf(metrics.getDecommissioningNodes())).__().
-        td().a(url("nodes/router/?node.state=decommissioned"),
-            String.valueOf(metrics.getDecommissionedNodes())).__().
-        td().a(url("nodes/router/?node.state=lost"),
-            String.valueOf(metrics.getLostNodes())).__().
-        td().a(url("nodes/router/?node.state=unhealthy"),
-            String.valueOf(metrics.getUnhealthyNodes())).__().
-        td().a(url("nodes/router/?node.state=rebooted"),
-            String.valueOf(metrics.getRebootedNodes())).__().
-        td().a(url("nodes/router/?node.state=shutdown"),
-            String.valueOf(metrics.getShutdownNodes())).__().
-        __().
-        __().__();
-  }
-
-  /**
-   * Init Federation Cluster SchedulersMetrics.
-   *
-   * @param div data display div.
-   * @param metrics data metric information.
-   * @param subclusters active subcluster List.
-   * @throws YarnException yarn error.
-   * @throws IOException io error.
-   * @throws InterruptedException interrupt error.
-   */
-  private void initFederationClusterSchedulersMetrics(Hamlet.DIV<Hamlet> div,
-      RouterClusterMetrics metrics, Collection<SubClusterInfo> subclusters)
-      throws YarnException, IOException, InterruptedException {
-
-    Hamlet.TBODY<Hamlet.TABLE<Hamlet.DIV<Hamlet>>> fsMetricsScheduleTr =
-        div.h3(metrics.getWebPageTitlePrefix() + " Scheduler Metrics").
-        table("#schedulermetricsoverview").
-        thead().$class("ui-widget-header").
-        tr().
-        th().$class("ui-state-default").__("SubCluster").__().
-        th().$class("ui-state-default").__("Scheduler Type").__().
-        th().$class("ui-state-default").__("Scheduling Resource Type").__().
-        th().$class("ui-state-default").__("Minimum Allocation").__().
-        th().$class("ui-state-default").__("Maximum Allocation").__().
-        th().$class("ui-state-default").__("Maximum Cluster Application Priority").__().
-        th().$class("ui-state-default").__("Scheduler Busy %").__().
-        th().$class("ui-state-default").__("RM Dispatcher EventQueue Size").__().
-        th().$class("ui-state-default")
-        .__("Scheduler Dispatcher EventQueue Size").__().
-        __().
-        __().
-        tbody().$class("ui-widget-content");
-
-    boolean isEnabled = isYarnFederationEnabled();
-
-    // If Federation mode is not enabled or there is currently no SubCluster available,
-    // each column in the list should be displayed as N/A
-    if (!isEnabled) {
-      initLocalClusterOverViewTable(fsMetricsScheduleTr);
-    } else if (subclusters != null && !subclusters.isEmpty()) {
-      initSubClusterOverViewTable(metrics, fsMetricsScheduleTr, subclusters);
-    } else {
-      showRouterSchedulerMetricsData(UNAVAILABLE, fsMetricsScheduleTr);
-    }
-
-    fsMetricsScheduleTr.__().__();
-  }
-
-  /**
-   * We display Scheduler information for local cluster.
-   *
-   * @param fsMetricsScheduleTr MetricsScheduleTr.
-   */
-  private void initLocalClusterOverViewTable(
-      Hamlet.TBODY<Hamlet.TABLE<Hamlet.DIV<Hamlet>>> fsMetricsScheduleTr) {
-    // configuration
-    Configuration config = this.router.getConfig();
-    Client client = RouterWebServiceUtil.createJerseyClient(config);
-    String webAppAddress = WebAppUtils.getRMWebAppURLWithScheme(config);
-
-    // Get the name of the local cluster.
-    String localClusterName = config.get(YarnConfiguration.RM_CLUSTER_ID, UNAVAILABLE);
-    SchedulerOverviewInfo schedulerOverviewInfo =
-        getSchedulerOverviewInfo(webAppAddress, config, client);
-    if (schedulerOverviewInfo != null) {
-      RouterSchedulerMetrics rsMetrics =
-          new RouterSchedulerMetrics(localClusterName, schedulerOverviewInfo);
-      // Basic information
-      showRouterSchedulerMetricsData(rsMetrics, fsMetricsScheduleTr);
-    } else {
-      showRouterSchedulerMetricsData(localClusterName, fsMetricsScheduleTr);
-    }
-  }
-
-  /**
-   * We display Scheduler information for multiple subClusters.
-   *
-   * @param metrics RouterClusterMetrics.
-   * @param fsMetricsScheduleTr MetricsScheduleTr.
-   * @param subClusters subCluster list.
-   */
-  private void initSubClusterOverViewTable(RouterClusterMetrics metrics,
-      Hamlet.TBODY<Hamlet.TABLE<Hamlet.DIV<Hamlet>>> fsMetricsScheduleTr,
-      Collection<SubClusterInfo> subClusters) {
-
-    // configuration
-    Configuration config = this.router.getConfig();
-
-    Client client = RouterWebServiceUtil.createJerseyClient(config);
-
-    // Traverse all SubClusters to get cluster information.
-    for (SubClusterInfo subcluster : subClusters) {
-      // We need to make sure subCluster is not null
-      if (subcluster != null && subcluster.getSubClusterId() != null) {
-        // Call the RM interface to obtain schedule information
-        String webAppAddress =  WebAppUtils.getHttpSchemePrefix(config) +
-            subcluster.getRMWebServiceAddress();
-        SchedulerOverviewInfo schedulerOverviewInfo =
-            getSchedulerOverviewInfo(webAppAddress, config, client);
-
-        // If schedulerOverviewInfo is not null,
-        // We will display information from rsMetrics, otherwise we will not display information.
-        if (schedulerOverviewInfo != null) {
-          RouterSchedulerMetrics rsMetrics =
-              new RouterSchedulerMetrics(subcluster, metrics, schedulerOverviewInfo);
-          // Basic information
-          showRouterSchedulerMetricsData(rsMetrics, fsMetricsScheduleTr);
-        }
-      }
-    }
-
-    client.destroy();
-  }
-
-  /**
-   * Get SchedulerOverview information based on webAppAddress.
-   *
-   * @param webAppAddress webAppAddress.
-   * @param config configuration.
-   * @param client jersey Client.
-   * @return SchedulerOverviewInfo.
-   */
-  private SchedulerOverviewInfo getSchedulerOverviewInfo(String webAppAddress,
-      Configuration config, Client client) {
-    try {
-      SchedulerOverviewInfo schedulerOverviewInfo = RouterWebServiceUtil
-          .genericForward(webAppAddress, null, SchedulerOverviewInfo.class, HTTPMethods.GET,
-          RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.SCHEDULER_OVERVIEW, null, null,
-           config, client);
-      return schedulerOverviewInfo;
-    } catch (Exception e) {
-      LOG.error("get SchedulerOverviewInfo from webAppAddress = {} error.",
-          webAppAddress, e);
-      return null;
-    }
-  }
-
-  /**
-   * Show RouterSchedulerMetricsData.
-   *
-   * @param rsMetrics routerSchedulerMetrics.
-   * @param fsMetricsScheduleTr MetricsScheduleTr.
-   */
-  private void showRouterSchedulerMetricsData(RouterSchedulerMetrics rsMetrics,
-      Hamlet.TBODY<Hamlet.TABLE<Hamlet.DIV<Hamlet>>> fsMetricsScheduleTr) {
-    // Basic information
-    fsMetricsScheduleTr.tr().
-        td(rsMetrics.getSubCluster()).
-        td(rsMetrics.getSchedulerType()).
-        td(rsMetrics.getSchedulingResourceType()).
-        td(rsMetrics.getMinimumAllocation()).
-        td(rsMetrics.getMaximumAllocation()).
-        td(rsMetrics.getApplicationPriority()).
-        td(rsMetrics.getSchedulerBusy()).
-        td(rsMetrics.getRmDispatcherEventQueueSize()).
-        td(rsMetrics.getSchedulerDispatcherEventQueueSize()).
-        __();
-  }
-
-  /**
-   * Show RouterSchedulerMetricsData.
-   *
-   * @param subClusterId subClusterId.
-   * @param fsMetricsScheduleTr MetricsScheduleTr.
-   */
-  private void showRouterSchedulerMetricsData(String subClusterId,
-      Hamlet.TBODY<Hamlet.TABLE<Hamlet.DIV<Hamlet>>> fsMetricsScheduleTr) {
-    String subCluster = StringUtils.isNotBlank(subClusterId) ? subClusterId : UNAVAILABLE;
-    fsMetricsScheduleTr.tr().
-        td(subCluster).
-        td(UNAVAILABLE).
-        td(UNAVAILABLE).
-        td(UNAVAILABLE).
-        td(UNAVAILABLE).
-        td(UNAVAILABLE).
-        td(UNAVAILABLE).
-        td(UNAVAILABLE).
-        td(UNAVAILABLE)
-        .__();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NavBlock.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NavBlock.java
deleted file mode 100644
index aa04096688f..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NavBlock.java
+++ /dev/null
@@ -1,74 +0,0 @@
-/**
-* Licensed to the Apache Software Foundation (ASF) under one
-* or more contributor license agreements.  See the NOTICE file
-* distributed with this work for additional information
-* regarding copyright ownership.  The ASF licenses this file
-* to you under the Apache License, Version 2.0 (the
-* "License"); you may not use this file except in compliance
-* with the License.  You may obtain a copy of the License at
-*
-*     http://www.apache.org/licenses/LICENSE-2.0
-*
-* Unless required by applicable law or agreed to in writing, software
-* distributed under the License is distributed on an "AS IS" BASIS,
-* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-* See the License for the specific language governing permissions and
-* limitations under the License.
-*/
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import com.google.inject.Inject;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.server.router.Router;
-import org.apache.hadoop.yarn.server.webapp.WebPageUtils;
-import org.apache.hadoop.yarn.webapp.hamlet2.Hamlet;
-
-import java.util.List;
-/**
- * Navigation block for the Router Web UI.
- */
-public class NavBlock extends RouterBlock {
-
-  private Router router;
-
-  @Inject
-  public NavBlock(Router router, ViewContext ctx) {
-    super(router, ctx);
-    this.router = router;
-  }
-
-  @Override
-  public void render(Block html) {
-
-    String federationText = isYarnFederationEnabled() ? "Federation" : "LocalCluster";
-
-    Hamlet.UL<Hamlet.DIV<Hamlet>> mainList = html.div("#nav").
-        h3("Cluster").
-        ul().
-        li().a(url(""), "About").__().
-        li().a(url("federation"), federationText).__();
-
-    List<String> subClusterIds = getActiveSubClusterIds();
-
-    // ### nodes info
-    initNodesMenu(mainList, subClusterIds);
-
-    // ### nodelabels info
-    initNodeLabelsMenu(mainList, subClusterIds);
-
-    // ### applications info
-    initApplicationsMenu(mainList, subClusterIds);
-
-    // ### tools
-    Hamlet.DIV<Hamlet> sectionBefore = mainList.__();
-    Configuration conf = new Configuration();
-    Hamlet.UL<Hamlet.DIV<Hamlet>> tools = WebPageUtils.appendToolSection(sectionBefore, conf);
-
-    if (tools == null) {
-      return;
-    }
-
-    tools.__().__();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NodeLabelsBlock.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NodeLabelsBlock.java
deleted file mode 100644
index 28bc49ed8cc..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NodeLabelsBlock.java
+++ /dev/null
@@ -1,178 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import com.google.inject.Inject;
-import com.sun.jersey.api.client.Client;
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.api.records.NodeLabel;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo;
-import org.apache.hadoop.yarn.server.router.Router;
-import org.apache.hadoop.yarn.webapp.YarnWebParams;
-import org.apache.hadoop.yarn.webapp.hamlet2.Hamlet;
-import org.apache.hadoop.yarn.webapp.util.WebAppUtils;
-
-import static org.apache.hadoop.yarn.webapp.YarnWebParams.NODE_SC;
-
-/**
- * Navigation block for the Router Web UI.
- */
-public class NodeLabelsBlock extends RouterBlock {
-
-  private Router router;
-
-  @Inject
-  public NodeLabelsBlock(Router router, ViewContext ctx) {
-    super(router, ctx);
-    this.router = router;
-  }
-
-  @Override
-  protected void render(Block html) {
-    boolean isEnabled = isYarnFederationEnabled();
-
-    // Get subClusterName
-    String subClusterName = $(NODE_SC);
-
-    NodeLabelsInfo nodeLabelsInfo = null;
-    if (StringUtils.isNotEmpty(subClusterName)) {
-      nodeLabelsInfo = getSubClusterNodeLabelsInfo(subClusterName);
-    } else {
-      nodeLabelsInfo = getYarnFederationNodeLabelsInfo(isEnabled);
-    }
-
-    initYarnFederationNodeLabelsOfCluster(nodeLabelsInfo, html);
-  }
-
-  /**
-   * Get NodeLabels Info based on SubCluster.
-   * @return NodeLabelsInfo.
-   */
-  private NodeLabelsInfo getSubClusterNodeLabelsInfo(String subCluster) {
-    try {
-      SubClusterId subClusterId = SubClusterId.newInstance(subCluster);
-      FederationStateStoreFacade facade =
-          FederationStateStoreFacade.getInstance(router.getConfig());
-      SubClusterInfo subClusterInfo = facade.getSubCluster(subClusterId);
-
-      if (subClusterInfo != null) {
-        // Prepare webAddress
-        String webAddress = subClusterInfo.getRMWebServiceAddress();
-        String herfWebAppAddress = "";
-        if (webAddress != null && !webAddress.isEmpty()) {
-          herfWebAppAddress =
-              WebAppUtils.getHttpSchemePrefix(this.router.getConfig()) + webAddress;
-          return getSubClusterNodeLabelsByWebAddress(herfWebAppAddress);
-        }
-      }
-    } catch (Exception e) {
-      LOG.error("get NodeLabelsInfo From SubCluster = {} error.", subCluster, e);
-    }
-    return null;
-  }
-
-  /**
-   * We will obtain the NodeLabel information of multiple sub-clusters.
-   *
-   * If Federation mode is enabled, get the NodeLabels of multiple sub-clusters,
-   * otherwise get the NodeLabels of the local cluster.
-   *
-   * @param isEnabled Whether to enable Federation mode,
-   * true, Federation mode; false, Non-Federation mode.
-   *
-   * @return NodeLabelsInfo.
-   */
-  private NodeLabelsInfo getYarnFederationNodeLabelsInfo(boolean isEnabled) {
-    Configuration config = this.router.getConfig();
-    String webAddress;
-    if (isEnabled) {
-      webAddress = WebAppUtils.getRouterWebAppURLWithScheme(config);
-    } else {
-      webAddress = WebAppUtils.getRMWebAppURLWithScheme(config);
-    }
-    return getSubClusterNodeLabelsByWebAddress(webAddress);
-  }
-
-  /**
-   * Get NodeLabels based on WebAddress.
-   *
-   * @param webAddress RM WebAddress.
-   * @return NodeLabelsInfo.
-   */
-  private NodeLabelsInfo getSubClusterNodeLabelsByWebAddress(String webAddress) {
-    Configuration conf = this.router.getConfig();
-    Client client = RouterWebServiceUtil.createJerseyClient(conf);
-    NodeLabelsInfo nodes = RouterWebServiceUtil
-        .genericForward(webAddress, null, NodeLabelsInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.GET_RM_NODE_LABELS, null, null, conf,
-        client);
-    client.destroy();
-    return nodes;
-  }
-
-  /**
-   * Initialize the Router page based on NodeLabels.
-   *
-   * @param nodeLabelsInfo NodeLabelsInfo.
-   * @param html html Block.
-   */
-  private void initYarnFederationNodeLabelsOfCluster(NodeLabelsInfo nodeLabelsInfo, Block html) {
-
-    Hamlet.TBODY<Hamlet.TABLE<Hamlet>> tbody = html.table("#nodelabels").
-        thead().
-        tr().
-        th(".name", "Label Name").
-        th(".type", "Label Type").
-        th(".numOfActiveNMs", "Num Of Active NMs").
-        th(".totalResource", "Total Resource").
-        __().__().
-        tbody();
-
-    if (nodeLabelsInfo != null) {
-      for (NodeLabelInfo info : nodeLabelsInfo.getNodeLabelsInfo()) {
-        Hamlet.TR<Hamlet.TBODY<Hamlet.TABLE<Hamlet>>> row =
-            tbody.tr().td(info.getName().isEmpty() ?
-            NodeLabel.DEFAULT_NODE_LABEL_PARTITION : info.getName());
-        String type = (info.getExclusivity()) ? "Exclusive Partition" : "Non Exclusive Partition";
-        row = row.td(type);
-        int nActiveNMs = info.getActiveNMs();
-        if (nActiveNMs > 0) {
-          row = row.td().a(url("nodes",
-              "?" + YarnWebParams.NODE_LABEL + "=" + info.getName()), String.valueOf(nActiveNMs))
-              .__();
-        } else {
-          row = row.td(String.valueOf(nActiveNMs));
-        }
-
-        PartitionInfo partitionInfo = info.getPartitionInfo();
-        ResourceInfo available = partitionInfo.getResourceAvailable();
-        row.td(available.toFormattedString()).__();
-      }
-    }
-
-    tbody.__().__();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NodeLabelsPage.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NodeLabelsPage.java
deleted file mode 100644
index 5ab462ee0f1..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NodeLabelsPage.java
+++ /dev/null
@@ -1,56 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import org.apache.hadoop.yarn.webapp.SubView;
-import org.apache.hadoop.yarn.webapp.hamlet2.Hamlet;
-
-import static org.apache.hadoop.yarn.server.router.webapp.RouterWebServiceUtil.generateWebTitle;
-import static org.apache.hadoop.yarn.webapp.YarnWebParams.NODE_SC;
-import static org.apache.hadoop.yarn.webapp.YarnWebParams.NODE_LABEL;
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.DATATABLES_ID;
-
-/**
- * Renders a block for the nodelabels with metrics information.
- */
-public class NodeLabelsPage extends RouterView {
-
-  @Override
-  protected void preHead(Hamlet.HTML<__> html) {
-    commonPreHead(html);
-    String type = $(NODE_SC);
-    String nodeLabel = $(NODE_LABEL);
-    String title = "Node labels of the cluster";
-
-    if (nodeLabel != null && !nodeLabel.isEmpty()) {
-      title = generateWebTitle(title, nodeLabel);
-    } else if (type != null && !type.isEmpty()) {
-      title = generateWebTitle(title, type);
-    }
-
-    setTitle(title);
-    set(DATATABLES_ID, "nodelabels");
-    setTableStyles(html, "nodelabels", ".healthStatus {width:10em}", ".healthReport {width:10em}");
-  }
-
-  @Override
-  protected Class<? extends SubView> content() {
-    return NodeLabelsBlock.class;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NodesBlock.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NodesBlock.java
deleted file mode 100644
index 4544ed4ed44..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NodesBlock.java
+++ /dev/null
@@ -1,206 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import com.sun.jersey.api.client.Client;
-import org.apache.commons.collections.CollectionUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.util.StringUtils;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.resourcemanager.nodelabels.RMNodeLabelsManager;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodesInfo;
-import org.apache.hadoop.yarn.server.router.Router;
-import org.apache.hadoop.yarn.webapp.hamlet2.Hamlet;
-import org.apache.hadoop.yarn.webapp.hamlet2.Hamlet.TABLE;
-import org.apache.hadoop.yarn.webapp.hamlet2.Hamlet.TBODY;
-import org.apache.hadoop.yarn.webapp.hamlet2.Hamlet.TR;
-import org.apache.hadoop.yarn.webapp.util.WebAppUtils;
-
-import com.google.inject.Inject;
-
-import java.util.Date;
-
-import static org.apache.hadoop.yarn.webapp.YarnWebParams.NODE_SC;
-import static org.apache.hadoop.yarn.webapp.YarnWebParams.NODE_LABEL;
-import static org.apache.hadoop.yarn.webapp.YarnWebParams.NODE_STATE;
-
-/**
- * Nodes block for the Router Web UI.
- */
-public class NodesBlock extends RouterBlock {
-
-  private final Router router;
-
-  @Inject
-  NodesBlock(Router router, ViewContext ctx) {
-    super(router, ctx);
-    this.router = router;
-  }
-
-  @Override
-  protected void render(Block html) {
-
-    boolean isEnabled = isYarnFederationEnabled();
-
-    // Get subClusterName
-    String subClusterName = $(NODE_SC);
-    String state = $(NODE_STATE);
-    String nodeLabel = $(NODE_LABEL);
-
-    // We will try to get the subClusterName.
-    // If the subClusterName is not empty,
-    // it means that we need to get the Node list of a subCluster.
-    NodesInfo nodesInfo;
-    if (subClusterName != null && !subClusterName.isEmpty() &&
-        !ROUTER.equalsIgnoreCase(subClusterName)) {
-      initSubClusterMetricsOverviewTable(html, subClusterName);
-      nodesInfo = getSubClusterNodesInfo(subClusterName);
-    } else {
-      // Metrics Overview Table
-      html.__(MetricsOverviewTable.class);
-      nodesInfo = getYarnFederationNodesInfo(isEnabled);
-    }
-
-    // Initialize NodeInfo List
-    initYarnFederationNodesOfCluster(nodesInfo, html, state, nodeLabel);
-  }
-
-  private NodesInfo getYarnFederationNodesInfo(boolean isEnabled) {
-    Configuration config = this.router.getConfig();
-    String webAddress;
-    if (isEnabled) {
-      webAddress = WebAppUtils.getRouterWebAppURLWithScheme(this.router.getConfig());
-    } else {
-      webAddress = WebAppUtils.getRMWebAppURLWithScheme(config);
-    }
-    return getSubClusterNodesInfoByWebAddress(webAddress);
-  }
-
-  private NodesInfo getSubClusterNodesInfo(String subCluster) {
-    try {
-      SubClusterId subClusterId = SubClusterId.newInstance(subCluster);
-      FederationStateStoreFacade facade =
-          FederationStateStoreFacade.getInstance(this.router.getConfig());
-      SubClusterInfo subClusterInfo = facade.getSubCluster(subClusterId);
-
-      if (subClusterInfo != null) {
-        // Prepare webAddress
-        String webAddress = subClusterInfo.getRMWebServiceAddress();
-        String herfWebAppAddress;
-        if (webAddress != null && !webAddress.isEmpty()) {
-          herfWebAppAddress =
-              WebAppUtils.getHttpSchemePrefix(this.router.getConfig()) + webAddress;
-          return getSubClusterNodesInfoByWebAddress(herfWebAppAddress);
-        }
-      }
-    } catch (Exception e) {
-      LOG.error("get NodesInfo From SubCluster = {} error.", subCluster, e);
-    }
-    return null;
-  }
-
-  private NodesInfo getSubClusterNodesInfoByWebAddress(String webAddress) {
-    Configuration conf = this.router.getConfig();
-    Client client = RouterWebServiceUtil.createJerseyClient(conf);
-    NodesInfo nodes = RouterWebServiceUtil
-        .genericForward(webAddress, null, NodesInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.NODES, null, null, conf,
-        client);
-    client.destroy();
-    return nodes;
-  }
-
-  private void initYarnFederationNodesOfCluster(NodesInfo nodesInfo, Block html,
-      String filterState, String filterLabel) {
-    TBODY<TABLE<Hamlet>> tbody = html.table("#nodes").thead().tr()
-        .th(".nodelabels", "Node Labels")
-        .th(".rack", "Rack")
-        .th(".state", "Node State")
-        .th(".nodeaddress", "Node Address")
-        .th(".nodehttpaddress", "Node HTTP Address")
-        .th(".lastHealthUpdate", "Last health-update")
-        .th(".healthReport", "Health-report")
-        .th(".containers", "Containers")
-        .th(".mem", "Mem Used")
-        .th(".mem", "Mem Avail")
-        .th(".vcores", "VCores Used")
-        .th(".vcores", "VCores Avail")
-        .th(".nodeManagerVersion", "Version")
-        .__().__().tbody();
-
-    if (nodesInfo != null && CollectionUtils.isNotEmpty(nodesInfo.getNodes())) {
-      for (NodeInfo info : nodesInfo.getNodes()) {
-        if (filterState != null && !filterState.isEmpty() && !filterState.equals(info.getState())) {
-          continue;
-        }
-
-        // Besides state, we need to filter label as well.
-        if (!filterLabel.equals(RMNodeLabelsManager.ANY)) {
-          if (filterLabel.isEmpty()) {
-            // Empty label filter means only shows nodes without label
-            if (!info.getNodeLabels().isEmpty()) {
-              continue;
-            }
-          } else if (!info.getNodeLabels().contains(filterLabel)) {
-            // Only nodes have given label can show on web page.
-            continue;
-          }
-        }
-
-        int usedMemory = (int) info.getUsedMemory();
-        int availableMemory = (int) info.getAvailableMemory();
-        TR<TBODY<TABLE<Hamlet>>> row = tbody.tr();
-        row.td().__(StringUtils.join(",", info.getNodeLabels())).__();
-        row.td().__(info.getRack()).__();
-        row.td().__(info.getState()).__();
-        row.td().__(info.getNodeId()).__();
-        boolean isInactive = false;
-        if (isInactive) {
-          row.td().__(UNAVAILABLE).__();
-        } else {
-          String httpAddress = info.getNodeHTTPAddress();
-          String herfWebAppAddress = "";
-          if (httpAddress != null && !httpAddress.isEmpty()) {
-            herfWebAppAddress =
-                WebAppUtils.getHttpSchemePrefix(this.router.getConfig()) + httpAddress;
-          }
-          row.td().a(herfWebAppAddress, httpAddress).__();
-        }
-
-        row.td().br().$title(String.valueOf(info.getLastHealthUpdate())).__()
-            .__(new Date(info.getLastHealthUpdate())).__()
-            .td(info.getHealthReport())
-            .td(String.valueOf(info.getNumContainers())).td().br()
-            .$title(String.valueOf(usedMemory)).__()
-            .__(StringUtils.byteDesc(usedMemory * BYTES_IN_MB)).__().td().br()
-            .$title(String.valueOf(availableMemory)).__()
-            .__(StringUtils.byteDesc(availableMemory * BYTES_IN_MB)).__()
-            .td(String.valueOf(info.getUsedVirtualCores()))
-            .td(String.valueOf(info.getAvailableVirtualCores()))
-            .td(info.getVersion()).__();
-      }
-    }
-
-    tbody.__().__();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NodesPage.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NodesPage.java
deleted file mode 100644
index 386e540b7d6..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/NodesPage.java
+++ /dev/null
@@ -1,65 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import static org.apache.hadoop.yarn.server.router.webapp.RouterWebServiceUtil.generateWebTitle;
-import static org.apache.hadoop.yarn.webapp.YarnWebParams.NODE_SC;
-import static org.apache.hadoop.yarn.webapp.YarnWebParams.NODE_STATE;
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.DATATABLES;
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.DATATABLES_ID;
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.initID;
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.tableInit;
-
-import org.apache.hadoop.yarn.webapp.SubView;
-
-class NodesPage extends RouterView {
-
-  @Override
-  protected void preHead(Page.HTML<__> html) {
-    commonPreHead(html);
-    String type = $(NODE_SC);
-    String state = $(NODE_STATE);
-    String title = "Nodes of the cluster";
-    if (state != null && !state.isEmpty()) {
-      title = generateWebTitle(title, state);
-    } else if (type != null && !type.isEmpty()) {
-      title = generateWebTitle(title, type);
-    }
-    setTitle(title);
-    set(DATATABLES_ID, "nodes");
-    set(initID(DATATABLES, "nodes"), nodesTableInit());
-    setTableStyles(html, "nodes", ".healthStatus {width:10em}",
-        ".healthReport {width:10em}");
-  }
-
-  @Override
-  protected Class<? extends SubView> content() {
-    return NodesBlock.class;
-  }
-
-  private String nodesTableInit() {
-    StringBuilder b = tableInit().append(", aoColumnDefs: [");
-    b.append("{'bSearchable': false, 'aTargets': [ 7 ]}")
-        .append(", {'sType': 'title-numeric', 'bSearchable': false, "
-            + "'aTargets': [ 2, 3, 4, 5, 6 ] }")
-        .append(", {'sType': 'title-numeric', 'aTargets': [ 5 ]}")
-        .append("]}");
-    return b.toString();
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RESTRequestInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RESTRequestInterceptor.java
deleted file mode 100644
index 2724cdd5ad2..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RESTRequestInterceptor.java
+++ /dev/null
@@ -1,140 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import javax.servlet.http.HttpServletRequest;
-import javax.servlet.http.HttpServletResponse;
-
-import org.apache.hadoop.conf.Configurable;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServiceProtocol;
-import org.apache.hadoop.yarn.server.router.clientrm.RouterClientRMService;
-import org.apache.hadoop.yarn.server.webapp.WebServices;
-import org.apache.hadoop.yarn.server.webapp.dao.AppAttemptInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainerInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainersInfo;
-
-/**
- * Defines the contract to be implemented by the request interceptor classes,
- * that can be used to intercept and inspect messages sent from the client to
- * the resource manager server.
- *
- * This class includes 4 methods getAppAttempts, getAppAttempt, getContainers
- * and getContainer that belong to {@link WebServices}. They are in this class
- * to make sure that RouterWebServices implements the same REST methods of
- * {@code RMWebServices}.
- */
-public interface RESTRequestInterceptor
-    extends RMWebServiceProtocol, Configurable {
-
-  /**
-   * This method is called for initializing the interceptor. This is guaranteed
-   * to be called only once in the lifetime of this instance.
-   *
-   * @param user the name of the client
-   */
-  void init(String user);
-
-  /**
-   * This method is called to release the resources held by the interceptor.
-   * This will be called when the application pipeline is being destroyed. The
-   * concrete implementations should dispose the resources and forward the
-   * request to the next interceptor, if any.
-   */
-  void shutdown();
-
-  /**
-   * Sets the next interceptor in the pipeline. The concrete implementation of
-   * this interface should always pass the request to the nextInterceptor after
-   * inspecting the message. The last interceptor in the chain is responsible to
-   * send the messages to the resource manager service and so the last
-   * interceptor will not receive this method call.
-   *
-   * @param nextInterceptor the RESTRequestInterceptor to set in the pipeline
-   */
-  void setNextInterceptor(RESTRequestInterceptor nextInterceptor);
-
-  /**
-   * Returns the next interceptor in the chain.
-   *
-   * @return the next interceptor in the chain
-   */
-  RESTRequestInterceptor getNextInterceptor();
-
-  /**
-   *
-   * @see WebServices#getAppAttempt(HttpServletRequest, HttpServletResponse,
-   *      String, String)
-   * @param req the servlet request
-   * @param res the servlet response
-   * @param appId the application we want to get the appAttempt. It is a
-   *          PathParam.
-   * @param appAttemptId the AppAttempt we want to get the info. It is a
-   *          PathParam.
-   * @return AppAttemptInfo of the specific AppAttempt
-   */
-  AppAttemptInfo getAppAttempt(HttpServletRequest req, HttpServletResponse res,
-      String appId, String appAttemptId);
-
-  /**
-   *
-   * @see WebServices#getContainers(HttpServletRequest, HttpServletResponse,
-   *      String, String)
-   * @param req the servlet request
-   * @param res the servlet response
-   * @param appId the application we want to get the containers info. It is a
-   *          PathParam.
-   * @param appAttemptId the AppAttempt we want to get the info. It is a
-   *          PathParam.
-   * @return ContainersInfo of all the containers that belong to the specific
-   *         AppAttempt
-   */
-  ContainersInfo getContainers(HttpServletRequest req, HttpServletResponse res,
-      String appId, String appAttemptId);
-
-  /**
-   *
-   * @see WebServices#getContainer(HttpServletRequest, HttpServletResponse,
-   *      String, String, String)
-   * @param req the servlet request
-   * @param res the servlet response
-   * @param appId the application we want to get the containers info. It is a
-   *          PathParam.
-   * @param appAttemptId the AppAttempt we want to get the info. It is a
-   *          PathParam.
-   * @param containerId the container we want to get the info. It is a
-   *          PathParam.
-   * @return ContainerInfo of the specific ContainerId
-   */
-  ContainerInfo getContainer(HttpServletRequest req, HttpServletResponse res,
-      String appId, String appAttemptId, String containerId);
-
-  /**
-   * Set RouterClientRMService.
-   *
-   * @param routerClientRMService routerClientRMService.
-   */
-  void setRouterClientRMService(RouterClientRMService routerClientRMService);
-
-  /**
-   * Get RouterClientRMService.
-   *
-   * @return RouterClientRMService
-   */
-  RouterClientRMService getRouterClientRMService();
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterBlock.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterBlock.java
deleted file mode 100644
index 55bcb81f259..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterBlock.java
+++ /dev/null
@@ -1,357 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import com.sun.jersey.api.client.Client;
-import com.sun.jersey.api.json.JSONConfiguration;
-import com.sun.jersey.api.json.JSONJAXBContext;
-import com.sun.jersey.api.json.JSONMarshaller;
-import org.apache.commons.collections.CollectionUtils;
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.util.Time;
-import org.apache.hadoop.yarn.api.records.YarnApplicationState;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterState;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.server.router.Router;
-import org.apache.hadoop.yarn.webapp.hamlet2.Hamlet;
-import org.apache.hadoop.yarn.webapp.util.WebAppUtils;
-import org.apache.hadoop.yarn.webapp.view.HtmlBlock;
-
-import java.io.StringWriter;
-import java.util.List;
-import java.util.ArrayList;
-import java.util.Map;
-import java.util.Collection;
-import java.util.Collections;
-import java.util.Comparator;
-
-public abstract class RouterBlock extends HtmlBlock {
-
-  private final Router router;
-  private final ViewContext ctx;
-  private final FederationStateStoreFacade facade;
-  private final Configuration conf;
-
-  public static final String ROUTER = "router";
-
-  public RouterBlock(Router router, ViewContext ctx) {
-    super(ctx);
-    this.ctx = ctx;
-    this.router = router;
-    this.facade = FederationStateStoreFacade.getInstance(router.getConfig());
-    this.conf = this.router.getConfig();
-  }
-
-  /**
-   * Get RouterClusterMetrics Info.
-   *
-   * @return Router ClusterMetricsInfo.
-   */
-  protected ClusterMetricsInfo getRouterClusterMetricsInfo() {
-    boolean isEnabled = isYarnFederationEnabled();
-    String webAppAddress;
-    if(isEnabled) {
-      webAppAddress = WebAppUtils.getRouterWebAppURLWithScheme(conf);
-    } else {
-      webAppAddress = WebAppUtils.getRMWebAppURLWithScheme(conf);
-    }
-    return getClusterMetricsInfo(webAppAddress);
-  }
-
-  /**
-   * Get RouterClusterMetrics Info.
-   *
-   * @param webAppAddress webAppAddress.
-   * @return ClusterMetricsInfo.
-   */
-  protected ClusterMetricsInfo getClusterMetricsInfo(String webAppAddress) {
-    // If webAppAddress is empty, we will return NULL.
-    if (StringUtils.isBlank(webAppAddress)) {
-      return null;
-    }
-
-    // We will get ClusterMetricsInfo By webAppAddress.
-    Client client = RouterWebServiceUtil.createJerseyClient(conf);
-    ClusterMetricsInfo metrics = RouterWebServiceUtil
-        .genericForward(webAppAddress, null, ClusterMetricsInfo.class, HTTPMethods.GET,
-        RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.METRICS, null, null,
-        conf, client);
-    client.destroy();
-    return metrics;
-  }
-
-  /**
-   * Get a list of subclusters.
-   *
-   * @return subcluster List.
-   */
-  protected List<SubClusterInfo> getSubClusterInfoList() {
-    List<SubClusterInfo> subClusters = new ArrayList<>();
-    try {
-      Map<SubClusterId, SubClusterInfo> subClustersInfo = facade.getSubClusters(true);
-
-      // Sort the SubClusters.
-      subClusters.addAll(subClustersInfo.values());
-      Comparator<? super SubClusterInfo> cmp = Comparator.comparing(o -> o.getSubClusterId());
-      Collections.sort(subClusters, cmp);
-
-      // Return results
-      return subClusters;
-    } catch (YarnException e) {
-      LOG.error("getSubClusterInfoList error.", e);
-      return subClusters;
-    }
-  }
-
-  /**
-   * Whether Yarn Federation is enabled.
-   *
-   * @return true, enable yarn federation; false, not enable yarn federation;
-   */
-  protected boolean isYarnFederationEnabled() {
-    boolean isEnabled = conf.getBoolean(
-        YarnConfiguration.FEDERATION_ENABLED,
-        YarnConfiguration.DEFAULT_FEDERATION_ENABLED);
-    return isEnabled;
-  }
-
-  /**
-   * Get a list of SubClusterIds for ActiveSubClusters.
-   *
-   * @return list of SubClusterIds.
-   */
-  protected List<String> getActiveSubClusterIds() {
-    List<String> result = new ArrayList<>();
-    try {
-      Map<SubClusterId, SubClusterInfo> subClustersInfo = facade.getSubClusters(true);
-      subClustersInfo.values().stream().forEach(subClusterInfo -> {
-        result.add(subClusterInfo.getSubClusterId().getId());
-      });
-    } catch (Exception e) {
-      LOG.error("getActiveSubClusters error.", e);
-    }
-    return result;
-  }
-
-  /**
-   * init SubCluster MetricsOverviewTable.
-   *
-   * @param html HTML Object.
-   * @param subclusterId subClusterId
-   */
-  protected void initSubClusterMetricsOverviewTable(Block html, String subclusterId) {
-    MetricsOverviewTable metricsOverviewTable = new MetricsOverviewTable(this.router, this.ctx);
-    metricsOverviewTable.render(html, subclusterId);
-  }
-
-  /**
-   * Get ClusterMetricsInfo By SubClusterId.
-   *
-   * @param subclusterId subClusterId
-   * @return SubCluster RM ClusterMetricsInfo
-   */
-  protected ClusterMetricsInfo getClusterMetricsInfoBySubClusterId(String subclusterId) {
-    try {
-      SubClusterId subClusterId = SubClusterId.newInstance(subclusterId);
-      SubClusterInfo subClusterInfo = facade.getSubCluster(subClusterId);
-      if (subClusterInfo != null) {
-        Client client = RouterWebServiceUtil.createJerseyClient(this.conf);
-        // Call the RM interface to obtain schedule information
-        String webAppAddress =  WebAppUtils.getHttpSchemePrefix(this.conf) +
-            subClusterInfo.getRMWebServiceAddress();
-        ClusterMetricsInfo metrics = RouterWebServiceUtil
-            .genericForward(webAppAddress, null, ClusterMetricsInfo.class, HTTPMethods.GET,
-            RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.METRICS, null, null,
-            conf, client);
-        client.destroy();
-        return metrics;
-      }
-    } catch (Exception e) {
-      LOG.error("getClusterMetricsInfoBySubClusterId subClusterId = {} error.", subclusterId, e);
-    }
-    return null;
-  }
-
-  /**
-   * Get SubClusterInfo based on subclusterId.
-   *
-   * @param subclusterId subCluster Id
-   * @return SubClusterInfo Collection
-   */
-  protected Collection<SubClusterInfo> getSubClusterInfoList(String subclusterId) {
-    try {
-      SubClusterId subClusterId = SubClusterId.newInstance(subclusterId);
-      SubClusterInfo subClusterInfo = facade.getSubCluster(subClusterId);
-      return Collections.singletonList(subClusterInfo);
-    } catch (Exception e) {
-      LOG.error("getSubClusterInfoList subClusterId = {} error.", subclusterId, e);
-    }
-    return null;
-  }
-
-  public FederationStateStoreFacade getFacade() {
-    return facade;
-  }
-
-  /**
-   * Initialize the Nodes menu.
-   *
-   * @param mainList HTML Object.
-   * @param subClusterIds subCluster List.
-   */
-  protected void initNodesMenu(Hamlet.UL<Hamlet.DIV<Hamlet>> mainList,
-      List<String> subClusterIds) {
-    if (CollectionUtils.isNotEmpty(subClusterIds)) {
-      Hamlet.UL<Hamlet.LI<Hamlet.UL<Hamlet.DIV<Hamlet>>>> nodesList =
-          mainList.li().a(url("nodes"), "Nodes").ul().
-          $style("padding:0.3em 1em 0.1em 2em");
-
-      // ### nodes info
-      nodesList.li().__();
-      for (String subClusterId : subClusterIds) {
-        nodesList.li().a(url("nodes", subClusterId), subClusterId).__();
-      }
-      nodesList.__().__();
-    } else {
-      mainList.li().a(url("nodes"), "Nodes").__();
-    }
-  }
-
-  /**
-   * Initialize the Applications menu.
-   *
-   * @param mainList HTML Object.
-   * @param subClusterIds subCluster List.
-   */
-  protected void initApplicationsMenu(Hamlet.UL<Hamlet.DIV<Hamlet>> mainList,
-      List<String> subClusterIds) {
-    if (CollectionUtils.isNotEmpty(subClusterIds)) {
-      Hamlet.UL<Hamlet.LI<Hamlet.UL<Hamlet.DIV<Hamlet>>>> apps =
-          mainList.li().a(url("apps"), "Applications").ul();
-      apps.li().__();
-      for (String subClusterId : subClusterIds) {
-        Hamlet.LI<Hamlet.UL<Hamlet.LI<Hamlet.UL<Hamlet.DIV<Hamlet>>>>> subClusterList = apps.
-            li().a(url("apps", subClusterId), subClusterId);
-        Hamlet.UL<Hamlet.LI<Hamlet.UL<Hamlet.LI<Hamlet.UL<Hamlet.DIV<Hamlet>>>>>> subAppStates =
-            subClusterList.ul().$style("padding:0.3em 1em 0.1em 2em");
-        subAppStates.li().__();
-        for (YarnApplicationState state : YarnApplicationState.values()) {
-          subAppStates.
-              li().a(url("apps", subClusterId, state.toString()), state.toString()).__();
-        }
-        subAppStates.li().__().__();
-        subClusterList.__();
-      }
-      apps.__().__();
-    } else {
-      mainList.li().a(url("apps"), "Applications").__();
-    }
-  }
-
-  /**
-   * Initialize the NodeLabels menu.
-   *
-   * @param mainList HTML Object.
-   * @param subClusterIds subCluster List.
-   */
-  protected void initNodeLabelsMenu(Hamlet.UL<Hamlet.DIV<Hamlet>> mainList,
-      List<String> subClusterIds) {
-
-    if (CollectionUtils.isNotEmpty(subClusterIds)) {
-      Hamlet.UL<Hamlet.LI<Hamlet.UL<Hamlet.DIV<Hamlet>>>> nodesList =
-          mainList.li().a(url("nodelabels"), "Node Labels").ul().
-          $style("padding:0.3em 1em 0.1em 2em");
-
-      // ### nodelabels info
-      nodesList.li().__();
-      for (String subClusterId : subClusterIds) {
-        nodesList.li().a(url("nodelabels", subClusterId), subClusterId).__();
-      }
-      nodesList.__().__();
-    } else {
-      mainList.li().a(url("nodelabels"), "Node Labels").__();
-    }
-  }
-
-  /**
-   * Generate SubClusterInfo based on local cluster information.
-   *
-   * @param config Configuration.
-   * @return SubClusterInfo.
-   */
-  protected SubClusterInfo getSubClusterInfoByLocalCluster(Configuration config) {
-
-    Client client = null;
-    try {
-
-      // Step1. Retrieve the name of the local cluster and ClusterMetricsInfo.
-      String localClusterName = config.get(YarnConfiguration.RM_CLUSTER_ID, UNAVAILABLE);
-      String webAppAddress = WebAppUtils.getRMWebAppURLWithScheme(config);
-      String rmWebAppURLWithoutScheme = WebAppUtils.getRMWebAppURLWithoutScheme(config);
-      client = RouterWebServiceUtil.createJerseyClient(config);
-      ClusterMetricsInfo clusterMetricsInfos = RouterWebServiceUtil
-          .genericForward(webAppAddress, null, ClusterMetricsInfo.class, HTTPMethods.GET,
-          RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.METRICS, null, null,
-           config, client);
-
-      if (clusterMetricsInfos == null) {
-        return null;
-      }
-
-      // Step2. Retrieve cluster information for the local cluster to obtain its startup time.
-      ClusterInfo clusterInfo = RouterWebServiceUtil.genericForward(webAppAddress, null,
-          ClusterInfo.class, HTTPMethods.GET, RMWSConsts.RM_WEB_SERVICE_PATH + RMWSConsts.INFO,
-          null, null, config, client);
-
-      if (clusterInfo == null) {
-        return null;
-      }
-
-      // Step3. Get Local-Cluster Capability
-      JSONJAXBContext jc = new JSONJAXBContext(
-          JSONConfiguration.mapped().rootUnwrapping(false).build(), ClusterMetricsInfo.class);
-      JSONMarshaller marshaller = jc.createJSONMarshaller();
-      StringWriter writer = new StringWriter();
-      marshaller.marshallToJSON(clusterMetricsInfos, writer);
-      String capability = writer.toString();
-
-      // Step4. Generate SubClusterInfo.
-      SubClusterId subClusterId = SubClusterId.newInstance(localClusterName);
-      SubClusterInfo subClusterInfo = SubClusterInfo.newInstance(subClusterId,
-          rmWebAppURLWithoutScheme, SubClusterState.SC_RUNNING, clusterInfo.getStartedOn(),
-          Time.now(), capability);
-
-      return subClusterInfo;
-    } catch (Exception e) {
-      LOG.error("An error occurred while parsing the local YARN cluster.", e);
-    } finally {
-      if (client != null) {
-        client.destroy();
-      }
-    }
-    return null;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterController.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterController.java
deleted file mode 100644
index 7d7165f7cad..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterController.java
+++ /dev/null
@@ -1,64 +0,0 @@
-/**
-* Licensed to the Apache Software Foundation (ASF) under one
-* or more contributor license agreements.  See the NOTICE file
-* distributed with this work for additional information
-* regarding copyright ownership.  The ASF licenses this file
-* to you under the Apache License, Version 2.0 (the
-* "License"); you may not use this file except in compliance
-* with the License.  You may obtain a copy of the License at
-*
-*     http://www.apache.org/licenses/LICENSE-2.0
-*
-* Unless required by applicable law or agreed to in writing, software
-* distributed under the License is distributed on an "AS IS" BASIS,
-* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-* See the License for the specific language governing permissions and
-* limitations under the License.
-*/
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import org.apache.hadoop.yarn.webapp.Controller;
-
-import com.google.inject.Inject;
-
-/**
- * Controller for the Router Web UI.
- */
-public class RouterController extends Controller {
-
-  @Inject
-  RouterController(RequestContext ctx) {
-    super(ctx);
-  }
-
-  @Override
-  public void index() {
-    setTitle("About the YARN Router");
-    render(AboutPage.class);
-  }
-
-  public void about() {
-    setTitle("About the Cluster");
-    render(AboutPage.class);
-  }
-
-  public void federation() {
-    render(FederationPage.class);
-  }
-
-  public void apps() {
-    setTitle("Applications");
-    render(AppsPage.class);
-  }
-
-  public void nodes() {
-    setTitle("Nodes");
-    render(NodesPage.class);
-  }
-
-  public void nodeLabels() {
-    setTitle("Node Labels");
-    render(NodeLabelsPage.class);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterView.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterView.java
deleted file mode 100644
index b377f7dc1dd..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterView.java
+++ /dev/null
@@ -1,52 +0,0 @@
-/**
-* Licensed to the Apache Software Foundation (ASF) under one
-* or more contributor license agreements.  See the NOTICE file
-* distributed with this work for additional information
-* regarding copyright ownership.  The ASF licenses this file
-* to you under the Apache License, Version 2.0 (the
-* "License"); you may not use this file except in compliance
-* with the License.  You may obtain a copy of the License at
-*
-*     http://www.apache.org/licenses/LICENSE-2.0
-*
-* Unless required by applicable law or agreed to in writing, software
-* distributed under the License is distributed on an "AS IS" BASIS,
-* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-* See the License for the specific language governing permissions and
-* limitations under the License.
-*/
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import org.apache.hadoop.yarn.webapp.SubView;
-import org.apache.hadoop.yarn.webapp.view.TwoColumnLayout;
-
-import static org.apache.hadoop.yarn.webapp.view.JQueryUI.*;
-
-/**
- * View for the Router Web UI.
- */
-public class RouterView extends TwoColumnLayout {
-
-  @Override
-  protected void preHead(Page.HTML<__> html) {
-    commonPreHead(html);
-
-    setTitle("Router");
-  }
-
-  protected void commonPreHead(Page.HTML<__> html) {
-    set(ACCORDION_ID, "nav");
-    set(initID(ACCORDION, "nav"), "{autoHeight:false, active:0}");
-  }
-
-  @Override
-  protected Class<? extends SubView> nav() {
-    return NavBlock.class;
-  }
-
-  @Override
-  protected Class<? extends SubView> content() {
-    return AboutBlock.class;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterWebApp.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterWebApp.java
deleted file mode 100644
index 989a3d43b43..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterWebApp.java
+++ /dev/null
@@ -1,57 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.JAXBContextResolver;
-import org.apache.hadoop.yarn.server.router.Router;
-import org.apache.hadoop.yarn.webapp.GenericExceptionHandler;
-import org.apache.hadoop.yarn.webapp.WebApp;
-import org.apache.hadoop.yarn.webapp.YarnWebParams;
-
-import static org.apache.hadoop.yarn.util.StringHelper.pajoin;
-
-/**
- * The Router webapp.
- */
-public class RouterWebApp extends WebApp implements YarnWebParams {
-  private Router router;
-
-  public RouterWebApp(Router router) {
-    this.router = router;
-  }
-
-  @Override
-  public void setup() {
-    bind(JAXBContextResolver.class);
-    bind(RouterWebServices.class);
-    bind(GenericExceptionHandler.class);
-    bind(RouterWebApp.class).toInstance(this);
-
-    if (router != null) {
-      bind(Router.class).toInstance(router);
-    }
-    route("/", RouterController.class);
-    route("/cluster", RouterController.class, "about");
-    route("/about", RouterController.class, "about");
-    route(pajoin("/apps", APP_SC, APP_STATE), RouterController.class, "apps");
-    route(pajoin("/nodes", NODE_SC), RouterController.class, "nodes");
-    route("/federation", RouterController.class, "federation");
-    route(pajoin("/nodelabels", NODE_SC), RouterController.class, "nodeLabels");
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterWebServiceUtil.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterWebServiceUtil.java
deleted file mode 100644
index f2c385fd022..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterWebServiceUtil.java
+++ /dev/null
@@ -1,776 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import static javax.servlet.http.HttpServletResponse.SC_NO_CONTENT;
-import static javax.servlet.http.HttpServletResponse.SC_OK;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices.DELEGATION_TOKEN_HEADER;
-
-import java.io.IOException;
-import java.net.InetSocketAddress;
-import java.security.PrivilegedExceptionAction;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Map;
-import java.util.Map.Entry;
-import java.util.Collection;
-import java.util.Set;
-import java.util.HashSet;
-import java.util.concurrent.TimeUnit;
-
-import javax.servlet.http.HttpServletRequest;
-import javax.ws.rs.core.HttpHeaders;
-import javax.ws.rs.core.MediaType;
-import javax.ws.rs.core.MultivaluedMap;
-import javax.ws.rs.core.Response;
-import javax.ws.rs.core.Response.ResponseBuilder;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.CommonConfigurationKeys;
-import org.apache.hadoop.net.NetUtils;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.security.authentication.server.KerberosAuthenticationHandler;
-import org.apache.hadoop.security.authorize.AuthorizationException;
-import org.apache.hadoop.security.token.Token;
-import org.apache.hadoop.security.token.delegation.web.DelegationTokenAuthenticationHandler;
-import org.apache.hadoop.yarn.api.records.YarnApplicationState;
-import org.apache.hadoop.yarn.api.records.NodeLabel;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.security.client.RMDelegationTokenIdentifier;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebAppUtil;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationStatisticsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.StatisticsItemInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionInfo;
-import org.apache.hadoop.yarn.server.uam.UnmanagedApplicationManager;
-import org.apache.hadoop.yarn.webapp.BadRequestException;
-import org.apache.hadoop.yarn.webapp.ForbiddenException;
-import org.apache.hadoop.yarn.webapp.NotFoundException;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import com.sun.jersey.api.ConflictException;
-import com.sun.jersey.api.client.Client;
-import com.sun.jersey.api.client.ClientResponse;
-import com.sun.jersey.api.client.WebResource;
-import com.sun.jersey.api.client.WebResource.Builder;
-import com.sun.jersey.core.util.MultivaluedMapImpl;
-
-/**
- * The Router webservice util class.
- */
-public final class RouterWebServiceUtil {
-
-  private static String user = "YarnRouter";
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(RouterWebServiceUtil.class.getName());
-
-  private final static String PARTIAL_REPORT = "Partial Report ";
-
-  /** Disable constructor. */
-  private RouterWebServiceUtil() {
-  }
-
-  /**
-   * Creates and performs a REST call to a specific WebService.
-   *
-   * @param webApp the address of the remote webapp
-   * @param hsr the servlet request
-   * @param returnType the return type of the REST call
-   * @param <T> Type of return object.
-   * @param method the HTTP method of the REST call
-   * @param targetPath additional path to add to the webapp address
-   * @param formParam the form parameters as input for a specific REST call
-   * @param additionalParam the query parameters as input for a specific REST
-   *          call in case the call has no servlet request
-   * @param conf configuration.
-   * @param client same client used to reduce number of clients created
-   * @return the retrieved entity from the REST call
-   */
-  protected static <T> T genericForward(final String webApp,
-      final HttpServletRequest hsr, final Class<T> returnType,
-      final HTTPMethods method, final String targetPath, final Object formParam,
-      final Map<String, String[]> additionalParam, Configuration conf,
-      Client client) {
-
-    UserGroupInformation callerUGI = null;
-
-    if (hsr != null) {
-      callerUGI = RMWebAppUtil.getCallerUserGroupInformation(hsr, true);
-    } else {
-      // user not required
-      callerUGI = UserGroupInformation.createRemoteUser(user);
-
-    }
-
-    if (callerUGI == null) {
-      LOG.error("Unable to obtain user name, user not authenticated");
-      return null;
-    }
-
-    try {
-      return callerUGI.doAs(new PrivilegedExceptionAction<T>() {
-        @SuppressWarnings("unchecked")
-        @Override
-        public T run() {
-
-          Map<String, String[]> paramMap = null;
-
-          // We can have hsr or additionalParam. There are no case with both.
-          if (hsr != null) {
-            paramMap = hsr.getParameterMap();
-          } else if (additionalParam != null) {
-            paramMap = additionalParam;
-          }
-
-          ClientResponse response = RouterWebServiceUtil
-              .invokeRMWebService(webApp, targetPath, method,
-                  (hsr == null) ? null : hsr.getPathInfo(), paramMap, formParam,
-                  getMediaTypeFromHttpServletRequest(hsr, returnType), conf,
-                  client);
-          if (Response.class.equals(returnType)) {
-            return (T) RouterWebServiceUtil.clientResponseToResponse(response);
-          }
-
-          try {
-            // YARN RM can answer with Status.OK or it throws an exception
-            if (response.getStatus() == SC_OK) {
-              return response.getEntity(returnType);
-            }
-            if (response.getStatus() == SC_NO_CONTENT) {
-              try {
-                return returnType.getConstructor().newInstance();
-              } catch (RuntimeException | ReflectiveOperationException e) {
-                LOG.error("Cannot create empty entity for {}", returnType, e);
-              }
-            }
-            RouterWebServiceUtil.retrieveException(response);
-            return null;
-          } finally {
-            if (response != null) {
-              response.close();
-            }
-          }
-        }
-      });
-    } catch (InterruptedException e) {
-      return null;
-    } catch (IOException e) {
-      return null;
-    }
-  }
-
-  /**
-   * Performs an invocation of a REST call on a remote RMWebService.
-   * @param webApp the address of the remote webapp
-   * @param path  to add to the webapp address
-   * @param method the HTTP method of the REST call
-   * @param additionalPath the servlet request path
-   * @param queryParams hsr of additional Param
-   * @param formParam the form parameters as input for a specific REST call
-   * @param mediaType Media type for Servlet request call
-   * @param conf to support http and https
-   * @param client same client used to reduce number of clients created
-   * @return Client response to REST call
-   */
-  private static ClientResponse invokeRMWebService(String webApp, String path,
-      HTTPMethods method, String additionalPath,
-      Map<String, String[]> queryParams, Object formParam, String mediaType,
-      Configuration conf, Client client) {
-    InetSocketAddress socketAddress = NetUtils
-        .getConnectAddress(NetUtils.createSocketAddr(webApp));
-    String scheme = YarnConfiguration.useHttps(conf) ? "https://" : "http://";
-    String webAddress = scheme + socketAddress.getHostName() + ":"
-        + socketAddress.getPort();
-    WebResource webResource = client.resource(webAddress).path(path);
-
-    if (additionalPath != null && !additionalPath.isEmpty()) {
-      webResource = webResource.path(additionalPath);
-    }
-
-    if (queryParams != null && !queryParams.isEmpty()) {
-      MultivaluedMap<String, String> paramMap = new MultivaluedMapImpl();
-
-      for (Entry<String, String[]> param : queryParams.entrySet()) {
-        String[] values = param.getValue();
-        for (int i = 0; i < values.length; i++) {
-          paramMap.add(param.getKey(), values[i]);
-        }
-      }
-      webResource = webResource.queryParams(paramMap);
-    }
-
-    Builder builder = null;
-    if (formParam != null) {
-      builder = webResource.entity(formParam, mediaType);
-      builder = builder.accept(mediaType);
-    } else {
-      builder = webResource.accept(mediaType);
-    }
-
-    ClientResponse response = null;
-
-    try {
-      switch (method) {
-      case DELETE:
-        response = builder.delete(ClientResponse.class);
-        break;
-      case GET:
-        response = builder.get(ClientResponse.class);
-        break;
-      case POST:
-        response = builder.post(ClientResponse.class);
-        break;
-      case PUT:
-        response = builder.put(ClientResponse.class);
-        break;
-      default:
-        break;
-      }
-    } finally {
-      client.destroy();
-    }
-
-    return response;
-  }
-
-  public static Response clientResponseToResponse(ClientResponse r) {
-    if (r == null) {
-      return null;
-    }
-    // copy the status code
-    ResponseBuilder rb = Response.status(r.getStatus());
-    // copy all the headers
-    for (Entry<String, List<String>> entry : r.getHeaders().entrySet()) {
-      for (String value : entry.getValue()) {
-        rb.header(entry.getKey(), value);
-      }
-    }
-    // copy the entity
-    rb.entity(r.getEntityInputStream());
-    // return the response
-    return rb.build();
-  }
-
-  public static void retrieveException(ClientResponse response) {
-    String serverErrorMsg = response.getEntity(String.class);
-    int status = response.getStatus();
-    if (status == 400) {
-      throw new BadRequestException(serverErrorMsg);
-    }
-    if (status == 403) {
-      throw new ForbiddenException(serverErrorMsg);
-    }
-    if (status == 404) {
-      throw new NotFoundException(serverErrorMsg);
-    }
-    if (status == 409) {
-      throw new ConflictException(serverErrorMsg);
-    }
-
-  }
-
-  /**
-   * Merges a list of AppInfo grouping by ApplicationId. Our current policy is
-   * to merge the application reports from the reachable SubClusters. Via
-   * configuration parameter, we decide whether to return applications for which
-   * the primary AM is missing or to omit them.
-   *
-   * @param appsInfo a list of AppInfo to merge
-   * @param returnPartialResult if the merge AppsInfo should contain partial
-   *          result or not
-   * @return the merged AppsInfo
-   */
-  public static AppsInfo mergeAppsInfo(ArrayList<AppInfo> appsInfo,
-      boolean returnPartialResult) {
-    AppsInfo allApps = new AppsInfo();
-
-    Map<String, AppInfo> federationAM = new HashMap<>();
-    Map<String, AppInfo> federationUAMSum = new HashMap<>();
-    for (AppInfo a : appsInfo) {
-      // Check if this AppInfo is an AM
-      if (a.getAMHostHttpAddress() != null) {
-        // Insert in the list of AM
-        federationAM.put(a.getAppId(), a);
-        // Check if there are any UAM found before
-        if (federationUAMSum.containsKey(a.getAppId())) {
-          // Merge the current AM with the found UAM
-          mergeAMWithUAM(a, federationUAMSum.get(a.getAppId()));
-          // Remove the sum of the UAMs
-          federationUAMSum.remove(a.getAppId());
-        }
-        // This AppInfo is an UAM
-      } else {
-        if (federationAM.containsKey(a.getAppId())) {
-          // Merge the current UAM with its own AM
-          mergeAMWithUAM(federationAM.get(a.getAppId()), a);
-        } else if (federationUAMSum.containsKey(a.getAppId())) {
-          // Merge the current UAM with its own UAM and update the list of UAM
-          federationUAMSum.put(a.getAppId(),
-              mergeUAMWithUAM(federationUAMSum.get(a.getAppId()), a));
-        } else {
-          // Insert in the list of UAM
-          federationUAMSum.put(a.getAppId(), a);
-        }
-      }
-    }
-
-    // Check the remaining UAMs are depending or not from federation
-    for (AppInfo a : federationUAMSum.values()) {
-      if (returnPartialResult || (a.getName() != null
-          && !(a.getName().startsWith(UnmanagedApplicationManager.APP_NAME)
-              || a.getName().startsWith(PARTIAL_REPORT)))) {
-        federationAM.put(a.getAppId(), a);
-      }
-    }
-
-    allApps.addAll(new ArrayList<>(federationAM.values()));
-    return allApps;
-  }
-
-  /**
-   * Create a Jersey client instance.
-   * @param conf Configuration
-   * @return a jersey client
-   */
-  protected static Client createJerseyClient(Configuration conf) {
-    Client client = Client.create();
-
-    long checkConnectTimeOut = conf.getLong(YarnConfiguration.ROUTER_WEBAPP_CONNECT_TIMEOUT, 0);
-    int connectTimeOut = (int) conf.getTimeDuration(YarnConfiguration.ROUTER_WEBAPP_CONNECT_TIMEOUT,
-        YarnConfiguration.DEFAULT_ROUTER_WEBAPP_CONNECT_TIMEOUT, TimeUnit.MILLISECONDS);
-    if (checkConnectTimeOut <= 0 || checkConnectTimeOut > Integer.MAX_VALUE) {
-      LOG.warn("Configuration {} = {} ms error. We will use the default value({} ms).",
-          YarnConfiguration.ROUTER_WEBAPP_CONNECT_TIMEOUT, connectTimeOut,
-          YarnConfiguration.DEFAULT_ROUTER_WEBAPP_CONNECT_TIMEOUT);
-      connectTimeOut = (int) TimeUnit.MILLISECONDS.convert(
-          YarnConfiguration.DEFAULT_ROUTER_WEBAPP_CONNECT_TIMEOUT, TimeUnit.MILLISECONDS);
-    }
-    client.setConnectTimeout(connectTimeOut);
-
-    long checkReadTimeout = conf.getLong(YarnConfiguration.ROUTER_WEBAPP_READ_TIMEOUT, 0);
-    int readTimeout = (int) conf.getTimeDuration(YarnConfiguration.ROUTER_WEBAPP_READ_TIMEOUT,
-        YarnConfiguration.DEFAULT_ROUTER_WEBAPP_READ_TIMEOUT, TimeUnit.MILLISECONDS);
-
-    if (checkReadTimeout < 0) {
-      LOG.warn("Configuration {} = {} ms error. We will use the default value({} ms).",
-          YarnConfiguration.ROUTER_WEBAPP_CONNECT_TIMEOUT, connectTimeOut,
-          YarnConfiguration.DEFAULT_ROUTER_WEBAPP_CONNECT_TIMEOUT);
-      readTimeout = (int) TimeUnit.MILLISECONDS.convert(
-          YarnConfiguration.DEFAULT_ROUTER_WEBAPP_CONNECT_TIMEOUT, TimeUnit.MILLISECONDS);
-    }
-    client.setReadTimeout(readTimeout);
-
-    return client;
-  }
-
-  private static AppInfo mergeUAMWithUAM(AppInfo uam1, AppInfo uam2) {
-    AppInfo partialReport = new AppInfo();
-    partialReport.setAppId(uam1.getAppId());
-    partialReport.setName(PARTIAL_REPORT + uam1.getAppId());
-    // We pick the status of the first uam
-    partialReport.setState(uam1.getState());
-    // Merge the newly partial AM with UAM1 and then with UAM2
-    mergeAMWithUAM(partialReport, uam1);
-    mergeAMWithUAM(partialReport, uam2);
-    return partialReport;
-  }
-
-  private static void mergeAMWithUAM(AppInfo am, AppInfo uam) {
-    am.setPreemptedResourceMB(
-        am.getPreemptedResourceMB() + uam.getPreemptedResourceMB());
-    am.setPreemptedResourceVCores(
-        am.getPreemptedResourceVCores() + uam.getPreemptedResourceVCores());
-    am.setNumNonAMContainerPreempted(am.getNumNonAMContainerPreempted()
-        + uam.getNumNonAMContainerPreempted());
-    am.setNumAMContainerPreempted(
-        am.getNumAMContainerPreempted() + uam.getNumAMContainerPreempted());
-    am.setPreemptedMemorySeconds(
-        am.getPreemptedMemorySeconds() + uam.getPreemptedMemorySeconds());
-    am.setPreemptedVcoreSeconds(
-        am.getPreemptedVcoreSeconds() + uam.getPreemptedVcoreSeconds());
-
-    if (am.getState() == YarnApplicationState.RUNNING
-        && uam.getState() == am.getState()) {
-
-      am.getResourceRequests().addAll(uam.getResourceRequests());
-
-      am.setAllocatedMB(am.getAllocatedMB() + uam.getAllocatedMB());
-      am.setAllocatedVCores(am.getAllocatedVCores() + uam.getAllocatedVCores());
-      am.setReservedMB(am.getReservedMB() + uam.getReservedMB());
-      am.setReservedVCores(am.getReservedVCores() + uam.getReservedMB());
-      am.setRunningContainers(
-          am.getRunningContainers() + uam.getRunningContainers());
-      am.setMemorySeconds(am.getMemorySeconds() + uam.getMemorySeconds());
-      am.setVcoreSeconds(am.getVcoreSeconds() + uam.getVcoreSeconds());
-    }
-  }
-
-  /**
-   * Deletes all the duplicate NodeInfo by discarding the old instances.
-   *
-   * @param nodes a list of NodeInfo to check for duplicates
-   * @return a NodesInfo that contains a list of NodeInfos without duplicates
-   */
-  public static NodesInfo deleteDuplicateNodesInfo(ArrayList<NodeInfo> nodes) {
-    NodesInfo nodesInfo = new NodesInfo();
-
-    Map<String, NodeInfo> nodesMap = new LinkedHashMap<>();
-    for (NodeInfo node : nodes) {
-      String nodeId = node.getNodeId();
-      // If the node already exists, it could be an old instance
-      if (nodesMap.containsKey(nodeId)) {
-        // Check if the node is an old instance
-        if (nodesMap.get(nodeId).getLastHealthUpdate() < node
-            .getLastHealthUpdate()) {
-          nodesMap.put(node.getNodeId(), node);
-        }
-      } else {
-        nodesMap.put(node.getNodeId(), node);
-      }
-    }
-    nodesInfo.addAll(new ArrayList<>(nodesMap.values()));
-    return nodesInfo;
-  }
-
-  /**
-   * Adds all the values from the second ClusterMetricsInfo to the first one.
-   *
-   * @param metrics the ClusterMetricsInfo we want to update
-   * @param metricsResponse the ClusterMetricsInfo we want to add to the first
-   *          param
-   */
-  public static void mergeMetrics(ClusterMetricsInfo metrics,
-      ClusterMetricsInfo metricsResponse) {
-    metrics.setAppsSubmitted(
-        metrics.getAppsSubmitted() + metricsResponse.getAppsSubmitted());
-    metrics.setAppsCompleted(
-        metrics.getAppsCompleted() + metricsResponse.getAppsCompleted());
-    metrics.setAppsPending(
-        metrics.getAppsPending() + metricsResponse.getAppsPending());
-    metrics.setAppsRunning(
-        metrics.getAppsRunning() + metricsResponse.getAppsRunning());
-    metrics.setAppsFailed(
-        metrics.getAppsFailed() + metricsResponse.getAppsFailed());
-    metrics.setAppsKilled(
-        metrics.getAppsKilled() + metricsResponse.getAppsKilled());
-
-    metrics.setReservedMB(
-        metrics.getReservedMB() + metricsResponse.getReservedMB());
-    metrics.setAvailableMB(
-        metrics.getAvailableMB() + metricsResponse.getAvailableMB());
-    metrics.setAllocatedMB(
-        metrics.getAllocatedMB() + metricsResponse.getAllocatedMB());
-
-    metrics.setReservedVirtualCores(metrics.getReservedVirtualCores()
-        + metricsResponse.getReservedVirtualCores());
-    metrics.setAvailableVirtualCores(metrics.getAvailableVirtualCores()
-        + metricsResponse.getAvailableVirtualCores());
-    metrics.setAllocatedVirtualCores(metrics.getAllocatedVirtualCores()
-        + metricsResponse.getAllocatedVirtualCores());
-
-    metrics.setContainersAllocated(metrics.getContainersAllocated()
-        + metricsResponse.getContainersAllocated());
-    metrics.setContainersReserved(metrics.getReservedContainers()
-        + metricsResponse.getReservedContainers());
-    metrics.setContainersPending(metrics.getPendingContainers()
-        + metricsResponse.getPendingContainers());
-
-    metrics.setTotalMB(metrics.getTotalMB()
-        + metricsResponse.getTotalMB());
-    metrics.setUtilizedMB(metrics.getUtilizedMB()
-        + metricsResponse.getUtilizedMB());
-    metrics.setTotalVirtualCores(metrics.getTotalVirtualCores()
-        + metricsResponse.getTotalVirtualCores());
-    metrics.setTotalNodes(metrics.getTotalNodes()
-        + metricsResponse.getTotalNodes());
-    metrics.setUtilizedVirtualCores(metrics.getUtilizedVirtualCores()
-        + metricsResponse.getUtilizedVirtualCores());
-    metrics.setLostNodes(metrics.getLostNodes()
-        + metricsResponse.getLostNodes());
-    metrics.setUnhealthyNodes(metrics.getUnhealthyNodes()
-        + metricsResponse.getUnhealthyNodes());
-    metrics.setDecommissioningNodes(metrics.getDecommissioningNodes()
-        + metricsResponse.getDecommissioningNodes());
-    metrics.setDecommissionedNodes(metrics.getDecommissionedNodes()
-        + metricsResponse.getDecommissionedNodes());
-    metrics.setRebootedNodes(metrics.getRebootedNodes()
-        + metricsResponse.getRebootedNodes());
-    metrics.setActiveNodes(metrics.getActiveNodes()
-        + metricsResponse.getActiveNodes());
-    metrics.setShutdownNodes(metrics.getShutdownNodes()
-        + metricsResponse.getShutdownNodes());
-
-    int utilizedVirtualCoresPercent = metrics.getTotalVirtualCores() <= 0 ? 0 :
-        (int) (metrics.getUtilizedVirtualCores() * 100 / metrics.getTotalVirtualCores());
-    metrics.setUtilizedVirtualCoresPercent(utilizedVirtualCoresPercent);
-
-    int utilizedMBPercent = metrics.getTotalMB() <= 0 ? 0 :
-        (int) (metrics.getUtilizedMB() * 100 / metrics.getTotalMB());
-    metrics.setUtilizedMBPercent(utilizedMBPercent);
-  }
-
-  /**
-   * Extract from HttpServletRequest the MediaType in output.
-   *
-   * @param request the servlet request.
-   * @param returnType the return type of the REST call.
-   * @param <T> Generic Type T.
-   * @return MediaType.
-   */
-  protected static <T> String getMediaTypeFromHttpServletRequest(
-      HttpServletRequest request, final Class<T> returnType) {
-    if (request == null) {
-      // By default, we return XML for REST call without HttpServletRequest
-      return MediaType.APPLICATION_XML;
-    }
-    // TODO
-    if (!returnType.equals(Response.class)) {
-      return MediaType.APPLICATION_XML;
-    }
-    String header = request.getHeader(HttpHeaders.ACCEPT);
-    if (header == null || header.equals("*")) {
-      // By default, we return JSON
-      return MediaType.APPLICATION_JSON;
-    }
-    return header;
-  }
-
-  public static NodeToLabelsInfo mergeNodeToLabels(
-      Map<SubClusterInfo, NodeToLabelsInfo> nodeToLabelsInfoMap) {
-
-    HashMap<String, NodeLabelsInfo> nodeToLabels = new HashMap<>();
-    Collection<NodeToLabelsInfo> nodeToLabelsInfos = nodeToLabelsInfoMap.values();
-
-    nodeToLabelsInfos.stream().forEach(nodeToLabelsInfo -> {
-      for (Map.Entry<String, NodeLabelsInfo> item : nodeToLabelsInfo.getNodeToLabels().entrySet()) {
-        String key = item.getKey();
-        NodeLabelsInfo itemValue = item.getValue();
-        NodeLabelsInfo nodeToLabelsValue = nodeToLabels.getOrDefault(item.getKey(), null);
-        Set<NodeLabel> hashSet = new HashSet<>();
-        if (itemValue != null) {
-          hashSet.addAll(itemValue.getNodeLabels());
-        }
-        if (nodeToLabelsValue != null) {
-          hashSet.addAll(nodeToLabelsValue.getNodeLabels());
-        }
-        nodeToLabels.put(key, new NodeLabelsInfo(hashSet));
-      }
-    });
-
-    return new NodeToLabelsInfo(nodeToLabels);
-  }
-
-  public static ApplicationStatisticsInfo mergeApplicationStatisticsInfo(
-      Collection<ApplicationStatisticsInfo> appStatistics) {
-    ApplicationStatisticsInfo result = new ApplicationStatisticsInfo();
-    Map<String, StatisticsItemInfo> statisticsItemMap = new HashMap<>();
-
-    appStatistics.stream().forEach(appStatistic -> {
-      List<StatisticsItemInfo> statisticsItemInfos = appStatistic.getStatItems();
-      for (StatisticsItemInfo statisticsItemInfo : statisticsItemInfos) {
-
-        String statisticsItemKey =
-            statisticsItemInfo.getType() + "_" + statisticsItemInfo.getState().toString();
-
-        StatisticsItemInfo statisticsItemValue;
-        if (statisticsItemMap.containsKey(statisticsItemKey)) {
-          statisticsItemValue = statisticsItemMap.get(statisticsItemKey);
-          long statisticsItemValueCount = statisticsItemValue.getCount();
-          long statisticsItemInfoCount = statisticsItemInfo.getCount();
-          long newCount = statisticsItemValueCount + statisticsItemInfoCount;
-          statisticsItemValue.setCount(newCount);
-        } else {
-          statisticsItemValue = new StatisticsItemInfo(statisticsItemInfo);
-        }
-
-        statisticsItemMap.put(statisticsItemKey, statisticsItemValue);
-      }
-    });
-
-    if (!statisticsItemMap.isEmpty()) {
-      result.getStatItems().addAll(statisticsItemMap.values());
-    }
-
-    return result;
-  }
-
-  public static NodeLabelsInfo mergeNodeLabelsInfo(Map<SubClusterInfo, NodeLabelsInfo> paramMap) {
-    Map<String, NodeLabelInfo> resultMap = new HashMap<>();
-    paramMap.values().stream()
-        .flatMap(nodeLabelsInfo -> nodeLabelsInfo.getNodeLabelsInfo().stream())
-        .forEach(nodeLabelInfo -> {
-          String keyLabelName = nodeLabelInfo.getName();
-          if (resultMap.containsKey(keyLabelName)) {
-            NodeLabelInfo mapNodeLabelInfo = resultMap.get(keyLabelName);
-            mapNodeLabelInfo = mergeNodeLabelInfo(mapNodeLabelInfo, nodeLabelInfo);
-            resultMap.put(keyLabelName, mapNodeLabelInfo);
-          } else {
-            resultMap.put(keyLabelName, nodeLabelInfo);
-          }
-        });
-    NodeLabelsInfo nodeLabelsInfo = new NodeLabelsInfo();
-    nodeLabelsInfo.getNodeLabelsInfo().addAll(resultMap.values());
-    return nodeLabelsInfo;
-  }
-
-  private static NodeLabelInfo mergeNodeLabelInfo(NodeLabelInfo left, NodeLabelInfo right) {
-    NodeLabelInfo resultNodeLabelInfo = new NodeLabelInfo();
-    resultNodeLabelInfo.setName(left.getName());
-
-    int newActiveNMs = left.getActiveNMs() + right.getActiveNMs();
-    resultNodeLabelInfo.setActiveNMs(newActiveNMs);
-
-    boolean newExclusivity = left.getExclusivity() && right.getExclusivity();
-    resultNodeLabelInfo.setExclusivity(newExclusivity);
-
-    PartitionInfo leftPartition = left.getPartitionInfo();
-    PartitionInfo rightPartition = right.getPartitionInfo();
-    PartitionInfo newPartitionInfo = PartitionInfo.addTo(leftPartition, rightPartition);
-    resultNodeLabelInfo.setPartitionInfo(newPartitionInfo);
-    return resultNodeLabelInfo;
-  }
-
-  /**
-   * initForWritableEndpoints does the init and acls verification for all
-   * writable REST end points.
-   *
-   * @param conf Configuration.
-   * @param callerUGI remote caller who initiated the request.
-   * @throws AuthorizationException in case of no access to perfom this op.
-   */
-  public static void initForWritableEndpoints(Configuration conf, UserGroupInformation callerUGI)
-          throws AuthorizationException {
-    if (callerUGI == null) {
-      String msg = "Unable to obtain user name, user not authenticated";
-      throw new AuthorizationException(msg);
-    }
-
-    if (UserGroupInformation.isSecurityEnabled() && isStaticUser(conf, callerUGI)) {
-      String msg = "The default static user cannot carry out this operation.";
-      throw new ForbiddenException(msg);
-    }
-  }
-
-  /**
-   * Determine whether the user is a static user.
-   *
-   * @param conf Configuration.
-   * @param callerUGI remote caller who initiated the request.
-   * @return true, static user; false, not static user;
-   */
-  private static boolean isStaticUser(Configuration conf, UserGroupInformation callerUGI) {
-    String staticUser = conf.get(CommonConfigurationKeys.HADOOP_HTTP_STATIC_USER,
-            CommonConfigurationKeys.DEFAULT_HADOOP_HTTP_STATIC_USER);
-    return staticUser.equals(callerUGI.getUserName());
-  }
-
-  public static void createKerberosUserGroupInformation(HttpServletRequest hsr)
-          throws YarnException {
-    String authType = hsr.getAuthType();
-
-    if (!KerberosAuthenticationHandler.TYPE.equalsIgnoreCase(authType)) {
-      String msg = "Delegation token operations can only be carried out on a "
-              + "Kerberos authenticated channel. Expected auth type is "
-              + KerberosAuthenticationHandler.TYPE + ", got type " + authType;
-      throw new YarnException(msg);
-    }
-
-    Object ugiAttr =
-            hsr.getAttribute(DelegationTokenAuthenticationHandler.DELEGATION_TOKEN_UGI_ATTRIBUTE);
-    if (ugiAttr != null) {
-      String msg = "Delegation token operations cannot be carried out using "
-              + "delegation token authentication.";
-      throw new YarnException(msg);
-    }
-  }
-
-  /**
-   * Parse Token data.
-   *
-   * @param encodedToken tokenData
-   * @return RMDelegationTokenIdentifier.
-   */
-  public static Token<RMDelegationTokenIdentifier> extractToken(String encodedToken) {
-    Token<RMDelegationTokenIdentifier> token = new Token<>();
-    try {
-      token.decodeFromUrlString(encodedToken);
-    } catch (Exception ie) {
-      throw new BadRequestException("Could not decode encoded token");
-    }
-    return token;
-  }
-
-  public static Token<RMDelegationTokenIdentifier> extractToken(HttpServletRequest request) {
-    String encodedToken = request.getHeader(DELEGATION_TOKEN_HEADER);
-    if (encodedToken == null) {
-      String msg = "Header '" + DELEGATION_TOKEN_HEADER
-              + "' containing encoded token not found";
-      throw new BadRequestException(msg);
-    }
-    return extractToken(encodedToken);
-  }
-
-  /**
-   * Get Kerberos UserGroupInformation.
-   *
-   * Parse ugi from hsr and set kerberos authentication attributes.
-   *
-   * @param conf Configuration.
-   * @param request the servlet request.
-   * @return UserGroupInformation.
-   * @throws AuthorizationException if Kerberos auth failed.
-   * @throws YarnException If Authentication Type verification fails.
-   */
-  public static UserGroupInformation getKerberosUserGroupInformation(Configuration conf,
-      HttpServletRequest request) throws AuthorizationException, YarnException {
-    // Parse ugi from hsr And Check ugi as expected.
-    // If ugi is empty or user is a static user, an exception will be thrown.
-    UserGroupInformation callerUGI = RMWebAppUtil.getCallerUserGroupInformation(request, true);
-    initForWritableEndpoints(conf, callerUGI);
-
-    // Set AuthenticationMethod Kerberos for ugi.
-    createKerberosUserGroupInformation(request);
-    callerUGI.setAuthenticationMethod(UserGroupInformation.AuthenticationMethod.KERBEROS);
-
-    // return caller UGI
-    return callerUGI;
-  }
-
-  public static String generateWebTitle(String title, String msg) {
-    StringBuilder stringBuilder = new StringBuilder();
-    stringBuilder.append(title);
-    stringBuilder.append(" (");
-    stringBuilder.append(msg);
-    stringBuilder.append(")");
-    return stringBuilder.toString();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterWebServices.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterWebServices.java
deleted file mode 100644
index 4e0d97e83e9..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/RouterWebServices.java
+++ /dev/null
@@ -1,964 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import java.io.IOException;
-import java.util.Collections;
-import java.util.Map;
-import java.util.Set;
-
-import javax.servlet.http.HttpServletRequest;
-import javax.servlet.http.HttpServletResponse;
-import javax.ws.rs.Consumes;
-import javax.ws.rs.DELETE;
-import javax.ws.rs.DefaultValue;
-import javax.ws.rs.FormParam;
-import javax.ws.rs.GET;
-import javax.ws.rs.POST;
-import javax.ws.rs.PUT;
-import javax.ws.rs.Path;
-import javax.ws.rs.PathParam;
-import javax.ws.rs.Produces;
-import javax.ws.rs.QueryParam;
-import javax.ws.rs.core.Context;
-import javax.ws.rs.core.MediaType;
-import javax.ws.rs.core.Response;
-
-import org.apache.hadoop.classification.InterfaceAudience.Private;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.http.JettyUtils;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.security.authorize.AuthorizationException;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServiceProtocol;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationStatisticsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterUserInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LabelsToNodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntryList;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.RMQueueAclInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceOptionInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.BulkActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerTypeInfo;
-import org.apache.hadoop.yarn.server.router.Router;
-import org.apache.hadoop.yarn.server.router.RouterServerUtil;
-import org.apache.hadoop.yarn.server.router.clientrm.RouterClientRMService;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainerInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainersInfo;
-import org.apache.hadoop.yarn.util.LRUCacheHashMap;
-import org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import org.apache.hadoop.classification.VisibleForTesting;
-import com.google.inject.Inject;
-import com.google.inject.Singleton;
-
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices.DEFAULT_ACTIVITIES_COUNT;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServices.DEFAULT_SUMMARIZE;
-
-/**
- * RouterWebServices is a service that runs on each router that can be used to
- * intercept and inspect {@link RMWebServiceProtocol} messages from client to
- * the cluster resource manager. It listens {@link RMWebServiceProtocol} REST
- * messages from the client and creates a request intercepting pipeline instance
- * for each client. The pipeline is a chain of {@link RESTRequestInterceptor}
- * instances that can inspect and modify the request/response as needed. The
- * main difference with AMRMProxyService is the protocol they implement.
- **/
-@Singleton
-@Path(RMWSConsts.RM_WEB_SERVICE_PATH)
-public class RouterWebServices implements RMWebServiceProtocol {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(RouterWebServices.class);
-  private final Router router;
-  private final Configuration conf;
-  private @Context HttpServletResponse response;
-
-  private Map<String, RequestInterceptorChainWrapper> userPipelineMap;
-
-  // -------Default values of QueryParams for RMWebServiceProtocol--------
-
-  public static final String DEFAULT_QUEUE = "default";
-  public static final String DEFAULT_RESERVATION_ID = "";
-  public static final String DEFAULT_START_TIME = "0";
-  public static final String DEFAULT_END_TIME = "-1";
-  public static final String DEFAULT_INCLUDE_RESOURCE = "false";
-
-  @Inject
-  public RouterWebServices(final Router router, Configuration conf) {
-    this.router = router;
-    this.conf = conf;
-    int maxCacheSize =
-        conf.getInt(YarnConfiguration.ROUTER_PIPELINE_CACHE_MAX_SIZE,
-            YarnConfiguration.DEFAULT_ROUTER_PIPELINE_CACHE_MAX_SIZE);
-    this.userPipelineMap = Collections.synchronizedMap(new LRUCacheHashMap<>(maxCacheSize, true));
-  }
-
-  private void init() {
-    // clear content type
-    response.setContentType(null);
-  }
-
-  @VisibleForTesting
-  protected RequestInterceptorChainWrapper getInterceptorChain(
-      final HttpServletRequest hsr) {
-    String user = "";
-    if (hsr != null) {
-      user = hsr.getRemoteUser();
-    }
-    try {
-      if (user == null || user.equals("")) {
-        // Yarn Router user
-        user = UserGroupInformation.getCurrentUser().getUserName();
-      }
-    } catch (IOException e) {
-      LOG.error("Cannot get user: {}", e.getMessage());
-    }
-    RequestInterceptorChainWrapper chain = userPipelineMap.get(user);
-    if (chain != null && chain.getRootInterceptor() != null) {
-      return chain;
-    }
-    return initializePipeline(user);
-  }
-
-  /**
-   * Gets the Request interceptor chains for all the users.
-   *
-   * @return the request interceptor chains.
-   */
-  @VisibleForTesting
-  protected Map<String, RequestInterceptorChainWrapper> getPipelines() {
-    return this.userPipelineMap;
-  }
-
-  /**
-   * This method creates and returns reference of the first interceptor in the
-   * chain of request interceptor instances.
-   *
-   * @return the reference of the first interceptor in the chain
-   */
-  @VisibleForTesting
-  protected RESTRequestInterceptor createRequestInterceptorChain() {
-    return RouterServerUtil.createRequestInterceptorChain(conf,
-        YarnConfiguration.ROUTER_WEBAPP_INTERCEPTOR_CLASS_PIPELINE,
-        YarnConfiguration.DEFAULT_ROUTER_WEBAPP_INTERCEPTOR_CLASS,
-        RESTRequestInterceptor.class);
-  }
-
-  /**
-   * Initializes the request interceptor pipeline for the specified user.
-   *
-   * @param user specified user.
-   */
-  private RequestInterceptorChainWrapper initializePipeline(String user) {
-    synchronized (this.userPipelineMap) {
-      if (this.userPipelineMap.containsKey(user)) {
-        LOG.info("Request to start an already existing user: {}"
-            + " was received, so ignoring.", user);
-        return userPipelineMap.get(user);
-      }
-
-      RequestInterceptorChainWrapper chainWrapper =
-          new RequestInterceptorChainWrapper();
-      try {
-        // We should init the pipeline instance after it is created and then
-        // add to the map, to ensure thread safe.
-        LOG.info("Initializing request processing pipeline for user: {}.", user);
-
-        RESTRequestInterceptor interceptorChain =
-            this.createRequestInterceptorChain();
-        interceptorChain.init(user);
-        RouterClientRMService routerClientRMService = router.getClientRMProxyService();
-        interceptorChain.setRouterClientRMService(routerClientRMService);
-        chainWrapper.init(interceptorChain);
-      } catch (Exception e) {
-        LOG.error("Init RESTRequestInterceptor error for user: {}", user, e);
-        throw e;
-      }
-
-      this.userPipelineMap.put(user, chainWrapper);
-      return chainWrapper;
-    }
-  }
-
-  /**
-   * Private structure for encapsulating RequestInterceptor and user instances.
-   *
-   */
-  @Private
-  public static class RequestInterceptorChainWrapper {
-    private RESTRequestInterceptor rootInterceptor;
-
-    /**
-     * Initializes the wrapper with the specified parameters.
-     *
-     * @param interceptor the first interceptor in the pipeline
-     */
-    public synchronized void init(RESTRequestInterceptor interceptor) {
-      this.rootInterceptor = interceptor;
-    }
-
-    /**
-     * Gets the root request interceptor.
-     *
-     * @return the root request interceptor
-     */
-    public synchronized RESTRequestInterceptor getRootInterceptor() {
-      return rootInterceptor;
-    }
-
-    /**
-     * Shutdown the chain of interceptors when the object is destroyed.
-     */
-    @Override
-    protected void finalize() {
-      rootInterceptor.shutdown();
-    }
-  }
-
-  @GET
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public ClusterInfo get() {
-    return getClusterInfo();
-  }
-
-  @GET
-  @Path(RMWSConsts.INFO)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public ClusterInfo getClusterInfo() {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(null);
-    return pipeline.getRootInterceptor().getClusterInfo();
-  }
-
-  @GET
-  @Path(RMWSConsts.CLUSTER_USER_INFO)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public ClusterUserInfo getClusterUserInfo(@Context HttpServletRequest hsr) {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().getClusterUserInfo(hsr);
-  }
-
-  @GET
-  @Path(RMWSConsts.METRICS)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public ClusterMetricsInfo getClusterMetricsInfo() {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(null);
-    return pipeline.getRootInterceptor().getClusterMetricsInfo();
-  }
-
-  @GET
-  @Path(RMWSConsts.SCHEDULER)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public SchedulerTypeInfo getSchedulerInfo() {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(null);
-    return pipeline.getRootInterceptor().getSchedulerInfo();
-  }
-
-  @POST
-  @Path(RMWSConsts.SCHEDULER_LOGS)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public String dumpSchedulerLogs(@FormParam(RMWSConsts.TIME) String time,
-      @Context HttpServletRequest hsr) throws IOException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().dumpSchedulerLogs(time, hsr);
-  }
-
-  @GET
-  @Path(RMWSConsts.NODES)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public NodesInfo getNodes(@QueryParam(RMWSConsts.STATES) String states) {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(null);
-    return pipeline.getRootInterceptor().getNodes(states);
-  }
-
-  @GET
-  @Path(RMWSConsts.NODES_NODEID)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public NodeInfo getNode(@PathParam(RMWSConsts.NODEID) String nodeId) {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(null);
-    return pipeline.getRootInterceptor().getNode(nodeId);
-  }
-
-  @POST
-  @Path(RMWSConsts.NODE_RESOURCE)
-  @Consumes({ MediaType.APPLICATION_JSON, MediaType.APPLICATION_XML })
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public ResourceInfo updateNodeResource(
-      @Context HttpServletRequest hsr,
-      @PathParam(RMWSConsts.NODEID) String nodeId,
-      ResourceOptionInfo resourceOption) throws AuthorizationException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(null);
-    return pipeline.getRootInterceptor().updateNodeResource(
-        hsr, nodeId, resourceOption);
-  }
-
-  @GET
-  @Path(RMWSConsts.APPS)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public AppsInfo getApps(@Context HttpServletRequest hsr,
-      @QueryParam(RMWSConsts.STATE) String stateQuery,
-      @QueryParam(RMWSConsts.STATES) Set<String> statesQuery,
-      @QueryParam(RMWSConsts.FINAL_STATUS) String finalStatusQuery,
-      @QueryParam(RMWSConsts.USER) String userQuery,
-      @QueryParam(RMWSConsts.QUEUE) String queueQuery,
-      @QueryParam(RMWSConsts.LIMIT) String count,
-      @QueryParam(RMWSConsts.STARTED_TIME_BEGIN) String startedBegin,
-      @QueryParam(RMWSConsts.STARTED_TIME_END) String startedEnd,
-      @QueryParam(RMWSConsts.FINISHED_TIME_BEGIN) String finishBegin,
-      @QueryParam(RMWSConsts.FINISHED_TIME_END) String finishEnd,
-      @QueryParam(RMWSConsts.APPLICATION_TYPES) Set<String> applicationTypes,
-      @QueryParam(RMWSConsts.APPLICATION_TAGS) Set<String> applicationTags,
-      @QueryParam(RMWSConsts.NAME) String name,
-      @QueryParam(RMWSConsts.DESELECTS) Set<String> unselectedFields) {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().getApps(hsr, stateQuery, statesQuery,
-        finalStatusQuery, userQuery, queueQuery, count, startedBegin,
-        startedEnd, finishBegin, finishEnd, applicationTypes, applicationTags,
-        name, unselectedFields);
-  }
-
-  @GET
-  @Path(RMWSConsts.SCHEDULER_ACTIVITIES)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public ActivitiesInfo getActivities(@Context HttpServletRequest hsr,
-      @QueryParam(RMWSConsts.NODEID) String nodeId,
-      @QueryParam(RMWSConsts.GROUP_BY) String groupBy) {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor()
-        .getActivities(hsr, nodeId, groupBy);
-  }
-
-  @GET
-  @Path(RMWSConsts.SCHEDULER_BULK_ACTIVITIES)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public BulkActivitiesInfo getBulkActivities(
-      @Context HttpServletRequest hsr,
-      @QueryParam(RMWSConsts.GROUP_BY) String groupBy,
-      @QueryParam(RMWSConsts.ACTIVITIES_COUNT)
-      @DefaultValue(DEFAULT_ACTIVITIES_COUNT) int activitiesCount)
-      throws InterruptedException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().getBulkActivities(hsr, groupBy,
-        activitiesCount);
-  }
-
-  @GET
-  @Path(RMWSConsts.SCHEDULER_APP_ACTIVITIES)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public AppActivitiesInfo getAppActivities(@Context HttpServletRequest hsr,
-      @PathParam(RMWSConsts.APPID) String appId,
-      @QueryParam(RMWSConsts.MAX_TIME) String time,
-      @QueryParam(RMWSConsts.REQUEST_PRIORITIES) Set<String> requestPriorities,
-      @QueryParam(RMWSConsts.ALLOCATION_REQUEST_IDS)
-          Set<String> allocationRequestIds,
-      @QueryParam(RMWSConsts.GROUP_BY) String groupBy,
-      @QueryParam(RMWSConsts.LIMIT) String limit,
-      @QueryParam(RMWSConsts.ACTIONS) Set<String> actions,
-      @QueryParam(RMWSConsts.SUMMARIZE) @DefaultValue(DEFAULT_SUMMARIZE)
-          boolean summarize) {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().getAppActivities(hsr, appId, time,
-        requestPriorities, allocationRequestIds, groupBy, limit, actions,
-        summarize);
-  }
-
-  @GET
-  @Path(RMWSConsts.APP_STATISTICS)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public ApplicationStatisticsInfo getAppStatistics(
-      @Context HttpServletRequest hsr,
-      @QueryParam(RMWSConsts.STATES) Set<String> stateQueries,
-      @QueryParam(RMWSConsts.APPLICATION_TYPES) Set<String> typeQueries) {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().getAppStatistics(hsr, stateQueries,
-        typeQueries);
-  }
-
-  @GET
-  @Path(RMWSConsts.APPS_APPID)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public AppInfo getApp(@Context HttpServletRequest hsr,
-      @PathParam(RMWSConsts.APPID) String appId,
-      @QueryParam(RMWSConsts.DESELECTS) Set<String> unselectedFields) {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().getApp(hsr, appId, unselectedFields);
-  }
-
-  @GET
-  @Path(RMWSConsts.APPS_APPID_STATE)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public AppState getAppState(@Context HttpServletRequest hsr,
-      @PathParam(RMWSConsts.APPID) String appId) throws AuthorizationException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().getAppState(hsr, appId);
-  }
-
-  @PUT
-  @Path(RMWSConsts.APPS_APPID_STATE)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public Response updateAppState(AppState targetState,
-      @Context HttpServletRequest hsr,
-      @PathParam(RMWSConsts.APPID) String appId) throws AuthorizationException,
-      YarnException, InterruptedException, IOException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().updateAppState(targetState, hsr,
-        appId);
-  }
-
-  @GET
-  @Path(RMWSConsts.GET_NODE_TO_LABELS)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public NodeToLabelsInfo getNodeToLabels(@Context HttpServletRequest hsr)
-      throws IOException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().getNodeToLabels(hsr);
-  }
-
-  @GET
-  @Path(RMWSConsts.LABEL_MAPPINGS)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public LabelsToNodesInfo getLabelsToNodes(
-      @QueryParam(RMWSConsts.LABELS) Set<String> labels) throws IOException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(null);
-    return pipeline.getRootInterceptor().getLabelsToNodes(labels);
-  }
-
-  @POST
-  @Path(RMWSConsts.REPLACE_NODE_TO_LABELS)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public Response replaceLabelsOnNodes(
-      final NodeToLabelsEntryList newNodeToLabels,
-      @Context HttpServletRequest hsr) throws Exception {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().replaceLabelsOnNodes(newNodeToLabels,
-        hsr);
-  }
-
-  @POST
-  @Path(RMWSConsts.NODES_NODEID_REPLACE_LABELS)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public Response replaceLabelsOnNode(
-      @QueryParam(RMWSConsts.LABELS) Set<String> newNodeLabelsName,
-      @Context HttpServletRequest hsr,
-      @PathParam(RMWSConsts.NODEID) String nodeId) throws Exception {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().replaceLabelsOnNode(newNodeLabelsName,
-        hsr, nodeId);
-  }
-
-  @GET
-  @Path(RMWSConsts.GET_NODE_LABELS)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public NodeLabelsInfo getClusterNodeLabels(@Context HttpServletRequest hsr)
-      throws IOException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().getClusterNodeLabels(hsr);
-  }
-
-  @POST
-  @Path(RMWSConsts.ADD_NODE_LABELS)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public Response addToClusterNodeLabels(NodeLabelsInfo newNodeLabels,
-      @Context HttpServletRequest hsr) throws Exception {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().addToClusterNodeLabels(newNodeLabels,
-        hsr);
-  }
-
-  @POST
-  @Path(RMWSConsts.REMOVE_NODE_LABELS)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public Response removeFromClusterNodeLabels(
-      @QueryParam(RMWSConsts.LABELS) Set<String> oldNodeLabels,
-      @Context HttpServletRequest hsr) throws Exception {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor()
-        .removeFromClusterNodeLabels(oldNodeLabels, hsr);
-  }
-
-  @GET
-  @Path(RMWSConsts.NODES_NODEID_GETLABELS)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public NodeLabelsInfo getLabelsOnNode(@Context HttpServletRequest hsr,
-      @PathParam(RMWSConsts.NODEID) String nodeId) throws IOException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().getLabelsOnNode(hsr, nodeId);
-  }
-
-  @GET
-  @Path(RMWSConsts.APPS_APPID_PRIORITY)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public AppPriority getAppPriority(@Context HttpServletRequest hsr,
-      @PathParam(RMWSConsts.APPID) String appId) throws AuthorizationException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().getAppPriority(hsr, appId);
-  }
-
-  @PUT
-  @Path(RMWSConsts.APPS_APPID_PRIORITY)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public Response updateApplicationPriority(AppPriority targetPriority,
-      @Context HttpServletRequest hsr,
-      @PathParam(RMWSConsts.APPID) String appId) throws AuthorizationException,
-      YarnException, InterruptedException, IOException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor()
-        .updateApplicationPriority(targetPriority, hsr, appId);
-  }
-
-  @GET
-  @Path(RMWSConsts.APPS_APPID_QUEUE)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public AppQueue getAppQueue(@Context HttpServletRequest hsr,
-      @PathParam(RMWSConsts.APPID) String appId) throws AuthorizationException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().getAppQueue(hsr, appId);
-  }
-
-  @PUT
-  @Path(RMWSConsts.APPS_APPID_QUEUE)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public Response updateAppQueue(AppQueue targetQueue,
-      @Context HttpServletRequest hsr,
-      @PathParam(RMWSConsts.APPID) String appId) throws AuthorizationException,
-      YarnException, InterruptedException, IOException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().updateAppQueue(targetQueue, hsr,
-        appId);
-  }
-
-  @POST
-  @Path(RMWSConsts.APPS_NEW_APPLICATION)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public Response createNewApplication(@Context HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().createNewApplication(hsr);
-  }
-
-  @POST
-  @Path(RMWSConsts.APPS)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public Response submitApplication(ApplicationSubmissionContextInfo newApp,
-      @Context HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().submitApplication(newApp, hsr);
-  }
-
-  @POST
-  @Path(RMWSConsts.DELEGATION_TOKEN)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public Response postDelegationToken(DelegationToken tokenData,
-      @Context HttpServletRequest hsr) throws AuthorizationException,
-      IOException, InterruptedException, Exception {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().postDelegationToken(tokenData, hsr);
-  }
-
-  @POST
-  @Path(RMWSConsts.DELEGATION_TOKEN_EXPIRATION)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public Response postDelegationTokenExpiration(@Context HttpServletRequest hsr)
-      throws AuthorizationException, IOException, Exception {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().postDelegationTokenExpiration(hsr);
-  }
-
-  @DELETE
-  @Path(RMWSConsts.DELEGATION_TOKEN)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public Response cancelDelegationToken(@Context HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException,
-      Exception {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().cancelDelegationToken(hsr);
-  }
-
-  @POST
-  @Path(RMWSConsts.RESERVATION_NEW)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public Response createNewReservation(@Context HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().createNewReservation(hsr);
-  }
-
-  @POST
-  @Path(RMWSConsts.RESERVATION_SUBMIT)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public Response submitReservation(ReservationSubmissionRequestInfo resContext,
-      @Context HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().submitReservation(resContext, hsr);
-  }
-
-  @POST
-  @Path(RMWSConsts.RESERVATION_UPDATE)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public Response updateReservation(ReservationUpdateRequestInfo resContext,
-      @Context HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().updateReservation(resContext, hsr);
-  }
-
-  @POST
-  @Path(RMWSConsts.RESERVATION_DELETE)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public Response deleteReservation(ReservationDeleteRequestInfo resContext,
-      @Context HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().deleteReservation(resContext, hsr);
-  }
-
-  @GET
-  @Path(RMWSConsts.RESERVATION_LIST)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public Response listReservation(
-      @QueryParam(RMWSConsts.QUEUE) @DefaultValue(DEFAULT_QUEUE) String queue,
-      @QueryParam(RMWSConsts.RESERVATION_ID)
-      @DefaultValue(DEFAULT_RESERVATION_ID) String reservationId,
-      @QueryParam(RMWSConsts.START_TIME) @DefaultValue(DEFAULT_START_TIME) long startTime,
-      @QueryParam(RMWSConsts.END_TIME) @DefaultValue(DEFAULT_END_TIME) long endTime,
-      @QueryParam(RMWSConsts.INCLUDE_RESOURCE)
-      @DefaultValue(DEFAULT_INCLUDE_RESOURCE) boolean includeResourceAllocations,
-      @Context HttpServletRequest hsr) throws Exception {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().listReservation(queue, reservationId,
-        startTime, endTime, includeResourceAllocations, hsr);
-  }
-
-  @GET
-  @Path(RMWSConsts.APPS_TIMEOUTS_TYPE)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public AppTimeoutInfo getAppTimeout(@Context HttpServletRequest hsr,
-      @PathParam(RMWSConsts.APPID) String appId,
-      @PathParam(RMWSConsts.TYPE) String type) throws AuthorizationException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().getAppTimeout(hsr, appId, type);
-  }
-
-  @GET
-  @Path(RMWSConsts.APPS_TIMEOUTS)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public AppTimeoutsInfo getAppTimeouts(@Context HttpServletRequest hsr,
-      @PathParam(RMWSConsts.APPID) String appId) throws AuthorizationException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().getAppTimeouts(hsr, appId);
-  }
-
-  @PUT
-  @Path(RMWSConsts.APPS_TIMEOUT)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public Response updateApplicationTimeout(AppTimeoutInfo appTimeout,
-      @Context HttpServletRequest hsr,
-      @PathParam(RMWSConsts.APPID) String appId) throws AuthorizationException,
-      YarnException, InterruptedException, IOException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().updateApplicationTimeout(appTimeout,
-        hsr, appId);
-  }
-
-  @GET
-  @Path(RMWSConsts.APPS_APPID_APPATTEMPTS)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public AppAttemptsInfo getAppAttempts(@Context HttpServletRequest hsr,
-      @PathParam(RMWSConsts.APPID) String appId) {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().getAppAttempts(hsr, appId);
-  }
-
-  @GET
-  @Path(RMWSConsts.CHECK_USER_ACCESS_TO_QUEUE)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-                MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public RMQueueAclInfo checkUserAccessToQueue(
-      @PathParam(RMWSConsts.QUEUE) String queue,
-      @QueryParam(RMWSConsts.USER) String username,
-      @QueryParam(RMWSConsts.QUEUE_ACL_TYPE)
-      @DefaultValue("SUBMIT_APPLICATIONS") String queueAclType,
-      @Context HttpServletRequest hsr) throws AuthorizationException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().checkUserAccessToQueue(queue,
-        username, queueAclType, hsr);
-  }
-
-  @GET
-  @Path(RMWSConsts.APPS_APPID_APPATTEMPTS_APPATTEMPTID)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  public org.apache.hadoop.yarn.server.webapp.dao.AppAttemptInfo getAppAttempt(
-      @Context HttpServletRequest req, @Context HttpServletResponse res,
-      @PathParam(RMWSConsts.APPID) String appId,
-      @PathParam(RMWSConsts.APPATTEMPTID) String appAttemptId) {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(req);
-    return pipeline.getRootInterceptor().getAppAttempt(req, res, appId,
-        appAttemptId);
-  }
-
-  @GET
-  @Path(RMWSConsts.APPS_APPID_APPATTEMPTS_APPATTEMPTID_CONTAINERS)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  public ContainersInfo getContainers(@Context HttpServletRequest req,
-      @Context HttpServletResponse res,
-      @PathParam(RMWSConsts.APPID) String appId,
-      @PathParam(RMWSConsts.APPATTEMPTID) String appAttemptId) {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(req);
-    return pipeline.getRootInterceptor().getContainers(req, res, appId,
-        appAttemptId);
-  }
-
-  @GET
-  @Path(RMWSConsts.GET_CONTAINER)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  public ContainerInfo getContainer(@Context HttpServletRequest req,
-      @Context HttpServletResponse res,
-      @PathParam(RMWSConsts.APPID) String appId,
-      @PathParam(RMWSConsts.APPATTEMPTID) String appAttemptId,
-      @PathParam(RMWSConsts.CONTAINERID) String containerId) {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(req);
-    return pipeline.getRootInterceptor().getContainer(req, res, appId,
-        appAttemptId, containerId);
-  }
-
-  @PUT
-  @Path(RMWSConsts.SCHEDULER_CONF)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Consumes({ MediaType.APPLICATION_JSON, MediaType.APPLICATION_XML })
-  @Override
-  public Response updateSchedulerConfiguration(SchedConfUpdateInfo mutationInfo,
-      HttpServletRequest hsr)
-      throws AuthorizationException, InterruptedException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor()
-        .updateSchedulerConfiguration(mutationInfo, hsr);
-  }
-
-  @GET
-  @Path(RMWSConsts.SCHEDULER_CONF)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  @Override
-  public Response getSchedulerConfiguration(HttpServletRequest hsr)
-      throws AuthorizationException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().getSchedulerConfiguration(hsr);
-  }
-
-  @VisibleForTesting
-  protected void setResponse(HttpServletResponse response) {
-    this.response = response;
-  }
-
-  @POST
-  @Path(RMWSConsts.SIGNAL_TO_CONTAINER)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  public Response signalToContainer(
-      @PathParam(RMWSConsts.CONTAINERID) String containerId,
-      @PathParam(RMWSConsts.COMMAND) String command,
-      @Context HttpServletRequest req)
-      throws AuthorizationException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(req);
-    return pipeline.getRootInterceptor()
-        .signalToContainer(containerId, command, req);
-  }
-
-  @GET
-  @Path(RMWSConsts.GET_RM_NODE_LABELS)
-  @Produces({ MediaType.APPLICATION_JSON + "; " + JettyUtils.UTF_8,
-      MediaType.APPLICATION_XML + "; " + JettyUtils.UTF_8 })
-  public NodeLabelsInfo getRMNodeLabels(@Context HttpServletRequest hsr)
-      throws IOException {
-    init();
-    RequestInterceptorChainWrapper pipeline = getInterceptorChain(hsr);
-    return pipeline.getRootInterceptor().getRMNodeLabels(hsr);
-  }
-
-  public Router getRouter() {
-    return router;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/cache/RouterAppInfoCacheKey.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/cache/RouterAppInfoCacheKey.java
deleted file mode 100644
index 27164f00415..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/cache/RouterAppInfoCacheKey.java
+++ /dev/null
@@ -1,156 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.webapp.cache;
-
-import org.apache.commons.lang3.builder.EqualsBuilder;
-import org.apache.commons.lang3.builder.HashCodeBuilder;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebAppUtil;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import javax.servlet.http.HttpServletRequest;
-import java.util.Set;
-
-public class RouterAppInfoCacheKey {
-
-  private static String user = "YarnRouter";
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(RouterAppInfoCacheKey.class.getName());
-
-  private UserGroupInformation ugi;
-  private String stateQuery;
-  private Set<String> statesQuery;
-  private String finalStatusQuery;
-  private String userQuery;
-  private String queueQuery;
-  private String count;
-  private String startedBegin;
-  private String startedEnd;
-  private String finishBegin;
-  private String finishEnd;
-  private Set<String> applicationTypes;
-  private Set<String> applicationTags;
-  private String name;
-  private Set<String> unselectedFields;
-
-  public RouterAppInfoCacheKey() {
-
-  }
-
-  @SuppressWarnings("checkstyle:ParameterNumber")
-  public RouterAppInfoCacheKey(UserGroupInformation ugi, String stateQuery,
-      Set<String> statesQuery, String finalStatusQuery, String userQuery,
-      String queueQuery, String count, String startedBegin, String startedEnd,
-      String finishBegin, String finishEnd, Set<String> applicationTypes,
-      Set<String> applicationTags, String name, Set<String> unselectedFields) {
-    this.ugi = ugi;
-    this.stateQuery = stateQuery;
-    this.statesQuery = statesQuery;
-    this.finalStatusQuery = finalStatusQuery;
-    this.userQuery = userQuery;
-    this.queueQuery = queueQuery;
-    this.count = count;
-    this.startedBegin = startedBegin;
-    this.startedEnd = startedEnd;
-    this.finishBegin = finishBegin;
-    this.finishEnd = finishEnd;
-    this.applicationTypes = applicationTypes;
-    this.applicationTags = applicationTags;
-    this.name = name;
-    this.unselectedFields = unselectedFields;
-  }
-
-
-  @SuppressWarnings("checkstyle:ParameterNumber")
-  public static RouterAppInfoCacheKey newInstance(HttpServletRequest hsr, String stateQuery,
-      Set<String> statesQuery, String finalStatusQuery, String userQuery,
-      String queueQuery, String count, String startedBegin, String startedEnd,
-      String finishBegin, String finishEnd, Set<String> applicationTypes,
-      Set<String> applicationTags, String name, Set<String> unselectedFields)  {
-
-    UserGroupInformation callerUGI = null;
-    if (hsr != null) {
-      callerUGI = RMWebAppUtil.getCallerUserGroupInformation(hsr, true);
-    } else {
-      // user not required
-      callerUGI = UserGroupInformation.createRemoteUser("YarnRouter");
-    }
-
-    if (callerUGI == null) {
-      LOG.error("Unable to obtain user name, user not authenticated.");
-      return null;
-    }
-
-    return new RouterAppInfoCacheKey(
-        callerUGI, stateQuery, statesQuery, finalStatusQuery, userQuery,
-        queueQuery, count, startedBegin, startedEnd, finishBegin, finishEnd,
-        applicationTypes, applicationTags, name, unselectedFields);
-  }
-
-  @Override
-  public boolean equals(Object o) {
-    if (this == o) {
-      return true;
-    }
-    if (o == null || getClass() != o.getClass()) {
-      return false;
-    }
-    RouterAppInfoCacheKey that = (RouterAppInfoCacheKey) o;
-
-    return new EqualsBuilder()
-        .append(this.ugi.getUserName(), that.ugi.getUserName())
-        .append(this.stateQuery, that.stateQuery)
-        .append(this.statesQuery, that.statesQuery)
-        .append(this.finalStatusQuery, that.finalStatusQuery)
-        .append(this.userQuery, that.userQuery)
-        .append(this.queueQuery, that.queueQuery)
-        .append(this.count, that.count)
-        .append(this.startedBegin, that.startedBegin)
-        .append(this.startedEnd, that.startedEnd)
-        .append(this.finishBegin, that.finishBegin)
-        .append(this.finishEnd, that.finishEnd)
-        .append(this.applicationTypes, that.applicationTypes)
-        .append(this.applicationTags, that.applicationTags)
-        .append(this.name, that.name)
-        .append(this.unselectedFields, that.unselectedFields)
-        .isEquals();
-  }
-
-  @Override
-  public int hashCode() {
-    return new HashCodeBuilder()
-       .append(this.ugi.getUserName())
-       .append(this.stateQuery)
-       .append(this.statesQuery)
-       .append(this.finalStatusQuery)
-       .append(this.userQuery)
-       .append(this.queueQuery)
-       .append(this.count)
-       .append(this.startedBegin)
-       .append(this.startedEnd)
-       .append(this.finishBegin)
-       .append(this.finishEnd)
-       .append(this.applicationTypes)
-       .append(this.applicationTags)
-       .append(this.name)
-       .append(this.unselectedFields)
-       .toHashCode();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/cache/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/cache/package-info.java
deleted file mode 100644
index 187cd72fe25..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/cache/package-info.java
+++ /dev/null
@@ -1,18 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.webapp.cache;
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationBulkActivitiesInfo.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationBulkActivitiesInfo.java
deleted file mode 100644
index 87d11ad0feb..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationBulkActivitiesInfo.java
+++ /dev/null
@@ -1,49 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.webapp.dao;
-
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.BulkActivitiesInfo;
-
-import javax.xml.bind.annotation.XmlAccessType;
-import javax.xml.bind.annotation.XmlAccessorType;
-import javax.xml.bind.annotation.XmlElement;
-import javax.xml.bind.annotation.XmlRootElement;
-import java.util.ArrayList;
-
-@XmlRootElement
-@XmlAccessorType(XmlAccessType.FIELD)
-public class FederationBulkActivitiesInfo extends BulkActivitiesInfo {
-
-  @XmlElement(name = "subCluster")
-  private ArrayList<BulkActivitiesInfo> list = new ArrayList<>();
-
-  public FederationBulkActivitiesInfo() {
-  } // JAXB needs this
-
-  public FederationBulkActivitiesInfo(ArrayList<BulkActivitiesInfo> list) {
-    this.list = list;
-  }
-
-  public ArrayList<BulkActivitiesInfo> getList() {
-    return list;
-  }
-
-  public void setList(ArrayList<BulkActivitiesInfo> list) {
-    this.list = list;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationClusterInfo.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationClusterInfo.java
deleted file mode 100644
index 9b8d7b5431a..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationClusterInfo.java
+++ /dev/null
@@ -1,50 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.webapp.dao;
-
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterInfo;
-
-import javax.xml.bind.annotation.XmlAccessType;
-import javax.xml.bind.annotation.XmlAccessorType;
-import javax.xml.bind.annotation.XmlElement;
-import javax.xml.bind.annotation.XmlRootElement;
-import java.util.ArrayList;
-import java.util.List;
-
-@XmlRootElement
-@XmlAccessorType(XmlAccessType.FIELD)
-public class FederationClusterInfo extends ClusterInfo {
-
-  @XmlElement(name = "subCluster")
-  private List<ClusterInfo> list = new ArrayList<>();
-
-  public FederationClusterInfo() {
-  } // JAXB needs this
-
-  public FederationClusterInfo(ArrayList<ClusterInfo> list) {
-    this.list = list;
-  }
-
-  public List<ClusterInfo> getList() {
-    return list;
-  }
-
-  public void setList(List<ClusterInfo> list) {
-    this.list = list;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationClusterUserInfo.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationClusterUserInfo.java
deleted file mode 100644
index b4a19b7919d..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationClusterUserInfo.java
+++ /dev/null
@@ -1,49 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.webapp.dao;
-
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterUserInfo;
-
-import javax.xml.bind.annotation.XmlAccessType;
-import javax.xml.bind.annotation.XmlAccessorType;
-import javax.xml.bind.annotation.XmlElement;
-import javax.xml.bind.annotation.XmlRootElement;
-import java.util.ArrayList;
-import java.util.List;
-
-@XmlRootElement
-@XmlAccessorType(XmlAccessType.FIELD)
-public class FederationClusterUserInfo extends ClusterUserInfo {
-  @XmlElement(name = "subCluster")
-  private List<ClusterUserInfo> list = new ArrayList<>();
-
-  public FederationClusterUserInfo() {
-  } // JAXB needs this
-
-  public FederationClusterUserInfo(ArrayList<ClusterUserInfo> list) {
-    this.list = list;
-  }
-
-  public List<ClusterUserInfo> getList() {
-    return list;
-  }
-
-  public void setList(List<ClusterUserInfo> list) {
-    this.list = list;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationConfInfo.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationConfInfo.java
deleted file mode 100644
index 6a5e611a4f8..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationConfInfo.java
+++ /dev/null
@@ -1,55 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.webapp.dao;
-
-import org.apache.hadoop.yarn.webapp.dao.ConfInfo;
-
-import javax.xml.bind.annotation.XmlAccessType;
-import javax.xml.bind.annotation.XmlAccessorType;
-import javax.xml.bind.annotation.XmlElement;
-import javax.xml.bind.annotation.XmlRootElement;
-import java.util.ArrayList;
-import java.util.List;
-
-@XmlRootElement
-@XmlAccessorType(XmlAccessType.FIELD)
-public class FederationConfInfo extends ConfInfo {
-  @XmlElement(name = "subCluster")
-  private List<ConfInfo> list = new ArrayList<>();
-
-  @XmlElement(name = "errorMsgs")
-  private List<String> errorMsgs = new ArrayList<>();
-  public FederationConfInfo() {
-  } // JAXB needs this
-
-  public List<ConfInfo> getList() {
-    return list;
-  }
-
-  public void setList(List<ConfInfo> list) {
-    this.list = list;
-  }
-
-  public List<String> getErrorMsgs() {
-    return errorMsgs;
-  }
-
-  public void setErrorMsgs(List<String> errorMsgs) {
-    this.errorMsgs = errorMsgs;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationRMQueueAclInfo.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationRMQueueAclInfo.java
deleted file mode 100644
index 4e61fd772ee..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationRMQueueAclInfo.java
+++ /dev/null
@@ -1,50 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.webapp.dao;
-
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.RMQueueAclInfo;
-
-import javax.xml.bind.annotation.XmlAccessType;
-import javax.xml.bind.annotation.XmlAccessorType;
-import javax.xml.bind.annotation.XmlElement;
-import javax.xml.bind.annotation.XmlRootElement;
-import java.util.ArrayList;
-import java.util.List;
-
-@XmlRootElement
-@XmlAccessorType(XmlAccessType.FIELD)
-public class FederationRMQueueAclInfo extends RMQueueAclInfo {
-
-  @XmlElement(name = "subCluster")
-  private List<RMQueueAclInfo> list = new ArrayList<>();
-
-  public FederationRMQueueAclInfo() {
-  } // JAXB needs this
-
-  public FederationRMQueueAclInfo(ArrayList<RMQueueAclInfo> list) {
-    this.list = list;
-  }
-
-  public List<RMQueueAclInfo> getList() {
-    return list;
-  }
-
-  public void setList(List<RMQueueAclInfo> list) {
-    this.list = list;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationSchedulerTypeInfo.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationSchedulerTypeInfo.java
deleted file mode 100644
index 733af0ce8e2..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/FederationSchedulerTypeInfo.java
+++ /dev/null
@@ -1,49 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.webapp.dao;
-
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerTypeInfo;
-
-import javax.xml.bind.annotation.XmlAccessType;
-import javax.xml.bind.annotation.XmlAccessorType;
-import javax.xml.bind.annotation.XmlElement;
-import javax.xml.bind.annotation.XmlRootElement;
-import java.util.ArrayList;
-import java.util.List;
-
-@XmlRootElement
-@XmlAccessorType(XmlAccessType.FIELD)
-public class FederationSchedulerTypeInfo extends SchedulerTypeInfo {
-  @XmlElement(name = "subCluster")
-  private List<SchedulerTypeInfo> list = new ArrayList<>();
-
-  public FederationSchedulerTypeInfo() {
-  } // JAXB needs this
-
-  public FederationSchedulerTypeInfo(ArrayList<SchedulerTypeInfo> list) {
-    this.list = list;
-  }
-
-  public List<SchedulerTypeInfo> getList() {
-    return list;
-  }
-
-  public void setList(List<SchedulerTypeInfo> list) {
-    this.list = list;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/RouterClusterMetrics.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/RouterClusterMetrics.java
deleted file mode 100644
index f06f85574db..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/RouterClusterMetrics.java
+++ /dev/null
@@ -1,323 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.webapp.dao;
-
-import org.apache.hadoop.util.StringUtils;
-import org.apache.hadoop.yarn.api.records.Resource;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.util.resource.Resources;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import javax.xml.bind.annotation.XmlAccessType;
-import javax.xml.bind.annotation.XmlAccessorType;
-import javax.xml.bind.annotation.XmlRootElement;
-
-@XmlRootElement
-@XmlAccessorType(XmlAccessType.FIELD)
-public class RouterClusterMetrics {
-
-  protected static final long BYTES_IN_MB = 1024 * 1024;
-  private static final Logger LOG = LoggerFactory.getLogger(RouterClusterMetrics.class);
-
-  // webPageTitlePrefix
-  private String webPageTitlePrefix = "Federation";
-
-  // Application Information.
-  private String appsSubmitted = "N/A";
-  private String appsCompleted = "N/A";
-  private String appsPending = "N/A";
-  private String appsRunning = "N/A";
-  private String appsFailed = "N/A";
-  private String appsKilled = "N/A";
-
-  // Memory Information.
-  private String totalMemory = "N/A";
-  private String reservedMemory = "N/A";
-  private String availableMemory = "N/A";
-  private String allocatedMemory = "N/A";
-  private String pendingMemory = "N/A";
-
-  // VirtualCores Information.
-  private String reservedVirtualCores = "N/A";
-  private String availableVirtualCores = "N/A";
-  private String allocatedVirtualCores = "N/A";
-  private String pendingVirtualCores = "N/A";
-  private String totalVirtualCores = "N/A";
-
-  // Resources Information.
-  private String usedResources = "N/A";
-  private String totalResources = "N/A";
-  private String reservedResources = "N/A";
-  private String allocatedContainers = "N/A";
-
-  // Resource Percent Information.
-  private String utilizedMBPercent = "N/A";
-  private String utilizedVirtualCoresPercent = "N/A";
-
-  // Node Information.
-  private String activeNodes = "N/A";
-  private String decommissioningNodes = "N/A";
-  private String decommissionedNodes = "N/A";
-  private String lostNodes = "N/A";
-  private String unhealthyNodes = "N/A";
-  private String rebootedNodes = "N/A";
-  private String shutdownNodes = "N/A";
-
-  public RouterClusterMetrics() {
-
-  }
-
-  public RouterClusterMetrics(ClusterMetricsInfo metrics) {
-    if (metrics != null) {
-      // Application Information Conversion.
-      conversionApplicationInformation(metrics);
-
-      // Memory Information Conversion.
-      conversionMemoryInformation(metrics);
-
-      // Resources Information Conversion.
-      conversionResourcesInformation(metrics);
-
-      // Percent Information Conversion.
-      conversionResourcesPercent(metrics);
-
-      // Node Information Conversion.
-      conversionNodeInformation(metrics);
-    }
-  }
-
-  public RouterClusterMetrics(ClusterMetricsInfo metrics,
-      String webPageTitlePrefix) {
-    this(metrics);
-    this.webPageTitlePrefix = webPageTitlePrefix;
-  }
-
-  // Get Key Metric Information
-  public String getAppsSubmitted() {
-    return appsSubmitted;
-  }
-
-  public String getAppsCompleted() {
-    return appsCompleted;
-  }
-
-  public String getAppsPending() {
-    return appsPending;
-  }
-
-  public String getAppsRunning() {
-    return appsRunning;
-  }
-
-  public String getAppsFailed() {
-    return appsFailed;
-  }
-
-  public String getAppsKilled() {
-    return appsKilled;
-  }
-
-  public String getTotalMemory() {
-    return totalMemory;
-  }
-
-  public String getReservedMemory() {
-    return reservedMemory;
-  }
-
-  public String getAvailableMemory() {
-    return availableMemory;
-  }
-
-  public String getAllocatedMemory() {
-    return allocatedMemory;
-  }
-
-  public String getPendingMemory() {
-    return pendingMemory;
-  }
-
-  public String getReservedVirtualCores() {
-    return reservedVirtualCores;
-  }
-
-  public String getAvailableVirtualCores() {
-    return availableVirtualCores;
-  }
-
-  public String getAllocatedVirtualCores() {
-    return allocatedVirtualCores;
-  }
-
-  public String getPendingVirtualCores() {
-    return pendingVirtualCores;
-  }
-
-  public String getTotalVirtualCores() {
-    return totalVirtualCores;
-  }
-
-  public String getUsedResources() {
-    return usedResources;
-  }
-
-  public String getTotalResources() {
-    return totalResources;
-  }
-
-  public String getReservedResources() {
-    return reservedResources;
-  }
-
-  public String getAllocatedContainers() {
-    return allocatedContainers;
-  }
-
-  public String getUtilizedMBPercent() {
-    return utilizedMBPercent;
-  }
-
-  public String getUtilizedVirtualCoresPercent() {
-    return utilizedVirtualCoresPercent;
-  }
-
-  public String getActiveNodes() {
-    return activeNodes;
-  }
-
-  public String getDecommissioningNodes() {
-    return decommissioningNodes;
-  }
-
-  public String getDecommissionedNodes() {
-    return decommissionedNodes;
-  }
-
-  public String getLostNodes() {
-    return lostNodes;
-  }
-
-  public String getUnhealthyNodes() {
-    return unhealthyNodes;
-  }
-
-  public String getRebootedNodes() {
-    return rebootedNodes;
-  }
-
-  public String getShutdownNodes() {
-    return shutdownNodes;
-  }
-
-  // Metric Information Conversion
-  public void conversionApplicationInformation(ClusterMetricsInfo metrics) {
-    try {
-      // Application Information.
-      this.appsSubmitted = String.valueOf(metrics.getAppsSubmitted());
-      this.appsCompleted = String.valueOf(metrics.getAppsCompleted() +
-           metrics.getAppsFailed() + metrics.getAppsKilled());
-      this.appsPending = String.valueOf(metrics.getAppsPending());
-      this.appsRunning = String.valueOf(metrics.getAppsRunning());
-      this.appsFailed = String.valueOf(metrics.getAppsFailed());
-      this.appsKilled = String.valueOf(metrics.getAppsKilled());
-    } catch (Exception e) {
-      LOG.error("conversionApplicationInformation error.", e);
-    }
-  }
-
-  // Metric Memory Information
-  public void conversionMemoryInformation(ClusterMetricsInfo metrics) {
-    try {
-      // Memory Information.
-      this.totalMemory = StringUtils.byteDesc(metrics.getTotalMB() * BYTES_IN_MB);
-      this.reservedMemory = StringUtils.byteDesc(metrics.getReservedMB() * BYTES_IN_MB);
-      this.availableMemory = StringUtils.byteDesc(metrics.getAvailableMB() * BYTES_IN_MB);
-      this.allocatedMemory = StringUtils.byteDesc(metrics.getAllocatedMB() * BYTES_IN_MB);
-      this.pendingMemory = StringUtils.byteDesc(metrics.getPendingMB() * BYTES_IN_MB);
-    } catch (Exception e) {
-      LOG.error("conversionMemoryInformation error.", e);
-    }
-  }
-
-  // ResourcesInformation Conversion
-  public void conversionResourcesInformation(ClusterMetricsInfo metrics) {
-    try {
-      // Parse resource information from metrics.
-      Resource metricUsedResources;
-      Resource metricTotalResources;
-      Resource metricReservedResources;
-
-      int metricAllocatedContainers;
-      if (metrics.getCrossPartitionMetricsAvailable()) {
-        metricAllocatedContainers = metrics.getTotalAllocatedContainersAcrossPartition();
-        metricUsedResources = metrics.getTotalUsedResourcesAcrossPartition().getResource();
-        metricTotalResources = metrics.getTotalClusterResourcesAcrossPartition().getResource();
-        metricReservedResources = metrics.getTotalReservedResourcesAcrossPartition().getResource();
-        // getTotalUsedResourcesAcrossPartition includes reserved resources.
-        Resources.subtractFrom(metricUsedResources, metricReservedResources);
-      } else {
-        metricAllocatedContainers = metrics.getContainersAllocated();
-        metricUsedResources = Resource.newInstance(metrics.getAllocatedMB(),
-            (int) metrics.getAllocatedVirtualCores());
-        metricTotalResources = Resource.newInstance(metrics.getTotalMB(),
-            (int) metrics.getTotalVirtualCores());
-        metricReservedResources = Resource.newInstance(metrics.getReservedMB(),
-            (int) metrics.getReservedVirtualCores());
-      }
-
-      // Convert to standard format.
-      usedResources = metricUsedResources.getFormattedString();
-      totalResources = metricTotalResources.getFormattedString();
-      reservedResources = metricReservedResources.getFormattedString();
-      allocatedContainers =  String.valueOf(metricAllocatedContainers);
-
-    } catch (Exception e) {
-      LOG.error("conversionResourcesInformation error.", e);
-    }
-  }
-
-  // ResourcesPercent Conversion
-  public void conversionResourcesPercent(ClusterMetricsInfo metrics) {
-    try {
-      this.utilizedMBPercent = String.valueOf(metrics.getUtilizedMBPercent());
-      this.utilizedVirtualCoresPercent = String.valueOf(metrics.getUtilizedVirtualCoresPercent());
-    } catch (Exception e) {
-      LOG.error("conversionResourcesPercent error.", e);
-    }
-  }
-
-  // NodeInformation Conversion
-  public void conversionNodeInformation(ClusterMetricsInfo metrics) {
-    try {
-      this.activeNodes = String.valueOf(metrics.getActiveNodes());
-      this.decommissioningNodes = String.valueOf(metrics.getDecommissioningNodes());
-      this.decommissionedNodes = String.valueOf(metrics.getDecommissionedNodes());
-      this.lostNodes = String.valueOf(metrics.getLostNodes());
-      this.unhealthyNodes = String.valueOf(metrics.getUnhealthyNodes());
-      this.rebootedNodes = String.valueOf(metrics.getRebootedNodes());
-      this.shutdownNodes = String.valueOf(metrics.getShutdownNodes());
-    } catch (Exception e) {
-      LOG.error("conversionNodeInformation error.", e);
-    }
-  }
-
-  public String getWebPageTitlePrefix() {
-    return webPageTitlePrefix;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/RouterInfo.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/RouterInfo.java
deleted file mode 100644
index 7cedd0c8e1f..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/RouterInfo.java
+++ /dev/null
@@ -1,104 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.webapp.dao;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.service.Service;
-import org.apache.hadoop.util.VersionInfo;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.server.router.Router;
-import org.apache.hadoop.yarn.util.YarnVersionInfo;
-
-import javax.xml.bind.annotation.XmlAccessType;
-import javax.xml.bind.annotation.XmlAccessorType;
-import javax.xml.bind.annotation.XmlRootElement;
-
-@XmlRootElement
-@XmlAccessorType(XmlAccessType.FIELD)
-public class RouterInfo {
-  private long id;
-  private long startedOn;
-  private Service.STATE state;
-  private String routerStateStoreName;
-  private String routerVersion;
-  private String routerBuildVersion;
-  private String routerVersionBuiltOn;
-  private String hadoopVersion;
-  private String hadoopBuildVersion;
-  private String hadoopVersionBuiltOn;
-
-  public RouterInfo() {
-  } // JAXB needs this
-
-  public RouterInfo(Router router) {
-    long ts = Router.getClusterTimeStamp();
-    this.id = ts;
-    this.state = router.getServiceState();
-    Configuration configuration = router.getConfig();
-    this.routerStateStoreName = configuration.get(
-        YarnConfiguration.FEDERATION_STATESTORE_CLIENT_CLASS,
-        YarnConfiguration.DEFAULT_FEDERATION_STATESTORE_CLIENT_CLASS);
-    this.routerVersion = YarnVersionInfo.getVersion();
-    this.routerBuildVersion = YarnVersionInfo.getBuildVersion();
-    this.routerVersionBuiltOn = YarnVersionInfo.getDate();
-    this.hadoopVersion = VersionInfo.getVersion();
-    this.hadoopBuildVersion = VersionInfo.getBuildVersion();
-    this.hadoopVersionBuiltOn = VersionInfo.getDate();
-    this.startedOn = ts;
-  }
-
-  public String getState() {
-    return this.state.toString();
-  }
-
-  public String getRouterStateStore() {
-    return this.routerStateStoreName;
-  }
-
-  public String getRouterVersion() {
-    return this.routerVersion;
-  }
-
-  public String getRouterBuildVersion() {
-    return this.routerBuildVersion;
-  }
-
-  public String getRouterVersionBuiltOn() {
-    return this.routerVersionBuiltOn;
-  }
-
-  public String getHadoopVersion() {
-    return this.hadoopVersion;
-  }
-
-  public String getHadoopBuildVersion() {
-    return this.hadoopBuildVersion;
-  }
-
-  public String getHadoopVersionBuiltOn() {
-    return this.hadoopVersionBuiltOn;
-  }
-
-  public long getClusterId() {
-    return this.id;
-  }
-
-  public long getStartedOn() {
-    return this.startedOn;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/RouterSchedulerMetrics.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/RouterSchedulerMetrics.java
deleted file mode 100644
index 714642cec83..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/RouterSchedulerMetrics.java
+++ /dev/null
@@ -1,120 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.webapp.dao;
-
-
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerOverviewInfo;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import javax.xml.bind.annotation.XmlAccessType;
-import javax.xml.bind.annotation.XmlAccessorType;
-import javax.xml.bind.annotation.XmlRootElement;
-
-@XmlRootElement
-@XmlAccessorType(XmlAccessType.FIELD)
-public class RouterSchedulerMetrics {
-
-  // Metrics Log.
-  private static final Logger LOG = LoggerFactory.getLogger(RouterSchedulerMetrics.class);
-
-  // Scheduler Information.
-  private String subCluster = "N/A";
-  private String schedulerType = "N/A";
-  private String schedulingResourceType = "N/A";
-  private String minimumAllocation = "N/A";
-  private String maximumAllocation = "N/A";
-  private String applicationPriority = "N/A";
-  private String schedulerBusy = "N/A";
-  private String rmDispatcherEventQueueSize = "N/A";
-  private String schedulerDispatcherEventQueueSize = "N/A";
-
-  public RouterSchedulerMetrics() {
-
-  }
-
-  public RouterSchedulerMetrics(SubClusterInfo subClusterInfo, RouterClusterMetrics metrics,
-      SchedulerOverviewInfo overview) {
-    if (subClusterInfo != null) {
-      initRouterSchedulerMetrics(subClusterInfo.getSubClusterId().getId(), overview);
-    }
-  }
-
-  public RouterSchedulerMetrics(String localClusterName, SchedulerOverviewInfo overview) {
-    initRouterSchedulerMetrics(localClusterName, overview);
-  }
-
-  private void initRouterSchedulerMetrics(String subClusterName,
-      SchedulerOverviewInfo overview) {
-    try {
-      // Parse Scheduler Information.
-      this.subCluster = subClusterName;
-      this.schedulerType = overview.getSchedulerType();
-      this.schedulingResourceType = overview.getSchedulingResourceType();
-      this.minimumAllocation = overview.getMinimumAllocation().toString();
-      this.maximumAllocation = overview.getMaximumAllocation().toString();
-      this.applicationPriority = String.valueOf(overview.getApplicationPriority());
-      if (overview.getSchedulerBusy() != -1) {
-        this.schedulerBusy = String.valueOf(overview.getSchedulerBusy());
-      }
-      this.rmDispatcherEventQueueSize =
-          String.valueOf(overview.getRmDispatcherEventQueueSize());
-      this.schedulerDispatcherEventQueueSize =
-          String.valueOf(overview.getSchedulerDispatcherEventQueueSize());
-    } catch (Exception ex) {
-      LOG.error("RouterSchedulerMetrics Error.", ex);
-    }
-  }
-
-  public String getSubCluster() {
-    return subCluster;
-  }
-
-  public String getSchedulerType() {
-    return schedulerType;
-  }
-
-  public String getSchedulingResourceType() {
-    return schedulingResourceType;
-  }
-
-  public String getMinimumAllocation() {
-    return minimumAllocation;
-  }
-
-  public String getMaximumAllocation() {
-    return maximumAllocation;
-  }
-
-  public String getApplicationPriority() {
-    return applicationPriority;
-  }
-
-  public String getRmDispatcherEventQueueSize() {
-    return rmDispatcherEventQueueSize;
-  }
-
-  public String getSchedulerDispatcherEventQueueSize() {
-    return schedulerDispatcherEventQueueSize;
-  }
-
-  public String getSchedulerBusy() {
-    return schedulerBusy;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/SubClusterResult.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/SubClusterResult.java
deleted file mode 100644
index 2a527c28d10..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/SubClusterResult.java
+++ /dev/null
@@ -1,59 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.webapp.dao;
-
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-
-public class SubClusterResult<R> {
-  private SubClusterInfo subClusterInfo;
-  private R response;
-  private Exception exception;
-
-  public SubClusterResult() {
-  }
-
-  public SubClusterResult(SubClusterInfo subCluster, R res, Exception ex) {
-    this.subClusterInfo = subCluster;
-    this.response = res;
-    this.exception = ex;
-  }
-
-  public SubClusterInfo getSubClusterInfo() {
-    return subClusterInfo;
-  }
-
-  public void setSubClusterInfo(SubClusterInfo subClusterInfo) {
-    this.subClusterInfo = subClusterInfo;
-  }
-
-  public Exception getException() {
-    return exception;
-  }
-
-  public void setException(Exception exception) {
-    this.exception = exception;
-  }
-
-  public R getResponse() {
-    return response;
-  }
-
-  public void setResponse(R response) {
-    this.response = response;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/package-info.java
deleted file mode 100644
index 27f43ad1ff4..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/dao/package-info.java
+++ /dev/null
@@ -1,20 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/** Router Web Dao package. **/
-package org.apache.hadoop.yarn.server.router.webapp.dao;
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/package-info.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/package-info.java
deleted file mode 100644
index bd94ead9c06..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/main/java/org/apache/hadoop/yarn/server/router/webapp/package-info.java
+++ /dev/null
@@ -1,20 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-/** Router WebApp package. **/
-package org.apache.hadoop.yarn.server.router.webapp;
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouter.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouter.java
deleted file mode 100644
index f51ac6d2b83..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouter.java
+++ /dev/null
@@ -1,407 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router;
-
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertTrue;
-import static org.junit.Assert.fail;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.CommonConfigurationKeysPublic;
-import org.apache.hadoop.http.HttpServer2;
-import org.apache.hadoop.security.HttpCrossOriginFilterInitializer;
-import org.apache.hadoop.security.authorize.AccessControlList;
-import org.apache.hadoop.security.authorize.ServiceAuthorizationManager;
-import org.apache.hadoop.security.http.CrossOriginFilter;
-import org.apache.hadoop.test.LambdaTestUtils;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.webapp.WebApp;
-import org.eclipse.jetty.servlet.FilterHolder;
-import org.eclipse.jetty.servlet.ServletHandler;
-import org.eclipse.jetty.webapp.WebAppContext;
-import org.junit.Assert;
-import org.junit.Test;
-import org.mockito.Mockito;
-
-import javax.servlet.FilterChain;
-import javax.servlet.ServletException;
-import javax.servlet.ServletOutputStream;
-import javax.servlet.http.Cookie;
-import javax.servlet.http.HttpServletRequest;
-import javax.servlet.http.HttpServletResponse;
-import java.io.ByteArrayOutputStream;
-import java.io.IOException;
-import java.io.PrintStream;
-import java.io.PrintWriter;
-import java.util.Collection;
-import java.util.HashMap;
-import java.util.Locale;
-import java.util.Map;
-
-/**
- * Tests {@link Router}.
- */
-public class TestRouter {
-
-  @Test
-  public void testJVMMetricsService() {
-    YarnConfiguration conf = new YarnConfiguration();
-    Router router = new Router();
-    router.init(conf);
-    assertEquals(3, router.getServices().size());
-  }
-
-  @Test
-  public void testServiceACLRefresh() {
-    Configuration conf = new Configuration();
-    conf.setBoolean(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION,
-        true);
-    String aclsString = "alice,bob users,wheel";
-    conf.set("security.applicationclient.protocol.acl", aclsString);
-    conf.set("security.resourcemanager-administration.protocol.acl",
-        aclsString);
-
-    Router router = new Router();
-    router.init(conf);
-    router.start();
-
-    // verify service Acls refresh for RouterClientRMService
-    ServiceAuthorizationManager clientRMServiceManager =
-        router.clientRMProxyService.getServer().
-        getServiceAuthorizationManager();
-    verifyServiceACLsRefresh(clientRMServiceManager,
-        org.apache.hadoop.yarn.api.ApplicationClientProtocolPB.class,
-        aclsString);
-
-    // verify service Acls refresh for RouterRMAdminService
-    ServiceAuthorizationManager routerAdminServiceManager =
-        router.rmAdminProxyService.getServer().getServiceAuthorizationManager();
-    verifyServiceACLsRefresh(routerAdminServiceManager,
-        org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocolPB.class,
-        aclsString);
-
-    router.stop();
-
-  }
-
-  private void verifyServiceACLsRefresh(ServiceAuthorizationManager manager,
-      Class<?> protocol, String aclString) {
-    if (manager.getProtocolsWithAcls().size() == 0) {
-      fail("Acls are not refreshed for protocol " + protocol);
-    }
-    for (Class<?> protocolClass : manager.getProtocolsWithAcls()) {
-      AccessControlList accessList = manager.getProtocolsAcls(protocolClass);
-      if (protocolClass == protocol) {
-        Assert.assertEquals(accessList.getAclString(), aclString);
-      }
-    }
-  }
-
-  @Test
-  public void testRouterSupportCrossOrigin() throws ServletException, IOException {
-
-    // We design test cases like this
-    // We start the Router and enable the Router to support Cross-origin.
-    // In the configuration, we allow example.com to access.
-    // 1. We simulate example.com and get the correct response
-    // 2. We simulate example.org and cannot get a response
-
-    // Initialize RouterWeb's CrossOrigin capability
-    Configuration conf = new Configuration();
-    conf.setBoolean(YarnConfiguration.ROUTER_WEBAPP_ENABLE_CORS_FILTER, true);
-    conf.set("hadoop.http.filter.initializers", HttpCrossOriginFilterInitializer.class.getName());
-    conf.set(HttpCrossOriginFilterInitializer.PREFIX + CrossOriginFilter.ALLOWED_ORIGINS,
-        "example.com");
-    conf.set(HttpCrossOriginFilterInitializer.PREFIX + CrossOriginFilter.ALLOWED_HEADERS,
-        "X-Requested-With,Accept");
-    conf.set(HttpCrossOriginFilterInitializer.PREFIX + CrossOriginFilter.ALLOWED_METHODS,
-        "GET,POST");
-
-    // Start the router
-    Router router = new Router();
-    router.init(conf);
-    router.start();
-    router.getServices();
-
-    // Get assigned to Filter.
-    // The name of the filter is "Cross Origin Filter",
-    // which is specified in HttpCrossOriginFilterInitializer.
-    WebApp webApp = router.getWebapp();
-    HttpServer2 httpServer2 = webApp.getHttpServer();
-    WebAppContext webAppContext = httpServer2.getWebAppContext();
-    ServletHandler servletHandler = webAppContext.getServletHandler();
-    FilterHolder holder = servletHandler.getFilter("Cross Origin Filter");
-    CrossOriginFilter filter = (CrossOriginFilter) holder.getFilter();
-
-    // 1. Simulate [example.com] for access
-    HttpServletRequest mockReq = Mockito.mock(HttpServletRequest.class);
-    Mockito.when(mockReq.getHeader("Origin")).thenReturn("example.com");
-    Mockito.when(mockReq.getHeader("Access-Control-Request-Method")).thenReturn("GET");
-    Mockito.when(mockReq.getHeader("Access-Control-Request-Headers"))
-        .thenReturn("X-Requested-With");
-
-    // Objects to verify interactions based on request
-    HttpServletResponseForRouterTest mockRes = new HttpServletResponseForRouterTest();
-    FilterChain mockChain = Mockito.mock(FilterChain.class);
-
-    // Object under test
-    filter.doFilter(mockReq, mockRes, mockChain);
-
-    // Why is 5, because when Filter passes,
-    // CrossOriginFilter will set 5 values to Map
-    Assert.assertEquals(5, mockRes.getHeaders().size());
-    String allowResult = mockRes.getHeader("Access-Control-Allow-Credentials");
-    Assert.assertEquals("true", allowResult);
-
-    // 2. Simulate [example.org] for access
-    HttpServletRequest mockReq2 = Mockito.mock(HttpServletRequest.class);
-    Mockito.when(mockReq2.getHeader("Origin")).thenReturn("example.org");
-    Mockito.when(mockReq2.getHeader("Access-Control-Request-Method")).thenReturn("GET");
-    Mockito.when(mockReq2.getHeader("Access-Control-Request-Headers"))
-        .thenReturn("X-Requested-With");
-
-    // Objects to verify interactions based on request
-    HttpServletResponseForRouterTest mockRes2 = new HttpServletResponseForRouterTest();
-    FilterChain mockChain2 = Mockito.mock(FilterChain.class);
-
-    // Object under test
-    filter.doFilter(mockReq2, mockRes2, mockChain2);
-
-    // Why is 0, because when the Filter fails,
-    // CrossOriginFilter will not set any value
-    Assert.assertEquals(0, mockRes2.getHeaders().size());
-
-    router.stop();
-  }
-
-  @Test
-  public void testUserProvidedUGIConf() throws Exception {
-    String errMsg = "Invalid attribute value for " +
-        CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION + " of DUMMYAUTH";
-    Configuration dummyConf = new YarnConfiguration();
-    dummyConf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION, "DUMMYAUTH");
-    Router router = new Router();
-    LambdaTestUtils.intercept(IllegalArgumentException.class, errMsg,
-        () -> router.init(dummyConf));
-    router.stop();
-  }
-
-  private class HttpServletResponseForRouterTest implements HttpServletResponse {
-    private final Map<String, String> headers = new HashMap<>(1);
-
-    @Override
-    public void addCookie(Cookie cookie) {
-
-    }
-
-    @Override
-    public boolean containsHeader(String name) {
-      return false;
-    }
-
-    @Override
-    public String encodeURL(String url) {
-      return null;
-    }
-
-    @Override
-    public String encodeRedirectURL(String url) {
-      return null;
-    }
-
-    @Override
-    public String encodeUrl(String url) {
-      return null;
-    }
-
-    @Override
-    public String encodeRedirectUrl(String url) {
-      return null;
-    }
-
-    @Override
-    public void sendError(int sc, String msg) throws IOException {
-
-    }
-
-    @Override
-    public void sendError(int sc) throws IOException {
-
-    }
-
-    @Override
-    public void sendRedirect(String location) throws IOException {
-
-    }
-
-    @Override
-    public void setDateHeader(String name, long date) {
-
-    }
-
-    @Override
-    public void addDateHeader(String name, long date) {
-
-    }
-
-    @Override
-    public void setHeader(String name, String value) {
-      headers.put(name, value);
-    }
-
-    @Override
-    public void addHeader(String name, String value) {
-
-    }
-
-    @Override
-    public void setIntHeader(String name, int value) {
-
-    }
-
-    @Override
-    public void addIntHeader(String name, int value) {
-
-    }
-
-    @Override
-    public void setStatus(int sc) {
-
-    }
-
-    @Override
-    public void setStatus(int sc, String sm) {
-
-    }
-
-    @Override
-    public int getStatus() {
-      return 0;
-    }
-
-    public String getHeader(String name) {
-      return headers.get(name);
-    }
-
-    @Override
-    public Collection<String> getHeaders(String name) {
-      return null;
-    }
-
-    @Override
-    public Collection<String> getHeaderNames() {
-      return null;
-    }
-
-    public Map<String, String> getHeaders() {
-      return headers;
-    }
-
-    @Override
-    public String getCharacterEncoding() {
-      return null;
-    }
-
-    @Override
-    public String getContentType() {
-      return null;
-    }
-
-    @Override
-    public ServletOutputStream getOutputStream() throws IOException {
-      return null;
-    }
-
-    @Override
-    public PrintWriter getWriter() throws IOException {
-      return null;
-    }
-
-    @Override
-    public void setCharacterEncoding(String charset) {
-
-    }
-
-    @Override
-    public void setContentLength(int len) {
-
-    }
-
-    @Override
-    public void setContentLengthLong(long len) {
-
-    }
-
-    @Override
-    public void setContentType(String type) {
-
-    }
-
-    @Override
-    public void setBufferSize(int size) {
-
-    }
-
-    @Override
-    public int getBufferSize() {
-      return 0;
-    }
-
-    @Override
-    public void flushBuffer() throws IOException {
-
-    }
-
-    @Override
-    public void resetBuffer() {
-
-    }
-
-    @Override
-    public boolean isCommitted() {
-      return false;
-    }
-
-    @Override
-    public void reset() {
-
-    }
-
-    @Override
-    public void setLocale(Locale loc) {
-
-    }
-
-    @Override
-    public Locale getLocale() {
-      return null;
-    }
-  }
-
-  @Test
-  public void testRouterCLI() {
-    ByteArrayOutputStream dataOut = new ByteArrayOutputStream();
-    ByteArrayOutputStream dataErr = new ByteArrayOutputStream();
-    System.setOut(new PrintStream(dataOut));
-    System.setErr(new PrintStream(dataErr));
-    Router.main(new String[]{"-help", "-format-state-store"});
-    assertTrue(dataErr.toString().contains(
-        "Usage: yarn router [-format-state-store] | " +
-        "[-remove-application-from-state-store <appId>]"));
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouterAuditLogger.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouterAuditLogger.java
deleted file mode 100644
index 287048237ee..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouterAuditLogger.java
+++ /dev/null
@@ -1,253 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router;
-
-import static org.junit.Assert.assertEquals;
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.when;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.ipc.ClientId;
-import org.apache.hadoop.ipc.ProtobufRpcEngine2;
-import org.apache.hadoop.ipc.RPC;
-import org.apache.hadoop.ipc.Server;
-import org.apache.hadoop.ipc.TestRpcBase;
-import org.apache.hadoop.ipc.protobuf.TestProtos;
-import org.apache.hadoop.ipc.protobuf.TestRpcServiceProtos;
-import org.apache.hadoop.ipc.TestRPC;
-import org.apache.hadoop.net.NetUtils;
-import org.apache.hadoop.thirdparty.protobuf.BlockingService;
-import org.apache.hadoop.thirdparty.protobuf.RpcController;
-import org.apache.hadoop.thirdparty.protobuf.ServiceException;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Test;
-
-import java.net.InetAddress;
-import java.net.InetSocketAddress;
-
-/**
- * Tests {@link RouterAuditLogger}.
- */
-public class TestRouterAuditLogger {
-  private static final String USER = "test";
-  private static final String OPERATION = "oper";
-  private static final String TARGET = "tgt";
-  private static final String DESC = "description of an audit log";
-
-  private static final ApplicationId APPID = mock(ApplicationId.class);
-  private static final SubClusterId SUBCLUSTERID = mock(SubClusterId.class);
-
-  @Before public void setUp() throws Exception {
-    when(APPID.toString()).thenReturn("app_1");
-    when(SUBCLUSTERID.toString()).thenReturn("sc0");
-  }
-
-  /**
-   * Test the AuditLog format with key-val pair.
-   */
-  @Test
-  public void testKeyValLogFormat() {
-    StringBuilder actLog = new StringBuilder();
-    StringBuilder expLog = new StringBuilder();
-
-    // add the first k=v pair and check
-    RouterAuditLogger.start(RouterAuditLogger.Keys.USER, USER, actLog);
-    expLog.append("USER=test");
-    assertEquals(expLog.toString(), actLog.toString());
-
-    // append another k1=v1 pair to already added k=v and test
-    RouterAuditLogger.add(RouterAuditLogger.Keys.OPERATION, OPERATION, actLog);
-    expLog.append("\tOPERATION=oper");
-    assertEquals(expLog.toString(), actLog.toString());
-
-    // append another k1=null pair and test
-    RouterAuditLogger.add(RouterAuditLogger.Keys.APPID, null, actLog);
-    expLog.append("\tAPPID=null");
-    assertEquals(expLog.toString(), actLog.toString());
-
-    // now add the target and check of the final string
-    RouterAuditLogger.add(RouterAuditLogger.Keys.TARGET, TARGET, actLog);
-    expLog.append("\tTARGET=tgt");
-    assertEquals(expLog.toString(), actLog.toString());
-  }
-
-  /**
-   * Test the AuditLog format for successful events.
-   */
-  private void testSuccessLogFormatHelper(boolean checkIP, ApplicationId appId,
-      SubClusterId subClusterId) {
-    // check without the IP
-    String sLog = RouterAuditLogger
-        .createSuccessLog(USER, OPERATION, TARGET, appId, subClusterId);
-    StringBuilder expLog = new StringBuilder();
-    expLog.append("USER=test\t");
-    if (checkIP) {
-      InetAddress ip = Server.getRemoteIp();
-      if (ip != null && ip.getHostAddress() != null) {
-        expLog.append(RouterAuditLogger.Keys.IP.name())
-            .append("=").append(ip.getHostAddress()).append("\t");
-      }
-    }
-    expLog.append("OPERATION=oper\tTARGET=tgt\tRESULT=SUCCESS");
-    if (appId != null) {
-      expLog.append("\tAPPID=app_1");
-    }
-    if (subClusterId != null) {
-      expLog.append("\tSUBCLUSTERID=sc0");
-    }
-    assertEquals(expLog.toString(), sLog);
-  }
-
-  /**
-   * Test the AuditLog format for successful events passing nulls.
-   */
-  private void testSuccessLogNulls() {
-    String sLog =
-        RouterAuditLogger.createSuccessLog(null, null, null, null, null);
-    StringBuilder expLog = new StringBuilder();
-    expLog.append("USER=null\t");
-    expLog.append("OPERATION=null\tTARGET=null\tRESULT=SUCCESS");
-    assertEquals(expLog.toString(), sLog);
-  }
-
-  /**
-   * Test the AuditLog format for successful events with the various
-   * parameters.
-   */
-  private void testSuccessLogFormat(boolean checkIP) {
-    testSuccessLogFormatHelper(checkIP, null, null);
-    testSuccessLogFormatHelper(checkIP, APPID, null);
-    testSuccessLogFormatHelper(checkIP, null, SUBCLUSTERID);
-    testSuccessLogFormatHelper(checkIP, APPID, SUBCLUSTERID);
-  }
-
-  /**
-   *  Test the AuditLog format for failure events.
-   */
-  private void testFailureLogFormatHelper(boolean checkIP, ApplicationId appId,
-      SubClusterId subClusterId) {
-    String fLog = RouterAuditLogger
-        .createFailureLog(USER, OPERATION, "UNKNOWN", TARGET, DESC, appId,
-            subClusterId);
-    StringBuilder expLog = new StringBuilder();
-    expLog.append("USER=test\t");
-    if (checkIP) {
-      InetAddress ip = Server.getRemoteIp();
-      if (ip != null && ip.getHostAddress() != null) {
-        expLog.append(RouterAuditLogger.Keys.IP.name())
-            .append("=")
-            .append(ip.getHostAddress()).append("\t");
-      }
-    }
-    expLog.append("OPERATION=oper\tTARGET=tgt\tRESULT=FAILURE\t");
-    expLog.append("DESCRIPTION=description of an audit log");
-    expLog.append("\tPERMISSIONS=UNKNOWN");
-
-    if (appId != null) {
-      expLog.append("\tAPPID=app_1");
-    }
-    if (subClusterId != null) {
-      expLog.append("\tSUBCLUSTERID=sc0");
-    }
-    assertEquals(expLog.toString(), fLog);
-  }
-
-  /**
-   * Test the AuditLog format for failure events with the various
-   * parameters.
-   */
-  private void testFailureLogFormat(boolean checkIP) {
-    testFailureLogFormatHelper(checkIP, null, null);
-    testFailureLogFormatHelper(checkIP, APPID, null);
-    testFailureLogFormatHelper(checkIP, null, SUBCLUSTERID);
-    testFailureLogFormatHelper(checkIP, APPID, SUBCLUSTERID);
-  }
-
-  /**
-   *  Test {@link RouterAuditLogger}.
-   */
-  @Test
-  public void testRouterAuditLoggerWithOutIP() {
-    testSuccessLogFormat(false);
-    testFailureLogFormat(false);
-  }
-
-  /**
-   * A special extension of {@link TestRPC.TestImpl} RPC server with
-   * {@link TestRPC.TestImpl#ping()} testing the audit logs.
-   */
-  private class MyTestRouterRPCServer extends TestRpcBase.PBServerImpl {
-    @Override
-    public TestProtos.EmptyResponseProto ping(
-            RpcController unused, TestProtos.EmptyRequestProto request)
-            throws ServiceException {
-      // Ensure clientId is received
-      byte[] clientId = Server.getClientId();
-      Assert.assertNotNull(clientId);
-      Assert.assertEquals(ClientId.BYTE_LENGTH, clientId.length);
-      // test with ip set
-      testSuccessLogFormat(true);
-      testFailureLogFormat(true);
-      return TestProtos.EmptyResponseProto.newBuilder().build();
-    }
-  }
-
-  /**
-   * Test {@link RouterAuditLogger} with IP set.
-   */
-  @Test
-  public void testRouterAuditLoggerWithIP() throws Exception {
-    Configuration conf = new Configuration();
-    RPC.setProtocolEngine(conf, TestRpcBase.TestRpcService.class, ProtobufRpcEngine2.class);
-
-    // Create server side implementation
-    MyTestRouterRPCServer serverImpl = new MyTestRouterRPCServer();
-    BlockingService service = TestRpcServiceProtos.TestProtobufRpcProto
-        .newReflectiveBlockingService(serverImpl);
-
-    // start the IPC server
-    Server server = new RPC.Builder(conf)
-        .setProtocol(TestRpcBase.TestRpcService.class)
-        .setInstance(service).setBindAddress("0.0.0.0")
-        .setPort(0).setNumHandlers(5).setVerbose(true).build();
-
-    server.start();
-
-    InetSocketAddress address = NetUtils.getConnectAddress(server);
-
-    // Make a client connection and test the audit log
-    TestRpcBase.TestRpcService proxy = null;
-    try {
-      proxy = RPC.getProxy(TestRpcBase.TestRpcService.class,
-          TestRPC.TestProtocol.versionID, address, conf);
-      // Start the testcase
-      TestProtos.EmptyRequestProto pingRequest =
-          TestProtos.EmptyRequestProto.newBuilder().build();
-      proxy.ping(null, pingRequest);
-    } finally {
-      server.stop();
-      if (proxy != null) {
-        RPC.stopProxy(proxy);
-      }
-    }
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouterMetrics.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouterMetrics.java
deleted file mode 100644
index 36c97e02eb1..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouterMetrics.java
+++ /dev/null
@@ -1,2382 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router;
-
-import org.junit.Assert;
-import org.junit.BeforeClass;
-import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * This class validates the correctness of Router Federation Interceptor
- * Metrics.
- */
-public class TestRouterMetrics {
-  public static final Logger LOG =
-      LoggerFactory.getLogger(TestRouterMetrics.class);
-
-  // All the operations in the bad subcluster failed.
-  private MockBadSubCluster badSubCluster = new MockBadSubCluster();
-  // All the operations in the bad subcluster succeed.
-  private MockGoodSubCluster goodSubCluster = new MockGoodSubCluster();
-
-  private static RouterMetrics metrics = RouterMetrics.getMetrics();
-
-  private static final Double ASSERT_DOUBLE_DELTA = 0.01;
-
-  @BeforeClass
-  public static void init() {
-
-    LOG.info("Test: aggregate metrics are initialized correctly");
-
-    Assert.assertEquals(0, metrics.getNumSucceededAppsCreated());
-    Assert.assertEquals(0, metrics.getNumSucceededAppsSubmitted());
-    Assert.assertEquals(0, metrics.getNumSucceededAppsKilled());
-    Assert.assertEquals(0, metrics.getNumSucceededAppsRetrieved());
-    Assert.assertEquals(0,
-        metrics.getNumSucceededAppAttemptsRetrieved());
-
-    Assert.assertEquals(0, metrics.getAppsFailedCreated());
-    Assert.assertEquals(0, metrics.getAppsFailedSubmitted());
-    Assert.assertEquals(0, metrics.getAppsFailedKilled());
-    Assert.assertEquals(0, metrics.getAppsFailedRetrieved());
-    Assert.assertEquals(0,
-        metrics.getAppAttemptsFailedRetrieved());
-
-    LOG.info("Test: aggregate metrics are updated correctly");
-  }
-
-  /**
-   * This test validates the correctness of the metric: Created Apps
-   * successfully.
-   */
-  @Test
-  public void testSucceededAppsCreated() {
-
-    long totalGoodBefore = metrics.getNumSucceededAppsCreated();
-
-    goodSubCluster.getNewApplication(100);
-
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededAppsCreated());
-    Assert.assertEquals(100, metrics.getLatencySucceededAppsCreated(), 0);
-
-    goodSubCluster.getNewApplication(200);
-
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededAppsCreated());
-    Assert.assertEquals(150, metrics.getLatencySucceededAppsCreated(), 0);
-  }
-
-  /**
-   * This test validates the correctness of the metric: Failed to create Apps.
-   */
-  @Test
-  public void testAppsFailedCreated() {
-
-    long totalBadbefore = metrics.getAppsFailedCreated();
-
-    badSubCluster.getNewApplication();
-
-    Assert.assertEquals(totalBadbefore + 1, metrics.getAppsFailedCreated());
-  }
-
-  /**
-   * This test validates the correctness of the metric: Submitted Apps
-   * successfully.
-   */
-  @Test
-  public void testSucceededAppsSubmitted() {
-
-    long totalGoodBefore = metrics.getNumSucceededAppsSubmitted();
-
-    goodSubCluster.submitApplication(100);
-
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededAppsSubmitted());
-    Assert.assertEquals(100, metrics.getLatencySucceededAppsSubmitted(), 0);
-
-    goodSubCluster.submitApplication(200);
-
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededAppsSubmitted());
-    Assert.assertEquals(150, metrics.getLatencySucceededAppsSubmitted(), 0);
-  }
-
-  /**
-   * This test validates the correctness of the metric: Failed to submit Apps.
-   */
-  @Test
-  public void testAppsFailedSubmitted() {
-
-    long totalBadbefore = metrics.getAppsFailedSubmitted();
-
-    badSubCluster.submitApplication();
-
-    Assert.assertEquals(totalBadbefore + 1, metrics.getAppsFailedSubmitted());
-  }
-
-  /**
-   * This test validates the correctness of the metric: Killed Apps
-   * successfully.
-   */
-  @Test
-  public void testSucceededAppsKilled() {
-
-    long totalGoodBefore = metrics.getNumSucceededAppsKilled();
-
-    goodSubCluster.forceKillApplication(100);
-
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededAppsKilled());
-    Assert.assertEquals(100, metrics.getLatencySucceededAppsKilled(), 0);
-
-    goodSubCluster.forceKillApplication(200);
-
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededAppsKilled());
-    Assert.assertEquals(150, metrics.getLatencySucceededAppsKilled(), 0);
-  }
-
-  /**
-   * This test validates the correctness of the metric: Failed to kill Apps.
-   */
-  @Test
-  public void testAppsFailedKilled() {
-
-    long totalBadbefore = metrics.getAppsFailedKilled();
-
-    badSubCluster.forceKillApplication();
-
-    Assert.assertEquals(totalBadbefore + 1, metrics.getAppsFailedKilled());
-  }
-
-  /**
-   * This test validates the correctness of the metric: Retrieved Apps
-   * successfully.
-   */
-  @Test
-  public void testSucceededAppsReport() {
-
-    long totalGoodBefore = metrics.getNumSucceededAppsRetrieved();
-
-    goodSubCluster.getApplicationReport(100);
-
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededAppsRetrieved());
-    Assert.assertEquals(100, metrics.getLatencySucceededGetAppReport(), 0);
-
-    goodSubCluster.getApplicationReport(200);
-
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededAppsRetrieved());
-    Assert.assertEquals(150, metrics.getLatencySucceededGetAppReport(), 0);
-  }
-
-  /**
-   * This test validates the correctness of the metric: Failed to retrieve Apps.
-   */
-  @Test
-  public void testAppsReportFailed() {
-
-    long totalBadbefore = metrics.getAppsFailedRetrieved();
-
-    badSubCluster.getApplicationReport();
-
-    Assert.assertEquals(totalBadbefore + 1, metrics.getAppsFailedRetrieved());
-  }
-
-  /**
-   * This test validates the correctness of the metric:
-   * Retrieved AppAttempt Report
-   * successfully.
-   */
-  @Test
-  public void testSucceededAppAttemptReport() {
-
-    long totalGoodBefore = metrics.getNumSucceededAppAttemptReportRetrieved();
-
-    goodSubCluster.getApplicationAttemptReport(100);
-
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededAppAttemptReportRetrieved());
-    Assert.assertEquals(100,
-        metrics.getLatencySucceededGetAppAttemptReport(), ASSERT_DOUBLE_DELTA);
-
-    goodSubCluster.getApplicationAttemptReport(200);
-
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededAppAttemptReportRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetAppAttemptReport(), ASSERT_DOUBLE_DELTA);
-  }
-
-  /**
-   * This test validates the correctness of the metric:
-   * Failed to retrieve AppAttempt Report.
-   */
-  @Test
-  public void testAppAttemptReportFailed() {
-
-    long totalBadBefore = metrics.getAppAttemptReportFailedRetrieved();
-
-    badSubCluster.getApplicationAttemptReport();
-
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getAppAttemptReportFailedRetrieved());
-  }
-
-  /**
-   * This test validates the correctness of the metric: Retrieved Multiple Apps
-   * successfully.
-   */
-  @Test
-  public void testSucceededMultipleAppsReport() {
-
-    long totalGoodBefore = metrics.getNumSucceededMultipleAppsRetrieved();
-
-    goodSubCluster.getApplicationsReport(100);
-
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededMultipleAppsRetrieved());
-    Assert.assertEquals(100, metrics.getLatencySucceededMultipleGetAppReport(),
-        0);
-
-    goodSubCluster.getApplicationsReport(200);
-
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededMultipleAppsRetrieved());
-    Assert.assertEquals(150, metrics.getLatencySucceededMultipleGetAppReport(),
-        0);
-  }
-
-  /**
-   * This test validates the correctness of the metric: Failed to retrieve
-   * Multiple Apps.
-   */
-  @Test
-  public void testMulipleAppsReportFailed() {
-
-    long totalBadbefore = metrics.getMultipleAppsFailedRetrieved();
-
-    badSubCluster.getApplicationsReport();
-
-    Assert.assertEquals(totalBadbefore + 1,
-        metrics.getMultipleAppsFailedRetrieved());
-  }
-
-  /**
-   * This test validates the correctness of the metric: Retrieved getClusterMetrics
-   * multiple times successfully.
-   */
-  @Test
-  public void testSucceededGetClusterMetrics() {
-    long totalGoodBefore = metrics.getNumSucceededGetClusterMetricsRetrieved();
-    goodSubCluster.getClusterMetrics(100);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetClusterMetricsRetrieved());
-    Assert.assertEquals(100, metrics.getLatencySucceededGetClusterMetricsRetrieved(),
-        0);
-    goodSubCluster.getClusterMetrics(200);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetClusterMetricsRetrieved());
-    Assert.assertEquals(150, metrics.getLatencySucceededGetClusterMetricsRetrieved(),
-        0);
-  }
-
-  /**
-   * This test validates the correctness of the metric: Failed to
-   * retrieve getClusterMetrics.
-   */
-  @Test
-  public void testGetClusterMetricsFailed() {
-    long totalBadbefore = metrics.getClusterMetricsFailedRetrieved();
-    badSubCluster.getClusterMetrics();
-    Assert.assertEquals(totalBadbefore + 1,
-        metrics.getClusterMetricsFailedRetrieved());
-  }
-
-  // Records failures for all calls
-  private class MockBadSubCluster {
-    public void getNewApplication() {
-      LOG.info("Mocked: failed getNewApplication call");
-      metrics.incrAppsFailedCreated();
-    }
-
-    public void submitApplication() {
-      LOG.info("Mocked: failed submitApplication call");
-      metrics.incrAppsFailedSubmitted();
-    }
-
-    public void forceKillApplication() {
-      LOG.info("Mocked: failed forceKillApplication call");
-      metrics.incrAppsFailedKilled();
-    }
-
-    public void getApplicationReport() {
-      LOG.info("Mocked: failed getApplicationReport call");
-      metrics.incrAppsFailedRetrieved();
-    }
-
-    public void getApplicationAttemptReport() {
-      LOG.info("Mocked: failed getApplicationAttemptReport call");
-      metrics.incrAppAttemptReportFailedRetrieved();
-    }
-
-    public void getApplicationsReport() {
-      LOG.info("Mocked: failed getApplicationsReport call");
-      metrics.incrMultipleAppsFailedRetrieved();
-    }
-
-    public void getClusterMetrics() {
-      LOG.info("Mocked: failed getClusterMetrics call");
-      metrics.incrGetClusterMetricsFailedRetrieved();
-    }
-
-    public void getClusterNodes() {
-      LOG.info("Mocked: failed getClusterNodes call");
-      metrics.incrClusterNodesFailedRetrieved();
-    }
-
-    public void getNodeToLabels() {
-      LOG.info("Mocked: failed getNodeToLabels call");
-      metrics.incrNodeToLabelsFailedRetrieved();
-    }
-
-    public void getLabelToNodes() {
-      LOG.info("Mocked: failed getLabelToNodes call");
-      metrics.incrLabelsToNodesFailedRetrieved();
-    }
-
-    public void getClusterNodeLabels() {
-      LOG.info("Mocked: failed getClusterNodeLabels call");
-      metrics.incrClusterNodeLabelsFailedRetrieved();
-    }
-
-    public void getQueueUserAcls() {
-      LOG.info("Mocked: failed getQueueUserAcls call");
-      metrics.incrQueueUserAclsFailedRetrieved();
-    }
-
-    public void getListReservations() {
-      LOG.info("Mocked: failed listReservations call");
-      metrics.incrListReservationsFailedRetrieved();
-    }
-
-    public void getApplicationAttempts() {
-      LOG.info("Mocked: failed getApplicationAttempts call");
-      metrics.incrAppAttemptsFailedRetrieved();
-    }
-
-    public void getContainerReport() {
-      LOG.info("Mocked: failed getContainerReport call");
-      metrics.incrGetContainerReportFailedRetrieved();
-    }
-
-    public void getContainers() {
-      LOG.info("Mocked: failed getContainer call");
-      metrics.incrGetContainersFailedRetrieved();
-    }
-
-    public void getResourceTypeInfo() {
-      LOG.info("Mocked: failed getResourceTypeInfo call");
-      metrics.incrResourceTypeInfoFailedRetrieved();
-    }
-
-    public void getFailApplicationAttempt() {
-      LOG.info("Mocked: failed failApplicationAttempt call");
-      metrics.incrFailAppAttemptFailedRetrieved();
-    }
-
-    public void getUpdateApplicationPriority() {
-      LOG.info("Mocked: failed updateApplicationPriority call");
-      metrics.incrUpdateAppPriorityFailedRetrieved();
-    }
-
-    public void getUpdateApplicationTimeouts() {
-      LOG.info("Mocked: failed updateApplicationTimeouts call");
-      metrics.incrUpdateApplicationTimeoutsRetrieved();
-    }
-
-    public void getSignalContainer() {
-      LOG.info("Mocked: failed signalContainer call");
-      metrics.incrSignalToContainerFailedRetrieved();
-    }
-
-    public void getQueueInfo() {
-      LOG.info("Mocked: failed getQueueInfo call");
-      metrics.incrGetQueueInfoFailedRetrieved();
-    }
-
-    public void moveApplicationAcrossQueuesFailed() {
-      LOG.info("Mocked: failed moveApplicationAcrossQueuesFailed call");
-      metrics.incrMoveApplicationAcrossQueuesFailedRetrieved();
-    }
-
-    public void getResourceProfilesFailed() {
-      LOG.info("Mocked: failed getResourceProfilesFailed call");
-      metrics.incrGetResourceProfilesFailedRetrieved();
-    }
-
-    public void getResourceProfileFailed() {
-      LOG.info("Mocked: failed getResourceProfileFailed call");
-      metrics.incrGetResourceProfileFailedRetrieved();
-    }
-
-    public void getAttributesToNodesFailed() {
-      LOG.info("Mocked: failed getAttributesToNodesFailed call");
-      metrics.incrGetAttributesToNodesFailedRetrieved();
-    }
-
-    public void getClusterNodeAttributesFailed() {
-      LOG.info("Mocked: failed getClusterNodeAttributesFailed call");
-      metrics.incrGetClusterNodeAttributesFailedRetrieved();
-    }
-
-    public void getNodesToAttributesFailed() {
-      LOG.info("Mocked: failed getNodesToAttributesFailed call");
-      metrics.incrGetNodesToAttributesFailedRetrieved();
-    }
-
-    public void getNewReservationFailed() {
-      LOG.info("Mocked: failed getNewReservationFailed call");
-      metrics.incrGetNewReservationFailedRetrieved();
-    }
-
-    public void getSubmitReservationFailed() {
-      LOG.info("Mocked: failed getSubmitReservationFailed call");
-      metrics.incrSubmitReservationFailedRetrieved();
-    }
-
-    public void getUpdateReservationFailed() {
-      LOG.info("Mocked: failed getUpdateReservationFailed call");
-      metrics.incrUpdateReservationFailedRetrieved();
-    }
-
-    public void getDeleteReservationFailed() {
-      LOG.info("Mocked: failed getDeleteReservationFailed call");
-      metrics.incrDeleteReservationFailedRetrieved();
-    }
-
-    public void getListReservationFailed() {
-      LOG.info("Mocked: failed getListReservationFailed call");
-      metrics.incrListReservationFailedRetrieved();
-    }
-
-    public void getAppActivitiesFailed() {
-      LOG.info("Mocked: failed getAppActivitiesFailed call");
-      metrics.incrGetAppActivitiesFailedRetrieved();
-    }
-
-    public void getAppStatisticsFailed() {
-      LOG.info("Mocked: failed getAppStatisticsFailed call");
-      metrics.incrGetAppStatisticsFailedRetrieved();
-    }
-
-    public void getAppPriorityFailed() {
-      LOG.info("Mocked: failed getAppPriorityFailed call");
-      metrics.incrGetAppPriorityFailedRetrieved();
-    }
-
-    public void getAppQueueFailed() {
-      LOG.info("Mocked: failed getAppQueueFailed call");
-      metrics.incrGetAppQueueFailedRetrieved();
-    }
-
-    public void getUpdateQueueFailed() {
-      LOG.info("Mocked: failed getUpdateQueueFailed call");
-      metrics.incrUpdateAppQueueFailedRetrieved();
-    }
-
-    public void getAppTimeoutFailed() {
-      LOG.info("Mocked: failed getAppTimeoutFailed call");
-      metrics.incrGetAppTimeoutFailedRetrieved();
-    }
-
-    public void getAppTimeoutsFailed() {
-      LOG.info("Mocked: failed getAppTimeoutsFailed call");
-      metrics.incrGetAppTimeoutsFailedRetrieved();
-    }
-
-    public void getRMNodeLabelsFailed() {
-      LOG.info("Mocked: failed getRMNodeLabelsFailed call");
-      metrics.incrGetRMNodeLabelsFailedRetrieved();
-    }
-
-    public void getCheckUserAccessToQueueFailed() {
-      LOG.info("Mocked: failed checkUserAccessToQueue call");
-      metrics.incrCheckUserAccessToQueueFailedRetrieved();
-    }
-
-    public void getDelegationTokenFailed() {
-      LOG.info("Mocked: failed getDelegationToken call");
-      metrics.incrGetDelegationTokenFailedRetrieved();
-    }
-
-    public void getRenewDelegationTokenFailed() {
-      LOG.info("Mocked: failed renewDelegationToken call");
-      metrics.incrRenewDelegationTokenFailedRetrieved();
-    }
-
-    public void getRefreshAdminAclsFailedRetrieved() {
-      LOG.info("Mocked: failed refreshAdminAcls call");
-      metrics.incrRefreshAdminAclsFailedRetrieved();
-    }
-
-    public void getRefreshServiceAclsFailedRetrieved() {
-      LOG.info("Mocked: failed refreshServiceAcls call");
-      metrics.incrRefreshServiceAclsFailedRetrieved();
-    }
-
-    public void getReplaceLabelsOnNodesFailed() {
-      LOG.info("Mocked: failed replaceLabelsOnNodes call");
-      metrics.incrReplaceLabelsOnNodesFailedRetrieved();
-    }
-
-    public void getReplaceLabelsOnNodeFailed() {
-      LOG.info("Mocked: failed ReplaceLabelOnNode call");
-      metrics.incrReplaceLabelsOnNodeFailedRetrieved();
-    }
-
-    public void getDumpSchedulerLogsFailed() {
-      LOG.info("Mocked: failed DumpSchedulerLogs call");
-      metrics.incrDumpSchedulerLogsFailedRetrieved();
-    }
-
-    public void getActivitiesFailed() {
-      LOG.info("Mocked: failed getBulkActivitie call");
-      metrics.incrGetActivitiesFailedRetrieved();
-    }
-
-    public void getBulkActivitiesFailed() {
-      LOG.info("Mocked: failed getBulkActivitie call");
-      metrics.incrGetBulkActivitiesFailedRetrieved();
-    }
-
-    public void getDeregisterSubClusterFailed() {
-      LOG.info("Mocked: failed deregisterSubCluster call");
-      metrics.incrDeregisterSubClusterFailedRetrieved();
-    }
-
-    public void getSchedulerConfigurationFailed() {
-      LOG.info("Mocked: failed getSchedulerConfiguration call");
-      metrics.incrGetSchedulerConfigurationFailedRetrieved();
-    }
-
-    public void updateSchedulerConfigurationFailedRetrieved() {
-      LOG.info("Mocked: failed updateSchedulerConfiguration call");
-      metrics.incrUpdateSchedulerConfigurationFailedRetrieved();
-    }
-
-    public void getClusterInfoFailed() {
-      LOG.info("Mocked: failed getClusterInfo call");
-      metrics.incrGetClusterInfoFailedRetrieved();
-    }
-
-    public void getClusterUserInfoFailed() {
-      LOG.info("Mocked: failed getClusterUserInfo call");
-      metrics.incrGetClusterUserInfoFailedRetrieved();
-    }
-
-    public void getUpdateNodeResourceFailed() {
-      LOG.info("Mocked: failed getClusterUserInfo call");
-      metrics.incrUpdateNodeResourceFailedRetrieved();
-    }
-
-    public void getRefreshNodesResourcesFailed() {
-      LOG.info("Mocked: failed refreshNodesResources call");
-      metrics.incrRefreshNodesResourcesFailedRetrieved();
-    }
-
-    public void getCheckForDecommissioningNodesFailed() {
-      LOG.info("Mocked: failed checkForDecommissioningNodes call");
-      metrics.incrCheckForDecommissioningNodesFailedRetrieved();
-    }
-
-    public void getRefreshClusterMaxPriorityFailed() {
-      LOG.info("Mocked: failed refreshClusterMaxPriority call");
-      metrics.incrRefreshClusterMaxPriorityFailedRetrieved();
-    }
-
-    public void getMapAttributesToNodesFailed() {
-      LOG.info("Mocked: failed getMapAttributesToNode call");
-      metrics.incrMapAttributesToNodesFailedRetrieved();
-    }
-
-    public void getGroupsForUserFailed() {
-      LOG.info("Mocked: failed getGroupsForUser call");
-      metrics.incrGetGroupsForUserFailedRetrieved();
-    }
-
-    public void getSaveFederationQueuePolicyFailedRetrieved() {
-      LOG.info("Mocked: failed refreshClusterMaxPriority call");
-      metrics.incrSaveFederationQueuePolicyFailedRetrieved();
-    }
-
-    public void getBatchSaveFederationQueuePoliciesFailedRetrieved() {
-      LOG.info("Mocked: failed BatchSaveFederationQueuePolicies call");
-      metrics.incrBatchSaveFederationQueuePoliciesFailedRetrieved();
-    }
-
-    public void getListFederationQueuePoliciesFailedRetrieved() {
-      LOG.info("Mocked: failed ListFederationQueuePolicies call");
-      metrics.incrListFederationQueuePoliciesFailedRetrieved();
-    }
-
-    public void getFederationSubClustersFailedRetrieved() {
-      LOG.info("Mocked: failed GetFederationSubClusters call");
-      metrics.incrGetFederationSubClustersFailedRetrieved();
-    }
-    public void getDeleteFederationPoliciesByQueuesFailedRetrieved() {
-      LOG.info("Mocked: failed DeleteFederationPoliciesByQueues call");
-      metrics.incrDeleteFederationPoliciesByQueuesRetrieved();
-    }
-  }
-
-  // Records successes for all calls
-  private class MockGoodSubCluster {
-    public void getNewApplication(long duration) {
-      LOG.info("Mocked: successful getNewApplication call with duration {}",
-          duration);
-      metrics.succeededAppsCreated(duration);
-    }
-
-    public void submitApplication(long duration) {
-      LOG.info("Mocked: successful submitApplication call with duration {}",
-          duration);
-      metrics.succeededAppsSubmitted(duration);
-    }
-
-    public void forceKillApplication(long duration) {
-      LOG.info("Mocked: successful forceKillApplication call with duration {}",
-          duration);
-      metrics.succeededAppsKilled(duration);
-    }
-
-    public void getApplicationReport(long duration) {
-      LOG.info("Mocked: successful getApplicationReport call with duration {}",
-          duration);
-      metrics.succeededAppsRetrieved(duration);
-    }
-
-    public void getApplicationAttemptReport(long duration) {
-      LOG.info("Mocked: successful getApplicationAttemptReport call " +
-          "with duration {}", duration);
-      metrics.succeededAppAttemptReportRetrieved(duration);
-    }
-
-    public void getApplicationsReport(long duration) {
-      LOG.info("Mocked: successful getApplicationsReport call with duration {}",
-          duration);
-      metrics.succeededMultipleAppsRetrieved(duration);
-    }
-
-    public void getClusterMetrics(long duration){
-      LOG.info("Mocked: successful getClusterMetrics call with duration {}",
-              duration);
-      metrics.succeededGetClusterMetricsRetrieved(duration);
-    }
-
-    public void getClusterNodes(long duration) {
-      LOG.info("Mocked: successful getClusterNodes call with duration {}", duration);
-      metrics.succeededGetClusterNodesRetrieved(duration);
-    }
-
-    public void getNodeToLabels(long duration) {
-      LOG.info("Mocked: successful getNodeToLabels call with duration {}", duration);
-      metrics.succeededGetNodeToLabelsRetrieved(duration);
-    }
-
-    public void getLabelToNodes(long duration) {
-      LOG.info("Mocked: successful getLabelToNodes call with duration {}", duration);
-      metrics.succeededGetLabelsToNodesRetrieved(duration);
-    }
-
-    public void getClusterNodeLabels(long duration) {
-      LOG.info("Mocked: successful getClusterNodeLabels call with duration {}", duration);
-      metrics.succeededGetClusterNodeLabelsRetrieved(duration);
-    }
-
-    public void getQueueUserAcls(long duration) {
-      LOG.info("Mocked: successful getQueueUserAcls call with duration {}", duration);
-      metrics.succeededGetQueueUserAclsRetrieved(duration);
-    }
-
-    public void getListReservations(long duration) {
-      LOG.info("Mocked: successful listReservations call with duration {}", duration);
-      metrics.succeededListReservationsRetrieved(duration);
-    }
-
-    public void getApplicationAttempts(long duration) {
-      LOG.info("Mocked: successful getApplicationAttempts call with duration {}", duration);
-      metrics.succeededAppAttemptsRetrieved(duration);
-    }
-
-    public void getContainerReport(long duration) {
-      LOG.info("Mocked: successful getContainerReport call with duration {}", duration);
-      metrics.succeededGetContainerReportRetrieved(duration);
-    }
-
-    public void getContainers(long duration) {
-      LOG.info("Mocked: successful getContainer call with duration {}", duration);
-      metrics.succeededGetContainersRetrieved(duration);
-    }
-
-    public void getResourceTypeInfo(long duration) {
-      LOG.info("Mocked: successful getResourceTypeInfo call with duration {}", duration);
-      metrics.succeededGetResourceTypeInfoRetrieved(duration);
-    }
-
-    public void getFailApplicationAttempt(long duration) {
-      LOG.info("Mocked: successful failApplicationAttempt call with duration {}", duration);
-      metrics.succeededFailAppAttemptRetrieved(duration);
-    }
-
-    public void getUpdateApplicationPriority(long duration) {
-      LOG.info("Mocked: successful updateApplicationPriority call with duration {}", duration);
-      metrics.succeededUpdateAppPriorityRetrieved(duration);
-    }
-
-    public void getUpdateApplicationTimeouts(long duration) {
-      LOG.info("Mocked: successful updateApplicationTimeouts call with duration {}", duration);
-      metrics.succeededUpdateAppTimeoutsRetrieved(duration);
-    }
-
-    public void getSignalToContainerTimeouts(long duration) {
-      LOG.info("Mocked: successful signalToContainer call with duration {}", duration);
-      metrics.succeededSignalToContainerRetrieved(duration);
-    }
-
-    public void getQueueInfoRetrieved(long duration) {
-      LOG.info("Mocked: successful getQueueInfo call with duration {}", duration);
-      metrics.succeededGetQueueInfoRetrieved(duration);
-    }
-
-    public void moveApplicationAcrossQueuesRetrieved(long duration) {
-      LOG.info("Mocked: successful moveApplicationAcrossQueues call with duration {}", duration);
-      metrics.succeededMoveApplicationAcrossQueuesRetrieved(duration);
-    }
-
-    public void getResourceProfilesRetrieved(long duration) {
-      LOG.info("Mocked: successful getResourceProfiles call with duration {}", duration);
-      metrics.succeededGetResourceProfilesRetrieved(duration);
-    }
-
-    public void getResourceProfileRetrieved(long duration) {
-      LOG.info("Mocked: successful getResourceProfile call with duration {}", duration);
-      metrics.succeededGetResourceProfileRetrieved(duration);
-    }
-
-    public void getAttributesToNodesRetrieved(long duration) {
-      LOG.info("Mocked: successful getAttributesToNodes call with duration {}", duration);
-      metrics.succeededGetAttributesToNodesRetrieved(duration);
-    }
-
-    public void getClusterNodeAttributesRetrieved(long duration) {
-      LOG.info("Mocked: successful getClusterNodeAttributes call with duration {}", duration);
-      metrics.succeededGetClusterNodeAttributesRetrieved(duration);
-    }
-
-    public void getNodesToAttributesRetrieved(long duration) {
-      LOG.info("Mocked: successful getNodesToAttributes call with duration {}", duration);
-      metrics.succeededGetNodesToAttributesRetrieved(duration);
-    }
-
-    public void getNewReservationRetrieved(long duration) {
-      LOG.info("Mocked: successful getNewReservation call with duration {}", duration);
-      metrics.succeededGetNewReservationRetrieved(duration);
-    }
-
-    public void getSubmitReservationRetrieved(long duration) {
-      LOG.info("Mocked: successful getSubmitReservation call with duration {}", duration);
-      metrics.succeededSubmitReservationRetrieved(duration);
-    }
-
-    public void getUpdateReservationRetrieved(long duration) {
-      LOG.info("Mocked: successful getUpdateReservation call with duration {}", duration);
-      metrics.succeededUpdateReservationRetrieved(duration);
-    }
-
-    public void getDeleteReservationRetrieved(long duration) {
-      LOG.info("Mocked: successful getDeleteReservation call with duration {}", duration);
-      metrics.succeededDeleteReservationRetrieved(duration);
-    }
-
-    public void getListReservationRetrieved(long duration) {
-      LOG.info("Mocked: successful getListReservation call with duration {}", duration);
-      metrics.succeededListReservationRetrieved(duration);
-    }
-
-    public void getAppActivitiesRetrieved(long duration) {
-      LOG.info("Mocked: successful getAppActivities call with duration {}", duration);
-      metrics.succeededGetAppActivitiesRetrieved(duration);
-    }
-
-    public void getAppStatisticsRetrieved(long duration) {
-      LOG.info("Mocked: successful getAppStatistics call with duration {}", duration);
-      metrics.succeededGetAppStatisticsRetrieved(duration);
-    }
-
-    public void getAppPriorityRetrieved(long duration) {
-      LOG.info("Mocked: successful getAppPriority call with duration {}", duration);
-      metrics.succeededGetAppPriorityRetrieved(duration);
-    }
-
-    public void getAppQueueRetrieved(long duration) {
-      LOG.info("Mocked: successful getAppQueue call with duration {}", duration);
-      metrics.succeededGetAppQueueRetrieved(duration);
-    }
-
-    public void getUpdateQueueRetrieved(long duration) {
-      LOG.info("Mocked: successful getUpdateQueue call with duration {}", duration);
-      metrics.succeededUpdateAppQueueRetrieved(duration);
-    }
-
-    public void getAppTimeoutRetrieved(long duration) {
-      LOG.info("Mocked: successful getAppTimeout call with duration {}", duration);
-      metrics.succeededGetAppTimeoutRetrieved(duration);
-    }
-
-    public void getAppTimeoutsRetrieved(long duration) {
-      LOG.info("Mocked: successful getAppTimeouts call with duration {}", duration);
-      metrics.succeededGetAppTimeoutsRetrieved(duration);
-    }
-
-    public void getRMNodeLabelsRetrieved(long duration) {
-      LOG.info("Mocked: successful getRMNodeLabels call with duration {}", duration);
-      metrics.succeededGetRMNodeLabelsRetrieved(duration);
-    }
-
-    public void getCheckUserAccessToQueueRetrieved(long duration) {
-      LOG.info("Mocked: successful CheckUserAccessToQueue call with duration {}", duration);
-      metrics.succeededCheckUserAccessToQueueRetrieved(duration);
-    }
-
-    public void getGetDelegationTokenRetrieved(long duration) {
-      LOG.info("Mocked: successful GetDelegationToken call with duration {}", duration);
-      metrics.succeededGetDelegationTokenRetrieved(duration);
-    }
-
-    public void getRenewDelegationTokenRetrieved(long duration) {
-      LOG.info("Mocked: successful RenewDelegationToken call with duration {}", duration);
-      metrics.succeededRenewDelegationTokenRetrieved(duration);
-    }
-
-    public void getRefreshAdminAclsRetrieved(long duration) {
-      LOG.info("Mocked: successful RefreshAdminAcls call with duration {}", duration);
-      metrics.succeededRefreshAdminAclsRetrieved(duration);
-    }
-
-    public void getRefreshServiceAclsRetrieved(long duration) {
-      LOG.info("Mocked: successful RefreshServiceAcls call with duration {}", duration);
-      metrics.succeededRefreshServiceAclsRetrieved(duration);
-    }
-
-    public void getNumSucceededReplaceLabelsOnNodesRetrieved(long duration) {
-      LOG.info("Mocked: successful ReplaceLabelsOnNodes call with duration {}", duration);
-      metrics.succeededReplaceLabelsOnNodesRetrieved(duration);
-    }
-
-    public void getNumSucceededReplaceLabelsOnNodeRetrieved(long duration) {
-      LOG.info("Mocked: successful ReplaceLabelOnNode call with duration {}", duration);
-      metrics.succeededReplaceLabelsOnNodeRetrieved(duration);
-    }
-
-    public void getDumpSchedulerLogsRetrieved(long duration) {
-      LOG.info("Mocked: successful DumpSchedulerLogs call with duration {}", duration);
-      metrics.succeededDumpSchedulerLogsRetrieved(duration);
-    }
-
-    public void getActivitiesRetrieved(long duration) {
-      LOG.info("Mocked: successful GetActivities call with duration {}", duration);
-      metrics.succeededGetActivitiesLatencyRetrieved(duration);
-    }
-
-    public void getBulkActivitiesRetrieved(long duration) {
-      LOG.info("Mocked: successful GetBulkActivities call with duration {}", duration);
-      metrics.succeededGetBulkActivitiesRetrieved(duration);
-    }
-
-    public void getDeregisterSubClusterRetrieved(long duration) {
-      LOG.info("Mocked: successful DeregisterSubCluster call with duration {}", duration);
-      metrics.succeededDeregisterSubClusterRetrieved(duration);
-    }
-
-    public void addToClusterNodeLabelsRetrieved(long duration) {
-      LOG.info("Mocked: successful AddToClusterNodeLabels call with duration {}", duration);
-      metrics.succeededAddToClusterNodeLabelsRetrieved(duration);
-    }
-
-    public void getSchedulerConfigurationRetrieved(long duration) {
-      LOG.info("Mocked: successful GetSchedulerConfiguration call with duration {}", duration);
-      metrics.succeededGetSchedulerConfigurationRetrieved(duration);
-    }
-
-    public void getUpdateSchedulerConfigurationRetrieved(long duration) {
-      LOG.info("Mocked: successful UpdateSchedulerConfiguration call with duration {}", duration);
-      metrics.succeededUpdateSchedulerConfigurationRetrieved(duration);
-    }
-
-    public void getClusterInfoRetrieved(long duration) {
-      LOG.info("Mocked: successful GetClusterInfoRetrieved call with duration {}", duration);
-      metrics.succeededGetClusterInfoRetrieved(duration);
-    }
-
-    public void getClusterUserInfoRetrieved(long duration) {
-      LOG.info("Mocked: successful GetClusterUserInfoRetrieved call with duration {}", duration);
-      metrics.succeededGetClusterUserInfoRetrieved(duration);
-    }
-
-    public void getUpdateNodeResourceRetrieved(long duration) {
-      LOG.info("Mocked: successful UpdateNodeResourceRetrieved call with duration {}", duration);
-      metrics.succeededUpdateNodeResourceRetrieved(duration);
-    }
-
-    public void getRefreshNodesResourcesRetrieved(long duration) {
-      LOG.info("Mocked: successful RefreshNodesResourcesRetrieved call with duration {}", duration);
-      metrics.succeededRefreshNodesResourcesRetrieved(duration);
-    }
-
-    public void getCheckForDecommissioningNodesRetrieved(long duration) {
-      LOG.info("Mocked: successful CheckForDecommissioningNodesRetrieved call with duration {}",
-          duration);
-      metrics.succeededCheckForDecommissioningNodesRetrieved(duration);
-    }
-
-    public void getRefreshClusterMaxPriorityRetrieved(long duration) {
-      LOG.info("Mocked: successful RefreshClusterMaxPriority call with duration {}",
-          duration);
-      metrics.succeededRefreshClusterMaxPriorityRetrieved(duration);
-    }
-
-    public void getMapAttributesToNodesRetrieved(long duration) {
-      LOG.info("Mocked: successful MapAttributesToNodes call with duration {}",
-          duration);
-      metrics.succeededMapAttributesToNodesRetrieved(duration);
-    }
-
-    public void getGroupsForUsersRetrieved(long duration) {
-      LOG.info("Mocked: successful GetGroupsForUsers call with duration {}",
-          duration);
-      metrics.succeededGetGroupsForUsersRetrieved(duration);
-    }
-
-    public void getSaveFederationQueuePolicyRetrieved(long duration) {
-      LOG.info("Mocked: successful SaveFederationQueuePolicy call with duration {}",
-          duration);
-      metrics.succeededSaveFederationQueuePolicyRetrieved(duration);
-    }
-
-    public void getBatchSaveFederationQueuePoliciesRetrieved(long duration) {
-      LOG.info("Mocked: successful BatchSaveFederationQueuePoliciesRetrieved " +
-          " call with duration {}", duration);
-      metrics.succeededBatchSaveFederationQueuePoliciesRetrieved(duration);
-    }
-
-    public void getListFederationQueuePoliciesRetrieved(long duration) {
-      LOG.info("Mocked: successful ListFederationQueuePoliciesRetrieved " +
-          " call with duration {}", duration);
-      metrics.succeededListFederationQueuePoliciesRetrieved(duration);
-    }
-
-    public void getFederationSubClustersRetrieved(long duration) {
-      LOG.info("Mocked: successful GetFederationSubClustersRetrieved " +
-          " call with duration {}", duration);
-      metrics.succeededGetFederationSubClustersRetrieved(duration);
-    }
-    public void deleteFederationPoliciesByQueuesRetrieved(long duration) {
-      LOG.info("Mocked: successful DeleteFederationPoliciesByQueuesRetrieved " +
-          " call with duration {}", duration);
-      metrics.succeededDeleteFederationPoliciesByQueuesRetrieved(duration);
-    }
-  }
-
-  @Test
-  public void testSucceededGetClusterNodes() {
-    long totalGoodBefore = metrics.getNumSucceededGetClusterNodesRetrieved();
-    goodSubCluster.getClusterNodes(150);
-    Assert.assertEquals(totalGoodBefore + 1, metrics.getNumSucceededGetClusterNodesRetrieved());
-    Assert.assertEquals(150, metrics.getLatencySucceededGetClusterNodesRetrieved(),
-        ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getClusterNodes(300);
-    Assert.assertEquals(totalGoodBefore + 2, metrics.getNumSucceededGetClusterNodesRetrieved());
-    Assert.assertEquals(225, metrics.getLatencySucceededGetClusterNodesRetrieved(),
-        ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetClusterNodesFailed() {
-    long totalBadBefore = metrics.getClusterNodesFailedRetrieved();
-    badSubCluster.getClusterNodes();
-    Assert.assertEquals(totalBadBefore + 1, metrics.getClusterNodesFailedRetrieved());
-  }
-
-  @Test
-  public void testSucceededGetNodeToLabels() {
-    long totalGoodBefore = metrics.getNumSucceededGetNodeToLabelsRetrieved();
-    goodSubCluster.getNodeToLabels(150);
-    Assert.assertEquals(totalGoodBefore + 1, metrics.getNumSucceededGetNodeToLabelsRetrieved());
-    Assert.assertEquals(150, metrics.getLatencySucceededGetNodeToLabelsRetrieved(),
-        ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getNodeToLabels(300);
-    Assert.assertEquals(totalGoodBefore + 2, metrics.getNumSucceededGetNodeToLabelsRetrieved());
-    Assert.assertEquals(225, metrics.getLatencySucceededGetNodeToLabelsRetrieved(),
-        ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetNodeToLabelsFailed() {
-    long totalBadBefore = metrics.getNodeToLabelsFailedRetrieved();
-    badSubCluster.getNodeToLabels();
-    Assert.assertEquals(totalBadBefore + 1, metrics.getNodeToLabelsFailedRetrieved());
-  }
-
-  @Test
-  public void testSucceededLabelsToNodes() {
-    long totalGoodBefore = metrics.getNumSucceededGetLabelsToNodesRetrieved();
-    goodSubCluster.getLabelToNodes(150);
-    Assert.assertEquals(totalGoodBefore + 1, metrics.getNumSucceededGetLabelsToNodesRetrieved());
-    Assert.assertEquals(150, metrics.getLatencySucceededGetLabelsToNodesRetrieved(),
-        ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getLabelToNodes(300);
-    Assert.assertEquals(totalGoodBefore + 2, metrics.getNumSucceededGetLabelsToNodesRetrieved());
-    Assert.assertEquals(225, metrics.getLatencySucceededGetLabelsToNodesRetrieved(),
-        ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetLabelsToNodesFailed() {
-    long totalBadBefore = metrics.getLabelsToNodesFailedRetrieved();
-    badSubCluster.getLabelToNodes();
-    Assert.assertEquals(totalBadBefore + 1, metrics.getLabelsToNodesFailedRetrieved());
-  }
-
-  @Test
-  public void testSucceededClusterNodeLabels() {
-    long totalGoodBefore = metrics.getNumSucceededGetClusterNodeLabelsRetrieved();
-    goodSubCluster.getClusterNodeLabels(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetClusterNodeLabelsRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetClusterNodeLabelsRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getClusterNodeLabels(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetClusterNodeLabelsRetrieved());
-    Assert.assertEquals(225, metrics.getLatencySucceededGetClusterNodeLabelsRetrieved(),
-        ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testClusterNodeLabelsFailed() {
-    long totalBadBefore = metrics.getGetClusterNodeLabelsFailedRetrieved();
-    badSubCluster.getClusterNodeLabels();
-    Assert.assertEquals(totalBadBefore + 1, metrics.getGetClusterNodeLabelsFailedRetrieved());
-  }
-
-  @Test
-  public void testSucceededQueueUserAcls() {
-    long totalGoodBefore = metrics.getNumSucceededGetQueueUserAclsRetrieved();
-    goodSubCluster.getQueueUserAcls(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetQueueUserAclsRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetQueueUserAclsRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getQueueUserAcls(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetQueueUserAclsRetrieved());
-    Assert.assertEquals(225, metrics.getLatencySucceededGetQueueUserAclsRetrieved(),
-        ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testQueueUserAclsFailed() {
-    long totalBadBefore = metrics.getQueueUserAclsFailedRetrieved();
-    badSubCluster.getQueueUserAcls();
-    Assert.assertEquals(totalBadBefore + 1, metrics.getQueueUserAclsFailedRetrieved());
-  }
-  @Test
-  public void testSucceededListReservations() {
-    long totalGoodBefore = metrics.getNumSucceededListReservationsRetrieved();
-    goodSubCluster.getListReservations(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededListReservationsRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededListReservationsRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getListReservations(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededListReservationsRetrieved());
-    Assert.assertEquals(225, metrics.getLatencySucceededListReservationsRetrieved(),
-        ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testListReservationsFailed() {
-    long totalBadBefore = metrics.getListReservationsFailedRetrieved();
-    badSubCluster.getListReservations();
-    Assert.assertEquals(totalBadBefore + 1, metrics.getListReservationsFailedRetrieved());
-  }
-
-  @Test
-  public void testSucceededGetApplicationAttempts() {
-    long totalGoodBefore = metrics.getNumSucceededAppAttemptsRetrieved();
-    goodSubCluster.getApplicationAttempts(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededAppAttemptsRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededAppAttemptRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getApplicationAttempts(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededAppAttemptsRetrieved());
-    Assert.assertEquals(225, metrics.getLatencySucceededAppAttemptRetrieved(),
-        ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetApplicationAttemptsFailed() {
-    long totalBadBefore = metrics.getAppAttemptsFailedRetrieved();
-    badSubCluster.getApplicationAttempts();
-    Assert.assertEquals(totalBadBefore + 1, metrics.getAppAttemptsFailedRetrieved());
-  }
-
-  @Test
-  public void testSucceededGetContainerReport() {
-    long totalGoodBefore = metrics.getNumSucceededGetContainerReportRetrieved();
-    goodSubCluster.getContainerReport(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetContainerReportRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetContainerReportRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getContainerReport(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetContainerReportRetrieved());
-    Assert.assertEquals(225, metrics.getLatencySucceededGetContainerReportRetrieved(),
-        ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetContainerReportFailed() {
-    long totalBadBefore = metrics.getContainerReportFailedRetrieved();
-    badSubCluster.getContainerReport();
-    Assert.assertEquals(totalBadBefore + 1, metrics.getContainerReportFailedRetrieved());
-  }
-
-  @Test
-  public void testSucceededGetContainers() {
-    long totalGoodBefore = metrics.getNumSucceededGetContainersRetrieved();
-    goodSubCluster.getContainers(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetContainersRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetContainersRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getContainers(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetContainersRetrieved());
-    Assert.assertEquals(225, metrics.getLatencySucceededGetContainersRetrieved(),
-        ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetContainersFailed() {
-    long totalBadBefore = metrics.getContainersFailedRetrieved();
-    badSubCluster.getContainers();
-    Assert.assertEquals(totalBadBefore + 1, metrics.getContainersFailedRetrieved());
-  }
-
-  @Test
-  public void testSucceededGetResourceTypeInfo() {
-    long totalGoodBefore = metrics.getNumSucceededGetResourceTypeInfoRetrieved();
-    goodSubCluster.getResourceTypeInfo(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetResourceTypeInfoRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetResourceTypeInfoRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getResourceTypeInfo(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetResourceTypeInfoRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetResourceTypeInfoRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetResourceTypeInfoFailed() {
-    long totalBadBefore = metrics.getGetResourceTypeInfoRetrieved();
-    badSubCluster.getResourceTypeInfo();
-    Assert.assertEquals(totalBadBefore + 1, metrics.getGetResourceTypeInfoRetrieved());
-  }
-
-  @Test
-  public void testSucceededFailApplicationAttempt() {
-    long totalGoodBefore = metrics.getNumSucceededFailAppAttemptRetrieved();
-    goodSubCluster.getFailApplicationAttempt(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededFailAppAttemptRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededFailAppAttemptRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getFailApplicationAttempt(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededFailAppAttemptRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededFailAppAttemptRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testFailApplicationAttemptFailed() {
-    long totalBadBefore = metrics.getFailApplicationAttemptFailedRetrieved();
-    badSubCluster.getFailApplicationAttempt();
-    Assert.assertEquals(totalBadBefore + 1, metrics.getFailApplicationAttemptFailedRetrieved());
-  }
-
-  @Test
-  public void testSucceededUpdateApplicationPriority() {
-    long totalGoodBefore = metrics.getNumSucceededUpdateAppPriorityRetrieved();
-    goodSubCluster.getUpdateApplicationPriority(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededUpdateAppPriorityRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededUpdateAppPriorityRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getUpdateApplicationPriority(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededUpdateAppPriorityRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededUpdateAppPriorityRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testUpdateApplicationPriorityFailed() {
-    long totalBadBefore = metrics.getUpdateApplicationPriorityFailedRetrieved();
-    badSubCluster.getUpdateApplicationPriority();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getUpdateApplicationPriorityFailedRetrieved());
-  }
-
-  @Test
-  public void testSucceededUpdateAppTimeoutsRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededUpdateAppTimeoutsRetrieved();
-    goodSubCluster.getUpdateApplicationTimeouts(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededUpdateAppTimeoutsRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededUpdateAppTimeoutsRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getUpdateApplicationTimeouts(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededUpdateAppTimeoutsRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededUpdateAppTimeoutsRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testUpdateAppTimeoutsFailed() {
-    long totalBadBefore = metrics.getUpdateApplicationTimeoutsFailedRetrieved();
-    badSubCluster.getUpdateApplicationTimeouts();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getUpdateApplicationTimeoutsFailedRetrieved());
-  }
-
-  @Test
-  public void testSucceededSignalToContainerRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededSignalToContainerRetrieved();
-    goodSubCluster.getSignalToContainerTimeouts(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededSignalToContainerRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededSignalToContainerRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getSignalToContainerTimeouts(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededSignalToContainerRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededSignalToContainerRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testSignalToContainerFailed() {
-    long totalBadBefore = metrics.getSignalToContainerFailedRetrieved();
-    badSubCluster.getSignalContainer();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getSignalToContainerFailedRetrieved());
-  }
-
-  @Test
-  public void testSucceededGetQueueInfoRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetQueueInfoRetrieved();
-    goodSubCluster.getQueueInfoRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetQueueInfoRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetQueueInfoRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getQueueInfoRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetQueueInfoRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetQueueInfoRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetQueueInfoFailed() {
-    long totalBadBefore = metrics.getQueueInfoFailedRetrieved();
-    badSubCluster.getQueueInfo();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getQueueInfoFailedRetrieved());
-  }
-
-  @Test
-  public void testSucceededMoveApplicationAcrossQueuesRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededMoveApplicationAcrossQueuesRetrieved();
-    goodSubCluster.moveApplicationAcrossQueuesRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededMoveApplicationAcrossQueuesRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededMoveApplicationAcrossQueuesRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.moveApplicationAcrossQueuesRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededMoveApplicationAcrossQueuesRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededMoveApplicationAcrossQueuesRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testMoveApplicationAcrossQueuesRetrievedFailed() {
-    long totalBadBefore = metrics.getMoveApplicationAcrossQueuesFailedRetrieved();
-    badSubCluster.moveApplicationAcrossQueuesFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getMoveApplicationAcrossQueuesFailedRetrieved());
-  }
-
-  @Test
-  public void testSucceededGetResourceProfilesRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetResourceProfilesRetrieved();
-    goodSubCluster.getResourceProfilesRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetResourceProfilesRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetResourceProfilesRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getResourceProfilesRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetResourceProfilesRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetResourceProfilesRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetResourceProfilesRetrievedFailed() {
-    long totalBadBefore = metrics.getResourceProfilesFailedRetrieved();
-    badSubCluster.getResourceProfilesFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getResourceProfilesFailedRetrieved());
-  }
-
-  @Test
-  public void testSucceededGetResourceProfileRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetResourceProfileRetrieved();
-    goodSubCluster.getResourceProfileRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetResourceProfileRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetResourceProfileRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getResourceProfileRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetResourceProfileRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetResourceProfileRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetResourceProfileRetrievedFailed() {
-    long totalBadBefore = metrics.getResourceProfileFailedRetrieved();
-    badSubCluster.getResourceProfileFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getResourceProfileFailedRetrieved());
-  }
-
-  @Test
-  public void testSucceededGetAttributesToNodesRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetAttributesToNodesRetrieved();
-    goodSubCluster.getAttributesToNodesRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetAttributesToNodesRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetAttributesToNodesRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getAttributesToNodesRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetAttributesToNodesRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetAttributesToNodesRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetAttributesToNodesRetrievedFailed() {
-    long totalBadBefore = metrics.getAttributesToNodesFailedRetrieved();
-    badSubCluster.getAttributesToNodesFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getAttributesToNodesFailedRetrieved());
-  }
-
-  @Test
-  public void testGetClusterNodeAttributesRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetClusterNodeAttributesRetrieved();
-    goodSubCluster.getClusterNodeAttributesRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetClusterNodeAttributesRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetClusterNodeAttributesRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getClusterNodeAttributesRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetClusterNodeAttributesRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetClusterNodeAttributesRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetClusterNodeAttributesRetrievedFailed() {
-    long totalBadBefore = metrics.getClusterNodeAttributesFailedRetrieved();
-    badSubCluster.getClusterNodeAttributesFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getClusterNodeAttributesFailedRetrieved());
-  }
-
-  @Test
-  public void testGetNodesToAttributesRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetNodesToAttributesRetrieved();
-    goodSubCluster.getNodesToAttributesRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetNodesToAttributesRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetNodesToAttributesRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getNodesToAttributesRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetNodesToAttributesRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetNodesToAttributesRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetNodesToAttributesRetrievedFailed() {
-    long totalBadBefore = metrics.getNodesToAttributesFailedRetrieved();
-    badSubCluster.getNodesToAttributesFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getNodesToAttributesFailedRetrieved());
-  }
-
-  @Test
-  public void testGetNewReservationRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetNewReservationRetrieved();
-    goodSubCluster.getNewReservationRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetNewReservationRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetNewReservationRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getNewReservationRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetNewReservationRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetNewReservationRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetNewReservationRetrievedFailed() {
-    long totalBadBefore = metrics.getNewReservationFailedRetrieved();
-    badSubCluster.getNewReservationFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getNewReservationFailedRetrieved());
-  }
-
-  @Test
-  public void testGetSubmitReservationRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededSubmitReservationRetrieved();
-    goodSubCluster.getSubmitReservationRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededSubmitReservationRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededSubmitReservationRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getSubmitReservationRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededSubmitReservationRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededSubmitReservationRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetSubmitReservationRetrievedFailed() {
-    long totalBadBefore = metrics.getSubmitReservationFailedRetrieved();
-    badSubCluster.getSubmitReservationFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getSubmitReservationFailedRetrieved());
-  }
-
-  @Test
-  public void testGetUpdateReservationRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededUpdateReservationRetrieved();
-    goodSubCluster.getUpdateReservationRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededUpdateReservationRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededUpdateReservationRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getUpdateReservationRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededUpdateReservationRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededUpdateReservationRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetUpdateReservationRetrievedFailed() {
-    long totalBadBefore = metrics.getUpdateReservationFailedRetrieved();
-    badSubCluster.getUpdateReservationFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getUpdateReservationFailedRetrieved());
-  }
-
-  @Test
-  public void testGetDeleteReservationRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededDeleteReservationRetrieved();
-    goodSubCluster.getDeleteReservationRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededDeleteReservationRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededDeleteReservationRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getDeleteReservationRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededDeleteReservationRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededDeleteReservationRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetDeleteReservationRetrievedFailed() {
-    long totalBadBefore = metrics.getDeleteReservationFailedRetrieved();
-    badSubCluster.getDeleteReservationFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getDeleteReservationFailedRetrieved());
-  }
-
-  @Test
-  public void testGetListReservationRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededListReservationRetrieved();
-    goodSubCluster.getListReservationRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededListReservationRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededListReservationRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getListReservationRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededListReservationRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededListReservationRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetListReservationRetrievedFailed() {
-    long totalBadBefore = metrics.getListReservationFailedRetrieved();
-    badSubCluster.getListReservationFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getListReservationFailedRetrieved());
-  }
-
-  @Test
-  public void testGetAppActivitiesRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetAppActivitiesRetrieved();
-    goodSubCluster.getAppActivitiesRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetAppActivitiesRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetAppActivitiesRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getAppActivitiesRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetAppActivitiesRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetAppActivitiesRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetAppActivitiesRetrievedFailed() {
-    long totalBadBefore = metrics.getAppActivitiesFailedRetrieved();
-    badSubCluster.getAppActivitiesFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getAppActivitiesFailedRetrieved());
-  }
-
-  @Test
-  public void testGetAppStatisticsLatencyRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetAppStatisticsRetrieved();
-    goodSubCluster.getAppStatisticsRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetAppStatisticsRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetAppStatisticsRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getAppStatisticsRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetAppStatisticsRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetAppStatisticsRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetAppStatisticsRetrievedFailed() {
-    long totalBadBefore = metrics.getAppStatisticsFailedRetrieved();
-    badSubCluster.getAppStatisticsFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getAppStatisticsFailedRetrieved());
-  }
-
-  @Test
-  public void testGetAppPriorityLatencyRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetAppPriorityRetrieved();
-    goodSubCluster.getAppPriorityRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetAppPriorityRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetAppPriorityRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getAppPriorityRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetAppPriorityRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetAppPriorityRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetAppPriorityRetrievedFailed() {
-    long totalBadBefore = metrics.getAppPriorityFailedRetrieved();
-    badSubCluster.getAppPriorityFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getAppPriorityFailedRetrieved());
-  }
-
-  @Test
-  public void testGetAppQueueLatencyRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetAppQueueRetrieved();
-    goodSubCluster.getAppQueueRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetAppQueueRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetAppQueueRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getAppQueueRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetAppQueueRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetAppQueueRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetAppQueueRetrievedFailed() {
-    long totalBadBefore = metrics.getAppQueueFailedRetrieved();
-    badSubCluster.getAppQueueFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getAppQueueFailedRetrieved());
-  }
-
-  @Test
-  public void testUpdateAppQueueLatencyRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededUpdateAppQueueRetrieved();
-    goodSubCluster.getUpdateQueueRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededUpdateAppQueueRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededUpdateAppQueueRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getUpdateQueueRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededUpdateAppQueueRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededUpdateAppQueueRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testUpdateAppQueueRetrievedFailed() {
-    long totalBadBefore = metrics.getUpdateAppQueueFailedRetrieved();
-    badSubCluster.getUpdateQueueFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getUpdateAppQueueFailedRetrieved());
-  }
-
-  @Test
-  public void testGetAppTimeoutLatencyRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetAppTimeoutRetrieved();
-    goodSubCluster.getAppTimeoutRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetAppTimeoutRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetAppTimeoutRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getAppTimeoutRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetAppTimeoutRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetAppTimeoutRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetAppTimeoutRetrievedFailed() {
-    long totalBadBefore = metrics.getAppTimeoutFailedRetrieved();
-    badSubCluster.getAppTimeoutFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getAppTimeoutFailedRetrieved());
-  }
-
-  @Test
-  public void testGetAppTimeoutsLatencyRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetAppTimeoutsRetrieved();
-    goodSubCluster.getAppTimeoutsRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetAppTimeoutsRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetAppTimeoutsRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getAppTimeoutsRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetAppTimeoutsRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetAppTimeoutsRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetAppTimeoutsRetrievedFailed() {
-    long totalBadBefore = metrics.getAppTimeoutsFailedRetrieved();
-    badSubCluster.getAppTimeoutsFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getAppTimeoutsFailedRetrieved());
-  }
-
-  @Test
-  public void testGetRMNodeLabelsRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetRMNodeLabelsRetrieved();
-    goodSubCluster.getRMNodeLabelsRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetRMNodeLabelsRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetRMNodeLabelsRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getRMNodeLabelsRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetRMNodeLabelsRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetRMNodeLabelsRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetRMNodeLabelsRetrievedFailed() {
-    long totalBadBefore = metrics.getRMNodeLabelsFailedRetrieved();
-    badSubCluster.getRMNodeLabelsFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getRMNodeLabelsFailedRetrieved());
-  }
-
-  @Test
-  public void testCheckUserAccessToQueueRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededCheckUserAccessToQueueRetrieved();
-    goodSubCluster.getCheckUserAccessToQueueRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededCheckUserAccessToQueueRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededCheckUserAccessToQueueRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getCheckUserAccessToQueueRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededCheckUserAccessToQueueRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededCheckUserAccessToQueueRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testCheckUserAccessToQueueRetrievedFailed() {
-    long totalBadBefore = metrics.getCheckUserAccessToQueueFailedRetrieved();
-    badSubCluster.getCheckUserAccessToQueueFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getCheckUserAccessToQueueFailedRetrieved());
-  }
-
-  @Test
-  public void testGetDelegationTokenRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetDelegationTokenRetrieved();
-    goodSubCluster.getGetDelegationTokenRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetDelegationTokenRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetDelegationTokenRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getGetDelegationTokenRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetDelegationTokenRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetDelegationTokenRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetDelegationTokenRetrievedFailed() {
-    long totalBadBefore = metrics.getDelegationTokenFailedRetrieved();
-    badSubCluster.getDelegationTokenFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getDelegationTokenFailedRetrieved());
-  }
-
-  @Test
-  public void testRenewDelegationTokenRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededRenewDelegationTokenRetrieved();
-    goodSubCluster.getRenewDelegationTokenRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededRenewDelegationTokenRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededRenewDelegationTokenRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getRenewDelegationTokenRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededRenewDelegationTokenRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededRenewDelegationTokenRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testRenewDelegationTokenRetrievedFailed() {
-    long totalBadBefore = metrics.getRenewDelegationTokenFailedRetrieved();
-    badSubCluster.getRenewDelegationTokenFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getRenewDelegationTokenFailedRetrieved());
-  }
-
-  @Test
-  public void testRefreshAdminAclsRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededRefreshAdminAclsRetrieved();
-    goodSubCluster.getRefreshAdminAclsRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededRefreshAdminAclsRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededRefreshAdminAclsRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getRefreshAdminAclsRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededRefreshAdminAclsRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededRefreshAdminAclsRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testRefreshAdminAclsRetrievedFailed() {
-    long totalBadBefore = metrics.getNumRefreshAdminAclsFailedRetrieved();
-    badSubCluster.getRefreshAdminAclsFailedRetrieved();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getNumRefreshAdminAclsFailedRetrieved());
-  }
-
-  @Test
-  public void testRefreshServiceAclsRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededRefreshServiceAclsRetrieved();
-    goodSubCluster.getRefreshServiceAclsRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededRefreshServiceAclsRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededRefreshServiceAclsRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getRefreshServiceAclsRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededRefreshServiceAclsRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededRefreshServiceAclsRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testRefreshServiceAclsRetrievedFailed() {
-    long totalBadBefore = metrics.getNumRefreshServiceAclsFailedRetrieved();
-    badSubCluster.getRefreshServiceAclsFailedRetrieved();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getNumRefreshServiceAclsFailedRetrieved());
-  }
-
-  @Test
-  public void testReplaceLabelsOnNodesRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededReplaceLabelsOnNodesRetrieved();
-    goodSubCluster.getNumSucceededReplaceLabelsOnNodesRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededReplaceLabelsOnNodesRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededReplaceLabelsOnNodesRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getNumSucceededReplaceLabelsOnNodesRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededReplaceLabelsOnNodesRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededReplaceLabelsOnNodesRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testReplaceLabelsOnNodesRetrievedFailed() {
-    long totalBadBefore = metrics.getNumReplaceLabelsOnNodesFailedRetrieved();
-    badSubCluster.getReplaceLabelsOnNodesFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getNumReplaceLabelsOnNodesFailedRetrieved());
-  }
-
-  @Test
-  public void testReplaceLabelsOnNodeRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededReplaceLabelsOnNodeRetrieved();
-    goodSubCluster.getNumSucceededReplaceLabelsOnNodeRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededReplaceLabelsOnNodeRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededReplaceLabelsOnNodeRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getNumSucceededReplaceLabelsOnNodeRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededReplaceLabelsOnNodeRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededReplaceLabelsOnNodeRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testReplaceLabelOnNodeRetrievedFailed() {
-    long totalBadBefore = metrics.getNumReplaceLabelsOnNodeFailedRetrieved();
-    badSubCluster.getReplaceLabelsOnNodeFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getNumReplaceLabelsOnNodeFailedRetrieved());
-  }
-
-  @Test
-  public void testDumpSchedulerLogsRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededDumpSchedulerLogsRetrieved();
-    goodSubCluster.getDumpSchedulerLogsRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededDumpSchedulerLogsRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededDumpSchedulerLogsRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getDumpSchedulerLogsRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededDumpSchedulerLogsRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededDumpSchedulerLogsRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testDumpSchedulerLogsRetrievedFailed() {
-    long totalBadBefore = metrics.getDumpSchedulerLogsFailedRetrieved();
-    badSubCluster.getDumpSchedulerLogsFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getDumpSchedulerLogsFailedRetrieved());
-  }
-
-  @Test
-  public void testGetActivitiesRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetActivitiesRetrieved();
-    goodSubCluster.getActivitiesRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetActivitiesRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetActivitiesRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getActivitiesRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetActivitiesRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetActivitiesRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetActivitiesRetrievedFailed() {
-    long totalBadBefore = metrics.getActivitiesFailedRetrieved();
-    badSubCluster.getActivitiesFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getActivitiesFailedRetrieved());
-  }
-
-  @Test
-  public void testGetBulkActivitiesRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetBulkActivitiesRetrieved();
-    goodSubCluster.getBulkActivitiesRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetBulkActivitiesRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetBulkActivitiesRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getBulkActivitiesRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetBulkActivitiesRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetBulkActivitiesRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetBulkActivitiesRetrievedFailed() {
-    long totalBadBefore = metrics.getBulkActivitiesFailedRetrieved();
-    badSubCluster.getBulkActivitiesFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getBulkActivitiesFailedRetrieved());
-  }
-
-  @Test
-  public void testDeregisterSubClusterRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededDeregisterSubClusterRetrieved();
-    goodSubCluster.getDeregisterSubClusterRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededDeregisterSubClusterRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededDeregisterSubClusterRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getDeregisterSubClusterRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededDeregisterSubClusterRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededDeregisterSubClusterRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testDeregisterSubClusterRetrievedFailed() {
-    long totalBadBefore = metrics.getDeregisterSubClusterFailedRetrieved();
-    badSubCluster.getDeregisterSubClusterFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getDeregisterSubClusterFailedRetrieved());
-  }
-
-  @Test
-  public void testAddToClusterNodeLabelsRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededAddToClusterNodeLabelsRetrieved();
-    goodSubCluster.addToClusterNodeLabelsRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededAddToClusterNodeLabelsRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededAddToClusterNodeLabelsRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.addToClusterNodeLabelsRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededAddToClusterNodeLabelsRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededAddToClusterNodeLabelsRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetSchedulerConfigurationRetrievedFailed() {
-    long totalBadBefore = metrics.getSchedulerConfigurationFailedRetrieved();
-    badSubCluster.getSchedulerConfigurationFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getSchedulerConfigurationFailedRetrieved());
-  }
-
-  @Test
-  public void testGetSchedulerConfigurationRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetSchedulerConfigurationRetrieved();
-    goodSubCluster.getSchedulerConfigurationRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetSchedulerConfigurationRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetSchedulerConfigurationRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getSchedulerConfigurationRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetSchedulerConfigurationRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetSchedulerConfigurationRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testUpdateSchedulerConfigurationRetrievedFailed() {
-    long totalBadBefore = metrics.getUpdateSchedulerConfigurationFailedRetrieved();
-    badSubCluster.updateSchedulerConfigurationFailedRetrieved();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getUpdateSchedulerConfigurationFailedRetrieved());
-  }
-
-  @Test
-  public void testUpdateSchedulerConfigurationRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededUpdateSchedulerConfigurationRetrieved();
-    goodSubCluster.getUpdateSchedulerConfigurationRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededUpdateSchedulerConfigurationRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededUpdateSchedulerConfigurationRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getUpdateSchedulerConfigurationRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededUpdateSchedulerConfigurationRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededUpdateSchedulerConfigurationRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetClusterInfoRetrievedFailed() {
-    long totalBadBefore = metrics.getClusterInfoFailedRetrieved();
-    badSubCluster.getClusterInfoFailed();
-    Assert.assertEquals(totalBadBefore + 1, metrics.getClusterInfoFailedRetrieved());
-  }
-
-  @Test
-  public void testGetClusterInfoRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetClusterInfoRetrieved();
-    goodSubCluster.getClusterInfoRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetClusterInfoRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetClusterInfoRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getClusterInfoRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetClusterInfoRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetClusterInfoRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetClusterUserInfoRetrievedFailed() {
-    long totalBadBefore = metrics.getClusterUserInfoFailedRetrieved();
-    badSubCluster.getClusterUserInfoFailed();
-    Assert.assertEquals(totalBadBefore + 1, metrics.getClusterUserInfoFailedRetrieved());
-  }
-
-  @Test
-  public void testGetClusterUserInfoRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetClusterUserInfoRetrieved();
-    goodSubCluster.getClusterUserInfoRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetClusterUserInfoRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetClusterUserInfoRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getClusterUserInfoRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetClusterUserInfoRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetClusterUserInfoRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testUpdateNodeResourceRetrievedFailed() {
-    long totalBadBefore = metrics.getUpdateNodeResourceFailedRetrieved();
-    badSubCluster.getUpdateNodeResourceFailed();
-    Assert.assertEquals(totalBadBefore + 1, metrics.getUpdateNodeResourceFailedRetrieved());
-  }
-
-  @Test
-  public void testUpdateNodeResourceRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetClusterUserInfoRetrieved();
-    goodSubCluster.getUpdateNodeResourceRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededUpdateNodeResourceRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededUpdateNodeResourceRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getUpdateNodeResourceRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededUpdateNodeResourceRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededUpdateNodeResourceRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testRefreshNodesResourcesRetrievedFailed() {
-    long totalBadBefore = metrics.getRefreshNodesResourcesFailedRetrieved();
-    badSubCluster.getRefreshNodesResourcesFailed();
-    Assert.assertEquals(totalBadBefore + 1, metrics.getRefreshNodesResourcesFailedRetrieved());
-  }
-
-  @Test
-  public void testRefreshNodesResourcesRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededRefreshNodesResourcesRetrieved();
-    goodSubCluster.getRefreshNodesResourcesRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededRefreshNodesResourcesRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededRefreshNodesResourcesRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getRefreshNodesResourcesRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededRefreshNodesResourcesRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededRefreshNodesResourcesRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testCheckForDecommissioningNodesFailedRetrieved() {
-    long totalBadBefore = metrics.getCheckForDecommissioningNodesFailedRetrieved();
-    badSubCluster.getCheckForDecommissioningNodesFailed();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getCheckForDecommissioningNodesFailedRetrieved());
-  }
-
-  @Test
-  public void testCheckForDecommissioningNodesRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededCheckForDecommissioningNodesRetrieved();
-    goodSubCluster.getCheckForDecommissioningNodesRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededCheckForDecommissioningNodesRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededCheckForDecommissioningNodesRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getCheckForDecommissioningNodesRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededCheckForDecommissioningNodesRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededCheckForDecommissioningNodesRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testRefreshClusterMaxPriorityFailedRetrieved() {
-    long totalBadBefore = metrics.getRefreshClusterMaxPriorityFailedRetrieved();
-    badSubCluster.getRefreshClusterMaxPriorityFailed();
-    Assert.assertEquals(totalBadBefore + 1, metrics.getRefreshClusterMaxPriorityFailedRetrieved());
-  }
-
-  @Test
-  public void testRefreshClusterMaxPriorityRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededRefreshClusterMaxPriorityRetrieved();
-    goodSubCluster.getRefreshClusterMaxPriorityRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededRefreshClusterMaxPriorityRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededRefreshClusterMaxPriorityRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getRefreshClusterMaxPriorityRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededRefreshClusterMaxPriorityRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededRefreshClusterMaxPriorityRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetMapAttributesToNodesFailedRetrieved() {
-    long totalBadBefore = metrics.getMapAttributesToNodesFailedRetrieved();
-    badSubCluster.getMapAttributesToNodesFailed();
-    Assert.assertEquals(totalBadBefore + 1, metrics.getMapAttributesToNodesFailedRetrieved());
-  }
-
-  @Test
-  public void testGetMapAttributesToNodesRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededMapAttributesToNodesRetrieved();
-    goodSubCluster.getMapAttributesToNodesRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededMapAttributesToNodesRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededMapAttributesToNodesRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getMapAttributesToNodesRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededMapAttributesToNodesRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededMapAttributesToNodesRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetGroupsForUserFailedRetrieved() {
-    long totalBadBefore = metrics.getGroupsForUserFailedRetrieved();
-    badSubCluster.getGroupsForUserFailed();
-    Assert.assertEquals(totalBadBefore + 1, metrics.getGroupsForUserFailedRetrieved());
-  }
-
-  @Test
-  public void testGetGroupsForUserRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetGroupsForUsersRetrieved();
-    goodSubCluster.getGroupsForUsersRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetGroupsForUsersRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetGroupsForUsersRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getGroupsForUsersRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetGroupsForUsersRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetGroupsForUsersRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testSaveFederationQueuePolicyFailedRetrieved() {
-    long totalBadBefore = metrics.getSaveFederationQueuePolicyFailedRetrieved();
-    badSubCluster.getSaveFederationQueuePolicyFailedRetrieved();
-    Assert.assertEquals(totalBadBefore + 1, metrics.getSaveFederationQueuePolicyFailedRetrieved());
-  }
-
-  @Test
-  public void testSaveFederationQueuePolicyRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededSaveFederationQueuePolicyRetrieved();
-    goodSubCluster.getSaveFederationQueuePolicyRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededSaveFederationQueuePolicyRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededSaveFederationQueuePolicyRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getSaveFederationQueuePolicyRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededSaveFederationQueuePolicyRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededSaveFederationQueuePolicyRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetBatchSaveFederationQueuePoliciesFailedRetrieved() {
-    long totalBadBefore = metrics.getBatchSaveFederationQueuePoliciesFailedRetrieved();
-    badSubCluster.getBatchSaveFederationQueuePoliciesFailedRetrieved();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getBatchSaveFederationQueuePoliciesFailedRetrieved());
-  }
-
-  @Test
-  public void testGetBatchSaveFederationQueuePoliciesRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededBatchSaveFederationQueuePoliciesRetrieved();
-    goodSubCluster.getBatchSaveFederationQueuePoliciesRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededBatchSaveFederationQueuePoliciesRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededBatchSaveFederationQueuePoliciesRetrieved(),
-        ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getBatchSaveFederationQueuePoliciesRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededBatchSaveFederationQueuePoliciesRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededBatchSaveFederationQueuePoliciesRetrieved(),
-        ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testListFederationQueuePoliciesFailedRetrieved() {
-    long totalBadBefore = metrics.getListFederationQueuePoliciesFailedRetrieved();
-    badSubCluster.getListFederationQueuePoliciesFailedRetrieved();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getListFederationQueuePoliciesFailedRetrieved());
-  }
-
-  @Test
-  public void testListFederationQueuePoliciesRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededListFederationQueuePoliciesFailedRetrieved();
-    goodSubCluster.getListFederationQueuePoliciesRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededListFederationQueuePoliciesFailedRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededListFederationQueuePoliciesRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getListFederationQueuePoliciesRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededListFederationQueuePoliciesFailedRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededListFederationQueuePoliciesRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testGetFederationSubClustersFailedRetrieved() {
-    long totalBadBefore = metrics.getFederationSubClustersFailedRetrieved();
-    badSubCluster.getFederationSubClustersFailedRetrieved();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getFederationSubClustersFailedRetrieved());
-  }
-
-  @Test
-  public void testGetFederationSubClustersRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededGetFederationSubClustersRetrieved();
-    goodSubCluster.getFederationSubClustersRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededGetFederationSubClustersRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededGetFederationSubClustersRetrieved(), ASSERT_DOUBLE_DELTA);
-    goodSubCluster.getFederationSubClustersRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededGetFederationSubClustersRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededGetFederationSubClustersRetrieved(), ASSERT_DOUBLE_DELTA);
-  }
-
-  @Test
-  public void testDeleteFederationPoliciesByQueuesFailedRetrieved() {
-    long totalBadBefore = metrics.getDeleteFederationPoliciesByQueuesRetrieved();
-    badSubCluster.getDeleteFederationPoliciesByQueuesFailedRetrieved();
-    Assert.assertEquals(totalBadBefore + 1,
-        metrics.getDeleteFederationPoliciesByQueuesRetrieved());
-  }
-
-  @Test
-  public void testDeleteFederationPoliciesByQueuesRetrieved() {
-    long totalGoodBefore = metrics.getNumSucceededDeleteFederationPoliciesByQueuesRetrieved();
-    goodSubCluster.deleteFederationPoliciesByQueuesRetrieved(150);
-    Assert.assertEquals(totalGoodBefore + 1,
-        metrics.getNumSucceededDeleteFederationPoliciesByQueuesRetrieved());
-    Assert.assertEquals(150,
-        metrics.getLatencySucceededDeleteFederationPoliciesByQueuesRetrieved(),
-        ASSERT_DOUBLE_DELTA);
-    goodSubCluster.deleteFederationPoliciesByQueuesRetrieved(300);
-    Assert.assertEquals(totalGoodBefore + 2,
-        metrics.getNumSucceededDeleteFederationPoliciesByQueuesRetrieved());
-    Assert.assertEquals(225,
-        metrics.getLatencySucceededDeleteFederationPoliciesByQueuesRetrieved(),
-        ASSERT_DOUBLE_DELTA);
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouterServerUtil.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouterServerUtil.java
deleted file mode 100644
index dcf3bd5bc0e..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouterServerUtil.java
+++ /dev/null
@@ -1,164 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */package org.apache.hadoop.yarn.server.router;
-
-import org.apache.hadoop.test.LambdaTestUtils;
-import org.apache.hadoop.util.Time;
-import org.apache.hadoop.yarn.api.records.Priority;
-import org.apache.hadoop.yarn.api.records.ReservationDefinition;
-import org.apache.hadoop.yarn.api.records.ReservationId;
-import org.apache.hadoop.yarn.api.records.ReservationRequests;
-import org.apache.hadoop.yarn.api.records.ReservationRequest;
-import org.apache.hadoop.yarn.api.records.Resource;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterIdInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo;
-import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.nio.ByteBuffer;
-import java.nio.charset.StandardCharsets;
-import java.util.List;
-import java.util.Map;
-
-import static org.apache.hadoop.yarn.server.router.webapp.TestFederationInterceptorREST.getReservationSubmissionRequestInfo;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertNotNull;
-
-public class TestRouterServerUtil {
-
-  public static final Logger LOG = LoggerFactory.getLogger(TestRouterServerUtil.class);
-
-  @Test
-  public void testConvertReservationDefinition() {
-    // Prepare parameters
-    ReservationId reservationId = ReservationId.newInstance(Time.now(), 1);
-    ReservationSubmissionRequestInfo requestInfo =
-        getReservationSubmissionRequestInfo(reservationId);
-    ReservationDefinitionInfo expectDefinitionInfo = requestInfo.getReservationDefinition();
-
-    // ReservationDefinitionInfo conversion ReservationDefinition
-    ReservationDefinition convertDefinition =
-        RouterServerUtil.convertReservationDefinition(expectDefinitionInfo);
-
-    // reservationDefinition is not null
-    assertNotNull(convertDefinition);
-    assertEquals(expectDefinitionInfo.getArrival(), convertDefinition.getArrival());
-    assertEquals(expectDefinitionInfo.getDeadline(), convertDefinition.getDeadline());
-
-    Priority priority = convertDefinition.getPriority();
-    assertNotNull(priority);
-    assertEquals(expectDefinitionInfo.getPriority(), priority.getPriority());
-    assertEquals(expectDefinitionInfo.getRecurrenceExpression(),
-        convertDefinition.getRecurrenceExpression());
-    assertEquals(expectDefinitionInfo.getReservationName(), convertDefinition.getReservationName());
-
-    ReservationRequestsInfo expectRequestsInfo = expectDefinitionInfo.getReservationRequests();
-    List<ReservationRequestInfo> expectRequestsInfoList =
-        expectRequestsInfo.getReservationRequest();
-
-    ReservationRequests convertReservationRequests =
-        convertDefinition.getReservationRequests();
-    assertNotNull(convertReservationRequests);
-
-    List<ReservationRequest> convertRequestList =
-        convertReservationRequests.getReservationResources();
-    assertNotNull(convertRequestList);
-    assertEquals(1, convertRequestList.size());
-
-    ReservationRequestInfo expectResRequestInfo = expectRequestsInfoList.get(0);
-    ReservationRequest convertResRequest = convertRequestList.get(0);
-    assertNotNull(convertResRequest);
-    assertEquals(expectResRequestInfo.getNumContainers(), convertResRequest.getNumContainers());
-    assertEquals(expectResRequestInfo.getDuration(), convertResRequest.getDuration());
-
-    ResourceInfo expectResourceInfo = expectResRequestInfo.getCapability();
-    Resource convertResource = convertResRequest.getCapability();
-    assertNotNull(expectResourceInfo);
-    assertEquals(expectResourceInfo.getMemorySize(), convertResource.getMemorySize());
-    assertEquals(expectResourceInfo.getvCores(), convertResource.getVirtualCores());
-  }
-
-  @Test
-  public void testConvertReservationDefinitionEmpty() throws Exception {
-
-    // param ReservationDefinitionInfo is Null
-    ReservationDefinitionInfo definitionInfo = null;
-
-    // null request1
-    LambdaTestUtils.intercept(RuntimeException.class,
-        "definitionInfo Or ReservationRequests is Null.",
-        () -> RouterServerUtil.convertReservationDefinition(definitionInfo));
-
-    // param ReservationRequests is Null
-    ReservationDefinitionInfo definitionInfo2 = new ReservationDefinitionInfo();
-
-    // null request2
-    LambdaTestUtils.intercept(RuntimeException.class,
-        "definitionInfo Or ReservationRequests is Null.",
-        () -> RouterServerUtil.convertReservationDefinition(definitionInfo2));
-
-    // param ReservationRequests is Null
-    ReservationDefinitionInfo definitionInfo3 = new ReservationDefinitionInfo();
-    ReservationRequestsInfo requestsInfo = new ReservationRequestsInfo();
-    definitionInfo3.setReservationRequests(requestsInfo);
-
-    // null request3
-    LambdaTestUtils.intercept(RuntimeException.class,
-        "definitionInfo Or ReservationRequests is Null.",
-        () -> RouterServerUtil.convertReservationDefinition(definitionInfo3));
-  }
-
-  @Test
-  public void testLoadFederationPolicyManager() throws Exception {
-
-    // In this unit test, we have configured the yarn-site.xml file with
-    // the yarn.federation.policy-manager-params parameter,
-    // and subsequently, we parse this parameter.
-    // We have configured two subclusters, SC-1 and SC-2,
-    // with routerPolicyWeights set to SC-1:0.7 and SC-2:0.3,
-    // and amrmPolicyWeights set to SC-1:0.6 and SC-2:0.4.
-    // Additionally, headroomAlpha is set to 1.0.
-
-    YarnConfiguration conf = new YarnConfiguration();
-    String defaultPolicyParamString = conf.get(YarnConfiguration.FEDERATION_POLICY_MANAGER_PARAMS,
-        YarnConfiguration.DEFAULT_FEDERATION_POLICY_MANAGER_PARAMS);
-    assertNotNull(defaultPolicyParamString);
-    ByteBuffer defaultPolicyParam = ByteBuffer.wrap(
-        defaultPolicyParamString.getBytes(StandardCharsets.UTF_8));
-    WeightedPolicyInfo policyInfo = WeightedPolicyInfo.fromByteBuffer(defaultPolicyParam);
-    float headroomAlpha = policyInfo.getHeadroomAlpha();
-    Map<SubClusterIdInfo, Float> routerPolicyWeights = policyInfo.getRouterPolicyWeights();
-    Map<SubClusterIdInfo, Float> amrmPolicyWeights = policyInfo.getAMRMPolicyWeights();
-
-    SubClusterIdInfo sc1 = new SubClusterIdInfo("SC-1");
-    SubClusterIdInfo sc2 = new SubClusterIdInfo("SC-2");
-
-    assertEquals(1.0, headroomAlpha, 0.001);
-    assertEquals(0.7, routerPolicyWeights.get(sc1), 0.001);
-    assertEquals(0.3, routerPolicyWeights.get(sc2), 0.001);
-
-    assertEquals(0.6, amrmPolicyWeights.get(sc1), 0.001);
-    assertEquals(0.4, amrmPolicyWeights.get(sc2), 0.001);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouterStoreCommands.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouterStoreCommands.java
deleted file mode 100644
index 04007ca88df..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/TestRouterStoreCommands.java
+++ /dev/null
@@ -1,77 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.test.LambdaTestUtils;
-import org.apache.hadoop.util.Time;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore;
-import org.apache.hadoop.yarn.server.federation.store.records.AddApplicationHomeSubClusterRequest;
-import org.apache.hadoop.yarn.server.federation.store.records.GetApplicationHomeSubClusterRequest;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.junit.Before;
-import org.junit.Test;
-
-public class TestRouterStoreCommands {
-
-  ////////////////////////////////
-  // Router Constants
-  ////////////////////////////////
-  private Configuration conf;
-  private MemoryFederationStateStore stateStore;
-  private FederationStateStoreFacade facade;
-
-  @Before
-  public void setup() throws YarnException {
-    conf = new YarnConfiguration();
-    stateStore = new MemoryFederationStateStore();
-    stateStore.init(conf);
-    facade = FederationStateStoreFacade.getInstance(conf);
-    facade.reinitialize(stateStore, conf);
-  }
-
-  @Test
-  public void testRemoveApplicationFromRouterStateStore() throws Exception {
-
-    // We will design such a unit test.
-    // We will write the applicationId and subCluster into the stateStore,
-    // and then remove the application through Router.removeApplication.
-    // At this time, if we continue to query through the stateStore,
-    // We will get a prompt that application not exists.
-
-    ApplicationId appId = ApplicationId.newInstance(Time.now(), 1);
-    SubClusterId homeSubCluster = SubClusterId.newInstance("SC-1");
-    ApplicationHomeSubCluster applicationHomeSubCluster =
-        ApplicationHomeSubCluster.newInstance(appId, homeSubCluster);
-    AddApplicationHomeSubClusterRequest request =
-        AddApplicationHomeSubClusterRequest.newInstance(applicationHomeSubCluster);
-    stateStore.addApplicationHomeSubCluster(request);
-    Router.removeApplication(conf, appId.toString());
-
-    GetApplicationHomeSubClusterRequest request1 =
-        GetApplicationHomeSubClusterRequest.newInstance(appId);
-
-    LambdaTestUtils.intercept(YarnException.class, "Application " + appId + " does not exist.",
-        () -> stateStore.getApplicationHomeSubCluster(request1));
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/cleaner/TestSubClusterCleaner.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/cleaner/TestSubClusterCleaner.java
deleted file mode 100644
index d24ac9827da..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/cleaner/TestSubClusterCleaner.java
+++ /dev/null
@@ -1,158 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.cleaner;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.util.Time;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterRegisterRequest;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterState;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatRequest;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterHeartbeatResponse;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Test;
-
-import java.util.Map;
-import java.util.concurrent.TimeoutException;
-
-public class TestSubClusterCleaner {
-
-  ////////////////////////////////
-  // Router Constants
-  ////////////////////////////////
-  private Configuration conf;
-  private MemoryFederationStateStore stateStore;
-  private FederationStateStoreFacade facade;
-  private SubClusterCleaner cleaner;
-  private final static int NUM_SUBCLUSTERS = 4;
-  private final static long EXPIRATION_TIME = Time.now() - 5000;
-
-  @Before
-  public void setup() throws YarnException {
-    conf = new YarnConfiguration();
-    conf.setLong(YarnConfiguration.ROUTER_SUBCLUSTER_EXPIRATION_TIME, 1000);
-    conf.setInt(YarnConfiguration.FEDERATION_CACHE_TIME_TO_LIVE_SECS, 0);
-
-    stateStore = new MemoryFederationStateStore();
-    stateStore.init(conf);
-
-    facade = FederationStateStoreFacade.getInstance(conf);
-    facade.reinitialize(stateStore, conf);
-
-    cleaner = new SubClusterCleaner(conf);
-    for (int i = 0; i < NUM_SUBCLUSTERS; i++){
-      // Create sub cluster id and info
-      SubClusterId subClusterId = SubClusterId.newInstance("SC-" + i);
-      SubClusterInfo subClusterInfo = SubClusterInfo.newInstance(subClusterId,
-          "127.0.0.1:1", "127.0.0.1:2", "127.0.0.1:3", "127.0.0.1:4",
-           SubClusterState.SC_RUNNING, Time.now(), "");
-      // Register the subCluster
-      stateStore.registerSubCluster(
-          SubClusterRegisterRequest.newInstance(subClusterInfo));
-    }
-  }
-
-  @Test
-  public void testSubClustersWithOutHeartBeat()
-      throws InterruptedException, TimeoutException, YarnException {
-
-    // We set up such a unit test, We set the status of all subClusters to RUNNING,
-    // and Manually set subCluster heartbeat expiration.
-    // At this time, the size of the Active SubCluster is 0.
-    Map<SubClusterId, SubClusterInfo> subClustersMap = facade.getSubClusters(false);
-
-    // Step1. Manually set subCluster heartbeat expiration.
-    // subCluster has no heartbeat, and all subClusters will expire.
-    subClustersMap.keySet().forEach(subClusterId ->
-        stateStore.setExpiredHeartbeat(subClusterId, EXPIRATION_TIME));
-
-    // Step2. Run the Cleaner to change the status of the expired SubCluster to SC_LOST.
-    cleaner.run();
-
-    // Step3. All clusters have expired,
-    // so the current Federation has no active subClusters.
-    int count = facade.getActiveSubClustersCount();
-    Assert.assertEquals(0, count);
-
-    // Step4. Check Active SubCluster Status.
-    // We want all subClusters to be SC_LOST.
-    subClustersMap.values().forEach(subClusterInfo -> {
-      SubClusterState subClusterState = subClusterInfo.getState();
-      Assert.assertEquals(SubClusterState.SC_LOST, subClusterState);
-    });
-  }
-
-  @Test
-  public void testSubClustersPartWithHeartBeat() throws YarnException, InterruptedException {
-
-    // Step1. Manually set subCluster heartbeat expiration.
-    for (int i = 0; i < NUM_SUBCLUSTERS; i++) {
-      // Create subCluster id and info.
-      expiredSubcluster("SC-" + i);
-    }
-
-    // Step2. Run the Cleaner to change the status of the expired SubCluster to SC_LOST.
-    cleaner.run();
-
-    // Step3. Let SC-0, SC-1 resume heartbeat.
-    resumeSubClusterHeartbeat("SC-0");
-    resumeSubClusterHeartbeat("SC-1");
-
-    // Step4. At this point we should have 2 subClusters that are surviving clusters.
-    int count = facade.getActiveSubClustersCount();
-    Assert.assertEquals(2, count);
-
-    // Step5. The result we expect is that SC-0 and SC-1 are in the RUNNING state,
-    // and SC-2 and SC-3 are in the SC_LOST state.
-    checkSubClusterState("SC-0", SubClusterState.SC_RUNNING);
-    checkSubClusterState("SC-1", SubClusterState.SC_RUNNING);
-    checkSubClusterState("SC-2", SubClusterState.SC_LOST);
-    checkSubClusterState("SC-3", SubClusterState.SC_LOST);
-  }
-
-  private void resumeSubClusterHeartbeat(String pSubClusterId)
-      throws YarnException {
-    SubClusterId subClusterId = SubClusterId.newInstance(pSubClusterId);
-    SubClusterHeartbeatRequest request = SubClusterHeartbeatRequest.newInstance(
-        subClusterId, Time.now(), SubClusterState.SC_RUNNING, "test");
-    SubClusterHeartbeatResponse response = stateStore.subClusterHeartbeat(request);
-    Assert.assertNotNull(response);
-  }
-
-  private void expiredSubcluster(String pSubClusterId) {
-    SubClusterId subClusterId = SubClusterId.newInstance(pSubClusterId);
-    stateStore.setExpiredHeartbeat(subClusterId, EXPIRATION_TIME);
-  }
-
-  private void checkSubClusterState(String pSubClusterId, SubClusterState expectState)
-      throws YarnException {
-    Map<SubClusterId, SubClusterInfo> subClustersMap = facade.getSubClusters(false);
-    SubClusterId subClusterId = SubClusterId.newInstance(pSubClusterId);
-    SubClusterInfo subClusterInfo = subClustersMap.get(subClusterId);
-    if (subClusterInfo == null) {
-      throw new YarnException("subClusterId=" + pSubClusterId + " does not exist.");
-    }
-    Assert.assertEquals(expectState, subClusterInfo.getState());
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/BaseRouterClientRMTest.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/BaseRouterClientRMTest.java
deleted file mode 100644
index 905b60f31ee..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/BaseRouterClientRMTest.java
+++ /dev/null
@@ -1,609 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import static org.mockito.Mockito.mock;
-
-import java.io.IOException;
-import java.security.PrivilegedExceptionAction;
-import java.util.Collections;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.yarn.MockApps;
-import org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainersResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.KillApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationResponse;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;
-import org.apache.hadoop.yarn.api.records.Priority;
-import org.apache.hadoop.yarn.api.records.ReservationDefinition;
-import org.apache.hadoop.yarn.api.records.ReservationId;
-import org.apache.hadoop.yarn.api.records.ReservationRequest;
-import org.apache.hadoop.yarn.api.records.ReservationRequestInterpreter;
-import org.apache.hadoop.yarn.api.records.ReservationRequests;
-import org.apache.hadoop.yarn.api.records.Resource;
-import org.apache.hadoop.yarn.api.records.Token;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.event.AsyncDispatcher;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.resourcemanager.reservation.ReservationSystemTestUtil;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceScheduler;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration;
-import org.apache.hadoop.yarn.util.Clock;
-import org.apache.hadoop.yarn.util.UTCClock;
-import org.apache.hadoop.yarn.util.resource.Resources;
-import org.junit.After;
-import org.junit.Assert;
-import org.junit.Before;
-
-/**
- * Base class for all the RouterClientRMService test cases. It provides utility
- * methods that can be used by the concrete test case classes.
- *
- */
-public abstract class BaseRouterClientRMTest {
-
-  /**
-   * The RouterClientRMService instance that will be used by all the test cases.
-   */
-  private MockRouterClientRMService clientrmService;
-  /**
-   * Thread pool used for asynchronous operations.
-   */
-  private static ExecutorService threadpool = Executors.newCachedThreadPool();
-  private Configuration conf;
-  private AsyncDispatcher dispatcher;
-
-  public final static int TEST_MAX_CACHE_SIZE = 10;
-
-  protected MockRouterClientRMService getRouterClientRMService() {
-    Assert.assertNotNull(this.clientrmService);
-    return this.clientrmService;
-  }
-
-  protected Configuration createConfiguration() {
-    YarnConfiguration config = new YarnConfiguration();
-    String mockPassThroughInterceptorClass =
-        PassThroughClientRequestInterceptor.class.getName();
-
-    // Create a request interceptor pipeline for testing. The last one in the
-    // chain will call the mock resource manager. The others in the chain will
-    // simply forward it to the next one in the chain
-    config.set(YarnConfiguration.ROUTER_CLIENTRM_INTERCEPTOR_CLASS_PIPELINE,
-        mockPassThroughInterceptorClass + "," + mockPassThroughInterceptorClass
-            + "," + mockPassThroughInterceptorClass + ","
-            + MockClientRequestInterceptor.class.getName());
-
-    config.setInt(YarnConfiguration.ROUTER_PIPELINE_CACHE_MAX_SIZE,
-        TEST_MAX_CACHE_SIZE);
-    CapacitySchedulerConfiguration schedulerConf =
-        new CapacitySchedulerConfiguration(config);
-    ReservationSystemTestUtil.setupQueueConfiguration(schedulerConf);
-    schedulerConf.setClass(YarnConfiguration.RM_SCHEDULER,
-        CapacityScheduler.class, ResourceScheduler.class);
-    schedulerConf.setBoolean(YarnConfiguration.RM_RESERVATION_SYSTEM_ENABLE,
-        true);
-    return schedulerConf;
-  }
-
-  @Before
-  public void setUp() throws IOException {
-    this.conf = createConfiguration();
-    this.dispatcher = new AsyncDispatcher();
-    this.dispatcher.init(conf);
-    this.dispatcher.start();
-    this.clientrmService = createAndStartRouterClientRMService();
-  }
-
-  public void setUpConfig() {
-    this.conf = createConfiguration();
-  }
-
-  protected Configuration getConf() {
-    return this.conf;
-  }
-
-  @After
-  public void tearDown() {
-    if (clientrmService != null) {
-      clientrmService.stop();
-      clientrmService = null;
-    }
-    if (this.dispatcher != null) {
-      this.dispatcher.stop();
-    }
-  }
-
-  protected ExecutorService getThreadPool() {
-    return threadpool;
-  }
-
-  protected MockRouterClientRMService createAndStartRouterClientRMService() {
-    MockRouterClientRMService svc = new MockRouterClientRMService();
-    svc.init(conf);
-    svc.start();
-    return svc;
-  }
-
-  protected static class MockRouterClientRMService
-      extends RouterClientRMService {
-    public MockRouterClientRMService() {
-      super();
-    }
-  }
-
-  protected GetNewApplicationResponse getNewApplication(String user)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<GetNewApplicationResponse>() {
-          @Override
-          public GetNewApplicationResponse run() throws Exception {
-            GetNewApplicationRequest req =
-                GetNewApplicationRequest.newInstance();
-            GetNewApplicationResponse response =
-                getRouterClientRMService().getNewApplication(req);
-            return response;
-          }
-        });
-  }
-
-  protected SubmitApplicationResponse submitApplication(
-      final ApplicationId appId, String user)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<SubmitApplicationResponse>() {
-          @Override
-          public SubmitApplicationResponse run() throws Exception {
-            ContainerLaunchContext amContainerSpec = mock(
-                ContainerLaunchContext.class);
-            ApplicationSubmissionContext context = ApplicationSubmissionContext
-                .newInstance(appId, MockApps.newAppName(), "q1",
-                    Priority.newInstance(0), amContainerSpec, false, false, -1,
-                    Resources.createResource(
-                        YarnConfiguration.
-                        DEFAULT_RM_SCHEDULER_MINIMUM_ALLOCATION_MB),
-                    "MockApp");
-            SubmitApplicationRequest req = SubmitApplicationRequest
-                .newInstance(context);
-            SubmitApplicationResponse response = getRouterClientRMService()
-                .submitApplication(req);
-            return response;
-          }
-        });
-  }
-
-  protected KillApplicationResponse forceKillApplication(
-      final ApplicationId appId, String user)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<KillApplicationResponse>() {
-          @Override
-          public KillApplicationResponse run() throws Exception {
-            KillApplicationRequest req =
-                KillApplicationRequest.newInstance(appId);
-            KillApplicationResponse response =
-                getRouterClientRMService().forceKillApplication(req);
-            return response;
-          }
-        });
-  }
-
-  protected GetClusterMetricsResponse getClusterMetrics(String user)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<GetClusterMetricsResponse>() {
-          @Override
-          public GetClusterMetricsResponse run() throws Exception {
-            GetClusterMetricsRequest req =
-                GetClusterMetricsRequest.newInstance();
-            GetClusterMetricsResponse response =
-                getRouterClientRMService().getClusterMetrics(req);
-            return response;
-          }
-        });
-  }
-
-  protected GetClusterNodesResponse getClusterNodes(String user)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<GetClusterNodesResponse>() {
-          @Override
-          public GetClusterNodesResponse run() throws Exception {
-            GetClusterNodesRequest req = GetClusterNodesRequest.newInstance();
-            GetClusterNodesResponse response =
-                getRouterClientRMService().getClusterNodes(req);
-            return response;
-          }
-        });
-  }
-
-  protected GetQueueInfoResponse getQueueInfo(String user)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<GetQueueInfoResponse>() {
-          @Override
-          public GetQueueInfoResponse run() throws Exception {
-            GetQueueInfoRequest req =
-                GetQueueInfoRequest.newInstance("default", false, false, false);
-            GetQueueInfoResponse response =
-                getRouterClientRMService().getQueueInfo(req);
-            return response;
-          }
-        });
-  }
-
-  protected GetQueueUserAclsInfoResponse getQueueUserAcls(String user)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<GetQueueUserAclsInfoResponse>() {
-          @Override
-          public GetQueueUserAclsInfoResponse run() throws Exception {
-            GetQueueUserAclsInfoRequest req =
-                GetQueueUserAclsInfoRequest.newInstance();
-            GetQueueUserAclsInfoResponse response =
-                getRouterClientRMService().getQueueUserAcls(req);
-            return response;
-          }
-        });
-  }
-
-  protected MoveApplicationAcrossQueuesResponse moveApplicationAcrossQueues(
-      String user, final ApplicationId appId)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user).doAs(
-        new PrivilegedExceptionAction<MoveApplicationAcrossQueuesResponse>() {
-          @Override
-          public MoveApplicationAcrossQueuesResponse run() throws Exception {
-
-            MoveApplicationAcrossQueuesRequest req =
-                MoveApplicationAcrossQueuesRequest.newInstance(appId,
-                    "newQueue");
-            MoveApplicationAcrossQueuesResponse response =
-                getRouterClientRMService().moveApplicationAcrossQueues(req);
-            return response;
-          }
-        });
-  }
-
-  public GetNewReservationResponse getNewReservation(String user)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<GetNewReservationResponse>() {
-          @Override
-          public GetNewReservationResponse run() throws Exception {
-            GetNewReservationResponse response = getRouterClientRMService()
-                .getNewReservation(GetNewReservationRequest.newInstance());
-            return response;
-          }
-        });
-  }
-
-  protected ReservationSubmissionResponse submitReservation(String user,
-      final ReservationId reservationId)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<ReservationSubmissionResponse>() {
-          @Override
-          public ReservationSubmissionResponse run() throws Exception {
-            Clock clock = new UTCClock();
-            long arrival = clock.getTime();
-            long duration = 60000;
-            long deadline = (long) (arrival + 1.05 * duration);
-            ReservationSubmissionRequest req = ReservationSystemTestUtil
-                .createSimpleReservationRequest(reservationId, 1, arrival,
-                    deadline, duration);
-            ReservationSubmissionResponse response =
-                getRouterClientRMService().submitReservation(req);
-            return response;
-          }
-        });
-  }
-
-  protected ReservationUpdateResponse updateReservation(String user,
-      final ReservationId reservationId)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<ReservationUpdateResponse>() {
-          @Override
-          public ReservationUpdateResponse run() throws Exception {
-            Clock clock = new UTCClock();
-            long arrival = clock.getTime();
-            long duration = 60000;
-            long deadline = (long) (arrival + 1.05 * duration);
-            ReservationDefinition rDef =
-                createSimpleReservationRequest(1, arrival, deadline, duration,
-                    reservationId).getReservationDefinition();
-
-            ReservationUpdateRequest req =
-                ReservationUpdateRequest.newInstance(rDef, reservationId);
-            ReservationUpdateResponse response =
-                getRouterClientRMService().updateReservation(req);
-            return response;
-          }
-        });
-  }
-
-  protected ReservationDeleteResponse deleteReservation(String user,
-      final ReservationId reservationId)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<ReservationDeleteResponse>() {
-          @Override
-          public ReservationDeleteResponse run() throws Exception {
-            ReservationDeleteRequest req =
-                ReservationDeleteRequest.newInstance(reservationId);
-            ReservationDeleteResponse response =
-                getRouterClientRMService().deleteReservation(req);
-            return response;
-          }
-        });
-  }
-
-  protected GetNodesToLabelsResponse getNodeToLabels(String user)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<GetNodesToLabelsResponse>() {
-          @Override
-          public GetNodesToLabelsResponse run() throws Exception {
-            GetNodesToLabelsRequest req = GetNodesToLabelsRequest.newInstance();
-            GetNodesToLabelsResponse response =
-                getRouterClientRMService().getNodeToLabels(req);
-            return response;
-          }
-        });
-  }
-
-  protected GetLabelsToNodesResponse getLabelsToNodes(String user)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<GetLabelsToNodesResponse>() {
-          @Override
-          public GetLabelsToNodesResponse run() throws Exception {
-            GetLabelsToNodesRequest req = GetLabelsToNodesRequest.newInstance();
-            GetLabelsToNodesResponse response =
-                getRouterClientRMService().getLabelsToNodes(req);
-            return response;
-          }
-        });
-  }
-
-  protected GetClusterNodeLabelsResponse getClusterNodeLabels(String user)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<GetClusterNodeLabelsResponse>() {
-          @Override
-          public GetClusterNodeLabelsResponse run() throws Exception {
-            GetClusterNodeLabelsRequest req =
-                GetClusterNodeLabelsRequest.newInstance();
-            GetClusterNodeLabelsResponse response =
-                getRouterClientRMService().getClusterNodeLabels(req);
-            return response;
-          }
-        });
-  }
-
-  protected GetApplicationReportResponse getApplicationReport(String user,
-      final ApplicationId appId)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<GetApplicationReportResponse>() {
-          @Override
-          public GetApplicationReportResponse run() throws Exception {
-            GetApplicationReportRequest req =
-                GetApplicationReportRequest.newInstance(appId);
-            GetApplicationReportResponse response =
-                getRouterClientRMService().getApplicationReport(req);
-            return response;
-          }
-        });
-  }
-
-  protected GetApplicationsResponse getApplications(String user)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<GetApplicationsResponse>() {
-          @Override
-          public GetApplicationsResponse run() throws Exception {
-            GetApplicationsRequest req = GetApplicationsRequest.newInstance();
-            GetApplicationsResponse response =
-                getRouterClientRMService().getApplications(req);
-            return response;
-          }
-        });
-  }
-
-  protected GetApplicationAttemptReportResponse getApplicationAttemptReport(
-      String user, final ApplicationAttemptId appAttemptId)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user).doAs(
-        new PrivilegedExceptionAction<GetApplicationAttemptReportResponse>() {
-          @Override
-          public GetApplicationAttemptReportResponse run() throws Exception {
-            GetApplicationAttemptReportRequest req =
-                GetApplicationAttemptReportRequest.newInstance(appAttemptId);
-            GetApplicationAttemptReportResponse response =
-                getRouterClientRMService().getApplicationAttemptReport(req);
-            return response;
-          }
-        });
-  }
-
-  protected GetApplicationAttemptsResponse getApplicationAttempts(String user,
-      final ApplicationId applicationId)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<GetApplicationAttemptsResponse>() {
-          @Override
-          public GetApplicationAttemptsResponse run() throws Exception {
-            GetApplicationAttemptsRequest req =
-                GetApplicationAttemptsRequest.newInstance(applicationId);
-            GetApplicationAttemptsResponse response =
-                getRouterClientRMService().getApplicationAttempts(req);
-            return response;
-          }
-        });
-  }
-
-  protected GetContainerReportResponse getContainerReport(String user,
-      final ContainerId containerId)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<GetContainerReportResponse>() {
-          @Override
-          public GetContainerReportResponse run() throws Exception {
-            GetContainerReportRequest req =
-                GetContainerReportRequest.newInstance(containerId);
-            GetContainerReportResponse response =
-                getRouterClientRMService().getContainerReport(req);
-            return response;
-          }
-        });
-  }
-
-  protected GetContainersResponse getContainers(String user,
-      final ApplicationAttemptId appAttemptId)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<GetContainersResponse>() {
-          @Override
-          public GetContainersResponse run() throws Exception {
-            GetContainersRequest req =
-                GetContainersRequest.newInstance(appAttemptId);
-            GetContainersResponse response =
-                getRouterClientRMService().getContainers(req);
-            return response;
-          }
-        });
-  }
-
-  protected GetDelegationTokenResponse getDelegationToken(final String user)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<GetDelegationTokenResponse>() {
-          @Override
-          public GetDelegationTokenResponse run() throws Exception {
-            GetDelegationTokenRequest req =
-                GetDelegationTokenRequest.newInstance(user);
-            GetDelegationTokenResponse response =
-                getRouterClientRMService().getDelegationToken(req);
-            return response;
-          }
-        });
-  }
-
-  protected RenewDelegationTokenResponse renewDelegationToken(String user,
-      final Token token)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<RenewDelegationTokenResponse>() {
-          @Override
-          public RenewDelegationTokenResponse run() throws Exception {
-            RenewDelegationTokenRequest req =
-                RenewDelegationTokenRequest.newInstance(token);
-            RenewDelegationTokenResponse response =
-                getRouterClientRMService().renewDelegationToken(req);
-            return response;
-          }
-        });
-  }
-
-  protected CancelDelegationTokenResponse cancelDelegationToken(String user,
-      final Token token)
-      throws YarnException, IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<CancelDelegationTokenResponse>() {
-          @Override
-          public CancelDelegationTokenResponse run() throws Exception {
-            CancelDelegationTokenRequest req =
-                CancelDelegationTokenRequest.newInstance(token);
-            CancelDelegationTokenResponse response =
-                getRouterClientRMService().cancelDelegationToken(req);
-            return response;
-          }
-        });
-  }
-
-  private ReservationSubmissionRequest createSimpleReservationRequest(
-      int numContainers, long arrival, long deadline, long duration,
-      ReservationId reservationId) {
-    // create a request with a single atomic ask
-    ReservationRequest r = ReservationRequest
-        .newInstance(Resource.newInstance(1024, 1), numContainers, 1, duration);
-    ReservationRequests reqs = ReservationRequests.newInstance(
-        Collections.singletonList(r), ReservationRequestInterpreter.R_ALL);
-    ReservationDefinition rDef = ReservationDefinition.newInstance(arrival,
-        deadline, reqs, "testRouterClientRMService#reservation");
-    ReservationSubmissionRequest request = ReservationSubmissionRequest
-        .newInstance(rDef, "dedicated", reservationId);
-    return request;
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/MockClientRequestInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/MockClientRequestInterceptor.java
deleted file mode 100644
index c85bbd6f2ea..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/MockClientRequestInterceptor.java
+++ /dev/null
@@ -1,80 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesResponse;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.resourcemanager.ClientRMService;
-import org.apache.hadoop.yarn.server.resourcemanager.MockRM;
-import org.junit.Assert;
-
-/**
- * This class mocks the ClientRequestInterceptor.
- */
-public class MockClientRequestInterceptor
-    extends DefaultClientRequestInterceptor {
-
-  MockRM mockRM = null;
-
-  public void init(String user) {
-    mockRM = new MockRM(super.getConf()) {
-      @Override
-      protected ClientRMService createClientRMService() {
-        return new ClientRMService(getRMContext(), getResourceScheduler(),
-            rmAppManager, applicationACLsManager, queueACLsManager,
-            getRMContext().getRMDelegationTokenSecretManager()) {
-          @Override
-          protected void serviceStart() {
-            // override to not start rpc handler
-          }
-
-          @Override
-          protected void serviceStop() {
-            // don't do anything
-          }
-
-          @Override
-          public MoveApplicationAcrossQueuesResponse moveApplicationAcrossQueues(
-              MoveApplicationAcrossQueuesRequest request) throws YarnException {
-            return MoveApplicationAcrossQueuesResponse.newInstance();
-          }
-        };
-      }
-    };
-    mockRM.init(super.getConf());
-    mockRM.start();
-    try {
-      mockRM.registerNode("127.0.0.1:1", 102400, 100);
-      // allow plan follower to synchronize
-      Thread.sleep(1050);
-    } catch (Exception e) {
-      Assert.fail(e.getMessage());
-    }
-    super.setRMClient(mockRM.getClientRMService());
-  }
-
-  @Override
-  public void shutdown() {
-    if (mockRM != null) {
-      mockRM.stop();
-    }
-    super.shutdown();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/PassThroughClientRequestInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/PassThroughClientRequestInterceptor.java
deleted file mode 100644
index d4820fc12b5..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/PassThroughClientRequestInterceptor.java
+++ /dev/null
@@ -1,316 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import java.io.IOException;
-
-import org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainersResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.KillApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationListResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.SignalContainerResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsResponse;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-
-/**
- * Mock interceptor that does not do anything other than forwarding it to the
- * next interceptor in the chain.
- */
-public class PassThroughClientRequestInterceptor
-    extends AbstractClientRequestInterceptor {
-
-  @Override
-  public GetNewApplicationResponse getNewApplication(
-      GetNewApplicationRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getNewApplication(request);
-  }
-
-  @Override
-  public SubmitApplicationResponse submitApplication(
-      SubmitApplicationRequest request) throws YarnException, IOException {
-    return getNextInterceptor().submitApplication(request);
-  }
-
-  @Override
-  public KillApplicationResponse forceKillApplication(
-      KillApplicationRequest request) throws YarnException, IOException {
-    return getNextInterceptor().forceKillApplication(request);
-  }
-
-  @Override
-  public GetClusterMetricsResponse getClusterMetrics(
-      GetClusterMetricsRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getClusterMetrics(request);
-  }
-
-  @Override
-  public GetClusterNodesResponse getClusterNodes(GetClusterNodesRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().getClusterNodes(request);
-  }
-
-  @Override
-  public GetQueueInfoResponse getQueueInfo(GetQueueInfoRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().getQueueInfo(request);
-  }
-
-  @Override
-  public GetQueueUserAclsInfoResponse getQueueUserAcls(
-      GetQueueUserAclsInfoRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getQueueUserAcls(request);
-  }
-
-  @Override
-  public MoveApplicationAcrossQueuesResponse moveApplicationAcrossQueues(
-      MoveApplicationAcrossQueuesRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().moveApplicationAcrossQueues(request);
-  }
-
-  @Override
-  public GetNewReservationResponse getNewReservation(
-      GetNewReservationRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getNewReservation(request);
-  }
-
-  @Override
-  public ReservationSubmissionResponse submitReservation(
-      ReservationSubmissionRequest request) throws YarnException, IOException {
-    return getNextInterceptor().submitReservation(request);
-  }
-
-  @Override
-  public ReservationListResponse listReservations(
-      ReservationListRequest request) throws YarnException, IOException {
-    return getNextInterceptor().listReservations(request);
-  }
-
-  @Override
-  public ReservationUpdateResponse updateReservation(
-      ReservationUpdateRequest request) throws YarnException, IOException {
-    return getNextInterceptor().updateReservation(request);
-  }
-
-  @Override
-  public ReservationDeleteResponse deleteReservation(
-      ReservationDeleteRequest request) throws YarnException, IOException {
-    return getNextInterceptor().deleteReservation(request);
-  }
-
-  @Override
-  public GetNodesToLabelsResponse getNodeToLabels(
-      GetNodesToLabelsRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getNodeToLabels(request);
-  }
-
-  @Override
-  public GetLabelsToNodesResponse getLabelsToNodes(
-      GetLabelsToNodesRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getLabelsToNodes(request);
-  }
-
-  @Override
-  public GetClusterNodeLabelsResponse getClusterNodeLabels(
-      GetClusterNodeLabelsRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getClusterNodeLabels(request);
-  }
-
-  @Override
-  public GetApplicationReportResponse getApplicationReport(
-      GetApplicationReportRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getApplicationReport(request);
-  }
-
-  @Override
-  public GetApplicationsResponse getApplications(GetApplicationsRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().getApplications(request);
-  }
-
-  @Override
-  public GetApplicationAttemptReportResponse getApplicationAttemptReport(
-      GetApplicationAttemptReportRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().getApplicationAttemptReport(request);
-  }
-
-  @Override
-  public GetApplicationAttemptsResponse getApplicationAttempts(
-      GetApplicationAttemptsRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getApplicationAttempts(request);
-  }
-
-  @Override
-  public GetContainerReportResponse getContainerReport(
-      GetContainerReportRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getContainerReport(request);
-  }
-
-  @Override
-  public GetContainersResponse getContainers(GetContainersRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().getContainers(request);
-  }
-
-  @Override
-  public GetDelegationTokenResponse getDelegationToken(
-      GetDelegationTokenRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getDelegationToken(request);
-  }
-
-  @Override
-  public RenewDelegationTokenResponse renewDelegationToken(
-      RenewDelegationTokenRequest request) throws YarnException, IOException {
-    return getNextInterceptor().renewDelegationToken(request);
-  }
-
-  @Override
-  public CancelDelegationTokenResponse cancelDelegationToken(
-      CancelDelegationTokenRequest request) throws YarnException, IOException {
-    return getNextInterceptor().cancelDelegationToken(request);
-  }
-
-  @Override
-  public FailApplicationAttemptResponse failApplicationAttempt(
-      FailApplicationAttemptRequest request) throws YarnException, IOException {
-    return getNextInterceptor().failApplicationAttempt(request);
-  }
-
-  @Override
-  public UpdateApplicationPriorityResponse updateApplicationPriority(
-      UpdateApplicationPriorityRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().updateApplicationPriority(request);
-  }
-
-  @Override
-  public SignalContainerResponse signalToContainer(
-      SignalContainerRequest request) throws YarnException, IOException {
-    return getNextInterceptor().signalToContainer(request);
-  }
-
-  @Override
-  public UpdateApplicationTimeoutsResponse updateApplicationTimeouts(
-      UpdateApplicationTimeoutsRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().updateApplicationTimeouts(request);
-  }
-
-  @Override
-  public GetAllResourceProfilesResponse getResourceProfiles(
-      GetAllResourceProfilesRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getResourceProfiles(request);
-  }
-
-  @Override
-  public GetResourceProfileResponse getResourceProfile(
-      GetResourceProfileRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getResourceProfile(request);
-  }
-
-  @Override
-  public GetAllResourceTypeInfoResponse getResourceTypeInfo(
-      GetAllResourceTypeInfoRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getResourceTypeInfo(request);
-  }
-
-  @Override
-  public GetAttributesToNodesResponse getAttributesToNodes(
-      GetAttributesToNodesRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getAttributesToNodes(request);
-  }
-
-  @Override
-  public GetClusterNodeAttributesResponse getClusterNodeAttributes(
-      GetClusterNodeAttributesRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().getClusterNodeAttributes(request);
-  }
-
-  @Override
-  public GetNodesToAttributesResponse getNodesToAttributes(
-      GetNodesToAttributesRequest request) throws YarnException, IOException {
-    return getNextInterceptor().getNodesToAttributes(request);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestApplicationSubmissionContextInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestApplicationSubmissionContextInterceptor.java
deleted file mode 100644
index d3cf6de4abf..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestApplicationSubmissionContextInterceptor.java
+++ /dev/null
@@ -1,160 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *  http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import java.nio.ByteBuffer;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.test.LambdaTestUtils;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest;
-import org.apache.hadoop.yarn.api.records.ApplicationAccessType;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
-import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;
-import org.apache.hadoop.yarn.api.records.LocalResource;
-import org.apache.hadoop.yarn.api.records.LocalResourceType;
-import org.apache.hadoop.yarn.api.records.LocalResourceVisibility;
-import org.apache.hadoop.yarn.api.records.Priority;
-import org.apache.hadoop.yarn.api.records.Resource;
-import org.apache.hadoop.yarn.api.records.URL;
-import org.apache.hadoop.yarn.api.records.impl.pb.ApplicationSubmissionContextPBImpl;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.router.RouterServerUtil;
-import org.junit.Test;
-
-/**
- * Extends the {@code BaseRouterClientRMTest} and overrides methods in order to
- * use the {@code RouterClientRMService} pipeline test cases for testing the
- * {@code ApplicationSubmissionContextInterceptor} class. The tests for
- * {@code RouterClientRMService} has been written cleverly so that it can be
- * reused to validate different request interceptor chains.
- */
-public class TestApplicationSubmissionContextInterceptor extends BaseRouterClientRMTest {
-
-  @Override
-  protected YarnConfiguration createConfiguration() {
-    YarnConfiguration conf = new YarnConfiguration();
-    String mockPassThroughInterceptorClass =
-        PassThroughClientRequestInterceptor.class.getName();
-
-    // Create a request interceptor pipeline for testing. The last one in the
-    // chain is the application submission context interceptor that checks
-    // for exceeded submission context size
-    // The others in the chain will simply forward it to the next one in the
-    // chain
-    conf.set(YarnConfiguration.ROUTER_CLIENTRM_INTERCEPTOR_CLASS_PIPELINE,
-        mockPassThroughInterceptorClass + "," +
-        ApplicationSubmissionContextInterceptor.class.getName() + "," +
-        MockClientRequestInterceptor.class.getName());
-
-    // Lower the max application context size
-    conf.set(YarnConfiguration.ROUTER_ASC_INTERCEPTOR_MAX_SIZE, "512B");
-
-    return conf;
-  }
-
-  /**
-   * This test validates the correctness of SubmitApplication in case of empty
-   * request.
-   * @throws Exception error occur.
-   */
-  @Test
-  public void testSubmitApplicationEmptyRequest() throws Exception {
-
-    MockRouterClientRMService rmService = getRouterClientRMService();
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing submitApplication request or applicationSubmissionContext information.",
-        () -> rmService.submitApplication(null));
-
-    ApplicationSubmissionContext context = ApplicationSubmissionContext.newInstance(
-        null, "", "", null, null, false, false, -1, null, null);
-    SubmitApplicationRequest request = SubmitApplicationRequest.newInstance(context);
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing submitApplication request or applicationSubmissionContext information.",
-        () -> rmService.submitApplication(null));
-  }
-
-  /**
-   * This test validates the correctness of SubmitApplication by setting up
-   * null, valid, and large ContainerLaunchContexts.
-   * @throws Exception error occur.
-   */
-  @Test
-  public void testCLCExceedSize() throws Exception {
-
-    ApplicationSubmissionContext context = ApplicationSubmissionContext.newInstance(
-        ApplicationId.newInstance(1, 1), "test", "default",
-        Priority.newInstance(0), null, false, true, 2,
-        Resource.newInstance(10, 2), "test");
-
-    LocalResource localResource = LocalResource.newInstance(
-        URL.newInstance("hdfs", "somehost", 12345, "/some/path/to/rsrc"),
-        LocalResourceType.FILE, LocalResourceVisibility.APPLICATION, 123L,
-        1234567890L);
-
-    Map<String, LocalResource> localResources = new HashMap<>();
-    localResources.put("rsrc", localResource);
-
-    Map<String, String> env = new HashMap<>();
-    env.put("somevar", "someval");
-
-    List<String> containerCmds = new ArrayList<>();
-    containerCmds.add("somecmd");
-    containerCmds.add("somearg");
-
-    Map<String, ByteBuffer> serviceData = new HashMap<>();
-    serviceData.put("someservice", ByteBuffer.wrap(new byte[] {0x1, 0x2, 0x3}));
-    ByteBuffer containerTokens = ByteBuffer.wrap(new byte[] {0x7, 0x8, 0x9, 0xa});
-
-    Map<ApplicationAccessType, String> acls = new HashMap<>();
-    acls.put(ApplicationAccessType.VIEW_APP, "viewuser");
-    acls.put(ApplicationAccessType.MODIFY_APP, "moduser");
-    ContainerLaunchContext clc = ContainerLaunchContext.newInstance(
-        localResources, env, containerCmds, serviceData, containerTokens, acls);
-    ApplicationSubmissionContextPBImpl appSubmissionContextPB =
-        (ApplicationSubmissionContextPBImpl) context;
-    Configuration configuration = getConf();
-
-    // Null ApplicationSubmissionContext
-    RouterServerUtil.checkAppSubmissionContext(null, configuration);
-
-    // Null ContainerLaunchContext
-    RouterServerUtil.checkAppSubmissionContext(appSubmissionContextPB, configuration);
-
-    // Valid ContainerLaunchContext
-    context.setAMContainerSpec(clc);
-    RouterServerUtil.checkAppSubmissionContext(appSubmissionContextPB, configuration);
-
-    // ContainerLaunchContext exceeds 1MB
-    for (int i = 0; i < 1000; i++) {
-      localResources.put("rsrc" + i, localResource);
-    }
-    ContainerLaunchContext clcExceedSize = ContainerLaunchContext.newInstance(
-        localResources, env, containerCmds, serviceData, containerTokens, acls);
-    context.setAMContainerSpec(clcExceedSize);
-    LambdaTestUtils.intercept(YarnException.class,
-        "The size of the ApplicationSubmissionContext of the application",
-        () -> RouterServerUtil.checkAppSubmissionContext(appSubmissionContextPB, configuration));
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestFederationClientInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestFederationClientInterceptor.java
deleted file mode 100644
index 3c2c7b4d3b3..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestFederationClientInterceptor.java
+++ /dev/null
@@ -1,1731 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.when;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.EnumSet;
-import java.util.List;
-import java.util.Map;
-import java.util.HashMap;
-import java.util.Set;
-import java.util.stream.Collectors;
-import java.util.Arrays;
-import java.util.Collection;
-
-import org.apache.hadoop.io.Text;
-import org.apache.hadoop.metrics2.lib.DefaultMetricsSystem;
-import org.apache.hadoop.test.LambdaTestUtils;
-import org.apache.hadoop.util.Time;
-import org.apache.hadoop.yarn.MockApps;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.KillApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.KillApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationAttemptsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationListResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainersRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainersResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetContainerReportResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.FailApplicationAttemptResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationPriorityResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.UpdateApplicationTimeoutsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.SignalContainerRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.SignalContainerResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.RenewDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.CancelDelegationTokenResponse;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
-import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;
-import org.apache.hadoop.yarn.api.records.Priority;
-import org.apache.hadoop.yarn.api.records.YarnApplicationState;
-import org.apache.hadoop.yarn.api.records.QueueACL;
-import org.apache.hadoop.yarn.api.records.QueueUserACLInfo;
-import org.apache.hadoop.yarn.api.records.ReservationId;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.api.records.ApplicationTimeoutType;
-import org.apache.hadoop.yarn.api.records.SignalContainerCommand;
-import org.apache.hadoop.yarn.api.records.QueueInfo;
-import org.apache.hadoop.yarn.api.records.Resource;
-import org.apache.hadoop.yarn.api.records.NodeAttributeKey;
-import org.apache.hadoop.yarn.api.records.NodeToAttributeValue;
-import org.apache.hadoop.yarn.api.records.NodeAttribute;
-import org.apache.hadoop.yarn.api.records.NodeAttributeInfo;
-import org.apache.hadoop.yarn.api.records.NodeAttributeType;
-import org.apache.hadoop.yarn.api.records.ReservationRequest;
-import org.apache.hadoop.yarn.api.records.ReservationDefinition;
-import org.apache.hadoop.yarn.api.records.ReservationRequestInterpreter;
-import org.apache.hadoop.yarn.api.records.ReservationRequests;
-import org.apache.hadoop.yarn.api.records.Token;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.security.client.RMDelegationTokenIdentifier;
-import org.apache.hadoop.yarn.server.federation.policies.manager.UniformBroadcastPolicyManager;
-import org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore;
-import org.apache.hadoop.yarn.server.federation.store.records.RouterRMDTSecretManagerState;
-import org.apache.hadoop.yarn.server.federation.store.records.RouterStoreToken;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreTestUtil;
-import org.apache.hadoop.yarn.server.resourcemanager.MockRM;
-import org.apache.hadoop.yarn.server.resourcemanager.MockNM;
-import org.apache.hadoop.yarn.server.resourcemanager.ResourceManager;
-import org.apache.hadoop.yarn.server.resourcemanager.reservation.ReservationSystem;
-import org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMApp;
-import org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMAppState;
-import org.apache.hadoop.yarn.server.resourcemanager.rmapp.attempt.RMAppAttemptState;
-import org.apache.hadoop.yarn.server.router.security.RouterDelegationTokenSecretManager;
-import org.apache.hadoop.yarn.util.ConverterUtils;
-import org.apache.hadoop.yarn.util.Records;
-import org.apache.hadoop.yarn.util.Times;
-import org.apache.hadoop.yarn.util.resource.Resources;
-import org.junit.Assert;
-import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * Extends the {@code BaseRouterClientRMTest} and overrides methods in order to
- * use the {@code RouterClientRMService} pipeline test cases for testing the
- * {@code FederationInterceptor} class. The tests for
- * {@code RouterClientRMService} has been written cleverly so that it can be
- * reused to validate different request interceptor chains.
- */
-public class TestFederationClientInterceptor extends BaseRouterClientRMTest {
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestFederationClientInterceptor.class);
-
-  private TestableFederationClientInterceptor interceptor;
-  private MemoryFederationStateStore stateStore;
-  private FederationStateStoreTestUtil stateStoreUtil;
-  private List<SubClusterId> subClusters;
-
-  private String user = "test-user";
-
-  private final static int NUM_SUBCLUSTER = 4;
-
-  private final static int APP_PRIORITY_ZERO = 0;
-
-  private final static long DEFAULT_DURATION = 10 * 60 * 1000;
-
-  @Override
-  public void setUp() throws IOException {
-    super.setUpConfig();
-    interceptor = new TestableFederationClientInterceptor();
-
-    stateStore = new MemoryFederationStateStore();
-    stateStore.init(this.getConf());
-    FederationStateStoreFacade.getInstance(getConf()).reinitialize(stateStore, getConf());
-    stateStoreUtil = new FederationStateStoreTestUtil(stateStore);
-
-    interceptor.setConf(this.getConf());
-    interceptor.init(user);
-    RouterDelegationTokenSecretManager tokenSecretManager =
-        interceptor.createRouterRMDelegationTokenSecretManager(this.getConf());
-
-    tokenSecretManager.startThreads();
-    interceptor.setTokenSecretManager(tokenSecretManager);
-
-    subClusters = new ArrayList<>();
-
-    try {
-      for (int i = 0; i < NUM_SUBCLUSTER; i++) {
-        SubClusterId sc = SubClusterId.newInstance(Integer.toString(i));
-        stateStoreUtil.registerSubCluster(sc);
-        subClusters.add(sc);
-      }
-    } catch (YarnException e) {
-      LOG.error(e.getMessage());
-      Assert.fail();
-    }
-
-    DefaultMetricsSystem.setMiniClusterMode(true);
-  }
-
-  @Override
-  public void tearDown() {
-    interceptor.shutdown();
-    super.tearDown();
-  }
-
-  @Override
-  protected YarnConfiguration createConfiguration() {
-    YarnConfiguration conf = new YarnConfiguration();
-    conf.setBoolean(YarnConfiguration.FEDERATION_ENABLED, true);
-    String mockPassThroughInterceptorClass =
-        PassThroughClientRequestInterceptor.class.getName();
-
-    // Create a request interceptor pipeline for testing. The last one in the
-    // chain is the federation interceptor that calls the mock resource manager.
-    // The others in the chain will simply forward it to the next one in the
-    // chain
-    conf.set(YarnConfiguration.ROUTER_CLIENTRM_INTERCEPTOR_CLASS_PIPELINE,
-        mockPassThroughInterceptorClass + "," + mockPassThroughInterceptorClass
-        + "," + TestableFederationClientInterceptor.class.getName());
-
-    conf.set(YarnConfiguration.FEDERATION_POLICY_MANAGER,
-        UniformBroadcastPolicyManager.class.getName());
-
-    // Disable StateStoreFacade cache
-    conf.setInt(YarnConfiguration.FEDERATION_CACHE_TIME_TO_LIVE_SECS, 0);
-
-    conf.setInt("yarn.scheduler.minimum-allocation-mb", 512);
-    conf.setInt("yarn.scheduler.minimum-allocation-vcores", 1);
-    conf.setInt("yarn.scheduler.maximum-allocation-mb", 100 * 1024);
-    conf.setInt("yarn.scheduler.maximum-allocation-vcores", 100);
-
-    conf.setBoolean("hadoop.security.authentication", true);
-    return conf;
-  }
-
-  /**
-   * This test validates the correctness of GetNewApplication. The return
-   * ApplicationId has to belong to one of the SubCluster in the cluster.
-   */
-  @Test
-  public void testGetNewApplication() throws YarnException, IOException {
-    LOG.info("Test FederationClientInterceptor: Get New Application.");
-
-    GetNewApplicationRequest request = GetNewApplicationRequest.newInstance();
-    GetNewApplicationResponse response = interceptor.getNewApplication(request);
-
-    Assert.assertNotNull(response);
-    Assert.assertNotNull(response.getApplicationId());
-    Assert.assertEquals(response.getApplicationId().getClusterTimestamp(),
-        ResourceManager.getClusterTimeStamp());
-  }
-
-  /**
-   * This test validates the correctness of SubmitApplication. The application
-   * has to be submitted to one of the SubCluster in the cluster.
-   */
-  @Test
-  public void testSubmitApplication()
-      throws YarnException, IOException {
-    LOG.info("Test FederationClientInterceptor: Submit Application.");
-
-    ApplicationId appId = ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-
-    SubmitApplicationResponse response = interceptor.submitApplication(request);
-
-    Assert.assertNotNull(response);
-    SubClusterId scIdResult = stateStoreUtil.queryApplicationHomeSC(appId);
-    Assert.assertNotNull(scIdResult);
-    Assert.assertTrue(subClusters.contains(scIdResult));
-  }
-
-  private SubmitApplicationRequest mockSubmitApplicationRequest(
-      ApplicationId appId) {
-    ContainerLaunchContext amContainerSpec = mock(ContainerLaunchContext.class);
-    ApplicationSubmissionContext context = ApplicationSubmissionContext.newInstance(
-        appId, MockApps.newAppName(), "default",
-        Priority.newInstance(APP_PRIORITY_ZERO), amContainerSpec, false, false, -1,
-        Resources.createResource(YarnConfiguration.DEFAULT_RM_SCHEDULER_MINIMUM_ALLOCATION_MB),
-        "MockApp");
-    SubmitApplicationRequest request = SubmitApplicationRequest.newInstance(context);
-    return request;
-  }
-
-  /**
-   * This test validates the correctness of SubmitApplication in case of
-   * multiple submission. The first retry has to be submitted to the same
-   * SubCluster of the first attempt.
-   */
-  @Test
-  public void testSubmitApplicationMultipleSubmission()
-      throws YarnException, IOException, InterruptedException {
-    LOG.info(
-        "Test FederationClientInterceptor: Submit Application - Multiple");
-
-    ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-
-    // First attempt
-    SubmitApplicationResponse response = interceptor.submitApplication(request);
-
-    Assert.assertNotNull(response);
-    SubClusterId scIdResult = stateStoreUtil.queryApplicationHomeSC(appId);
-    Assert.assertNotNull(scIdResult);
-
-    // First retry
-    response = interceptor.submitApplication(request);
-
-    Assert.assertNotNull(response);
-    SubClusterId scIdResult2 = stateStoreUtil.queryApplicationHomeSC(appId);
-    Assert.assertNotNull(scIdResult2);
-    Assert.assertEquals(scIdResult, scIdResult);
-  }
-
-  /**
-   * This test validates the correctness of SubmitApplication in case of empty
-   * request.
-   */
-  @Test
-  public void testSubmitApplicationEmptyRequest()
-      throws Exception {
-    LOG.info("Test FederationClientInterceptor: Submit Application - Empty.");
-
-    // null request1
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing submitApplication request or applicationSubmissionContext information.",
-        () -> interceptor.submitApplication(null));
-
-    // null request2
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing submitApplication request or applicationSubmissionContext information.",
-        () -> interceptor.submitApplication(SubmitApplicationRequest.newInstance(null)));
-
-    // null request3
-    ApplicationSubmissionContext context = ApplicationSubmissionContext
-        .newInstance(null, "", "", null, null, false, false, -1, null, null);
-    SubmitApplicationRequest request =
-        SubmitApplicationRequest.newInstance(context);
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing submitApplication request or applicationSubmissionContext information.",
-        () -> interceptor.submitApplication(request));
-  }
-
-  /**
-   * This test validates the correctness of ForceKillApplication in case the
-   * application exists in the cluster.
-   */
-  @Test
-  public void testForceKillApplication()
-      throws YarnException, IOException, InterruptedException {
-    LOG.info("Test FederationClientInterceptor: Force Kill Application.");
-
-    ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-
-    // Submit the application we are going to kill later
-    SubmitApplicationResponse response = interceptor.submitApplication(request);
-
-    Assert.assertNotNull(response);
-    Assert.assertNotNull(stateStoreUtil.queryApplicationHomeSC(appId));
-
-    KillApplicationRequest requestKill = KillApplicationRequest.newInstance(appId);
-    KillApplicationResponse responseKill = interceptor.forceKillApplication(requestKill);
-    Assert.assertNotNull(responseKill);
-  }
-
-  /**
-   * This test validates the correctness of ForceKillApplication in case of
-   * application does not exist in StateStore.
-   */
-  @Test
-  public void testForceKillApplicationNotExists() throws Exception {
-    LOG.info("Test FederationClientInterceptor: Force Kill Application - Not Exists");
-
-    ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    KillApplicationRequest requestKill =
-        KillApplicationRequest.newInstance(appId);
-
-    LambdaTestUtils.intercept(YarnException.class,
-        "Application " + appId + " does not exist in FederationStateStore.",
-        () -> interceptor.forceKillApplication(requestKill));
-  }
-
-  /**
-   * This test validates the correctness of ForceKillApplication in case of
-   * empty request.
-   */
-  @Test
-  public void testForceKillApplicationEmptyRequest()
-      throws Exception {
-    LOG.info("Test FederationClientInterceptor: Force Kill Application - Empty.");
-
-    // null request1
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing forceKillApplication request or ApplicationId.",
-        () -> interceptor.forceKillApplication(null));
-
-    // null request2
-    KillApplicationRequest killRequest = KillApplicationRequest.newInstance(null);
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing forceKillApplication request or ApplicationId.",
-        () -> interceptor.forceKillApplication(killRequest));
-  }
-
-  /**
-   * This test validates the correctness of GetApplicationReport in case the
-   * application exists in the cluster.
-   */
-  @Test
-  public void testGetApplicationReport()
-      throws YarnException, IOException, InterruptedException {
-    LOG.info("Test FederationClientInterceptor: Get Application Report");
-
-    ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-
-    // Submit the application we want the report later
-    SubmitApplicationResponse response = interceptor.submitApplication(request);
-
-    Assert.assertNotNull(response);
-    Assert.assertNotNull(stateStoreUtil.queryApplicationHomeSC(appId));
-
-    GetApplicationReportRequest requestGet =
-        GetApplicationReportRequest.newInstance(appId);
-
-    GetApplicationReportResponse responseGet =
-        interceptor.getApplicationReport(requestGet);
-
-    Assert.assertNotNull(responseGet);
-  }
-
-  /**
-   * This test validates the correctness of GetApplicationReport in case the
-   * application does not exist in StateStore.
-   */
-  @Test
-  public void testGetApplicationNotExists()
-      throws Exception {
-    LOG.info("Test ApplicationClientProtocol: Get Application Report - Not Exists.");
-
-    ApplicationId appId = ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    GetApplicationReportRequest requestGet = GetApplicationReportRequest.newInstance(appId);
-    LambdaTestUtils.intercept(YarnException.class,
-        "Application " + appId + " does not exist in FederationStateStore.",
-        () -> interceptor.getApplicationReport(requestGet));
-  }
-
-  /**
-   * This test validates the correctness of GetApplicationReport in case of
-   * empty request.
-   */
-  @Test
-  public void testGetApplicationEmptyRequest()
-      throws Exception {
-    LOG.info("Test FederationClientInterceptor: Get Application Report - Empty.");
-
-    // null request1
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing getApplicationReport request or applicationId information.",
-        () -> interceptor.getApplicationReport(null));
-
-    // null request2
-    GetApplicationReportRequest reportRequest = GetApplicationReportRequest.newInstance(null);
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing getApplicationReport request or applicationId information.",
-        () -> interceptor.getApplicationReport(reportRequest));
-  }
-
-  /**
-   * This test validates the correctness of GetApplicationAttemptReport in case the
-   * application exists in the cluster.
-   */
-  @Test
-  public void testGetApplicationAttemptReport()
-          throws YarnException, IOException, InterruptedException {
-    LOG.info("Test FederationClientInterceptor: Get ApplicationAttempt Report.");
-
-    ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-
-    SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-
-    // Submit the application we want the applicationAttempt report later
-    SubmitApplicationResponse response = interceptor.submitApplication(request);
-
-    Assert.assertNotNull(response);
-    Assert.assertNotNull(stateStoreUtil.queryApplicationHomeSC(appId));
-
-    // Call GetApplicationAttempts Get ApplicationAttemptId
-    GetApplicationAttemptsRequest attemptsRequest =
-         GetApplicationAttemptsRequest.newInstance(appId);
-    GetApplicationAttemptsResponse attemptsResponse =
-         interceptor.getApplicationAttempts(attemptsRequest);
-
-    // Wait for app to start
-    while(attemptsResponse.getApplicationAttemptList().size() == 0) {
-      attemptsResponse =
-          interceptor.getApplicationAttempts(attemptsRequest);
-    }
-
-    Assert.assertNotNull(attemptsResponse);
-
-    GetApplicationAttemptReportRequest requestGet =
-         GetApplicationAttemptReportRequest.newInstance(
-         attemptsResponse.getApplicationAttemptList().get(0).getApplicationAttemptId());
-
-    GetApplicationAttemptReportResponse responseGet =
-         interceptor.getApplicationAttemptReport(requestGet);
-
-    Assert.assertNotNull(responseGet);
-  }
-
-  /**
-   * This test validates the correctness of GetApplicationAttemptReport in case the
-   * application does not exist in StateStore.
-   */
-  @Test
-  public void testGetApplicationAttemptNotExists() throws Exception {
-    LOG.info("Test FederationClientInterceptor: Get ApplicationAttempt Report - Not Exists.");
-
-    ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    ApplicationAttemptId appAttemptID =
-        ApplicationAttemptId.newInstance(appId, 1);
-    GetApplicationAttemptReportRequest requestGet =
-        GetApplicationAttemptReportRequest.newInstance(appAttemptID);
-
-    LambdaTestUtils.intercept(YarnException.class, "ApplicationAttempt " +
-        appAttemptID + " belongs to Application " +
-        appId + " does not exist in FederationStateStore.",
-        () -> interceptor.getApplicationAttemptReport(requestGet));
-  }
-
-  /**
-   * This test validates the correctness of GetApplicationAttemptReport in case of
-   * empty request.
-   */
-  @Test
-  public void testGetApplicationAttemptEmptyRequest()
-      throws Exception {
-    LOG.info("Test FederationClientInterceptor: Get ApplicationAttempt Report - Empty.");
-
-    // null request1
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing getApplicationAttemptReport request or applicationId " +
-        "or applicationAttemptId information.",
-        () -> interceptor.getApplicationAttemptReport(null));
-
-    // null request2
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing getApplicationAttemptReport request or applicationId " +
-        "or applicationAttemptId information.",
-        () -> interceptor.getApplicationAttemptReport(
-        GetApplicationAttemptReportRequest.newInstance(null)));
-
-    // null request3
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing getApplicationAttemptReport request or applicationId " +
-        "or applicationAttemptId information.",
-        () -> interceptor.getApplicationAttemptReport(
-        GetApplicationAttemptReportRequest.newInstance(
-        ApplicationAttemptId.newInstance(null, 1))));
-  }
-
-
-  @Test
-  public void testGetClusterMetricsRequest() throws Exception {
-    LOG.info("Test FederationClientInterceptor : Get Cluster Metrics request.");
-
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing getClusterMetrics request.",
-        () -> interceptor.getClusterMetrics(null));
-
-    // normal request.
-    GetClusterMetricsResponse response =
-        interceptor.getClusterMetrics(GetClusterMetricsRequest.newInstance());
-    Assert.assertEquals(subClusters.size(),
-        response.getClusterMetrics().getNumNodeManagers());
-
-    // Clear Membership
-    Map<SubClusterId, SubClusterInfo> membership = new HashMap<>();
-    membership.putAll(stateStore.getMembership());
-    stateStore.getMembership().clear();
-
-    ClientMethod remoteMethod = new ClientMethod("getClusterMetrics",
-        new Class[] {GetClusterMetricsRequest.class},
-        new Object[] {GetClusterMetricsRequest.newInstance()});
-    Collection<GetClusterMetricsResponse> clusterMetrics = interceptor.invokeConcurrent(
-        remoteMethod, GetClusterMetricsResponse.class);
-    Assert.assertTrue(clusterMetrics.isEmpty());
-
-    // Restore membership
-    stateStore.setMembership(membership);
-  }
-
-  /**
-   * This test validates the correctness of GetApplicationsResponse in case the
-   * application exists in the cluster.
-   */
-  @Test
-  public void testGetApplicationsResponse()
-      throws YarnException, IOException, InterruptedException {
-    LOG.info("Test FederationClientInterceptor: Get Applications Response.");
-    ApplicationId appId = ApplicationId.newInstance(System.currentTimeMillis(), 1);
-
-    SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-    SubmitApplicationResponse response = interceptor.submitApplication(request);
-
-    Assert.assertNotNull(response);
-    Assert.assertNotNull(stateStoreUtil.queryApplicationHomeSC(appId));
-
-    Set<String> appTypes = Collections.singleton("MockApp");
-    GetApplicationsRequest requestGet = GetApplicationsRequest.newInstance(appTypes);
-    GetApplicationsResponse responseGet = interceptor.getApplications(requestGet);
-
-    Assert.assertNotNull(responseGet);
-  }
-
-  /**
-   * This test validates the correctness of GetApplicationsResponse in case of
-   * empty request.
-   */
-  @Test
-  public void testGetApplicationsNullRequest() throws Exception {
-    LOG.info("Test FederationClientInterceptor: Get Applications request.");
-    LambdaTestUtils.intercept(YarnException.class, "Missing getApplications request.",
-        () -> interceptor.getApplications(null));
-  }
-
-  /**
-   * This test validates the correctness of GetApplicationsResponse in case applications
-   * with given type does not exist.
-   */
-  @Test
-  public void testGetApplicationsApplicationTypeNotExists() throws Exception{
-    LOG.info("Test FederationClientInterceptor: Application with type does not exist.");
-
-    ApplicationId appId = ApplicationId.newInstance(System.currentTimeMillis(), 1);
-
-    SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-    SubmitApplicationResponse response = interceptor.submitApplication(request);
-
-    Assert.assertNotNull(response);
-    Assert.assertNotNull(stateStoreUtil.queryApplicationHomeSC(appId));
-
-    Set<String> appTypes = Collections.singleton("SPARK");
-
-    GetApplicationsRequest requestGet = GetApplicationsRequest.newInstance(appTypes);
-    GetApplicationsResponse responseGet = interceptor.getApplications(requestGet);
-
-    Assert.assertNotNull(responseGet);
-    Assert.assertTrue(responseGet.getApplicationList().isEmpty());
-  }
-
-  /**
-   * This test validates the correctness of GetApplicationsResponse in case applications
-   * with given YarnApplicationState does not exist.
-   */
-  @Test
-  public void testGetApplicationsApplicationStateNotExists() throws Exception {
-    LOG.info("Test FederationClientInterceptor: Application with state does not exist.");
-
-    ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-
-    SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-    SubmitApplicationResponse response = interceptor.submitApplication(request);
-
-    Assert.assertNotNull(response);
-    Assert.assertNotNull(stateStoreUtil.queryApplicationHomeSC(appId));
-
-    EnumSet<YarnApplicationState> applicationStates = EnumSet.noneOf(
-        YarnApplicationState.class);
-    applicationStates.add(YarnApplicationState.KILLED);
-
-    GetApplicationsRequest requestGet =
-        GetApplicationsRequest.newInstance(applicationStates);
-
-    GetApplicationsResponse responseGet = interceptor.getApplications(requestGet);
-
-    Assert.assertNotNull(responseGet);
-    Assert.assertTrue(responseGet.getApplicationList().isEmpty());
-  }
-
-  @Test
-  public void testGetClusterNodesRequest() throws Exception {
-    LOG.info("Test FederationClientInterceptor : Get Cluster Nodes request.");
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing getClusterNodes request.",
-        () -> interceptor.getClusterNodes(null));
-    // normal request.
-    GetClusterNodesResponse response =
-        interceptor.getClusterNodes(GetClusterNodesRequest.newInstance());
-    Assert.assertEquals(subClusters.size(), response.getNodeReports().size());
-  }
-
-  @Test
-  public void testGetNodeToLabelsRequest() throws Exception {
-    LOG.info("Test FederationClientInterceptor :  Get Node To Labels request.");
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing getNodesToLabels request.",
-        () -> interceptor.getNodeToLabels(null));
-    // normal request.
-    GetNodesToLabelsResponse response =
-        interceptor.getNodeToLabels(GetNodesToLabelsRequest.newInstance());
-    Assert.assertEquals(0, response.getNodeToLabels().size());
-  }
-
-  @Test
-  public void testGetLabelsToNodesRequest() throws Exception {
-    LOG.info("Test FederationClientInterceptor :  Get Labels To Node request.");
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing getLabelsToNodes request.",
-        () -> interceptor.getLabelsToNodes(null));
-    // normal request.
-    GetLabelsToNodesResponse response =
-        interceptor.getLabelsToNodes(GetLabelsToNodesRequest.newInstance());
-    Assert.assertEquals(0, response.getLabelsToNodes().size());
-  }
-
-  @Test
-  public void testClusterNodeLabelsRequest() throws Exception {
-    LOG.info("Test FederationClientInterceptor :  Get Cluster NodeLabels request.");
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing getClusterNodeLabels request.",
-        () -> interceptor.getClusterNodeLabels(null));
-    // normal request.
-    GetClusterNodeLabelsResponse response =
-        interceptor.getClusterNodeLabels(GetClusterNodeLabelsRequest.newInstance());
-    Assert.assertEquals(0, response.getNodeLabelList().size());
-  }
-
-  @Test
-  public void testGetQueueUserAcls() throws Exception {
-    LOG.info("Test FederationClientInterceptor : Get QueueUserAcls request.");
-
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing getQueueUserAcls request.",
-        () -> interceptor.getQueueUserAcls(null));
-
-    // normal request
-    GetQueueUserAclsInfoResponse response = interceptor.getQueueUserAcls(
-        GetQueueUserAclsInfoRequest.newInstance());
-
-    Assert.assertNotNull(response);
-
-    List<QueueACL> submitAndAdministerAcl = new ArrayList<>();
-    submitAndAdministerAcl.add(QueueACL.SUBMIT_APPLICATIONS);
-    submitAndAdministerAcl.add(QueueACL.ADMINISTER_QUEUE);
-
-    QueueUserACLInfo exceptRootQueueACLInfo = QueueUserACLInfo.newInstance("root",
-        submitAndAdministerAcl);
-
-    QueueUserACLInfo queueRootQueueACLInfo = response.getUserAclsInfoList().stream().
-        filter(acl->acl.getQueueName().equals("root")).
-        collect(Collectors.toList()).get(0);
-
-    Assert.assertEquals(exceptRootQueueACLInfo, queueRootQueueACLInfo);
-  }
-
-  @Test
-  public void testListReservations() throws Exception {
-    LOG.info("Test FederationClientInterceptor :  Get ListReservations request.");
-
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing listReservations request.",
-        () -> interceptor.listReservations(null));
-
-    // normal request
-    ReservationId reservationId = ReservationId.newInstance(1653487680L, 1L);
-    ReservationListResponse response = interceptor.listReservations(
-        ReservationListRequest.newInstance("root.decided", reservationId.toString()));
-    Assert.assertNotNull(response);
-    Assert.assertEquals(0, response.getReservationAllocationState().size());
-  }
-
-  @Test
-  public void testGetContainersRequest() throws Exception {
-    LOG.info("Test FederationClientInterceptor : Get Containers request.");
-
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing getContainers request " +
-        "or ApplicationAttemptId.", () -> interceptor.getContainers(null));
-
-    // normal request
-    ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-
-    // Submit the application
-    SubmitApplicationResponse response = interceptor.submitApplication(request);
-
-    Assert.assertNotNull(response);
-    Assert.assertNotNull(stateStoreUtil.queryApplicationHomeSC(appId));
-
-    // Call GetApplicationAttempts
-    GetApplicationAttemptsRequest attemptsRequest =
-        GetApplicationAttemptsRequest.newInstance(appId);
-    GetApplicationAttemptsResponse attemptsResponse =
-        interceptor.getApplicationAttempts(attemptsRequest);
-
-    // Wait for app to start
-    while(attemptsResponse.getApplicationAttemptList().size() == 0) {
-      attemptsResponse =
-          interceptor.getApplicationAttempts(attemptsRequest);
-    }
-
-    Assert.assertNotNull(attemptsResponse);
-
-    // Call GetContainers
-    GetContainersRequest containersRequest =
-        GetContainersRequest.newInstance(
-        attemptsResponse.getApplicationAttemptList().get(0).getApplicationAttemptId());
-    GetContainersResponse containersResponse =
-        interceptor.getContainers(containersRequest);
-
-    Assert.assertNotNull(containersResponse);
-  }
-
-  @Test
-  public void testGetContainerReportRequest() throws Exception {
-    LOG.info("Test FederationClientInterceptor : Get Container Report request.");
-
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing getContainerReport request " +
-        "or containerId", () -> interceptor.getContainerReport(null));
-
-    // normal request
-    ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-
-    // Submit the application
-    SubmitApplicationResponse response = interceptor.submitApplication(request);
-
-    Assert.assertNotNull(response);
-    Assert.assertNotNull(stateStoreUtil.queryApplicationHomeSC(appId));
-
-    // Call GetApplicationAttempts
-    GetApplicationAttemptsRequest attemptsRequest =
-         GetApplicationAttemptsRequest.newInstance(appId);
-    GetApplicationAttemptsResponse attemptsResponse =
-         interceptor.getApplicationAttempts(attemptsRequest);
-
-    // Wait for app to start
-    while(attemptsResponse.getApplicationAttemptList().size() == 0) {
-      attemptsResponse =
-          interceptor.getApplicationAttempts(attemptsRequest);
-    }
-    Assert.assertNotNull(attemptsResponse);
-
-    ApplicationAttemptId attemptId = attemptsResponse.getApplicationAttemptList().
-        get(0).getApplicationAttemptId();
-    ContainerId containerId = ContainerId.newContainerId(attemptId, 1);
-
-    // Call ContainerReport, RM does not allocate Container, Here is null
-    GetContainerReportRequest containerReportRequest =
-         GetContainerReportRequest.newInstance(containerId);
-    GetContainerReportResponse containerReportResponse =
-         interceptor.getContainerReport(containerReportRequest);
-
-    Assert.assertEquals(containerReportResponse, null);
-  }
-
-  @Test
-  public void getApplicationAttempts() throws Exception {
-    LOG.info("Test FederationClientInterceptor : Get Application Attempts request.");
-
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing getApplicationAttempts " +
-            "request or application id.", () -> interceptor.getApplicationAttempts(null));
-
-    // normal request
-    ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-
-    // Submit the application
-    SubmitApplicationResponse response = interceptor.submitApplication(request);
-
-    Assert.assertNotNull(response);
-    Assert.assertNotNull(stateStoreUtil.queryApplicationHomeSC(appId));
-
-    // Call GetApplicationAttempts
-    GetApplicationAttemptsRequest attemptsRequest =
-         GetApplicationAttemptsRequest.newInstance(appId);
-    GetApplicationAttemptsResponse attemptsResponse =
-         interceptor.getApplicationAttempts(attemptsRequest);
-
-    Assert.assertNotNull(attemptsResponse);
-  }
-
-  @Test
-  public void testGetResourceTypeInfoRequest() throws Exception {
-    LOG.info("Test FederationClientInterceptor :  Get Resource TypeInfo request.");
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing getResourceTypeInfo request.",
-        () -> interceptor.getResourceTypeInfo(null));
-    // normal request.
-    GetAllResourceTypeInfoResponse response =
-        interceptor.getResourceTypeInfo(GetAllResourceTypeInfoRequest.newInstance());
-    Assert.assertEquals(2, response.getResourceTypeInfo().size());
-  }
-
-  @Test
-  public void testFailApplicationAttempt() throws Exception {
-    LOG.info("Test FederationClientInterceptor : Fail Application Attempt request.");
-
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing failApplicationAttempt request " +
-        "or applicationId or applicationAttemptId information.",
-        () -> interceptor.failApplicationAttempt(null));
-
-    // normal request
-    ApplicationId appId = ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-
-    // Submit the application
-    SubmitApplicationResponse response = interceptor.submitApplication(request);
-
-    Assert.assertNotNull(response);
-    Assert.assertNotNull(stateStoreUtil.queryApplicationHomeSC(appId));
-
-    SubClusterId subClusterId = interceptor.getApplicationHomeSubCluster(appId);
-    Assert.assertNotNull(subClusterId);
-
-    MockRM mockRM = interceptor.getMockRMs().get(subClusterId);
-    mockRM.waitForState(appId, RMAppState.ACCEPTED);
-    RMApp rmApp = mockRM.getRMContext().getRMApps().get(appId);
-    mockRM.waitForState(rmApp.getCurrentAppAttempt().getAppAttemptId(),
-        RMAppAttemptState.SCHEDULED);
-
-    // Call GetApplicationAttempts
-    GetApplicationAttemptsRequest attemptsRequest =
-        GetApplicationAttemptsRequest.newInstance(appId);
-    GetApplicationAttemptsResponse attemptsResponse =
-        interceptor.getApplicationAttempts(attemptsRequest);
-    Assert.assertNotNull(attemptsResponse);
-
-    ApplicationAttemptId attemptId = attemptsResponse.getApplicationAttemptList().
-        get(0).getApplicationAttemptId();
-
-    FailApplicationAttemptRequest requestFailAppAttempt =
-        FailApplicationAttemptRequest.newInstance(attemptId);
-    FailApplicationAttemptResponse responseFailAppAttempt =
-        interceptor.failApplicationAttempt(requestFailAppAttempt);
-
-    Assert.assertNotNull(responseFailAppAttempt);
-  }
-
-  @Test
-  public void testUpdateApplicationPriority() throws Exception {
-    LOG.info("Test FederationClientInterceptor : Update Application Priority request.");
-
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing updateApplicationPriority request " +
-        "or applicationId or applicationPriority information.",
-        () -> interceptor.updateApplicationPriority(null));
-
-    // normal request
-    ApplicationId appId = ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-
-    // Submit the application
-    SubmitApplicationResponse response = interceptor.submitApplication(request);
-
-    Assert.assertNotNull(response);
-    Assert.assertNotNull(stateStoreUtil.queryApplicationHomeSC(appId));
-
-    SubClusterId subClusterId = interceptor.getApplicationHomeSubCluster(appId);
-    Assert.assertNotNull(subClusterId);
-
-    MockRM mockRM = interceptor.getMockRMs().get(subClusterId);
-    mockRM.waitForState(appId, RMAppState.ACCEPTED);
-    RMApp rmApp = mockRM.getRMContext().getRMApps().get(appId);
-    mockRM.waitForState(rmApp.getCurrentAppAttempt().getAppAttemptId(),
-        RMAppAttemptState.SCHEDULED);
-
-    // Call GetApplicationAttempts
-    GetApplicationAttemptsRequest attemptsRequest =
-        GetApplicationAttemptsRequest.newInstance(appId);
-    GetApplicationAttemptsResponse attemptsResponse =
-        interceptor.getApplicationAttempts(attemptsRequest);
-    Assert.assertNotNull(attemptsResponse);
-
-    Priority priority = Priority.newInstance(20);
-    UpdateApplicationPriorityRequest requestUpdateAppPriority =
-        UpdateApplicationPriorityRequest.newInstance(appId, priority);
-    UpdateApplicationPriorityResponse responseAppPriority =
-        interceptor.updateApplicationPriority(requestUpdateAppPriority);
-
-    Assert.assertNotNull(responseAppPriority);
-    Assert.assertEquals(20,
-        responseAppPriority.getApplicationPriority().getPriority());
-  }
-
-  @Test
-  public void testUpdateApplicationTimeouts() throws Exception {
-    LOG.info("Test FederationClientInterceptor : Update Application Timeouts request.");
-
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing updateApplicationTimeouts request " +
-        "or applicationId or applicationTimeouts information.",
-        () -> interceptor.updateApplicationTimeouts(null));
-
-    // normal request
-    ApplicationId appId = ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-
-    // Submit the application
-    SubmitApplicationResponse response = interceptor.submitApplication(request);
-
-    Assert.assertNotNull(response);
-    Assert.assertNotNull(stateStoreUtil.queryApplicationHomeSC(appId));
-
-    SubClusterId subClusterId = interceptor.getApplicationHomeSubCluster(appId);
-    Assert.assertNotNull(subClusterId);
-
-    MockRM mockRM = interceptor.getMockRMs().get(subClusterId);
-    mockRM.waitForState(appId, RMAppState.ACCEPTED);
-    RMApp rmApp = mockRM.getRMContext().getRMApps().get(appId);
-    mockRM.waitForState(rmApp.getCurrentAppAttempt().getAppAttemptId(),
-        RMAppAttemptState.SCHEDULED);
-
-    // Call GetApplicationAttempts
-    GetApplicationAttemptsRequest attemptsRequest =
-        GetApplicationAttemptsRequest.newInstance(appId);
-    GetApplicationAttemptsResponse attemptsResponse =
-        interceptor.getApplicationAttempts(attemptsRequest);
-    Assert.assertNotNull(attemptsResponse);
-
-    String appTimeout =
-        Times.formatISO8601(System.currentTimeMillis() + 5 * 1000);
-    Map<ApplicationTimeoutType, String> applicationTimeouts = new HashMap<>();
-    applicationTimeouts.put(ApplicationTimeoutType.LIFETIME, appTimeout);
-
-    UpdateApplicationTimeoutsRequest timeoutsRequest =
-        UpdateApplicationTimeoutsRequest.newInstance(appId, applicationTimeouts);
-    UpdateApplicationTimeoutsResponse timeoutsResponse =
-        interceptor.updateApplicationTimeouts(timeoutsRequest);
-
-    String responseTimeOut =
-        timeoutsResponse.getApplicationTimeouts().get(ApplicationTimeoutType.LIFETIME);
-    Assert.assertNotNull(timeoutsResponse);
-    Assert.assertEquals(appTimeout, responseTimeOut);
-  }
-
-  @Test
-  public void testSignalContainer() throws Exception {
-    LOG.info("Test FederationClientInterceptor : Signal Container request.");
-
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing signalToContainer request " +
-        "or containerId or command information.", () -> interceptor.signalToContainer(null));
-
-    // normal request
-    ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-
-    // Submit the application
-    SubmitApplicationResponse response = interceptor.submitApplication(request);
-    Assert.assertNotNull(response);
-    Assert.assertNotNull(stateStoreUtil.queryApplicationHomeSC(appId));
-
-    SubClusterId subClusterId = interceptor.getApplicationHomeSubCluster(appId);
-    Assert.assertNotNull(subClusterId);
-
-    MockRM mockRM = interceptor.getMockRMs().get(subClusterId);
-    mockRM.waitForState(appId, RMAppState.ACCEPTED);
-    RMApp rmApp = mockRM.getRMContext().getRMApps().get(appId);
-    mockRM.waitForState(rmApp.getCurrentAppAttempt().getAppAttemptId(),
-        RMAppAttemptState.SCHEDULED);
-    MockNM nm = interceptor.getMockNMs().get(subClusterId);
-    nm.nodeHeartbeat(true);
-    MockRM.waitForState(rmApp.getCurrentAppAttempt(), RMAppAttemptState.ALLOCATED);
-    mockRM.sendAMLaunched(rmApp.getCurrentAppAttempt().getAppAttemptId());
-
-    ContainerId containerId = rmApp.getCurrentAppAttempt().getMasterContainer().getId();
-
-    SignalContainerRequest signalContainerRequest =
-        SignalContainerRequest.newInstance(containerId, SignalContainerCommand.GRACEFUL_SHUTDOWN);
-    SignalContainerResponse signalContainerResponse =
-        interceptor.signalToContainer(signalContainerRequest);
-
-    Assert.assertNotNull(signalContainerResponse);
-  }
-
-  @Test
-  public void testMoveApplicationAcrossQueues() throws Exception {
-    LOG.info("Test FederationClientInterceptor : MoveApplication AcrossQueues request.");
-
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing moveApplicationAcrossQueues request " +
-        "or applicationId or target queue.", () -> interceptor.moveApplicationAcrossQueues(null));
-
-    // normal request
-    ApplicationId appId = ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-
-    // Submit the application
-    SubmitApplicationResponse response = interceptor.submitApplication(request);
-
-    Assert.assertNotNull(response);
-    Assert.assertNotNull(stateStoreUtil.queryApplicationHomeSC(appId));
-
-    SubClusterId subClusterId = interceptor.getApplicationHomeSubCluster(appId);
-    Assert.assertNotNull(subClusterId);
-
-    MockRM mockRM = interceptor.getMockRMs().get(subClusterId);
-    mockRM.waitForState(appId, RMAppState.ACCEPTED);
-    RMApp rmApp = mockRM.getRMContext().getRMApps().get(appId);
-    mockRM.waitForState(rmApp.getCurrentAppAttempt().getAppAttemptId(),
-          RMAppAttemptState.SCHEDULED);
-    MockNM nm = interceptor.getMockNMs().get(subClusterId);
-    nm.nodeHeartbeat(true);
-    MockRM.waitForState(rmApp.getCurrentAppAttempt(), RMAppAttemptState.ALLOCATED);
-    mockRM.sendAMLaunched(rmApp.getCurrentAppAttempt().getAppAttemptId());
-
-    MoveApplicationAcrossQueuesRequest acrossQueuesRequest =
-        MoveApplicationAcrossQueuesRequest.newInstance(appId, "root.target");
-    MoveApplicationAcrossQueuesResponse acrossQueuesResponse =
-        interceptor.moveApplicationAcrossQueues(acrossQueuesRequest);
-
-    Assert.assertNotNull(acrossQueuesResponse);
-  }
-
-
-  @Test
-  public void testGetQueueInfo() throws Exception {
-    LOG.info("Test FederationClientInterceptor : Get Queue Info request.");
-
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing getQueueInfo request or queueName.",
-        () -> interceptor.getQueueInfo(null));
-
-    // normal request
-    GetQueueInfoResponse response = interceptor.getQueueInfo(
-        GetQueueInfoRequest.newInstance("root", true, true, true));
-
-    Assert.assertNotNull(response);
-
-    QueueInfo queueInfo = response.getQueueInfo();
-    Assert.assertNotNull(queueInfo);
-    Assert.assertEquals("root", queueInfo.getQueueName());
-    Assert.assertEquals(4.0, queueInfo.getCapacity(), 0);
-    Assert.assertEquals(0.0, queueInfo.getCurrentCapacity(), 0);
-    Assert.assertEquals(12, queueInfo.getChildQueues().size(), 0);
-    Assert.assertEquals(1, queueInfo.getAccessibleNodeLabels().size());
-  }
-
-  @Test
-  public void testSubClusterGetQueueInfo() throws IOException, YarnException {
-    // We have set up a unit test where we access queue information for subcluster1.
-    GetQueueInfoResponse response = interceptor.getQueueInfo(
-        GetQueueInfoRequest.newInstance("root", true, true, true, "1"));
-    Assert.assertNotNull(response);
-
-    QueueInfo queueInfo = response.getQueueInfo();
-    Assert.assertNotNull(queueInfo);
-    Assert.assertEquals("root", queueInfo.getQueueName());
-    Assert.assertEquals(1.0, queueInfo.getCapacity(), 0);
-    Assert.assertEquals(0.0, queueInfo.getCurrentCapacity(), 0);
-    Assert.assertEquals(3, queueInfo.getChildQueues().size(), 0);
-    Assert.assertEquals(1, queueInfo.getAccessibleNodeLabels().size());
-  }
-
-  @Test
-  public void testGetResourceProfiles() throws Exception {
-    LOG.info("Test FederationClientInterceptor : Get Resource Profiles request.");
-
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing getResourceProfiles request.",
-        () -> interceptor.getResourceProfiles(null));
-
-    // normal request
-    GetAllResourceProfilesRequest request = GetAllResourceProfilesRequest.newInstance();
-    GetAllResourceProfilesResponse response = interceptor.getResourceProfiles(request);
-
-    Assert.assertNotNull(response);
-    Map<String, Resource> resProfiles = response.getResourceProfiles();
-
-    Resource maxResProfiles = resProfiles.get("maximum");
-    Assert.assertEquals(32768, maxResProfiles.getMemorySize());
-    Assert.assertEquals(16, maxResProfiles.getVirtualCores());
-
-    Resource defaultResProfiles = resProfiles.get("default");
-    Assert.assertEquals(8192, defaultResProfiles.getMemorySize());
-    Assert.assertEquals(8, defaultResProfiles.getVirtualCores());
-
-    Resource minimumResProfiles = resProfiles.get("minimum");
-    Assert.assertEquals(4096, minimumResProfiles.getMemorySize());
-    Assert.assertEquals(4, minimumResProfiles.getVirtualCores());
-  }
-
-  @Test
-  public void testGetResourceProfile() throws Exception {
-    LOG.info("Test FederationClientInterceptor : Get Resource Profile request.");
-
-    // null request
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing getResourceProfile request or profileName.",
-        () -> interceptor.getResourceProfile(null));
-
-    // normal request
-    GetResourceProfileRequest request = GetResourceProfileRequest.newInstance("maximum");
-    GetResourceProfileResponse response = interceptor.getResourceProfile(request);
-
-    Assert.assertNotNull(response);
-    Assert.assertEquals(32768, response.getResource().getMemorySize());
-    Assert.assertEquals(16, response.getResource().getVirtualCores());
-
-    GetResourceProfileRequest request2 = GetResourceProfileRequest.newInstance("default");
-    GetResourceProfileResponse response2 = interceptor.getResourceProfile(request2);
-
-    Assert.assertNotNull(response2);
-    Assert.assertEquals(8192, response2.getResource().getMemorySize());
-    Assert.assertEquals(8, response2.getResource().getVirtualCores());
-
-    GetResourceProfileRequest request3 = GetResourceProfileRequest.newInstance("minimum");
-    GetResourceProfileResponse response3 = interceptor.getResourceProfile(request3);
-
-    Assert.assertNotNull(response3);
-    Assert.assertEquals(4096, response3.getResource().getMemorySize());
-    Assert.assertEquals(4, response3.getResource().getVirtualCores());
-  }
-
-  @Test
-  public void testGetAttributesToNodes() throws Exception {
-    LOG.info("Test FederationClientInterceptor : Get AttributesToNodes request.");
-
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing getAttributesToNodes request " +
-        "or nodeAttributes.", () -> interceptor.getAttributesToNodes(null));
-
-    // normal request
-    GetAttributesToNodesResponse response =
-        interceptor.getAttributesToNodes(GetAttributesToNodesRequest.newInstance());
-
-    Assert.assertNotNull(response);
-    Map<NodeAttributeKey, List<NodeToAttributeValue>> attrs = response.getAttributesToNodes();
-    Assert.assertNotNull(attrs);
-    Assert.assertEquals(4, attrs.size());
-
-    NodeAttribute gpu = NodeAttribute.newInstance(NodeAttribute.PREFIX_CENTRALIZED, "GPU",
-        NodeAttributeType.STRING, "nvidia");
-    NodeToAttributeValue attributeValue1 =
-        NodeToAttributeValue.newInstance("0-host1", gpu.getAttributeValue());
-    NodeAttributeKey gpuKey = gpu.getAttributeKey();
-    Assert.assertTrue(attrs.get(gpuKey).contains(attributeValue1));
-  }
-
-  @Test
-  public void testClusterNodeAttributes() throws Exception {
-    LOG.info("Test FederationClientInterceptor : Get ClusterNodeAttributes request.");
-
-    // null request
-    LambdaTestUtils.intercept(YarnException.class, "Missing getClusterNodeAttributes request.",
-        () -> interceptor.getClusterNodeAttributes(null));
-
-    // normal request
-    GetClusterNodeAttributesResponse response =
-        interceptor.getClusterNodeAttributes(GetClusterNodeAttributesRequest.newInstance());
-
-    Assert.assertNotNull(response);
-    Set<NodeAttributeInfo> nodeAttributeInfos = response.getNodeAttributes();
-    Assert.assertNotNull(nodeAttributeInfos);
-    Assert.assertEquals(4, nodeAttributeInfos.size());
-
-    NodeAttributeInfo nodeAttributeInfo1 =
-        NodeAttributeInfo.newInstance(NodeAttributeKey.newInstance("GPU"),
-        NodeAttributeType.STRING);
-    Assert.assertTrue(nodeAttributeInfos.contains(nodeAttributeInfo1));
-
-    NodeAttributeInfo nodeAttributeInfo2 =
-        NodeAttributeInfo.newInstance(NodeAttributeKey.newInstance("OS"),
-        NodeAttributeType.STRING);
-    Assert.assertTrue(nodeAttributeInfos.contains(nodeAttributeInfo2));
-  }
-
-  @Test
-  public void testNodesToAttributes() throws Exception {
-    LOG.info("Test FederationClientInterceptor : Get NodesToAttributes request.");
-
-    // null request
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing getNodesToAttributes request or hostNames.",
-        () -> interceptor.getNodesToAttributes(null));
-
-    // normal request
-    Set<String> hostNames = Collections.singleton("0-host1");
-    GetNodesToAttributesResponse response =
-        interceptor.getNodesToAttributes(GetNodesToAttributesRequest.newInstance(hostNames));
-    Assert.assertNotNull(response);
-
-    Map<String, Set<NodeAttribute>> nodeAttributeMap = response.getNodeToAttributes();
-    Assert.assertNotNull(nodeAttributeMap);
-    Assert.assertEquals(1, nodeAttributeMap.size());
-
-    NodeAttribute gpu = NodeAttribute.newInstance(NodeAttribute.PREFIX_CENTRALIZED, "GPU",
-        NodeAttributeType.STRING, "nvida");
-    Assert.assertTrue(nodeAttributeMap.get("0-host1").contains(gpu));
-  }
-
-  @Test
-  public void testGetNewReservation() throws Exception {
-    LOG.info("Test FederationClientInterceptor : Get NewReservation request.");
-
-    // null request
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing getNewReservation request.", () -> interceptor.getNewReservation(null));
-
-    // normal request
-    GetNewReservationRequest request = GetNewReservationRequest.newInstance();
-    GetNewReservationResponse response = interceptor.getNewReservation(request);
-    Assert.assertNotNull(response);
-
-    ReservationId reservationId = response.getReservationId();
-    Assert.assertNotNull(reservationId);
-    Assert.assertTrue(reservationId.toString().contains("reservation"));
-    Assert.assertEquals(reservationId.getClusterTimestamp(), ResourceManager.getClusterTimeStamp());
-  }
-
-  @Test
-  public void testSubmitReservation() throws Exception {
-    LOG.info("Test FederationClientInterceptor : SubmitReservation request.");
-
-    // get new reservationId
-    GetNewReservationRequest request = GetNewReservationRequest.newInstance();
-    GetNewReservationResponse response = interceptor.getNewReservation(request);
-    Assert.assertNotNull(response);
-
-    // Submit Reservation
-    ReservationId reservationId = response.getReservationId();
-    ReservationDefinition rDefinition = createReservationDefinition(1024, 1);
-    ReservationSubmissionRequest rSubmissionRequest = ReservationSubmissionRequest.newInstance(
-        rDefinition, "decided", reservationId);
-
-    ReservationSubmissionResponse submissionResponse =
-        interceptor.submitReservation(rSubmissionRequest);
-    Assert.assertNotNull(submissionResponse);
-
-    SubClusterId subClusterId = stateStoreUtil.queryReservationHomeSC(reservationId);
-    Assert.assertNotNull(subClusterId);
-    Assert.assertTrue(subClusters.contains(subClusterId));
-  }
-
-  @Test
-  public void testSubmitReservationEmptyRequest() throws Exception {
-    LOG.info("Test FederationClientInterceptor : SubmitReservation request empty.");
-
-    String errorMsg =
-        "Missing submitReservation request or reservationId or reservation definition or queue.";
-
-    // null request1
-    LambdaTestUtils.intercept(YarnException.class, errorMsg,
-        () -> interceptor.submitReservation(null));
-
-    // null request2
-    ReservationSubmissionRequest request2 =
-        ReservationSubmissionRequest.newInstance(null, null, null);
-    LambdaTestUtils.intercept(YarnException.class, errorMsg,
-        () -> interceptor.submitReservation(request2));
-
-    // null request3
-    ReservationSubmissionRequest request3 =
-        ReservationSubmissionRequest.newInstance(null, "q1", null);
-    LambdaTestUtils.intercept(YarnException.class, errorMsg,
-        () -> interceptor.submitReservation(request3));
-
-    // null request4
-    ReservationId reservationId = ReservationId.newInstance(Time.now(), 1);
-    ReservationSubmissionRequest request4 =
-        ReservationSubmissionRequest.newInstance(null, null,  reservationId);
-    LambdaTestUtils.intercept(YarnException.class, errorMsg,
-        () -> interceptor.submitReservation(request4));
-
-    // null request5
-    long arrival = Time.now();
-    long deadline = arrival + (int)(DEFAULT_DURATION * 1.1);
-
-    ReservationRequest rRequest = ReservationRequest.newInstance(
-        Resource.newInstance(1024, 1), 1, 1, DEFAULT_DURATION);
-    ReservationRequest[] rRequests = new ReservationRequest[] {rRequest};
-    ReservationDefinition rDefinition = createReservationDefinition(arrival, deadline, rRequests,
-        ReservationRequestInterpreter.R_ALL, "u1");
-    ReservationSubmissionRequest request5 =
-        ReservationSubmissionRequest.newInstance(rDefinition, null,  reservationId);
-    LambdaTestUtils.intercept(YarnException.class, errorMsg,
-        () -> interceptor.submitReservation(request5));
-  }
-
-  @Test
-  public void testSubmitReservationMultipleSubmission() throws Exception {
-    LOG.info("Test FederationClientInterceptor: Submit Reservation - Multiple");
-
-    // get new reservationId
-    GetNewReservationRequest request = GetNewReservationRequest.newInstance();
-    GetNewReservationResponse response = interceptor.getNewReservation(request);
-    Assert.assertNotNull(response);
-
-    // First Submit Reservation
-    ReservationId reservationId = response.getReservationId();
-    ReservationDefinition rDefinition = createReservationDefinition(1024, 1);
-    ReservationSubmissionRequest rSubmissionRequest = ReservationSubmissionRequest.newInstance(
-        rDefinition, "decided", reservationId);
-    ReservationSubmissionResponse submissionResponse =
-        interceptor.submitReservation(rSubmissionRequest);
-    Assert.assertNotNull(submissionResponse);
-
-    SubClusterId subClusterId1 = stateStoreUtil.queryReservationHomeSC(reservationId);
-    Assert.assertNotNull(subClusterId1);
-    Assert.assertTrue(subClusters.contains(subClusterId1));
-
-    // First Retry, repeat the submission
-    ReservationSubmissionResponse submissionResponse1 =
-        interceptor.submitReservation(rSubmissionRequest);
-    Assert.assertNotNull(submissionResponse1);
-
-    // Expect reserved clusters to be consistent
-    SubClusterId subClusterId2 = stateStoreUtil.queryReservationHomeSC(reservationId);
-    Assert.assertNotNull(subClusterId2);
-    Assert.assertEquals(subClusterId1, subClusterId2);
-  }
-
-  @Test
-  public void testUpdateReservation() throws Exception {
-    LOG.info("Test FederationClientInterceptor : UpdateReservation request.");
-
-    // get new reservationId
-    GetNewReservationRequest request = GetNewReservationRequest.newInstance();
-    GetNewReservationResponse response = interceptor.getNewReservation(request);
-    Assert.assertNotNull(response);
-
-    // allow plan follower to synchronize, manually trigger an assignment
-    Map<SubClusterId, MockRM> mockRMs = interceptor.getMockRMs();
-    for (MockRM mockRM : mockRMs.values()) {
-      ReservationSystem reservationSystem = mockRM.getReservationSystem();
-      reservationSystem.synchronizePlan("root.decided", true);
-    }
-
-    // Submit Reservation
-    ReservationId reservationId = response.getReservationId();
-    ReservationDefinition rDefinition = createReservationDefinition(1024, 1);
-    ReservationSubmissionRequest rSubmissionRequest = ReservationSubmissionRequest.newInstance(
-        rDefinition, "decided", reservationId);
-
-    ReservationSubmissionResponse submissionResponse =
-        interceptor.submitReservation(rSubmissionRequest);
-    Assert.assertNotNull(submissionResponse);
-
-    // Update Reservation
-    ReservationDefinition rDefinition2 = createReservationDefinition(2048, 1);
-    ReservationUpdateRequest updateRequest =
-        ReservationUpdateRequest.newInstance(rDefinition2, reservationId);
-    ReservationUpdateResponse updateResponse =
-        interceptor.updateReservation(updateRequest);
-    Assert.assertNotNull(updateResponse);
-
-    SubClusterId subClusterId = stateStoreUtil.queryReservationHomeSC(reservationId);
-    Assert.assertNotNull(subClusterId);
-  }
-
-  @Test
-  public void testDeleteReservation() throws Exception {
-    LOG.info("Test FederationClientInterceptor : DeleteReservation request.");
-
-    // get new reservationId
-    GetNewReservationRequest request = GetNewReservationRequest.newInstance();
-    GetNewReservationResponse response = interceptor.getNewReservation(request);
-    Assert.assertNotNull(response);
-
-    // allow plan follower to synchronize, manually trigger an assignment
-    Map<SubClusterId, MockRM> mockRMs = interceptor.getMockRMs();
-    for (MockRM mockRM : mockRMs.values()) {
-      ReservationSystem reservationSystem = mockRM.getReservationSystem();
-      reservationSystem.synchronizePlan("root.decided", true);
-    }
-
-    // Submit Reservation
-    ReservationId reservationId = response.getReservationId();
-    ReservationDefinition rDefinition = createReservationDefinition(1024, 1);
-    ReservationSubmissionRequest rSubmissionRequest = ReservationSubmissionRequest.newInstance(
-        rDefinition, "decided", reservationId);
-
-    ReservationSubmissionResponse submissionResponse =
-        interceptor.submitReservation(rSubmissionRequest);
-    Assert.assertNotNull(submissionResponse);
-
-    // Delete Reservation
-    ReservationDeleteRequest deleteRequest = ReservationDeleteRequest.newInstance(reservationId);
-    ReservationDeleteResponse deleteResponse = interceptor.deleteReservation(deleteRequest);
-    Assert.assertNotNull(deleteResponse);
-
-    LambdaTestUtils.intercept(YarnException.class,
-        "Reservation " + reservationId + " does not exist",
-        () -> stateStoreUtil.queryReservationHomeSC(reservationId));
-  }
-
-
-  private ReservationDefinition createReservationDefinition(int memory, int core) {
-    // get reservationId
-    long arrival = Time.now();
-    long deadline = arrival + (int)(DEFAULT_DURATION * 1.1);
-
-    ReservationRequest rRequest = ReservationRequest.newInstance(
-        Resource.newInstance(memory, core), 1, 1, DEFAULT_DURATION);
-    ReservationRequest[] rRequests = new ReservationRequest[] {rRequest};
-
-    ReservationDefinition rDefinition = createReservationDefinition(arrival, deadline, rRequests,
-        ReservationRequestInterpreter.R_ALL, "u1");
-
-    return rDefinition;
-  }
-
-  /**
-   * This method is used to create a ReservationDefinition.
-   *
-   * @param arrival Job arrival time
-   * @param deadline Job deadline
-   * @param reservationRequests reservationRequest Array
-   * @param rType Enumeration of various types of
-   *              dependencies among multiple ReservationRequest
-   * @param username username
-   * @return ReservationDefinition
-   */
-  private ReservationDefinition createReservationDefinition(long arrival,
-      long deadline, ReservationRequest[] reservationRequests,
-      ReservationRequestInterpreter rType, String username) {
-    ReservationRequests requests = ReservationRequests
-        .newInstance(Arrays.asList(reservationRequests), rType);
-    return ReservationDefinition.newInstance(arrival, deadline,
-        requests, username, "0", Priority.UNDEFINED);
-  }
-
-  @Test
-  public void testGetNumMinThreads() {
-    // If we don't configure YarnConfiguration.ROUTER_USER_CLIENT_THREAD_POOL_MINIMUM_POOL_SIZE,
-    // we expect to get 5 threads
-    int minThreads = interceptor.getNumMinThreads(this.getConf());
-    Assert.assertEquals(5, minThreads);
-
-    // If we configure YarnConfiguration.ROUTER_USER_CLIENT_THREAD_POOL_MINIMUM_POOL_SIZE,
-    // we expect to get 3 threads
-    this.getConf().unset(YarnConfiguration.ROUTER_USER_CLIENT_THREADS_SIZE);
-    this.getConf().setInt(YarnConfiguration.ROUTER_USER_CLIENT_THREAD_POOL_MINIMUM_POOL_SIZE, 3);
-    int minThreads2 = interceptor.getNumMinThreads(this.getConf());
-    Assert.assertEquals(3, minThreads2);
-  }
-
-  @Test
-  public void testGetNumMaxThreads() {
-    // If we don't configure YarnConfiguration.ROUTER_USER_CLIENT_THREAD_POOL_MAXIMUM_POOL_SIZE,
-    // we expect to get 5 threads
-    int minThreads = interceptor.getNumMaxThreads(this.getConf());
-    Assert.assertEquals(5, minThreads);
-
-    // If we configure YarnConfiguration.ROUTER_USER_CLIENT_THREAD_POOL_MAXIMUM_POOL_SIZE,
-    // we expect to get 8 threads
-    this.getConf().unset(YarnConfiguration.ROUTER_USER_CLIENT_THREADS_SIZE);
-    this.getConf().setInt(YarnConfiguration.ROUTER_USER_CLIENT_THREAD_POOL_MAXIMUM_POOL_SIZE, 8);
-    int minThreads2 = interceptor.getNumMaxThreads(this.getConf());
-    Assert.assertEquals(8, minThreads2);
-  }
-
-  @Test
-  public void testGetDelegationToken() throws IOException, YarnException {
-
-    // We design such a unit test to check
-    // that the execution of the GetDelegationToken method is as expected.
-    //
-    // 1. Apply for a DelegationToken for renewer1,
-    // the Router returns the DelegationToken of the user, and the KIND of the token is
-    // RM_DELEGATION_TOKEN
-    //
-    // 2. We maintain the compatibility with RMDelegationTokenIdentifier,
-    // we can serialize the token into RMDelegationTokenIdentifier.
-    //
-    // 3. We can get the issueDate, and compare the data in the StateStore,
-    // the data should be consistent.
-
-    // Step1. We apply for DelegationToken for renewer1
-    // Both response & delegationToken cannot be empty
-    GetDelegationTokenRequest request = mock(GetDelegationTokenRequest.class);
-    when(request.getRenewer()).thenReturn("renewer1");
-    GetDelegationTokenResponse response = interceptor.getDelegationToken(request);
-    Assert.assertNotNull(response);
-    Token delegationToken = response.getRMDelegationToken();
-    Assert.assertNotNull(delegationToken);
-    Assert.assertEquals("RM_DELEGATION_TOKEN", delegationToken.getKind());
-
-    // Step2. Serialize the returned Token as RMDelegationTokenIdentifier.
-    org.apache.hadoop.security.token.Token<RMDelegationTokenIdentifier> token =
-        ConverterUtils.convertFromYarn(delegationToken, (Text) null);
-    RMDelegationTokenIdentifier rMDelegationTokenIdentifier = token.decodeIdentifier();
-    Assert.assertNotNull(rMDelegationTokenIdentifier);
-
-    // Step3. Verify the returned data of the token.
-    String renewer = rMDelegationTokenIdentifier.getRenewer().toString();
-    long issueDate = rMDelegationTokenIdentifier.getIssueDate();
-    long maxDate = rMDelegationTokenIdentifier.getMaxDate();
-    Assert.assertEquals("renewer1", renewer);
-
-    long tokenMaxLifetime = this.getConf().getLong(
-        YarnConfiguration.RM_DELEGATION_TOKEN_MAX_LIFETIME_KEY,
-        YarnConfiguration.RM_DELEGATION_TOKEN_MAX_LIFETIME_DEFAULT);
-    Assert.assertEquals(issueDate + tokenMaxLifetime, maxDate);
-
-    RouterRMDTSecretManagerState managerState = stateStore.getRouterRMSecretManagerState();
-    Assert.assertNotNull(managerState);
-
-    Map<RMDelegationTokenIdentifier, RouterStoreToken> delegationTokenState =
-        managerState.getTokenState();
-    Assert.assertNotNull(delegationTokenState);
-    Assert.assertTrue(delegationTokenState.containsKey(rMDelegationTokenIdentifier));
-
-    long tokenRenewInterval = this.getConf().getLong(
-        YarnConfiguration.RM_DELEGATION_TOKEN_RENEW_INTERVAL_KEY,
-        YarnConfiguration.RM_DELEGATION_TOKEN_RENEW_INTERVAL_DEFAULT);
-    RouterStoreToken resultRouterStoreToken = delegationTokenState.get(rMDelegationTokenIdentifier);
-    Assert.assertNotNull(resultRouterStoreToken);
-    long renewDate = resultRouterStoreToken.getRenewDate();
-    Assert.assertEquals(issueDate + tokenRenewInterval, renewDate);
-  }
-
-  @Test
-  public void testRenewDelegationToken() throws IOException, YarnException {
-
-    // We design such a unit test to check
-    // that the execution of the GetDelegationToken method is as expected
-    // 1. Call GetDelegationToken to apply for delegationToken.
-    // 2. Call renewDelegationToken to refresh delegationToken.
-    // By looking at the code of AbstractDelegationTokenSecretManager#renewToken,
-    // we know that renewTime is calculated as Math.min(id.getMaxDate(), now + tokenRenewInterval)
-    // so renewTime will be less than or equal to maxDate.
-    // 3. We will compare whether the expirationTime returned to the
-    // client is consistent with the renewDate in the stateStore.
-
-    // Step1. Call GetDelegationToken to apply for delegationToken.
-    GetDelegationTokenRequest request = mock(GetDelegationTokenRequest.class);
-    when(request.getRenewer()).thenReturn("renewer2");
-    GetDelegationTokenResponse response = interceptor.getDelegationToken(request);
-    Assert.assertNotNull(response);
-    Token delegationToken = response.getRMDelegationToken();
-
-    org.apache.hadoop.security.token.Token<RMDelegationTokenIdentifier> token =
-        ConverterUtils.convertFromYarn(delegationToken, (Text) null);
-    RMDelegationTokenIdentifier rMDelegationTokenIdentifier = token.decodeIdentifier();
-    String renewer = rMDelegationTokenIdentifier.getRenewer().toString();
-    long maxDate = rMDelegationTokenIdentifier.getMaxDate();
-    Assert.assertEquals("renewer2", renewer);
-
-    // Step2. Call renewDelegationToken to refresh delegationToken.
-    RenewDelegationTokenRequest renewRequest = Records.newRecord(RenewDelegationTokenRequest.class);
-    renewRequest.setDelegationToken(delegationToken);
-    RenewDelegationTokenResponse renewResponse = interceptor.renewDelegationToken(renewRequest);
-    Assert.assertNotNull(renewResponse);
-
-    long expDate = renewResponse.getNextExpirationTime();
-    Assert.assertTrue(expDate <= maxDate);
-
-    // Step3. Compare whether the expirationTime returned to
-    // the client is consistent with the renewDate in the stateStore
-    RouterRMDTSecretManagerState managerState = stateStore.getRouterRMSecretManagerState();
-    Map<RMDelegationTokenIdentifier, RouterStoreToken> delegationTokenState =
-        managerState.getTokenState();
-    Assert.assertNotNull(delegationTokenState);
-    Assert.assertTrue(delegationTokenState.containsKey(rMDelegationTokenIdentifier));
-    RouterStoreToken resultRouterStoreToken = delegationTokenState.get(rMDelegationTokenIdentifier);
-    Assert.assertNotNull(resultRouterStoreToken);
-    long renewDate = resultRouterStoreToken.getRenewDate();
-    Assert.assertEquals(expDate, renewDate);
-  }
-
-  @Test
-  public void testCancelDelegationToken() throws IOException, YarnException {
-
-    // We design such a unit test to check
-    // that the execution of the CancelDelegationToken method is as expected
-    // 1. Call GetDelegationToken to apply for delegationToken.
-    // 2. Call CancelDelegationToken to cancel delegationToken.
-    // 3. Query the data in the StateStore and confirm that the Delegation has been deleted.
-
-    // Step1. Call GetDelegationToken to apply for delegationToken.
-    GetDelegationTokenRequest request = mock(GetDelegationTokenRequest.class);
-    when(request.getRenewer()).thenReturn("renewer3");
-    GetDelegationTokenResponse response = interceptor.getDelegationToken(request);
-    Assert.assertNotNull(response);
-    Token delegationToken = response.getRMDelegationToken();
-
-    // Step2. Call CancelDelegationToken to cancel delegationToken.
-    CancelDelegationTokenRequest cancelTokenRequest =
-        CancelDelegationTokenRequest.newInstance(delegationToken);
-    CancelDelegationTokenResponse cancelTokenResponse =
-        interceptor.cancelDelegationToken(cancelTokenRequest);
-    Assert.assertNotNull(cancelTokenResponse);
-
-    // Step3. Query the data in the StateStore and confirm that the Delegation has been deleted.
-    // At this point, the size of delegationTokenState should be 0.
-    RouterRMDTSecretManagerState managerState = stateStore.getRouterRMSecretManagerState();
-    Map<RMDelegationTokenIdentifier, RouterStoreToken> delegationTokenState =
-        managerState.getTokenState();
-    Assert.assertNotNull(delegationTokenState);
-    Assert.assertEquals(0, delegationTokenState.size());
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestFederationClientInterceptorRetry.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestFederationClientInterceptorRetry.java
deleted file mode 100644
index f0ecf8367cc..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestFederationClientInterceptorRetry.java
+++ /dev/null
@@ -1,431 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.FEDERATION_POLICY_MANAGER;
-import static org.hamcrest.CoreMatchers.is;
-import static org.mockito.Mockito.mock;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.List;
-
-import org.apache.hadoop.test.LambdaTestUtils;
-import org.apache.hadoop.yarn.MockApps;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
-import org.apache.hadoop.yarn.api.records.ContainerLaunchContext;
-import org.apache.hadoop.yarn.api.records.Priority;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.federation.policies.manager.UniformBroadcastPolicyManager;
-import org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore;
-import org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster;
-import org.apache.hadoop.yarn.server.federation.store.records.GetApplicationHomeSubClusterRequest;
-import org.apache.hadoop.yarn.server.federation.store.records.GetApplicationHomeSubClusterResponse;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreTestUtil;
-import org.apache.hadoop.yarn.server.resourcemanager.ResourceManager;
-import org.apache.hadoop.yarn.util.resource.Resources;
-import org.junit.Assert;
-import org.junit.Assume;
-import org.junit.Test;
-import org.junit.runner.RunWith;
-import org.junit.runners.Parameterized;
-import org.junit.runners.Parameterized.Parameters;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import static org.apache.hadoop.yarn.server.federation.policies.FederationPolicyUtils.NO_ACTIVE_SUBCLUSTER_AVAILABLE;
-
-/**
- * Extends the {@code BaseRouterClientRMTest} and overrides methods in order to
- * use the {@code RouterClientRMService} pipeline test cases for testing the
- * {@code FederationInterceptor} class. The tests for
- * {@code RouterClientRMService} has been written cleverly so that it can be
- * reused to validate different request interceptor chains.
- *
- * It tests the case with SubClusters down and the Router logic of retries. We
- * have 1 good SubCluster and 2 bad ones for all the tests.
- */
-@RunWith(Parameterized.class)
-public class TestFederationClientInterceptorRetry
-    extends BaseRouterClientRMTest {
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestFederationClientInterceptorRetry.class);
-
-  @Parameters
-  public static Collection<String[]> getParameters() {
-    return Arrays.asList(new String[][] {{UniformBroadcastPolicyManager.class.getName()},
-        {TestSequentialBroadcastPolicyManager.class.getName()}});
-  }
-
-  private TestableFederationClientInterceptor interceptor;
-  private MemoryFederationStateStore stateStore;
-  private FederationStateStoreTestUtil stateStoreUtil;
-  private String routerPolicyManagerName;
-
-  private String user = "test-user";
-
-  // running and registered
-  private static SubClusterId good;
-
-  // registered but not running
-  private static SubClusterId bad1;
-  private static SubClusterId bad2;
-
-  private static List<SubClusterId> scs = new ArrayList<>();
-
-  public TestFederationClientInterceptorRetry(String policyManagerName) {
-    this.routerPolicyManagerName = policyManagerName;
-  }
-
-  @Override
-  public void setUp() throws IOException {
-    super.setUpConfig();
-    interceptor = new TestableFederationClientInterceptor();
-
-    stateStore = new MemoryFederationStateStore();
-    stateStore.init(this.getConf());
-    FederationStateStoreFacade.getInstance(getConf()).reinitialize(stateStore,
-        getConf());
-    stateStoreUtil = new FederationStateStoreTestUtil(stateStore);
-
-    interceptor.setConf(this.getConf());
-    interceptor.init(user);
-
-    // Create SubClusters
-    good = SubClusterId.newInstance("0");
-    bad1 = SubClusterId.newInstance("1");
-    bad2 = SubClusterId.newInstance("2");
-    scs.add(good);
-    scs.add(bad1);
-    scs.add(bad2);
-
-    // The mock RM will not start in these SubClusters, this is done to simulate
-    // a SubCluster down
-
-    interceptor.registerBadSubCluster(bad1);
-    interceptor.registerBadSubCluster(bad2);
-  }
-
-  @Override
-  public void tearDown() {
-    interceptor.shutdown();
-    super.tearDown();
-  }
-
-  private void setupCluster(List<SubClusterId> scsToRegister) throws YarnException {
-
-    try {
-      // Clean up the StateStore before every test
-      stateStoreUtil.deregisterAllSubClusters();
-
-      for (SubClusterId sc : scsToRegister) {
-        stateStoreUtil.registerSubCluster(sc);
-      }
-    } catch (YarnException e) {
-      LOG.error(e.getMessage());
-      Assert.fail();
-    }
-  }
-
-  @Override
-  protected YarnConfiguration createConfiguration() {
-
-    YarnConfiguration conf = new YarnConfiguration();
-    conf.setBoolean(YarnConfiguration.FEDERATION_ENABLED, true);
-    String mockPassThroughInterceptorClass =
-        PassThroughClientRequestInterceptor.class.getName();
-
-    // Create a request interceptor pipeline for testing. The last one in the
-    // chain is the federation interceptor that calls the mock resource manager.
-    // The others in the chain will simply forward it to the next one in the
-    // chain
-    conf.set(YarnConfiguration.ROUTER_CLIENTRM_INTERCEPTOR_CLASS_PIPELINE,
-        mockPassThroughInterceptorClass + "," + mockPassThroughInterceptorClass
-            + "," + TestableFederationClientInterceptor.class.getName());
-
-    conf.set(FEDERATION_POLICY_MANAGER, this.routerPolicyManagerName);
-
-    // Disable StateStoreFacade cache
-    conf.setInt(YarnConfiguration.FEDERATION_CACHE_TIME_TO_LIVE_SECS, 0);
-
-    return conf;
-  }
-
-  /**
-   * This test validates the correctness of GetNewApplication in case the
-   * cluster is composed of only 1 bad SubCluster.
-   */
-  @Test
-  public void testGetNewApplicationOneBadSC() throws Exception {
-
-    LOG.info("Test getNewApplication with one bad SubCluster");
-    setupCluster(Arrays.asList(bad2));
-
-    GetNewApplicationRequest request = GetNewApplicationRequest.newInstance();
-    LambdaTestUtils.intercept(YarnException.class, NO_ACTIVE_SUBCLUSTER_AVAILABLE,
-        () -> interceptor.getNewApplication(request));
-  }
-
-  /**
-   * This test validates the correctness of GetNewApplication in case the
-   * cluster is composed of only 2 bad SubClusters.
-   */
-  @Test
-  public void testGetNewApplicationTwoBadSCs() throws Exception {
-
-    LOG.info("Test getNewApplication with two bad SubClusters");
-    setupCluster(Arrays.asList(bad1, bad2));
-
-    GetNewApplicationRequest request = GetNewApplicationRequest.newInstance();
-    LambdaTestUtils.intercept(YarnException.class, NO_ACTIVE_SUBCLUSTER_AVAILABLE,
-        () -> interceptor.getNewApplication(request));
-  }
-
-  /**
-   * This test validates the correctness of GetNewApplication in case the
-   * cluster is composed of only 1 bad SubCluster and 1 good one.
-   */
-  @Test
-  public void testGetNewApplicationOneBadOneGood() throws YarnException, IOException {
-
-    LOG.info("Test getNewApplication with one bad, one good SC");
-    setupCluster(Arrays.asList(good, bad2));
-    GetNewApplicationRequest request = GetNewApplicationRequest.newInstance();
-    GetNewApplicationResponse response = interceptor.getNewApplication(request);
-
-    Assert.assertNotNull(response);
-    Assert.assertEquals(ResourceManager.getClusterTimeStamp(),
-        response.getApplicationId().getClusterTimestamp());
-  }
-
-  /**
-   * This test validates the correctness of SubmitApplication in case the
-   * cluster is composed of only 1 bad SubCluster.
-   */
-  @Test
-  public void testSubmitApplicationOneBadSC() throws Exception {
-
-    LOG.info("Test submitApplication with one bad SubCluster");
-    setupCluster(Arrays.asList(bad2));
-
-    final ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-
-    final SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-    LambdaTestUtils.intercept(YarnException.class, NO_ACTIVE_SUBCLUSTER_AVAILABLE,
-        () -> interceptor.submitApplication(request));
-  }
-
-  private SubmitApplicationRequest mockSubmitApplicationRequest(ApplicationId appId) {
-    ContainerLaunchContext amContainerSpec = mock(ContainerLaunchContext.class);
-    ApplicationSubmissionContext context = ApplicationSubmissionContext
-        .newInstance(appId, MockApps.newAppName(), "q1",
-        Priority.newInstance(0), amContainerSpec, false, false, -1,
-        Resources.createResource(YarnConfiguration.DEFAULT_RM_SCHEDULER_MINIMUM_ALLOCATION_MB),
-        "MockApp");
-    SubmitApplicationRequest request = SubmitApplicationRequest.newInstance(context);
-    return request;
-  }
-
-  /**
-   * This test validates the correctness of SubmitApplication in case the
-   * cluster is composed of only 2 bad SubClusters.
-   */
-  @Test
-  public void testSubmitApplicationTwoBadSCs() throws Exception {
-
-    LOG.info("Test submitApplication with two bad SubClusters.");
-    setupCluster(Arrays.asList(bad1, bad2));
-
-    final ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-
-    final SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-    LambdaTestUtils.intercept(YarnException.class, NO_ACTIVE_SUBCLUSTER_AVAILABLE,
-        () -> interceptor.submitApplication(request));
-  }
-
-  /**
-   * This test validates the correctness of SubmitApplication in case the
-   * cluster is composed of only 1 bad SubCluster and a good one.
-   */
-  @Test
-  public void testSubmitApplicationOneBadOneGood()
-      throws YarnException, IOException, InterruptedException {
-
-    LOG.info("Test submitApplication with one bad, one good SC.");
-    setupCluster(Arrays.asList(good, bad2));
-
-    final ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-
-    final SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-    SubmitApplicationResponse response = interceptor.submitApplication(request);
-    Assert.assertNotNull(response);
-
-    GetApplicationHomeSubClusterRequest getAppRequest =
-        GetApplicationHomeSubClusterRequest.newInstance(appId);
-    GetApplicationHomeSubClusterResponse getAppResponse =
-        stateStore.getApplicationHomeSubCluster(getAppRequest);
-    Assert.assertNotNull(getAppResponse);
-
-    ApplicationHomeSubCluster responseHomeSubCluster =
-        getAppResponse.getApplicationHomeSubCluster();
-    Assert.assertNotNull(responseHomeSubCluster);
-    SubClusterId respSubClusterId = responseHomeSubCluster.getHomeSubCluster();
-    Assert.assertEquals(good, respSubClusterId);
-  }
-
-  @Test
-  public void testSubmitApplicationTwoBadOneGood() throws Exception {
-
-    LOG.info("Test submitApplication with two bad, one good SC.");
-
-    // This test must require the TestSequentialRouterPolicy policy
-    Assume.assumeThat(routerPolicyManagerName,
-        is(TestSequentialBroadcastPolicyManager.class.getName()));
-
-    setupCluster(Arrays.asList(bad1, bad2, good));
-    final ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-
-    // Use the TestSequentialRouterPolicy strategy,
-    // which will sort the SubClusterId because good=0, bad1=1, bad2=2
-    // We will get 2, 1, 0 [bad2, bad1, good]
-    // Set the retryNum to 1
-    // 1st time will use bad2, 2nd time will use bad1
-    // bad1 is updated to stateStore
-    interceptor.setNumSubmitRetries(1);
-    final SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-    LambdaTestUtils.intercept(YarnException.class, "RM is stopped",
-        () -> interceptor.submitApplication(request));
-
-    // We will get bad1
-    checkSubmitSubCluster(appId, bad1);
-
-    // Set the retryNum to 2
-    // 1st time will use bad2, 2nd time will use bad1, 3rd good
-    interceptor.setNumSubmitRetries(2);
-    SubmitApplicationResponse submitAppResponse = interceptor.submitApplication(request);
-    Assert.assertNotNull(submitAppResponse);
-
-    // We will get good
-    checkSubmitSubCluster(appId, good);
-  }
-
-  private void checkSubmitSubCluster(ApplicationId appId, SubClusterId expectSubCluster)
-      throws YarnException {
-    GetApplicationHomeSubClusterRequest getAppRequest =
-        GetApplicationHomeSubClusterRequest.newInstance(appId);
-    GetApplicationHomeSubClusterResponse getAppResponse =
-        stateStore.getApplicationHomeSubCluster(getAppRequest);
-    Assert.assertNotNull(getAppResponse);
-    Assert.assertNotNull(getAppResponse);
-    ApplicationHomeSubCluster responseHomeSubCluster =
-        getAppResponse.getApplicationHomeSubCluster();
-    Assert.assertNotNull(responseHomeSubCluster);
-    SubClusterId respSubClusterId = responseHomeSubCluster.getHomeSubCluster();
-    Assert.assertEquals(expectSubCluster, respSubClusterId);
-  }
-
-  @Test
-  public void testSubmitApplicationTwoBadNodeWithRealError() throws Exception {
-    LOG.info("Test submitApplication with two bad SubClusters.");
-    setupCluster(Arrays.asList(bad1, bad2));
-    interceptor.setNumSubmitRetries(1);
-
-    final ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 5);
-
-    final SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-
-    LambdaTestUtils.intercept(YarnException.class, "RM is stopped",
-        () -> interceptor.submitApplication(request));
-  }
-
-  @Test
-  public void testSubmitApplicationOneBadNodeWithRealError() throws Exception {
-    LOG.info("Test submitApplication with one bad SubClusters.");
-    setupCluster(Arrays.asList(bad1));
-    interceptor.setNumSubmitRetries(0);
-
-    final ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 6);
-
-    final SubmitApplicationRequest request = mockSubmitApplicationRequest(appId);
-
-    LambdaTestUtils.intercept(YarnException.class, "RM is stopped",
-        () -> interceptor.submitApplication(request));
-  }
-
-  @Test
-  public void testGetClusterMetricsTwoBadNodeWithRealError() throws Exception {
-    LOG.info("Test getClusterMetrics with two bad SubClusters.");
-    setupCluster(Arrays.asList(bad1, bad2));
-    GetClusterMetricsRequest request = GetClusterMetricsRequest.newInstance();
-
-    LambdaTestUtils.intercept(YarnException.class,
-        "subClusterId 1 exec getClusterMetrics error RM is stopped.",
-        () -> interceptor.getClusterMetrics(request));
-
-    LambdaTestUtils.intercept(YarnException.class,
-        "subClusterId 2 exec getClusterMetrics error RM is stopped.",
-        () -> interceptor.getClusterMetrics(request));
-  }
-
-  @Test
-  public void testGetClusterMetricsOneBadNodeWithRealError() throws Exception {
-    LOG.info("Test getClusterMetrics with one bad SubClusters.");
-    setupCluster(Arrays.asList(bad1));
-    GetClusterMetricsRequest request = GetClusterMetricsRequest.newInstance();
-
-    LambdaTestUtils.intercept(YarnException.class,
-        "subClusterId 1 exec getClusterMetrics error RM is stopped.",
-        () -> interceptor.getClusterMetrics(request));
-  }
-
-  @Test
-  public void testGetClusterMetricsOneBadOneGoodNodeWithRealError() throws Exception {
-    LOG.info("Test getClusterMetrics with one bad and one good SubCluster.");
-    setupCluster(Arrays.asList(bad1, good));
-    GetClusterMetricsRequest request = GetClusterMetricsRequest.newInstance();
-
-    GetClusterMetricsResponse clusterMetrics = interceptor.getClusterMetrics(request);
-    Assert.assertNotNull(clusterMetrics);
-
-    // If partial results are not allowed to be returned, an exception will be thrown.
-    interceptor.setAllowPartialResult(false);
-    LambdaTestUtils.intercept(YarnException.class,
-        "subClusterId 1 exec getClusterMetrics error RM is stopped.",
-        () -> interceptor.getClusterMetrics(request));
-    interceptor.setAllowPartialResult(true);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestRouterClientRMService.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestRouterClientRMService.java
deleted file mode 100644
index a7bec085d1e..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestRouterClientRMService.java
+++ /dev/null
@@ -1,270 +0,0 @@
-/**
-* Licensed to the Apache Software Foundation (ASF) under one
-* or more contributor license agreements.  See the NOTICE file
-* distributed with this work for additional information
-* regarding copyright ownership.  The ASF licenses this file
-* to you under the Apache License, Version 2.0 (the
-* "License"); you may not use this file except in compliance
-* with the License.  You may obtain a copy of the License at
-*
-*     http://www.apache.org/licenses/LICENSE-2.0
-*
-* Unless required by applicable law or agreed to in writing, software
-* distributed under the License is distributed on an "AS IS" BASIS,
-* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-* See the License for the specific language governing permissions and
-* limitations under the License.
-*/
-
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import java.io.IOException;
-import java.security.PrivilegedExceptionAction;
-import java.util.Map;
-
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNewReservationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.KillApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.MoveApplicationAcrossQueuesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationResponse;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.router.clientrm.RouterClientRMService.RequestInterceptorChainWrapper;
-import org.junit.Assert;
-import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * Test class to validate the ClientRM Service inside the Router.
- */
-public class TestRouterClientRMService extends BaseRouterClientRMTest {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestRouterClientRMService.class);
-
-  /**
-   * Tests if the pipeline is created properly.
-   */
-  @Test
-  public void testRequestInterceptorChainCreation() throws Exception {
-    ClientRequestInterceptor root =
-        super.getRouterClientRMService().createRequestInterceptorChain();
-    int index = 0;
-    while (root != null) {
-      // The current pipeline is:
-      // PassThroughClientRequestInterceptor - index = 0
-      // PassThroughClientRequestInterceptor - index = 1
-      // PassThroughClientRequestInterceptor - index = 2
-      // MockClientRequestInterceptor - index = 3
-      switch (index) {
-      case 0: // Fall to the next case
-      case 1: // Fall to the next case
-      case 2:
-        // If index is equal to 0,1 or 2 we fall in this check
-        Assert.assertEquals(PassThroughClientRequestInterceptor.class.getName(),
-            root.getClass().getName());
-        break;
-      case 3:
-        Assert.assertEquals(MockClientRequestInterceptor.class.getName(),
-            root.getClass().getName());
-        break;
-      default:
-        Assert.fail();
-      }
-      root = root.getNextInterceptor();
-      index++;
-    }
-    Assert.assertEquals("The number of interceptors in chain does not match", 4,
-        index);
-  }
-
-  /**
-   * Test if the RouterClientRM forwards all the requests to the MockRM and get
-   * back the responses.
-   */
-  @Test
-  public void testRouterClientRMServiceE2E() throws Exception {
-
-    String user = "test1";
-
-    LOG.info("testRouterClientRMServiceE2E - Get New Application");
-
-    GetNewApplicationResponse responseGetNewApp = getNewApplication(user);
-    Assert.assertNotNull(responseGetNewApp);
-
-    LOG.info("testRouterClientRMServiceE2E - Submit Application");
-
-    SubmitApplicationResponse responseSubmitApp =
-        submitApplication(responseGetNewApp.getApplicationId(), user);
-    Assert.assertNotNull(responseSubmitApp);
-
-    LOG.info("testRouterClientRMServiceE2E - Get Cluster Metrics");
-
-    GetClusterMetricsResponse responseGetClusterMetrics =
-        getClusterMetrics(user);
-    Assert.assertNotNull(responseGetClusterMetrics);
-
-    LOG.info("testRouterClientRMServiceE2E - Get Cluster Nodes");
-
-    GetClusterNodesResponse responseGetClusterNodes = getClusterNodes(user);
-    Assert.assertNotNull(responseGetClusterNodes);
-
-    LOG.info("testRouterClientRMServiceE2E - Get Queue Info");
-
-    GetQueueInfoResponse responseGetQueueInfo = getQueueInfo(user);
-    Assert.assertNotNull(responseGetQueueInfo);
-
-    LOG.info("testRouterClientRMServiceE2E - Get Queue User");
-
-    GetQueueUserAclsInfoResponse responseGetQueueUser = getQueueUserAcls(user);
-    Assert.assertNotNull(responseGetQueueUser);
-
-    LOG.info("testRouterClientRMServiceE2E - Get Cluster Node");
-
-    GetClusterNodeLabelsResponse responseGetClusterNode =
-        getClusterNodeLabels(user);
-    Assert.assertNotNull(responseGetClusterNode);
-
-    LOG.info("testRouterClientRMServiceE2E - Move Application Across Queues");
-
-    MoveApplicationAcrossQueuesResponse responseMoveApp =
-        moveApplicationAcrossQueues(user, responseGetNewApp.getApplicationId());
-    Assert.assertNotNull(responseMoveApp);
-
-    LOG.info("testRouterClientRMServiceE2E - Get New Reservation");
-
-    GetNewReservationResponse getNewReservationResponse =
-        getNewReservation(user);
-
-    LOG.info("testRouterClientRMServiceE2E - Submit Reservation");
-
-    ReservationSubmissionResponse responseSubmitReser =
-        submitReservation(user, getNewReservationResponse.getReservationId());
-    Assert.assertNotNull(responseSubmitReser);
-
-    LOG.info("testRouterClientRMServiceE2E - Update Reservation");
-
-    ReservationUpdateResponse responseUpdateReser =
-        updateReservation(user, getNewReservationResponse.getReservationId());
-    Assert.assertNotNull(responseUpdateReser);
-
-    LOG.info("testRouterClientRMServiceE2E - Delete Reservation");
-
-    ReservationDeleteResponse responseDeleteReser =
-        deleteReservation(user, getNewReservationResponse.getReservationId());
-    Assert.assertNotNull(responseDeleteReser);
-
-    LOG.info("testRouterClientRMServiceE2E - Kill Application");
-
-    KillApplicationResponse responseKillApp =
-        forceKillApplication(responseGetNewApp.getApplicationId(), user);
-    Assert.assertNotNull(responseKillApp);
-  }
-
-  /**
-   * Test if the different chains for users are generated, and LRU cache is
-   * working as expected.
-   */
-  @Test
-  public void testUsersChainMapWithLRUCache()
-      throws YarnException, IOException, InterruptedException {
-
-    Map<String, RequestInterceptorChainWrapper> pipelines;
-    RequestInterceptorChainWrapper chain;
-
-    getNewApplication("test1");
-    getNewApplication("test2");
-    getNewApplication("test3");
-    getNewApplication("test4");
-    getNewApplication("test5");
-    getNewApplication("test6");
-    getNewApplication("test7");
-    getNewApplication("test8");
-
-    pipelines = super.getRouterClientRMService().getPipelines();
-    Assert.assertEquals(8, pipelines.size());
-
-    getNewApplication("test9");
-    getNewApplication("test10");
-    getNewApplication("test1");
-    getNewApplication("test11");
-
-    // The cache max size is defined in
-    // BaseRouterClientRMTest.TEST_MAX_CACHE_SIZE
-    Assert.assertEquals(10, pipelines.size());
-
-    chain = pipelines.get("test1");
-    Assert.assertNotNull("test1 should not be evicted", chain);
-
-    chain = pipelines.get("test2");
-    Assert.assertNull("test2 should have been evicted", chain);
-  }
-
-  /**
-   * This test validates if the ClientRequestInterceptor chain for the user
-   * can build and init correctly when a multi-client process begins to
-   * request RouterClientRMService for the same user simultaneously.
-   */
-  @Test
-  public void testClientPipelineConcurrent() throws InterruptedException {
-    final String user = "test1";
-
-    /*
-     * ClientTestThread is a thread to simulate a client request to get a
-     * ClientRequestInterceptor for the user.
-     */
-    class ClientTestThread extends Thread {
-      private ClientRequestInterceptor interceptor;
-      @Override public void run() {
-        try {
-          interceptor = pipeline();
-        } catch (IOException | InterruptedException e) {
-          e.printStackTrace();
-        }
-      }
-      private ClientRequestInterceptor pipeline()
-          throws IOException, InterruptedException {
-        return UserGroupInformation.createRemoteUser(user).doAs(
-            new PrivilegedExceptionAction<ClientRequestInterceptor>() {
-              @Override
-              public ClientRequestInterceptor run() throws Exception {
-                RequestInterceptorChainWrapper wrapper =
-                    getRouterClientRMService().getInterceptorChain();
-                ClientRequestInterceptor interceptor =
-                    wrapper.getRootInterceptor();
-                Assert.assertNotNull(interceptor);
-                LOG.info("init client interceptor success for user " + user);
-                return interceptor;
-              }
-            });
-      }
-    }
-
-    /*
-     * We start the first thread. It should not finish initing a chainWrapper
-     * before the other thread starts. In this way, the second thread can
-     * init at the same time of the first one. In the end, we validate that
-     * the 2 threads get the same chainWrapper without going into error.
-     */
-    ClientTestThread client1 = new ClientTestThread();
-    ClientTestThread client2 = new ClientTestThread();
-    client1.start();
-    client2.start();
-    client1.join();
-    client2.join();
-
-    Assert.assertNotNull(client1.interceptor);
-    Assert.assertNotNull(client2.interceptor);
-    Assert.assertTrue(client1.interceptor == client2.interceptor);
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestRouterYarnClientUtils.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestRouterYarnClientUtils.java
deleted file mode 100644
index 346e9e87841..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestRouterYarnClientUtils.java
+++ /dev/null
@@ -1,768 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Set;
-import java.util.Map;
-import java.util.HashMap;
-import java.util.HashSet;
-
-import org.apache.commons.collections.CollectionUtils;
-import org.apache.hadoop.thirdparty.com.google.common.collect.ImmutableSet;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToLabelsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetLabelsToNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetQueueUserAclsInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationListResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceTypeInfoResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetResourceProfileResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAllResourceProfilesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetAttributesToNodesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterNodeAttributesResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetNodesToAttributesResponse;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.ApplicationReport;
-import org.apache.hadoop.yarn.api.records.ApplicationResourceUsageReport;
-import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;
-import org.apache.hadoop.yarn.api.records.Resource;
-import org.apache.hadoop.yarn.api.records.YarnApplicationState;
-import org.apache.hadoop.yarn.api.records.YarnClusterMetrics;
-import org.apache.hadoop.yarn.api.records.NodeId;
-import org.apache.hadoop.yarn.api.records.NodeLabel;
-import org.apache.hadoop.yarn.api.records.QueueACL;
-import org.apache.hadoop.yarn.api.records.QueueUserACLInfo;
-import org.apache.hadoop.yarn.api.records.ReservationAllocationState;
-import org.apache.hadoop.yarn.api.records.ReservationDefinition;
-import org.apache.hadoop.yarn.api.records.ReservationId;
-import org.apache.hadoop.yarn.api.records.ResourceTypeInfo;
-import org.apache.hadoop.yarn.api.records.NodeAttribute;
-import org.apache.hadoop.yarn.api.records.NodeAttributeType;
-import org.apache.hadoop.yarn.api.records.NodeAttributeKey;
-import org.apache.hadoop.yarn.api.records.NodeToAttributeValue;
-import org.apache.hadoop.yarn.api.records.NodeAttributeInfo;
-import org.apache.hadoop.yarn.util.Records;
-import org.apache.hadoop.yarn.server.uam.UnmanagedApplicationManager;
-import org.junit.Assert;
-import org.junit.Test;
-
-/**
- * Test class for RouterYarnClientUtils.
- */
-public class TestRouterYarnClientUtils {
-
-  private final static String PARTIAL_REPORT = "Partial Report ";
-
-  @Test
-  public void testClusterMetricsMerge() {
-    ArrayList<GetClusterMetricsResponse> responses = new ArrayList<>();
-    responses.add(getClusterMetricsResponse(1));
-    responses.add(getClusterMetricsResponse(2));
-    GetClusterMetricsResponse result = RouterYarnClientUtils.merge(responses);
-    YarnClusterMetrics resultMetrics = result.getClusterMetrics();
-    Assert.assertEquals(3, resultMetrics.getNumNodeManagers());
-    Assert.assertEquals(3, resultMetrics.getNumActiveNodeManagers());
-    Assert.assertEquals(3, resultMetrics.getNumDecommissioningNodeManagers());
-    Assert.assertEquals(3, resultMetrics.getNumDecommissionedNodeManagers());
-    Assert.assertEquals(3, resultMetrics.getNumLostNodeManagers());
-    Assert.assertEquals(3, resultMetrics.getNumRebootedNodeManagers());
-    Assert.assertEquals(3, resultMetrics.getNumUnhealthyNodeManagers());
-    Assert.assertEquals(3, resultMetrics.getNumShutdownNodeManagers());
-  }
-
-  public GetClusterMetricsResponse getClusterMetricsResponse(int value) {
-    YarnClusterMetrics metrics = YarnClusterMetrics.newInstance(value);
-    metrics.setNumUnhealthyNodeManagers(value);
-    metrics.setNumRebootedNodeManagers(value);
-    metrics.setNumLostNodeManagers(value);
-    metrics.setNumDecommissioningNodeManagers(value);
-    metrics.setNumDecommissionedNodeManagers(value);
-    metrics.setNumActiveNodeManagers(value);
-    metrics.setNumNodeManagers(value);
-    metrics.setNumShutdownNodeManagers(value);
-    return GetClusterMetricsResponse.newInstance(metrics);
-  }
-
-  /**
-   * This test validates the correctness of
-   * RouterYarnClientUtils#mergeApplications.
-   */
-  @Test
-  public void testMergeApplications() {
-    ArrayList<GetApplicationsResponse> responses = new ArrayList<>();
-    responses.add(getApplicationsResponse(1, false));
-    responses.add(getApplicationsResponse(2, false));
-    GetApplicationsResponse result = RouterYarnClientUtils.
-        mergeApplications(responses, false);
-    Assert.assertNotNull(result);
-    Assert.assertEquals(2, result.getApplicationList().size());
-
-    String appName1 = result.getApplicationList().get(0).getName();
-    String appName2 = result.getApplicationList().get(1).getName();
-
-    // Check that no Unmanaged applications are added to the result
-    Assert.assertEquals(false,
-        appName1.contains(UnmanagedApplicationManager.APP_NAME));
-    Assert.assertEquals(false,
-        appName2.contains(UnmanagedApplicationManager.APP_NAME));
-  }
-
-  /**
-   * This test validates the correctness of
-   * RouterYarnClientUtils#mergeApplications.
-   */
-  @Test
-  public void testMergeUnmanagedApplications() {
-    ArrayList<GetApplicationsResponse> responses = new ArrayList<>();
-    responses.add(getApplicationsResponse(1, true));
-
-    // Check response if partial results are enabled
-    GetApplicationsResponse result = RouterYarnClientUtils.
-        mergeApplications(responses, true);
-    Assert.assertNotNull(result);
-    Assert.assertEquals(1, result.getApplicationList().size());
-    ApplicationReport appReport = result.getApplicationList().iterator().next();
-    String appName = appReport.getName();
-    Assert.assertTrue(appName.startsWith(PARTIAL_REPORT));
-
-    // Check ApplicationResourceUsageReport merge
-    ApplicationResourceUsageReport resourceUsageReport =
-        appReport.getApplicationResourceUsageReport();
-
-    Assert.assertEquals(2, resourceUsageReport.getNumUsedContainers());
-    Assert.assertEquals(4, resourceUsageReport.getNumReservedContainers());
-
-    // Check response if partial results are disabled
-    result = RouterYarnClientUtils.
-        mergeApplications(responses, false);
-    Assert.assertNotNull(result);
-    Assert.assertTrue(result.getApplicationList().isEmpty());
-  }
-
-  /**
-   * This test validates the correctness of
-   * RouterYarnClientUtils#mergeApplications when
-   * ApplicationResourceUsageReport might be null.
-   */
-  @Test
-  public void testMergeApplicationsNullResourceUsage() {
-    ApplicationId appId = ApplicationId.newInstance(1234, 1);
-    ApplicationReport appReport = ApplicationReport.newInstance(
-        appId, ApplicationAttemptId.newInstance(appId, 1),
-        "user", "queue", "app1", "host",
-        124, null, YarnApplicationState.RUNNING,
-        "diagnostics", "url", 0, 0,
-        0, FinalApplicationStatus.SUCCEEDED, null, "N/A",
-        0.53789f, "YARN", null, null, false, null, null, null);
-
-    ApplicationReport uamAppReport = ApplicationReport.newInstance(
-        appId, ApplicationAttemptId.newInstance(appId, 1),
-        "user", "queue", "app1", "host",
-        124, null, YarnApplicationState.RUNNING,
-        "diagnostics", "url", 0, 0,
-        0, FinalApplicationStatus.SUCCEEDED, null, "N/A",
-        0.53789f, "YARN", null, null, true, null, null, null);
-
-
-    ArrayList<GetApplicationsResponse> responses = new ArrayList<>();
-    List<ApplicationReport> applications = new ArrayList<>();
-    applications.add(appReport);
-    applications.add(uamAppReport);
-    responses.add(GetApplicationsResponse.newInstance(applications));
-
-    GetApplicationsResponse result = RouterYarnClientUtils.
-        mergeApplications(responses, false);
-    Assert.assertNotNull(result);
-    Assert.assertEquals(1, result.getApplicationList().size());
-
-    String appName = result.getApplicationList().get(0).getName();
-
-    // Check that no Unmanaged applications are added to the result
-    Assert.assertFalse(appName.contains(UnmanagedApplicationManager.APP_NAME));
-  }
-
-  /**
-   * This generates a GetApplicationsResponse with 2 applications with
-   * same ApplicationId.
-   * @param value Used as Id in ApplicationId
-   * @param uamOnly If set to true, only unmanaged applications are added in
-   *                response, else one managed and one unmanaged applications
-   *                are added with same ApplicationId.
-   * @return GetApplicationsResponse
-   */
-  private GetApplicationsResponse getApplicationsResponse(int value,
-      boolean uamOnly) {
-    String appName = uamOnly? UnmanagedApplicationManager.APP_NAME: "appname";
-    List<ApplicationReport> applications = new ArrayList<>();
-
-    // Create first application report. This is a managed app by default.
-    // If uamOnly is true, this becomes unmanaged application.
-    ApplicationId appId = ApplicationId.newInstance(1234, value);
-    Resource resource = Resource.newInstance(1024, 1);
-    ApplicationResourceUsageReport appResourceUsageReport =
-        ApplicationResourceUsageReport.newInstance(
-            1, 2, resource, resource,
-            resource, null, 0.1f,
-            0.1f, null);
-
-    ApplicationReport appReport = ApplicationReport.newInstance(
-        appId, ApplicationAttemptId.newInstance(appId, 1),
-        "user", "queue", appName, "host",
-        124, null, YarnApplicationState.RUNNING,
-        "diagnostics", "url", 0, 0,
-        0, FinalApplicationStatus.SUCCEEDED, appResourceUsageReport, "N/A",
-        0.53789f, "YARN", null, null, uamOnly, null, null, null);
-
-    // Create second application report. This is always unmanaged application.
-    ApplicationId appId2 = ApplicationId.newInstance(1234, value);
-    ApplicationReport appReport2 = ApplicationReport.newInstance(
-        appId2, ApplicationAttemptId.newInstance(appId, 1),
-        "user", "queue", UnmanagedApplicationManager.APP_NAME, "host",
-        124, null, YarnApplicationState.RUNNING,
-        "diagnostics", "url", 0, 0,
-        0, FinalApplicationStatus.SUCCEEDED, appResourceUsageReport, "N/A",
-        0.53789f, "YARN", null, null, true, null, null, null);
-
-    applications.add(appReport);
-    applications.add(appReport2);
-
-    return GetApplicationsResponse.newInstance(applications);
-  }
-
-  @Test
-  public void testMergeNodesToLabelsResponse() {
-    NodeId node1 = NodeId.fromString("SubCluster1Node1:1111");
-    NodeId node2 = NodeId.fromString("SubCluster1Node2:2222");
-    NodeId node3 = NodeId.fromString("SubCluster2Node1:1111");
-
-    Map<NodeId, Set<String>> nodeLabelsMapSC1 = new HashMap<>();
-    nodeLabelsMapSC1.put(node1, ImmutableSet.of("node1"));
-    nodeLabelsMapSC1.put(node2, ImmutableSet.of("node2"));
-    nodeLabelsMapSC1.put(node3, ImmutableSet.of("node3"));
-
-    // normal response
-    GetNodesToLabelsResponse response1 = Records.newRecord(
-        GetNodesToLabelsResponse.class);
-    response1.setNodeToLabels(nodeLabelsMapSC1);
-
-    // empty response
-    Map<NodeId, Set<String>> nodeLabelsMapSC2 = new HashMap<>();
-    GetNodesToLabelsResponse response2 = Records.newRecord(
-        GetNodesToLabelsResponse.class);
-    response2.setNodeToLabels(nodeLabelsMapSC2);
-
-    // null response
-    GetNodesToLabelsResponse response3 = null;
-
-    Map<NodeId, Set<String>> expectedResponse = new HashMap<>();
-    expectedResponse.put(node1, ImmutableSet.of("node1"));
-    expectedResponse.put(node2, ImmutableSet.of("node2"));
-    expectedResponse.put(node3, ImmutableSet.of("node3"));
-
-    List<GetNodesToLabelsResponse> responses = new ArrayList<>();
-    responses.add(response1);
-    responses.add(response2);
-    responses.add(response3);
-
-    GetNodesToLabelsResponse response = RouterYarnClientUtils.
-        mergeNodesToLabelsResponse(responses);
-    Assert.assertEquals(expectedResponse, response.getNodeToLabels());
-  }
-
-  @Test
-  public void testMergeClusterNodeLabelsResponse() {
-    NodeLabel nodeLabel1 = NodeLabel.newInstance("nodeLabel1");
-    NodeLabel nodeLabel2 = NodeLabel.newInstance("nodeLabel2");
-    NodeLabel nodeLabel3 = NodeLabel.newInstance("nodeLabel3");
-
-    // normal response
-    List<NodeLabel> nodeLabelListSC1 = new ArrayList<>();
-    nodeLabelListSC1.add(nodeLabel1);
-    nodeLabelListSC1.add(nodeLabel2);
-    nodeLabelListSC1.add(nodeLabel3);
-
-    GetClusterNodeLabelsResponse response1 = Records.newRecord(
-        GetClusterNodeLabelsResponse.class);
-    response1.setNodeLabelList(nodeLabelListSC1);
-
-    // empty response
-    List<NodeLabel> nodeLabelListSC2 = new ArrayList<>();
-
-    GetClusterNodeLabelsResponse response2 = Records.newRecord(
-        GetClusterNodeLabelsResponse.class);
-    response2.setNodeLabelList(nodeLabelListSC2);
-
-    // null response
-    GetClusterNodeLabelsResponse response3 = null;
-
-    List<GetClusterNodeLabelsResponse> responses = new ArrayList<>();
-    responses.add(response1);
-    responses.add(response2);
-    responses.add(response3);
-
-    List<NodeLabel> expectedResponse = new ArrayList<>();
-    expectedResponse.add(nodeLabel1);
-    expectedResponse.add(nodeLabel2);
-    expectedResponse.add(nodeLabel3);
-
-    GetClusterNodeLabelsResponse response = RouterYarnClientUtils.
-        mergeClusterNodeLabelsResponse(responses);
-    Assert.assertTrue(CollectionUtils.isEqualCollection(expectedResponse,
-        response.getNodeLabelList()));
-  }
-
-  @Test
-  public void testMergeLabelsToNodes(){
-    NodeId node1 = NodeId.fromString("SubCluster1Node1:1111");
-    NodeId node2 = NodeId.fromString("SubCluster1Node2:2222");
-    NodeId node3 = NodeId.fromString("SubCluster2node1:1111");
-    NodeId node4 = NodeId.fromString("SubCluster2node2:2222");
-
-    Map<String, Set<NodeId>> labelsToNodesSC1 = new HashMap<>();
-
-    Set<NodeId> nodeIdSet1 = new HashSet<>();
-    nodeIdSet1.add(node1);
-    nodeIdSet1.add(node2);
-    labelsToNodesSC1.put("Label1", nodeIdSet1);
-
-    // normal response
-    GetLabelsToNodesResponse response1 = Records.newRecord(
-        GetLabelsToNodesResponse.class);
-    response1.setLabelsToNodes(labelsToNodesSC1);
-    Map<String, Set<NodeId>> labelsToNodesSC2 = new HashMap<>();
-    Set<NodeId> nodeIdSet2 = new HashSet<>();
-    nodeIdSet2.add(node3);
-    Set<NodeId> nodeIdSet3 = new HashSet<>();
-    nodeIdSet3.add(node4);
-    labelsToNodesSC2.put("Label1", nodeIdSet2);
-    labelsToNodesSC2.put("Label2", nodeIdSet3);
-
-    GetLabelsToNodesResponse response2 = Records.newRecord(
-        GetLabelsToNodesResponse.class);
-    response2.setLabelsToNodes(labelsToNodesSC2);
-
-    // empty response
-    GetLabelsToNodesResponse response3 = Records.newRecord(
-        GetLabelsToNodesResponse.class);
-
-    // null response
-    GetLabelsToNodesResponse response4 = null;
-
-    List<GetLabelsToNodesResponse> responses = new ArrayList<>();
-    responses.add(response1);
-    responses.add(response2);
-    responses.add(response3);
-    responses.add(response4);
-
-    Map<String, Set<NodeId>> expectedResponse = new HashMap<>();
-    Set<NodeId> nodeIdMergedSet1 = new HashSet<>();
-    nodeIdMergedSet1.add(node1);
-    nodeIdMergedSet1.add(node2);
-    nodeIdMergedSet1.add(node3);
-
-    Set<NodeId> nodeIdMergedSet2 = new HashSet<>();
-    nodeIdMergedSet2.add(node4);
-    expectedResponse.put("Label1", nodeIdMergedSet1);
-    expectedResponse.put("Label2", nodeIdMergedSet2);
-
-    GetLabelsToNodesResponse response = RouterYarnClientUtils.
-        mergeLabelsToNodes(responses);
-
-    Assert.assertEquals(expectedResponse, response.getLabelsToNodes());
-  }
-
-  @Test
-  public void testMergeQueueUserAclsResponse() {
-
-    List<QueueACL> submitOnlyAcl = new ArrayList<>();
-    submitOnlyAcl.add(QueueACL.SUBMIT_APPLICATIONS);
-
-    List<QueueACL> administerOnlyAcl = new ArrayList<>();
-    administerOnlyAcl.add(QueueACL.ADMINISTER_QUEUE);
-
-    List<QueueACL> submitAndAdministerAcl = new ArrayList<>();
-    submitAndAdministerAcl.add(QueueACL.ADMINISTER_QUEUE);
-    submitAndAdministerAcl.add(QueueACL.SUBMIT_APPLICATIONS);
-
-    QueueUserACLInfo queueUserACLInfo1 = QueueUserACLInfo.newInstance(
-        "root", submitAndAdministerAcl);
-
-    QueueUserACLInfo queueUserACLInfo2 = QueueUserACLInfo.newInstance(
-        "default", submitOnlyAcl);
-
-    QueueUserACLInfo queueUserACLInfo3 = QueueUserACLInfo.newInstance(
-        "root", submitAndAdministerAcl);
-
-    QueueUserACLInfo queueUserACLInfo4 = QueueUserACLInfo.newInstance(
-        "yarn", administerOnlyAcl);
-
-    List<QueueUserACLInfo> queueUserACLInfoList1 = new ArrayList<>();
-    List<QueueUserACLInfo> queueUserACLInfoList2 = new ArrayList<>();
-
-    queueUserACLInfoList1.add(queueUserACLInfo1);
-    queueUserACLInfoList1.add(queueUserACLInfo2);
-    queueUserACLInfoList2.add(queueUserACLInfo3);
-    queueUserACLInfoList2.add(queueUserACLInfo4);
-
-    // normal response
-    GetQueueUserAclsInfoResponse response1 = Records.newRecord(
-        GetQueueUserAclsInfoResponse.class);
-    response1.setUserAclsInfoList(queueUserACLInfoList1);
-    GetQueueUserAclsInfoResponse response2 = Records.newRecord(
-        GetQueueUserAclsInfoResponse.class);
-    response2.setUserAclsInfoList(queueUserACLInfoList2);
-
-    // empty response
-    GetQueueUserAclsInfoResponse response3 = Records.newRecord(
-        GetQueueUserAclsInfoResponse.class);
-
-    // null response
-    GetQueueUserAclsInfoResponse response4 = null;
-
-    List<GetQueueUserAclsInfoResponse> responses = new ArrayList<>();
-    responses.add(response1);
-    responses.add(response2);
-    responses.add(response3);
-    responses.add(response4);
-
-    // expected user acls
-    List<QueueUserACLInfo> expectedOutput = new ArrayList<>();
-    expectedOutput.add(queueUserACLInfo1);
-    expectedOutput.add(queueUserACLInfo2);
-    expectedOutput.add(queueUserACLInfo4);
-
-    GetQueueUserAclsInfoResponse response =
-        RouterYarnClientUtils.mergeQueueUserAcls(responses);
-    Assert.assertTrue(CollectionUtils.isEqualCollection(expectedOutput,
-        response.getUserAclsInfoList()));
-  }
-
-  @Test
-  public void testMergeReservationsList() {
-
-    // normal response
-    ReservationListResponse response1 = createReservationListResponse(
-        165348678000L, 165348690000L, 165348678000L, 1L);
-
-    ReservationListResponse response2 = createReservationListResponse(
-        165348750000L, 165348768000L, 165348750000L, 1L);
-
-    // empty response
-    ReservationListResponse response3 = ReservationListResponse.newInstance(new ArrayList<>());
-
-    // null response
-    ReservationListResponse response4 = null;
-
-    List<ReservationListResponse> responses = new ArrayList<>();
-    responses.add(response1);
-    responses.add(response2);
-    responses.add(response3);
-    responses.add(response4);
-
-    // expected response
-    List<ReservationAllocationState> expectedResponse = new ArrayList<>();
-    expectedResponse.addAll(response1.getReservationAllocationState());
-    expectedResponse.addAll(response2.getReservationAllocationState());
-
-    ReservationListResponse response =
-        RouterYarnClientUtils.mergeReservationsList(responses);
-    Assert.assertEquals(expectedResponse, response.getReservationAllocationState());
-  }
-
-  private ReservationListResponse createReservationListResponse(long startTime,
-      long endTime, long reservationTime, long reservationNumber) {
-    List<ReservationAllocationState> reservationsList = new ArrayList<>();
-    ReservationDefinition reservationDefinition =
-        Records.newRecord(ReservationDefinition.class);
-    reservationDefinition.setArrival(startTime);
-    reservationDefinition.setDeadline(endTime);
-    ReservationAllocationState reservationAllocationState =
-        Records.newRecord(ReservationAllocationState.class);
-    ReservationId reservationId = ReservationId.newInstance(reservationTime,
-        reservationNumber);
-    reservationAllocationState.setReservationDefinition(reservationDefinition);
-    reservationAllocationState.setReservationId(reservationId);
-    reservationsList.add(reservationAllocationState);
-    return ReservationListResponse.newInstance(reservationsList);
-  }
-
-  @Test
-  public void testMergeResourceTypes() {
-
-    ResourceTypeInfo resourceTypeInfo1 = ResourceTypeInfo.newInstance("vcores");
-    ResourceTypeInfo resourceTypeInfo2 = ResourceTypeInfo.newInstance("gpu");
-    ResourceTypeInfo resourceTypeInfo3 = ResourceTypeInfo.newInstance("memory-mb");
-
-    List<ResourceTypeInfo> resourceTypeInfoList1 = new ArrayList<>();
-    resourceTypeInfoList1.add(resourceTypeInfo1);
-    resourceTypeInfoList1.add(resourceTypeInfo3);
-
-    List<ResourceTypeInfo> resourceTypeInfoList2 = new ArrayList<>();
-    resourceTypeInfoList2.add(resourceTypeInfo3);
-    resourceTypeInfoList2.add(resourceTypeInfo2);
-
-    // normal response
-    GetAllResourceTypeInfoResponse response1 =
-        Records.newRecord(GetAllResourceTypeInfoResponse.class);
-    response1.setResourceTypeInfo(resourceTypeInfoList1);
-
-    GetAllResourceTypeInfoResponse response2 =
-        Records.newRecord(GetAllResourceTypeInfoResponse.class);
-    response2.setResourceTypeInfo(resourceTypeInfoList2);
-
-    // empty response
-    GetAllResourceTypeInfoResponse response3 =
-        Records.newRecord(GetAllResourceTypeInfoResponse.class);
-
-    // null response
-    GetAllResourceTypeInfoResponse response4 = null;
-
-    List<GetAllResourceTypeInfoResponse> responses = new ArrayList<>();
-    responses.add(response1);
-    responses.add(response2);
-    responses.add(response3);
-    responses.add(response4);
-
-    // expected response
-    List<ResourceTypeInfo> expectedResponse = new ArrayList<>();
-    expectedResponse.add(resourceTypeInfo1);
-    expectedResponse.add(resourceTypeInfo2);
-    expectedResponse.add(resourceTypeInfo3);
-    GetAllResourceTypeInfoResponse response =
-        RouterYarnClientUtils.mergeResourceTypes(responses);
-    Assert.assertTrue(CollectionUtils.isEqualCollection(expectedResponse,
-        response.getResourceTypeInfo()));
-  }
-
-  @Test
-  public void testMergeResourceProfiles() {
-    // normal response1
-    Map<String, Resource> profiles = new HashMap<>();
-    Resource resource1 = Resource.newInstance(1024, 1);
-    GetAllResourceProfilesResponse response1 = GetAllResourceProfilesResponse.newInstance();
-    profiles.put("maximum", resource1);
-    response1.setResourceProfiles(profiles);
-
-    // normal response2
-    profiles = new HashMap<>();
-    Resource resource2 = Resource.newInstance(2048, 2);
-    GetAllResourceProfilesResponse response2 = GetAllResourceProfilesResponse.newInstance();
-    profiles.put("maximum", resource2);
-    response2.setResourceProfiles(profiles);
-
-    // empty response
-    GetAllResourceProfilesResponse response3 = GetAllResourceProfilesResponse.newInstance();
-
-    // null response
-    GetAllResourceProfilesResponse response4 = null;
-
-    List<GetAllResourceProfilesResponse> responses = new ArrayList<>();
-    responses.add(response1);
-    responses.add(response2);
-    responses.add(response3);
-    responses.add(response4);
-
-    GetAllResourceProfilesResponse response =
-        RouterYarnClientUtils.mergeClusterResourceProfilesResponse(responses);
-    Resource resource = response.getResourceProfiles().get("maximum");
-    Assert.assertEquals(3, resource.getVirtualCores());
-    Assert.assertEquals(3072, resource.getMemorySize());
-  }
-
-  @Test
-  public void testMergeResourceProfile() {
-    // normal response1
-    Resource resource1 = Resource.newInstance(1024, 1);
-    GetResourceProfileResponse response1 =
-        Records.newRecord(GetResourceProfileResponse.class);
-    response1.setResource(resource1);
-
-    // normal response2
-    Resource resource2 = Resource.newInstance(2048, 2);
-    GetResourceProfileResponse response2 =
-        Records.newRecord(GetResourceProfileResponse.class);
-    response2.setResource(resource2);
-
-    // empty response
-    GetResourceProfileResponse response3 =
-        Records.newRecord(GetResourceProfileResponse.class);
-
-    // null response
-    GetResourceProfileResponse response4 = null;
-
-    List<GetResourceProfileResponse> responses = new ArrayList<>();
-    responses.add(response1);
-    responses.add(response2);
-    responses.add(response3);
-    responses.add(response4);
-
-    GetResourceProfileResponse response =
-        RouterYarnClientUtils.mergeClusterResourceProfileResponse(responses);
-    Resource resource = response.getResource();
-    Assert.assertEquals(3, resource.getVirtualCores());
-    Assert.assertEquals(3072, resource.getMemorySize());
-  }
-
-  @Test
-  public void testMergeAttributesToNodesResponse() {
-    // normal response1
-    NodeAttribute gpu = NodeAttribute.newInstance(NodeAttribute.PREFIX_CENTRALIZED, "GPU",
-        NodeAttributeType.STRING, "nvidia");
-    Map<NodeAttributeKey, List<NodeToAttributeValue>> map1 = new HashMap<>();
-    List<NodeToAttributeValue> lists1 = new ArrayList<>();
-    NodeToAttributeValue attributeValue1 =
-        NodeToAttributeValue.newInstance("node1", gpu.getAttributeValue());
-    lists1.add(attributeValue1);
-    map1.put(gpu.getAttributeKey(), lists1);
-    GetAttributesToNodesResponse response1 = GetAttributesToNodesResponse.newInstance(map1);
-
-    // normal response2
-    NodeAttribute docker = NodeAttribute.newInstance(NodeAttribute.PREFIX_DISTRIBUTED, "DOCKER",
-        NodeAttributeType.STRING, "docker0");
-    Map<NodeAttributeKey, List<NodeToAttributeValue>> map2 = new HashMap<>();
-    List<NodeToAttributeValue> lists2 = new ArrayList<>();
-    NodeToAttributeValue attributeValue2 =
-        NodeToAttributeValue.newInstance("node2", docker.getAttributeValue());
-    lists2.add(attributeValue2);
-    map2.put(docker.getAttributeKey(), lists2);
-    GetAttributesToNodesResponse response2 = GetAttributesToNodesResponse.newInstance(map2);
-
-    // empty response3
-    GetAttributesToNodesResponse response3 =
-        GetAttributesToNodesResponse.newInstance(new HashMap<>());
-
-    // null response4
-    GetAttributesToNodesResponse response4 = null;
-
-    List<GetAttributesToNodesResponse> responses = new ArrayList<>();
-    responses.add(response1);
-    responses.add(response2);
-    responses.add(response3);
-    responses.add(response4);
-
-    GetAttributesToNodesResponse response =
-        RouterYarnClientUtils.mergeAttributesToNodesResponse(responses);
-
-    Assert.assertNotNull(response);
-    Assert.assertEquals(2, response.getAttributesToNodes().size());
-
-    Map<NodeAttributeKey, List<NodeToAttributeValue>> attrs = response.getAttributesToNodes();
-
-    NodeAttributeKey gpuKey = gpu.getAttributeKey();
-    Assert.assertEquals(attributeValue1.toString(), attrs.get(gpuKey).get(0).toString());
-
-    NodeAttributeKey dockerKey = docker.getAttributeKey();
-    Assert.assertEquals(attributeValue2.toString(), attrs.get(dockerKey).get(0).toString());
-  }
-
-  @Test
-  public void testMergeClusterNodeAttributesResponse() {
-    // normal response1
-    NodeAttributeInfo nodeAttributeInfo1 =
-        NodeAttributeInfo.newInstance(NodeAttributeKey.newInstance("GPU"),
-        NodeAttributeType.STRING);
-    Set<NodeAttributeInfo> attributes1 = new HashSet<>();
-    attributes1.add(nodeAttributeInfo1);
-    GetClusterNodeAttributesResponse response1 =
-        GetClusterNodeAttributesResponse.newInstance(attributes1);
-
-    // normal response2
-    NodeAttributeInfo nodeAttributeInfo2 =
-        NodeAttributeInfo.newInstance(NodeAttributeKey.newInstance("CPU"),
-        NodeAttributeType.STRING);
-    Set<NodeAttributeInfo> attributes2 = new HashSet<>();
-    attributes2.add(nodeAttributeInfo2);
-    GetClusterNodeAttributesResponse response2 =
-        GetClusterNodeAttributesResponse.newInstance(attributes2);
-
-    // empty response3
-    GetClusterNodeAttributesResponse response3 =
-        GetClusterNodeAttributesResponse.newInstance(new HashSet<>());
-
-    // null response4
-    GetClusterNodeAttributesResponse response4 = null;
-
-    List<GetClusterNodeAttributesResponse> responses = new ArrayList<>();
-    responses.add(response1);
-    responses.add(response2);
-    responses.add(response3);
-    responses.add(response4);
-
-    GetClusterNodeAttributesResponse response =
-        RouterYarnClientUtils.mergeClusterNodeAttributesResponse(responses);
-
-    Assert.assertNotNull(response);
-
-    Set<NodeAttributeInfo> nodeAttributeInfos = response.getNodeAttributes();
-    Assert.assertEquals(2, nodeAttributeInfos.size());
-    Assert.assertTrue(nodeAttributeInfos.contains(nodeAttributeInfo1));
-    Assert.assertTrue(nodeAttributeInfos.contains(nodeAttributeInfo2));
-  }
-
-  @Test
-  public void testMergeNodesToAttributesResponse() {
-    // normal response1
-    NodeAttribute gpu = NodeAttribute.newInstance(NodeAttribute.PREFIX_CENTRALIZED, "GPU",
-        NodeAttributeType.STRING, "nvida");
-    NodeAttribute os = NodeAttribute.newInstance(NodeAttribute.PREFIX_CENTRALIZED, "OS",
-        NodeAttributeType.STRING, "windows64");
-    NodeAttribute dist = NodeAttribute.newInstance(NodeAttribute.PREFIX_DISTRIBUTED, "VERSION",
-        NodeAttributeType.STRING, "3_0_2");
-    Map<String, Set<NodeAttribute>> node1Map = new HashMap<>();
-    node1Map.put("node1", ImmutableSet.of(gpu, os, dist));
-    GetNodesToAttributesResponse response1 = GetNodesToAttributesResponse.newInstance(node1Map);
-
-    // normal response2
-    NodeAttribute docker = NodeAttribute.newInstance(NodeAttribute.PREFIX_DISTRIBUTED, "DOCKER",
-        NodeAttributeType.STRING, "docker0");
-    Map<String, Set<NodeAttribute>> node2Map = new HashMap<>();
-    node2Map.put("node2", ImmutableSet.of(docker));
-    GetNodesToAttributesResponse response2 = GetNodesToAttributesResponse.newInstance(node2Map);
-
-    // empty response3
-    GetNodesToAttributesResponse response3 =
-        GetNodesToAttributesResponse.newInstance(new HashMap<>());
-
-    // null response4
-    GetNodesToAttributesResponse response4 = null;
-
-    List<GetNodesToAttributesResponse> responses = new ArrayList<>();
-    responses.add(response1);
-    responses.add(response2);
-    responses.add(response3);
-    responses.add(response4);
-
-    GetNodesToAttributesResponse response =
-        RouterYarnClientUtils.mergeNodesToAttributesResponse(responses);
-
-    Assert.assertNotNull(response);
-
-    Map<String, Set<NodeAttribute>> hostToAttrs = response.getNodeToAttributes();
-    Assert.assertNotNull(hostToAttrs);
-    Assert.assertEquals(2, hostToAttrs.size());
-    Assert.assertTrue(hostToAttrs.get("node1").contains(dist));
-    Assert.assertTrue(hostToAttrs.get("node1").contains(gpu));
-    Assert.assertTrue(hostToAttrs.get("node1").contains(os));
-    Assert.assertTrue(hostToAttrs.get("node2").contains(docker));
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestSequentialBroadcastPolicyManager.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestSequentialBroadcastPolicyManager.java
deleted file mode 100644
index ffc702f64ea..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestSequentialBroadcastPolicyManager.java
+++ /dev/null
@@ -1,54 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import org.apache.hadoop.yarn.server.federation.policies.amrmproxy.BroadcastAMRMProxyPolicy;
-import org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo;
-import org.apache.hadoop.yarn.server.federation.policies.manager.AbstractPolicyManager;
-
-/**
- * This PolicyManager is used for testing and will contain the
- * {@link TestSequentialRouterPolicy} policy.
- *
- * When we test FederationClientInterceptor Retry,
- * we hope that SubCluster can return in a certain order, not randomly.
- * We can view the policy description by linking to TestSequentialRouterPolicy.
- */
-public class TestSequentialBroadcastPolicyManager extends AbstractPolicyManager {
-  public TestSequentialBroadcastPolicyManager() {
-    // this structurally hard-codes two compatible policies for Router and
-    // AMRMProxy.
-    routerFederationPolicy = TestSequentialRouterPolicy.class;
-    amrmProxyFederationPolicy = BroadcastAMRMProxyPolicy.class;
-  }
-
-  @Override
-  public WeightedPolicyInfo getWeightedPolicyInfo() {
-    return null;
-  }
-
-  @Override
-  public void setWeightedPolicyInfo(WeightedPolicyInfo weightedPolicyInfo) {
-  }
-
-  @Override
-  public boolean isSupportWeightedPolicyInfo() {
-    return false;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestSequentialRouterPolicy.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestSequentialRouterPolicy.java
deleted file mode 100644
index e702b764fed..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestSequentialRouterPolicy.java
+++ /dev/null
@@ -1,78 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import org.apache.commons.collections.CollectionUtils;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.federation.policies.FederationPolicyInitializationContext;
-import org.apache.hadoop.yarn.server.federation.policies.FederationPolicyInitializationContextValidator;
-import org.apache.hadoop.yarn.server.federation.policies.exceptions.FederationPolicyInitializationException;
-import org.apache.hadoop.yarn.server.federation.policies.router.AbstractRouterPolicy;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Map;
-
-/**
- * This is a test strategy,
- * the purpose of this strategy is to return subClusters in descending order of subClusterId.
- *
- * This strategy is to verify the situation of Retry during the use of FederationClientInterceptor.
- * The conditions of use are as follows:
- * 1.We require subClusterId to be an integer.
- * 2.The larger the subCluster, the sooner the representative is selected.
- *
- * We have 4 subClusters, 2 normal subClusters, 2 bad subClusters.
- * We expect to select badSubClusters first and then goodSubClusters during testing.
- * We can set the subCluster like this, good1 = [0], good2 = [1], bad1 = [2], bad2 = [3].
- * This strategy will return [3, 2, 1, 0],
- * The selection order of subCluster is bad2, bad1, good2, good1.
- */
-public class TestSequentialRouterPolicy extends AbstractRouterPolicy {
-
-  @Override
-  public void reinitialize(FederationPolicyInitializationContext policyContext)
-      throws FederationPolicyInitializationException {
-    FederationPolicyInitializationContextValidator.validate(policyContext,
-        this.getClass().getCanonicalName());
-    setPolicyContext(policyContext);
-  }
-
-  @Override
-  protected SubClusterId chooseSubCluster(String queue,
-      Map<SubClusterId, SubClusterInfo> preSelectSubClusters) throws YarnException {
-    /**
-      * This strategy is only suitable for testing. We need to obtain subClusters sequentially.
-      * We have 3 subClusters, 1 goodSubCluster and 2 badSubClusters.
-      * The sc-id of goodSubCluster is 0, and the sc-id of badSubCluster is 1 and 2.
-      * We hope Return in reverse order, that is, return 2, 1, 0
-      * Return to badCluster first.
-      */
-    List<SubClusterId> subClusterIds = new ArrayList<>(preSelectSubClusters.keySet());
-    if (subClusterIds.size() > 1) {
-      subClusterIds.sort((o1, o2) -> Integer.parseInt(o2.getId()) - Integer.parseInt(o1.getId()));
-    }
-    if(CollectionUtils.isNotEmpty(subClusterIds)){
-      return subClusterIds.get(0);
-    }
-    return null;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestableFederationClientInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestableFederationClientInterceptor.java
deleted file mode 100644
index 9d6b87e8cc9..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/clientrm/TestableFederationClientInterceptor.java
+++ /dev/null
@@ -1,257 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.clientrm;
-
-import static org.mockito.Mockito.mock;
-
-import java.io.IOException;
-import java.net.ConnectException;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Set;
-import java.util.Map;
-import java.util.HashMap;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.concurrent.TimeUnit;
-import java.util.concurrent.TimeoutException;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.test.GenericTestUtils;
-import org.apache.hadoop.thirdparty.com.google.common.collect.ImmutableSet;
-import org.apache.hadoop.yarn.api.ApplicationClientProtocol;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.SubmitApplicationResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse;
-import org.apache.hadoop.yarn.api.records.NodeAttribute;
-import org.apache.hadoop.yarn.api.records.NodeAttributeType;
-import org.apache.hadoop.yarn.api.records.Resource;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.nodelabels.NodeAttributesManager;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.resourcemanager.ClientRMService;
-import org.apache.hadoop.yarn.server.resourcemanager.MockRM;
-import org.apache.hadoop.yarn.server.resourcemanager.MockNM;
-import org.apache.hadoop.yarn.server.resourcemanager.RMAppManager;
-import org.apache.hadoop.yarn.server.resourcemanager.RMContext;
-import org.apache.hadoop.yarn.server.resourcemanager.reservation.Plan;
-import org.apache.hadoop.yarn.server.resourcemanager.reservation.ReservationSystem;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.YarnScheduler;
-import org.apache.hadoop.yarn.server.resourcemanager.security.QueueACLsManager;
-import org.apache.hadoop.yarn.server.resourcemanager.security.RMDelegationTokenSecretManager;
-import org.apache.hadoop.yarn.server.router.security.RouterDelegationTokenSecretManager;
-import org.apache.hadoop.yarn.server.security.ApplicationACLsManager;
-import org.junit.Assert;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * Extends the FederationClientInterceptor and overrides methods to provide a
- * testable implementation of FederationClientInterceptor.
- */
-public class TestableFederationClientInterceptor
-    extends FederationClientInterceptor {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestableFederationClientInterceptor.class);
-
-  private ConcurrentHashMap<SubClusterId, MockRM> mockRMs =
-      new ConcurrentHashMap<>();
-
-  private ConcurrentHashMap<SubClusterId, MockNM> mockNMs =
-      new ConcurrentHashMap<>();
-
-  private List<SubClusterId> badSubCluster = new ArrayList<SubClusterId>();
-
-  @Override
-  protected ApplicationClientProtocol getClientRMProxyForSubCluster(
-      SubClusterId subClusterId) throws YarnException {
-
-    MockRM mockRM = null;
-    synchronized (this) {
-      if (mockRMs.containsKey(subClusterId)) {
-        mockRM = mockRMs.get(subClusterId);
-      } else {
-        mockRM = new MockRM();
-        if (badSubCluster.contains(subClusterId)) {
-          RMContext rmContext = mock(RMContext.class);
-          return new MockClientRMService(rmContext, null, null, null, null,
-              null);
-        }
-        mockRM.init(super.getConf());
-        mockRM.start();
-        try {
-          MockNM nm = mockRM.registerNode("127.0.0.1:1234", 8*1024, 4);
-          mockNMs.put(subClusterId, nm);
-        } catch (Exception e) {
-          Assert.fail(e.getMessage());
-        }
-        mockRMs.put(subClusterId, mockRM);
-      }
-      initNodeAttributes(subClusterId, mockRM);
-      initReservationSystem(mockRM);
-      return mockRM.getClientRMService();
-    }
-  }
-
-  private static class MockClientRMService extends ClientRMService {
-
-    MockClientRMService(RMContext rmContext, YarnScheduler scheduler,
-        RMAppManager rmAppManager,
-        ApplicationACLsManager applicationACLsManager,
-        QueueACLsManager queueACLsManager,
-        RMDelegationTokenSecretManager rmDTSecretManager) {
-      super(rmContext, scheduler, rmAppManager, applicationACLsManager,
-          queueACLsManager, rmDTSecretManager);
-    }
-
-    @Override
-    public SubmitApplicationResponse submitApplication(
-        SubmitApplicationRequest request) throws YarnException, IOException {
-      throw new ConnectException("RM is stopped");
-    }
-
-    @Override
-    public GetClusterMetricsResponse getClusterMetrics(GetClusterMetricsRequest request)
-        throws YarnException {
-      throw new YarnException("RM is stopped");
-    }
-  }
-
-  /**
-   * For testing purpose, some subclusters has to be down to simulate particular
-   * scenarios as RM Failover, network issues. For this reason we keep track of
-   * these bad subclusters. This method make the subcluster unusable.
-   *
-   * @param badSC the subcluster to make unusable
-   * @throws IOException
-   */
-  protected void registerBadSubCluster(SubClusterId badSC) throws IOException {
-    badSubCluster.add(badSC);
-    if (mockRMs.contains(badSC)) {
-      mockRMs.get(badSC).close();
-    }
-  }
-
-  public ConcurrentHashMap<SubClusterId, MockRM> getMockRMs() {
-    return mockRMs;
-  }
-
-  public ConcurrentHashMap<SubClusterId, MockNM> getMockNMs() {
-    return mockNMs;
-  }
-
-  private void initNodeAttributes(SubClusterId subClusterId, MockRM mockRM)  {
-    String node1 = subClusterId.getId() +"-host1";
-    String node2 = subClusterId.getId() +"-host2";
-    NodeAttributesManager mgr = mockRM.getRMContext().getNodeAttributesManager();
-    NodeAttribute gpu =
-        NodeAttribute.newInstance(NodeAttribute.PREFIX_CENTRALIZED, "GPU",
-        NodeAttributeType.STRING, "nvidia");
-    NodeAttribute os =
-        NodeAttribute.newInstance(NodeAttribute.PREFIX_CENTRALIZED, "OS",
-        NodeAttributeType.STRING, "windows64");
-    NodeAttribute docker =
-        NodeAttribute.newInstance(NodeAttribute.PREFIX_DISTRIBUTED, "DOCKER",
-        NodeAttributeType.STRING, "docker0");
-    NodeAttribute dist =
-        NodeAttribute.newInstance(NodeAttribute.PREFIX_DISTRIBUTED, "VERSION",
-        NodeAttributeType.STRING, "3_0_2");
-    Map<String, Set<NodeAttribute>> nodes = new HashMap<>();
-    nodes.put(node1, ImmutableSet.of(gpu, os, dist));
-    nodes.put(node2, ImmutableSet.of(docker, dist));
-    try {
-      mgr.addNodeAttributes(nodes);
-    } catch (IOException e) {
-      throw new RuntimeException(e);
-    }
-  }
-
-  private void initReservationSystem(MockRM mockRM) throws YarnException {
-    try {
-      // Ensure that the reserved resources of the RM#Reservation System are allocated
-      String planName = "root.decided";
-      ReservationSystem reservationSystem = mockRM.getReservationSystem();
-      reservationSystem.synchronizePlan(planName, true);
-
-      GenericTestUtils.waitFor(() -> {
-        Plan plan = reservationSystem.getPlan(planName);
-        Resource resource = plan.getTotalCapacity();
-        return (resource.getMemorySize() > 0 && resource.getVirtualCores() > 0);
-      }, 100, 2000);
-    } catch (TimeoutException | InterruptedException e) {
-      throw new YarnException(e);
-    }
-  }
-
-  @Override
-  public void shutdown() {
-    if (mockRMs != null && !mockRMs.isEmpty()) {
-      for (Map.Entry<SubClusterId, MockRM> item : mockRMs.entrySet()) {
-        SubClusterId subClusterId = item.getKey();
-
-        // close mockNM
-        MockNM mockNM = mockNMs.getOrDefault(subClusterId, null);
-        try {
-          mockNM.unRegisterNode();
-          mockNM = null;
-        } catch (Exception e) {
-          LOG.error("mockNM unRegisterNode error.", e);
-        }
-
-        // close mockRM
-        MockRM mockRM = item.getValue();
-        if (mockRM != null) {
-          mockRM.stop();
-        }
-      }
-    }
-    mockNMs.clear();
-    mockRMs.clear();
-    super.shutdown();
-  }
-
-  public RouterDelegationTokenSecretManager createRouterRMDelegationTokenSecretManager(
-      Configuration conf) {
-
-    long secretKeyInterval = conf.getTimeDuration(
-        YarnConfiguration.RM_DELEGATION_KEY_UPDATE_INTERVAL_KEY,
-        YarnConfiguration.RM_DELEGATION_KEY_UPDATE_INTERVAL_DEFAULT,
-        TimeUnit.MILLISECONDS);
-
-    long tokenMaxLifetime = conf.getTimeDuration(
-        YarnConfiguration.RM_DELEGATION_TOKEN_MAX_LIFETIME_KEY,
-        YarnConfiguration.RM_DELEGATION_TOKEN_MAX_LIFETIME_DEFAULT,
-        TimeUnit.MILLISECONDS);
-
-    long tokenRenewInterval = conf.getTimeDuration(
-        YarnConfiguration.RM_DELEGATION_TOKEN_RENEW_INTERVAL_KEY,
-        YarnConfiguration.RM_DELEGATION_TOKEN_RENEW_INTERVAL_DEFAULT,
-        TimeUnit.MILLISECONDS);
-
-    long removeScanInterval = conf.getTimeDuration(
-        YarnConfiguration.RM_DELEGATION_TOKEN_REMOVE_SCAN_INTERVAL_KEY,
-        YarnConfiguration.RM_DELEGATION_TOKEN_REMOVE_SCAN_INTERVAL_DEFAULT,
-        TimeUnit.MILLISECONDS);
-
-    return new RouterDelegationTokenSecretManager(secretKeyInterval,
-        tokenMaxLifetime, tokenRenewInterval, removeScanInterval, conf);
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/BaseRouterRMAdminTest.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/BaseRouterRMAdminTest.java
deleted file mode 100644
index 33cda8751db..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/BaseRouterRMAdminTest.java
+++ /dev/null
@@ -1,318 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.rmadmin;
-
-import java.io.IOException;
-import java.security.PrivilegedExceptionAction;
-import java.util.HashMap;
-import java.util.Set;
-import java.util.concurrent.ExecutorService;
-import java.util.concurrent.Executors;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.metrics2.lib.DefaultMetricsSystem;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.yarn.api.records.NodeId;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.event.AsyncDispatcher;
-import org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.CheckForDecommissioningNodesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.CheckForDecommissioningNodesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshAdminAclsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshAdminAclsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshClusterMaxPriorityRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshClusterMaxPriorityResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshQueuesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshQueuesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshSuperUserGroupsConfigurationRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshSuperUserGroupsConfigurationResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshUserToGroupsMappingsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshUserToGroupsMappingsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RemoveFromClusterNodeLabelsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RemoveFromClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceResponse;
-import org.junit.After;
-import org.junit.Assert;
-import org.junit.Before;
-
-/**
- * Base class for all the RouterRMAdminService test cases. It provides utility
- * methods that can be used by the concrete test case classes.
- *
- */
-public abstract class BaseRouterRMAdminTest {
-
-  /**
-   * The RouterRMAdminService instance that will be used by all the test cases.
-   */
-  private MockRouterRMAdminService rmAdminService;
-  /**
-   * Thread pool used for asynchronous operations.
-   */
-  private static ExecutorService threadpool = Executors.newCachedThreadPool();
-  private Configuration conf;
-  private AsyncDispatcher dispatcher;
-
-  public final static int TEST_MAX_CACHE_SIZE = 10;
-
-  protected MockRouterRMAdminService getRouterRMAdminService() {
-    Assert.assertNotNull(this.rmAdminService);
-    return this.rmAdminService;
-  }
-
-  @Before
-  public void setUp() {
-    this.conf = createConfiguration();
-    this.dispatcher = new AsyncDispatcher();
-    this.dispatcher.init(conf);
-    this.dispatcher.start();
-    this.rmAdminService = createAndStartRouterRMAdminService();
-    DefaultMetricsSystem.setMiniClusterMode(true);
-  }
-
-  protected Configuration getConf() {
-    return this.conf;
-  }
-
-  public void setUpConfig() {
-    this.conf = createConfiguration();
-  }
-
-  protected Configuration createConfiguration() {
-    YarnConfiguration config = new YarnConfiguration();
-    String mockPassThroughInterceptorClass =
-        PassThroughRMAdminRequestInterceptor.class.getName();
-
-    // Create a request interceptor pipeline for testing. The last one in the
-    // chain will call the mock resource manager. The others in the chain will
-    // simply forward it to the next one in the chain
-    config.set(YarnConfiguration.ROUTER_RMADMIN_INTERCEPTOR_CLASS_PIPELINE,
-        mockPassThroughInterceptorClass + "," + mockPassThroughInterceptorClass + "," +
-        mockPassThroughInterceptorClass + "," + MockRMAdminRequestInterceptor.class.getName());
-
-    config.setInt(YarnConfiguration.ROUTER_PIPELINE_CACHE_MAX_SIZE, TEST_MAX_CACHE_SIZE);
-    return config;
-  }
-
-  @After
-  public void tearDown() {
-    if (rmAdminService != null) {
-      rmAdminService.stop();
-      rmAdminService = null;
-    }
-    if (this.dispatcher != null) {
-      this.dispatcher.stop();
-    }
-  }
-
-  protected ExecutorService getThreadPool() {
-    return threadpool;
-  }
-
-  protected MockRouterRMAdminService createAndStartRouterRMAdminService() {
-    MockRouterRMAdminService svc = new MockRouterRMAdminService();
-    svc.init(conf);
-    svc.start();
-    return svc;
-  }
-
-  protected static class MockRouterRMAdminService extends RouterRMAdminService {
-    public MockRouterRMAdminService() {
-      super();
-    }
-  }
-
-  protected RefreshQueuesResponse refreshQueues(String user)
-      throws IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs((PrivilegedExceptionAction<RefreshQueuesResponse>) () -> {
-          RefreshQueuesRequest req = RefreshQueuesRequest.newInstance();
-          RefreshQueuesResponse response =
-              getRouterRMAdminService().refreshQueues(req);
-          return response;
-        });
-  }
-
-  protected RefreshNodesResponse refreshNodes(String user)
-      throws IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs((PrivilegedExceptionAction<RefreshNodesResponse>) () -> {
-          RefreshNodesRequest req = RefreshNodesRequest.newInstance();
-          RefreshNodesResponse response =
-              getRouterRMAdminService().refreshNodes(req);
-          return response;
-        });
-  }
-
-  protected RefreshSuperUserGroupsConfigurationResponse refreshSuperUserGroupsConfiguration(
-      String user) throws IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user).doAs(
-        (PrivilegedExceptionAction<RefreshSuperUserGroupsConfigurationResponse>) () -> {
-          RefreshSuperUserGroupsConfigurationRequest req =
-              RefreshSuperUserGroupsConfigurationRequest.newInstance();
-          RefreshSuperUserGroupsConfigurationResponse response =
-              getRouterRMAdminService()
-                  .refreshSuperUserGroupsConfiguration(req);
-          return response;
-        });
-  }
-
-  protected RefreshUserToGroupsMappingsResponse refreshUserToGroupsMappings(
-      String user) throws IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user).doAs(
-        (PrivilegedExceptionAction<RefreshUserToGroupsMappingsResponse>) () -> {
-          RefreshUserToGroupsMappingsRequest req =
-              RefreshUserToGroupsMappingsRequest.newInstance();
-          RefreshUserToGroupsMappingsResponse response =
-              getRouterRMAdminService().refreshUserToGroupsMappings(req);
-          return response;
-        });
-  }
-
-  protected RefreshAdminAclsResponse refreshAdminAcls(String user)
-      throws IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs((PrivilegedExceptionAction<RefreshAdminAclsResponse>) () -> {
-          RefreshAdminAclsRequest req = RefreshAdminAclsRequest.newInstance();
-          RefreshAdminAclsResponse response =
-              getRouterRMAdminService().refreshAdminAcls(req);
-          return response;
-        });
-  }
-
-  protected RefreshServiceAclsResponse refreshServiceAcls(String user)
-      throws IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs((PrivilegedExceptionAction<RefreshServiceAclsResponse>) () -> {
-          RefreshServiceAclsRequest req =
-              RefreshServiceAclsRequest.newInstance();
-          RefreshServiceAclsResponse response =
-              getRouterRMAdminService().refreshServiceAcls(req);
-          return response;
-        });
-  }
-
-  protected UpdateNodeResourceResponse updateNodeResource(String user)
-      throws IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs((PrivilegedExceptionAction<UpdateNodeResourceResponse>) () -> {
-          UpdateNodeResourceRequest req =
-              UpdateNodeResourceRequest.newInstance(null);
-          UpdateNodeResourceResponse response =
-              getRouterRMAdminService().updateNodeResource(req);
-          return response;
-        });
-  }
-
-  protected RefreshNodesResourcesResponse refreshNodesResources(String user)
-      throws IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs((PrivilegedExceptionAction<RefreshNodesResourcesResponse>) () -> {
-          RefreshNodesResourcesRequest req =
-              RefreshNodesResourcesRequest.newInstance();
-          RefreshNodesResourcesResponse response =
-              getRouterRMAdminService().refreshNodesResources(req);
-          return response;
-        });
-  }
-
-  protected AddToClusterNodeLabelsResponse addToClusterNodeLabels(String user)
-      throws IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs((PrivilegedExceptionAction<AddToClusterNodeLabelsResponse>) () -> {
-          AddToClusterNodeLabelsRequest req =
-              AddToClusterNodeLabelsRequest.newInstance(null);
-          AddToClusterNodeLabelsResponse response =
-              getRouterRMAdminService().addToClusterNodeLabels(req);
-          return response;
-        });
-  }
-
-  protected RemoveFromClusterNodeLabelsResponse removeFromClusterNodeLabels(
-      String user) throws IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user).doAs(
-        (PrivilegedExceptionAction<RemoveFromClusterNodeLabelsResponse>) () -> {
-          RemoveFromClusterNodeLabelsRequest req =
-              RemoveFromClusterNodeLabelsRequest.newInstance(null);
-          RemoveFromClusterNodeLabelsResponse response =
-              getRouterRMAdminService().removeFromClusterNodeLabels(req);
-          return response;
-        });
-  }
-
-  protected ReplaceLabelsOnNodeResponse replaceLabelsOnNode(String user)
-      throws IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs((PrivilegedExceptionAction<ReplaceLabelsOnNodeResponse>) () -> {
-          ReplaceLabelsOnNodeRequest req = ReplaceLabelsOnNodeRequest
-              .newInstance(new HashMap<NodeId, Set<String>>());
-          ReplaceLabelsOnNodeResponse response =
-              getRouterRMAdminService().replaceLabelsOnNode(req);
-          return response;
-        });
-  }
-
-  protected CheckForDecommissioningNodesResponse checkForDecommissioningNodes(
-      String user) throws IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user).doAs(
-        (PrivilegedExceptionAction<CheckForDecommissioningNodesResponse>) () -> {
-          CheckForDecommissioningNodesRequest req =
-              CheckForDecommissioningNodesRequest.newInstance();
-          CheckForDecommissioningNodesResponse response =
-              getRouterRMAdminService().checkForDecommissioningNodes(req);
-          return response;
-        });
-  }
-
-  protected RefreshClusterMaxPriorityResponse refreshClusterMaxPriority(
-      String user) throws IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user).doAs(
-        (PrivilegedExceptionAction<RefreshClusterMaxPriorityResponse>) () -> {
-          RefreshClusterMaxPriorityRequest req =
-              RefreshClusterMaxPriorityRequest.newInstance();
-          RefreshClusterMaxPriorityResponse response =
-              getRouterRMAdminService().refreshClusterMaxPriority(req);
-          return response;
-        });
-  }
-
-  protected String[] getGroupsForUser(String user)
-      throws IOException, InterruptedException {
-    return UserGroupInformation.createRemoteUser(user)
-        .doAs(new PrivilegedExceptionAction<String[]>() {
-          @Override
-          public String[] run() throws Exception {
-            String[] response =
-                getRouterRMAdminService().getGroupsForUser(user);
-            return response;
-          }
-        });
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/MockRMAdminRequestInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/MockRMAdminRequestInterceptor.java
deleted file mode 100644
index a1a366f7664..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/MockRMAdminRequestInterceptor.java
+++ /dev/null
@@ -1,72 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.rmadmin;
-
-import java.io.IOException;
-
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsResponse;
-import org.apache.hadoop.yarn.server.resourcemanager.AdminService;
-import org.apache.hadoop.yarn.server.resourcemanager.MockRM;
-
-/**
- * This class mocks the RMAdminRequestInterceptor.
- */
-public class MockRMAdminRequestInterceptor
-    extends DefaultRMAdminRequestInterceptor {
-
-  MockRM mockRM = null;
-  public void init(String user) {
-    mockRM = new MockRM(super.getConf()) {
-      @Override
-      protected AdminService createAdminService() {
-        return new AdminService(this) {
-          @Override
-          protected void startServer() {
-            // override to not start rpc handler
-          }
-
-          @Override
-          public RefreshServiceAclsResponse refreshServiceAcls(
-              RefreshServiceAclsRequest request)
-              throws YarnException, IOException {
-            return RefreshServiceAclsResponse.newInstance();
-          }
-
-          @Override
-          protected void stopServer() {
-            // don't do anything
-          }
-        };
-      }
-    };
-    mockRM.init(super.getConf());
-    mockRM.start();
-    super.setRMAdmin(mockRM.getAdminService());
-  }
-
-  @Override
-  public void shutdown() {
-    if (mockRM != null) {
-      mockRM.stop();
-    }
-    super.shutdown();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/PassThroughRMAdminRequestInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/PassThroughRMAdminRequestInterceptor.java
deleted file mode 100644
index 943e9440ecf..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/PassThroughRMAdminRequestInterceptor.java
+++ /dev/null
@@ -1,212 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.rmadmin;
-
-import java.io.IOException;
-
-import org.apache.hadoop.ipc.StandbyException;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.CheckForDecommissioningNodesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.CheckForDecommissioningNodesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshAdminAclsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshAdminAclsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshClusterMaxPriorityRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshClusterMaxPriorityResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshQueuesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshQueuesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshSuperUserGroupsConfigurationRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshSuperUserGroupsConfigurationResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshUserToGroupsMappingsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshUserToGroupsMappingsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RemoveFromClusterNodeLabelsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RemoveFromClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeregisterSubClusterRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeregisterSubClusterResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.SaveFederationQueuePolicyRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.SaveFederationQueuePolicyResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.BatchSaveFederationQueuePoliciesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.BatchSaveFederationQueuePoliciesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.QueryFederationQueuePoliciesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.QueryFederationQueuePoliciesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationApplicationRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationApplicationResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.GetSubClustersRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.GetSubClustersResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationQueuePoliciesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationQueuePoliciesResponse;
-
-/**
- * Mock interceptor that does not do anything other than forwarding it to the
- * next interceptor in the chain.
- */
-public class PassThroughRMAdminRequestInterceptor
-    extends AbstractRMAdminRequestInterceptor {
-
-  @Override
-  public RefreshQueuesResponse refreshQueues(RefreshQueuesRequest request)
-      throws StandbyException, YarnException, IOException {
-    return getNextInterceptor().refreshQueues(request);
-  }
-
-  @Override
-  public RefreshNodesResponse refreshNodes(RefreshNodesRequest request)
-      throws StandbyException, YarnException, IOException {
-    return getNextInterceptor().refreshNodes(request);
-  }
-
-  @Override
-  public RefreshSuperUserGroupsConfigurationResponse refreshSuperUserGroupsConfiguration(
-      RefreshSuperUserGroupsConfigurationRequest request)
-      throws StandbyException, YarnException, IOException {
-    return getNextInterceptor().refreshSuperUserGroupsConfiguration(request);
-  }
-
-  @Override
-  public RefreshUserToGroupsMappingsResponse refreshUserToGroupsMappings(
-      RefreshUserToGroupsMappingsRequest request)
-      throws StandbyException, YarnException, IOException {
-    return getNextInterceptor().refreshUserToGroupsMappings(request);
-  }
-
-  @Override
-  public RefreshAdminAclsResponse refreshAdminAcls(
-      RefreshAdminAclsRequest request) throws YarnException, IOException {
-    return getNextInterceptor().refreshAdminAcls(request);
-  }
-
-  @Override
-  public RefreshServiceAclsResponse refreshServiceAcls(
-      RefreshServiceAclsRequest request) throws YarnException, IOException {
-    return getNextInterceptor().refreshServiceAcls(request);
-  }
-
-  @Override
-  public UpdateNodeResourceResponse updateNodeResource(
-      UpdateNodeResourceRequest request) throws YarnException, IOException {
-    return getNextInterceptor().updateNodeResource(request);
-  }
-
-  @Override
-  public RefreshNodesResourcesResponse refreshNodesResources(
-      RefreshNodesResourcesRequest request) throws YarnException, IOException {
-    return getNextInterceptor().refreshNodesResources(request);
-  }
-
-  @Override
-  public AddToClusterNodeLabelsResponse addToClusterNodeLabels(
-      AddToClusterNodeLabelsRequest request) throws YarnException, IOException {
-    return getNextInterceptor().addToClusterNodeLabels(request);
-  }
-
-  @Override
-  public RemoveFromClusterNodeLabelsResponse removeFromClusterNodeLabels(
-      RemoveFromClusterNodeLabelsRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().removeFromClusterNodeLabels(request);
-  }
-
-  @Override
-  public ReplaceLabelsOnNodeResponse replaceLabelsOnNode(
-      ReplaceLabelsOnNodeRequest request) throws YarnException, IOException {
-    return getNextInterceptor().replaceLabelsOnNode(request);
-  }
-
-  @Override
-  public CheckForDecommissioningNodesResponse checkForDecommissioningNodes(
-      CheckForDecommissioningNodesRequest checkForDecommissioningNodesRequest)
-      throws YarnException, IOException {
-    return getNextInterceptor()
-        .checkForDecommissioningNodes(checkForDecommissioningNodesRequest);
-  }
-
-  @Override
-  public RefreshClusterMaxPriorityResponse refreshClusterMaxPriority(
-      RefreshClusterMaxPriorityRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().refreshClusterMaxPriority(request);
-  }
-
-  @Override
-  public String[] getGroupsForUser(String user) throws IOException {
-    return getNextInterceptor().getGroupsForUser(user);
-  }
-
-  @Override
-  public NodesToAttributesMappingResponse mapAttributesToNodes(
-      NodesToAttributesMappingRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().mapAttributesToNodes(request);
-  }
-
-  @Override
-  public DeregisterSubClusterResponse deregisterSubCluster(DeregisterSubClusterRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().deregisterSubCluster(request);
-  }
-
-  @Override
-  public SaveFederationQueuePolicyResponse saveFederationQueuePolicy(
-      SaveFederationQueuePolicyRequest request) throws YarnException, IOException {
-    return getNextInterceptor().saveFederationQueuePolicy(request);
-  }
-
-  @Override
-  public BatchSaveFederationQueuePoliciesResponse batchSaveFederationQueuePolicies(
-      BatchSaveFederationQueuePoliciesRequest request) throws YarnException, IOException {
-    return getNextInterceptor().batchSaveFederationQueuePolicies(request);
-  }
-
-  @Override
-  public QueryFederationQueuePoliciesResponse listFederationQueuePolicies(
-      QueryFederationQueuePoliciesRequest request) throws YarnException, IOException {
-    return getNextInterceptor().listFederationQueuePolicies(request);
-  }
-
-  @Override
-  public DeleteFederationApplicationResponse deleteFederationApplication(
-      DeleteFederationApplicationRequest request) throws YarnException, IOException {
-    return getNextInterceptor().deleteFederationApplication(request);
-  }
-
-  @Override
-  public GetSubClustersResponse getFederationSubClusters(GetSubClustersRequest request)
-      throws YarnException, IOException {
-    return getNextInterceptor().getFederationSubClusters(request);
-  }
-
-  @Override
-  public DeleteFederationQueuePoliciesResponse deleteFederationPoliciesByQueues(
-      DeleteFederationQueuePoliciesRequest request) throws YarnException, IOException {
-    return getNextInterceptor().deleteFederationPoliciesByQueues(request);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/TestFederationRMAdminInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/TestFederationRMAdminInterceptor.java
deleted file mode 100644
index ffea73bc712..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/TestFederationRMAdminInterceptor.java
+++ /dev/null
@@ -1,1092 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.rmadmin;
-
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.fs.CommonConfigurationKeysPublic;
-import org.apache.hadoop.metrics2.lib.DefaultMetricsSystem;
-import org.apache.hadoop.test.LambdaTestUtils;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.DecommissionType;
-import org.apache.hadoop.yarn.api.records.NodeId;
-import org.apache.hadoop.yarn.api.records.Resource;
-import org.apache.hadoop.yarn.api.records.ResourceOption;
-import org.apache.hadoop.yarn.api.records.NodeLabel;
-import org.apache.hadoop.yarn.api.records.NodeAttribute;
-import org.apache.hadoop.yarn.api.records.NodeAttributeType;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshQueuesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshQueuesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshSuperUserGroupsConfigurationRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshSuperUserGroupsConfigurationResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshUserToGroupsMappingsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshUserToGroupsMappingsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshAdminAclsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshAdminAclsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RemoveFromClusterNodeLabelsRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RemoveFromClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.CheckForDecommissioningNodesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.CheckForDecommissioningNodesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.NodesToAttributesMappingRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.AttributeMappingOperationType;
-import org.apache.hadoop.yarn.server.api.protocolrecords.NodeToAttributes;
-import org.apache.hadoop.yarn.server.api.protocolrecords.FederationQueueWeight;
-import org.apache.hadoop.yarn.server.api.protocolrecords.SaveFederationQueuePolicyRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.SaveFederationQueuePolicyResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.BatchSaveFederationQueuePoliciesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.BatchSaveFederationQueuePoliciesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.QueryFederationQueuePoliciesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.QueryFederationQueuePoliciesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationApplicationRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationApplicationResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.GetSubClustersRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.GetSubClustersResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.FederationSubCluster;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationQueuePoliciesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.DeleteFederationQueuePoliciesResponse;
-import org.apache.hadoop.yarn.server.federation.policies.dao.WeightedPolicyInfo;
-import org.apache.hadoop.yarn.server.federation.policies.manager.WeightedLocalityPolicyManager;
-import org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterIdInfo;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterPolicyConfiguration;
-import org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreTestUtil;
-import org.junit.Assert;
-import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.nio.ByteBuffer;
-import java.text.DecimalFormat;
-import java.util.ArrayList;
-import java.util.Collections;
-import java.util.HashMap;
-import java.util.List;
-import java.util.LinkedHashMap;
-import java.util.Map;
-import java.util.Set;
-import java.util.HashSet;
-import java.util.Random;
-
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertNotNull;
-
-/**
- * Extends the FederationRMAdminInterceptor and overrides methods to provide a
- * testable implementation of FederationRMAdminInterceptor.
- */
-public class TestFederationRMAdminInterceptor extends BaseRouterRMAdminTest {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestFederationRMAdminInterceptor.class);
-
-  ////////////////////////////////
-  // constant information
-  ////////////////////////////////
-  private final static String USER_NAME = "test-user";
-  private final static int NUM_SUBCLUSTER = 4;
-  private final static int GB = 1024;
-
-  private TestableFederationRMAdminInterceptor interceptor;
-  private FederationStateStoreFacade facade;
-  private MemoryFederationStateStore stateStore;
-  private FederationStateStoreTestUtil stateStoreUtil;
-  private List<SubClusterId> subClusters;
-
-  @Override
-  public void setUp() {
-
-    super.setUpConfig();
-
-    // Initialize facade & stateSore
-    stateStore = new MemoryFederationStateStore();
-    stateStore.init(this.getConf());
-    facade = FederationStateStoreFacade.getInstance(this.getConf());
-    facade.reinitialize(stateStore, this.getConf());
-    stateStoreUtil = new FederationStateStoreTestUtil(stateStore);
-
-    // Initialize interceptor
-    interceptor = new TestableFederationRMAdminInterceptor();
-    interceptor.setConf(this.getConf());
-    interceptor.init(USER_NAME);
-
-    // Storage SubClusters
-    subClusters = new ArrayList<>();
-    try {
-      for (int i = 0; i < NUM_SUBCLUSTER; i++) {
-        SubClusterId sc = SubClusterId.newInstance("SC-" + i);
-        stateStoreUtil.registerSubCluster(sc);
-        subClusters.add(sc);
-      }
-    } catch (YarnException e) {
-      LOG.error(e.getMessage());
-      Assert.fail();
-    }
-
-    DefaultMetricsSystem.setMiniClusterMode(true);
-  }
-
-  @Override
-  protected YarnConfiguration createConfiguration() {
-    // Set Enable YarnFederation
-    YarnConfiguration config = new YarnConfiguration();
-    config.setBoolean(YarnConfiguration.FEDERATION_ENABLED, true);
-
-    String mockPassThroughInterceptorClass =
-        PassThroughRMAdminRequestInterceptor.class.getName();
-
-    // Create a request interceptor pipeline for testing. The last one in the
-    // chain will call the mock resource manager. The others in the chain will
-    // simply forward it to the next one in the chain
-    config.set(YarnConfiguration.ROUTER_RMADMIN_INTERCEPTOR_CLASS_PIPELINE,
-        mockPassThroughInterceptorClass + "," + mockPassThroughInterceptorClass + "," +
-        TestFederationRMAdminInterceptor.class.getName());
-    config.setBoolean(
-        CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION, true);
-    return config;
-  }
-
-  @Override
-  public void tearDown() {
-    interceptor.shutdown();
-    super.tearDown();
-  }
-
-  @Test
-  public void testRefreshQueues() throws Exception {
-    // We will test 2 cases:
-    // case 1, request is null.
-    // case 2, normal request.
-    // If the request is null, a Missing RefreshQueues request exception will be thrown.
-
-    // null request.
-    LambdaTestUtils.intercept(YarnException.class, "Missing RefreshQueues request.",
-        () -> interceptor.refreshQueues(null));
-
-    // normal request.
-    RefreshQueuesRequest request = RefreshQueuesRequest.newInstance();
-    RefreshQueuesResponse response = interceptor.refreshQueues(request);
-    assertNotNull(response);
-  }
-
-  @Test
-  public void testSC1RefreshQueues() throws Exception {
-    // We will test 2 cases:
-    // case 1, test the existing subCluster (SC-1).
-    // case 2, test the non-exist subCluster.
-
-    String existSubCluster = "SC-1";
-    RefreshQueuesRequest request = RefreshQueuesRequest.newInstance(existSubCluster);
-    interceptor.refreshQueues(request);
-
-    String notExistsSubCluster = "SC-NON";
-    RefreshQueuesRequest request1 = RefreshQueuesRequest.newInstance(notExistsSubCluster);
-    LambdaTestUtils.intercept(YarnException.class,
-        "subClusterId = SC-NON is not an active subCluster.",
-        () -> interceptor.refreshQueues(request1));
-  }
-
-  @Test
-  public void testRefreshNodes() throws Exception {
-    // We will test 2 cases:
-    // case 1, request is null.
-    // case 2, normal request.
-    // If the request is null, a Missing RefreshNodes request exception will be thrown.
-
-    // null request.
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing RefreshNodes request.", () -> interceptor.refreshNodes(null));
-
-    // normal request.
-    RefreshNodesRequest request = RefreshNodesRequest.newInstance(DecommissionType.NORMAL);
-    interceptor.refreshNodes(request);
-  }
-
-  @Test
-  public void testSC1RefreshNodes() throws Exception {
-
-    // We will test 2 cases:
-    // case 1, test the existing subCluster (SC-1).
-    // case 2, test the non-exist subCluster.
-
-    RefreshNodesRequest request =
-        RefreshNodesRequest.newInstance(DecommissionType.NORMAL, 10, "SC-1");
-    interceptor.refreshNodes(request);
-
-    String notExistsSubCluster = "SC-NON";
-    RefreshNodesRequest request1 = RefreshNodesRequest.newInstance(
-        DecommissionType.NORMAL, 10, notExistsSubCluster);
-    LambdaTestUtils.intercept(YarnException.class,
-        "subClusterId = SC-NON is not an active subCluster.",
-        () -> interceptor.refreshNodes(request1));
-  }
-
-  @Test
-  public void testRefreshSuperUserGroupsConfiguration() throws Exception {
-    // null request.
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing RefreshSuperUserGroupsConfiguration request.",
-        () -> interceptor.refreshSuperUserGroupsConfiguration(null));
-
-    // normal request.
-    // There is no return information defined in RefreshSuperUserGroupsConfigurationResponse,
-    // as long as it is not empty, it means that the command is successfully executed.
-    RefreshSuperUserGroupsConfigurationRequest request =
-        RefreshSuperUserGroupsConfigurationRequest.newInstance();
-    RefreshSuperUserGroupsConfigurationResponse response =
-        interceptor.refreshSuperUserGroupsConfiguration(request);
-    assertNotNull(response);
-  }
-
-  @Test
-  public void testSC1RefreshSuperUserGroupsConfiguration() throws Exception {
-
-    // case 1, test the existing subCluster (SC-1).
-    String existSubCluster = "SC-1";
-    RefreshSuperUserGroupsConfigurationRequest request =
-        RefreshSuperUserGroupsConfigurationRequest.newInstance(existSubCluster);
-    RefreshSuperUserGroupsConfigurationResponse response =
-        interceptor.refreshSuperUserGroupsConfiguration(request);
-    assertNotNull(response);
-
-    // case 2, test the non-exist subCluster.
-    String notExistsSubCluster = "SC-NON";
-    RefreshSuperUserGroupsConfigurationRequest request1 =
-        RefreshSuperUserGroupsConfigurationRequest.newInstance(notExistsSubCluster);
-    LambdaTestUtils.intercept(Exception.class,
-        "subClusterId = SC-NON is not an active subCluster.",
-        () -> interceptor.refreshSuperUserGroupsConfiguration(request1));
-  }
-
-  @Test
-  public void testRefreshUserToGroupsMappings() throws Exception {
-    // null request.
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing RefreshUserToGroupsMappings request.",
-        () -> interceptor.refreshUserToGroupsMappings(null));
-
-    // normal request.
-    RefreshUserToGroupsMappingsRequest request = RefreshUserToGroupsMappingsRequest.newInstance();
-    RefreshUserToGroupsMappingsResponse response = interceptor.refreshUserToGroupsMappings(request);
-    assertNotNull(response);
-  }
-
-  @Test
-  public void testSC1RefreshUserToGroupsMappings() throws Exception {
-    // case 1, test the existing subCluster (SC-1).
-    String existSubCluster = "SC-1";
-    RefreshUserToGroupsMappingsRequest request =
-        RefreshUserToGroupsMappingsRequest.newInstance(existSubCluster);
-    RefreshUserToGroupsMappingsResponse response =
-        interceptor.refreshUserToGroupsMappings(request);
-    assertNotNull(response);
-
-    // case 2, test the non-exist subCluster.
-    String notExistsSubCluster = "SC-NON";
-    RefreshUserToGroupsMappingsRequest request1 =
-        RefreshUserToGroupsMappingsRequest.newInstance(notExistsSubCluster);
-    LambdaTestUtils.intercept(Exception.class,
-        "subClusterId = SC-NON is not an active subCluster.",
-        () -> interceptor.refreshUserToGroupsMappings(request1));
-  }
-
-  @Test
-  public void testRefreshAdminAcls() throws Exception {
-    // null request.
-    LambdaTestUtils.intercept(YarnException.class, "Missing RefreshAdminAcls request.",
-        () -> interceptor.refreshAdminAcls(null));
-
-    // normal request.
-    RefreshAdminAclsRequest request = RefreshAdminAclsRequest.newInstance();
-    RefreshAdminAclsResponse response = interceptor.refreshAdminAcls(request);
-    assertNotNull(response);
-  }
-
-  @Test
-  public void testSC1RefreshAdminAcls() throws Exception {
-    // case 1, test the existing subCluster (SC-1).
-    String existSubCluster = "SC-1";
-    RefreshAdminAclsRequest request = RefreshAdminAclsRequest.newInstance(existSubCluster);
-    RefreshAdminAclsResponse response = interceptor.refreshAdminAcls(request);
-    assertNotNull(response);
-
-    // case 2, test the non-exist subCluster.
-    String notExistsSubCluster = "SC-NON";
-    RefreshAdminAclsRequest request1 = RefreshAdminAclsRequest.newInstance(notExistsSubCluster);
-    LambdaTestUtils.intercept(Exception.class, "subClusterId = SC-NON is not an active subCluster.",
-        () -> interceptor.refreshAdminAcls(request1));
-  }
-
-  @Test
-  public void testRefreshServiceAcls() throws Exception {
-    // null request.
-    LambdaTestUtils.intercept(YarnException.class, "Missing RefreshServiceAcls request.",
-        () -> interceptor.refreshServiceAcls(null));
-
-    // normal request.
-    RefreshServiceAclsRequest request = RefreshServiceAclsRequest.newInstance();
-    RefreshServiceAclsResponse response = interceptor.refreshServiceAcls(request);
-    assertNotNull(response);
-  }
-
-  @Test
-  public void testSC1RefreshServiceAcls() throws Exception {
-    // case 1, test the existing subCluster (SC-1).
-    String existSubCluster = "SC-1";
-    RefreshServiceAclsRequest request = RefreshServiceAclsRequest.newInstance(existSubCluster);
-    RefreshServiceAclsResponse response = interceptor.refreshServiceAcls(request);
-    assertNotNull(response);
-
-    // case 2, test the non-exist subCluster.
-    String notExistsSubCluster = "SC-NON";
-    RefreshServiceAclsRequest request1 = RefreshServiceAclsRequest.newInstance(notExistsSubCluster);
-    LambdaTestUtils.intercept(Exception.class, "subClusterId = SC-NON is not an active subCluster.",
-        () -> interceptor.refreshServiceAcls(request1));
-  }
-
-  @Test
-  public void testUpdateNodeResourceEmptyRequest() throws Exception {
-    // null request1.
-    LambdaTestUtils.intercept(YarnException.class, "Missing UpdateNodeResource request.",
-        () -> interceptor.updateNodeResource(null));
-
-    // null request2.
-    Map<NodeId, ResourceOption> nodeResourceMap = new HashMap<>();
-    UpdateNodeResourceRequest request = UpdateNodeResourceRequest.newInstance(nodeResourceMap);
-    LambdaTestUtils.intercept(YarnException.class, "Missing UpdateNodeResource SubClusterId.",
-        () -> interceptor.updateNodeResource(request));
-  }
-
-  @Test
-  public void testUpdateNodeResourceNormalRequest() throws Exception {
-    // case 1, test the existing subCluster (SC-1).
-    Map<NodeId, ResourceOption> nodeResourceMap = new HashMap<>();
-    NodeId nodeId = NodeId.newInstance("127.0.0.1", 1);
-    ResourceOption resourceOption =
-        ResourceOption.newInstance(Resource.newInstance(2 * GB, 1), -1);
-    nodeResourceMap.put(nodeId, resourceOption);
-    UpdateNodeResourceRequest request =
-        UpdateNodeResourceRequest.newInstance(nodeResourceMap, "SC-1");
-    UpdateNodeResourceResponse response = interceptor.updateNodeResource(request);
-    assertNotNull(response);
-
-    // case 2, test the non-exist subCluster.
-    UpdateNodeResourceRequest request1 =
-        UpdateNodeResourceRequest.newInstance(nodeResourceMap, "SC-NON");
-    LambdaTestUtils.intercept(Exception.class, "subClusterId = SC-NON is not an active subCluster.",
-        () -> interceptor.updateNodeResource(request1));
-  }
-
-  @Test
-  public void testRefreshNodesResourcesEmptyRequest() throws Exception {
-    // null request1.
-    LambdaTestUtils.intercept(YarnException.class, "Missing RefreshNodesResources request.",
-        () -> interceptor.refreshNodesResources(null));
-
-    // null request2.
-    RefreshNodesResourcesRequest request = RefreshNodesResourcesRequest.newInstance();
-    LambdaTestUtils.intercept(YarnException.class, "Missing RefreshNodesResources SubClusterId.",
-        () -> interceptor.refreshNodesResources(request));
-  }
-
-  @Test
-  public void testRefreshNodesResourcesNormalRequest() throws Exception {
-    // case 1, test the existing subCluster (SC-1).
-    RefreshNodesResourcesRequest request = RefreshNodesResourcesRequest.newInstance("SC-1");
-    RefreshNodesResourcesResponse response = interceptor.refreshNodesResources(request);
-    assertNotNull(response);
-
-    // case 2, test the non-exist subCluster.
-    RefreshNodesResourcesRequest request1 = RefreshNodesResourcesRequest.newInstance("SC-NON");
-    LambdaTestUtils.intercept(Exception.class, "subClusterId = SC-NON is not an active subCluster.",
-        () -> interceptor.refreshNodesResources(request1));
-  }
-
-  @Test
-  public void testAddToClusterNodeLabelsEmptyRequest() throws Exception {
-    // null request1.
-    LambdaTestUtils.intercept(YarnException.class, "Missing AddToClusterNodeLabels request.",
-        () -> interceptor.addToClusterNodeLabels(null));
-
-    // null request2.
-    AddToClusterNodeLabelsRequest request = AddToClusterNodeLabelsRequest.newInstance(null, null);
-    LambdaTestUtils.intercept(YarnException.class, "Missing AddToClusterNodeLabels SubClusterId.",
-        () -> interceptor.addToClusterNodeLabels(request));
-  }
-
-  @Test
-  public void testAddToClusterNodeLabelsNormalRequest() throws Exception {
-    // case1, We add NodeLabel to subCluster SC-1
-    NodeLabel nodeLabelA = NodeLabel.newInstance("a");
-    NodeLabel nodeLabelB = NodeLabel.newInstance("b");
-    List<NodeLabel> labels = new ArrayList<>();
-    labels.add(nodeLabelA);
-    labels.add(nodeLabelB);
-
-    AddToClusterNodeLabelsRequest request =
-        AddToClusterNodeLabelsRequest.newInstance("SC-1", labels);
-    AddToClusterNodeLabelsResponse response = interceptor.addToClusterNodeLabels(request);
-    assertNotNull(response);
-
-    // case2, test the non-exist subCluster.
-    AddToClusterNodeLabelsRequest request1 =
-        AddToClusterNodeLabelsRequest.newInstance("SC-NON", labels);
-    LambdaTestUtils.intercept(Exception.class, "subClusterId = SC-NON is not an active subCluster.",
-        () -> interceptor.addToClusterNodeLabels(request1));
-  }
-
-  @Test
-  public void testRemoveFromClusterNodeLabelsEmptyRequest() throws Exception {
-    // null request1.
-    LambdaTestUtils.intercept(YarnException.class, "Missing RemoveFromClusterNodeLabels request.",
-        () -> interceptor.removeFromClusterNodeLabels(null));
-
-    // null request2.
-    RemoveFromClusterNodeLabelsRequest request =
-        RemoveFromClusterNodeLabelsRequest.newInstance(null, null);
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing RemoveFromClusterNodeLabels SubClusterId.",
-        () -> interceptor.removeFromClusterNodeLabels(request));
-  }
-
-  @Test
-  public void testRemoveFromClusterNodeLabelsNormalRequest() throws Exception {
-    // case1, We add nodelabel a for SC-1, and then remove nodelabel a
-
-    // Step1. Add NodeLabel for subCluster SC-1
-    NodeLabel nodeLabelA = NodeLabel.newInstance("a");
-    NodeLabel nodeLabelB = NodeLabel.newInstance("b");
-    List<NodeLabel> nodeLabels = new ArrayList<>();
-    nodeLabels.add(nodeLabelA);
-    nodeLabels.add(nodeLabelB);
-
-    AddToClusterNodeLabelsRequest request =
-        AddToClusterNodeLabelsRequest.newInstance("SC-1", nodeLabels);
-    interceptor.addToClusterNodeLabels(request);
-
-    // Step2. We delete the label a of subCluster SC-1
-    Set<String> labels = new HashSet<>();
-    labels.add("a");
-
-    RemoveFromClusterNodeLabelsRequest request1 =
-        RemoveFromClusterNodeLabelsRequest.newInstance("SC-1", labels);
-    RemoveFromClusterNodeLabelsResponse response =
-        interceptor.removeFromClusterNodeLabels(request1);
-    assertNotNull(response);
-
-    // case2, test the non-exist subCluster.
-    RemoveFromClusterNodeLabelsRequest request2 =
-        RemoveFromClusterNodeLabelsRequest.newInstance("SC-NON", labels);
-    LambdaTestUtils.intercept(YarnException.class,
-        "subClusterId = SC-NON is not an active subCluster.",
-        () -> interceptor.removeFromClusterNodeLabels(request2));
-  }
-
-  @Test
-  public void testReplaceLabelsOnNodeEmptyRequest() throws Exception {
-    // null request1.
-    LambdaTestUtils.intercept(YarnException.class, "Missing ReplaceLabelsOnNode request.",
-        () -> interceptor.replaceLabelsOnNode(null));
-
-    // null request2.
-    Map<NodeId, Set<String>> labelMap = new HashMap<>();
-    ReplaceLabelsOnNodeRequest request = ReplaceLabelsOnNodeRequest.newInstance(labelMap, null);
-    LambdaTestUtils.intercept(YarnException.class, "Missing ReplaceLabelsOnNode SubClusterId.",
-        () -> interceptor.replaceLabelsOnNode(request));
-  }
-
-  @Test
-  public void tesReplaceLabelsOnNodeEmptyNormalRequest() throws Exception {
-    // case1, We add nodelabel for SC-1, and then replace the label for the specific node.
-    NodeLabel nodeLabelA = NodeLabel.newInstance("a");
-    NodeLabel nodeLabelB = NodeLabel.newInstance("b");
-    List<NodeLabel> nodeLabels = new ArrayList<>();
-    nodeLabels.add(nodeLabelA);
-    nodeLabels.add(nodeLabelB);
-
-    AddToClusterNodeLabelsRequest request =
-        AddToClusterNodeLabelsRequest.newInstance("SC-1", nodeLabels);
-    interceptor.addToClusterNodeLabels(request);
-
-    Map<NodeId, Set<String>> pMap = new HashMap<>();
-    NodeId nodeId = NodeId.newInstance("127.0.0.1", 0);
-    Set<String> labels = new HashSet<>();
-    labels.add("a");
-    pMap.put(nodeId, labels);
-
-    ReplaceLabelsOnNodeRequest request1 = ReplaceLabelsOnNodeRequest.newInstance(pMap, "SC-1");
-    ReplaceLabelsOnNodeResponse response = interceptor.replaceLabelsOnNode(request1);
-    assertNotNull(response);
-
-    // case2, test the non-exist subCluster.
-    ReplaceLabelsOnNodeRequest request2 =
-        ReplaceLabelsOnNodeRequest.newInstance(pMap, "SC-NON");
-    LambdaTestUtils.intercept(YarnException.class,
-        "subClusterId = SC-NON is not an active subCluster.",
-        () -> interceptor.replaceLabelsOnNode(request2));
-  }
-
-  @Test
-  public void testCheckForDecommissioningNodesRequest() throws Exception {
-    // null request1.
-    LambdaTestUtils.intercept(YarnException.class, "Missing checkForDecommissioningNodes request.",
-        () -> interceptor.checkForDecommissioningNodes(null));
-
-    // null request2.
-    CheckForDecommissioningNodesRequest request =
-        CheckForDecommissioningNodesRequest.newInstance(null);
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing checkForDecommissioningNodes SubClusterId.",
-        () -> interceptor.checkForDecommissioningNodes(request));
-  }
-
-  @Test
-  public void testCheckForDecommissioningNodesNormalRequest() throws Exception {
-    CheckForDecommissioningNodesRequest request =
-        CheckForDecommissioningNodesRequest.newInstance("SC-1");
-    CheckForDecommissioningNodesResponse response =
-        interceptor.checkForDecommissioningNodes(request);
-    assertNotNull(response);
-    Set<NodeId> nodeIds = response.getDecommissioningNodes();
-    assertNotNull(nodeIds);
-    assertEquals(0, nodeIds.size());
-  }
-
-  @Test
-  public void testMapAttributesToNodesRequest() throws Exception {
-    // null request1.
-    LambdaTestUtils.intercept(YarnException.class, "Missing mapAttributesToNodes request.",
-        () -> interceptor.mapAttributesToNodes(null));
-
-    // null request2.
-    NodeAttribute nodeAttribute = NodeAttribute.newInstance(NodeAttribute.PREFIX_CENTRALIZED, "x",
-        NodeAttributeType.STRING, "dfasdf");
-    List<NodeAttribute> nodeAttributeList = Collections.singletonList(nodeAttribute);
-    NodeToAttributes nodeToAttributes = NodeToAttributes.newInstance("host1", nodeAttributeList);
-    List<NodeToAttributes> nodeToAttributesList = Collections.singletonList(nodeToAttributes);
-    NodesToAttributesMappingRequest request = NodesToAttributesMappingRequest.newInstance(
-        AttributeMappingOperationType.ADD, nodeToAttributesList, true, null);
-    LambdaTestUtils.intercept(YarnException.class, "Missing mapAttributesToNodes SubClusterId.",
-        () -> interceptor.mapAttributesToNodes(request));
-  }
-
-  @Test
-  public void testMapAttributesToNodesNormalRequest() throws Exception {
-    NodeAttribute nodeAttribute = NodeAttribute.newInstance(NodeAttribute.PREFIX_CENTRALIZED, "x",
-        NodeAttributeType.STRING, "dfasdf");
-    List<NodeAttribute> nodeAttributeList = Collections.singletonList(nodeAttribute);
-    NodeToAttributes nodeToAttributes =
-        NodeToAttributes.newInstance("127.0.0.1", nodeAttributeList);
-    List<NodeToAttributes> nodeToAttributesList = Collections.singletonList(nodeToAttributes);
-    NodesToAttributesMappingRequest request = NodesToAttributesMappingRequest.newInstance(
-        AttributeMappingOperationType.ADD, nodeToAttributesList, true, "SC-1");
-    interceptor.mapAttributesToNodes(request);
-  }
-
-  @Test
-  public void testGetGroupsForUserRequest() throws Exception {
-    // null request1.
-    LambdaTestUtils.intercept(IOException.class, "Missing getGroupsForUser user.",
-        () -> interceptor.getGroupsForUser(null));
-  }
-
-  @Test
-  public void testGetGroupsForUserNormalRequest() throws Exception {
-    String[] groups = interceptor.getGroupsForUser("admin");
-    assertNotNull(groups);
-    assertEquals(1, groups.length);
-    assertEquals("admin", groups[0]);
-  }
-
-  @Test
-  public void testSaveFederationQueuePolicyErrorRequest() throws Exception {
-    // null request.
-    LambdaTestUtils.intercept(YarnException.class, "Missing SaveFederationQueuePolicy request.",
-        () -> interceptor.saveFederationQueuePolicy(null));
-
-    // federationQueueWeight is null.
-    LambdaTestUtils.intercept(
-        IllegalArgumentException.class, "FederationQueueWeight cannot be null.",
-        () -> SaveFederationQueuePolicyRequest.newInstance("root.a", null, "-"));
-
-    // queue is null
-    FederationQueueWeight federationQueueWeight =
-        FederationQueueWeight.newInstance("SC-1:0.7,SC-2:0.3", "SC-1:0.7,SC-2:0.3", "1.0");
-    SaveFederationQueuePolicyRequest request =
-        SaveFederationQueuePolicyRequest.newInstance("", federationQueueWeight, "-");
-    LambdaTestUtils.intercept(YarnException.class, "Missing Queue information.",
-        () -> interceptor.saveFederationQueuePolicy(request));
-
-    // PolicyManager needs to support weight
-    FederationQueueWeight federationQueueWeight2 = FederationQueueWeight.newInstance(
-        "SC-1:0.7,SC-2:0.3", "SC-1:0.8,SC-2:0.3", "1.0");
-    SaveFederationQueuePolicyRequest request2 =
-        SaveFederationQueuePolicyRequest.newInstance("root.a", federationQueueWeight2,
-        "TestPolicyManager");
-    LambdaTestUtils.intercept(YarnException.class,
-        "TestPolicyManager does not support the use of queue weights.",
-        () -> interceptor.saveFederationQueuePolicy(request2));
-
-    // routerWeight / amrmWeight
-    // The sum of the routerWeight is not equal to 1.
-    String policyTypeName = WeightedLocalityPolicyManager.class.getCanonicalName();
-    FederationQueueWeight federationQueueWeight3 = FederationQueueWeight.newInstance(
-        "SC-1:0.7,SC-2:0.3", "SC-1:0.8,SC-2:0.3", "1.0");
-    SaveFederationQueuePolicyRequest request3 =
-        SaveFederationQueuePolicyRequest.newInstance("root.a", federationQueueWeight3,
-        policyTypeName);
-    LambdaTestUtils.intercept(YarnException.class,
-        "The sum of ratios for all subClusters must be equal to 1.",
-        () -> interceptor.saveFederationQueuePolicy(request3));
-  }
-
-  @Test
-  public void testSaveFederationQueuePolicyRequest() throws IOException, YarnException {
-
-    // We design unit tests, including 2 SubCluster (SC-1, SC-2)
-    // Router Weight: SC-1=0.7,SC-2=0.3
-    // AMRM Weight: SC-1=0.6,SC-2=0.4
-    // headRoomAlpha: 1.0
-    String queue = "root.a";
-    String subCluster1 = "SC-1";
-    String subCluster2 = "SC-2";
-    String routerWeight = "SC-1:0.7,SC-2:0.3";
-    String amrmWeight = "SC-1:0.6,SC-2:0.4";
-    String headRoomAlpha = "1.0";
-
-    // Step1. Write FederationQueue information to stateStore.
-    String policyTypeName = WeightedLocalityPolicyManager.class.getCanonicalName();
-    FederationQueueWeight federationQueueWeight =
-        FederationQueueWeight.newInstance(routerWeight, amrmWeight, headRoomAlpha);
-    SaveFederationQueuePolicyRequest request =
-        SaveFederationQueuePolicyRequest.newInstance(queue, federationQueueWeight, policyTypeName);
-    SaveFederationQueuePolicyResponse response = interceptor.saveFederationQueuePolicy(request);
-    assertNotNull(response);
-    assertEquals("save policy success.", response.getMessage());
-
-    // Step2. We query Policy information from FederationStateStore.
-    FederationStateStoreFacade federationFacade = interceptor.getFederationFacade();
-    SubClusterPolicyConfiguration policyConfiguration =
-        federationFacade.getPolicyConfiguration(queue);
-    assertNotNull(policyConfiguration);
-    assertEquals(queue, policyConfiguration.getQueue());
-
-    ByteBuffer params = policyConfiguration.getParams();
-    assertNotNull(params);
-    WeightedPolicyInfo weightedPolicyInfo = WeightedPolicyInfo.fromByteBuffer(params);
-    assertNotNull(weightedPolicyInfo);
-
-    SubClusterIdInfo sc1 = new SubClusterIdInfo(subCluster1);
-    SubClusterIdInfo sc2 = new SubClusterIdInfo(subCluster2);
-
-    // Step3. We will compare the accuracy of routerPolicyWeights and amrmPolicyWeights.
-    Map<SubClusterIdInfo, Float> routerPolicyWeights = weightedPolicyInfo.getRouterPolicyWeights();
-    Float sc1Weight = routerPolicyWeights.get(sc1);
-    assertNotNull(sc1Weight);
-    assertEquals(0.7f, sc1Weight.floatValue(), 0.00001);
-
-    Float sc2Weight = routerPolicyWeights.get(sc2);
-    assertNotNull(sc2Weight);
-    assertEquals(0.3f, sc2Weight.floatValue(), 0.00001);
-
-    Map<SubClusterIdInfo, Float> amrmPolicyWeights = weightedPolicyInfo.getAMRMPolicyWeights();
-    Float sc1AMRMWeight = amrmPolicyWeights.get(sc1);
-    assertNotNull(sc1AMRMWeight);
-    assertEquals(0.6f, sc1AMRMWeight.floatValue(), 0.00001);
-
-    Float sc2AMRMWeight = amrmPolicyWeights.get(sc2);
-    assertNotNull(sc2AMRMWeight);
-    assertEquals(0.4f, sc2AMRMWeight.floatValue(), 0.00001);
-  }
-
-  @Test
-  public void testBatchSaveFederationQueuePoliciesRequest() throws IOException, YarnException {
-
-    // subClusters
-    List<String> subClusterLists = new ArrayList<>();
-    subClusterLists.add("SC-1");
-    subClusterLists.add("SC-2");
-
-    // generate queue A, queue B, queue C
-    FederationQueueWeight rootA = generateFederationQueueWeight("root.a", subClusterLists);
-    FederationQueueWeight rootB = generateFederationQueueWeight("root.b", subClusterLists);
-    FederationQueueWeight rootC = generateFederationQueueWeight("root.b", subClusterLists);
-
-    List<FederationQueueWeight> federationQueueWeights = new ArrayList<>();
-    federationQueueWeights.add(rootA);
-    federationQueueWeights.add(rootB);
-    federationQueueWeights.add(rootC);
-
-    // Step1. Save Queue Policies in Batches
-    BatchSaveFederationQueuePoliciesRequest request =
-        BatchSaveFederationQueuePoliciesRequest.newInstance(federationQueueWeights);
-
-    BatchSaveFederationQueuePoliciesResponse policiesResponse =
-        interceptor.batchSaveFederationQueuePolicies(request);
-
-    assertNotNull(policiesResponse);
-    assertNotNull(policiesResponse.getMessage());
-    assertEquals("batch save policies success.", policiesResponse.getMessage());
-
-    // Step2. We query Policy information from FederationStateStore.
-    FederationStateStoreFacade federationFacade = interceptor.getFederationFacade();
-    SubClusterPolicyConfiguration policyConfiguration =
-        federationFacade.getPolicyConfiguration("root.a");
-    assertNotNull(policyConfiguration);
-    assertEquals("root.a", policyConfiguration.getQueue());
-
-    ByteBuffer params = policyConfiguration.getParams();
-    assertNotNull(params);
-    WeightedPolicyInfo weightedPolicyInfo = WeightedPolicyInfo.fromByteBuffer(params);
-    assertNotNull(weightedPolicyInfo);
-    Map<SubClusterIdInfo, Float> amrmPolicyWeights = weightedPolicyInfo.getAMRMPolicyWeights();
-    Map<SubClusterIdInfo, Float> routerPolicyWeights = weightedPolicyInfo.getRouterPolicyWeights();
-
-    SubClusterIdInfo sc1 = new SubClusterIdInfo("SC-1");
-    SubClusterIdInfo sc2 = new SubClusterIdInfo("SC-2");
-
-    // Check whether the AMRMWeight of SC-1 and SC-2 of root.a meet expectations
-    FederationQueueWeight queueWeight = federationQueueWeights.get(0);
-    Map<SubClusterIdInfo, Float> subClusterAmrmWeightMap =
-        interceptor.getSubClusterWeightMap(queueWeight.getAmrmWeight());
-    Float sc1ExpectedAmrmWeightFloat = amrmPolicyWeights.get(sc1);
-    Float sc1AmrmWeightFloat = subClusterAmrmWeightMap.get(sc1);
-    assertNotNull(sc1AmrmWeightFloat);
-    assertEquals(sc1ExpectedAmrmWeightFloat, sc1AmrmWeightFloat, 0.00001);
-
-    Float sc2ExpectedAmrmWeightFloat = amrmPolicyWeights.get(sc2);
-    Float sc2AmrmWeightFloat = subClusterAmrmWeightMap.get(sc2);
-    assertNotNull(sc2ExpectedAmrmWeightFloat);
-    assertEquals(sc2ExpectedAmrmWeightFloat, sc2AmrmWeightFloat, 0.00001);
-
-    // Check whether the RouterPolicyWeight of SC-1 and SC-2 of root.a meet expectations
-    Map<SubClusterIdInfo, Float> subClusterRouterWeightMap =
-        interceptor.getSubClusterWeightMap(queueWeight.getRouterWeight());
-    Float sc1ExpectedRouterWeightFloat = routerPolicyWeights.get(sc1);
-    Float sc1RouterWeightFloat = subClusterRouterWeightMap.get(sc1);
-    assertNotNull(sc1RouterWeightFloat);
-    assertEquals(sc1ExpectedRouterWeightFloat, sc1RouterWeightFloat, 0.00001);
-
-    Float sc2ExpectedRouterWeightFloat = routerPolicyWeights.get(sc2);
-    Float sc2RouterWeightFloat = subClusterRouterWeightMap.get(sc2);
-    assertNotNull(sc2ExpectedRouterWeightFloat);
-    assertEquals(sc2ExpectedRouterWeightFloat, sc2RouterWeightFloat, 0.00001);
-  }
-
-  /**
-   * Generate FederationQueueWeight.
-   * We will generate the weight information of the queue.
-   *
-   * @param queue queue name
-   * @param pSubClusters subClusters
-   * @return subCluster FederationQueueWeight
-   */
-  private FederationQueueWeight generateFederationQueueWeight(
-      String queue, List<String> pSubClusters) {
-    String routerWeight = generatePolicyWeight(pSubClusters);
-    String amrmWeight = generatePolicyWeight(pSubClusters);
-    String policyTypeName = WeightedLocalityPolicyManager.class.getCanonicalName();
-    String headRoomAlpha = "1.0";
-    return FederationQueueWeight.newInstance(routerWeight, amrmWeight, headRoomAlpha,
-        queue, policyTypeName);
-  }
-
-  /**
-   * Generating Policy Weight Data.
-   *
-   * @param pSubClusters set of sub-clusters.
-   * @return policy Weight String, like SC-1:0.7,SC-2:0.3
-   */
-  private String generatePolicyWeight(List<String> pSubClusters) {
-    List<String> weights = generateWeights(pSubClusters.size());
-    List<String> subClusterWeight = new ArrayList<>();
-    for (int i = 0; i < pSubClusters.size(); i++) {
-      String subCluster = pSubClusters.get(i);
-      String weight = weights.get(i);
-      subClusterWeight.add(subCluster + ":" + weight);
-    }
-    return StringUtils.join(subClusterWeight, ",");
-  }
-
-  /**
-   * Generate a set of random numbers, and the sum of the numbers is 1.
-   *
-   * @param n number of random numbers generated.
-   * @return a set of random numbers
-   */
-  private List<String> generateWeights(int n) {
-    List<Float> randomNumbers = new ArrayList<>();
-    float total = 0.0f;
-
-    Random random = new Random();
-    for (int i = 0; i < n - 1; i++) {
-      float randNum = random.nextFloat();
-      randomNumbers.add(randNum);
-      total += randNum;
-    }
-
-    float lastNumber = 1 - total;
-    randomNumbers.add(lastNumber);
-
-    DecimalFormat decimalFormat = new DecimalFormat("#.##");
-    List<String> formattedRandomNumbers = new ArrayList<>();
-    for (double number : randomNumbers) {
-      String formattedNumber = decimalFormat.format(number);
-      formattedRandomNumbers.add(formattedNumber);
-    }
-
-    return formattedRandomNumbers;
-  }
-
-  @Test
-  public void testParsePolicyWeights() {
-    Map<SubClusterIdInfo, Float> policyWeights = new LinkedHashMap<>();
-    SubClusterIdInfo sc1 = new SubClusterIdInfo("SC-1");
-    policyWeights.put(sc1, 0.7f);
-    SubClusterIdInfo sc2 = new SubClusterIdInfo("SC-2");
-    policyWeights.put(sc2, 0.3f);
-    String policyWeight = interceptor.parsePolicyWeights(policyWeights);
-    assertEquals("SC-1:0.7,SC-2:0.3", policyWeight);
-  }
-
-  @Test
-  public void testFilterPoliciesConfigurationsByQueues() throws Exception {
-    // SubClusters : SC-1,SC-2
-    List<String> subClusterLists = new ArrayList<>();
-    subClusterLists.add("SC-1");
-    subClusterLists.add("SC-2");
-
-    // We initialize 26 queues, queue root.a~root.z
-    List<FederationQueueWeight> federationQueueWeights = new ArrayList<>();
-    for (char letter = 'a'; letter <= 'z'; letter++) {
-      FederationQueueWeight leaf =
-          generateFederationQueueWeight("root." + letter, subClusterLists);
-      federationQueueWeights.add(leaf);
-    }
-
-    // Save Queue Policies in Batches
-    BatchSaveFederationQueuePoliciesRequest request =
-        BatchSaveFederationQueuePoliciesRequest.newInstance(federationQueueWeights);
-
-    BatchSaveFederationQueuePoliciesResponse policiesResponse =
-        interceptor.batchSaveFederationQueuePolicies(request);
-
-    assertNotNull(policiesResponse);
-    assertNotNull(policiesResponse.getMessage());
-    assertEquals("batch save policies success.", policiesResponse.getMessage());
-
-    // We query 12 queues, root.a ~ root.l
-    List<String> queues = new ArrayList<>();
-    for (char letter = 'a'; letter <= 'l'; letter++) {
-      queues.add("root." + letter);
-    }
-
-    // Queue1: We query page 1, 10 items per page, and the returned result should be 10 items.
-    // TotalPage should be 2, TotalSize should be 12.
-    QueryFederationQueuePoliciesRequest request1 =
-        QueryFederationQueuePoliciesRequest.newInstance(10, 1, "", queues);
-    QueryFederationQueuePoliciesResponse response1 =
-        interceptor.listFederationQueuePolicies(request1);
-    assertNotNull(response1);
-    assertEquals(1, response1.getCurrentPage());
-    assertEquals(10, response1.getPageSize());
-    assertEquals(2, response1.getTotalPage());
-    assertEquals(12, response1.getTotalSize());
-    List<FederationQueueWeight> federationQueueWeights1 = response1.getFederationQueueWeights();
-    assertNotNull(federationQueueWeights1);
-    assertEquals(10, federationQueueWeights1.size());
-
-    // Queue2: We query page 1, 12 items per page, and the returned result should be 12 items.
-    // TotalPage should be 1, TotalSize should be 12.
-    QueryFederationQueuePoliciesRequest request2 =
-        QueryFederationQueuePoliciesRequest.newInstance(12, 1, "", queues);
-    QueryFederationQueuePoliciesResponse response2 =
-        interceptor.listFederationQueuePolicies(request2);
-    assertNotNull(response2);
-    assertEquals(1, response2.getCurrentPage());
-    assertEquals(12, response2.getPageSize());
-    assertEquals(1, response2.getTotalPage());
-    assertEquals(12, response2.getTotalSize());
-    List<FederationQueueWeight> federationQueueWeights2 = response2.getFederationQueueWeights();
-    assertNotNull(federationQueueWeights2);
-    assertEquals(12, federationQueueWeights2.size());
-
-    // Queue3: Boundary limit exceeded
-    // We filter 12 queues, should return 12 records, 12 per page,
-    // should return 1 page, but we are going to return page 2.
-    QueryFederationQueuePoliciesRequest request3 =
-        QueryFederationQueuePoliciesRequest.newInstance(12, 2, "", queues);
-    QueryFederationQueuePoliciesResponse response3 =
-        interceptor.listFederationQueuePolicies(request3);
-    assertNotNull(response3);
-    assertEquals(2, response3.getCurrentPage());
-    assertEquals(12, response3.getPageSize());
-    assertEquals(1, response2.getTotalPage());
-    assertEquals(12, response3.getTotalSize());
-    List<FederationQueueWeight> federationQueueWeights3 = response3.getFederationQueueWeights();
-    assertNotNull(federationQueueWeights3);
-    assertEquals(0, federationQueueWeights3.size());
-
-    // Queue4: Boundary limit exceeded
-    // We pass in some negative parameters and we will get some exceptions
-    QueryFederationQueuePoliciesRequest request4 =
-        QueryFederationQueuePoliciesRequest.newInstance(-1, 2, "", queues);
-    LambdaTestUtils.intercept(YarnException.class, "PageSize cannot be negative or zero.",
-        () -> interceptor.listFederationQueuePolicies(request4));
-
-    // Queue5: Boundary limit exceeded
-    // We pass in some negative parameters and we will get some exceptions
-    QueryFederationQueuePoliciesRequest request5 =
-        QueryFederationQueuePoliciesRequest.newInstance(10, -1, "", queues);
-    LambdaTestUtils.intercept(YarnException.class, "CurrentPage cannot be negative or zero.",
-        () -> interceptor.listFederationQueuePolicies(request5));
-
-    // Queue6: We use Queue as the condition,
-    // at this time we will only get the only one return value.
-    QueryFederationQueuePoliciesRequest request6 =
-        QueryFederationQueuePoliciesRequest.newInstance(10, 1, "root.a", null);
-    QueryFederationQueuePoliciesResponse response6 =
-        interceptor.listFederationQueuePolicies(request6);
-    assertNotNull(response6);
-    assertEquals(1, response6.getCurrentPage());
-    assertEquals(10, response6.getPageSize());
-    assertEquals(1, response6.getTotalPage());
-    assertEquals(1, response6.getTotalSize());
-    List<FederationQueueWeight> federationQueueWeights6 = response6.getFederationQueueWeights();
-    assertNotNull(federationQueueWeights6);
-    assertEquals(1, federationQueueWeights6.size());
-
-    // Queue7: We design such a test case, we do not set any filter conditions,
-    // but we need to get the return results
-    QueryFederationQueuePoliciesRequest request7 =
-        QueryFederationQueuePoliciesRequest.newInstance(10, 1, null, null);
-    QueryFederationQueuePoliciesResponse response7 =
-        interceptor.listFederationQueuePolicies(request7);
-    assertNotNull(response7);
-    assertEquals(1, response7.getCurrentPage());
-    assertEquals(10, response7.getPageSize());
-    assertEquals(3, response7.getTotalPage());
-    assertEquals(26, response7.getTotalSize());
-    List<FederationQueueWeight> federationQueueWeights7 = response7.getFederationQueueWeights();
-    assertNotNull(federationQueueWeights7);
-    assertEquals(10, federationQueueWeights7.size());
-
-    // Queue8: We are designing a unit test where the number of records
-    // we need to retrieve exceeds the maximum number of Policies available.
-    QueryFederationQueuePoliciesRequest request8 =
-        QueryFederationQueuePoliciesRequest.newInstance(10, 10, null, null);
-    LambdaTestUtils.intercept(YarnException.class,
-        "The index of the records to be retrieved has exceeded the maximum index.",
-        () -> interceptor.listFederationQueuePolicies(request8));
-  }
-
-  @Test
-  public void testDeleteFederationApplication() throws Exception {
-    ApplicationId applicationId = ApplicationId.newInstance(10, 1);
-    DeleteFederationApplicationRequest request1 =
-        DeleteFederationApplicationRequest.newInstance(applicationId.toString());
-    LambdaTestUtils.intercept(YarnException.class,
-        "Application application_10_0001 does not exist.",
-        () -> interceptor.deleteFederationApplication(request1));
-
-    ApplicationId applicationId2 = ApplicationId.newInstance(10, 2);
-    SubClusterId homeSubCluster = SubClusterId.newInstance("SC-1");
-    ApplicationHomeSubCluster appHomeSubCluster =
-        ApplicationHomeSubCluster.newInstance(applicationId2, homeSubCluster);
-    facade.addApplicationHomeSubCluster(appHomeSubCluster);
-    DeleteFederationApplicationRequest request2 =
-        DeleteFederationApplicationRequest.newInstance(applicationId2.toString());
-    DeleteFederationApplicationResponse deleteFederationApplicationResponse =
-        interceptor.deleteFederationApplication(request2);
-    assertNotNull(deleteFederationApplicationResponse);
-    assertEquals("applicationId = " + applicationId2 + " delete success.",
-        deleteFederationApplicationResponse.getMessage());
-  }
-
-  @Test
-  public void testGetFederationSubClusters() throws Exception {
-    LambdaTestUtils.intercept(YarnException.class,
-        "Missing getFederationSubClusters Request.",
-        () -> interceptor.getFederationSubClusters(null));
-
-    GetSubClustersRequest request = GetSubClustersRequest.newInstance();
-    GetSubClustersResponse federationSubClusters = interceptor.getFederationSubClusters(request);
-    assertNotNull(federationSubClusters);
-
-    List<FederationSubCluster> federationSubClustersList =
-        federationSubClusters.getFederationSubClusters();
-    assertNotNull(federationSubClustersList);
-    assertEquals(4, federationSubClustersList.size());
-  }
-
-  @Test
-  public void testDeleteFederationPoliciesByQueues() throws IOException, YarnException {
-    // subClusters
-    List<String> subClusterLists = new ArrayList<>();
-    subClusterLists.add("SC-1");
-    subClusterLists.add("SC-2");
-
-    // generate queue A, queue B, queue C
-    FederationQueueWeight rootA = generateFederationQueueWeight("root.a", subClusterLists);
-    FederationQueueWeight rootB = generateFederationQueueWeight("root.b", subClusterLists);
-    FederationQueueWeight rootC = generateFederationQueueWeight("root.c", subClusterLists);
-
-    List<FederationQueueWeight> federationQueueWeights = new ArrayList<>();
-    federationQueueWeights.add(rootA);
-    federationQueueWeights.add(rootB);
-    federationQueueWeights.add(rootC);
-
-    // Step1. Save Queue Policies in Batches
-    BatchSaveFederationQueuePoliciesRequest request =
-        BatchSaveFederationQueuePoliciesRequest.newInstance(federationQueueWeights);
-
-    BatchSaveFederationQueuePoliciesResponse policiesResponse =
-        interceptor.batchSaveFederationQueuePolicies(request);
-
-    assertNotNull(policiesResponse);
-    assertNotNull(policiesResponse.getMessage());
-    assertEquals("batch save policies success.", policiesResponse.getMessage());
-
-    // Step2. Delete the policy of root.c
-    List<String> deleteQueues = new ArrayList<>();
-    deleteQueues.add("root.c");
-    DeleteFederationQueuePoliciesRequest deleteRequest =
-        DeleteFederationQueuePoliciesRequest.newInstance(deleteQueues);
-    DeleteFederationQueuePoliciesResponse deleteResponse =
-        interceptor.deleteFederationPoliciesByQueues(deleteRequest);
-    assertNotNull(deleteResponse);
-    String message = deleteResponse.getMessage();
-    assertEquals("queues = root.c delete success.", message);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/TestRouterRMAdminService.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/TestRouterRMAdminService.java
deleted file mode 100644
index 867c71fa82e..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/TestRouterRMAdminService.java
+++ /dev/null
@@ -1,278 +0,0 @@
-/**
-* Licensed to the Apache Software Foundation (ASF) under one
-* or more contributor license agreements.  See the NOTICE file
-* distributed with this work for additional information
-* regarding copyright ownership.  The ASF licenses this file
-* to you under the Apache License, Version 2.0 (the
-* "License"); you may not use this file except in compliance
-* with the License.  You may obtain a copy of the License at
-*
-*     http://www.apache.org/licenses/LICENSE-2.0
-*
-* Unless required by applicable law or agreed to in writing, software
-* distributed under the License is distributed on an "AS IS" BASIS,
-* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-* See the License for the specific language governing permissions and
-* limitations under the License.
-*/
-
-package org.apache.hadoop.yarn.server.router.rmadmin;
-
-import java.io.IOException;
-import java.security.PrivilegedExceptionAction;
-import java.util.Map;
-
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.yarn.server.api.protocolrecords.AddToClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.CheckForDecommissioningNodesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshAdminAclsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshClusterMaxPriorityResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResourcesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshQueuesResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshServiceAclsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshSuperUserGroupsConfigurationResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshUserToGroupsMappingsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RemoveFromClusterNodeLabelsResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.ReplaceLabelsOnNodeResponse;
-import org.apache.hadoop.yarn.server.api.protocolrecords.UpdateNodeResourceResponse;
-import org.apache.hadoop.yarn.server.router.rmadmin.RouterRMAdminService.RequestInterceptorChainWrapper;
-import org.junit.Assert;
-import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * Test class to validate the RMAdmin Service inside the Router.
- */
-public class TestRouterRMAdminService extends BaseRouterRMAdminTest {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestRouterRMAdminService.class);
-
-  /**
-   * Tests if the pipeline is created properly.
-   */
-  @Test
-  public void testRequestInterceptorChainCreation() throws Exception {
-    RMAdminRequestInterceptor root =
-        super.getRouterRMAdminService().createRequestInterceptorChain();
-    int index = 0;
-    while (root != null) {
-      // The current pipeline is:
-      // PassThroughRMAdminRequestInterceptor - index = 0
-      // PassThroughRMAdminRequestInterceptor - index = 1
-      // PassThroughRMAdminRequestInterceptor - index = 2
-      // MockClientRequestInterceptor - index = 3
-      switch (index) {
-      case 0: // Fall to the next case
-      case 1: // Fall to the next case
-      case 2:
-        // If index is equal to 0,1 or 2 we fall in this check
-        Assert.assertEquals(
-            PassThroughRMAdminRequestInterceptor.class.getName(),
-            root.getClass().getName());
-        break;
-      case 3:
-        Assert.assertEquals(MockRMAdminRequestInterceptor.class.getName(),
-            root.getClass().getName());
-        break;
-      default:
-        Assert.fail();
-      }
-      root = root.getNextInterceptor();
-      index++;
-    }
-    Assert.assertEquals("The number of interceptors in chain does not match", 4,
-        index);
-  }
-
-  /**
-   * Test if the RouterRMAdmin forwards all the requests to the MockRM and get
-   * back the responses.
-   */
-  @Test
-  public void testRouterRMAdminServiceE2E() throws Exception {
-
-    String user = "test1";
-
-    LOG.info("testRouterRMAdminServiceE2E - Refresh Queues");
-
-    RefreshQueuesResponse responseRefreshQueues = refreshQueues(user);
-    Assert.assertNotNull(responseRefreshQueues);
-
-    LOG.info("testRouterRMAdminServiceE2E - Refresh Nodes");
-
-    RefreshNodesResponse responseRefreshNodes = refreshNodes(user);
-    Assert.assertNotNull(responseRefreshNodes);
-
-    LOG.info("testRouterRMAdminServiceE2E - Refresh Super User");
-
-    RefreshSuperUserGroupsConfigurationResponse responseRefreshSuperUser =
-        refreshSuperUserGroupsConfiguration(user);
-    Assert.assertNotNull(responseRefreshSuperUser);
-
-    LOG.info("testRouterRMAdminServiceE2E - Refresh User to Group");
-
-    RefreshUserToGroupsMappingsResponse responseRefreshUserToGroup =
-        refreshUserToGroupsMappings(user);
-    Assert.assertNotNull(responseRefreshUserToGroup);
-
-    LOG.info("testRouterRMAdminServiceE2E - Refresh Admin Acls");
-
-    RefreshAdminAclsResponse responseRefreshAdminAcls = refreshAdminAcls(user);
-    Assert.assertNotNull(responseRefreshAdminAcls);
-
-    LOG.info("testRouterRMAdminServiceE2E - Refresh Service Acls");
-
-    RefreshServiceAclsResponse responseRefreshServiceAcls =
-        refreshServiceAcls(user);
-    Assert.assertNotNull(responseRefreshServiceAcls);
-
-    LOG.info("testRouterRMAdminServiceE2E - Update Node Resource");
-
-    UpdateNodeResourceResponse responseUpdateNodeResource =
-        updateNodeResource(user);
-    Assert.assertNotNull(responseUpdateNodeResource);
-
-    LOG.info("testRouterRMAdminServiceE2E - Refresh Nodes Resource");
-
-    RefreshNodesResourcesResponse responseRefreshNodesResources =
-        refreshNodesResources(user);
-    Assert.assertNotNull(responseRefreshNodesResources);
-
-    LOG.info("testRouterRMAdminServiceE2E - Add To Cluster NodeLabels");
-
-    AddToClusterNodeLabelsResponse responseAddToClusterNodeLabels =
-        addToClusterNodeLabels(user);
-    Assert.assertNotNull(responseAddToClusterNodeLabels);
-
-    LOG.info("testRouterRMAdminServiceE2E - Remove To Cluster NodeLabels");
-
-    RemoveFromClusterNodeLabelsResponse responseRemoveFromClusterNodeLabels =
-        removeFromClusterNodeLabels(user);
-    Assert.assertNotNull(responseRemoveFromClusterNodeLabels);
-
-    LOG.info("testRouterRMAdminServiceE2E - Replace Labels On Node");
-
-    ReplaceLabelsOnNodeResponse responseReplaceLabelsOnNode =
-        replaceLabelsOnNode(user);
-    Assert.assertNotNull(responseReplaceLabelsOnNode);
-
-    LOG.info("testRouterRMAdminServiceE2E - Check For Decommissioning Nodes");
-
-    CheckForDecommissioningNodesResponse responseCheckForDecom =
-        checkForDecommissioningNodes(user);
-    Assert.assertNotNull(responseCheckForDecom);
-
-    LOG.info("testRouterRMAdminServiceE2E - Refresh Cluster Max Priority");
-
-    RefreshClusterMaxPriorityResponse responseRefreshClusterMaxPriority =
-        refreshClusterMaxPriority(user);
-    Assert.assertNotNull(responseRefreshClusterMaxPriority);
-
-    LOG.info("testRouterRMAdminServiceE2E - Get Groups For User");
-
-    String[] responseGetGroupsForUser = getGroupsForUser(user);
-    Assert.assertNotNull(responseGetGroupsForUser);
-
-  }
-
-  /**
-   * Test if the different chains for users are generated, and LRU cache is
-   * working as expected.
-   */
-  @Test
-  public void testUsersChainMapWithLRUCache()
-      throws IOException, InterruptedException {
-
-    Map<String, RequestInterceptorChainWrapper> pipelines;
-    RequestInterceptorChainWrapper chain;
-
-    refreshQueues("test1");
-    refreshQueues("test2");
-    refreshQueues("test3");
-    refreshQueues("test4");
-    refreshQueues("test5");
-    refreshQueues("test6");
-    refreshQueues("test7");
-    refreshQueues("test8");
-
-    pipelines = super.getRouterRMAdminService().getPipelines();
-    Assert.assertEquals(8, pipelines.size());
-
-    refreshQueues("test9");
-    refreshQueues("test10");
-    refreshQueues("test1");
-    refreshQueues("test11");
-
-    // The cache max size is defined in
-    // BaseRouterClientRMTest.TEST_MAX_CACHE_SIZE
-    Assert.assertEquals(10, pipelines.size());
-
-    chain = pipelines.get("test1");
-    Assert.assertNotNull("test1 should not be evicted", chain);
-
-    chain = pipelines.get("test2");
-    Assert.assertNull("test2 should have been evicted", chain);
-  }
-
-  /**
-   * This test validates if the RMAdminRequestInterceptor chain for the user
-   * can build and init correctly when a multi-client process begins to
-   * request RouterRMAdminService for the same user simultaneously.
-   */
-  @Test
-  public void testRMAdminPipelineConcurrent() throws InterruptedException {
-    final String user = "test1";
-
-    /*
-     * ClientTestThread is a thread to simulate a client request to get a
-     * RMAdminRequestInterceptor for the user.
-     */
-    class ClientTestThread extends Thread {
-      private RMAdminRequestInterceptor interceptor;
-      @Override public void run() {
-        try {
-          interceptor = pipeline();
-        } catch (IOException | InterruptedException e) {
-          e.printStackTrace();
-        }
-      }
-      private RMAdminRequestInterceptor pipeline()
-          throws IOException, InterruptedException {
-        return UserGroupInformation.createRemoteUser(user).doAs(
-            new PrivilegedExceptionAction<RMAdminRequestInterceptor>() {
-              @Override
-              public RMAdminRequestInterceptor run() throws Exception {
-                RequestInterceptorChainWrapper wrapper =
-                    getRouterRMAdminService().getInterceptorChain();
-                RMAdminRequestInterceptor interceptor =
-                    wrapper.getRootInterceptor();
-                Assert.assertNotNull(interceptor);
-                LOG.info("init rm admin interceptor success for user" + user);
-                return interceptor;
-              }
-            });
-      }
-    }
-
-    /*
-     * We start the first thread. It should not finish initing a chainWrapper
-     * before the other thread starts. In this way, the second thread can
-     * init at the same time of the first one. In the end, we validate that
-     * the 2 threads get the same chainWrapper without going into error.
-     */
-    ClientTestThread client1 = new ClientTestThread();
-    ClientTestThread client2 = new ClientTestThread();
-    client1.start();
-    client2.start();
-    client1.join();
-    client2.join();
-
-    Assert.assertNotNull(client1.interceptor);
-    Assert.assertNotNull(client2.interceptor);
-    Assert.assertTrue(client1.interceptor == client2.interceptor);
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/TestableFederationRMAdminInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/TestableFederationRMAdminInterceptor.java
deleted file mode 100644
index 29d06385e4e..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/rmadmin/TestableFederationRMAdminInterceptor.java
+++ /dev/null
@@ -1,105 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.rmadmin;
-
-import org.apache.commons.collections.MapUtils;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.api.ResourceManagerAdministrationProtocol;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.resourcemanager.AdminService;
-import org.apache.hadoop.yarn.server.resourcemanager.ResourceManager;
-import org.apache.hadoop.yarn.server.resourcemanager.MockRM;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-import java.net.ConnectException;
-import java.util.Set;
-import java.util.HashSet;
-import java.util.Map;
-import java.util.concurrent.ConcurrentHashMap;
-
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.RM_CLUSTER_ID;
-
-public class TestableFederationRMAdminInterceptor extends FederationRMAdminInterceptor {
-
-  // Record log information
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestableFederationRMAdminInterceptor.class);
-
-  // Used to Store the relationship between SubClusterId and RM
-  private ConcurrentHashMap<SubClusterId, MockRM> mockRMs = new ConcurrentHashMap<>();
-
-  // Store Bad subCluster
-  private Set<SubClusterId> badSubCluster = new HashSet<>();
-
-  @Override
-  protected ResourceManagerAdministrationProtocol getAdminRMProxyForSubCluster(
-      SubClusterId subClusterId) throws Exception {
-    MockRM mockRM;
-    synchronized (this) {
-      if (mockRMs.containsKey(subClusterId)) {
-        mockRM = mockRMs.get(subClusterId);
-      } else {
-        YarnConfiguration config = new YarnConfiguration(super.getConf());
-        config.set(RM_CLUSTER_ID, "subcluster." + subClusterId);
-        mockRM = new MockRM(config);
-        if (badSubCluster.contains(subClusterId)) {
-          return new MockRMAdminBadService(mockRM);
-        }
-        mockRM.init(config);
-        mockRM.start();
-        mockRM.registerNode("127.0.0.1:1", 102400, 100);
-        mockRMs.put(subClusterId, mockRM);
-      }
-      return mockRM.getAdminService();
-    }
-  }
-
-  // This represents an unserviceable SubCluster
-  private class MockRMAdminBadService extends AdminService {
-    MockRMAdminBadService(ResourceManager rm) {
-      super(rm);
-    }
-
-    @Override
-    public void refreshQueues() throws IOException, YarnException {
-      throw new ConnectException("RM is stopped");
-    }
-  }
-
-  @Override
-  public void shutdown() {
-    // if mockRMs is not null
-    if (MapUtils.isNotEmpty(mockRMs)) {
-      for (Map.Entry<SubClusterId, MockRM> item : mockRMs.entrySet()) {
-        SubClusterId subClusterId = item.getKey();
-        // close mockRM.
-        MockRM mockRM = item.getValue();
-        if (mockRM != null) {
-          LOG.info("subClusterId = {} mockRM shutdown.", subClusterId);
-          mockRM.stop();
-        }
-      }
-    }
-    mockRMs.clear();
-    super.shutdown();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/secure/AbstractSecureRouterTest.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/secure/AbstractSecureRouterTest.java
deleted file mode 100644
index a074689cccd..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/secure/AbstractSecureRouterTest.java
+++ /dev/null
@@ -1,249 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.secure;
-
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.CommonConfigurationKeysPublic;
-import org.apache.hadoop.metrics2.lib.DefaultMetricsSystem;
-import org.apache.hadoop.minikdc.MiniKdc;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.resourcemanager.MockRM;
-import org.apache.hadoop.yarn.server.resourcemanager.TestRMRestart;
-import org.apache.hadoop.yarn.server.router.Router;
-import org.apache.hadoop.yarn.server.router.clientrm.FederationClientInterceptor;
-import org.junit.AfterClass;
-import org.junit.BeforeClass;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.File;
-import java.util.Map;
-import java.util.Properties;
-import java.util.concurrent.ConcurrentHashMap;
-
-import static org.junit.Assert.assertNull;
-import static org.junit.Assert.assertTrue;
-import static org.junit.Assert.assertNotNull;
-
-public abstract class AbstractSecureRouterTest {
-
-  private static final Logger LOG = LoggerFactory.getLogger(AbstractSecureRouterTest.class);
-
-  ////////////////////////////////
-  // Kerberos Constants
-  ////////////////////////////////
-
-  public static final String REALM = "EXAMPLE.COM";
-  public static final String ROUTER = "router";
-  public static final String LOCALHOST = "localhost";
-  public static final String IP127001 = "127.0.0.1";
-  public static final String ROUTER_LOCALHOST = "router/" + LOCALHOST;
-  public static final String ROUTER_127001 = "router/" + IP127001;
-  public static final String ROUTER_REALM = "router@" + REALM;
-  public static final String ROUTER_LOCALHOST_REALM = ROUTER_LOCALHOST + "@" + REALM;
-  public static final String SUN_SECURITY_KRB5_DEBUG = "sun.security.krb5.debug";
-  public static final String KERBEROS = "kerberos";
-
-  ////////////////////////////////
-  // BeforeSecureRouterTestClass Init
-  ////////////////////////////////
-
-  private static MiniKdc kdc;
-  private static File routerKeytab;
-  private static File kdcWorkDir;
-  private static Configuration conf;
-
-  ////////////////////////////////
-  // Specific Constant
-  // Like Mem, VCore, ClusterNum
-  ////////////////////////////////
-  private static final int NUM_SUBCLUSTER = 4;
-  private static final int GB = 1024;
-  private static final int NM_MEMORY = 8 * GB;
-  private static final int NM_VCORE = 4;
-
-  ////////////////////////////////
-  // Test use in subclasses
-  ////////////////////////////////
-
-  private Router router = null;
-
-  private static ConcurrentHashMap<SubClusterId, MockRM> mockRMs =
-      new ConcurrentHashMap<>();
-
-  @BeforeClass
-  public static void beforeSecureRouterTestClass() throws Exception {
-    // Sets up the KDC and Principals.
-    setupKDCAndPrincipals();
-
-    // Init YarnConfiguration
-    conf = new YarnConfiguration();
-
-    // Enable Kerberos authentication configuration
-    conf.setBoolean(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHORIZATION, true);
-    conf.set(CommonConfigurationKeysPublic.HADOOP_SECURITY_AUTHENTICATION, KERBEROS);
-
-    // Router configuration
-    conf.set(YarnConfiguration.ROUTER_BIND_HOST, "0.0.0.0");
-    conf.set(YarnConfiguration.ROUTER_CLIENTRM_INTERCEPTOR_CLASS_PIPELINE,
-        FederationClientInterceptor.class.getName());
-
-    // Router Kerberos KeyTab configuration
-    conf.set(YarnConfiguration.ROUTER_PRINCIPAL, ROUTER_LOCALHOST_REALM);
-    conf.set(YarnConfiguration.ROUTER_KEYTAB, routerKeytab.getAbsolutePath());
-
-    DefaultMetricsSystem.setMiniClusterMode(true);
-  }
-
-  /**
-   * Sets up the KDC and Principals.
-   *
-   * @throws Exception an error occurred.
-   */
-  public static void setupKDCAndPrincipals() throws Exception {
-    // set up the KDC
-    File target = new File(System.getProperty("test.dir", "target"));
-    kdcWorkDir = new File(target, "kdc");
-    kdcWorkDir.mkdirs();
-    if (!kdcWorkDir.mkdirs()) {
-      assertTrue(kdcWorkDir.isDirectory());
-    }
-    Properties kdcConf = MiniKdc.createConf();
-    kdcConf.setProperty(MiniKdc.DEBUG, "true");
-    kdc = new MiniKdc(kdcConf, kdcWorkDir);
-    kdc.start();
-    routerKeytab = createKeytab(ROUTER, "router.keytab");
-  }
-
-  /**
-   * Initialize RM in safe mode.
-   *
-   * @throws Exception an error occurred.
-   */
-  public static void setupSecureMockRM() throws Exception {
-    for (int i = 0; i < NUM_SUBCLUSTER; i++) {
-      SubClusterId sc = SubClusterId.newInstance(i);
-      if (mockRMs.containsKey(sc)) {
-        continue;
-      }
-      MockRM mockRM = new TestRMRestart.TestSecurityMockRM(conf);
-      mockRM.start();
-      mockRM.registerNode("127.0.0.1:1234", NM_MEMORY, NM_VCORE);
-      mockRMs.put(sc, mockRM);
-    }
-  }
-
-  /**
-   * Create the keytab for the given principal, includes
-   * raw principal and $principal/localhost.
-   *
-   * @param principal principal short name.
-   * @param filename filename of keytab.
-   * @return file of keytab.
-   * @throws Exception an error occurred.
-   */
-  public static File createKeytab(String principal, String filename) throws Exception {
-    assertTrue("empty principal", StringUtils.isNotBlank(principal));
-    assertTrue("empty host", StringUtils.isNotBlank(filename));
-    assertNotNull("null KDC", kdc);
-    File keytab = new File(kdcWorkDir, filename);
-    kdc.createPrincipal(keytab,
-        principal,
-        principal + "/localhost",
-        principal + "/127.0.0.1");
-    return keytab;
-  }
-
-  /**
-   * Start the router in safe mode.
-   *
-   * @throws Exception an error occurred.
-   */
-  public synchronized void startSecureRouter() {
-    assertNull("Router is already running", router);
-    MemoryFederationStateStore stateStore = new MemoryFederationStateStore();
-    stateStore.init(getConf());
-    FederationStateStoreFacade.getInstance(getConf()).reinitialize(stateStore, getConf());
-    UserGroupInformation.setConfiguration(conf);
-    router = new Router();
-    router.init(conf);
-    router.start();
-  }
-
-  /**
-   * Shut down the KDC service.
-   *
-   * @throws Exception an error occurred.
-   */
-  public static void teardownKDC() throws Exception {
-    if (kdc != null) {
-      kdc.stop();
-      kdc = null;
-    }
-  }
-
-  /**
-   * Stop the router in safe mode.
-   *
-   * @throws Exception an error occurred.
-   */
-  protected synchronized void stopSecureRouter() throws Exception {
-    if (router != null) {
-      router.stop();
-      router = null;
-    }
-  }
-
-  /**
-   * Stop the entire test service.
-   *
-   * @throws Exception an error occurred.
-   */
-  @AfterClass
-  public static void afterSecureRouterTest() throws Exception {
-    LOG.info("teardown of kdc instance.");
-    teardownKDC();
-    if (mockRMs != null && mockRMs.isEmpty()) {
-      for (MockRM mockRM : mockRMs.values()) {
-        mockRM.close();
-      }
-    }
-    mockRMs.clear();
-  }
-
-  public static MiniKdc getKdc() {
-    return kdc;
-  }
-
-  public Router getRouter() {
-    return router;
-  }
-
-  public static ConcurrentHashMap<SubClusterId, MockRM> getMockRMs() {
-    return mockRMs;
-  }
-
-  public static Configuration getConf() {
-    return conf;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/secure/TestRouterDelegationTokenSecretManager.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/secure/TestRouterDelegationTokenSecretManager.java
deleted file mode 100644
index eac2c5a03ba..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/secure/TestRouterDelegationTokenSecretManager.java
+++ /dev/null
@@ -1,201 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.secure;
-
-import org.apache.hadoop.io.Text;
-import org.apache.hadoop.security.token.delegation.DelegationKey;
-import org.apache.hadoop.test.LambdaTestUtils;
-import org.apache.hadoop.util.Time;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.security.client.RMDelegationTokenIdentifier;
-import org.apache.hadoop.yarn.server.router.clientrm.RouterClientRMService;
-import org.apache.hadoop.yarn.server.router.security.RouterDelegationTokenSecretManager;
-import org.junit.Assert;
-import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-
-import static org.junit.Assert.assertNotNull;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertArrayEquals;
-
-public class TestRouterDelegationTokenSecretManager extends AbstractSecureRouterTest {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestRouterDelegationTokenSecretManager.class);
-
-  @Test
-  public void testRouterStoreNewMasterKey() throws Exception {
-    LOG.info("Test RouterDelegationTokenSecretManager: StoreNewMasterKey.");
-
-    // Start the Router in Secure Mode
-    startSecureRouter();
-
-    // Store NewMasterKey
-    RouterClientRMService routerClientRMService = this.getRouter().getClientRMProxyService();
-    RouterDelegationTokenSecretManager secretManager =
-        routerClientRMService.getRouterDTSecretManager();
-    DelegationKey storeKey = new DelegationKey(1234, 4321, "keyBytes".getBytes());
-    secretManager.storeNewMasterKey(storeKey);
-
-    // Get DelegationKey
-    DelegationKey paramKey = new DelegationKey(1234, 4321, "keyBytes".getBytes());
-    DelegationKey responseKey = secretManager.getMasterKeyByDelegationKey(paramKey);
-
-    assertNotNull(paramKey);
-    assertEquals(storeKey.getExpiryDate(), responseKey.getExpiryDate());
-    assertEquals(storeKey.getKeyId(), responseKey.getKeyId());
-    assertArrayEquals(storeKey.getEncodedKey(), responseKey.getEncodedKey());
-    assertEquals(storeKey, responseKey);
-
-    stopSecureRouter();
-  }
-
-  @Test
-  public void testRouterRemoveStoredMasterKey() throws Exception {
-    LOG.info("Test RouterDelegationTokenSecretManager: RemoveStoredMasterKey.");
-
-    // Start the Router in Secure Mode
-    startSecureRouter();
-
-    // Store NewMasterKey
-    RouterClientRMService routerClientRMService = this.getRouter().getClientRMProxyService();
-    RouterDelegationTokenSecretManager secretManager =
-        routerClientRMService.getRouterDTSecretManager();
-    DelegationKey storeKey = new DelegationKey(1234, 4321, "keyBytes".getBytes());
-    secretManager.storeNewMasterKey(storeKey);
-
-    // Remove DelegationKey
-    secretManager.removeStoredMasterKey(storeKey);
-
-    // Get DelegationKey
-    DelegationKey paramKey = new DelegationKey(1234, 4321, "keyBytes".getBytes());
-    LambdaTestUtils.intercept(IOException.class,
-        "GetMasterKey with keyID: " + storeKey.getKeyId() + " does not exist.",
-        () -> secretManager.getMasterKeyByDelegationKey(paramKey));
-
-    stopSecureRouter();
-  }
-
-  @Test
-  public void testRouterStoreNewToken() throws Exception {
-    LOG.info("Test RouterDelegationTokenSecretManager: StoreNewToken.");
-
-    // Start the Router in Secure Mode
-    startSecureRouter();
-
-    // Store new rm-token
-    RouterClientRMService routerClientRMService = this.getRouter().getClientRMProxyService();
-    RouterDelegationTokenSecretManager secretManager =
-        routerClientRMService.getRouterDTSecretManager();
-    RMDelegationTokenIdentifier dtId1 = new RMDelegationTokenIdentifier(
-        new Text("owner1"), new Text("renewer1"), new Text("realuser1"));
-    int sequenceNumber = 1;
-    dtId1.setSequenceNumber(sequenceNumber);
-    Long renewDate1 = Time.now();
-    secretManager.storeNewToken(dtId1, renewDate1);
-
-    // query rm-token
-    RMDelegationTokenIdentifier dtId2 = new RMDelegationTokenIdentifier(
-        new Text("owner1"), new Text("renewer1"), new Text("realuser1"));
-    dtId2.setSequenceNumber(sequenceNumber);
-    RMDelegationTokenIdentifier dtId3 = secretManager.getTokenByRouterStoreToken(dtId2);
-    Assert.assertEquals(dtId1, dtId3);
-
-    // query rm-token2 not exists
-    sequenceNumber++;
-    dtId2.setSequenceNumber(2);
-    LambdaTestUtils.intercept(YarnException.class,
-        "RMDelegationToken: " + dtId2 + " does not exist.",
-        () -> secretManager.getTokenByRouterStoreToken(dtId2));
-
-    stopSecureRouter();
-  }
-
-  @Test
-  public void testRouterUpdateNewToken() throws Exception {
-    LOG.info("Test RouterDelegationTokenSecretManager: UpdateNewToken.");
-
-    // Start the Router in Secure Mode
-    startSecureRouter();
-
-    // Store new rm-token
-    RouterClientRMService routerClientRMService = this.getRouter().getClientRMProxyService();
-    RouterDelegationTokenSecretManager secretManager =
-        routerClientRMService.getRouterDTSecretManager();
-    RMDelegationTokenIdentifier dtId1 = new RMDelegationTokenIdentifier(
-        new Text("owner1"), new Text("renewer1"), new Text("realuser1"));
-    int sequenceNumber = 1;
-    dtId1.setSequenceNumber(sequenceNumber);
-    Long renewDate1 = Time.now();
-    secretManager.storeNewToken(dtId1, renewDate1);
-
-    sequenceNumber++;
-    dtId1.setSequenceNumber(sequenceNumber);
-    secretManager.updateStoredToken(dtId1, renewDate1);
-
-    // query rm-token
-    RMDelegationTokenIdentifier dtId2 = new RMDelegationTokenIdentifier(
-        new Text("owner1"), new Text("renewer1"), new Text("realuser1"));
-    dtId2.setSequenceNumber(sequenceNumber);
-    RMDelegationTokenIdentifier dtId3 = secretManager.getTokenByRouterStoreToken(dtId2);
-    assertNotNull(dtId3);
-    assertEquals(dtId1.getKind(), dtId3.getKind());
-    assertEquals(dtId1.getOwner(), dtId3.getOwner());
-    assertEquals(dtId1.getRealUser(), dtId3.getRealUser());
-    assertEquals(dtId1.getRenewer(), dtId3.getRenewer());
-    assertEquals(dtId1.getIssueDate(), dtId3.getIssueDate());
-    assertEquals(dtId1.getMasterKeyId(), dtId3.getMasterKeyId());
-    assertEquals(dtId1.getSequenceNumber(), dtId3.getSequenceNumber());
-    assertEquals(sequenceNumber, dtId3.getSequenceNumber());
-    assertEquals(dtId1, dtId3);
-
-    stopSecureRouter();
-  }
-
-  @Test
-  public void testRouterRemoveToken() throws Exception {
-    LOG.info("Test RouterDelegationTokenSecretManager: RouterRemoveToken.");
-
-    // Start the Router in Secure Mode
-    startSecureRouter();
-
-    // Store new rm-token
-    RouterClientRMService routerClientRMService = this.getRouter().getClientRMProxyService();
-    RouterDelegationTokenSecretManager secretManager =
-        routerClientRMService.getRouterDTSecretManager();
-    RMDelegationTokenIdentifier dtId1 = new RMDelegationTokenIdentifier(
-        new Text("owner1"), new Text("renewer1"), new Text("realuser1"));
-    int sequenceNumber = 1;
-    dtId1.setSequenceNumber(sequenceNumber);
-    Long renewDate1 = Time.now();
-    secretManager.storeNewToken(dtId1, renewDate1);
-
-    // Remove rm-token
-    secretManager.removeStoredToken(dtId1);
-
-    // query rm-token
-    LambdaTestUtils.intercept(YarnException.class,
-        "RMDelegationToken: " + dtId1 + " does not exist.",
-        () -> secretManager.getTokenByRouterStoreToken(dtId1));
-
-    stopSecureRouter();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/secure/TestSecureLogins.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/secure/TestSecureLogins.java
deleted file mode 100644
index 40911814c04..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/secure/TestSecureLogins.java
+++ /dev/null
@@ -1,156 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.secure;
-
-import org.apache.commons.collections.MapUtils;
-import org.apache.hadoop.service.Service;
-import org.apache.hadoop.yarn.api.ApplicationClientProtocol;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetClusterMetricsResponse;
-import org.apache.hadoop.yarn.api.records.YarnClusterMetrics;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesRequest;
-import org.apache.hadoop.yarn.server.api.protocolrecords.RefreshNodesResponse;
-import org.apache.hadoop.yarn.server.federation.store.FederationStateStore;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreTestUtil;
-import org.apache.hadoop.yarn.server.resourcemanager.MockRM;
-import org.apache.hadoop.yarn.server.router.Router;
-import org.apache.hadoop.yarn.server.router.clientrm.FederationClientInterceptor;
-import org.apache.hadoop.yarn.server.router.clientrm.RouterClientRMService;
-import org.apache.hadoop.yarn.server.router.rmadmin.DefaultRMAdminRequestInterceptor;
-import org.apache.hadoop.yarn.server.router.rmadmin.RouterRMAdminService;
-import org.junit.Assert;
-import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.util.List;
-import java.util.Map;
-
-public class TestSecureLogins extends AbstractSecureRouterTest {
-
-  private static final Logger LOG = LoggerFactory.getLogger(TestSecureLogins.class);
-
-  @Test
-  public void testHasRealm() throws Throwable {
-    Assert.assertNotNull(getRealm());
-    LOG.info("Router principal = {}", getPrincipalAndRealm(ROUTER_LOCALHOST));
-  }
-
-  @Test
-  public void testRouterSecureLogin() throws Exception {
-    startSecureRouter();
-
-    List<Service> services = this.getRouter().getServices();
-    Assert.assertNotNull(services);
-    Assert.assertEquals(3, services.size());
-
-    stopSecureRouter();
-  }
-
-  @Test
-  public void testRouterClientRMService() throws Exception {
-    // Start the Router in Secure Mode
-    startSecureRouter();
-
-    // Start RM and RouterClientRMService in Secure mode
-    setupSecureMockRM();
-    initRouterClientRMService();
-
-    // Test the simple rpc call of the Router in the Secure environment
-    RouterClientRMService routerClientRMService = this.getRouter().getClientRMProxyService();
-    GetClusterMetricsRequest metricsRequest = GetClusterMetricsRequest.newInstance();
-    GetClusterMetricsResponse metricsResponse =
-        routerClientRMService.getClusterMetrics(metricsRequest);
-    Assert.assertNotNull(metricsResponse);
-    YarnClusterMetrics clusterMetrics = metricsResponse.getClusterMetrics();
-    Assert.assertEquals(4, clusterMetrics.getNumNodeManagers());
-    Assert.assertEquals(0, clusterMetrics.getNumLostNodeManagers());
-
-    // Stop the Router in Secure Mode
-    stopSecureRouter();
-  }
-
-  @Test
-  public void testRouterRMAdminService() throws Exception {
-    // Start the Router in Secure Mode
-    startSecureRouter();
-
-    // Start RM and RouterClientRMService in Secure mode
-    setupSecureMockRM();
-    initRouterRMAdminService();
-
-    // Test the simple rpc call of the Router in the Secure environment
-    RouterRMAdminService routerRMAdminService = this.getRouter().getRmAdminProxyService();
-    RefreshNodesRequest refreshNodesRequest = RefreshNodesRequest.newInstance();
-    RefreshNodesResponse refreshNodesResponse =
-        routerRMAdminService.refreshNodes(refreshNodesRequest);
-    Assert.assertNotNull(refreshNodesResponse);
-
-    // Stop the Router in Secure Mode
-    stopSecureRouter();
-  }
-
-  public static String getPrincipalAndRealm(String principal) {
-    return principal + "@" + getRealm();
-  }
-
-  protected static String getRealm() {
-    return getKdc().getRealm();
-  }
-
-  private void initRouterClientRMService() throws Exception {
-    Router router = this.getRouter();
-    Map<SubClusterId, MockRM> mockRMs = getMockRMs();
-
-    RouterClientRMService rmService = router.getClientRMProxyService();
-    RouterClientRMService.RequestInterceptorChainWrapper wrapper = rmService.getInterceptorChain();
-    FederationClientInterceptor interceptor =
-        (FederationClientInterceptor) wrapper.getRootInterceptor();
-    FederationStateStoreFacade stateStoreFacade = interceptor.getFederationFacade();
-    FederationStateStore stateStore = stateStoreFacade.getStateStore();
-    FederationStateStoreTestUtil stateStoreUtil = new FederationStateStoreTestUtil(stateStore);
-    Map<SubClusterId, ApplicationClientProtocol> clientRMProxies = interceptor.getClientRMProxies();
-
-    if (MapUtils.isNotEmpty(mockRMs)) {
-      for (Map.Entry<SubClusterId, MockRM> entry : mockRMs.entrySet()) {
-        SubClusterId sc = entry.getKey();
-        MockRM mockRM = entry.getValue();
-        stateStoreUtil.registerSubCluster(sc);
-        if (clientRMProxies.containsKey(sc)) {
-          continue;
-        }
-        clientRMProxies.put(sc, mockRM.getClientRMService());
-      }
-    }
-  }
-
-  private void initRouterRMAdminService() throws Exception {
-    Router router = this.getRouter();
-    Map<SubClusterId, MockRM> mockRMs = getMockRMs();
-    SubClusterId sc = SubClusterId.newInstance(0);
-    MockRM mockRM = mockRMs.get(sc);
-    RouterRMAdminService routerRMAdminService = router.getRmAdminProxyService();
-    RouterRMAdminService.RequestInterceptorChainWrapper rmAdminChainWrapper =
-        routerRMAdminService.getInterceptorChain();
-    DefaultRMAdminRequestInterceptor rmInterceptor =
-        (DefaultRMAdminRequestInterceptor) rmAdminChainWrapper.getRootInterceptor();
-    rmInterceptor.setRMAdmin(mockRM.getAdminService());
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/TestFederationSubCluster.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/TestFederationSubCluster.java
deleted file mode 100644
index 71034558687..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/TestFederationSubCluster.java
+++ /dev/null
@@ -1,345 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.subcluster;
-
-import com.sun.jersey.api.client.Client;
-import com.sun.jersey.api.client.ClientResponse;
-import com.sun.jersey.api.client.WebResource;
-import org.apache.commons.collections.CollectionUtils;
-import org.apache.curator.framework.CuratorFramework;
-import org.apache.curator.framework.CuratorFrameworkFactory;
-import org.apache.curator.framework.state.ConnectionState;
-import org.apache.curator.retry.RetryNTimes;
-import org.apache.curator.test.TestingServer;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.CommonConfigurationKeys;
-import org.apache.hadoop.io.retry.RetryPolicy;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.test.GenericTestUtils;
-import org.apache.hadoop.util.Time;
-import org.apache.hadoop.yarn.api.records.NodeLabel;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.federation.store.FederationStateStore;
-import org.apache.hadoop.yarn.server.federation.store.records.GetSubClustersInfoRequest;
-import org.apache.hadoop.yarn.server.federation.store.records.GetSubClustersInfoResponse;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NewApplication;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NewReservation;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo;
-import org.apache.hadoop.yarn.server.router.webapp.HTTPMethods;
-import org.apache.hadoop.yarn.server.router.webapp.JavaProcess;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.File;
-import java.io.IOException;
-import java.security.PrivilegedExceptionAction;
-import java.util.LinkedList;
-import java.util.List;
-import java.util.ArrayList;
-import java.util.concurrent.TimeoutException;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
-import static javax.servlet.http.HttpServletResponse.SC_OK;
-import static javax.ws.rs.core.MediaType.APPLICATION_JSON;
-import static javax.ws.rs.core.MediaType.APPLICATION_XML;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.RM_WEB_SERVICE_PATH;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.NODES;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_NEW_APPLICATION;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.RESERVATION_NEW;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.ADD_NODE_LABELS;
-import static org.apache.hadoop.yarn.server.router.webapp.TestRouterWebServicesREST.waitWebAppRunning;
-import static org.junit.Assert.assertEquals;
-
-public class TestFederationSubCluster {
-
-  private static final Logger LOG = LoggerFactory.getLogger(TestFederationSubCluster.class);
-  private static TestingServer curatorTestingServer;
-  private static CuratorFramework curatorFramework;
-  private static JavaProcess subCluster1;
-  private static JavaProcess subCluster2;
-  private static JavaProcess router;
-  public static final String ZK_FEDERATION_STATESTORE =
-      "org.apache.hadoop.yarn.server.federation.store.impl.ZookeeperFederationStateStore";
-  private static String userName = "test";
-
-  public void startFederationSubCluster(int zkPort, String sc1Param,
-      String sc2Param, String routerParam) throws IOException, InterruptedException,
-      YarnException, TimeoutException {
-
-    // Step1. Initialize ZK's service.
-    try {
-      curatorTestingServer = new TestingServer(zkPort);
-      curatorTestingServer.start();
-      String connectString = curatorTestingServer.getConnectString();
-      curatorFramework = CuratorFrameworkFactory.builder()
-          .connectString(connectString)
-          .retryPolicy(new RetryNTimes(100, 100))
-          .build();
-      curatorFramework.start();
-      curatorFramework.getConnectionStateListenable().addListener((client, newState) -> {
-        if (newState == ConnectionState.CONNECTED) {
-          System.out.println("Connected to the ZooKeeper server!");
-        }
-      });
-    } catch (Exception e) {
-      LOG.error("Cannot initialize ZooKeeper store.", e);
-      throw new IOException(e);
-    }
-
-    // Step2. Create a temporary directory output log.
-    File baseDir = GenericTestUtils.getTestDir("processes");
-    baseDir.mkdirs();
-    String baseName = TestFederationSubCluster.class.getSimpleName();
-
-    // Step3. Initialize subCluster SC-1
-    String sc1WebAddress = getSCWebAddress(sc1Param);
-    File rmOutput = new File(baseDir, baseName + "-" + Time.now() + "-rm.log");
-    rmOutput.createNewFile();
-    List<String> addClasspath = new LinkedList<>();
-    addClasspath.add("../hadoop-yarn-server-timelineservice/target/classes");
-    subCluster1 = new JavaProcess(TestMockSubCluster.class, addClasspath, rmOutput, sc1Param);
-    waitWebAppRunning(sc1WebAddress, RM_WEB_SERVICE_PATH);
-
-    // Step4. Initialize subCluster SC-2
-    String sc2WebAddress = getSCWebAddress(sc2Param);
-    File rmOutput2 = new File(baseDir, baseName + "-" + Time.now() + "-rm.log");
-    rmOutput2.createNewFile();
-    List<String> addClasspath2 = new LinkedList<>();
-    addClasspath2.add("../hadoop-yarn-server-timelineservice/target/classes");
-    subCluster2 = new JavaProcess(TestMockSubCluster.class, addClasspath2, rmOutput2, sc2Param);
-    waitWebAppRunning(sc2WebAddress, RM_WEB_SERVICE_PATH);
-
-    // Step5. Confirm that subClusters have been registered to ZK.
-    String zkAddress = getZkAddress(zkPort);
-    verifyRegistration(zkAddress);
-
-    // Step6. Initialize router
-    String routerWebAddress = getRouterWebAddress(routerParam);
-    File routerOutput = new File(baseDir, baseName + "-" + Time.now() + "-router.log");
-    routerOutput.createNewFile();
-    router = new JavaProcess(TestMockRouter.class, null, routerOutput, routerParam);
-    waitWebAppRunning(routerWebAddress, RM_WEB_SERVICE_PATH);
-  }
-
-  private String getSCWebAddress(String scParam) {
-    String[] scParams = scParam.split(",");
-    return "http://localhost:" + scParams[3];
-  }
-
-  private String getRouterWebAddress(String routerParam) {
-    String[] routerParams = routerParam.split(",");
-    return "http://localhost:" + routerParams[2];
-  }
-
-  private String getZkAddress(int port) {
-    return "localhost:" + port;
-  }
-
-  public void stop() throws Exception {
-    if (subCluster1 != null) {
-      subCluster1.stop();
-    }
-    if (subCluster2 != null) {
-      subCluster2.stop();
-    }
-    if (router != null) {
-      router.stop();
-    }
-    if (curatorTestingServer != null) {
-      curatorTestingServer.stop();
-    }
-  }
-
-  private void verifyRegistration(String zkAddress)
-      throws YarnException, InterruptedException, TimeoutException {
-    Configuration conf = new Configuration();
-    conf.setBoolean(YarnConfiguration.FEDERATION_ENABLED, true);
-    conf.set(YarnConfiguration.FEDERATION_STATESTORE_CLIENT_CLASS, ZK_FEDERATION_STATESTORE);
-    conf.set(CommonConfigurationKeys.ZK_ADDRESS, zkAddress);
-    RetryPolicy retryPolicy = FederationStateStoreFacade.createRetryPolicy(conf);
-    FederationStateStore stateStore = (FederationStateStore)
-        FederationStateStoreFacade.createRetryInstance(conf,
-        YarnConfiguration.FEDERATION_STATESTORE_CLIENT_CLASS,
-        YarnConfiguration.DEFAULT_FEDERATION_STATESTORE_CLIENT_CLASS,
-        FederationStateStore.class, retryPolicy);
-    stateStore.init(conf);
-    FederationStateStoreFacade.getInstance().reinitialize(stateStore, conf);
-    GetSubClustersInfoRequest request = GetSubClustersInfoRequest.newInstance(true);
-
-    GenericTestUtils.waitFor(() -> {
-      try {
-        GetSubClustersInfoResponse response = stateStore.getSubClusters(request);
-        List<SubClusterInfo> subClusters = response.getSubClusters();
-        if (CollectionUtils.isNotEmpty(subClusters)) {
-          return true;
-        }
-      } catch (Exception e) {
-      }
-      return false;
-    }, 5000, 50 * 1000);
-  }
-
-  public static <T> T performGetCalls(final String routerAddress, final String path,
-       final Class<T> returnType, final String queryName,
-       final String queryValue) throws IOException, InterruptedException {
-
-    Client clientToRouter = Client.create();
-    clientToRouter.setReadTimeout(5000);
-    clientToRouter.setConnectTimeout(5000);
-    WebResource toRouter = clientToRouter.resource(routerAddress).path(path);
-
-    final WebResource.Builder toRouterBuilder;
-
-    if (queryValue != null && queryName != null) {
-      toRouterBuilder = toRouter.queryParam(queryName, queryValue).accept(APPLICATION_XML);
-    } else {
-      toRouterBuilder = toRouter.accept(APPLICATION_XML);
-    }
-
-    return UserGroupInformation.createRemoteUser(userName).doAs(
-        (PrivilegedExceptionAction<T>) () -> {
-          ClientResponse response = toRouterBuilder.get(ClientResponse.class);
-          assertEquals(SC_OK, response.getStatus());
-          return response.getEntity(returnType);
-        });
-  }
-
-  public static ClientResponse performCall(final String routerAddress, final String webAddress,
-      final String queryKey, final String queryValue, final Object context,
-      final HTTPMethods method) throws IOException, InterruptedException {
-
-    return UserGroupInformation.createRemoteUser(userName).doAs(
-        (PrivilegedExceptionAction<ClientResponse>) () -> {
-          Client clientToRouter = Client.create();
-          WebResource toRouter = clientToRouter.resource(routerAddress).path(webAddress);
-
-          WebResource toRouterWR = toRouter;
-          if (queryKey != null && queryValue != null) {
-            toRouterWR = toRouterWR.queryParam(queryKey, queryValue);
-          }
-
-          WebResource.Builder builder;
-          if (context != null) {
-            builder = toRouterWR.entity(context, APPLICATION_JSON);
-            builder = builder.accept(APPLICATION_JSON);
-          } else {
-            builder = toRouterWR.accept(APPLICATION_JSON);
-          }
-
-          ClientResponse response = null;
-
-          switch (method) {
-            case DELETE:
-              response = builder.delete(ClientResponse.class);
-              break;
-            case POST:
-              response = builder.post(ClientResponse.class);
-              break;
-            case PUT:
-              response = builder.put(ClientResponse.class);
-              break;
-            default:
-              break;
-          }
-
-          return response;
-      });
-  }
-
-  public String getNodeId(String rmAddress) {
-    Client clientToRM = Client.create();
-    clientToRM.setConnectTimeout(3000);
-    clientToRM.setReadTimeout(3000);
-    WebResource toRM = clientToRM.resource(rmAddress).path(RM_WEB_SERVICE_PATH + NODES);
-    ClientResponse response =
-        toRM.accept(APPLICATION_XML).get(ClientResponse.class);
-    NodesInfo ci = response.getEntity(NodesInfo.class);
-    List<NodeInfo> nodes = ci.getNodes();
-    if (nodes.isEmpty()) {
-      return null;
-    }
-    clientToRM.destroy();
-    return nodes.get(0).getNodeId();
-  }
-
-  public NewApplication getNewApplicationId(String routerAddress) {
-    Client clientToRM = Client.create();
-    clientToRM.setConnectTimeout(3000);
-    clientToRM.setReadTimeout(3000);
-    WebResource toRM = clientToRM.resource(routerAddress).path(
-        RM_WEB_SERVICE_PATH + APPS_NEW_APPLICATION);
-    ClientResponse response = toRM.accept(APPLICATION_XML).post(ClientResponse.class);
-    clientToRM.destroy();
-    return response.getEntity(NewApplication.class);
-  }
-
-  public String submitApplication(String routerAddress) {
-    ApplicationSubmissionContextInfo context = new ApplicationSubmissionContextInfo();
-    String appId = getNewApplicationId(routerAddress).getApplicationId();
-    context.setApplicationId(appId);
-    Client clientToRouter = Client.create();
-    clientToRouter.setConnectTimeout(3000);
-    clientToRouter.setReadTimeout(3000);
-    WebResource toRM = clientToRouter.resource(routerAddress).path(
-        RM_WEB_SERVICE_PATH + APPS);
-    toRM.entity(context, APPLICATION_XML).accept(APPLICATION_XML).post(ClientResponse.class);
-    clientToRouter.destroy();
-    return appId;
-  }
-
-  public NewReservation getNewReservationId(String routerAddress) {
-    Client clientToRM = Client.create();
-    clientToRM.setConnectTimeout(3000);
-    clientToRM.setReadTimeout(3000);
-    WebResource toRM = clientToRM.resource(routerAddress).
-        path(RM_WEB_SERVICE_PATH + RESERVATION_NEW);
-    ClientResponse response = toRM.accept(APPLICATION_XML).post(ClientResponse.class);
-    return response.getEntity(NewReservation.class);
-  }
-
-  public String addNodeLabel(String routerAddress) {
-    Client clientToRM = Client.create();
-    clientToRM.setConnectTimeout(3000);
-    clientToRM.setReadTimeout(3000);
-    WebResource toRM = clientToRM.resource(routerAddress)
-        .path(RM_WEB_SERVICE_PATH + ADD_NODE_LABELS);
-    List<NodeLabel> nodeLabels = new ArrayList<>();
-    nodeLabels.add(NodeLabel.newInstance("default"));
-    NodeLabelsInfo context = new NodeLabelsInfo(nodeLabels);
-    ClientResponse response = toRM
-        .entity(context, APPLICATION_XML)
-        .accept(APPLICATION_XML)
-        .post(ClientResponse.class);
-    return response.getEntity(String.class);
-  }
-
-  public static String format(String format, Object... args) {
-    Pattern p = Pattern.compile("\\{.*?}");
-    Matcher m = p.matcher(format);
-    String newFormat = m.replaceAll("%s");
-    return String.format(newFormat, args);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/TestMockRouter.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/TestMockRouter.java
deleted file mode 100644
index 751a3fed648..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/TestMockRouter.java
+++ /dev/null
@@ -1,93 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.subcluster;
-
-import org.apache.commons.lang3.ArrayUtils;
-import org.apache.hadoop.fs.CommonConfigurationKeys;
-import org.apache.hadoop.io.retry.RetryPolicy;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.MiniYARNCluster;
-import org.apache.hadoop.yarn.server.federation.store.FederationStateStore;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.router.Router;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * Tests {@link Router}.
- */
-public class TestMockRouter {
-
-  private static final Logger LOG = LoggerFactory.getLogger(TestMockRouter.class);
-
-  public TestMockRouter() {
-  }
-
-  public static void main(String[] args) throws YarnException {
-    if (ArrayUtils.isEmpty(args)) {
-      return;
-    }
-
-    // Step1. Parse the parameters.
-    String[] params = args[0].split(",");
-    int pRouterClientRMPort = Integer.parseInt(params[0]);
-    int pRouterAdminAddressPort = Integer.parseInt(params[1]);
-    int pRouterWebAddressPort = Integer.parseInt(params[2]);
-    String zkAddress = params[3];
-
-    LOG.info("routerClientRMPort={}, routerAdminAddressPort={}, routerWebAddressPort={}, " +
-        "zkAddress = {}.", pRouterClientRMPort, pRouterAdminAddressPort,
-        pRouterWebAddressPort, zkAddress);
-
-    YarnConfiguration conf = new YarnConfiguration();
-    Router router = new Router();
-    conf.setBoolean(YarnConfiguration.FEDERATION_ENABLED, true);
-    conf.set(YarnConfiguration.FEDERATION_STATESTORE_CLIENT_CLASS,
-        "org.apache.hadoop.yarn.server.federation.store.impl.ZookeeperFederationStateStore");
-    conf.set(YarnConfiguration.ROUTER_WEBAPP_INTERCEPTOR_CLASS_PIPELINE,
-        "org.apache.hadoop.yarn.server.router.webapp.FederationInterceptorREST");
-    conf.set(YarnConfiguration.ROUTER_CLIENTRM_INTERCEPTOR_CLASS_PIPELINE,
-        "org.apache.hadoop.yarn.server.router.clientrm.FederationClientInterceptor");
-    conf.set(CommonConfigurationKeys.ZK_ADDRESS, zkAddress);
-    conf.set(YarnConfiguration.ROUTER_RMADMIN_INTERCEPTOR_CLASS_PIPELINE,
-        "org.apache.hadoop.yarn.server.router.rmadmin.FederationRMAdminInterceptor");
-    conf.setInt(YarnConfiguration.FEDERATION_CACHE_TIME_TO_LIVE_SECS, -1);
-    conf.set(YarnConfiguration.ROUTER_CLIENTRM_ADDRESS, getHostNameAndPort(pRouterClientRMPort));
-    conf.set(YarnConfiguration.ROUTER_RMADMIN_ADDRESS, getHostNameAndPort(pRouterAdminAddressPort));
-    conf.set(YarnConfiguration.ROUTER_WEBAPP_ADDRESS,
-        getHostNameAndPort(pRouterWebAddressPort));
-
-    RetryPolicy retryPolicy = FederationStateStoreFacade.createRetryPolicy(conf);
-
-    router.init(conf);
-    router.start();
-
-    FederationStateStore stateStore = (FederationStateStore)
-        FederationStateStoreFacade.createRetryInstance(conf,
-        YarnConfiguration.FEDERATION_STATESTORE_CLIENT_CLASS,
-        YarnConfiguration.DEFAULT_FEDERATION_STATESTORE_CLIENT_CLASS,
-        FederationStateStore.class, retryPolicy);
-    stateStore.init(conf);
-    FederationStateStoreFacade.getInstance().reinitialize(stateStore, conf);
-  }
-
-  private static String getHostNameAndPort(int port) {
-    return MiniYARNCluster.getHostname() + ":" + port;
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/TestMockSubCluster.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/TestMockSubCluster.java
deleted file mode 100644
index 00227ae9ffc..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/TestMockSubCluster.java
+++ /dev/null
@@ -1,100 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.subcluster;
-
-import org.apache.commons.lang3.ArrayUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.fs.CommonConfigurationKeys;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.server.MiniYARNCluster;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import static org.apache.hadoop.yarn.server.router.subcluster.TestFederationSubCluster.ZK_FEDERATION_STATESTORE;
-
-public class TestMockSubCluster {
-
-  private static final Logger LOG = LoggerFactory.getLogger(TestMockSubCluster.class);
-  private Configuration conf;
-  private String subClusterId;
-
-  public TestMockSubCluster() {
-  }
-
-  public TestMockSubCluster(String pSubClusterId, Configuration pConf) {
-    this.conf = pConf;
-    this.subClusterId = pSubClusterId;
-  }
-
-  private static String getHostNameAndPort(int port) {
-    return MiniYARNCluster.getHostname() + ":" + port;
-  }
-
-  public void startYarnSubCluster() {
-    MiniYARNCluster yrCluster = new MiniYARNCluster(subClusterId, 3, 1, 1, false);
-    yrCluster.init(conf);
-    yrCluster.start();
-  }
-
-  public static void main(String[] args) {
-    if (ArrayUtils.isEmpty(args)) {
-      return;
-    }
-
-    // Step1. Parse the parameters.
-    String[] params = args[0].split(",");
-    int pRmAddressPort = Integer.parseInt(params[0]);
-    int pRmSchedulerAddressPort = Integer.parseInt(params[1]);
-    int pRmTrackerAddressPort = Integer.parseInt(params[2]);
-    int pRmWebAddressPort = Integer.parseInt(params[3]);
-    int pRmAdminAddressPort = Integer.parseInt(params[4]);
-    String pSubClusterId = params[5];
-    String pZkAddress = params[6];
-    String schedulerType = params[7];
-
-    // Step 2. Print the parameters.
-    LOG.info("subClusterId = {}, rmAddressPort = {}, rmSchedulerAddressPort = {}, " +
-        "rmTrackerAddressPort = {}, rmWebAddressPort = {}, rmAdminAddressPort = {}",
-        pSubClusterId, pRmAddressPort, pRmSchedulerAddressPort, pRmTrackerAddressPort,
-        pRmWebAddressPort, pRmAdminAddressPort);
-
-    // Step 3. determine which scheduler to use.
-    Configuration conf = new YarnConfiguration();
-    conf.set(YarnConfiguration.RM_ADDRESS, getHostNameAndPort(pRmAddressPort));
-    conf.set(YarnConfiguration.RM_ADMIN_ADDRESS, getHostNameAndPort(pRmAdminAddressPort));
-    conf.set(YarnConfiguration.RM_HOSTNAME, MiniYARNCluster.getHostname());
-    conf.set(YarnConfiguration.RM_SCHEDULER_ADDRESS, getHostNameAndPort(pRmSchedulerAddressPort));
-    conf.set(YarnConfiguration.RM_RESOURCE_TRACKER_ADDRESS,
-        getHostNameAndPort(pRmTrackerAddressPort));
-    conf.set(YarnConfiguration.RM_WEBAPP_ADDRESS, getHostNameAndPort(pRmWebAddressPort));
-    conf.setBoolean(YarnConfiguration.YARN_MINICLUSTER_FIXED_PORTS, true);
-    conf.setBoolean(YarnConfiguration.FEDERATION_ENABLED, true);
-    conf.set(YarnConfiguration.FEDERATION_STATESTORE_CLIENT_CLASS, ZK_FEDERATION_STATESTORE);
-    conf.set(CommonConfigurationKeys.ZK_ADDRESS, pZkAddress);
-    conf.set(YarnConfiguration.RM_CLUSTER_ID, pSubClusterId);
-    if (schedulerType.equals("fair-scheduler")) {
-      conf.set("yarn.resourcemanager.scheduler.class",
-          "org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler");
-      conf.set("yarn.scheduler.fair.allocation.file", "fair-scheduler.xml");
-    }
-
-    // Step 4, start the mockSubCluster cluster.
-    TestMockSubCluster sc = new TestMockSubCluster(pSubClusterId, conf);
-    sc.startYarnSubCluster();
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/capacity/TestYarnFederationWithCapacityScheduler.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/capacity/TestYarnFederationWithCapacityScheduler.java
deleted file mode 100644
index 9fc4b5fd036..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/capacity/TestYarnFederationWithCapacityScheduler.java
+++ /dev/null
@@ -1,615 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.subcluster.capacity;
-
-import static javax.servlet.http.HttpServletResponse.SC_ACCEPTED;
-import static javax.servlet.http.HttpServletResponse.SC_BAD_REQUEST;
-import static javax.servlet.http.HttpServletResponse.SC_SERVICE_UNAVAILABLE;
-import com.sun.jersey.api.client.ClientResponse;
-import org.apache.hadoop.test.GenericTestUtils;
-import org.apache.hadoop.util.Sets;
-import org.apache.hadoop.yarn.api.records.ApplicationTimeoutType;
-import org.apache.hadoop.yarn.api.records.NodeLabel;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterUserInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerTypeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.CapacitySchedulerInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationStatisticsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.StatisticsItemInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NewApplication;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NewReservation;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LabelsToNodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntryList;
-import org.apache.hadoop.yarn.server.router.subcluster.TestFederationSubCluster;
-import org.apache.hadoop.yarn.server.router.webapp.dao.FederationClusterInfo;
-import org.apache.hadoop.yarn.server.router.webapp.dao.FederationClusterUserInfo;
-import org.apache.hadoop.yarn.server.router.webapp.dao.FederationSchedulerTypeInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.AppsInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.AppInfo;
-import org.junit.AfterClass;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Set;
-import java.util.concurrent.TimeoutException;
-
-import static javax.servlet.http.HttpServletResponse.SC_OK;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.RM_WEB_SERVICE_PATH;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.INFO;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.CLUSTER_USER_INFO;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.METRICS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.SCHEDULER;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.NODES;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.STATES;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.NODES_NODEID;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.SCHEDULER_ACTIVITIES;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_NEW_APPLICATION;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APP_STATISTICS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_APPID;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_APPID_APPATTEMPTS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_APPID_STATE;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_APPID_PRIORITY;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_APPID_QUEUE;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_TIMEOUTS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_TIMEOUT;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.RESERVATION_NEW;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.RESERVATION_SUBMIT;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.RESERVATION_UPDATE;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.RESERVATION_DELETE;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.GET_NODE_LABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.NODES_NODEID_GETLABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.LABEL_MAPPINGS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.LABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.ADD_NODE_LABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.GET_NODE_TO_LABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.REMOVE_NODE_LABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.REPLACE_NODE_TO_LABELS;
-import static org.apache.hadoop.yarn.server.router.subcluster.TestFederationSubCluster.format;
-import static org.apache.hadoop.yarn.server.router.webapp.HTTPMethods.POST;
-import static org.apache.hadoop.yarn.server.router.webapp.HTTPMethods.PUT;
-import static org.junit.Assert.assertNotNull;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertTrue;
-
-public class TestYarnFederationWithCapacityScheduler {
-
-  private static TestFederationSubCluster testFederationSubCluster;
-  private static Set<String> subClusters;
-  private static final String ROUTER_WEB_ADDRESS = "http://localhost:18089";
-  private static final String SC1_RM_WEB_ADDRESS = "http://localhost:18088";
-  private static final String SC2_RM_WEB_ADDRESS = "http://localhost:28088";
-
-  @BeforeClass
-  public static void setUp()
-      throws IOException, InterruptedException, YarnException, TimeoutException {
-    testFederationSubCluster = new TestFederationSubCluster();
-    testFederationSubCluster.startFederationSubCluster(2181,
-        "18032,18030,18031,18088,18033,SC-1,127.0.0.1:2181,capacity-scheduler",
-        "28032,28030,28031,28088,28033,SC-2,127.0.0.1:2181,capacity-scheduler",
-        "18050,18052,18089,127.0.0.1:2181");
-    subClusters = Sets.newHashSet();
-    subClusters.add("SC-1");
-    subClusters.add("SC-2");
-  }
-
-  @AfterClass
-  public static void shutDown() throws Exception {
-    testFederationSubCluster.stop();
-  }
-
-  @Test
-  public void testGetClusterInfo() throws InterruptedException, IOException {
-    FederationClusterInfo federationClusterInfo =
-        TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS, RM_WEB_SERVICE_PATH,
-        FederationClusterInfo.class, null, null);
-    List<ClusterInfo> clusterInfos = federationClusterInfo.getList();
-    assertNotNull(clusterInfos);
-    assertEquals(2, clusterInfos.size());
-    for (ClusterInfo clusterInfo : clusterInfos) {
-      assertNotNull(clusterInfo);
-      assertTrue(subClusters.contains(clusterInfo.getSubClusterId()));
-    }
-  }
-
-  @Test
-  public void testInfo() throws InterruptedException, IOException {
-    FederationClusterInfo federationClusterInfo =
-        TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS, RM_WEB_SERVICE_PATH + INFO,
-        FederationClusterInfo.class, null, null);
-    List<ClusterInfo> clusterInfos = federationClusterInfo.getList();
-    assertNotNull(clusterInfos);
-    assertEquals(2, clusterInfos.size());
-    for (ClusterInfo clusterInfo : clusterInfos) {
-      assertNotNull(clusterInfo);
-      assertTrue(subClusters.contains(clusterInfo.getSubClusterId()));
-    }
-  }
-
-  @Test
-  public void testClusterUserInfo() throws Exception {
-    FederationClusterUserInfo federationClusterUserInfo =
-        TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + CLUSTER_USER_INFO,
-        FederationClusterUserInfo.class, null, null);
-    List<ClusterUserInfo> clusterUserInfos = federationClusterUserInfo.getList();
-    assertNotNull(clusterUserInfos);
-    assertEquals(2, clusterUserInfos.size());
-    for (ClusterUserInfo clusterUserInfo : clusterUserInfos) {
-      assertNotNull(clusterUserInfo);
-      assertTrue(subClusters.contains(clusterUserInfo.getSubClusterId()));
-    }
-  }
-
-  @Test
-  public void testMetricsInfo() throws Exception {
-    // It takes time to start the sub-cluster.
-    // We need to wait for the sub-cluster to be completely started,
-    // so we need to set the waiting time.
-    // The resources of the two sub-clusters we registered are 24C and 12G,
-    // so the resources that the Router should collect are 48C and 24G.
-    GenericTestUtils.waitFor(() -> {
-      try {
-        ClusterMetricsInfo clusterMetricsInfo =
-            TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-            RM_WEB_SERVICE_PATH + METRICS, ClusterMetricsInfo.class, null, null);
-        assertNotNull(clusterMetricsInfo);
-        return (48 == clusterMetricsInfo.getTotalVirtualCores() &&
-            24576 == clusterMetricsInfo.getTotalMB());
-      } catch (Exception e) {
-        return false;
-      }
-    }, 5000, 50 * 5000);
-  }
-
-  @Test
-  public void testSchedulerInfo() throws Exception {
-    FederationSchedulerTypeInfo schedulerTypeInfo =
-        TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + SCHEDULER, FederationSchedulerTypeInfo.class, null, null);
-    assertNotNull(schedulerTypeInfo);
-    List<SchedulerTypeInfo> schedulerTypeInfos = schedulerTypeInfo.getList();
-    assertNotNull(schedulerTypeInfos);
-    assertEquals(2, schedulerTypeInfos.size());
-    for (SchedulerTypeInfo schedulerTypeInfoItem : schedulerTypeInfos) {
-      assertNotNull(schedulerTypeInfoItem);
-      assertTrue(subClusters.contains(schedulerTypeInfoItem.getSubClusterId()));
-      CapacitySchedulerInfo schedulerInfo =
-          (CapacitySchedulerInfo) schedulerTypeInfoItem.getSchedulerInfo();
-      assertNotNull(schedulerInfo);
-      assertEquals(3, schedulerInfo.getQueues().getQueueInfoList().size());
-    }
-  }
-
-  @Test
-  public void testNodesEmpty() throws Exception {
-    // We are in 2 sub-clusters, each with 3 nodes, so our Router should correspond to 6 nodes.
-    GenericTestUtils.waitFor(() -> {
-      try {
-        NodesInfo nodesInfo =
-            TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-            RM_WEB_SERVICE_PATH + NODES, NodesInfo.class, null, null);
-        assertNotNull(nodesInfo);
-        ArrayList<NodeInfo> nodes = nodesInfo.getNodes();
-        assertNotNull(nodes);
-        return (6 == nodes.size());
-      } catch (Exception e) {
-        return false;
-      }
-    }, 5000, 50 * 5000);
-  }
-
-  @Test
-  public void testNodesLost() throws Exception {
-    GenericTestUtils.waitFor(() -> {
-      try {
-        NodesInfo nodesInfo =
-            TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-            RM_WEB_SERVICE_PATH + NODES, NodesInfo.class, STATES, "LOST");
-        assertNotNull(nodesInfo);
-        ArrayList<NodeInfo> nodes = nodesInfo.getNodes();
-        assertNotNull(nodes);
-        return nodes.isEmpty();
-      } catch (Exception e) {
-        return false;
-      }
-    }, 5000, 50 * 5000);
-  }
-
-  @Test
-  public void testNode() throws Exception {
-    String rm1NodeId = testFederationSubCluster.getNodeId(SC1_RM_WEB_ADDRESS);
-    NodeInfo nodeInfo =
-        TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(NODES_NODEID, rm1NodeId),
-        NodeInfo.class, null, null);
-    assertNotNull(nodeInfo);
-    assertEquals(rm1NodeId, nodeInfo.getNodeId());
-
-    String rm2NodeId = testFederationSubCluster.getNodeId(SC2_RM_WEB_ADDRESS);
-    NodeInfo nodeInfo2 =
-        TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(NODES_NODEID, rm2NodeId),
-        NodeInfo.class, null, null);
-    assertNotNull(nodeInfo2);
-    assertEquals(rm2NodeId, nodeInfo2.getNodeId());
-  }
-
-  @Test
-  public void testUpdateNodeResource() throws Exception {
-    // wait until a node shows up and check the resources
-    GenericTestUtils.waitFor(() -> testFederationSubCluster.getNodeId(SC1_RM_WEB_ADDRESS) != null,
-         100, 5 * 1000);
-    String rm1NodeId = testFederationSubCluster.getNodeId(SC1_RM_WEB_ADDRESS);
-
-    // assert memory and default vcores
-    NodeInfo nodeInfo = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(NODES_NODEID, rm1NodeId),
-        NodeInfo.class, null, null);
-    assertEquals(4096, nodeInfo.getTotalResource().getMemorySize());
-    assertEquals(8, nodeInfo.getTotalResource().getvCores());
-  }
-
-  @Test
-  public void testActivies() throws Exception {
-    // wait until a node shows up and check the resources
-    GenericTestUtils.waitFor(() -> testFederationSubCluster.getNodeId(SC1_RM_WEB_ADDRESS) != null,
-        100, 5 * 1000);
-    String rm1NodeId = testFederationSubCluster.getNodeId(SC1_RM_WEB_ADDRESS);
-
-    ActivitiesInfo activitiesInfo = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + SCHEDULER_ACTIVITIES, ActivitiesInfo.class, "nodeId", rm1NodeId);
-
-    assertNotNull(activitiesInfo);
-    assertEquals(rm1NodeId, activitiesInfo.getNodeId());
-  }
-
-  @Test
-  public void testAppActivitiesXML() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    AppActivitiesInfo appActivitiesInfo =
-        TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + "/scheduler/app-activities/" + appId,
-        AppActivitiesInfo.class, null, null);
-    assertNotNull(appActivitiesInfo);
-    assertEquals(appId, appActivitiesInfo.getApplicationId());
-  }
-
-  @Test
-  public void testAppStatistics() throws Exception {
-    ApplicationStatisticsInfo applicationStatisticsInfo =
-        TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + APP_STATISTICS, ApplicationStatisticsInfo.class, STATES, "RUNNING");
-    assertNotNull(applicationStatisticsInfo);
-    ArrayList<StatisticsItemInfo> statItems = applicationStatisticsInfo.getStatItems();
-    assertNotNull(statItems);
-    assertEquals(1, statItems.size());
-  }
-
-  @Test
-  public void testNewApplication() throws Exception {
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + APPS_NEW_APPLICATION, null,
-        null, null, POST);
-    assertEquals(SC_OK, response.getStatus());
-    NewApplication ci = response.getEntity(NewApplication.class);
-    assertNotNull(ci);
-  }
-
-  @Test
-  public void testSubmitApplicationXML() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    assertNotNull(appId);
-  }
-
-  @Test
-  public void testApps() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    assertNotNull(appId);
-    AppsInfo appsInfo = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + APPS, AppsInfo.class, null, null);
-    assertNotNull(appsInfo);
-    assertEquals(1, appsInfo.getApps().size());
-  }
-
-  @Test
-  public void testApp() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    assertNotNull(appId);
-    AppInfo appInfo = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(APPS_APPID, appId),
-        AppInfo.class, null, null);
-    assertNotNull(appInfo);
-  }
-
-  @Test
-  public void testAppAttempt() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    assertNotNull(appId);
-    AppAttemptsInfo appAttemptsInfo = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_APPATTEMPTS, appId),
-        AppAttemptsInfo.class, null, null);
-    assertNotNull(appAttemptsInfo);
-    ArrayList<AppAttemptInfo> attempts = appAttemptsInfo.getAttempts();
-    assertNotNull(attempts);
-    assertEquals(1, attempts.size());
-  }
-
-  @Test
-  public void testAppState() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    assertNotNull(appId);
-    AppState appState = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_STATE, appId),
-         AppState.class, null, null);
-    assertNotNull(appState);
-    String state = appState.getState();
-    assertNotNull(state);
-    assertEquals("ACCEPTED", state);
-  }
-
-  @Test
-  public void testUpdateAppState() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    assertNotNull(appId);
-    AppState appState = new AppState("KILLED");
-    String pathApp = RM_WEB_SERVICE_PATH + format(APPS_APPID_STATE, appId);
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        pathApp, null, null, appState, PUT);
-    assertNotNull(response);
-    assertEquals(SC_ACCEPTED, response.getStatus());
-    AppState appState1 = response.getEntity(AppState.class);
-    assertNotNull(appState1);
-    assertNotNull(appState1.getState());
-    assertEquals("KILLING", appState1.getState());
-  }
-
-  @Test
-  public void testAppPriority() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    assertNotNull(appId);
-    AppPriority appPriority = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_PRIORITY, appId),
-        AppPriority.class, null, null);
-    assertNotNull(appPriority);
-    assertEquals(-1, appPriority.getPriority());
-  }
-
-  @Test
-  public void testUpdateAppPriority() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    AppPriority appPriority = new AppPriority(1);
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_PRIORITY, appId),
-        null, null, appPriority, PUT);
-
-    assertEquals(SC_OK, response.getStatus());
-    AppPriority ci = response.getEntity(AppPriority.class);
-    assertNotNull(ci);
-    assertNotNull(ci.getPriority());
-    assertEquals(1, ci.getPriority());
-  }
-
-  @Test
-  public void testAppQueue() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    AppQueue appQueue = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_QUEUE, appId),
-        AppQueue.class, null, null);
-    assertNotNull(appQueue);
-    String queue = appQueue.getQueue();
-    assertEquals("root.default", queue);
-  }
-
-  @Test
-  public void testUpdateAppQueue() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    AppQueue appQueue = new AppQueue("root.default");
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_QUEUE, appId),
-        null, null, appQueue, PUT);
-    assertEquals(SC_OK, response.getStatus());
-    AppQueue appQueue1 = response.getEntity(AppQueue.class);
-    assertNotNull(appQueue1);
-    String queue1 = appQueue1.getQueue();
-    assertEquals("root.default", queue1);
-  }
-
-  @Test
-  public void testAppTimeouts() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    AppTimeoutsInfo appTimeoutsInfo = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(APPS_TIMEOUTS, appId),
-        AppTimeoutsInfo.class, null, null);
-    assertNotNull(appTimeoutsInfo);
-    ArrayList<AppTimeoutInfo> appTimeouts = appTimeoutsInfo.getAppTimeouts();
-    assertNotNull(appTimeouts);
-    assertEquals(1, appTimeouts.size());
-    AppTimeoutInfo appTimeoutInfo = appTimeouts.get(0);
-    assertNotNull(appTimeoutInfo);
-    assertEquals(ApplicationTimeoutType.LIFETIME, appTimeoutInfo.getTimeoutType());
-    assertEquals("UNLIMITED", appTimeoutInfo.getExpireTime());
-  }
-
-  @Test
-  public void testAppTimeout() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    String pathApp = RM_WEB_SERVICE_PATH + format(APPS_TIMEOUTS, appId);
-    AppTimeoutInfo appTimeoutInfo = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        pathApp + "/" + "LIFETIME", AppTimeoutInfo.class, null, null);
-    assertNotNull(appTimeoutInfo);
-  }
-
-  @Test
-  public void testUpdateAppTimeouts() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    AppTimeoutInfo appTimeoutInfo = new AppTimeoutInfo();
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(APPS_TIMEOUT, appId),
-        null, null, appTimeoutInfo, PUT);
-    assertEquals(SC_BAD_REQUEST, response.getStatus());
-    String entity = response.getEntity(String.class);
-    assertNotNull(entity);
-  }
-
-  @Test
-  public void testNewReservation() throws Exception {
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + RESERVATION_NEW,
-        null, null, null, POST);
-    assertEquals(SC_OK, response.getStatus());
-    NewReservation ci = response.getEntity(NewReservation.class);
-    assertNotNull(ci);
-  }
-
-  @Test
-  public void testSubmitReservation() throws Exception {
-    ReservationSubmissionRequestInfo context = new ReservationSubmissionRequestInfo();
-    NewReservation newReservationId =
-        testFederationSubCluster.getNewReservationId(ROUTER_WEB_ADDRESS);
-    context.setReservationId(newReservationId.getReservationId());
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + RESERVATION_SUBMIT, null, null, context, POST);
-    assertEquals(SC_BAD_REQUEST, response.getStatus());
-    String entity = response.getEntity(String.class);
-    assertNotNull(entity);
-  }
-
-  @Test
-  public void testUpdateReservation() throws Exception {
-    NewReservation newReservationId =
-        testFederationSubCluster.getNewReservationId(ROUTER_WEB_ADDRESS);
-    String reservationId = newReservationId.getReservationId();
-    ReservationUpdateRequestInfo context = new ReservationUpdateRequestInfo();
-    context.setReservationId(reservationId);
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + RESERVATION_UPDATE, null, null, context, POST);
-    assertEquals(SC_BAD_REQUEST, response.getStatus());
-    String entity = response.getEntity(String.class);
-    assertNotNull(entity);
-  }
-
-  @Test
-  public void testDeleteReservation() throws Exception {
-    NewReservation newReservationId =
-        testFederationSubCluster.getNewReservationId(ROUTER_WEB_ADDRESS);
-    String reservationId = newReservationId.getReservationId();
-    ReservationDeleteRequestInfo context = new ReservationDeleteRequestInfo();
-    context.setReservationId(reservationId);
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + RESERVATION_DELETE, null, null, context, POST);
-    assertEquals(SC_SERVICE_UNAVAILABLE, response.getStatus());
-    String entity = response.getEntity(String.class);
-    assertNotNull(entity);
-  }
-
-  @Test
-  public void testGetClusterNodeLabels() throws Exception {
-    NodeLabelsInfo nodeLabelsInfo = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + GET_NODE_LABELS, NodeLabelsInfo.class, null, null);
-    assertNotNull(nodeLabelsInfo);
-  }
-
-  @Test
-  public void testGetLabelsOnNode() throws Exception {
-    String rm1NodeId = testFederationSubCluster.getNodeId(SC1_RM_WEB_ADDRESS);
-    NodeLabelsInfo nodeLabelsInfo = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(NODES_NODEID_GETLABELS, rm1NodeId),
-        NodeLabelsInfo.class, null, null);
-    assertNotNull(nodeLabelsInfo);
-  }
-
-  @Test
-  public void testGetLabelsMappingEmpty() throws Exception {
-    LabelsToNodesInfo labelsToNodesInfo = TestFederationSubCluster.performGetCalls(
-        ROUTER_WEB_ADDRESS, RM_WEB_SERVICE_PATH + LABEL_MAPPINGS,
-        LabelsToNodesInfo.class, null, null);
-    assertNotNull(labelsToNodesInfo);
-  }
-
-  @Test
-  public void testGetLabelsMapping() throws Exception {
-    LabelsToNodesInfo labelsToNodesInfo = TestFederationSubCluster.performGetCalls(
-        ROUTER_WEB_ADDRESS, RM_WEB_SERVICE_PATH + LABEL_MAPPINGS,
-        LabelsToNodesInfo.class, LABELS, "label1");
-    assertNotNull(labelsToNodesInfo);
-  }
-
-  @Test
-  public void testAddToClusterNodeLabels() throws Exception {
-    List<NodeLabel> nodeLabels = new ArrayList<>();
-    nodeLabels.add(NodeLabel.newInstance("default"));
-    NodeLabelsInfo context = new NodeLabelsInfo(nodeLabels);
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + ADD_NODE_LABELS, null, null, context, POST);
-    assertEquals(SC_OK, response.getStatus());
-    String entity = response.getEntity(String.class);
-    assertNotNull(entity);
-  }
-
-  @Test
-  public void testGetNodeToLabels() throws Exception {
-    NodeToLabelsInfo nodeToLabelsInfo = TestFederationSubCluster.performGetCalls(
-        ROUTER_WEB_ADDRESS, RM_WEB_SERVICE_PATH + GET_NODE_TO_LABELS,
-        NodeToLabelsInfo.class, null, null);
-    assertNotNull(nodeToLabelsInfo);
-  }
-
-  @Test
-  public void testRemoveFromClusterNodeLabels() throws Exception {
-    testFederationSubCluster.addNodeLabel(ROUTER_WEB_ADDRESS);
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + REMOVE_NODE_LABELS,
-        LABELS, "default", null, POST);
-    assertEquals(SC_OK, response.getStatus());
-    String entity = response.getEntity(String.class);
-    assertNotNull(entity);
-  }
-
-  @Test
-  public void testReplaceLabelsOnNodes() throws Exception {
-    testFederationSubCluster.addNodeLabel(ROUTER_WEB_ADDRESS);
-    NodeToLabelsEntryList context = new NodeToLabelsEntryList();
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + REPLACE_NODE_TO_LABELS,
-        null, null, context, POST);
-    String entity = response.getEntity(String.class);
-    assertNotNull(entity);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/fair/TestYarnFederationWithFairScheduler.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/fair/TestYarnFederationWithFairScheduler.java
deleted file mode 100644
index 8af40193149..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/subcluster/fair/TestYarnFederationWithFairScheduler.java
+++ /dev/null
@@ -1,639 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.subcluster.fair;
-
-import static javax.servlet.http.HttpServletResponse.SC_ACCEPTED;
-import static javax.servlet.http.HttpServletResponse.SC_SERVICE_UNAVAILABLE;
-import static javax.servlet.http.HttpServletResponse.SC_BAD_REQUEST;
-import com.sun.jersey.api.client.ClientResponse;
-import org.apache.hadoop.test.GenericTestUtils;
-import org.apache.hadoop.util.Sets;
-import org.apache.hadoop.yarn.api.records.Resource;
-import org.apache.hadoop.yarn.api.records.ResourceOption;
-import org.apache.hadoop.yarn.api.records.ApplicationTimeoutType;
-import org.apache.hadoop.yarn.api.records.NodeLabel;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterUserInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerTypeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.FairSchedulerInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.FairSchedulerQueueInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceOptionInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationStatisticsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.StatisticsItemInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NewApplication;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NewReservation;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LabelsToNodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntryList;
-import org.apache.hadoop.yarn.server.router.subcluster.TestFederationSubCluster;
-import org.apache.hadoop.yarn.server.router.webapp.dao.FederationClusterInfo;
-import org.apache.hadoop.yarn.server.router.webapp.dao.FederationClusterUserInfo;
-import org.apache.hadoop.yarn.server.router.webapp.dao.FederationSchedulerTypeInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.AppsInfo;
-import org.codehaus.jettison.json.JSONObject;
-import org.junit.AfterClass;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Set;
-import java.util.concurrent.TimeoutException;
-
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.RM_WEB_SERVICE_PATH;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.INFO;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.CLUSTER_USER_INFO;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.METRICS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.SCHEDULER;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.NODES;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.STATES;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.NODES_NODEID;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.NODES_NODEID_REPLACE_LABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.SCHEDULER_ACTIVITIES;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_NEW_APPLICATION;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APP_STATISTICS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APP_ID;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_APPID_APPATTEMPTS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_APPID_STATE;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_APPID_PRIORITY;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_APPID_QUEUE;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_TIMEOUTS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_TIMEOUT;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.RESERVATION_NEW;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.RESERVATION_SUBMIT;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.RESERVATION_UPDATE;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.RESERVATION_DELETE;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.GET_NODE_LABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.NODES_NODEID_GETLABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.LABEL_MAPPINGS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.LABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.ADD_NODE_LABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.GET_NODE_TO_LABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.REMOVE_NODE_LABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.REPLACE_NODE_TO_LABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.NODE_RESOURCE;
-import static org.apache.hadoop.yarn.server.router.subcluster.TestFederationSubCluster.format;
-import static org.apache.hadoop.yarn.server.router.webapp.HTTPMethods.POST;
-import static org.apache.hadoop.yarn.server.router.webapp.HTTPMethods.PUT;
-import static org.apache.http.HttpStatus.SC_OK;
-import static org.junit.Assert.assertNotNull;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertTrue;
-
-public class TestYarnFederationWithFairScheduler {
-  private static TestFederationSubCluster testFederationSubCluster;
-  private static Set<String> subClusters;
-  private static final String ROUTER_WEB_ADDRESS = "http://localhost:28089";
-  private static final String SC1_RM_WEB_ADDRESS = "http://localhost:38088";
-  private static final String SC2_RM_WEB_ADDRESS = "http://localhost:48088";
-
-  @BeforeClass
-  public static void setUp()
-      throws IOException, InterruptedException, YarnException, TimeoutException {
-    testFederationSubCluster = new TestFederationSubCluster();
-    testFederationSubCluster.startFederationSubCluster(2182,
-        "38032,38030,38031,38088,38033,SC-1,127.0.0.1:2182,fair-scheduler",
-        "48032,48030,48031,48088,48033,SC-2,127.0.0.1:2182,fair-scheduler",
-        "28050,28052,28089,127.0.0.1:2182");
-    subClusters = Sets.newHashSet();
-    subClusters.add("SC-1");
-    subClusters.add("SC-2");
-  }
-
-  @AfterClass
-  public static void shutDown() throws Exception {
-    testFederationSubCluster.stop();
-  }
-
-  @Test
-  public void testGetClusterInfo() throws InterruptedException, IOException {
-    FederationClusterInfo federationClusterInfo =
-        TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS, RM_WEB_SERVICE_PATH,
-        FederationClusterInfo.class, null, null);
-    List<ClusterInfo> clusterInfos = federationClusterInfo.getList();
-    assertNotNull(clusterInfos);
-    assertEquals(2, clusterInfos.size());
-    for (ClusterInfo clusterInfo : clusterInfos) {
-      assertNotNull(clusterInfo);
-      assertTrue(subClusters.contains(clusterInfo.getSubClusterId()));
-    }
-  }
-
-  @Test
-  public void testInfo() throws InterruptedException, IOException {
-    FederationClusterInfo federationClusterInfo =
-        TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS, RM_WEB_SERVICE_PATH + INFO,
-        FederationClusterInfo.class, null, null);
-    List<ClusterInfo> clusterInfos = federationClusterInfo.getList();
-    assertNotNull(clusterInfos);
-    assertEquals(2, clusterInfos.size());
-    for (ClusterInfo clusterInfo : clusterInfos) {
-      assertNotNull(clusterInfo);
-      assertTrue(subClusters.contains(clusterInfo.getSubClusterId()));
-    }
-  }
-
-  @Test
-  public void testClusterUserInfo() throws Exception {
-    FederationClusterUserInfo federationClusterUserInfo =
-        TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + CLUSTER_USER_INFO,
-        FederationClusterUserInfo.class, null, null);
-    List<ClusterUserInfo> clusterUserInfos = federationClusterUserInfo.getList();
-    assertNotNull(clusterUserInfos);
-    assertEquals(2, clusterUserInfos.size());
-    for (ClusterUserInfo clusterUserInfo : clusterUserInfos) {
-      assertNotNull(clusterUserInfo);
-      assertTrue(subClusters.contains(clusterUserInfo.getSubClusterId()));
-    }
-  }
-
-  @Test
-  public void testMetricsInfo() throws Exception {
-    // It takes time to start the sub-cluster.
-    // We need to wait for the sub-cluster to be completely started,
-    // so we need to set the waiting time.
-    // The resources of the two sub-clusters we registered are 24C and 12G,
-    // so the resources that the Router should collect are 48C and 24G.
-    GenericTestUtils.waitFor(() -> {
-      try {
-        ClusterMetricsInfo clusterMetricsInfo =
-            TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-            RM_WEB_SERVICE_PATH + METRICS, ClusterMetricsInfo.class, null, null);
-        assertNotNull(clusterMetricsInfo);
-        return (48 == clusterMetricsInfo.getTotalVirtualCores() &&
-            24576 == clusterMetricsInfo.getTotalMB());
-      } catch (Exception e) {
-        return false;
-      }
-    }, 5000, 50 * 5000);
-  }
-
-  @Test
-  public void testSchedulerInfo() throws Exception {
-    FederationSchedulerTypeInfo schedulerTypeInfo =
-        TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + SCHEDULER, FederationSchedulerTypeInfo.class, null, null);
-    assertNotNull(schedulerTypeInfo);
-    List<SchedulerTypeInfo> schedulerTypeInfos = schedulerTypeInfo.getList();
-    assertNotNull(schedulerTypeInfos);
-    assertEquals(2, schedulerTypeInfos.size());
-    for (SchedulerTypeInfo schedulerTypeInfoItem : schedulerTypeInfos) {
-      assertNotNull(schedulerTypeInfoItem);
-      assertTrue(subClusters.contains(schedulerTypeInfoItem.getSubClusterId()));
-      FairSchedulerQueueInfo rootQueueInfo =
-          ((FairSchedulerInfo) schedulerTypeInfoItem.getSchedulerInfo()).getRootQueueInfo();
-      assertNotNull(rootQueueInfo);
-      assertEquals("fair", rootQueueInfo.getSchedulingPolicy());
-    }
-  }
-
-  @Test
-  public void testNodesEmpty() throws Exception {
-    // We are in 2 sub-clusters, each with 3 nodes, so our Router should correspond to 6 nodes.
-    GenericTestUtils.waitFor(() -> {
-      try {
-        NodesInfo nodesInfo =
-            TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-            RM_WEB_SERVICE_PATH + NODES, NodesInfo.class, null, null);
-        assertNotNull(nodesInfo);
-        ArrayList<NodeInfo> nodes = nodesInfo.getNodes();
-        assertNotNull(nodes);
-        return (6 == nodes.size());
-      } catch (Exception e) {
-        return false;
-      }
-    }, 5000, 50 * 5000);
-  }
-
-  @Test
-  public void testNodesLost() throws Exception {
-    GenericTestUtils.waitFor(() -> {
-      try {
-        NodesInfo nodesInfo =
-            TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-            RM_WEB_SERVICE_PATH + NODES, NodesInfo.class, STATES, "LOST");
-        assertNotNull(nodesInfo);
-        ArrayList<NodeInfo> nodes = nodesInfo.getNodes();
-        assertNotNull(nodes);
-        return nodes.isEmpty();
-      } catch (Exception e) {
-        return false;
-      }
-    }, 5000, 50 * 5000);
-  }
-
-  @Test
-  public void testNode() throws Exception {
-    String rm1NodeId = testFederationSubCluster.getNodeId(SC1_RM_WEB_ADDRESS);
-    NodeInfo nodeInfo =
-        TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(NODES_NODEID, rm1NodeId),
-        NodeInfo.class, null, null);
-    assertNotNull(nodeInfo);
-    assertEquals(rm1NodeId, nodeInfo.getNodeId());
-
-    String rm2NodeId = testFederationSubCluster.getNodeId(SC2_RM_WEB_ADDRESS);
-    NodeInfo nodeInfo2 =
-        TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(NODES_NODEID, rm2NodeId),
-        NodeInfo.class, null, null);
-    assertNotNull(nodeInfo2);
-    assertEquals(rm2NodeId, nodeInfo2.getNodeId());
-  }
-
-  @Test
-  public void testUpdateNodeResource() throws Exception {
-    // wait until a node shows up and check the resources
-    GenericTestUtils.waitFor(() -> testFederationSubCluster.getNodeId(SC1_RM_WEB_ADDRESS) != null,
-        100, 5 * 1000);
-    String rm1NodeId = testFederationSubCluster.getNodeId(SC1_RM_WEB_ADDRESS);
-
-    // assert memory and default vcores
-    NodeInfo nodeInfo = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(NODES_NODEID, rm1NodeId),
-        NodeInfo.class, null, null);
-    assertEquals(4096, nodeInfo.getTotalResource().getMemorySize());
-    assertEquals(8, nodeInfo.getTotalResource().getvCores());
-
-    Resource resource = Resource.newInstance(4096, 5);
-    ResourceOptionInfo resourceOption = new ResourceOptionInfo(
-        ResourceOption.newInstance(resource, 1000));
-    ClientResponse routerResponse = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(NODE_RESOURCE, rm1NodeId),
-        null, null, resourceOption, POST);
-    JSONObject json = routerResponse.getEntity(JSONObject.class);
-    JSONObject totalResource = json.getJSONObject("resourceInfo");
-    assertEquals(resource.getMemorySize(), totalResource.getLong("memory"));
-    assertEquals(resource.getVirtualCores(), totalResource.getLong("vCores"));
-
-    // assert updated memory and cores
-    NodeInfo nodeInfo1 = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(NODES_NODEID, rm1NodeId),
-        NodeInfo.class, null, null);
-    assertEquals(4096, nodeInfo1.getTotalResource().getMemorySize());
-    assertEquals(5, nodeInfo1.getTotalResource().getvCores());
-  }
-
-  @Test
-  public void testActivies() throws Exception {
-    // wait until a node shows up and check the resources
-    GenericTestUtils.waitFor(() -> testFederationSubCluster.getNodeId(SC1_RM_WEB_ADDRESS) != null,
-        100, 5 * 1000);
-    String rm1NodeId = testFederationSubCluster.getNodeId(SC1_RM_WEB_ADDRESS);
-
-    ActivitiesInfo activitiesInfo = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + SCHEDULER_ACTIVITIES, ActivitiesInfo.class, "nodeId", rm1NodeId);
-
-    assertNotNull(activitiesInfo);
-    assertEquals(rm1NodeId, activitiesInfo.getNodeId());
-    assertEquals("Not Capacity Scheduler", activitiesInfo.getDiagnostic());
-  }
-
-  @Test
-  public void testAppActivities() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    AppActivitiesInfo appActivitiesInfo =
-        TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + "/scheduler/app-activities/" + appId,
-        AppActivitiesInfo.class, APP_ID, appId);
-    assertNotNull(appActivitiesInfo);
-    assertEquals(appId, appActivitiesInfo.getApplicationId());
-    assertEquals("Not Capacity Scheduler", appActivitiesInfo.getDiagnostic());
-  }
-
-  @Test
-  public void testAppStatistics() throws Exception {
-    ApplicationStatisticsInfo applicationStatisticsInfo =
-        TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + APP_STATISTICS, ApplicationStatisticsInfo.class, STATES, "RUNNING");
-    assertNotNull(applicationStatisticsInfo);
-    ArrayList<StatisticsItemInfo> statItems = applicationStatisticsInfo.getStatItems();
-    assertNotNull(statItems);
-    assertEquals(1, statItems.size());
-  }
-
-  @Test
-  public void testNewApplication() throws Exception {
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + APPS_NEW_APPLICATION, null,
-        null, null, POST);
-    assertEquals(SC_OK, response.getStatus());
-    NewApplication ci = response.getEntity(NewApplication.class);
-    assertNotNull(ci);
-  }
-
-  @Test
-  public void testSubmitApplication() {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    assertNotNull(appId);
-  }
-
-  @Test
-  public void testApps() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    assertNotNull(appId);
-    AppsInfo appsInfo = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + APPS, AppsInfo.class, null, null);
-    assertNotNull(appsInfo);
-    assertEquals(1, appsInfo.getApps().size());
-  }
-
-  @Test
-  public void testAppAttempt() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    assertNotNull(appId);
-    AppAttemptsInfo appAttemptsInfo = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_APPATTEMPTS, appId),
-        AppAttemptsInfo.class, null, null);
-    assertNotNull(appAttemptsInfo);
-    ArrayList<AppAttemptInfo> attempts = appAttemptsInfo.getAttempts();
-    assertNotNull(attempts);
-    assertEquals(1, attempts.size());
-  }
-
-  @Test
-  public void testAppState() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    assertNotNull(appId);
-    AppState appState = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_STATE, appId),
-        AppState.class, null, null);
-    assertNotNull(appState);
-    String state = appState.getState();
-    assertNotNull(state);
-    assertEquals("ACCEPTED", state);
-  }
-
-  @Test
-  public void testUpdateAppState() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    assertNotNull(appId);
-    AppState appState = new AppState("KILLED");
-    String pathApp = RM_WEB_SERVICE_PATH + format(APPS_APPID_STATE, appId);
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        pathApp, null, null, appState, PUT);
-    assertNotNull(response);
-    assertEquals(SC_ACCEPTED, response.getStatus());
-    AppState appState1 = response.getEntity(AppState.class);
-    assertNotNull(appState1);
-    assertNotNull(appState1.getState());
-    assertEquals("KILLING", appState1.getState());
-  }
-
-  @Test
-  public void testAppPriority() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    assertNotNull(appId);
-    AppPriority appPriority = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_PRIORITY, appId),
-        AppPriority.class, null, null);
-    assertNotNull(appPriority);
-    assertEquals(0, appPriority.getPriority());
-  }
-
-  @Test
-  public void testUpdateAppPriority() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    AppPriority appPriority = new AppPriority(1);
-    // FairScheduler does not support Update Application Priority.
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_PRIORITY, appId),
-        null, null, appPriority, PUT);
-    assertEquals(SC_SERVICE_UNAVAILABLE, response.getStatus());
-  }
-
-  @Test
-  public void testAppQueue() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    AppQueue appQueue = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_QUEUE, appId),
-        AppQueue.class, null, null);
-    assertNotNull(appQueue);
-    String queue = appQueue.getQueue();
-    assertEquals("root.dr_dot_who", queue);
-  }
-
-  @Test
-  public void testUpdateAppQueue() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    AppQueue appQueue = new AppQueue("root.a");
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_QUEUE, appId),
-        null, null, appQueue, PUT);
-    assertEquals(SC_OK, response.getStatus());
-    AppQueue appQueue1 = response.getEntity(AppQueue.class);
-    assertNotNull(appQueue1);
-    String queue1 = appQueue1.getQueue();
-    assertEquals("root.a", queue1);
-  }
-
-  @Test
-  public void testAppTimeouts() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    AppTimeoutsInfo appTimeoutsInfo = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(APPS_TIMEOUTS, appId),
-        AppTimeoutsInfo.class, null, null);
-    assertNotNull(appTimeoutsInfo);
-    ArrayList<AppTimeoutInfo> appTimeouts = appTimeoutsInfo.getAppTimeouts();
-    assertNotNull(appTimeouts);
-    assertEquals(1, appTimeouts.size());
-    AppTimeoutInfo appTimeoutInfo = appTimeouts.get(0);
-    assertNotNull(appTimeoutInfo);
-    assertEquals(ApplicationTimeoutType.LIFETIME, appTimeoutInfo.getTimeoutType());
-    assertEquals("UNLIMITED", appTimeoutInfo.getExpireTime());
-  }
-
-  @Test
-  public void testAppTimeout() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    String pathApp = RM_WEB_SERVICE_PATH + format(APPS_TIMEOUTS, appId);
-    AppTimeoutInfo appTimeoutInfo = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        pathApp + "/" + "LIFETIME", AppTimeoutInfo.class, null, null);
-    assertNotNull(appTimeoutInfo);
-  }
-
-  @Test
-  public void testUpdateAppTimeouts() throws Exception {
-    String appId = testFederationSubCluster.submitApplication(ROUTER_WEB_ADDRESS);
-    AppTimeoutInfo appTimeoutInfo = new AppTimeoutInfo();
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(APPS_TIMEOUT, appId),
-        null, null, appTimeoutInfo, PUT);
-    assertEquals(SC_BAD_REQUEST, response.getStatus());
-    String entity = response.getEntity(String.class);
-    assertNotNull(entity);
-  }
-
-  @Test
-  public void testNewReservation() throws Exception {
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + RESERVATION_NEW,
-        null, null, null, POST);
-    assertEquals(SC_OK, response.getStatus());
-    NewReservation ci = response.getEntity(NewReservation.class);
-    assertNotNull(ci);
-  }
-
-  @Test
-  public void testSubmitReservation() throws Exception {
-    ReservationSubmissionRequestInfo context = new ReservationSubmissionRequestInfo();
-    NewReservation newReservationId =
-        testFederationSubCluster.getNewReservationId(ROUTER_WEB_ADDRESS);
-    context.setReservationId(newReservationId.getReservationId());
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + RESERVATION_SUBMIT, null, null, context, POST);
-    assertEquals(SC_BAD_REQUEST, response.getStatus());
-    String entity = response.getEntity(String.class);
-    assertNotNull(entity);
-  }
-
-  @Test
-  public void testUpdateReservation() throws Exception {
-    NewReservation newReservationId =
-        testFederationSubCluster.getNewReservationId(ROUTER_WEB_ADDRESS);
-    String reservationId = newReservationId.getReservationId();
-    ReservationUpdateRequestInfo context = new ReservationUpdateRequestInfo();
-    context.setReservationId(reservationId);
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + RESERVATION_UPDATE, null, null, context, POST);
-    assertEquals(SC_BAD_REQUEST, response.getStatus());
-    String entity = response.getEntity(String.class);
-    assertNotNull(entity);
-  }
-
-  @Test
-  public void testDeleteReservation() throws Exception {
-    NewReservation newReservationId =
-        testFederationSubCluster.getNewReservationId(ROUTER_WEB_ADDRESS);
-    String reservationId = newReservationId.getReservationId();
-    ReservationDeleteRequestInfo context = new ReservationDeleteRequestInfo();
-    context.setReservationId(reservationId);
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + RESERVATION_DELETE, null, null, context, POST);
-    assertEquals(SC_SERVICE_UNAVAILABLE, response.getStatus());
-    String entity = response.getEntity(String.class);
-    assertNotNull(entity);
-  }
-
-  @Test
-  public void testGetClusterNodeLabels() throws Exception {
-    NodeLabelsInfo nodeLabelsInfo = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + GET_NODE_LABELS, NodeLabelsInfo.class, null, null);
-    assertNotNull(nodeLabelsInfo);
-  }
-
-  @Test
-  public void testGetLabelsOnNode() throws Exception {
-    String rm1NodeId = testFederationSubCluster.getNodeId(SC1_RM_WEB_ADDRESS);
-    NodeLabelsInfo nodeLabelsInfo = TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + format(NODES_NODEID_GETLABELS, rm1NodeId),
-        NodeLabelsInfo.class, null, null);
-    assertNotNull(nodeLabelsInfo);
-  }
-
-  @Test
-  public void testGetLabelsMappingEmpty() throws Exception {
-    LabelsToNodesInfo labelsToNodesInfo =
-        TestFederationSubCluster.performGetCalls(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + LABEL_MAPPINGS, LabelsToNodesInfo.class, null, null);
-    assertNotNull(labelsToNodesInfo);
-  }
-
-  @Test
-  public void testGetLabelsMapping() throws Exception {
-    LabelsToNodesInfo labelsToNodesInfo = TestFederationSubCluster.performGetCalls(
-        ROUTER_WEB_ADDRESS, RM_WEB_SERVICE_PATH + LABEL_MAPPINGS,
-        LabelsToNodesInfo.class, LABELS, "label1");
-    assertNotNull(labelsToNodesInfo);
-  }
-
-  @Test
-  public void testAddToClusterNodeLabels() throws Exception {
-    List<NodeLabel> nodeLabels = new ArrayList<>();
-    nodeLabels.add(NodeLabel.newInstance("default"));
-    NodeLabelsInfo context = new NodeLabelsInfo(nodeLabels);
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + ADD_NODE_LABELS, null, null, context, POST);
-    assertEquals(SC_OK, response.getStatus());
-    String entity = response.getEntity(String.class);
-    assertNotNull(entity);
-  }
-
-  @Test
-  public void testGetNodeToLabels() throws Exception {
-    NodeToLabelsInfo nodeToLabelsInfo = TestFederationSubCluster.performGetCalls(
-        ROUTER_WEB_ADDRESS, RM_WEB_SERVICE_PATH + GET_NODE_TO_LABELS,
-        NodeToLabelsInfo.class, null, null);
-    assertNotNull(nodeToLabelsInfo);
-  }
-
-  @Test
-  public void testRemoveFromClusterNodeLabels() throws Exception {
-    testFederationSubCluster.addNodeLabel(ROUTER_WEB_ADDRESS);
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + REMOVE_NODE_LABELS,
-        LABELS, "default", null, POST);
-    assertEquals(SC_OK, response.getStatus());
-    String entity = response.getEntity(String.class);
-    assertNotNull(entity);
-  }
-
-  @Test
-  public void testReplaceLabelsOnNodes() throws Exception {
-    testFederationSubCluster.addNodeLabel(ROUTER_WEB_ADDRESS);
-    NodeToLabelsEntryList context = new NodeToLabelsEntryList();
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        RM_WEB_SERVICE_PATH + REPLACE_NODE_TO_LABELS,
-        null, null, context, POST);
-    String entity = response.getEntity(String.class);
-    assertNotNull(entity);
-  }
-
-  @Test
-  public void testReplaceLabelsOnNode() throws Exception {
-    String rm1NodeId = testFederationSubCluster.getNodeId(SC1_RM_WEB_ADDRESS);
-    String pathNode = RM_WEB_SERVICE_PATH +
-        format(NODES_NODEID_REPLACE_LABELS, rm1NodeId);
-    testFederationSubCluster.addNodeLabel(ROUTER_WEB_ADDRESS);
-    ClientResponse response = TestFederationSubCluster.performCall(ROUTER_WEB_ADDRESS,
-        pathNode, LABELS, "default", null, POST);
-    assertEquals(SC_OK, response.getStatus());
-    String entity = response.getEntity(String.class);
-    assertNotNull(entity);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/BaseRouterWebServicesTest.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/BaseRouterWebServicesTest.java
deleted file mode 100644
index 423e0e5a38c..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/BaseRouterWebServicesTest.java
+++ /dev/null
@@ -1,419 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.spy;
-import static org.mockito.Mockito.when;
-
-import java.io.IOException;
-
-import javax.servlet.http.HttpServletRequest;
-import javax.servlet.http.HttpServletResponse;
-import javax.ws.rs.core.Response;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.security.authorize.AuthorizationException;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationStatisticsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LabelsToNodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.BulkActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerTypeInfo;
-import org.apache.hadoop.yarn.server.router.Router;
-import org.apache.hadoop.yarn.server.router.webapp.RouterWebServices.RequestInterceptorChainWrapper;
-import org.apache.hadoop.yarn.server.webapp.dao.AppAttemptInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainerInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainersInfo;
-import org.junit.After;
-import org.junit.Assert;
-import org.junit.Before;
-import org.mockito.Mockito;
-
-/**
- * Base class for all the RouterRMAdminService test cases. It provides utility
- * methods that can be used by the concrete test case classes.
- *
- */
-public abstract class BaseRouterWebServicesTest {
-
-  private YarnConfiguration conf;
-
-  private Router router;
-  public final static int TEST_MAX_CACHE_SIZE = 10;
-
-  public static final String QUEUE_DEFAULT = "default";
-  public static final String QUEUE_DEFAULT_FULL = CapacitySchedulerConfiguration.ROOT +
-      CapacitySchedulerConfiguration.DOT + QUEUE_DEFAULT;
-  public static final String QUEUE_DEDICATED = "dedicated";
-  public static final String QUEUE_DEDICATED_FULL = CapacitySchedulerConfiguration.ROOT +
-      CapacitySchedulerConfiguration.DOT + QUEUE_DEDICATED;
-
-  private RouterWebServices routerWebService;
-
-  @Before
-  public void setUp() throws YarnException, IOException {
-
-    this.conf = createConfiguration();
-
-    router = spy(new Router());
-    Mockito.doNothing().when(router).startWepApp();
-    routerWebService = new RouterWebServices(router, conf);
-    routerWebService.setResponse(mock(HttpServletResponse.class));
-
-    router.init(conf);
-    router.start();
-  }
-
-  protected YarnConfiguration createConfiguration() {
-    YarnConfiguration config = new YarnConfiguration();
-    String mockPassThroughInterceptorClass =
-        PassThroughRESTRequestInterceptor.class.getName();
-
-    // Create a request interceptor pipeline for testing. The last one in the
-    // chain will call the mock resource manager. The others in the chain will
-    // simply forward it to the next one in the chain
-    config.set(YarnConfiguration.ROUTER_WEBAPP_INTERCEPTOR_CLASS_PIPELINE,
-        mockPassThroughInterceptorClass + "," + mockPassThroughInterceptorClass
-            + "," + mockPassThroughInterceptorClass + ","
-            + MockRESTRequestInterceptor.class.getName());
-
-    config.setInt(YarnConfiguration.ROUTER_PIPELINE_CACHE_MAX_SIZE,
-        TEST_MAX_CACHE_SIZE);
-    return config;
-  }
-
-  @After
-  public void tearDown() {
-    if (router != null) {
-      router.stop();
-    }
-  }
-
-  public void setUpConfig() {
-    this.conf = createConfiguration();
-  }
-
-  protected Configuration getConf() {
-    return this.conf;
-  }
-
-  protected RouterWebServices getRouterWebServices() {
-    Assert.assertNotNull(this.routerWebService);
-    return this.routerWebService;
-  }
-
-  protected ClusterInfo get(String user)
-      throws IOException, InterruptedException {
-    // HSR is not used here
-    return routerWebService.get();
-  }
-
-  protected ClusterInfo getClusterInfo(String user)
-      throws IOException, InterruptedException {
-    // HSR is not used here
-    return routerWebService.getClusterInfo();
-  }
-
-  protected ClusterMetricsInfo getClusterMetricsInfo(String user)
-      throws IOException, InterruptedException {
-    // HSR is not used here
-    return routerWebService.getClusterMetricsInfo();
-  }
-
-  protected SchedulerTypeInfo getSchedulerInfo(String user)
-      throws IOException, InterruptedException {
-    // HSR is not used here
-    return routerWebService.getSchedulerInfo();
-  }
-
-  protected String dumpSchedulerLogs(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.dumpSchedulerLogs(null,
-        createHttpServletRequest(user));
-  }
-
-  protected NodesInfo getNodes(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getNodes(null);
-  }
-
-  protected NodeInfo getNode(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getNode(null);
-  }
-
-  protected AppsInfo getApps(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getApps(createHttpServletRequest(user), null, null,
-        null, null, null, null, null, null, null, null, null, null, null,
-        null);
-  }
-
-  protected ActivitiesInfo getActivities(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getActivities(
-        createHttpServletRequest(user), null, null);
-  }
-
-  protected BulkActivitiesInfo getBulkActivities(String user)
-      throws InterruptedException {
-    return routerWebService.getBulkActivities(
-        createHttpServletRequest(user), null, 0);
-  }
-
-  protected AppActivitiesInfo getAppActivities(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getAppActivities(createHttpServletRequest(user),
-        null, null, null, null, null, null, null, false);
-  }
-
-  protected ApplicationStatisticsInfo getAppStatistics(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getAppStatistics(
-        createHttpServletRequest(user), null, null);
-  }
-
-  protected AppInfo getApp(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getApp(createHttpServletRequest(user), null, null);
-  }
-
-  protected AppState getAppState(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getAppState(createHttpServletRequest(user), null);
-  }
-
-  protected Response updateAppState(String user) throws AuthorizationException,
-      YarnException, InterruptedException, IOException {
-    return routerWebService.updateAppState(
-        null, createHttpServletRequest(user), null);
-  }
-
-  protected NodeToLabelsInfo getNodeToLabels(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getNodeToLabels(createHttpServletRequest(user));
-  }
-
-  protected LabelsToNodesInfo getLabelsToNodes(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getLabelsToNodes(null);
-  }
-
-  protected Response replaceLabelsOnNodes(String user) throws Exception {
-    return routerWebService.replaceLabelsOnNodes(
-        null, createHttpServletRequest(user));
-  }
-
-  protected Response replaceLabelsOnNode(String user) throws Exception {
-    return routerWebService.replaceLabelsOnNode(
-        null, createHttpServletRequest(user), null);
-  }
-
-  protected NodeLabelsInfo getClusterNodeLabels(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getClusterNodeLabels(
-        createHttpServletRequest(user));
-  }
-
-  protected Response addToClusterNodeLabels(String user) throws Exception {
-    return routerWebService.addToClusterNodeLabels(
-        null, createHttpServletRequest(user));
-  }
-
-  protected Response removeFromClusterNodeLabels(String user) throws Exception {
-    return routerWebService.removeFromClusterNodeLabels(
-        null, createHttpServletRequest(user));
-  }
-
-  protected NodeLabelsInfo getLabelsOnNode(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getLabelsOnNode(
-        createHttpServletRequest(user), null);
-  }
-
-  protected AppPriority getAppPriority(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getAppPriority(
-        createHttpServletRequest(user), null);
-  }
-
-  protected Response updateApplicationPriority(String user)
-      throws AuthorizationException, YarnException, InterruptedException,
-      IOException {
-    return routerWebService.updateApplicationPriority(
-        null, createHttpServletRequest(user), null);
-  }
-
-  protected AppQueue getAppQueue(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getAppQueue(createHttpServletRequest(user), null);
-  }
-
-  protected Response updateAppQueue(String user) throws AuthorizationException,
-      YarnException, InterruptedException, IOException {
-    return routerWebService.updateAppQueue(
-        null, createHttpServletRequest(user), null);
-  }
-
-  protected Response createNewApplication(String user)
-      throws AuthorizationException, IOException, InterruptedException {
-    return routerWebService.createNewApplication(
-        createHttpServletRequest(user));
-  }
-
-  protected Response submitApplication(String user)
-      throws AuthorizationException, IOException, InterruptedException {
-    return routerWebService.submitApplication(
-        null, createHttpServletRequest(user));
-  }
-
-  protected Response postDelegationToken(String user)
-      throws AuthorizationException, IOException, InterruptedException,
-      Exception {
-    return routerWebService.postDelegationToken(
-        null, createHttpServletRequest(user));
-  }
-
-  protected Response postDelegationTokenExpiration(String user)
-      throws AuthorizationException, IOException, Exception {
-    return routerWebService.postDelegationTokenExpiration(
-        createHttpServletRequest(user));
-  }
-
-  protected Response cancelDelegationToken(String user)
-      throws AuthorizationException, IOException, InterruptedException,
-      Exception {
-    return routerWebService.cancelDelegationToken(
-        createHttpServletRequest(user));
-  }
-
-  protected Response createNewReservation(String user)
-      throws AuthorizationException, IOException, InterruptedException {
-    return routerWebService.createNewReservation(
-        createHttpServletRequest(user));
-  }
-
-  protected Response submitReservation(String user)
-      throws AuthorizationException, IOException, InterruptedException {
-    return routerWebService.submitReservation(
-        null, createHttpServletRequest(user));
-  }
-
-  protected Response updateReservation(String user)
-      throws AuthorizationException, IOException, InterruptedException {
-    return routerWebService.updateReservation(
-        null, createHttpServletRequest(user));
-  }
-
-  protected Response deleteReservation(String user)
-      throws AuthorizationException, IOException, InterruptedException {
-    return routerWebService.deleteReservation(
-        null, createHttpServletRequest(user));
-  }
-
-  protected Response listReservation(String user) throws Exception {
-    return routerWebService.listReservation(
-        null, null, 0, 0, false, createHttpServletRequest(user));
-  }
-
-  protected AppTimeoutInfo getAppTimeout(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getAppTimeout(
-        createHttpServletRequest(user), null, null);
-  }
-
-  protected AppTimeoutsInfo getAppTimeouts(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getAppTimeouts(
-        createHttpServletRequest(user), null);
-  }
-
-  protected Response updateApplicationTimeout(String user)
-      throws AuthorizationException, YarnException, InterruptedException,
-      IOException {
-    return routerWebService.updateApplicationTimeout(
-        null, createHttpServletRequest(user), null);
-  }
-
-  protected AppAttemptsInfo getAppAttempts(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getAppAttempts(
-        createHttpServletRequest(user), null);
-  }
-
-  protected AppAttemptInfo getAppAttempt(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getAppAttempt(
-        createHttpServletRequest(user), null, null, null);
-  }
-
-  protected ContainersInfo getContainers(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getContainers(
-        createHttpServletRequest(user), null, null, null);
-  }
-
-  protected ContainerInfo getContainer(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.getContainer(
-        createHttpServletRequest(user), null, null, null, null);
-  }
-
-  protected RequestInterceptorChainWrapper getInterceptorChain(String user)
-      throws IOException, InterruptedException {
-    HttpServletRequest request = createHttpServletRequest(user);
-    return routerWebService.getInterceptorChain(request);
-  }
-
-  private HttpServletRequest createHttpServletRequest(String user) {
-    HttpServletRequest request = mock(HttpServletRequest.class);
-    when(request.getRemoteUser()).thenReturn(user);
-    return request;
-  }
-
-  protected Response updateSchedulerConfiguration(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.updateSchedulerConfiguration(null,
-        createHttpServletRequest(user));
-  }
-
-  protected Response getSchedulerConfiguration(String user)
-      throws IOException, InterruptedException {
-    return routerWebService.
-        getSchedulerConfiguration(createHttpServletRequest(user));
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/JavaProcess.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/JavaProcess.java
deleted file mode 100644
index 3760b96c241..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/JavaProcess.java
+++ /dev/null
@@ -1,86 +0,0 @@
-/**
-* Licensed to the Apache Software Foundation (ASF) under one
-* or more contributor license agreements.  See the NOTICE file
-* distributed with this work for additional information
-* regarding copyright ownership.  The ASF licenses this file
-* to you under the Apache License, Version 2.0 (the
-* "License"); you may not use this file except in compliance
-* with the License.  You may obtain a copy of the License at
-*
-*     http://www.apache.org/licenses/LICENSE-2.0
-*
-* Unless required by applicable law or agreed to in writing, software
-* distributed under the License is distributed on an "AS IS" BASIS,
-* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-* See the License for the specific language governing permissions and
-* limitations under the License.
-*/
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import java.io.File;
-import java.io.IOException;
-import java.util.List;
-
-/**
- * Helper class to start a new process.
- */
-public class JavaProcess {
-
-  private Process process;
-
-  public JavaProcess(Class<?> clazz, File output)
-      throws IOException, InterruptedException {
-    this(clazz, null, output);
-  }
-
-  public JavaProcess(Class<?> clazz, List<String> addClassPaths, File output)
-      throws IOException {
-    String javaHome = System.getProperty("java.home");
-    String javaBin =
-        javaHome + File.separator + "bin" + File.separator + "java";
-    String classpath = System.getProperty("java.class.path");
-    classpath = classpath.concat("./src/test/resources");
-    if (addClassPaths != null) {
-      for (String addClasspath : addClassPaths) {
-        classpath = classpath.concat(File.pathSeparatorChar + addClasspath);
-      }
-    }
-    String className = clazz.getCanonicalName();
-    ProcessBuilder builder =
-        new ProcessBuilder(javaBin, "-cp", classpath, className);
-    builder.redirectInput(ProcessBuilder.Redirect.INHERIT);
-    builder.redirectOutput(output);
-    builder.redirectError(output);
-    process = builder.start();
-  }
-
-  public JavaProcess(Class<?> clazz, List<String> addClassPaths, File output, String param)
-      throws IOException {
-    String javaHome = System.getProperty("java.home");
-    String javaBin = javaHome + File.separator + "bin" + File.separator + "java";
-    String classpath = System.getProperty("java.class.path");
-    classpath = classpath.concat("./src/test/resources");
-    if (addClassPaths != null) {
-      for (String addClasspath : addClassPaths) {
-        classpath = classpath.concat(File.pathSeparatorChar + addClasspath);
-      }
-    }
-    String className = clazz.getCanonicalName();
-    ProcessBuilder builder =
-        new ProcessBuilder(javaBin, "-cp", classpath, className, param);
-    builder.redirectInput(ProcessBuilder.Redirect.INHERIT);
-    builder.redirectOutput(output);
-    builder.redirectError(output);
-    process = builder.start();
-  }
-
-  public void stop() throws InterruptedException {
-    if (process != null) {
-      process.destroy();
-      process.waitFor();
-      process.exitValue();
-    }
-  }
-
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/MockDefaultRequestInterceptorREST.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/MockDefaultRequestInterceptorREST.java
deleted file mode 100644
index f162ab6be65..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/MockDefaultRequestInterceptorREST.java
+++ /dev/null
@@ -1,1406 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import java.io.IOException;
-import java.net.ConnectException;
-import java.security.Principal;
-import java.util.ArrayList;
-import java.util.Set;
-import java.util.Map;
-import java.util.HashMap;
-import java.util.Collections;
-import java.util.Arrays;
-import java.util.List;
-import java.util.concurrent.atomic.AtomicInteger;
-import java.util.concurrent.atomic.AtomicLong;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.stream.Collectors;
-
-import javax.servlet.http.HttpServletRequest;
-import javax.servlet.http.HttpServletResponse;
-import javax.ws.rs.core.Context;
-import javax.ws.rs.core.HttpHeaders;
-import javax.ws.rs.core.Response;
-import javax.ws.rs.core.Response.Status;
-
-import org.apache.commons.lang3.EnumUtils;
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.classification.VisibleForTesting;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.metrics2.lib.DefaultMetricsSystem;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.security.authorize.AuthorizationException;
-import org.apache.hadoop.thirdparty.com.google.common.collect.ImmutableSet;
-import org.apache.hadoop.util.Sets;
-import org.apache.hadoop.util.Time;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationDeleteRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationListRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationListResponse;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationUpdateRequest;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.ReservationId;
-import org.apache.hadoop.yarn.api.records.Resource;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
-import org.apache.hadoop.yarn.api.records.NodeId;
-import org.apache.hadoop.yarn.api.records.Priority;
-import org.apache.hadoop.yarn.api.records.ContainerState;
-import org.apache.hadoop.yarn.api.records.ContainerReport;
-import org.apache.hadoop.yarn.api.records.NodeLabel;
-import org.apache.hadoop.yarn.api.records.SignalContainerCommand;
-import org.apache.hadoop.yarn.api.records.ApplicationReport;
-import org.apache.hadoop.yarn.api.records.YarnApplicationState;
-import org.apache.hadoop.yarn.api.records.FinalApplicationStatus;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptReport;
-import org.apache.hadoop.yarn.api.records.YarnApplicationAttemptState;
-import org.apache.hadoop.yarn.api.records.ApplicationTimeoutType;
-import org.apache.hadoop.yarn.api.records.ApplicationTimeout;
-import org.apache.hadoop.yarn.api.records.ReservationRequestInterpreter;
-import org.apache.hadoop.yarn.api.records.ReservationRequest;
-import org.apache.hadoop.yarn.api.records.ReservationRequests;
-import org.apache.hadoop.yarn.api.records.ReservationDefinition;
-import org.apache.hadoop.yarn.api.records.QueueACL;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.ApplicationNotFoundException;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.resourcemanager.ClientRMService;
-import org.apache.hadoop.yarn.server.resourcemanager.MockRM;
-import org.apache.hadoop.yarn.server.resourcemanager.RMContext;
-import org.apache.hadoop.yarn.server.resourcemanager.ResourceManager;
-import org.apache.hadoop.yarn.server.resourcemanager.reservation.ReservationSystem;
-import org.apache.hadoop.yarn.server.resourcemanager.rmapp.RMApp;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.ActiveUsersManager;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceScheduler;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.SchedulerNode;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.activities.ActivitiesManager;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.activities.ActivitiesLogger;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.activities.ActivityDiagnosticConstant;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.activities.ActivityState;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.activities.ActivityLevel;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.LeafQueue;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.TestUtils;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CSQueue;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerTestUtilities;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.conf.MutableCSConfigurationProvider;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerApp;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.common.fica.FiCaSchedulerNode;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.NodeIDsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LabelsToNodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterUserInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NewApplication;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceOptionInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.StatisticsItemInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationStatisticsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NewReservation;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationListInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateResponseInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteResponseInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntryList;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.BulkActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeAllocationInfo;
-import org.apache.hadoop.yarn.server.router.RouterServerUtil;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.PartitionInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.RMQueueAclInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerTypeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.CapacitySchedulerInfo;
-import org.apache.hadoop.yarn.server.scheduler.SchedulerRequestKey;
-import org.apache.hadoop.yarn.server.webapp.dao.AppAttemptInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainerInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainersInfo;
-import org.apache.hadoop.yarn.util.SystemClock;
-import org.apache.hadoop.yarn.util.resource.Resources;
-import org.apache.hadoop.yarn.webapp.BadRequestException;
-import org.apache.hadoop.yarn.webapp.ForbiddenException;
-import org.apache.hadoop.yarn.webapp.NotFoundException;
-import org.apache.hadoop.yarn.webapp.dao.ConfInfo;
-import org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo;
-import org.mockito.Mockito;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import static org.apache.hadoop.yarn.server.router.webapp.BaseRouterWebServicesTest.QUEUE_DEFAULT;
-import static org.apache.hadoop.yarn.server.router.webapp.BaseRouterWebServicesTest.QUEUE_DEFAULT_FULL;
-import static org.apache.hadoop.yarn.server.router.webapp.BaseRouterWebServicesTest.QUEUE_DEDICATED;
-import static org.apache.hadoop.yarn.server.router.webapp.BaseRouterWebServicesTest.QUEUE_DEDICATED_FULL;
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.when;
-
-/**
- * This class mocks the RESTRequestInterceptor.
- */
-public class MockDefaultRequestInterceptorREST
-    extends DefaultRequestInterceptorREST {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(MockDefaultRequestInterceptorREST.class);
-  final private AtomicInteger applicationCounter = new AtomicInteger(0);
-  // True if the Mock RM is running, false otherwise.
-  // This property allows us to write tests for specific scenario as YARN RM
-  // down e.g. network issue, failover.
-  private boolean isRunning = true;
-  private Map<ApplicationId, ApplicationReport> applicationMap = new HashMap<>();
-  public static final String APP_STATE_RUNNING = "RUNNING";
-
-  // duration(milliseconds), 1mins
-  public static final long DURATION = 60*1000;
-
-  // Containers 4
-  public static final int NUM_CONTAINERS = 4;
-
-  private Map<ReservationId, SubClusterId> reservationMap = new HashMap<>();
-  private AtomicLong resCounter = new AtomicLong();
-  private MockRM mockRM = null;
-
-  private void validateRunning() throws ConnectException {
-    if (!isRunning) {
-      throw new ConnectException("RM is stopped");
-    }
-  }
-
-  @Override
-  public Response createNewApplication(HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    validateRunning();
-
-    ApplicationId applicationId =
-        ApplicationId.newInstance(Integer.parseInt(getSubClusterId().getId()),
-            applicationCounter.incrementAndGet());
-    NewApplication appId =
-        new NewApplication(applicationId.toString(), new ResourceInfo());
-    return Response.status(Status.OK).entity(appId).build();
-  }
-
-  @Override
-  public Response submitApplication(ApplicationSubmissionContextInfo newApp,
-      HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    validateRunning();
-
-    ApplicationId appId = ApplicationId.fromString(newApp.getApplicationId());
-    LOG.info("Application submitted: " + appId);
-
-    // Initialize appReport
-    ApplicationReport appReport = ApplicationReport.newInstance(
-        appId, ApplicationAttemptId.newInstance(appId, 1), null, newApp.getQueue(), null, null, 0,
-        null, YarnApplicationState.ACCEPTED, "", null, 0, 0, null, null, null, 0,
-        newApp.getApplicationType(), null, null, false, Priority.newInstance(newApp.getPriority()),
-        null, null);
-
-    // Initialize appTimeoutsMap
-    HashMap<ApplicationTimeoutType, ApplicationTimeout> appTimeoutsMap = new HashMap<>();
-    ApplicationTimeoutType timeoutType = ApplicationTimeoutType.LIFETIME;
-    ApplicationTimeout appTimeOut =
-        ApplicationTimeout.newInstance(ApplicationTimeoutType.LIFETIME, "UNLIMITED", 10);
-    appTimeoutsMap.put(timeoutType, appTimeOut);
-    appReport.setApplicationTimeouts(appTimeoutsMap);
-
-    applicationMap.put(appId, appReport);
-    return Response.status(Status.ACCEPTED).header(HttpHeaders.LOCATION, "")
-        .entity(getSubClusterId()).build();
-  }
-
-  @Override
-  public AppInfo getApp(HttpServletRequest hsr, String appId,
-      Set<String> unselectedFields) {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    ApplicationId applicationId = ApplicationId.fromString(appId);
-    if (!applicationMap.containsKey(applicationId)) {
-      throw new NotFoundException("app with id: " + appId + " not found");
-    }
-
-    return new AppInfo();
-  }
-
-  @Override
-  public AppsInfo getApps(HttpServletRequest hsr, String stateQuery,
-      Set<String> statesQuery, String finalStatusQuery, String userQuery,
-      String queueQuery, String count, String startedBegin, String startedEnd,
-      String finishBegin, String finishEnd, Set<String> applicationTypes,
-      Set<String> applicationTags, String name, Set<String> unselectedFields) {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-    AppsInfo appsInfo = new AppsInfo();
-    AppInfo appInfo = new AppInfo();
-
-    appInfo.setAppId(
-        ApplicationId.newInstance(Integer.parseInt(getSubClusterId().getId()),
-            applicationCounter.incrementAndGet()).toString());
-    appInfo.setAMHostHttpAddress("http://i_am_the_AM:1234");
-
-    appsInfo.add(appInfo);
-    return appsInfo;
-  }
-
-  @Override
-  public Response updateAppState(AppState targetState, HttpServletRequest hsr,
-      String appId) throws AuthorizationException, YarnException,
-      InterruptedException, IOException {
-    validateRunning();
-
-    ApplicationId applicationId = ApplicationId.fromString(appId);
-    if (applicationMap.remove(applicationId) == null) {
-      throw new ApplicationNotFoundException(
-          "Trying to kill an absent application: " + appId);
-    }
-
-    if (targetState == null) {
-      return Response.status(Status.BAD_REQUEST).build();
-    }
-
-    LOG.info("Force killing application: " + appId);
-    AppState ret = new AppState();
-    ret.setState(targetState.toString());
-    return Response.status(Status.OK).entity(ret).build();
-  }
-
-  @Override
-  public NodeInfo getNode(String nodeId) {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-    NodeInfo node = null;
-    SubClusterId subCluster = getSubClusterId();
-    String subClusterId = subCluster.getId();
-    if (nodeId.contains(subClusterId) || nodeId.contains("test")) {
-      node = new NodeInfo();
-      node.setId(nodeId);
-      node.setLastHealthUpdate(Integer.parseInt(getSubClusterId().getId()));
-    }
-    return node;
-  }
-
-  @Override
-  public NodesInfo getNodes(String states) {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-    NodeInfo node = new NodeInfo();
-    node.setId("Node " + Integer.valueOf(getSubClusterId().getId()));
-    node.setLastHealthUpdate(Integer.parseInt(getSubClusterId().getId()));
-    NodesInfo nodes = new NodesInfo();
-    nodes.add(node);
-    return nodes;
-  }
-
-  @Override
-  public ResourceInfo updateNodeResource(HttpServletRequest hsr,
-      String nodeId, ResourceOptionInfo resourceOption) {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-    Resource resource = resourceOption.getResourceOption().getResource();
-    return new ResourceInfo(resource);
-  }
-
-  @Override
-  public ClusterMetricsInfo getClusterMetricsInfo() {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-    ClusterMetricsInfo metrics = new ClusterMetricsInfo();
-    metrics.setAppsSubmitted(Integer.parseInt(getSubClusterId().getId()));
-    metrics.setAppsCompleted(Integer.parseInt(getSubClusterId().getId()));
-    metrics.setAppsPending(Integer.parseInt(getSubClusterId().getId()));
-    metrics.setAppsRunning(Integer.parseInt(getSubClusterId().getId()));
-    metrics.setAppsFailed(Integer.parseInt(getSubClusterId().getId()));
-    metrics.setAppsKilled(Integer.parseInt(getSubClusterId().getId()));
-
-    return metrics;
-  }
-
-  @Override
-  public AppState getAppState(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    ApplicationId applicationId = ApplicationId.fromString(appId);
-    if (!applicationMap.containsKey(applicationId)) {
-      throw new NotFoundException("app with id: " + appId + " not found");
-    }
-
-    return new AppState(APP_STATE_RUNNING);
-  }
-
-  public void setSubClusterId(int subClusterId) {
-    setSubClusterId(SubClusterId.newInstance(Integer.toString(subClusterId)));
-  }
-
-  public boolean isRunning() {
-    return isRunning;
-  }
-
-  public void setRunning(boolean runningMode) {
-    this.isRunning = runningMode;
-  }
-
-  @Override
-  public ContainersInfo getContainers(HttpServletRequest req, HttpServletResponse res,
-      String appId, String appAttemptId) {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    // Try format conversion for app_id
-    ApplicationId applicationId = null;
-    try {
-      applicationId = ApplicationId.fromString(appId);
-    } catch (Exception e) {
-      throw new BadRequestException(e);
-    }
-
-    // Try format conversion for app_attempt_id
-    ApplicationAttemptId applicationAttemptId = null;
-    try {
-      applicationAttemptId =
-          ApplicationAttemptId.fromString(appAttemptId);
-    } catch (Exception e) {
-      throw new BadRequestException(e);
-    }
-
-    // We avoid to check if the Application exists in the system because we need
-    // to validate that each subCluster returns 1 container.
-    ContainersInfo containers = new ContainersInfo();
-
-    int subClusterId = Integer.valueOf(getSubClusterId().getId());
-
-    ContainerId containerId = ContainerId.newContainerId(
-        ApplicationAttemptId.fromString(appAttemptId), subClusterId);
-    Resource allocatedResource =
-        Resource.newInstance(subClusterId, subClusterId);
-
-    NodeId assignedNode = NodeId.newInstance("Node", subClusterId);
-    Priority priority = Priority.newInstance(subClusterId);
-    long creationTime = subClusterId;
-    long finishTime = subClusterId;
-    String diagnosticInfo = "Diagnostic " + subClusterId;
-    String logUrl = "Log " + subClusterId;
-    int containerExitStatus = subClusterId;
-    ContainerState containerState = ContainerState.COMPLETE;
-    String nodeHttpAddress = "HttpAddress " + subClusterId;
-
-    ContainerReport containerReport = ContainerReport.newInstance(
-        containerId, allocatedResource, assignedNode, priority,
-        creationTime, finishTime, diagnosticInfo, logUrl,
-        containerExitStatus, containerState, nodeHttpAddress);
-
-    ContainerInfo container = new ContainerInfo(containerReport);
-    containers.add(container);
-
-    return containers;
-  }
-
-  @Override
-  public NodeToLabelsInfo getNodeToLabels(HttpServletRequest hsr) throws IOException {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-    NodeLabelsInfo cpuNode = new NodeLabelsInfo(Collections.singleton("CPU"));
-    NodeLabelsInfo gpuNode = new NodeLabelsInfo(Collections.singleton("GPU"));
-
-    HashMap<String, NodeLabelsInfo> nodeLabels = new HashMap<>();
-    nodeLabels.put("node1", cpuNode);
-    nodeLabels.put("node2", gpuNode);
-    return new NodeToLabelsInfo(nodeLabels);
-  }
-
-  @Override
-  public LabelsToNodesInfo getLabelsToNodes(Set<String> labels) throws IOException {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    Map<NodeLabelInfo, NodeIDsInfo> labelsToNodes = new HashMap<>();
-
-    NodeLabel labelX = NodeLabel.newInstance("x", false);
-    NodeLabelInfo nodeLabelInfoX = new NodeLabelInfo(labelX);
-    ArrayList<String> hostsX = new ArrayList<>(Arrays.asList("host1A", "host1B"));
-    Resource resourceX = Resource.newInstance(20*1024, 10);
-    NodeIDsInfo nodeIDsInfoX = new NodeIDsInfo(hostsX, resourceX);
-    labelsToNodes.put(nodeLabelInfoX, nodeIDsInfoX);
-
-    NodeLabel labelY = NodeLabel.newInstance("y", false);
-    NodeLabelInfo nodeLabelInfoY = new NodeLabelInfo(labelY);
-    ArrayList<String> hostsY = new ArrayList<>(Arrays.asList("host2A", "host2B"));
-    Resource resourceY = Resource.newInstance(40*1024, 20);
-    NodeIDsInfo nodeIDsInfoY = new NodeIDsInfo(hostsY, resourceY);
-    labelsToNodes.put(nodeLabelInfoY, nodeIDsInfoY);
-
-    NodeLabel labelZ = NodeLabel.newInstance("z", false);
-    NodeLabelInfo nodeLabelInfoZ = new NodeLabelInfo(labelZ);
-    ArrayList<String> hostsZ = new ArrayList<>(Arrays.asList("host3A", "host3B"));
-    Resource resourceZ = Resource.newInstance(80*1024, 40);
-    NodeIDsInfo nodeIDsInfoZ = new NodeIDsInfo(hostsZ, resourceZ);
-    labelsToNodes.put(nodeLabelInfoZ, nodeIDsInfoZ);
-
-    return new LabelsToNodesInfo(labelsToNodes);
-  }
-
-  @Override
-  public NodeLabelsInfo getClusterNodeLabels(HttpServletRequest hsr) throws IOException {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-    NodeLabel labelCpu = NodeLabel.newInstance("cpu", false);
-    NodeLabel labelGpu = NodeLabel.newInstance("gpu", false);
-    return new NodeLabelsInfo(Sets.newHashSet(labelCpu, labelGpu));
-  }
-
-  @Override
-  public NodeLabelsInfo getLabelsOnNode(HttpServletRequest hsr, String nodeId) throws IOException {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    if (StringUtils.equalsIgnoreCase(nodeId, "node1")) {
-      NodeLabel labelCpu = NodeLabel.newInstance("x", false);
-      NodeLabel labelGpu = NodeLabel.newInstance("y", false);
-      return new NodeLabelsInfo(Sets.newHashSet(labelCpu, labelGpu));
-    } else {
-      return null;
-    }
-  }
-
-  @Override
-  public ContainerInfo getContainer(HttpServletRequest req, HttpServletResponse res,
-      String appId, String appAttemptId, String containerId) {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    ContainerId newContainerId = ContainerId.fromString(containerId);
-
-    Resource allocatedResource = Resource.newInstance(1024, 2);
-
-    int subClusterId = Integer.valueOf(getSubClusterId().getId());
-    NodeId assignedNode = NodeId.newInstance("Node", subClusterId);
-    Priority priority = Priority.newInstance(subClusterId);
-    long creationTime = subClusterId;
-    long finishTime = subClusterId;
-    String diagnosticInfo = "Diagnostic " + subClusterId;
-    String logUrl = "Log " + subClusterId;
-    int containerExitStatus = subClusterId;
-    ContainerState containerState = ContainerState.COMPLETE;
-    String nodeHttpAddress = "HttpAddress " + subClusterId;
-
-    ContainerReport containerReport = ContainerReport.newInstance(
-        newContainerId, allocatedResource, assignedNode, priority,
-        creationTime, finishTime, diagnosticInfo, logUrl,
-        containerExitStatus, containerState, nodeHttpAddress);
-
-    return new ContainerInfo(containerReport);
-  }
-
-  @Override
-  public Response signalToContainer(String containerId, String command,
-      HttpServletRequest req) throws AuthorizationException {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    if (!EnumUtils.isValidEnum(SignalContainerCommand.class, command.toUpperCase())) {
-      String errMsg = "Invalid command: " + command.toUpperCase() + ", valid commands are: "
-          + Arrays.asList(SignalContainerCommand.values());
-      return Response.status(Status.BAD_REQUEST).entity(errMsg).build();
-    }
-
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public AppAttemptInfo getAppAttempt(HttpServletRequest req, HttpServletResponse res,
-      String appId, String appAttemptId) {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    ApplicationId applicationId = ApplicationId.fromString(appId);
-    if (!applicationMap.containsKey(applicationId)) {
-      throw new NotFoundException("app with id: " + appId + " not found");
-    }
-
-    ApplicationAttemptId attemptId = ApplicationAttemptId.fromString(appAttemptId);
-
-    ApplicationReport newApplicationReport = ApplicationReport.newInstance(
-        applicationId, attemptId, "user", "queue", "appname", "host", 124, null,
-        YarnApplicationState.RUNNING, "diagnostics", "url", 1, 2, 3, 4,
-        FinalApplicationStatus.SUCCEEDED, null, "N/A", 0.53789f, "YARN", null);
-
-    ApplicationAttemptReport attempt = ApplicationAttemptReport.newInstance(
-        attemptId, "host", 124, "url", "oUrl", "diagnostics",
-        YarnApplicationAttemptState.FINISHED, ContainerId.newContainerId(
-        newApplicationReport.getCurrentApplicationAttemptId(), 1));
-
-    return new AppAttemptInfo(attempt);
-  }
-
-  @Override
-  public AppAttemptsInfo getAppAttempts(HttpServletRequest hsr, String appId) {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    ApplicationId applicationId = ApplicationId.fromString(appId);
-    if (!applicationMap.containsKey(applicationId)) {
-      throw new NotFoundException("app with id: " + appId + " not found");
-    }
-
-    AppAttemptsInfo infos = new AppAttemptsInfo();
-    infos.add(TestRouterWebServiceUtil.generateAppAttemptInfo(0));
-    infos.add(TestRouterWebServiceUtil.generateAppAttemptInfo(1));
-    return infos;
-  }
-
-  @Override
-  public AppTimeoutInfo getAppTimeout(HttpServletRequest hsr,
-      String appId, String type) throws AuthorizationException {
-
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    ApplicationId applicationId = ApplicationId.fromString(appId);
-    if (!applicationMap.containsKey(applicationId)) {
-      throw new NotFoundException("app with id: " + appId + " not found");
-    }
-
-    ApplicationReport appReport = applicationMap.get(applicationId);
-    Map<ApplicationTimeoutType, ApplicationTimeout> timeouts = appReport.getApplicationTimeouts();
-    ApplicationTimeoutType paramType = ApplicationTimeoutType.valueOf(type);
-
-    if (paramType == null) {
-      throw new NotFoundException("application timeout type not found");
-    }
-
-    if (!timeouts.containsKey(paramType)) {
-      throw new NotFoundException("timeout with id: " + appId + " not found");
-    }
-
-    ApplicationTimeout applicationTimeout = timeouts.get(paramType);
-
-    AppTimeoutInfo timeoutInfo = new AppTimeoutInfo();
-    timeoutInfo.setExpiryTime(applicationTimeout.getExpiryTime());
-    timeoutInfo.setTimeoutType(applicationTimeout.getTimeoutType());
-    timeoutInfo.setRemainingTime(applicationTimeout.getRemainingTime());
-
-    return timeoutInfo;
-  }
-
-  @Override
-  public AppTimeoutsInfo getAppTimeouts(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    ApplicationId applicationId = ApplicationId.fromString(appId);
-
-    if (!applicationMap.containsKey(applicationId)) {
-      throw new NotFoundException("app with id: " + appId + " not found");
-    }
-
-    ApplicationReport appReport = applicationMap.get(applicationId);
-    Map<ApplicationTimeoutType, ApplicationTimeout> timeouts = appReport.getApplicationTimeouts();
-
-    AppTimeoutsInfo timeoutsInfo = new AppTimeoutsInfo();
-
-    for (ApplicationTimeout timeout : timeouts.values()) {
-      AppTimeoutInfo timeoutInfo = new AppTimeoutInfo();
-      timeoutInfo.setExpiryTime(timeout.getExpiryTime());
-      timeoutInfo.setTimeoutType(timeout.getTimeoutType());
-      timeoutInfo.setRemainingTime(timeout.getRemainingTime());
-      timeoutsInfo.add(timeoutInfo);
-    }
-
-    return timeoutsInfo;
-  }
-
-  @Override
-  public Response updateApplicationTimeout(AppTimeoutInfo appTimeout, HttpServletRequest hsr,
-      String appId) throws AuthorizationException,
-      YarnException, InterruptedException, IOException {
-
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    ApplicationId applicationId = ApplicationId.fromString(appId);
-
-    if (!applicationMap.containsKey(applicationId)) {
-      throw new NotFoundException("app with id: " + appId + " not found");
-    }
-
-    ApplicationReport appReport = applicationMap.get(applicationId);
-    Map<ApplicationTimeoutType, ApplicationTimeout> timeouts = appReport.getApplicationTimeouts();
-
-    ApplicationTimeoutType paramTimeoutType = appTimeout.getTimeoutType();
-    if (!timeouts.containsKey(paramTimeoutType)) {
-      throw new NotFoundException("TimeOutType with id: " + appId + " not found");
-    }
-
-    ApplicationTimeout applicationTimeout = timeouts.get(paramTimeoutType);
-    applicationTimeout.setTimeoutType(appTimeout.getTimeoutType());
-    applicationTimeout.setExpiryTime(appTimeout.getExpireTime());
-    applicationTimeout.setRemainingTime(appTimeout.getRemainingTimeInSec());
-
-    AppTimeoutInfo result = new AppTimeoutInfo(applicationTimeout);
-
-    return Response.status(Status.OK).entity(result).build();
-  }
-
-  @Override
-  public Response updateApplicationPriority(AppPriority targetPriority, HttpServletRequest hsr,
-      String appId) throws YarnException, InterruptedException, IOException {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    ApplicationId applicationId = ApplicationId.fromString(appId);
-    if (targetPriority == null) {
-      return Response.status(Status.BAD_REQUEST).build();
-    }
-
-    if (!applicationMap.containsKey(applicationId)) {
-      throw new NotFoundException("app with id: " + appId + " not found");
-    }
-
-    ApplicationReport appReport = applicationMap.get(applicationId);
-    Priority newPriority = Priority.newInstance(targetPriority.getPriority());
-    appReport.setPriority(newPriority);
-
-    return Response.status(Status.OK).entity(targetPriority).build();
-  }
-
-  @Override
-  public AppPriority getAppPriority(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    ApplicationId applicationId = ApplicationId.fromString(appId);
-
-    if (!applicationMap.containsKey(applicationId)) {
-      throw new NotFoundException("app with id: " + appId + " not found");
-    }
-    ApplicationReport appReport = applicationMap.get(applicationId);
-    Priority priority = appReport.getPriority();
-
-    return new AppPriority(priority.getPriority());
-  }
-
-  @Override
-  public AppQueue getAppQueue(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-    ApplicationId applicationId = ApplicationId.fromString(appId);
-    if (!applicationMap.containsKey(applicationId)) {
-      throw new NotFoundException("app with id: " + appId + " not found");
-    }
-    String queue = applicationMap.get(applicationId).getQueue();
-    return new AppQueue(queue);
-  }
-
-  @Override
-  public Response updateAppQueue(AppQueue targetQueue, HttpServletRequest hsr, String appId)
-      throws AuthorizationException, YarnException, InterruptedException, IOException {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-    ApplicationId applicationId = ApplicationId.fromString(appId);
-    if (!applicationMap.containsKey(applicationId)) {
-      throw new NotFoundException("app with id: " + appId + " not found");
-    }
-    if (targetQueue == null || StringUtils.isBlank(targetQueue.getQueue())) {
-      return Response.status(Status.BAD_REQUEST).build();
-    }
-
-    ApplicationReport appReport = applicationMap.get(applicationId);
-    String originalQueue = appReport.getQueue();
-    appReport.setQueue(targetQueue.getQueue());
-    applicationMap.put(applicationId, appReport);
-    LOG.info("Update applicationId = {} from originalQueue = {} to targetQueue = {}.",
-        appId, originalQueue, targetQueue);
-
-    AppQueue targetAppQueue = new AppQueue(targetQueue.getQueue());
-    return Response.status(Status.OK).entity(targetAppQueue).build();
-  }
-
-  public void updateApplicationState(YarnApplicationState appState, String appId)
-      throws AuthorizationException, YarnException, InterruptedException, IOException {
-    validateRunning();
-    ApplicationId applicationId = ApplicationId.fromString(appId);
-    if (!applicationMap.containsKey(applicationId)) {
-      throw new NotFoundException("app with id: " + appId + " not found");
-    }
-    ApplicationReport appReport = applicationMap.get(applicationId);
-    appReport.setYarnApplicationState(appState);
-  }
-
-  @Override
-  public ApplicationStatisticsInfo getAppStatistics(
-      HttpServletRequest hsr, Set<String> stateQueries, Set<String> typeQueries) {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    Map<String, StatisticsItemInfo> itemInfoMap = new HashMap<>();
-
-    for (ApplicationReport appReport : applicationMap.values()) {
-
-      YarnApplicationState appState = appReport.getYarnApplicationState();
-      String appType = appReport.getApplicationType();
-
-      if (stateQueries.contains(appState.name()) && typeQueries.contains(appType)) {
-        String itemInfoMapKey = appState.toString() + "_" + appType;
-        StatisticsItemInfo itemInfo = itemInfoMap.getOrDefault(itemInfoMapKey, null);
-        if (itemInfo == null) {
-          itemInfo = new StatisticsItemInfo(appState, appType, 1);
-        } else {
-          long newCount = itemInfo.getCount() + 1;
-          itemInfo.setCount(newCount);
-        }
-        itemInfoMap.put(itemInfoMapKey, itemInfo);
-      }
-    }
-
-    return new ApplicationStatisticsInfo(itemInfoMap.values());
-  }
-
-  @Override
-  public AppActivitiesInfo getAppActivities(
-      HttpServletRequest hsr, String appId, String time, Set<String> requestPriorities,
-      Set<String> allocationRequestIds, String groupBy, String limit, Set<String> actions,
-      boolean summarize) {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    ApplicationId applicationId = ApplicationId.fromString(appId);
-    if (!applicationMap.containsKey(applicationId)) {
-      throw new NotFoundException("app with id: " + appId + " not found");
-    }
-
-    SchedulerNode schedulerNode = TestUtils.getMockNode("host0", "rack", 1, 10240);
-
-    RMContext rmContext = Mockito.mock(RMContext.class);
-    Mockito.when(rmContext.getYarnConfiguration()).thenReturn(this.getConf());
-    ResourceScheduler scheduler = Mockito.mock(ResourceScheduler.class);
-    Mockito.when(scheduler.getMinimumResourceCapability()).thenReturn(Resources.none());
-    Mockito.when(rmContext.getScheduler()).thenReturn(scheduler);
-    LeafQueue mockQueue = Mockito.mock(LeafQueue.class);
-    Map<ApplicationId, RMApp> rmApps = new ConcurrentHashMap<>();
-    Mockito.doReturn(rmApps).when(rmContext).getRMApps();
-
-    FiCaSchedulerNode node = (FiCaSchedulerNode) schedulerNode;
-    ApplicationAttemptId appAttemptId = ApplicationAttemptId.newInstance(applicationId, 0);
-    RMApp mockApp = Mockito.mock(RMApp.class);
-    Mockito.doReturn(appAttemptId.getApplicationId()).when(mockApp).getApplicationId();
-    Mockito.doReturn(FinalApplicationStatus.UNDEFINED).when(mockApp).getFinalApplicationStatus();
-    rmApps.put(appAttemptId.getApplicationId(), mockApp);
-    FiCaSchedulerApp app = new FiCaSchedulerApp(appAttemptId, "user", mockQueue,
-        mock(ActiveUsersManager.class), rmContext);
-
-    ActivitiesManager newActivitiesManager = new ActivitiesManager(rmContext);
-    newActivitiesManager.turnOnAppActivitiesRecording(app.getApplicationId(), 3);
-
-    int numActivities = 10;
-    for (int i = 0; i < numActivities; i++) {
-      ActivitiesLogger.APP.startAppAllocationRecording(newActivitiesManager, node,
-          SystemClock.getInstance().getTime(), app);
-      ActivitiesLogger.APP.recordAppActivityWithoutAllocation(newActivitiesManager, node, app,
-          new SchedulerRequestKey(Priority.newInstance(0), 0, null),
-          ActivityDiagnosticConstant.NODE_IS_BLACKLISTED, ActivityState.REJECTED,
-          ActivityLevel.NODE);
-      ActivitiesLogger.APP.finishSkippedAppAllocationRecording(newActivitiesManager,
-          app.getApplicationId(), ActivityState.SKIPPED, ActivityDiagnosticConstant.EMPTY);
-    }
-
-    Set<Integer> prioritiesInt =
-        requestPriorities.stream().map(pri -> Integer.parseInt(pri)).collect(Collectors.toSet());
-    Set<Long> allocationReqIds =
-        allocationRequestIds.stream().map(id -> Long.parseLong(id)).collect(Collectors.toSet());
-    AppActivitiesInfo appActivitiesInfo = newActivitiesManager.
-        getAppActivitiesInfo(app.getApplicationId(), prioritiesInt, allocationReqIds, null,
-        Integer.parseInt(limit), summarize, 3);
-
-    return appActivitiesInfo;
-  }
-
-  @Override
-  public Response listReservation(String queue, String reservationId, long startTime, long endTime,
-      boolean includeResourceAllocations, HttpServletRequest hsr) throws Exception {
-
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    if (!StringUtils.equals(queue, QUEUE_DEDICATED_FULL)) {
-      throw new RuntimeException("The specified queue: " + queue +
-          " is not managed by reservation system." +
-          " Please try again with a valid reservable queue.");
-    }
-
-    ReservationId reservationID =
-        ReservationId.parseReservationId(reservationId);
-
-    if (!reservationMap.containsKey(reservationID)) {
-      throw new NotFoundException("reservationId with id: " + reservationId + " not found");
-    }
-
-    ClientRMService clientService = mockRM.getClientRMService();
-
-    // listReservations
-    ReservationListRequest request = ReservationListRequest.newInstance(
-        queue, reservationId, startTime, endTime, includeResourceAllocations);
-    ReservationListResponse resRespInfo = clientService.listReservations(request);
-    ReservationListInfo resResponse =
-        new ReservationListInfo(resRespInfo, includeResourceAllocations);
-
-    return Response.status(Status.OK).entity(resResponse).build();
-  }
-
-  @Override
-  public Response createNewReservation(HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    ReservationId resId = ReservationId.newInstance(Time.now(), resCounter.incrementAndGet());
-    LOG.info("Allocated new reservationId: {}.", resId);
-
-    NewReservation reservationId = new NewReservation(resId.toString());
-    return Response.status(Status.OK).entity(reservationId).build();
-  }
-
-  @Override
-  public Response submitReservation(ReservationSubmissionRequestInfo resContext,
-      HttpServletRequest hsr) throws AuthorizationException, IOException, InterruptedException {
-
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    ReservationId reservationId = ReservationId.parseReservationId(resContext.getReservationId());
-    ReservationDefinitionInfo definitionInfo = resContext.getReservationDefinition();
-    ReservationDefinition definition =
-            RouterServerUtil.convertReservationDefinition(definitionInfo);
-    ReservationSubmissionRequest request = ReservationSubmissionRequest.newInstance(
-            definition, resContext.getQueue(), reservationId);
-    submitReservation(request);
-
-    LOG.info("Reservation submitted: {}.", reservationId);
-
-    SubClusterId subClusterId = getSubClusterId();
-    reservationMap.put(reservationId, subClusterId);
-
-    return Response.status(Status.ACCEPTED).build();
-  }
-
-  private void submitReservation(ReservationSubmissionRequest request) {
-    try {
-      // synchronize plan
-      ReservationSystem reservationSystem = mockRM.getReservationSystem();
-      reservationSystem.synchronizePlan(QUEUE_DEDICATED_FULL, true);
-      // Generate reserved resources
-      ClientRMService clientService = mockRM.getClientRMService();
-      clientService.submitReservation(request);
-    } catch (IOException | YarnException e) {
-      throw new RuntimeException(e);
-    }
-  }
-
-  @Override
-  public Response updateReservation(ReservationUpdateRequestInfo resContext,
-      HttpServletRequest hsr) throws AuthorizationException, IOException, InterruptedException {
-
-    if (resContext == null || resContext.getReservationId() == null ||
-        resContext.getReservationDefinition() == null) {
-      return Response.status(Status.BAD_REQUEST).build();
-    }
-
-    String resId = resContext.getReservationId();
-    ReservationId reservationId = ReservationId.parseReservationId(resId);
-
-    if (!reservationMap.containsKey(reservationId)) {
-      throw new NotFoundException("reservationId with id: " + reservationId + " not found");
-    }
-
-    // Generate reserved resources
-    updateReservation(resContext);
-
-    ReservationUpdateResponseInfo resRespInfo = new ReservationUpdateResponseInfo();
-    return Response.status(Status.OK).entity(resRespInfo).build();
-  }
-
-  private void updateReservation(ReservationUpdateRequestInfo resContext) throws IOException {
-
-    if (resContext == null) {
-      throw new BadRequestException("Input ReservationSubmissionContext should not be null");
-    }
-
-    ReservationDefinitionInfo resInfo = resContext.getReservationDefinition();
-    if (resInfo == null) {
-      throw new BadRequestException("Input ReservationDefinition should not be null");
-    }
-
-    ReservationRequestsInfo resReqsInfo = resInfo.getReservationRequests();
-    if (resReqsInfo == null || resReqsInfo.getReservationRequest() == null
-        || resReqsInfo.getReservationRequest().isEmpty()) {
-      throw new BadRequestException("The ReservationDefinition should " +
-          "contain at least one ReservationRequest");
-    }
-
-    if (resContext.getReservationId() == null) {
-      throw new BadRequestException("Update operations must specify an existing ReservationId");
-    }
-
-    ReservationRequestInterpreter[] values = ReservationRequestInterpreter.values();
-    ReservationRequestInterpreter requestInterpreter =
-        values[resReqsInfo.getReservationRequestsInterpreter()];
-    List<ReservationRequest> list = new ArrayList<>();
-
-    for (ReservationRequestInfo resReqInfo : resReqsInfo.getReservationRequest()) {
-      ResourceInfo rInfo = resReqInfo.getCapability();
-      Resource capability = Resource.newInstance(rInfo.getMemorySize(), rInfo.getvCores());
-      int numContainers = resReqInfo.getNumContainers();
-      int minConcurrency = resReqInfo.getMinConcurrency();
-      long duration = resReqInfo.getDuration();
-      ReservationRequest rr = ReservationRequest.newInstance(
-          capability, numContainers, minConcurrency, duration);
-      list.add(rr);
-    }
-
-    ReservationRequests reqs = ReservationRequests.newInstance(list, requestInterpreter);
-    ReservationDefinition rDef = ReservationDefinition.newInstance(
-        resInfo.getArrival(), resInfo.getDeadline(), reqs,
-        resInfo.getReservationName(), resInfo.getRecurrenceExpression(),
-        Priority.newInstance(resInfo.getPriority()));
-    ReservationUpdateRequest request = ReservationUpdateRequest.newInstance(
-        rDef, ReservationId.parseReservationId(resContext.getReservationId()));
-
-    ClientRMService clientService = mockRM.getClientRMService();
-    try {
-      clientService.updateReservation(request);
-    } catch (YarnException ex) {
-      throw new RuntimeException(ex);
-    }
-  }
-
-  @Override
-  public Response deleteReservation(ReservationDeleteRequestInfo resContext, HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    if (!isRunning) {
-      throw new RuntimeException("RM is stopped");
-    }
-
-    try {
-      String resId = resContext.getReservationId();
-      ReservationId reservationId = ReservationId.parseReservationId(resId);
-
-      if (!reservationMap.containsKey(reservationId)) {
-        throw new NotFoundException("reservationId with id: " + reservationId + " not found");
-      }
-
-      ReservationDeleteRequest reservationDeleteRequest =
-          ReservationDeleteRequest.newInstance(reservationId);
-      ClientRMService clientService = mockRM.getClientRMService();
-      clientService.deleteReservation(reservationDeleteRequest);
-
-      ReservationDeleteResponseInfo resRespInfo = new ReservationDeleteResponseInfo();
-      reservationMap.remove(reservationId);
-
-      return Response.status(Status.OK).entity(resRespInfo).build();
-    } catch (YarnException e) {
-      throw new RuntimeException(e);
-    }
-  }
-
-  @VisibleForTesting
-  public MockRM getMockRM() {
-    return mockRM;
-  }
-
-  @VisibleForTesting
-  public void setMockRM(MockRM mockResourceManager) {
-    this.mockRM = mockResourceManager;
-  }
-
-  @Override
-  public NodeLabelsInfo getRMNodeLabels(HttpServletRequest hsr) {
-
-    NodeLabelInfo nodeLabelInfo = new NodeLabelInfo();
-    nodeLabelInfo.setExclusivity(true);
-    nodeLabelInfo.setName("Test-Label");
-    nodeLabelInfo.setActiveNMs(10);
-    PartitionInfo partitionInfo = new PartitionInfo();
-
-    NodeLabelsInfo nodeLabelsInfo = new NodeLabelsInfo();
-    nodeLabelsInfo.getNodeLabelsInfo().add(nodeLabelInfo);
-
-    return nodeLabelsInfo;
-  }
-
-  private MockRM setupResourceManager() throws Exception {
-    DefaultMetricsSystem.setMiniClusterMode(true);
-
-    CapacitySchedulerConfiguration conf = new CapacitySchedulerConfiguration();
-
-    // Define default queue
-    conf.setCapacity(QUEUE_DEFAULT_FULL, 20);
-    // Define dedicated queues
-    conf.setQueues(CapacitySchedulerConfiguration.ROOT,
-        new String[] {QUEUE_DEFAULT,  QUEUE_DEDICATED});
-    conf.setCapacity(QUEUE_DEDICATED_FULL, 80);
-    conf.setReservable(QUEUE_DEDICATED_FULL, true);
-
-    conf.setClass(YarnConfiguration.RM_SCHEDULER, CapacityScheduler.class, ResourceScheduler.class);
-    conf.setBoolean(YarnConfiguration.RM_RESERVATION_SYSTEM_ENABLE, true);
-    MockRM rm = new MockRM(conf);
-    rm.start();
-    rm.registerNode("127.0.0.1:5678", 100*1024, 100);
-    return rm;
-  }
-
-  @Override
-  public RMQueueAclInfo checkUserAccessToQueue(String queue, String username,
-      String queueAclType, HttpServletRequest hsr) throws AuthorizationException {
-
-    ResourceManager mockResourceManager = mock(ResourceManager.class);
-    Configuration conf = new YarnConfiguration();
-
-    ResourceScheduler mockScheduler = new CapacityScheduler() {
-      @Override
-      public synchronized boolean checkAccess(UserGroupInformation callerUGI,
-          QueueACL acl, String queueName) {
-        if (acl == QueueACL.ADMINISTER_QUEUE) {
-          if (callerUGI.getUserName().equals("admin")) {
-            return true;
-          }
-        } else {
-          if (ImmutableSet.of("admin", "yarn").contains(callerUGI.getUserName())) {
-            return true;
-          }
-        }
-        return false;
-      }
-    };
-
-    when(mockResourceManager.getResourceScheduler()).thenReturn(mockScheduler);
-    MockRMWebServices webSvc = new MockRMWebServices(mockResourceManager, conf,
-        mock(HttpServletResponse.class));
-    return webSvc.checkUserAccessToQueue(queue, username, queueAclType, hsr);
-  }
-
-  class MockRMWebServices {
-
-    @Context
-    private HttpServletResponse httpServletResponse;
-    private ResourceManager resourceManager;
-
-    private void initForReadableEndpoints() {
-      // clear content type
-      httpServletResponse.setContentType(null);
-    }
-
-    MockRMWebServices(ResourceManager rm, Configuration conf, HttpServletResponse response) {
-      this.resourceManager = rm;
-      this.httpServletResponse = response;
-    }
-
-    private UserGroupInformation getCallerUserGroupInformation(
-        HttpServletRequest hsr, boolean usePrincipal) {
-
-      String remoteUser = hsr.getRemoteUser();
-
-      if (usePrincipal) {
-        Principal princ = hsr.getUserPrincipal();
-        remoteUser = princ == null ? null : princ.getName();
-      }
-
-      UserGroupInformation callerUGI = null;
-      if (remoteUser != null) {
-        callerUGI = UserGroupInformation.createRemoteUser(remoteUser);
-      }
-
-      return callerUGI;
-    }
-
-    public RMQueueAclInfo checkUserAccessToQueue(
-        String queue, String username, String queueAclType, HttpServletRequest hsr)
-        throws AuthorizationException {
-      initForReadableEndpoints();
-
-      // For the user who invokes this REST call, he/she should have admin access
-      // to the queue. Otherwise we will reject the call.
-      UserGroupInformation callerUGI = getCallerUserGroupInformation(hsr, true);
-      if (callerUGI != null && !this.resourceManager.getResourceScheduler().checkAccess(
-              callerUGI, QueueACL.ADMINISTER_QUEUE, queue)) {
-        throw new ForbiddenException(
-                "User=" + callerUGI.getUserName() + " doesn't haven access to queue="
-                        + queue + " so it cannot check ACLs for other users.");
-      }
-
-      // Create UGI for the to-be-checked user.
-      UserGroupInformation user = UserGroupInformation.createRemoteUser(username);
-      if (user == null) {
-        throw new ForbiddenException(
-           "Failed to retrieve UserGroupInformation for user=" + username);
-      }
-
-      // Check if the specified queue acl is valid.
-      QueueACL queueACL;
-      try {
-        queueACL = QueueACL.valueOf(queueAclType);
-      } catch (IllegalArgumentException e) {
-        throw new BadRequestException("Specified queueAclType=" + queueAclType
-            + " is not a valid type, valid queue acl types={"
-            + "SUBMIT_APPLICATIONS/ADMINISTER_QUEUE}");
-      }
-
-      if (!this.resourceManager.getResourceScheduler().checkAccess(user, queueACL, queue)) {
-        return new RMQueueAclInfo(false, user.getUserName(),
-            "User=" + username + " doesn't have access to queue=" + queue
-            + " with acl-type=" + queueAclType);
-      }
-
-      return new RMQueueAclInfo(true, user.getUserName(), "");
-    }
-
-    public String dumpSchedulerLogs(String time, HttpServletRequest hsr)
-        throws IOException {
-
-      int period = Integer.parseInt(time);
-      if (period <= 0) {
-        throw new BadRequestException("Period must be greater than 0");
-      }
-
-      return "Capacity scheduler logs are being created.";
-    }
-  }
-
-  @Override
-  public String dumpSchedulerLogs(String time, HttpServletRequest hsr) throws IOException {
-    ResourceManager mockResourceManager = mock(ResourceManager.class);
-    Configuration conf = new YarnConfiguration();
-    MockRMWebServices webSvc = new MockRMWebServices(mockResourceManager, conf,
-        mock(HttpServletResponse.class));
-    return webSvc.dumpSchedulerLogs(time, hsr);
-  }
-
-  public Response replaceLabelsOnNodes(NodeToLabelsEntryList newNodeToLabels,
-      HttpServletRequest hsr) throws IOException {
-    return super.replaceLabelsOnNodes(newNodeToLabels, hsr);
-  }
-
-  @Override
-  public Response replaceLabelsOnNode(Set<String> newNodeLabelsName,
-      HttpServletRequest hsr, String nodeId) throws Exception {
-    return super.replaceLabelsOnNode(newNodeLabelsName, hsr, nodeId);
-  }
-
-  public ActivitiesInfo getActivities(HttpServletRequest hsr, String nodeId, String groupBy) {
-    if (!EnumUtils.isValidEnum(RMWSConsts.ActivitiesGroupBy.class, groupBy.toUpperCase())) {
-      String errMessage = "Got invalid groupBy: " + groupBy + ", valid groupBy types: "
-          + Arrays.asList(RMWSConsts.ActivitiesGroupBy.values());
-      throw new IllegalArgumentException(errMessage);
-    }
-
-    SubClusterId subClusterId = getSubClusterId();
-    ActivitiesInfo activitiesInfo = mock(ActivitiesInfo.class);
-    Mockito.when(activitiesInfo.getNodeId()).thenReturn(nodeId);
-    Mockito.when(activitiesInfo.getTimestamp()).thenReturn(1673081972L);
-    Mockito.when(activitiesInfo.getDiagnostic()).thenReturn("Diagnostic:" + subClusterId.getId());
-
-    List<NodeAllocationInfo> allocationInfos = new ArrayList<>();
-    NodeAllocationInfo nodeAllocationInfo = mock(NodeAllocationInfo.class);
-    Mockito.when(nodeAllocationInfo.getPartition()).thenReturn("p" + subClusterId.getId());
-    Mockito.when(nodeAllocationInfo.getFinalAllocationState()).thenReturn("ALLOCATED");
-
-    allocationInfos.add(nodeAllocationInfo);
-    Mockito.when(activitiesInfo.getAllocations()).thenReturn(allocationInfos);
-    return activitiesInfo;
-  }
-
-  @Override
-  public BulkActivitiesInfo getBulkActivities(HttpServletRequest hsr,
-      String groupBy, int activitiesCount) {
-
-    if (activitiesCount <= 0) {
-      throw new IllegalArgumentException("activitiesCount needs to be greater than 0.");
-    }
-
-    if (!EnumUtils.isValidEnum(RMWSConsts.ActivitiesGroupBy.class, groupBy.toUpperCase())) {
-      String errMessage = "Got invalid groupBy: " + groupBy + ", valid groupBy types: "
-          + Arrays.asList(RMWSConsts.ActivitiesGroupBy.values());
-      throw new IllegalArgumentException(errMessage);
-    }
-
-    BulkActivitiesInfo bulkActivitiesInfo = new BulkActivitiesInfo();
-
-    for (int i = 0; i < activitiesCount; i++) {
-      SubClusterId subClusterId = getSubClusterId();
-      ActivitiesInfo activitiesInfo = mock(ActivitiesInfo.class);
-      Mockito.when(activitiesInfo.getNodeId()).thenReturn(subClusterId + "-nodeId-" + i);
-      Mockito.when(activitiesInfo.getTimestamp()).thenReturn(1673081972L);
-      Mockito.when(activitiesInfo.getDiagnostic()).thenReturn("Diagnostic:" + subClusterId.getId());
-
-      List<NodeAllocationInfo> allocationInfos = new ArrayList<>();
-      NodeAllocationInfo nodeAllocationInfo = mock(NodeAllocationInfo.class);
-      Mockito.when(nodeAllocationInfo.getPartition()).thenReturn("p" + subClusterId.getId());
-      Mockito.when(nodeAllocationInfo.getFinalAllocationState()).thenReturn("ALLOCATED");
-
-      allocationInfos.add(nodeAllocationInfo);
-      Mockito.when(activitiesInfo.getAllocations()).thenReturn(allocationInfos);
-      bulkActivitiesInfo.getActivities().add(activitiesInfo);
-    }
-
-    return bulkActivitiesInfo;
-  }
-
-  public SchedulerTypeInfo getSchedulerInfo() {
-    try {
-      ResourceManager resourceManager = CapacitySchedulerTestUtilities.createResourceManager();
-      CapacityScheduler cs = (CapacityScheduler) resourceManager.getResourceScheduler();
-      CSQueue root = cs.getRootQueue();
-      SchedulerInfo schedulerInfo = new CapacitySchedulerInfo(root, cs);
-      return new SchedulerTypeInfo(schedulerInfo);
-    } catch (Exception e) {
-      throw new RuntimeException(e);
-    }
-  }
-
-  @Override
-  public Response addToClusterNodeLabels(NodeLabelsInfo newNodeLabels, HttpServletRequest hsr)
-      throws Exception {
-    List<NodeLabelInfo> nodeLabelInfoList = newNodeLabels.getNodeLabelsInfo();
-    NodeLabelInfo nodeLabelInfo = nodeLabelInfoList.get(0);
-    String nodeLabelName = nodeLabelInfo.getName();
-
-    // If nodeLabelName is ALL, we let all subclusters pass
-    if (StringUtils.equals("ALL", nodeLabelName)) {
-      return Response.status(Status.OK).build();
-    } else if (StringUtils.equals("A0", nodeLabelName)) {
-      SubClusterId subClusterId = getSubClusterId();
-      String id = subClusterId.getId();
-      if (StringUtils.contains("A0", id)) {
-        return Response.status(Status.OK).build();
-      } else {
-        return Response.status(Status.BAD_REQUEST).entity(null).build();
-      }
-    }
-    throw new YarnException("addToClusterNodeLabels Error");
-  }
-
-  @Override
-  public Response removeFromClusterNodeLabels(Set<String> oldNodeLabels, HttpServletRequest hsr)
-      throws Exception {
-    // If oldNodeLabels contains ALL, we let all subclusters pass
-    if (oldNodeLabels.contains("ALL")) {
-      return Response.status(Status.OK).build();
-    } else if (oldNodeLabels.contains("A0")) {
-      SubClusterId subClusterId = getSubClusterId();
-      String id = subClusterId.getId();
-      if (StringUtils.contains("A0", id)) {
-        return Response.status(Status.OK).build();
-      } else {
-        return Response.status(Status.BAD_REQUEST).entity(null).build();
-      }
-    }
-    throw new YarnException("removeFromClusterNodeLabels Error");
-  }
-
-  @Override
-  public Response updateSchedulerConfiguration(SchedConfUpdateInfo mutationInfo,
-      HttpServletRequest req) throws AuthorizationException, InterruptedException {
-    RMContext rmContext = mockRM.getRMContext();
-    MutableCSConfigurationProvider provider = new MutableCSConfigurationProvider(rmContext);
-    try {
-      Configuration conf = new Configuration();
-      conf.set(YarnConfiguration.SCHEDULER_CONFIGURATION_STORE_CLASS,
-          YarnConfiguration.MEMORY_CONFIGURATION_STORE);
-      provider.init(conf);
-      provider.logAndApplyMutation(UserGroupInformation.getCurrentUser(), mutationInfo);
-    } catch (Exception e) {
-      throw new RuntimeException(e);
-    }
-    return Response.status(Status.OK).
-        entity("Configuration change successfully applied.").build();
-  }
-
-  @Override
-  public Response getSchedulerConfiguration(HttpServletRequest req) throws AuthorizationException {
-    return Response.status(Status.OK).entity(new ConfInfo(mockRM.getConfig()))
-        .build();
-  }
-
-  public ClusterInfo getClusterInfo() {
-    ClusterInfo clusterInfo = new ClusterInfo(mockRM);
-    return clusterInfo;
-  }
-
-  @Override
-  public ClusterUserInfo getClusterUserInfo(HttpServletRequest hsr) {
-    String remoteUser = hsr.getRemoteUser();
-    UserGroupInformation callerUGI = UserGroupInformation.createRemoteUser(remoteUser);
-    return new ClusterUserInfo(mockRM, callerUGI);
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/MockRESTRequestInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/MockRESTRequestInterceptor.java
deleted file mode 100644
index a09199b9e85..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/MockRESTRequestInterceptor.java
+++ /dev/null
@@ -1,394 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import java.io.IOException;
-import java.util.Set;
-
-import javax.servlet.http.HttpServletRequest;
-import javax.servlet.http.HttpServletResponse;
-import javax.ws.rs.core.Response;
-import javax.ws.rs.core.Response.Status;
-
-import org.apache.hadoop.security.authorize.AuthorizationException;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationStatisticsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterUserInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LabelsToNodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntryList;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.RMQueueAclInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceOptionInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.BulkActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerTypeInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.AppAttemptInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainerInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainersInfo;
-import org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo;
-
-/**
- * This class mocks the RESTRequestInterceptor.
- */
-public class MockRESTRequestInterceptor extends AbstractRESTRequestInterceptor {
-
-  @Override
-  public void setNextInterceptor(RESTRequestInterceptor next) {
-    throw new YarnRuntimeException(
-        "setNextInterceptor is being called on MockRESTRequestInterceptor,"
-            + "which should be the last one in the chain. "
-            + "Check if the interceptor pipeline configuration is correct");
-  }
-
-  @Override
-  public ClusterInfo get() {
-    return new ClusterInfo();
-  }
-
-  @Override
-  public ClusterInfo getClusterInfo() {
-    return new ClusterInfo();
-  }
-
-  @Override
-  public ClusterUserInfo getClusterUserInfo(HttpServletRequest hsr) {
-    return new ClusterUserInfo();
-  }
-
-  @Override
-  public ClusterMetricsInfo getClusterMetricsInfo() {
-    return new ClusterMetricsInfo();
-  }
-
-  @Override
-  public SchedulerTypeInfo getSchedulerInfo() {
-    return new SchedulerTypeInfo();
-  }
-
-  @Override
-  public String dumpSchedulerLogs(String time, HttpServletRequest hsr)
-      throws IOException {
-    return "Done";
-  }
-
-  @Override
-  public NodesInfo getNodes(String states) {
-    return new NodesInfo();
-  }
-
-  @Override
-  public NodeInfo getNode(String nodeId) {
-    return new NodeInfo();
-  }
-
-  @Override
-  public ResourceInfo updateNodeResource(HttpServletRequest hsr, String nodeId,
-      ResourceOptionInfo resourceOption) throws AuthorizationException {
-    return new ResourceInfo();
-  }
-
-  @SuppressWarnings("checkstyle:parameternumber")
-  @Override
-  public AppsInfo getApps(HttpServletRequest hsr, String stateQuery,
-      Set<String> statesQuery, String finalStatusQuery, String userQuery,
-      String queueQuery, String count, String startedBegin, String startedEnd,
-      String finishBegin, String finishEnd, Set<String> applicationTypes,
-      Set<String> applicationTags, String name, Set<String> unselectedFields) {
-    return new AppsInfo();
-  }
-
-  @Override
-  public ActivitiesInfo getActivities(HttpServletRequest hsr, String nodeId,
-      String groupBy) {
-    return new ActivitiesInfo();
-  }
-
-  @Override
-  public BulkActivitiesInfo getBulkActivities(HttpServletRequest hsr,
-       String groupBy, int activitiesCount) throws InterruptedException{
-    return new BulkActivitiesInfo();
-  }
-
-  @Override
-  public AppActivitiesInfo getAppActivities(HttpServletRequest hsr,
-      String appId, String time, Set<String> requestPriorities,
-      Set<String> allocationRequestIds, String groupBy, String limit,
-      Set<String> actions, boolean summarize) {
-    return new AppActivitiesInfo();
-  }
-
-  @Override
-  public ApplicationStatisticsInfo getAppStatistics(HttpServletRequest hsr,
-      Set<String> stateQueries, Set<String> typeQueries) {
-    return new ApplicationStatisticsInfo();
-  }
-
-  @Override
-  public AppInfo getApp(HttpServletRequest hsr, String appId,
-      Set<String> unselectedFields) {
-    return new AppInfo();
-  }
-
-  @Override
-  public AppState getAppState(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-    return new AppState();
-  }
-
-  @Override
-  public Response updateAppState(AppState targetState, HttpServletRequest hsr,
-      String appId) throws AuthorizationException, YarnException,
-      InterruptedException, IOException {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public NodeToLabelsInfo getNodeToLabels(HttpServletRequest hsr)
-      throws IOException {
-    return new NodeToLabelsInfo();
-  }
-
-  @Override
-  public NodeLabelsInfo getRMNodeLabels(HttpServletRequest hsr) throws IOException {
-    return new NodeLabelsInfo();
-  }
-
-  @Override
-  public LabelsToNodesInfo getLabelsToNodes(Set<String> labels)
-      throws IOException {
-    return new LabelsToNodesInfo();
-  }
-
-  @Override
-  public Response replaceLabelsOnNodes(NodeToLabelsEntryList newNodeToLabels,
-      HttpServletRequest hsr) throws Exception {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public Response replaceLabelsOnNode(Set<String> newNodeLabelsName,
-      HttpServletRequest hsr, String nodeId) throws Exception {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public NodeLabelsInfo getClusterNodeLabels(HttpServletRequest hsr)
-      throws IOException {
-    return new NodeLabelsInfo();
-  }
-
-  @Override
-  public Response addToClusterNodeLabels(NodeLabelsInfo newNodeLabels,
-      HttpServletRequest hsr) throws Exception {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public Response removeFromClusterNodeLabels(Set<String> oldNodeLabels,
-      HttpServletRequest hsr) throws Exception {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public NodeLabelsInfo getLabelsOnNode(HttpServletRequest hsr, String nodeId)
-      throws IOException {
-    return new NodeLabelsInfo();
-  }
-
-  @Override
-  public AppPriority getAppPriority(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-    return new AppPriority();
-  }
-
-  @Override
-  public Response updateApplicationPriority(AppPriority targetPriority,
-      HttpServletRequest hsr, String appId) throws AuthorizationException,
-      YarnException, InterruptedException, IOException {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public AppQueue getAppQueue(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-    return new AppQueue();
-  }
-
-  @Override
-  public Response updateAppQueue(AppQueue targetQueue, HttpServletRequest hsr,
-      String appId) throws AuthorizationException, YarnException,
-      InterruptedException, IOException {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public Response createNewApplication(HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public Response submitApplication(ApplicationSubmissionContextInfo newApp,
-      HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public Response postDelegationToken(DelegationToken tokenData,
-      HttpServletRequest hsr) throws AuthorizationException, IOException,
-      InterruptedException, Exception {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public Response postDelegationTokenExpiration(HttpServletRequest hsr)
-      throws AuthorizationException, IOException, Exception {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public Response cancelDelegationToken(HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException,
-      Exception {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public Response createNewReservation(HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public Response submitReservation(ReservationSubmissionRequestInfo resContext,
-      HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public Response updateReservation(ReservationUpdateRequestInfo resContext,
-      HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public Response deleteReservation(ReservationDeleteRequestInfo resContext,
-      HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public Response listReservation(String queue, String reservationId,
-      long startTime, long endTime, boolean includeResourceAllocations,
-      HttpServletRequest hsr) throws Exception {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public AppTimeoutInfo getAppTimeout(HttpServletRequest hsr, String appId,
-      String type) throws AuthorizationException {
-    return new AppTimeoutInfo();
-  }
-
-  @Override
-  public AppTimeoutsInfo getAppTimeouts(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-    return new AppTimeoutsInfo();
-  }
-
-  @Override
-  public Response updateApplicationTimeout(AppTimeoutInfo appTimeout,
-      HttpServletRequest hsr, String appId) throws AuthorizationException,
-      YarnException, InterruptedException, IOException {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public AppAttemptsInfo getAppAttempts(HttpServletRequest hsr, String appId) {
-    return new AppAttemptsInfo();
-  }
-
-  @Override
-  public RMQueueAclInfo checkUserAccessToQueue(String queue, String username,
-      String queueAclType, HttpServletRequest hsr) {
-    return new RMQueueAclInfo(true, username, "");
-  }
-
-  @Override
-  public AppAttemptInfo getAppAttempt(HttpServletRequest req,
-      HttpServletResponse res, String appId, String appAttemptId) {
-    return new AppAttemptInfo();
-  }
-
-  @Override
-  public ContainersInfo getContainers(HttpServletRequest req,
-      HttpServletResponse res, String appId, String appAttemptId) {
-    return new ContainersInfo();
-  }
-
-  @Override
-  public ContainerInfo getContainer(HttpServletRequest req,
-      HttpServletResponse res, String appId, String appAttemptId,
-      String containerId) {
-    return new ContainerInfo();
-  }
-
-  @Override
-  public Response signalToContainer(String containerId, String command,
-      HttpServletRequest req) {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public Response updateSchedulerConfiguration(SchedConfUpdateInfo mutationInfo,
-      HttpServletRequest hsr) throws AuthorizationException, InterruptedException {
-    return Response.status(Status.OK).build();
-  }
-
-  @Override
-  public Response getSchedulerConfiguration(HttpServletRequest hsr)
-      throws AuthorizationException {
-    return Response.status(Status.OK).build();
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/MockRouter.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/MockRouter.java
deleted file mode 100644
index 95b9e13936f..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/MockRouter.java
+++ /dev/null
@@ -1,99 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import org.apache.commons.io.FileUtils;
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.util.Time;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.federation.store.FederationStateStore;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterRegisterRequest;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterState;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.router.Router;
-
-import java.io.File;
-import java.io.IOException;
-import java.nio.charset.StandardCharsets;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
-public class MockRouter extends Router {
-
-  private FederationStateStoreFacade facade;
-
-  public MockRouter(Configuration configuration)
-      throws InterruptedException, YarnException, IOException {
-    this.setConfig(configuration);
-
-    boolean isEnabled = configuration.getBoolean(
-        YarnConfiguration.FEDERATION_ENABLED,
-        YarnConfiguration.DEFAULT_FEDERATION_ENABLED);
-
-    if (isEnabled) {
-      facade = FederationStateStoreFacade.getInstance(configuration);
-      initTestFederationSubCluster();
-    }
-  }
-
-  public void initTestFederationSubCluster()
-      throws IOException, InterruptedException, YarnException {
-
-    // Initialize subcluster information
-    String scAmRMAddress = "5.6.7.8:5";
-    String scClientRMAddress = "5.6.7.8:6";
-    String scRmAdminAddress = "5.6.7.8:7";
-    String scWebAppAddress = "127.0.0.1:8080";
-
-    // Initialize subcluster capability
-    String[] capabilityPathItems = new String[] {".", "target", "test-classes", "capability"};
-    String capabilityPath = StringUtils.join(capabilityPathItems, File.separator);
-    String capabilityJson =
-        FileUtils.readFileToString(new File(capabilityPath), StandardCharsets.UTF_8);
-
-    // capability json needs to remove asflicense
-    String regex = "\"___asflicense__.*\\n(.*,\\n){1,15}.*\\n.*";
-    Pattern p = Pattern.compile(regex);
-    Matcher m = p.matcher(capabilityJson);
-    capabilityJson = m.replaceAll("").trim();
-
-    // Initialize subcluster sc1
-    SubClusterInfo sc1 =
-        SubClusterInfo.newInstance(SubClusterId.newInstance("SC-1"),
-        scAmRMAddress, scClientRMAddress, scRmAdminAddress, scWebAppAddress,
-        SubClusterState.SC_RUNNING, Time.now(), capabilityJson);
-    Thread.sleep(5000);
-    sc1.setLastHeartBeat(Time.now());
-
-    // Initialize subcluster sc2
-    SubClusterInfo sc2 =
-        SubClusterInfo.newInstance(SubClusterId.newInstance("SC-2"),
-        scAmRMAddress, scClientRMAddress, scRmAdminAddress, scWebAppAddress,
-        SubClusterState.SC_RUNNING, Time.now(), capabilityJson);
-    Thread.sleep(5000);
-    sc2.setLastHeartBeat(Time.now());
-
-    FederationStateStore stateStore = facade.getStateStore();
-    stateStore.registerSubCluster(SubClusterRegisterRequest.newInstance(sc1));
-    stateStore.registerSubCluster(SubClusterRegisterRequest.newInstance(sc2));
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/PassThroughRESTRequestInterceptor.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/PassThroughRESTRequestInterceptor.java
deleted file mode 100644
index 1bffd40db3c..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/PassThroughRESTRequestInterceptor.java
+++ /dev/null
@@ -1,401 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import java.io.IOException;
-import java.util.Set;
-
-import javax.servlet.http.HttpServletRequest;
-import javax.servlet.http.HttpServletResponse;
-import javax.ws.rs.core.Response;
-
-import org.apache.hadoop.security.authorize.AuthorizationException;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationStatisticsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterUserInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LabelsToNodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntryList;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.RMQueueAclInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceOptionInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.BulkActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerTypeInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.AppAttemptInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainerInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainersInfo;
-import org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo;
-
-/**
- * Mock interceptor that does not do anything other than forwarding it to the
- * next interceptor in the chain.
- */
-public class PassThroughRESTRequestInterceptor
-    extends AbstractRESTRequestInterceptor {
-
-  @Override
-  public AppAttemptsInfo getAppAttempts(HttpServletRequest hsr, String appId) {
-    return getNextInterceptor().getAppAttempts(hsr, appId);
-  }
-
-  @Override
-  public RMQueueAclInfo checkUserAccessToQueue(String queue, String username,
-      String queueAclType, HttpServletRequest hsr)
-      throws AuthorizationException {
-    return getNextInterceptor().checkUserAccessToQueue(queue, username,
-        queueAclType, hsr);
-  }
-
-  @Override
-  public AppAttemptInfo getAppAttempt(HttpServletRequest req,
-      HttpServletResponse res, String appId, String appAttemptId) {
-    return getNextInterceptor().getAppAttempt(req, res, appId, appAttemptId);
-  }
-
-  @Override
-  public ContainersInfo getContainers(HttpServletRequest req,
-      HttpServletResponse res, String appId, String appAttemptId) {
-    return getNextInterceptor().getContainers(req, res, appId, appAttemptId);
-  }
-
-  @Override
-  public ContainerInfo getContainer(HttpServletRequest req,
-      HttpServletResponse res, String appId, String appAttemptId,
-      String containerId) {
-    return getNextInterceptor().getContainer(req, res, appId, appAttemptId,
-        containerId);
-  }
-
-  @Override
-  public ClusterInfo get() {
-    return getNextInterceptor().get();
-  }
-
-  @Override
-  public ClusterInfo getClusterInfo() {
-    return getNextInterceptor().getClusterInfo();
-  }
-
-  @Override
-  public ClusterUserInfo getClusterUserInfo(HttpServletRequest hsr) {
-    return getNextInterceptor().getClusterUserInfo(hsr);
-  }
-
-  @Override
-  public ClusterMetricsInfo getClusterMetricsInfo() {
-    return getNextInterceptor().getClusterMetricsInfo();
-  }
-
-  @Override
-  public SchedulerTypeInfo getSchedulerInfo() {
-    return getNextInterceptor().getSchedulerInfo();
-  }
-
-  @Override
-  public String dumpSchedulerLogs(String time, HttpServletRequest hsr)
-      throws IOException {
-    return getNextInterceptor().dumpSchedulerLogs(time, hsr);
-  }
-
-  @Override
-  public NodesInfo getNodes(String states) {
-    return getNextInterceptor().getNodes(states);
-  }
-
-  @Override
-  public NodeInfo getNode(String nodeId) {
-    return getNextInterceptor().getNode(nodeId);
-  }
-
-  @Override
-  public ResourceInfo updateNodeResource(HttpServletRequest hsr, String nodeId,
-      ResourceOptionInfo resourceOption) throws AuthorizationException {
-    return getNextInterceptor().updateNodeResource(
-        hsr, nodeId, resourceOption);
-  }
-
-  @Override
-  public AppsInfo getApps(HttpServletRequest hsr, String stateQuery,
-      Set<String> statesQuery, String finalStatusQuery, String userQuery,
-      String queueQuery, String count, String startedBegin, String startedEnd,
-      String finishBegin, String finishEnd, Set<String> applicationTypes,
-      Set<String> applicationTags, String name, Set<String> unselectedFields) {
-    return getNextInterceptor().getApps(hsr, stateQuery, statesQuery,
-        finalStatusQuery, userQuery, queueQuery, count, startedBegin,
-        startedEnd, finishBegin, finishEnd, applicationTypes, applicationTags,
-        name, unselectedFields);
-  }
-
-  @Override
-  public ActivitiesInfo getActivities(HttpServletRequest hsr, String nodeId,
-      String groupBy) {
-    return getNextInterceptor().getActivities(hsr, nodeId, groupBy);
-  }
-
-  @Override
-  public BulkActivitiesInfo getBulkActivities(HttpServletRequest hsr,
-      String groupBy, int activitiesCount) throws InterruptedException {
-    return getNextInterceptor().getBulkActivities(hsr, groupBy,
-        activitiesCount);
-  }
-
-  @Override
-  public AppActivitiesInfo getAppActivities(HttpServletRequest hsr,
-      String appId, String time, Set<String> requestPriorities,
-      Set<String> allocationRequestIds, String groupBy, String limit,
-      Set<String> actions, boolean summarize) {
-    return getNextInterceptor().getAppActivities(hsr, appId, time,
-        requestPriorities, allocationRequestIds, groupBy, limit,
-        actions, summarize);
-  }
-
-  @Override
-  public ApplicationStatisticsInfo getAppStatistics(HttpServletRequest hsr,
-      Set<String> stateQueries, Set<String> typeQueries) {
-    return getNextInterceptor().getAppStatistics(hsr, stateQueries,
-        typeQueries);
-  }
-
-  @Override
-  public AppInfo getApp(HttpServletRequest hsr, String appId,
-      Set<String> unselectedFields) {
-    return getNextInterceptor().getApp(hsr, appId, unselectedFields);
-  }
-
-  @Override
-  public AppState getAppState(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-    return getNextInterceptor().getAppState(hsr, appId);
-  }
-
-  @Override
-  public Response updateAppState(AppState targetState, HttpServletRequest hsr,
-      String appId) throws AuthorizationException, YarnException,
-      InterruptedException, IOException {
-    return getNextInterceptor().updateAppState(targetState, hsr, appId);
-  }
-
-  @Override
-  public NodeToLabelsInfo getNodeToLabels(HttpServletRequest hsr)
-      throws IOException {
-    return getNextInterceptor().getNodeToLabels(hsr);
-  }
-
-  @Override
-  public NodeLabelsInfo getRMNodeLabels(HttpServletRequest hsr) throws IOException {
-    return getNextInterceptor().getRMNodeLabels(hsr);
-  }
-
-  @Override
-  public LabelsToNodesInfo getLabelsToNodes(Set<String> labels)
-      throws IOException {
-    return getNextInterceptor().getLabelsToNodes(labels);
-  }
-
-  @Override
-  public Response replaceLabelsOnNodes(NodeToLabelsEntryList newNodeToLabels,
-      HttpServletRequest hsr) throws Exception {
-    return getNextInterceptor().replaceLabelsOnNodes(newNodeToLabels, hsr);
-  }
-
-  @Override
-  public Response replaceLabelsOnNode(Set<String> newNodeLabelsName,
-      HttpServletRequest hsr, String nodeId) throws Exception {
-    return getNextInterceptor().replaceLabelsOnNode(newNodeLabelsName, hsr,
-        nodeId);
-  }
-
-  @Override
-  public NodeLabelsInfo getClusterNodeLabels(HttpServletRequest hsr)
-      throws IOException {
-    return getNextInterceptor().getClusterNodeLabels(hsr);
-  }
-
-  @Override
-  public Response addToClusterNodeLabels(NodeLabelsInfo newNodeLabels,
-      HttpServletRequest hsr) throws Exception {
-    return getNextInterceptor().addToClusterNodeLabels(newNodeLabels, hsr);
-  }
-
-  @Override
-  public Response removeFromClusterNodeLabels(Set<String> oldNodeLabels,
-      HttpServletRequest hsr) throws Exception {
-    return getNextInterceptor().removeFromClusterNodeLabels(oldNodeLabels, hsr);
-  }
-
-  @Override
-  public NodeLabelsInfo getLabelsOnNode(HttpServletRequest hsr, String nodeId)
-      throws IOException {
-    return getNextInterceptor().getLabelsOnNode(hsr, nodeId);
-  }
-
-  @Override
-  public AppPriority getAppPriority(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-    return getNextInterceptor().getAppPriority(hsr, appId);
-  }
-
-  @Override
-  public Response updateApplicationPriority(AppPriority targetPriority,
-      HttpServletRequest hsr, String appId) throws AuthorizationException,
-      YarnException, InterruptedException, IOException {
-    return getNextInterceptor().updateApplicationPriority(targetPriority, hsr,
-        appId);
-  }
-
-  @Override
-  public AppQueue getAppQueue(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-    return getNextInterceptor().getAppQueue(hsr, appId);
-  }
-
-  @Override
-  public Response updateAppQueue(AppQueue targetQueue, HttpServletRequest hsr,
-      String appId) throws AuthorizationException, YarnException,
-      InterruptedException, IOException {
-    return getNextInterceptor().updateAppQueue(targetQueue, hsr, appId);
-  }
-
-  @Override
-  public Response createNewApplication(HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    return getNextInterceptor().createNewApplication(hsr);
-  }
-
-  @Override
-  public Response submitApplication(ApplicationSubmissionContextInfo newApp,
-      HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    return getNextInterceptor().submitApplication(newApp, hsr);
-  }
-
-  @Override
-  public Response postDelegationToken(DelegationToken tokenData,
-      HttpServletRequest hsr) throws AuthorizationException, IOException,
-      InterruptedException, Exception {
-    return getNextInterceptor().postDelegationToken(tokenData, hsr);
-  }
-
-  @Override
-  public Response postDelegationTokenExpiration(HttpServletRequest hsr)
-      throws AuthorizationException, IOException, Exception {
-    return getNextInterceptor().postDelegationTokenExpiration(hsr);
-  }
-
-  @Override
-  public Response cancelDelegationToken(HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException,
-      Exception {
-    return getNextInterceptor().cancelDelegationToken(hsr);
-  }
-
-  @Override
-  public Response createNewReservation(HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    return getNextInterceptor().createNewReservation(hsr);
-  }
-
-  @Override
-  public Response submitReservation(ReservationSubmissionRequestInfo resContext,
-      HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    return getNextInterceptor().submitReservation(resContext, hsr);
-  }
-
-  @Override
-  public Response updateReservation(ReservationUpdateRequestInfo resContext,
-      HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    return getNextInterceptor().updateReservation(resContext, hsr);
-  }
-
-  @Override
-  public Response deleteReservation(ReservationDeleteRequestInfo resContext,
-      HttpServletRequest hsr)
-      throws AuthorizationException, IOException, InterruptedException {
-    return getNextInterceptor().deleteReservation(resContext, hsr);
-  }
-
-  @Override
-  public Response listReservation(String queue, String reservationId,
-      long startTime, long endTime, boolean includeResourceAllocations,
-      HttpServletRequest hsr) throws Exception {
-    return getNextInterceptor().listReservation(queue, reservationId, startTime,
-        endTime, includeResourceAllocations, hsr);
-  }
-
-  @Override
-  public AppTimeoutInfo getAppTimeout(HttpServletRequest hsr, String appId,
-      String type) throws AuthorizationException {
-    return getNextInterceptor().getAppTimeout(hsr, appId, type);
-  }
-
-  @Override
-  public AppTimeoutsInfo getAppTimeouts(HttpServletRequest hsr, String appId)
-      throws AuthorizationException {
-    return getNextInterceptor().getAppTimeouts(hsr, appId);
-  }
-
-  @Override
-  public Response updateApplicationTimeout(AppTimeoutInfo appTimeout,
-      HttpServletRequest hsr, String appId) throws AuthorizationException,
-      YarnException, InterruptedException, IOException {
-    return getNextInterceptor().updateApplicationTimeout(appTimeout, hsr,
-        appId);
-  }
-
-  @Override
-  public Response signalToContainer(String containerId,
-      String command, HttpServletRequest req) throws AuthorizationException {
-    return getNextInterceptor().signalToContainer(containerId, command, req);
-  }
-
-  @Override
-  public Response updateSchedulerConfiguration(SchedConfUpdateInfo mutationInfo,
-      HttpServletRequest hsr)
-      throws AuthorizationException, InterruptedException {
-    return getNextInterceptor().updateSchedulerConfiguration(mutationInfo, hsr);
-  }
-
-  @Override
-  public Response getSchedulerConfiguration(HttpServletRequest hsr)
-      throws AuthorizationException {
-    return getNextInterceptor().getSchedulerConfiguration(hsr);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestFederationInterceptorREST.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestFederationInterceptorREST.java
deleted file mode 100644
index 9bde2a3dcd1..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestFederationInterceptorREST.java
+++ /dev/null
@@ -1,2267 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import java.io.IOException;
-import java.security.Principal;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.HashMap;
-import java.util.Map;
-import java.util.Set;
-import java.util.Arrays;
-import java.util.HashSet;
-import java.util.Collections;
-import java.util.stream.Collectors;
-import java.util.concurrent.TimeUnit;
-
-import javax.servlet.http.HttpServletRequest;
-import javax.ws.rs.core.Response;
-import javax.ws.rs.core.Response.Status;
-
-import org.apache.commons.lang3.StringUtils;
-import org.apache.hadoop.security.authorize.AuthorizationException;
-import org.apache.hadoop.test.LambdaTestUtils;
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.http.HttpConfig;
-import org.apache.hadoop.util.Lists;
-import org.apache.hadoop.util.Sets;
-import org.apache.hadoop.util.Time;
-import org.apache.hadoop.yarn.api.protocolrecords.ReservationSubmissionRequest;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.ReservationId;
-import org.apache.hadoop.yarn.api.records.Resource;
-import org.apache.hadoop.yarn.api.records.ResourceOption;
-import org.apache.hadoop.yarn.api.records.ApplicationAttemptId;
-import org.apache.hadoop.yarn.api.records.NodeLabel;
-import org.apache.hadoop.yarn.api.records.ApplicationTimeoutType;
-import org.apache.hadoop.yarn.api.records.YarnApplicationState;
-import org.apache.hadoop.yarn.api.records.ReservationDefinition;
-import org.apache.hadoop.yarn.api.records.Priority;
-import org.apache.hadoop.yarn.api.records.ReservationRequest;
-import org.apache.hadoop.yarn.api.records.ReservationRequests;
-import org.apache.hadoop.yarn.api.records.ReservationRequestInterpreter;
-import org.apache.hadoop.yarn.api.records.ContainerId;
-import org.apache.hadoop.yarn.api.records.QueueACL;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-import org.apache.hadoop.yarn.server.federation.policies.manager.UniformBroadcastPolicyManager;
-import org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterRegisterRequest;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterState;
-import org.apache.hadoop.yarn.server.federation.store.records.GetApplicationHomeSubClusterRequest;
-import org.apache.hadoop.yarn.server.federation.store.records.GetApplicationHomeSubClusterResponse;
-import org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreTestUtil;
-import org.apache.hadoop.yarn.server.resourcemanager.MockRM;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterUserInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NewApplication;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceOptionInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LabelsToNodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.StatisticsItemInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationListInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.RMQueueAclInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.DelegationToken;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntry;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntryList;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.NodeIDsInfo;
-import org.apache.hadoop.yarn.server.router.clientrm.RouterClientRMService;
-import org.apache.hadoop.yarn.server.router.clientrm.RouterClientRMService.RequestInterceptorChainWrapper;
-import org.apache.hadoop.yarn.server.router.clientrm.TestableFederationClientInterceptor;
-import org.apache.hadoop.yarn.server.router.security.RouterDelegationTokenSecretManager;
-import org.apache.hadoop.yarn.server.router.webapp.cache.RouterAppInfoCacheKey;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationStatisticsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDefinitionInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerTypeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.CapacitySchedulerInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.CapacitySchedulerQueueInfoList;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.CapacitySchedulerQueueInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NewReservation;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeAllocationInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.BulkActivitiesInfo;
-import org.apache.hadoop.yarn.server.router.webapp.dao.FederationConfInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainerInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainersInfo;
-import org.apache.hadoop.yarn.server.router.webapp.dao.FederationRMQueueAclInfo;
-import org.apache.hadoop.yarn.server.router.webapp.dao.FederationBulkActivitiesInfo;
-import org.apache.hadoop.yarn.server.router.webapp.dao.FederationSchedulerTypeInfo;
-import org.apache.hadoop.yarn.server.router.webapp.dao.FederationClusterInfo;
-import org.apache.hadoop.yarn.server.router.webapp.dao.FederationClusterUserInfo;
-import org.apache.hadoop.yarn.util.LRUCacheHashMap;
-import org.apache.hadoop.yarn.util.MonotonicClock;
-import org.apache.hadoop.yarn.util.Times;
-import org.apache.hadoop.yarn.util.YarnVersionInfo;
-import org.apache.hadoop.yarn.webapp.BadRequestException;
-import org.apache.hadoop.yarn.webapp.dao.ConfInfo;
-import org.apache.hadoop.yarn.webapp.dao.QueueConfigInfo;
-import org.apache.hadoop.yarn.webapp.dao.SchedConfUpdateInfo;
-import org.apache.hadoop.yarn.webapp.util.WebAppUtils;
-import org.junit.Assert;
-import org.junit.Test;
-
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.RM_DELEGATION_KEY_UPDATE_INTERVAL_DEFAULT;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.RM_DELEGATION_KEY_UPDATE_INTERVAL_KEY;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.RM_DELEGATION_TOKEN_MAX_LIFETIME_DEFAULT;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.RM_DELEGATION_TOKEN_MAX_LIFETIME_KEY;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.RM_DELEGATION_TOKEN_RENEW_INTERVAL_DEFAULT;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.RM_DELEGATION_TOKEN_RENEW_INTERVAL_KEY;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.RM_DELEGATION_TOKEN_REMOVE_SCAN_INTERVAL_DEFAULT;
-import static org.apache.hadoop.yarn.conf.YarnConfiguration.RM_DELEGATION_TOKEN_REMOVE_SCAN_INTERVAL_KEY;
-
-import static org.apache.hadoop.yarn.server.router.webapp.MockDefaultRequestInterceptorREST.DURATION;
-import static org.apache.hadoop.yarn.server.router.webapp.MockDefaultRequestInterceptorREST.NUM_CONTAINERS;
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.when;
-
-/**
- * Extends the {@code BaseRouterClientRMTest} and overrides methods in order to
- * use the {@code RouterClientRMService} pipeline test cases for testing the
- * {@code FederationInterceptor} class. The tests for
- * {@code RouterClientRMService} has been written cleverly so that it can be
- * reused to validate different request interceptor chains.
- */
-public class TestFederationInterceptorREST extends BaseRouterWebServicesTest {
-
-  private final static int NUM_SUBCLUSTER = 4;
-  private static final int BAD_REQUEST = 400;
-  private static final int ACCEPTED = 202;
-  private static final String TEST_USER = "test-user";
-  private static final int OK = 200;
-  private static String user = "test-user";
-  private TestableFederationInterceptorREST interceptor;
-  private MemoryFederationStateStore stateStore;
-  private FederationStateStoreTestUtil stateStoreUtil;
-  private List<SubClusterId> subClusters;
-  private static final String TEST_RENEWER = "test-renewer";
-
-  public void setUp() throws YarnException, IOException {
-
-    super.setUpConfig();
-    interceptor = new TestableFederationInterceptorREST();
-
-    stateStore = new MemoryFederationStateStore();
-    stateStore.init(this.getConf());
-    FederationStateStoreFacade.getInstance(this.getConf()).reinitialize(stateStore,
-        this.getConf());
-    stateStoreUtil = new FederationStateStoreTestUtil(stateStore);
-
-    interceptor.setConf(this.getConf());
-    interceptor.init(TEST_USER);
-
-    subClusters = new ArrayList<>();
-
-    for (int i = 0; i < NUM_SUBCLUSTER; i++) {
-      SubClusterId sc = SubClusterId.newInstance(Integer.toString(i));
-      stateStoreUtil.registerSubCluster(sc);
-      subClusters.add(sc);
-    }
-
-    RouterClientRMService routerClientRMService = new RouterClientRMService();
-    routerClientRMService.initUserPipelineMap(getConf());
-    long secretKeyInterval = this.getConf().getLong(
-        RM_DELEGATION_KEY_UPDATE_INTERVAL_KEY, RM_DELEGATION_KEY_UPDATE_INTERVAL_DEFAULT);
-    long tokenMaxLifetime = this.getConf().getLong(
-        RM_DELEGATION_TOKEN_MAX_LIFETIME_KEY, RM_DELEGATION_TOKEN_MAX_LIFETIME_DEFAULT);
-    long tokenRenewInterval = this.getConf().getLong(
-        RM_DELEGATION_TOKEN_RENEW_INTERVAL_KEY, RM_DELEGATION_TOKEN_RENEW_INTERVAL_DEFAULT);
-    long removeScanInterval = this.getConf().getTimeDuration(
-        RM_DELEGATION_TOKEN_REMOVE_SCAN_INTERVAL_KEY,
-        RM_DELEGATION_TOKEN_REMOVE_SCAN_INTERVAL_DEFAULT, TimeUnit.MILLISECONDS);
-    RouterDelegationTokenSecretManager tokenSecretManager = new RouterDelegationTokenSecretManager(
-        secretKeyInterval, tokenMaxLifetime, tokenRenewInterval, removeScanInterval,
-        this.getConf());
-    tokenSecretManager.startThreads();
-    routerClientRMService.setRouterDTSecretManager(tokenSecretManager);
-
-    TestableFederationClientInterceptor clientInterceptor =
-        new TestableFederationClientInterceptor();
-    clientInterceptor.setConf(this.getConf());
-    clientInterceptor.init(TEST_RENEWER);
-    clientInterceptor.setTokenSecretManager(tokenSecretManager);
-    RequestInterceptorChainWrapper wrapper = new RequestInterceptorChainWrapper();
-    wrapper.init(clientInterceptor);
-    routerClientRMService.getUserPipelineMap().put(TEST_RENEWER, wrapper);
-    interceptor.setRouterClientRMService(routerClientRMService);
-
-    for (SubClusterId subCluster : subClusters) {
-      SubClusterInfo subClusterInfo = stateStoreUtil.querySubClusterInfo(subCluster);
-      interceptor.getOrCreateInterceptorForSubCluster(
-          subCluster, subClusterInfo.getRMWebServiceAddress());
-    }
-
-    interceptor.setupResourceManager();
-
-  }
-
-  @Override
-  public void tearDown() {
-    interceptor.shutdown();
-    super.tearDown();
-  }
-
-  @Override
-  protected YarnConfiguration createConfiguration() {
-    YarnConfiguration conf = new YarnConfiguration();
-    conf.setBoolean(YarnConfiguration.FEDERATION_ENABLED, true);
-    conf.set(YarnConfiguration.ROUTER_WEBAPP_DEFAULT_INTERCEPTOR_CLASS,
-        MockDefaultRequestInterceptorREST.class.getName());
-    String mockPassThroughInterceptorClass =
-        PassThroughRESTRequestInterceptor.class.getName();
-
-    // Create a request interceptor pipeline for testing. The last one in the
-    // chain is the federation interceptor that calls the mock resource manager.
-    // The others in the chain will simply forward it to the next one in the
-    // chain
-    conf.set(YarnConfiguration.ROUTER_CLIENTRM_INTERCEPTOR_CLASS_PIPELINE,
-        mockPassThroughInterceptorClass + ","
-            + TestableFederationInterceptorREST.class.getName());
-
-    conf.set(YarnConfiguration.FEDERATION_POLICY_MANAGER,
-        UniformBroadcastPolicyManager.class.getName());
-
-    // Disable StateStoreFacade cache
-    conf.setInt(YarnConfiguration.FEDERATION_CACHE_TIME_TO_LIVE_SECS, 0);
-
-    // Open AppsInfo Cache
-    conf.setBoolean(YarnConfiguration.ROUTER_APPSINFO_ENABLED, true);
-    conf.setInt(YarnConfiguration.ROUTER_APPSINFO_CACHED_COUNT, 10);
-
-    return conf;
-  }
-
-  /**
-   * This test validates the correctness of GetNewApplication. The return
-   * ApplicationId has to belong to one of the SubCluster in the cluster.
-   */
-  @Test
-  public void testGetNewApplication() throws IOException, InterruptedException {
-
-    Response response = interceptor.createNewApplication(null);
-
-    Assert.assertNotNull(response);
-    NewApplication ci = (NewApplication) response.getEntity();
-    Assert.assertNotNull(ci);
-    ApplicationId appId = ApplicationId.fromString(ci.getApplicationId());
-    Assert.assertTrue(appId.getClusterTimestamp() < NUM_SUBCLUSTER);
-    Assert.assertTrue(appId.getClusterTimestamp() >= 0);
-  }
-
-  /**
-   * This test validates the correctness of SubmitApplication. The application
-   * has to be submitted to one of the SubCluster in the cluster.
-   */
-  @Test
-  public void testSubmitApplication()
-      throws YarnException, IOException, InterruptedException {
-
-    ApplicationId appId =
-        ApplicationId.newInstance(Time.now(), 1);
-
-    ApplicationSubmissionContextInfo context =
-        new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-
-    Response response = interceptor.submitApplication(context, null);
-    Assert.assertEquals(ACCEPTED, response.getStatus());
-    SubClusterId ci = (SubClusterId) response.getEntity();
-
-    Assert.assertNotNull(response);
-    SubClusterId scIdResult = stateStoreUtil.queryApplicationHomeSC(appId);
-    Assert.assertNotNull(scIdResult);
-    Assert.assertTrue(subClusters.contains(scIdResult));
-    Assert.assertEquals(ci, scIdResult);
-  }
-
-  /**
-   * This test validates the correctness of SubmitApplication in case of
-   * multiple submission. The first retry has to be submitted to the same
-   * SubCluster of the first attempt.
-   */
-  @Test
-  public void testSubmitApplicationMultipleSubmission()
-      throws YarnException, IOException, InterruptedException {
-
-    ApplicationId appId =
-        ApplicationId.newInstance(Time.now(), 1);
-    ApplicationSubmissionContextInfo context =
-        new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-
-    // First attempt
-    Response response = interceptor.submitApplication(context, null);
-    Assert.assertNotNull(response);
-    Assert.assertEquals(ACCEPTED, response.getStatus());
-
-    SubClusterId scIdResult = stateStoreUtil.queryApplicationHomeSC(appId);
-    Assert.assertNotNull(scIdResult);
-
-    // First retry
-    response = interceptor.submitApplication(context, null);
-
-    Assert.assertNotNull(response);
-    Assert.assertEquals(ACCEPTED, response.getStatus());
-    SubClusterId scIdResult2 = stateStoreUtil.queryApplicationHomeSC(appId);
-    Assert.assertNotNull(scIdResult2);
-    Assert.assertEquals(scIdResult, scIdResult2);
-  }
-
-  /**
-   * This test validates the correctness of SubmitApplication in case of empty
-   * request.
-   */
-  @Test
-  public void testSubmitApplicationEmptyRequest() throws IOException, InterruptedException {
-
-    // ApplicationSubmissionContextInfo null
-    Response response = interceptor.submitApplication(null, null);
-
-    Assert.assertEquals(BAD_REQUEST, response.getStatus());
-
-    // ApplicationSubmissionContextInfo empty
-    response = interceptor
-        .submitApplication(new ApplicationSubmissionContextInfo(), null);
-
-    Assert.assertEquals(BAD_REQUEST, response.getStatus());
-
-    ApplicationSubmissionContextInfo context =
-        new ApplicationSubmissionContextInfo();
-    response = interceptor.submitApplication(context, null);
-    Assert.assertEquals(BAD_REQUEST, response.getStatus());
-  }
-
-  /**
-   * This test validates the correctness of SubmitApplication in case of
-   * application in wrong format.
-   */
-  @Test
-  public void testSubmitApplicationWrongFormat() throws IOException, InterruptedException {
-
-    ApplicationSubmissionContextInfo context =
-        new ApplicationSubmissionContextInfo();
-    context.setApplicationId("Application_wrong_id");
-    Response response = interceptor.submitApplication(context, null);
-    Assert.assertEquals(BAD_REQUEST, response.getStatus());
-  }
-
-  /**
-   * This test validates the correctness of ForceKillApplication in case the
-   * application exists in the cluster.
-   */
-  @Test
-  public void testForceKillApplication()
-      throws YarnException, IOException, InterruptedException {
-
-    ApplicationId appId =
-        ApplicationId.newInstance(Time.now(), 1);
-    ApplicationSubmissionContextInfo context =
-        new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-
-    // Submit the application we are going to kill later
-    Response response = interceptor.submitApplication(context, null);
-
-    Assert.assertNotNull(response);
-    Assert.assertNotNull(stateStoreUtil.queryApplicationHomeSC(appId));
-
-    AppState appState = new AppState("KILLED");
-
-    Response responseKill =
-        interceptor.updateAppState(appState, null, appId.toString());
-    Assert.assertNotNull(responseKill);
-  }
-
-  /**
-   * This test validates the correctness of ForceKillApplication in case of
-   * application does not exist in StateStore.
-   */
-  @Test
-  public void testForceKillApplicationNotExists()
-      throws YarnException, IOException, InterruptedException {
-
-    ApplicationId appId =
-        ApplicationId.newInstance(Time.now(), 1);
-    AppState appState = new AppState("KILLED");
-
-    Response response =
-        interceptor.updateAppState(appState, null, appId.toString());
-    Assert.assertEquals(BAD_REQUEST, response.getStatus());
-
-  }
-
-  /**
-   * This test validates the correctness of ForceKillApplication in case of
-   * application in wrong format.
-   */
-  @Test
-  public void testForceKillApplicationWrongFormat()
-      throws YarnException, IOException, InterruptedException {
-
-    AppState appState = new AppState("KILLED");
-    Response response =
-        interceptor.updateAppState(appState, null, "Application_wrong_id");
-    Assert.assertEquals(BAD_REQUEST, response.getStatus());
-  }
-
-  /**
-   * This test validates the correctness of ForceKillApplication in case of
-   * empty request.
-   */
-  @Test
-  public void testForceKillApplicationEmptyRequest()
-      throws YarnException, IOException, InterruptedException {
-    ApplicationId appId =
-        ApplicationId.newInstance(Time.now(), 1);
-
-    ApplicationSubmissionContextInfo context =
-        new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-
-    // Submit the application we are going to kill later
-    interceptor.submitApplication(context, null);
-
-    Response response =
-        interceptor.updateAppState(null, null, appId.toString());
-    Assert.assertEquals(BAD_REQUEST, response.getStatus());
-
-  }
-
-  /**
-   * This test validates the correctness of GetApplicationReport in case the
-   * application exists in the cluster.
-   */
-  @Test
-  public void testGetApplicationReport()
-      throws YarnException, IOException, InterruptedException {
-
-    ApplicationId appId =
-        ApplicationId.newInstance(Time.now(), 1);
-    ApplicationSubmissionContextInfo context =
-        new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-
-    // Submit the application we want the report later
-    Response response = interceptor.submitApplication(context, null);
-
-    Assert.assertNotNull(response);
-    Assert.assertNotNull(stateStoreUtil.queryApplicationHomeSC(appId));
-
-    AppInfo responseGet = interceptor.getApp(null, appId.toString(), null);
-
-    Assert.assertNotNull(responseGet);
-  }
-
-  /**
-   * This test validates the correctness of GetApplicationReport in case the
-   * application does not exist in StateStore.
-   */
-  @Test
-  public void testGetApplicationNotExists() {
-
-    ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-
-    AppInfo response = interceptor.getApp(null, appId.toString(), null);
-
-    Assert.assertNull(response);
-  }
-
-  /**
-   * This test validates the correctness of GetApplicationReport in case of
-   * application in wrong format.
-   */
-  @Test
-  public void testGetApplicationWrongFormat() {
-
-    AppInfo response = interceptor.getApp(null, "Application_wrong_id", null);
-
-    Assert.assertNull(response);
-  }
-
-  /**
-   * This test validates the correctness of GetApplicationsReport in case each
-   * subcluster provided one application.
-   */
-  @Test
-  public void testGetApplicationsReport() {
-
-    AppsInfo responseGet = interceptor.getApps(null, null, null, null, null,
-        null, null, null, null, null, null, null, null, null, null);
-
-    Assert.assertNotNull(responseGet);
-    Assert.assertEquals(NUM_SUBCLUSTER, responseGet.getApps().size());
-    // The merged operations is tested in TestRouterWebServiceUtil
-  }
-
-  /**
-   * This test validates the correctness of GetNodes in case each subcluster
-   * provided one node with the LastHealthUpdate set to the SubClusterId. The
-   * expected result would be the NodeInfo from the last SubCluster that has
-   * LastHealthUpdate equal to Num_SubCluster -1.
-   */
-  @Test
-  public void testGetNode() {
-
-    NodeInfo responseGet = interceptor.getNode("testGetNode");
-
-    Assert.assertNotNull(responseGet);
-    Assert.assertEquals(NUM_SUBCLUSTER - 1, responseGet.getLastHealthUpdate());
-  }
-
-  /**
-   * This test validates the correctness of GetNodes in case each subcluster
-   * provided one node.
-   */
-  @Test
-  public void testGetNodes() {
-
-    NodesInfo responseGet = interceptor.getNodes(null);
-
-    Assert.assertNotNull(responseGet);
-    Assert.assertEquals(NUM_SUBCLUSTER, responseGet.getNodes().size());
-    // The remove duplicate operations is tested in TestRouterWebServiceUtil
-  }
-
-  /**
-   * This test validates the correctness of updateNodeResource().
-   */
-  @Test
-  public void testUpdateNodeResource() {
-    List<NodeInfo> nodes = interceptor.getNodes(null).getNodes();
-    Assert.assertFalse(nodes.isEmpty());
-    final String nodeId = nodes.get(0).getNodeId();
-    ResourceOptionInfo resourceOption = new ResourceOptionInfo(
-        ResourceOption.newInstance(
-            Resource.newInstance(2048, 3), 1000));
-    ResourceInfo resource = interceptor.updateNodeResource(
-        null, nodeId, resourceOption);
-    Assert.assertNotNull(resource);
-    Assert.assertEquals(2048, resource.getMemorySize());
-    Assert.assertEquals(3, resource.getvCores());
-  }
-
-  /**
-   * This test validates the correctness of getClusterMetricsInfo in case each
-   * SubCluster provided a ClusterMetricsInfo with appsSubmitted set to the
-   * SubClusterId. The expected result would be appSubmitted equals to the sum
-   * of SubClusterId. SubClusterId in this case is an integer.
-   */
-  @Test
-  public void testGetClusterMetrics() {
-
-    ClusterMetricsInfo responseGet = interceptor.getClusterMetricsInfo();
-
-    Assert.assertNotNull(responseGet);
-    int expectedAppSubmitted = 0;
-    for (int i = 0; i < NUM_SUBCLUSTER; i++) {
-      expectedAppSubmitted += i;
-    }
-    Assert.assertEquals(expectedAppSubmitted, responseGet.getAppsSubmitted());
-    // The merge operations is tested in TestRouterWebServiceUtil
-  }
-
-  /**
-   * This test validates the correctness of GetApplicationState in case the
-   * application exists in the cluster.
-   */
-  @Test
-  public void testGetApplicationState()
-      throws YarnException, IOException, InterruptedException {
-
-    ApplicationId appId =
-        ApplicationId.newInstance(Time.now(), 1);
-    ApplicationSubmissionContextInfo context =
-        new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-
-    // Submit the application we want the report later
-    Response response = interceptor.submitApplication(context, null);
-
-    Assert.assertNotNull(response);
-    Assert.assertNotNull(stateStoreUtil.queryApplicationHomeSC(appId));
-
-    AppState responseGet = interceptor.getAppState(null, appId.toString());
-
-    Assert.assertNotNull(responseGet);
-    Assert.assertEquals(MockDefaultRequestInterceptorREST.APP_STATE_RUNNING,
-        responseGet.getState());
-  }
-
-  /**
-   * This test validates the correctness of GetApplicationState in case the
-   * application does not exist in StateStore.
-   */
-  @Test
-  public void testGetApplicationStateNotExists() throws IOException {
-
-    ApplicationId appId =
-        ApplicationId.newInstance(Time.now(), 1);
-
-    AppState response = interceptor.getAppState(null, appId.toString());
-
-    Assert.assertNull(response);
-  }
-
-  /**
-   * This test validates the correctness of GetApplicationState in case of
-   * application in wrong format.
-   */
-  @Test
-  public void testGetApplicationStateWrongFormat()
-      throws IOException {
-
-    AppState response = interceptor.getAppState(null, "Application_wrong_id");
-
-    Assert.assertNull(response);
-  }
-
-  /**
-   * This test validates the creation of new interceptor in case of a
-   * RMSwitchover in a subCluster.
-   */
-  @Test
-  public void testRMSwitchoverOfOneSC() throws Exception {
-    SubClusterId subClusterId = SubClusterId.newInstance(Integer.toString(0));
-
-    interceptor.getClusterMetricsInfo();
-    Assert.assertEquals("http://1.2.3.4:4", interceptor
-            .getInterceptorForSubCluster(subClusterId).getWebAppAddress());
-
-    //Register the first subCluster with secondRM simulating RMSwitchover
-    registerSubClusterWithSwitchoverRM(subClusterId);
-
-    interceptor.getClusterMetricsInfo();
-    Assert.assertEquals("http://5.6.7.8:8", interceptor
-            .getInterceptorForSubCluster(subClusterId).getWebAppAddress());
-  }
-
-  private void registerSubClusterWithSwitchoverRM(SubClusterId subClusterId)
-          throws YarnException {
-    String amRMAddress = "5.6.7.8:5";
-    String clientRMAddress = "5.6.7.8:6";
-    String rmAdminAddress = "5.6.7.8:7";
-    String webAppAddress = "5.6.7.8:8";
-
-    SubClusterInfo subClusterInfo = SubClusterInfo.newInstance(subClusterId,
-            amRMAddress, clientRMAddress, rmAdminAddress, webAppAddress,
-            SubClusterState.SC_RUNNING, new MonotonicClock().getTime(),
-            "capability");
-    stateStore.registerSubCluster(
-            SubClusterRegisterRequest.newInstance(subClusterInfo));
-  }
-
-  @Test
-  public void testGetContainers()
-      throws YarnException, IOException, InterruptedException {
-
-    ApplicationId appId = ApplicationId.newInstance(Time.now(), 1);
-    ApplicationSubmissionContextInfo context =
-        new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-
-    // Submit the application we want the report later
-    Response response = interceptor.submitApplication(context, null);
-
-    Assert.assertNotNull(response);
-    Assert.assertNotNull(stateStoreUtil.queryApplicationHomeSC(appId));
-
-    ApplicationAttemptId appAttempt = ApplicationAttemptId.newInstance(appId, 1);
-
-    ContainersInfo responseGet = interceptor.getContainers(
-        null, null, appId.toString(), appAttempt.toString());
-
-    Assert.assertEquals(4, responseGet.getContainers().size());
-  }
-
-  @Test
-  public void testGetContainersNotExists() throws Exception {
-    ApplicationId appId = ApplicationId.newInstance(Time.now(), 1);
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "Parameter error, the appAttemptId is empty or null.",
-        () -> interceptor.getContainers(null, null, appId.toString(), null));
-  }
-
-  @Test
-  public void testGetContainersWrongFormat() throws Exception {
-    ApplicationId appId = ApplicationId.newInstance(Time.now(), 1);
-    ApplicationAttemptId appAttempt = ApplicationAttemptId.newInstance(appId, 1);
-
-    // Test Case 1: appId is wrong format, appAttemptId is accurate.
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "Invalid ApplicationId prefix: Application_wrong_id. " +
-        "The valid ApplicationId should start with prefix application",
-        () -> interceptor.getContainers(null, null, "Application_wrong_id", appAttempt.toString()));
-
-    // Test Case2: appId is accurate, appAttemptId is wrong format.
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "Invalid AppAttemptId prefix: AppAttempt_wrong_id",
-        () -> interceptor.getContainers(null, null, appId.toString(), "AppAttempt_wrong_id"));
-  }
-
-  @Test
-  public void testGetNodeToLabels() throws IOException {
-    NodeToLabelsInfo info = interceptor.getNodeToLabels(null);
-    HashMap<String, NodeLabelsInfo> map = info.getNodeToLabels();
-    Assert.assertNotNull(map);
-    Assert.assertEquals(2, map.size());
-
-    NodeLabelsInfo node1Value = map.getOrDefault("node1", null);
-    Assert.assertNotNull(node1Value);
-    Assert.assertEquals(1, node1Value.getNodeLabelsName().size());
-    Assert.assertEquals("CPU", node1Value.getNodeLabelsName().get(0));
-
-    NodeLabelsInfo node2Value = map.getOrDefault("node2", null);
-    Assert.assertNotNull(node2Value);
-    Assert.assertEquals(1, node2Value.getNodeLabelsName().size());
-    Assert.assertEquals("GPU", node2Value.getNodeLabelsName().get(0));
-  }
-
-  @Test
-  public void testGetLabelsToNodes() throws Exception {
-    LabelsToNodesInfo labelsToNodesInfo = interceptor.getLabelsToNodes(null);
-    Map<NodeLabelInfo, NodeIDsInfo> map = labelsToNodesInfo.getLabelsToNodes();
-    Assert.assertNotNull(map);
-    Assert.assertEquals(3, map.size());
-
-    NodeLabel labelX = NodeLabel.newInstance("x", false);
-    NodeLabelInfo nodeLabelInfoX = new NodeLabelInfo(labelX);
-    NodeIDsInfo nodeIDsInfoX = map.get(nodeLabelInfoX);
-    Assert.assertNotNull(nodeIDsInfoX);
-    Assert.assertEquals(2, nodeIDsInfoX.getNodeIDs().size());
-    Resource resourceX =
-        nodeIDsInfoX.getPartitionInfo().getResourceAvailable().getResource();
-    Assert.assertNotNull(resourceX);
-    Assert.assertEquals(4*10, resourceX.getVirtualCores());
-    Assert.assertEquals(4*20*1024, resourceX.getMemorySize());
-
-    NodeLabel labelY = NodeLabel.newInstance("y", false);
-    NodeLabelInfo nodeLabelInfoY = new NodeLabelInfo(labelY);
-    NodeIDsInfo nodeIDsInfoY = map.get(nodeLabelInfoY);
-    Assert.assertNotNull(nodeIDsInfoY);
-    Assert.assertEquals(2, nodeIDsInfoY.getNodeIDs().size());
-    Resource resourceY =
-        nodeIDsInfoY.getPartitionInfo().getResourceAvailable().getResource();
-    Assert.assertNotNull(resourceY);
-    Assert.assertEquals(4*20, resourceY.getVirtualCores());
-    Assert.assertEquals(4*40*1024, resourceY.getMemorySize());
-  }
-
-  @Test
-  public void testGetClusterNodeLabels() throws Exception {
-    NodeLabelsInfo nodeLabelsInfo = interceptor.getClusterNodeLabels(null);
-    Assert.assertNotNull(nodeLabelsInfo);
-    Assert.assertEquals(2, nodeLabelsInfo.getNodeLabelsName().size());
-
-    List<String> nodeLabelsName = nodeLabelsInfo.getNodeLabelsName();
-    Assert.assertNotNull(nodeLabelsName);
-    Assert.assertTrue(nodeLabelsName.contains("cpu"));
-    Assert.assertTrue(nodeLabelsName.contains("gpu"));
-
-    ArrayList<NodeLabelInfo> nodeLabelInfos = nodeLabelsInfo.getNodeLabelsInfo();
-    Assert.assertNotNull(nodeLabelInfos);
-    Assert.assertEquals(2, nodeLabelInfos.size());
-    NodeLabelInfo cpuNodeLabelInfo = new NodeLabelInfo("cpu", false);
-    Assert.assertTrue(nodeLabelInfos.contains(cpuNodeLabelInfo));
-    NodeLabelInfo gpuNodeLabelInfo = new NodeLabelInfo("gpu", false);
-    Assert.assertTrue(nodeLabelInfos.contains(gpuNodeLabelInfo));
-  }
-
-  @Test
-  public void testGetLabelsOnNode() throws Exception {
-    NodeLabelsInfo nodeLabelsInfo = interceptor.getLabelsOnNode(null, "node1");
-    Assert.assertNotNull(nodeLabelsInfo);
-    Assert.assertEquals(2, nodeLabelsInfo.getNodeLabelsName().size());
-
-    List<String> nodeLabelsName = nodeLabelsInfo.getNodeLabelsName();
-    Assert.assertNotNull(nodeLabelsName);
-    Assert.assertTrue(nodeLabelsName.contains("x"));
-    Assert.assertTrue(nodeLabelsName.contains("y"));
-
-    // null request
-    interceptor.setAllowPartialResult(false);
-    NodeLabelsInfo nodeLabelsInfo2 = interceptor.getLabelsOnNode(null, "node2");
-    Assert.assertNotNull(nodeLabelsInfo2);
-    Assert.assertEquals(0, nodeLabelsInfo2.getNodeLabelsName().size());
-  }
-
-  @Test
-  public void testGetContainer() throws Exception {
-    //
-    ApplicationId appId = ApplicationId.newInstance(Time.now(), 1);
-    ApplicationAttemptId appAttemptId = ApplicationAttemptId.newInstance(appId, 1);
-    ContainerId appContainerId = ContainerId.newContainerId(appAttemptId, 1);
-    String applicationId = appId.toString();
-    String attemptId = appAttemptId.toString();
-    String containerId = appContainerId.toString();
-
-    // Submit application to multiSubCluster
-    ApplicationSubmissionContextInfo context = new ApplicationSubmissionContextInfo();
-    context.setApplicationId(applicationId);
-    Assert.assertNotNull(interceptor.submitApplication(context, null));
-
-    // Test Case1: Wrong ContainerId
-    LambdaTestUtils.intercept(IllegalArgumentException.class, "Invalid ContainerId prefix: 0",
-        () -> interceptor.getContainer(null, null, applicationId, attemptId, "0"));
-
-    // Test Case2: Correct ContainerId
-
-    ContainerInfo containerInfo = interceptor.getContainer(null, null, applicationId,
-        attemptId, containerId);
-    Assert.assertNotNull(containerInfo);
-  }
-
-  @Test
-  public void testGetAppAttempts() throws IOException, InterruptedException {
-    // Submit application to multiSubCluster
-    ApplicationId appId = ApplicationId.newInstance(Time.now(), 1);
-    ApplicationSubmissionContextInfo context = new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-
-    Assert.assertNotNull(interceptor.submitApplication(context, null));
-
-    AppAttemptsInfo appAttemptsInfo = interceptor.getAppAttempts(null, appId.toString());
-    Assert.assertNotNull(appAttemptsInfo);
-
-    ArrayList<AppAttemptInfo> attemptLists = appAttemptsInfo.getAttempts();
-    Assert.assertNotNull(appAttemptsInfo);
-    Assert.assertEquals(2, attemptLists.size());
-
-    AppAttemptInfo attemptInfo1 = attemptLists.get(0);
-    Assert.assertNotNull(attemptInfo1);
-    Assert.assertEquals(0, attemptInfo1.getAttemptId());
-    Assert.assertEquals("AppAttemptId_0", attemptInfo1.getAppAttemptId());
-    Assert.assertEquals("LogLink_0", attemptInfo1.getLogsLink());
-    Assert.assertEquals(1659621705L, attemptInfo1.getFinishedTime());
-
-    AppAttemptInfo attemptInfo2 = attemptLists.get(1);
-    Assert.assertNotNull(attemptInfo2);
-    Assert.assertEquals(0, attemptInfo2.getAttemptId());
-    Assert.assertEquals("AppAttemptId_1", attemptInfo2.getAppAttemptId());
-    Assert.assertEquals("LogLink_1", attemptInfo2.getLogsLink());
-    Assert.assertEquals(1659621705L, attemptInfo2.getFinishedTime());
-  }
-
-  @Test
-  public void testGetAppAttempt() throws IOException, InterruptedException {
-
-    // Generate ApplicationId information
-    ApplicationId appId = ApplicationId.newInstance(Time.now(), 1);
-    ApplicationSubmissionContextInfo context = new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-
-    // Generate ApplicationAttemptId information
-    Assert.assertNotNull(interceptor.submitApplication(context, null));
-    ApplicationAttemptId expectAppAttemptId = ApplicationAttemptId.newInstance(appId, 1);
-    String appAttemptId = expectAppAttemptId.toString();
-
-    org.apache.hadoop.yarn.server.webapp.dao.AppAttemptInfo
-        appAttemptInfo = interceptor.getAppAttempt(null, null, appId.toString(), appAttemptId);
-
-    Assert.assertNotNull(appAttemptInfo);
-    Assert.assertEquals(expectAppAttemptId.toString(), appAttemptInfo.getAppAttemptId());
-    Assert.assertEquals("url", appAttemptInfo.getTrackingUrl());
-    Assert.assertEquals("oUrl", appAttemptInfo.getOriginalTrackingUrl());
-    Assert.assertEquals(124, appAttemptInfo.getRpcPort());
-    Assert.assertEquals("host", appAttemptInfo.getHost());
-  }
-
-  @Test
-  public void testGetAppTimeout() throws IOException, InterruptedException {
-
-    // Generate ApplicationId information
-    ApplicationId appId = ApplicationId.newInstance(Time.now(), 1);
-    ApplicationSubmissionContextInfo context = new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-
-    // Generate ApplicationAttemptId information
-    Assert.assertNotNull(interceptor.submitApplication(context, null));
-
-    ApplicationTimeoutType appTimeoutType = ApplicationTimeoutType.LIFETIME;
-    AppTimeoutInfo appTimeoutInfo =
-        interceptor.getAppTimeout(null, appId.toString(), appTimeoutType.toString());
-    Assert.assertNotNull(appTimeoutInfo);
-    Assert.assertEquals(10, appTimeoutInfo.getRemainingTimeInSec());
-    Assert.assertEquals("UNLIMITED", appTimeoutInfo.getExpireTime());
-    Assert.assertEquals(appTimeoutType, appTimeoutInfo.getTimeoutType());
-  }
-
-  @Test
-  public void testGetAppTimeouts() throws IOException, InterruptedException {
-
-    // Generate ApplicationId information
-    ApplicationId appId = ApplicationId.newInstance(Time.now(), 1);
-    ApplicationSubmissionContextInfo context = new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-
-    // Generate ApplicationAttemptId information
-    Assert.assertNotNull(interceptor.submitApplication(context, null));
-
-    AppTimeoutsInfo appTimeoutsInfo = interceptor.getAppTimeouts(null, appId.toString());
-    Assert.assertNotNull(appTimeoutsInfo);
-
-    List<AppTimeoutInfo> timeouts = appTimeoutsInfo.getAppTimeouts();
-    Assert.assertNotNull(timeouts);
-    Assert.assertEquals(1, timeouts.size());
-
-    AppTimeoutInfo resultAppTimeout = timeouts.get(0);
-    Assert.assertNotNull(resultAppTimeout);
-    Assert.assertEquals(10, resultAppTimeout.getRemainingTimeInSec());
-    Assert.assertEquals("UNLIMITED", resultAppTimeout.getExpireTime());
-    Assert.assertEquals(ApplicationTimeoutType.LIFETIME, resultAppTimeout.getTimeoutType());
-  }
-
-  @Test
-  public void testUpdateApplicationTimeout() throws IOException, InterruptedException,
-      YarnException {
-
-    // Generate ApplicationId information
-    ApplicationId appId = ApplicationId.newInstance(Time.now(), 1);
-    ApplicationSubmissionContextInfo context = new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-
-    // Generate ApplicationAttemptId information
-    Assert.assertNotNull(interceptor.submitApplication(context, null));
-
-    long newLifetime = 10L;
-    // update 10L seconds more to timeout
-    String timeout = Times.formatISO8601(Time.now() + newLifetime * 1000);
-    AppTimeoutInfo paramAppTimeOut = new AppTimeoutInfo();
-    paramAppTimeOut.setExpiryTime(timeout);
-    // RemainingTime = Math.max((timeoutInMillis - System.currentTimeMillis()) / 1000, 0))
-    paramAppTimeOut.setRemainingTime(newLifetime);
-    paramAppTimeOut.setTimeoutType(ApplicationTimeoutType.LIFETIME);
-
-    Response response =
-        interceptor.updateApplicationTimeout(paramAppTimeOut, null, appId.toString());
-    Assert.assertNotNull(response);
-    AppTimeoutInfo entity = (AppTimeoutInfo) response.getEntity();
-    Assert.assertNotNull(entity);
-    Assert.assertEquals(paramAppTimeOut.getExpireTime(), entity.getExpireTime());
-    Assert.assertEquals(paramAppTimeOut.getTimeoutType(), entity.getTimeoutType());
-    Assert.assertEquals(paramAppTimeOut.getRemainingTimeInSec(), entity.getRemainingTimeInSec());
-  }
-
-  @Test
-  public void testUpdateApplicationPriority() throws IOException, InterruptedException,
-      YarnException {
-
-    // Submit application to multiSubCluster
-    ApplicationId appId = ApplicationId.newInstance(Time.now(), 1);
-    ApplicationSubmissionContextInfo context = new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-    context.setPriority(20);
-
-    // Submit the application we are going to kill later
-    Assert.assertNotNull(interceptor.submitApplication(context, null));
-
-    int iPriority = 10;
-    // Set Priority for application
-    Response response = interceptor.updateApplicationPriority(
-        new AppPriority(iPriority), null, appId.toString());
-
-    Assert.assertNotNull(response);
-    AppPriority entity = (AppPriority) response.getEntity();
-    Assert.assertNotNull(entity);
-    Assert.assertEquals(iPriority, entity.getPriority());
-  }
-
-  @Test
-  public void testGetAppPriority() throws IOException, InterruptedException {
-
-    // Submit application to multiSubCluster
-    ApplicationId appId = ApplicationId.newInstance(Time.now(), 1);
-    int priority = 40;
-    ApplicationSubmissionContextInfo context = new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-    context.setPriority(priority);
-
-    // Submit the application we are going to kill later
-    Assert.assertNotNull(interceptor.submitApplication(context, null));
-
-    // Set Priority for application
-    AppPriority appPriority = interceptor.getAppPriority(null, appId.toString());
-    Assert.assertNotNull(appPriority);
-    Assert.assertEquals(priority, appPriority.getPriority());
-  }
-
-  @Test
-  public void testUpdateAppQueue() throws IOException, InterruptedException,
-      YarnException {
-
-    String oldQueue = "oldQueue";
-    String newQueue = "newQueue";
-
-    // Submit application to multiSubCluster
-    ApplicationId appId = ApplicationId.newInstance(Time.now(), 1);
-    ApplicationSubmissionContextInfo context = new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-    context.setQueue(oldQueue);
-
-    // Submit the application
-    Assert.assertNotNull(interceptor.submitApplication(context, null));
-
-    // Set New Queue for application
-    Response response = interceptor.updateAppQueue(new AppQueue(newQueue),
-        null, appId.toString());
-
-    Assert.assertNotNull(response);
-    AppQueue appQueue = (AppQueue) response.getEntity();
-    Assert.assertEquals(newQueue, appQueue.getQueue());
-
-    // Get AppQueue by application
-    AppQueue queue = interceptor.getAppQueue(null, appId.toString());
-    Assert.assertNotNull(queue);
-    Assert.assertEquals(newQueue, queue.getQueue());
-  }
-
-  @Test
-  public void testGetAppQueue() throws IOException, InterruptedException {
-    String queueName = "queueName";
-
-    // Submit application to multiSubCluster
-    ApplicationId appId = ApplicationId.newInstance(Time.now(), 1);
-    ApplicationSubmissionContextInfo context = new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-    context.setQueue(queueName);
-
-    Assert.assertNotNull(interceptor.submitApplication(context, null));
-
-    // Get Queue by application
-    AppQueue queue = interceptor.getAppQueue(null, appId.toString());
-    Assert.assertNotNull(queue);
-    Assert.assertEquals(queueName, queue.getQueue());
-  }
-
-  @Test
-  public void testGetAppsInfoCache() {
-
-    AppsInfo responseGet = interceptor.getApps(
-        null, null, null, null, null, null, null, null, null, null, null, null, null, null, null);
-    Assert.assertNotNull(responseGet);
-
-    RouterAppInfoCacheKey cacheKey = RouterAppInfoCacheKey.newInstance(
-        null, null, null, null, null, null, null, null, null, null, null, null, null, null, null);
-
-    LRUCacheHashMap<RouterAppInfoCacheKey, AppsInfo> appsInfoCache =
-        interceptor.getAppInfosCaches();
-    Assert.assertNotNull(appsInfoCache);
-    Assert.assertFalse(appsInfoCache.isEmpty());
-    Assert.assertEquals(1, appsInfoCache.size());
-    Assert.assertTrue(appsInfoCache.containsKey(cacheKey));
-
-    AppsInfo cacheResult = appsInfoCache.get(cacheKey);
-    Assert.assertNotNull(cacheResult);
-    Assert.assertEquals(responseGet, cacheResult);
-  }
-
-  @Test
-  public void testGetAppStatistics() throws IOException, InterruptedException, YarnException {
-
-    // Submit application to multiSubCluster
-    ApplicationId appId = ApplicationId.newInstance(Time.now(), 1);
-    ApplicationSubmissionContextInfo context = new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-    context.setApplicationType("MapReduce");
-    context.setQueue("queue");
-
-    Assert.assertNotNull(interceptor.submitApplication(context, null));
-
-    GetApplicationHomeSubClusterRequest request =
-        GetApplicationHomeSubClusterRequest.newInstance(appId);
-    GetApplicationHomeSubClusterResponse response =
-        stateStore.getApplicationHomeSubCluster(request);
-
-    Assert.assertNotNull(response);
-    ApplicationHomeSubCluster homeSubCluster = response.getApplicationHomeSubCluster();
-
-    DefaultRequestInterceptorREST interceptorREST =
-        interceptor.getInterceptorForSubCluster(homeSubCluster.getHomeSubCluster());
-
-    MockDefaultRequestInterceptorREST mockInterceptorREST =
-        (MockDefaultRequestInterceptorREST) interceptorREST;
-    mockInterceptorREST.updateApplicationState(YarnApplicationState.RUNNING,
-        appId.toString());
-
-    Set<String> stateQueries = new HashSet<>();
-    stateQueries.add(YarnApplicationState.RUNNING.name());
-
-    Set<String> typeQueries = new HashSet<>();
-    typeQueries.add("MapReduce");
-
-    ApplicationStatisticsInfo response2 =
-        interceptor.getAppStatistics(null, stateQueries, typeQueries);
-
-    Assert.assertNotNull(response2);
-    Assert.assertFalse(response2.getStatItems().isEmpty());
-
-    StatisticsItemInfo result = response2.getStatItems().get(0);
-    Assert.assertEquals(1, result.getCount());
-    Assert.assertEquals(YarnApplicationState.RUNNING, result.getState());
-    Assert.assertEquals("MapReduce", result.getType());
-  }
-
-  @Test
-  public void testGetAppActivities() throws IOException, InterruptedException {
-    // Submit application to multiSubCluster
-    ApplicationId appId = ApplicationId.newInstance(Time.now(), 1);
-    ApplicationSubmissionContextInfo context = new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-    context.setApplicationType("MapReduce");
-    context.setQueue("queue");
-
-    Assert.assertNotNull(interceptor.submitApplication(context, null));
-    Set<String> prioritiesSet = Collections.singleton("0");
-    Set<String> allocationRequestIdsSet = Collections.singleton("0");
-
-    AppActivitiesInfo appActivitiesInfo =
-        interceptor.getAppActivities(null, appId.toString(), String.valueOf(Time.now()),
-        prioritiesSet, allocationRequestIdsSet, null, "-1", null, false);
-
-    Assert.assertNotNull(appActivitiesInfo);
-    Assert.assertEquals(appId.toString(), appActivitiesInfo.getApplicationId());
-    Assert.assertEquals(10, appActivitiesInfo.getAllocations().size());
-  }
-
-  @Test
-  public void testListReservation() throws Exception {
-
-    // submitReservation
-    ReservationId reservationId = ReservationId.newInstance(Time.now(), 1);
-    submitReservation(reservationId);
-
-    // Call the listReservation method
-    String applyReservationId = reservationId.toString();
-    Response listReservationResponse = interceptor.listReservation(
-        QUEUE_DEDICATED_FULL, applyReservationId, -1, -1, false, null);
-    Assert.assertNotNull(listReservationResponse);
-    Assert.assertNotNull(listReservationResponse.getStatus());
-    Status status = Status.fromStatusCode(listReservationResponse.getStatus());
-    Assert.assertEquals(Status.OK, status);
-
-    Object entity = listReservationResponse.getEntity();
-    Assert.assertNotNull(entity);
-    Assert.assertNotNull(entity instanceof ReservationListInfo);
-
-    Assert.assertTrue(entity instanceof ReservationListInfo);
-    ReservationListInfo listInfo = (ReservationListInfo) entity;
-    Assert.assertNotNull(listInfo);
-
-    List<ReservationInfo> reservationInfoList = listInfo.getReservations();
-    Assert.assertNotNull(reservationInfoList);
-    Assert.assertEquals(1, reservationInfoList.size());
-
-    ReservationInfo reservationInfo = reservationInfoList.get(0);
-    Assert.assertNotNull(reservationInfo);
-    Assert.assertEquals(applyReservationId, reservationInfo.getReservationId());
-
-    ReservationDefinitionInfo definitionInfo = reservationInfo.getReservationDefinition();
-    Assert.assertNotNull(definitionInfo);
-
-    ReservationRequestsInfo reservationRequestsInfo = definitionInfo.getReservationRequests();
-    Assert.assertNotNull(reservationRequestsInfo);
-
-    ArrayList<ReservationRequestInfo> reservationRequestInfoList =
-        reservationRequestsInfo.getReservationRequest();
-    Assert.assertNotNull(reservationRequestInfoList);
-    Assert.assertEquals(1, reservationRequestInfoList.size());
-
-    ReservationRequestInfo reservationRequestInfo = reservationRequestInfoList.get(0);
-    Assert.assertNotNull(reservationRequestInfo);
-    Assert.assertEquals(4, reservationRequestInfo.getNumContainers());
-
-    ResourceInfo resourceInfo = reservationRequestInfo.getCapability();
-    Assert.assertNotNull(resourceInfo);
-
-    int vCore = resourceInfo.getvCores();
-    long memory = resourceInfo.getMemorySize();
-    Assert.assertEquals(1, vCore);
-    Assert.assertEquals(1024, memory);
-  }
-
-  @Test
-  public void testCreateNewReservation() throws Exception {
-    Response response = interceptor.createNewReservation(null);
-    Assert.assertNotNull(response);
-
-    Object entity = response.getEntity();
-    Assert.assertNotNull(entity);
-    Assert.assertTrue(entity instanceof NewReservation);
-
-    NewReservation newReservation = (NewReservation) entity;
-    Assert.assertNotNull(newReservation);
-    Assert.assertTrue(newReservation.getReservationId().contains("reservation"));
-  }
-
-  @Test
-  public void testSubmitReservation() throws Exception {
-
-    // submit reservation
-    ReservationId reservationId = ReservationId.newInstance(Time.now(), 2);
-    Response response = submitReservation(reservationId);
-    Assert.assertNotNull(response);
-    Assert.assertEquals(Status.ACCEPTED.getStatusCode(), response.getStatus());
-
-    String applyReservationId = reservationId.toString();
-    Response reservationResponse = interceptor.listReservation(
-        QUEUE_DEDICATED_FULL, applyReservationId, -1, -1, false, null);
-    Assert.assertNotNull(reservationResponse);
-
-    Object entity = reservationResponse.getEntity();
-    Assert.assertNotNull(entity);
-    Assert.assertNotNull(entity instanceof ReservationListInfo);
-
-    Assert.assertTrue(entity instanceof ReservationListInfo);
-    ReservationListInfo listInfo = (ReservationListInfo) entity;
-    Assert.assertNotNull(listInfo);
-
-    List<ReservationInfo> reservationInfos = listInfo.getReservations();
-    Assert.assertNotNull(reservationInfos);
-    Assert.assertEquals(1, reservationInfos.size());
-
-    ReservationInfo reservationInfo = reservationInfos.get(0);
-    Assert.assertNotNull(reservationInfo);
-    Assert.assertEquals(reservationInfo.getReservationId(), applyReservationId);
-  }
-
-  @Test
-  public void testUpdateReservation() throws Exception {
-    // submit reservation
-    ReservationId reservationId = ReservationId.newInstance(Time.now(), 3);
-    Response response = submitReservation(reservationId);
-    Assert.assertNotNull(response);
-    Assert.assertEquals(Status.ACCEPTED.getStatusCode(), response.getStatus());
-
-    // update reservation
-    ReservationSubmissionRequest resSubRequest =
-        getReservationSubmissionRequest(reservationId, 6, 2048, 2);
-    ReservationDefinition reservationDefinition = resSubRequest.getReservationDefinition();
-    ReservationDefinitionInfo reservationDefinitionInfo =
-        new ReservationDefinitionInfo(reservationDefinition);
-
-    ReservationUpdateRequestInfo updateRequestInfo = new ReservationUpdateRequestInfo();
-    updateRequestInfo.setReservationId(reservationId.toString());
-    updateRequestInfo.setReservationDefinition(reservationDefinitionInfo);
-    Response updateReservationResp = interceptor.updateReservation(updateRequestInfo, null);
-    Assert.assertNotNull(updateReservationResp);
-    Assert.assertEquals(Status.OK.getStatusCode(), updateReservationResp.getStatus());
-
-    String applyReservationId = reservationId.toString();
-    Response reservationResponse = interceptor.listReservation(
-            QUEUE_DEDICATED_FULL, applyReservationId, -1, -1, false, null);
-    Assert.assertNotNull(reservationResponse);
-
-    Object entity = reservationResponse.getEntity();
-    Assert.assertNotNull(entity);
-    Assert.assertNotNull(entity instanceof ReservationListInfo);
-
-    Assert.assertTrue(entity instanceof ReservationListInfo);
-    ReservationListInfo listInfo = (ReservationListInfo) entity;
-    Assert.assertNotNull(listInfo);
-
-    List<ReservationInfo> reservationInfos = listInfo.getReservations();
-    Assert.assertNotNull(reservationInfos);
-    Assert.assertEquals(1, reservationInfos.size());
-
-    ReservationInfo reservationInfo = reservationInfos.get(0);
-    Assert.assertNotNull(reservationInfo);
-    Assert.assertEquals(reservationInfo.getReservationId(), applyReservationId);
-
-    ReservationDefinitionInfo resDefinitionInfo = reservationInfo.getReservationDefinition();
-    Assert.assertNotNull(resDefinitionInfo);
-
-    ReservationRequestsInfo reservationRequestsInfo = resDefinitionInfo.getReservationRequests();
-    Assert.assertNotNull(reservationRequestsInfo);
-
-    ArrayList<ReservationRequestInfo> reservationRequestInfoList =
-            reservationRequestsInfo.getReservationRequest();
-    Assert.assertNotNull(reservationRequestInfoList);
-    Assert.assertEquals(1, reservationRequestInfoList.size());
-
-    ReservationRequestInfo reservationRequestInfo = reservationRequestInfoList.get(0);
-    Assert.assertNotNull(reservationRequestInfo);
-    Assert.assertEquals(6, reservationRequestInfo.getNumContainers());
-
-    ResourceInfo resourceInfo = reservationRequestInfo.getCapability();
-    Assert.assertNotNull(resourceInfo);
-
-    int vCore = resourceInfo.getvCores();
-    long memory = resourceInfo.getMemorySize();
-    Assert.assertEquals(2, vCore);
-    Assert.assertEquals(2048, memory);
-  }
-
-  @Test
-  public void testDeleteReservation() throws Exception {
-    // submit reservation
-    ReservationId reservationId = ReservationId.newInstance(Time.now(), 4);
-    Response response = submitReservation(reservationId);
-    Assert.assertNotNull(response);
-    Assert.assertEquals(Status.ACCEPTED.getStatusCode(), response.getStatus());
-
-    String applyResId = reservationId.toString();
-    Response reservationResponse = interceptor.listReservation(
-        QUEUE_DEDICATED_FULL, applyResId, -1, -1, false, null);
-    Assert.assertNotNull(reservationResponse);
-
-    ReservationDeleteRequestInfo deleteRequestInfo =
-        new ReservationDeleteRequestInfo();
-    deleteRequestInfo.setReservationId(applyResId);
-    Response delResponse = interceptor.deleteReservation(deleteRequestInfo, null);
-    Assert.assertNotNull(delResponse);
-
-    LambdaTestUtils.intercept(Exception.class,
-        "reservationId with id: " + reservationId + " not found",
-        () -> interceptor.listReservation(QUEUE_DEDICATED_FULL, applyResId, -1, -1, false, null));
-  }
-
-  private Response submitReservation(ReservationId reservationId)
-       throws IOException, InterruptedException {
-    ReservationSubmissionRequestInfo resSubmissionRequestInfo =
-        getReservationSubmissionRequestInfo(reservationId);
-    return interceptor.submitReservation(resSubmissionRequestInfo, null);
-  }
-
-  public static ReservationSubmissionRequestInfo getReservationSubmissionRequestInfo(
-      ReservationId reservationId) {
-
-    ReservationSubmissionRequest resSubRequest =
-        getReservationSubmissionRequest(reservationId, NUM_CONTAINERS, 1024, 1);
-    ReservationDefinition reservationDefinition = resSubRequest.getReservationDefinition();
-
-    ReservationSubmissionRequestInfo resSubmissionRequestInfo =
-        new ReservationSubmissionRequestInfo();
-    resSubmissionRequestInfo.setQueue(resSubRequest.getQueue());
-    resSubmissionRequestInfo.setReservationId(reservationId.toString());
-    ReservationDefinitionInfo reservationDefinitionInfo =
-        new ReservationDefinitionInfo(reservationDefinition);
-    resSubmissionRequestInfo.setReservationDefinition(reservationDefinitionInfo);
-
-    return resSubmissionRequestInfo;
-  }
-
-  public static ReservationSubmissionRequest getReservationSubmissionRequest(
-      ReservationId reservationId, int numContainers, int memory, int vcore) {
-
-    // arrival time from which the resource(s) can be allocated.
-    long arrival = Time.now();
-
-    // deadline by when the resource(s) must be allocated.
-    // The reason for choosing 1.05 is that this gives an integer
-    // DURATION * 0.05 = 3000(ms)
-    // deadline = arrival + 3000ms
-    long deadline = (long) (arrival + 1.05 * DURATION);
-
-    return createSimpleReservationRequest(
-        reservationId, numContainers, arrival, deadline, DURATION, memory, vcore);
-  }
-
-  public static ReservationSubmissionRequest createSimpleReservationRequest(
-      ReservationId reservationId, int numContainers, long arrival,
-      long deadline, long duration, int memory, int vcore) {
-    // create a request with a single atomic ask
-    ReservationRequest r = ReservationRequest.newInstance(
-        Resource.newInstance(memory, vcore), numContainers, 1, duration);
-    ReservationRequests reqs = ReservationRequests.newInstance(
-        Collections.singletonList(r), ReservationRequestInterpreter.R_ALL);
-    ReservationDefinition rDef = ReservationDefinition.newInstance(
-        arrival, deadline, reqs, "testClientRMService#reservation", "0", Priority.UNDEFINED);
-    return ReservationSubmissionRequest.newInstance(rDef, QUEUE_DEDICATED_FULL, reservationId);
-  }
-
-  @Test
-  public void testWebAddressWithScheme() {
-    // The style of the web address reported by the subCluster in the heartbeat is 0.0.0.0:8000
-    // We design the following 2 test cases:
-    String webAppAddress = "0.0.0.0:8000";
-
-    // 1. We try to disable Https, at this point we should get the following link:
-    // http://0.0.0.0:8000
-    String expectedHttpWebAddress = "http://0.0.0.0:8000";
-    String webAppAddressWithScheme =
-        WebAppUtils.getHttpSchemePrefix(this.getConf()) + webAppAddress;
-    Assert.assertEquals(expectedHttpWebAddress, webAppAddressWithScheme);
-
-    // 2. We try to enable Httpsat this point we should get the following link:
-    // https://0.0.0.0:8000
-    Configuration configuration = this.getConf();
-    configuration.set(YarnConfiguration.YARN_HTTP_POLICY_KEY,
-        HttpConfig.Policy.HTTPS_ONLY.name());
-    String expectedHttpsWebAddress = "https://0.0.0.0:8000";
-    String webAppAddressWithScheme2 =
-        WebAppUtils.getHttpSchemePrefix(this.getConf()) + webAppAddress;
-    Assert.assertEquals(expectedHttpsWebAddress, webAppAddressWithScheme2);
-  }
-
-  @Test
-  public void testCheckUserAccessToQueue() throws Exception {
-
-    interceptor.setAllowPartialResult(false);
-
-    // Case 1: Only queue admin user can access other user's information
-    HttpServletRequest mockHsr = mockHttpServletRequestByUserName("non-admin");
-    String errorMsg1 = "User=non-admin doesn't haven access to queue=queue " +
-        "so it cannot check ACLs for other users.";
-    LambdaTestUtils.intercept(YarnRuntimeException.class, errorMsg1,
-        () -> interceptor.checkUserAccessToQueue("queue", "jack",
-        QueueACL.SUBMIT_APPLICATIONS.name(), mockHsr));
-
-    // Case 2: request an unknown ACL causes BAD_REQUEST
-    HttpServletRequest mockHsr1 = mockHttpServletRequestByUserName("admin");
-    String errorMsg2 = "Specified queueAclType=XYZ_ACL is not a valid type, " +
-        "valid queue acl types={SUBMIT_APPLICATIONS/ADMINISTER_QUEUE}";
-    LambdaTestUtils.intercept(YarnRuntimeException.class, errorMsg2,
-        () -> interceptor.checkUserAccessToQueue("queue", "jack", "XYZ_ACL", mockHsr1));
-
-    // We design a test, admin user has ADMINISTER_QUEUE, SUBMIT_APPLICATIONS permissions,
-    // yarn user has SUBMIT_APPLICATIONS permissions, other users have no permissions
-
-    // Case 3: get FORBIDDEN for rejected ACL
-    checkUserAccessToQueueFailed("queue", "jack", QueueACL.SUBMIT_APPLICATIONS, "admin");
-    checkUserAccessToQueueFailed("queue", "jack", QueueACL.ADMINISTER_QUEUE, "admin");
-
-    // Case 4: get OK for listed ACLs
-    checkUserAccessToQueueSuccess("queue", "admin", QueueACL.ADMINISTER_QUEUE, "admin");
-    checkUserAccessToQueueSuccess("queue", "admin", QueueACL.SUBMIT_APPLICATIONS, "admin");
-
-    // Case 5: get OK only for SUBMIT_APP acl for "yarn" user
-    checkUserAccessToQueueFailed("queue", "yarn", QueueACL.ADMINISTER_QUEUE, "admin");
-    checkUserAccessToQueueSuccess("queue", "yarn", QueueACL.SUBMIT_APPLICATIONS, "admin");
-
-    interceptor.setAllowPartialResult(true);
-  }
-
-  private void checkUserAccessToQueueSuccess(String queue, String userName,
-      QueueACL queueACL, String mockUser) throws AuthorizationException {
-    HttpServletRequest mockHsr = mockHttpServletRequestByUserName(mockUser);
-    RMQueueAclInfo aclInfo =
-        interceptor.checkUserAccessToQueue(queue, userName, queueACL.name(), mockHsr);
-    Assert.assertNotNull(aclInfo);
-    Assert.assertTrue(aclInfo instanceof FederationRMQueueAclInfo);
-    FederationRMQueueAclInfo fedAclInfo = (FederationRMQueueAclInfo) aclInfo;
-    List<RMQueueAclInfo> aclInfos = fedAclInfo.getList();
-    Assert.assertNotNull(aclInfos);
-    Assert.assertEquals(4, aclInfos.size());
-    for (RMQueueAclInfo rMQueueAclInfo : aclInfos) {
-      Assert.assertTrue(rMQueueAclInfo.isAllowed());
-    }
-  }
-
-  private void checkUserAccessToQueueFailed(String queue, String userName,
-      QueueACL queueACL, String mockUser) throws AuthorizationException {
-    HttpServletRequest mockHsr = mockHttpServletRequestByUserName(mockUser);
-    RMQueueAclInfo aclInfo =
-        interceptor.checkUserAccessToQueue(queue, userName, queueACL.name(), mockHsr);
-    Assert.assertNotNull(aclInfo);
-    Assert.assertTrue(aclInfo instanceof FederationRMQueueAclInfo);
-    FederationRMQueueAclInfo fedAclInfo = (FederationRMQueueAclInfo) aclInfo;
-    List<RMQueueAclInfo> aclInfos = fedAclInfo.getList();
-    Assert.assertNotNull(aclInfos);
-    Assert.assertEquals(4, aclInfos.size());
-    for (RMQueueAclInfo rMQueueAclInfo : aclInfos) {
-      Assert.assertFalse(rMQueueAclInfo.isAllowed());
-      String expectDiagnostics = "User=" + userName +
-          " doesn't have access to queue=queue with acl-type=" + queueACL.name();
-      Assert.assertEquals(expectDiagnostics, rMQueueAclInfo.getDiagnostics());
-    }
-  }
-
-  private HttpServletRequest mockHttpServletRequestByUserName(String username) {
-    HttpServletRequest mockHsr = mock(HttpServletRequest.class);
-    when(mockHsr.getRemoteUser()).thenReturn(username);
-    Principal principal = mock(Principal.class);
-    when(principal.getName()).thenReturn(username);
-    when(mockHsr.getUserPrincipal()).thenReturn(principal);
-    return mockHsr;
-  }
-
-  @Test
-  public void testCheckFederationInterceptorRESTClient() {
-    SubClusterId subClusterId = SubClusterId.newInstance("SC-1");
-    String webAppSocket = "SC-1:WebAddress";
-    String webAppAddress = "http://" + webAppSocket;
-
-    Configuration configuration = new Configuration();
-    FederationInterceptorREST rest = new FederationInterceptorREST();
-    rest.setConf(configuration);
-    rest.init("router");
-
-    DefaultRequestInterceptorREST interceptorREST =
-        rest.getOrCreateInterceptorForSubCluster(subClusterId, webAppSocket);
-
-    Assert.assertNotNull(interceptorREST);
-    Assert.assertNotNull(interceptorREST.getClient());
-    Assert.assertEquals(webAppAddress, interceptorREST.getWebAppAddress());
-  }
-
-  @Test
-  public void testInvokeConcurrent() throws IOException, YarnException {
-
-    // We design such a test case, we call the interceptor's getNodes interface,
-    // this interface will generate the following test data
-    // subCluster0 Node 0
-    // subCluster1 Node 1
-    // subCluster2 Node 2
-    // subCluster3 Node 3
-    // We use the returned data to verify whether the subClusterId
-    // of the multi-thread call can match the node data
-    Map<SubClusterInfo, NodesInfo> subClusterInfoNodesInfoMap =
-        interceptor.invokeConcurrentGetNodeLabel();
-    Assert.assertNotNull(subClusterInfoNodesInfoMap);
-    Assert.assertEquals(4, subClusterInfoNodesInfoMap.size());
-
-    subClusterInfoNodesInfoMap.forEach((subClusterInfo, nodesInfo) -> {
-      String subClusterId = subClusterInfo.getSubClusterId().getId();
-      List<NodeInfo> nodeInfos = nodesInfo.getNodes();
-      Assert.assertNotNull(nodeInfos);
-      Assert.assertEquals(1, nodeInfos.size());
-
-      String expectNodeId = "Node " + subClusterId;
-      String nodeId = nodeInfos.get(0).getNodeId();
-      Assert.assertEquals(expectNodeId, nodeId);
-    });
-  }
-
-  @Test
-  public void testGetSchedulerInfo() {
-    // In this test case, we will get the return results of 4 sub-clusters.
-    SchedulerTypeInfo typeInfo = interceptor.getSchedulerInfo();
-    Assert.assertNotNull(typeInfo);
-    Assert.assertTrue(typeInfo instanceof FederationSchedulerTypeInfo);
-
-    FederationSchedulerTypeInfo federationSchedulerTypeInfo =
-        (FederationSchedulerTypeInfo) typeInfo;
-    Assert.assertNotNull(federationSchedulerTypeInfo);
-    List<SchedulerTypeInfo> schedulerTypeInfos = federationSchedulerTypeInfo.getList();
-    Assert.assertNotNull(schedulerTypeInfos);
-    Assert.assertEquals(4, schedulerTypeInfos.size());
-    List<String> subClusterIds = subClusters.stream().map(SubClusterId::getId).
-        collect(Collectors.toList());
-
-    for (SchedulerTypeInfo schedulerTypeInfo : schedulerTypeInfos) {
-      Assert.assertNotNull(schedulerTypeInfo);
-
-      // 1. Whether the returned subClusterId is in the subCluster list
-      String subClusterId = schedulerTypeInfo.getSubClusterId();
-      Assert.assertTrue(subClusterIds.contains(subClusterId));
-
-      // 2. We test CapacityScheduler, the returned type should be CapacityScheduler.
-      SchedulerInfo schedulerInfo = schedulerTypeInfo.getSchedulerInfo();
-      Assert.assertNotNull(schedulerInfo);
-      Assert.assertTrue(schedulerInfo instanceof CapacitySchedulerInfo);
-      CapacitySchedulerInfo capacitySchedulerInfo = (CapacitySchedulerInfo) schedulerInfo;
-      Assert.assertNotNull(capacitySchedulerInfo);
-
-      // 3. The parent queue name should be root
-      String queueName = capacitySchedulerInfo.getQueueName();
-      Assert.assertEquals("root", queueName);
-
-      // 4. schedulerType should be CapacityScheduler
-      String schedulerType = capacitySchedulerInfo.getSchedulerType();
-      Assert.assertEquals("Capacity Scheduler", schedulerType);
-
-      // 5. queue path should be root
-      String queuePath = capacitySchedulerInfo.getQueuePath();
-      Assert.assertEquals("root", queuePath);
-
-      // 6. mockRM has 2 test queues, [root.a, root.b]
-      List<String> queues = Lists.newArrayList("root.a", "root.b");
-      CapacitySchedulerQueueInfoList csSchedulerQueueInfoList = capacitySchedulerInfo.getQueues();
-      Assert.assertNotNull(csSchedulerQueueInfoList);
-      List<CapacitySchedulerQueueInfo> csQueueInfoList =
-          csSchedulerQueueInfoList.getQueueInfoList();
-      Assert.assertEquals(2, csQueueInfoList.size());
-      for (CapacitySchedulerQueueInfo csQueueInfo : csQueueInfoList) {
-        Assert.assertNotNull(csQueueInfo);
-        Assert.assertTrue(queues.contains(csQueueInfo.getQueuePath()));
-      }
-    }
-  }
-
-  @Test
-  public void testPostDelegationTokenErrorHsr() throws Exception {
-    // Prepare delegationToken data
-    DelegationToken token = new DelegationToken();
-    token.setRenewer(TEST_RENEWER);
-
-    HttpServletRequest request = mock(HttpServletRequest.class);
-
-    // If we don't set token
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "Parameter error, the tokenData or hsr is null.",
-        () -> interceptor.postDelegationToken(null, request));
-
-    // If we don't set hsr
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "Parameter error, the tokenData or hsr is null.",
-        () -> interceptor.postDelegationToken(token, null));
-
-    // If we don't set renewUser, we will get error message.
-    LambdaTestUtils.intercept(AuthorizationException.class,
-        "Unable to obtain user name, user not authenticated",
-        () -> interceptor.postDelegationToken(token, request));
-
-    Principal principal = mock(Principal.class);
-    when(principal.getName()).thenReturn(TEST_RENEWER);
-    when(request.getRemoteUser()).thenReturn(TEST_RENEWER);
-    when(request.getUserPrincipal()).thenReturn(principal);
-
-    // If we don't set the authentication type, we will get error message.
-    Response response = interceptor.postDelegationToken(token, request);
-    Assert.assertNotNull(response);
-    Assert.assertEquals(response.getStatus(), Status.FORBIDDEN.getStatusCode());
-    String errMsg = "Delegation token operations can only be carried out on a " +
-        "Kerberos authenticated channel. Expected auth type is kerberos, got type null";
-    Object entity = response.getEntity();
-    Assert.assertNotNull(entity);
-    Assert.assertTrue(entity instanceof String);
-    String entityMsg = String.valueOf(entity);
-    Assert.assertTrue(errMsg.contains(entityMsg));
-  }
-
-  @Test
-  public void testPostDelegationToken() throws Exception {
-    Long now = Time.now();
-
-    DelegationToken token = new DelegationToken();
-    token.setRenewer(TEST_RENEWER);
-
-    Principal principal = mock(Principal.class);
-    when(principal.getName()).thenReturn(TEST_RENEWER);
-
-    HttpServletRequest request = mock(HttpServletRequest.class);
-    when(request.getRemoteUser()).thenReturn(TEST_RENEWER);
-    when(request.getUserPrincipal()).thenReturn(principal);
-    when(request.getAuthType()).thenReturn("kerberos");
-
-    Response response = interceptor.postDelegationToken(token, request);
-    Assert.assertNotNull(response);
-
-    Object entity = response.getEntity();
-    Assert.assertNotNull(entity);
-    Assert.assertTrue(entity instanceof DelegationToken);
-
-    DelegationToken dtoken = (DelegationToken) entity;
-    Assert.assertEquals(TEST_RENEWER, dtoken.getRenewer());
-    Assert.assertEquals(TEST_RENEWER, dtoken.getOwner());
-    Assert.assertEquals("RM_DELEGATION_TOKEN", dtoken.getKind());
-    Assert.assertNotNull(dtoken.getToken());
-    Assert.assertTrue(dtoken.getNextExpirationTime() > now);
-  }
-
-  @Test
-  public void testPostDelegationTokenExpirationError() throws Exception {
-
-    // If we don't set hsr
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "Parameter error, the hsr is null.",
-        () -> interceptor.postDelegationTokenExpiration(null));
-
-    Principal principal = mock(Principal.class);
-    when(principal.getName()).thenReturn(TEST_RENEWER);
-
-    HttpServletRequest request = mock(HttpServletRequest.class);
-    when(request.getRemoteUser()).thenReturn(TEST_RENEWER);
-    when(request.getUserPrincipal()).thenReturn(principal);
-    when(request.getAuthType()).thenReturn("kerberos");
-
-    // If we don't set the header.
-    String errorMsg = "Header 'Hadoop-YARN-RM-Delegation-Token' containing encoded token not found";
-    LambdaTestUtils.intercept(BadRequestException.class, errorMsg,
-        () -> interceptor.postDelegationTokenExpiration(request));
-  }
-
-  @Test
-  public void testPostDelegationTokenExpiration() throws Exception {
-
-    DelegationToken token = new DelegationToken();
-    token.setRenewer(TEST_RENEWER);
-
-    Principal principal = mock(Principal.class);
-    when(principal.getName()).thenReturn(TEST_RENEWER);
-
-    HttpServletRequest request = mock(HttpServletRequest.class);
-    when(request.getRemoteUser()).thenReturn(TEST_RENEWER);
-    when(request.getUserPrincipal()).thenReturn(principal);
-    when(request.getAuthType()).thenReturn("kerberos");
-
-    Response response = interceptor.postDelegationToken(token, request);
-    Assert.assertNotNull(response);
-    Object entity = response.getEntity();
-    Assert.assertNotNull(entity);
-    Assert.assertTrue(entity instanceof DelegationToken);
-    DelegationToken dtoken = (DelegationToken) entity;
-
-    final String yarnTokenHeader = "Hadoop-YARN-RM-Delegation-Token";
-    when(request.getHeader(yarnTokenHeader)).thenReturn(dtoken.getToken());
-
-    Response renewResponse = interceptor.postDelegationTokenExpiration(request);
-    Assert.assertNotNull(renewResponse);
-
-    Object renewEntity = renewResponse.getEntity();
-    Assert.assertNotNull(renewEntity);
-    Assert.assertTrue(renewEntity instanceof DelegationToken);
-
-    // renewDelegation, we only return renewDate, other values are NULL.
-    DelegationToken renewDToken = (DelegationToken) renewEntity;
-    Assert.assertNull(renewDToken.getRenewer());
-    Assert.assertNull(renewDToken.getOwner());
-    Assert.assertNull(renewDToken.getKind());
-    Assert.assertTrue(renewDToken.getNextExpirationTime() > dtoken.getNextExpirationTime());
-  }
-
-  @Test
-  public void testCancelDelegationToken() throws Exception {
-    DelegationToken token = new DelegationToken();
-    token.setRenewer(TEST_RENEWER);
-
-    Principal principal = mock(Principal.class);
-    when(principal.getName()).thenReturn(TEST_RENEWER);
-
-    HttpServletRequest request = mock(HttpServletRequest.class);
-    when(request.getRemoteUser()).thenReturn(TEST_RENEWER);
-    when(request.getUserPrincipal()).thenReturn(principal);
-    when(request.getAuthType()).thenReturn("kerberos");
-
-    Response response = interceptor.postDelegationToken(token, request);
-    Assert.assertNotNull(response);
-    Object entity = response.getEntity();
-    Assert.assertNotNull(entity);
-    Assert.assertTrue(entity instanceof DelegationToken);
-    DelegationToken dtoken = (DelegationToken) entity;
-
-    final String yarnTokenHeader = "Hadoop-YARN-RM-Delegation-Token";
-    when(request.getHeader(yarnTokenHeader)).thenReturn(dtoken.getToken());
-
-    Response cancelResponse = interceptor.cancelDelegationToken(request);
-    Assert.assertNotNull(cancelResponse);
-    Assert.assertEquals(response.getStatus(), Status.OK.getStatusCode());
-  }
-
-  @Test
-  public void testReplaceLabelsOnNodes() throws Exception {
-    // subCluster0 -> node0:0 -> label:NodeLabel0
-    // subCluster1 -> node1:1 -> label:NodeLabel1
-    // subCluster2 -> node2:2 -> label:NodeLabel2
-    // subCluster3 -> node3:3 -> label:NodeLabel3
-    NodeToLabelsEntryList nodeToLabelsEntryList = new NodeToLabelsEntryList();
-    for (int i = 0; i < NUM_SUBCLUSTER; i++) {
-      // labels
-      List<String> labels = new ArrayList<>();
-      labels.add("NodeLabel" + i);
-      // nodes
-      String nodeId = "node" + i + ":" + i;
-      NodeToLabelsEntry nodeToLabelsEntry = new NodeToLabelsEntry(nodeId, labels);
-      List<NodeToLabelsEntry> nodeToLabelsEntries = nodeToLabelsEntryList.getNodeToLabels();
-      nodeToLabelsEntries.add(nodeToLabelsEntry);
-    }
-
-    // one of the results:
-    // subCluster#0:Success;subCluster#1:Success;subCluster#3:Success;subCluster#2:Success;
-    // We can't confirm the complete return order.
-    Response response = interceptor.replaceLabelsOnNodes(nodeToLabelsEntryList, null);
-    Assert.assertNotNull(response);
-    Assert.assertEquals(200, response.getStatus());
-
-    Object entityObject = response.getEntity();
-    Assert.assertNotNull(entityObject);
-
-    String entityValue = String.valueOf(entityObject);
-    String[] entities = entityValue.split(",");
-    Assert.assertNotNull(entities);
-    Assert.assertEquals(4, entities.length);
-    String expectValue =
-        "subCluster-0:Success,subCluster-1:Success,subCluster-2:Success,subCluster-3:Success,";
-    for (String entity : entities) {
-      Assert.assertTrue(expectValue.contains(entity));
-    }
-  }
-
-  @Test
-  public void testReplaceLabelsOnNodesError() throws Exception {
-    // newNodeToLabels is null
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "Parameter error, newNodeToLabels must not be empty.",
-        () -> interceptor.replaceLabelsOnNodes(null, null));
-
-    // nodeToLabelsEntryList is Empty
-    NodeToLabelsEntryList nodeToLabelsEntryList = new NodeToLabelsEntryList();
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "Parameter error, nodeToLabelsEntries must not be empty.",
-        () -> interceptor.replaceLabelsOnNodes(nodeToLabelsEntryList, null));
-  }
-
-  @Test
-  public void testReplaceLabelsOnNode() throws Exception {
-    // subCluster3 -> node3:3 -> label:NodeLabel3
-    String nodeId = "node3:3";
-    Set<String> labels = Collections.singleton("NodeLabel3");
-
-    // We expect the following result: subCluster#3:Success;
-    String expectValue = "subCluster#3:Success;";
-    Response response = interceptor.replaceLabelsOnNode(labels, null, nodeId);
-    Assert.assertNotNull(response);
-    Assert.assertEquals(200, response.getStatus());
-
-    Object entityObject = response.getEntity();
-    Assert.assertNotNull(entityObject);
-
-    String entityValue = String.valueOf(entityObject);
-    Assert.assertNotNull(entityValue);
-    Assert.assertEquals(expectValue, entityValue);
-  }
-
-  @Test
-  public void testReplaceLabelsOnNodeError() throws Exception {
-    // newNodeToLabels is null
-    String nodeId = "node3:3";
-    Set<String> labels = Collections.singleton("NodeLabel3");
-    Set<String> labelsEmpty = new HashSet<>();
-
-    // nodeId is null
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "Parameter error, nodeId must not be null or empty.",
-        () -> interceptor.replaceLabelsOnNode(labels, null, null));
-
-    // labels is null
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "Parameter error, newNodeLabelsName must not be empty.",
-        () -> interceptor.replaceLabelsOnNode(null, null, nodeId));
-
-    // labels is empty
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "Parameter error, newNodeLabelsName must not be empty.",
-        () -> interceptor.replaceLabelsOnNode(labelsEmpty, null, nodeId));
-  }
-
-  @Test
-  public void testDumpSchedulerLogs() throws Exception {
-    HttpServletRequest mockHsr = mockHttpServletRequestByUserName("admin");
-    String dumpSchedulerLogsMsg = interceptor.dumpSchedulerLogs("1", mockHsr);
-
-    // We cannot guarantee the calling order of the sub-clusters,
-    // We guarantee that the returned result contains the information of each subCluster.
-    Assert.assertNotNull(dumpSchedulerLogsMsg);
-    subClusters.forEach(subClusterId -> {
-      String subClusterMsg =
-          "subClusterId" + subClusterId + " : Capacity scheduler logs are being created.; ";
-      Assert.assertTrue(dumpSchedulerLogsMsg.contains(subClusterMsg));
-    });
-  }
-
-  @Test
-  public void testDumpSchedulerLogsError() throws Exception {
-    HttpServletRequest mockHsr = mockHttpServletRequestByUserName("admin");
-
-    // time is empty
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "Parameter error, the time is empty or null.",
-        () -> interceptor.dumpSchedulerLogs(null, mockHsr));
-
-    // time is negative
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "time must be greater than 0.",
-        () -> interceptor.dumpSchedulerLogs("-1", mockHsr));
-
-    // time is non-numeric
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "time must be a number.",
-        () -> interceptor.dumpSchedulerLogs("abc", mockHsr));
-  }
-
-  @Test
-  public void testGetActivitiesNormal() {
-    ActivitiesInfo activitiesInfo = interceptor.getActivities(null, "1", "DIAGNOSTIC");
-    Assert.assertNotNull(activitiesInfo);
-
-    String nodeId = activitiesInfo.getNodeId();
-    Assert.assertNotNull(nodeId);
-    Assert.assertEquals("1", nodeId);
-
-    String diagnostic = activitiesInfo.getDiagnostic();
-    Assert.assertNotNull(diagnostic);
-    Assert.assertTrue(StringUtils.contains(diagnostic, "Diagnostic"));
-
-    long timestamp = activitiesInfo.getTimestamp();
-    Assert.assertEquals(1673081972L, timestamp);
-
-    List<NodeAllocationInfo> allocationInfos = activitiesInfo.getAllocations();
-    Assert.assertNotNull(allocationInfos);
-    Assert.assertEquals(1, allocationInfos.size());
-  }
-
-  @Test
-  public void testGetActivitiesError() throws Exception {
-    // nodeId is empty
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "'nodeId' must not be empty.",
-        () -> interceptor.getActivities(null, "", "DIAGNOSTIC"));
-
-    // groupBy is empty
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "'groupBy' must not be empty.",
-        () -> interceptor.getActivities(null, "1", ""));
-
-    // groupBy value is wrong
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "Got invalid groupBy: TEST1, valid groupBy types: [DIAGNOSTIC]",
-        () -> interceptor.getActivities(null, "1", "TEST1"));
-  }
-
-  @Test
-  public void testGetBulkActivitiesNormal() throws InterruptedException {
-    BulkActivitiesInfo bulkActivitiesInfo =
-        interceptor.getBulkActivities(null, "DIAGNOSTIC", 5);
-    Assert.assertNotNull(bulkActivitiesInfo);
-
-    Assert.assertTrue(bulkActivitiesInfo instanceof FederationBulkActivitiesInfo);
-
-    FederationBulkActivitiesInfo federationBulkActivitiesInfo =
-        (FederationBulkActivitiesInfo) bulkActivitiesInfo;
-    Assert.assertNotNull(federationBulkActivitiesInfo);
-
-    List<BulkActivitiesInfo> activitiesInfos = federationBulkActivitiesInfo.getList();
-    Assert.assertNotNull(activitiesInfos);
-    Assert.assertEquals(4, activitiesInfos.size());
-
-    for (BulkActivitiesInfo activitiesInfo : activitiesInfos) {
-      Assert.assertNotNull(activitiesInfo);
-      List<ActivitiesInfo> activitiesInfoList = activitiesInfo.getActivities();
-      Assert.assertNotNull(activitiesInfoList);
-      Assert.assertEquals(5, activitiesInfoList.size());
-    }
-  }
-
-  @Test
-  public void testGetBulkActivitiesError() throws Exception {
-    // activitiesCount < 0
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "'activitiesCount' must not be negative.",
-        () -> interceptor.getBulkActivities(null, "DIAGNOSTIC", -1));
-
-    // groupBy value is wrong
-    LambdaTestUtils.intercept(YarnRuntimeException.class,
-        "Got invalid groupBy: TEST1, valid groupBy types: [DIAGNOSTIC]",
-        () -> interceptor.getBulkActivities(null, "TEST1", 1));
-
-    // groupBy is empty
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "'groupBy' must not be empty.",
-        () -> interceptor.getBulkActivities(null, "", 1));
-  }
-
-  @Test
-  public void testAddToClusterNodeLabels1() throws Exception {
-    // In this test, we try to add ALL label, all subClusters will return success.
-    NodeLabelsInfo nodeLabelsInfo = new NodeLabelsInfo();
-    NodeLabelInfo nodeLabelInfo = new NodeLabelInfo("ALL", true);
-    nodeLabelsInfo.getNodeLabelsInfo().add(nodeLabelInfo);
-
-    Response response = interceptor.addToClusterNodeLabels(nodeLabelsInfo, null);
-    Assert.assertNotNull(response);
-
-    Object entityObj = response.getEntity();
-    Assert.assertNotNull(entityObj);
-
-    String entity = String.valueOf(entityObj);
-    String[] entities = StringUtils.split(entity, ",");
-    Assert.assertNotNull(entities);
-    Assert.assertEquals(4, entities.length);
-
-    // The order in which the cluster returns messages is uncertain,
-    // we confirm the result by contains
-    String expectedMsg =
-        "SubCluster-0:SUCCESS,SubCluster-1:SUCCESS,SubCluster-2:SUCCESS,SubCluster-3:SUCCESS";
-    Arrays.stream(entities).forEach(item -> Assert.assertTrue(expectedMsg.contains(item)));
-  }
-
-  @Test
-  public void testAddToClusterNodeLabels2() throws Exception {
-    // In this test, we try to add A0 label,
-    // subCluster0 will return success, and other subClusters will return null
-    NodeLabelsInfo nodeLabelsInfo = new NodeLabelsInfo();
-    NodeLabelInfo nodeLabelInfo = new NodeLabelInfo("A0", true);
-    nodeLabelsInfo.getNodeLabelsInfo().add(nodeLabelInfo);
-
-    Response response = interceptor.addToClusterNodeLabels(nodeLabelsInfo, null);
-    Assert.assertNotNull(response);
-
-    Object entityObj = response.getEntity();
-    Assert.assertNotNull(entityObj);
-
-    String expectedValue = "SubCluster-0:SUCCESS,";
-    String entity = String.valueOf(entityObj);
-    Assert.assertTrue(entity.contains(expectedValue));
-  }
-
-  @Test
-  public void testAddToClusterNodeLabelsError() throws Exception {
-    // the newNodeLabels is null
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "Parameter error, the newNodeLabels is null.",
-        () -> interceptor.addToClusterNodeLabels(null, null));
-
-    // the nodeLabelsInfo is null
-    NodeLabelsInfo nodeLabelsInfo = new NodeLabelsInfo();
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "Parameter error, the nodeLabelsInfo is null or empty.",
-        () -> interceptor.addToClusterNodeLabels(nodeLabelsInfo, null));
-
-    // error nodeLabelsInfo
-    NodeLabelsInfo nodeLabelsInfo1 = new NodeLabelsInfo();
-    NodeLabelInfo nodeLabelInfo1 = new NodeLabelInfo("A", true);
-    nodeLabelsInfo1.getNodeLabelsInfo().add(nodeLabelInfo1);
-    LambdaTestUtils.intercept(YarnRuntimeException.class, "addToClusterNodeLabels Error",
-        () -> interceptor.addToClusterNodeLabels(nodeLabelsInfo1, null));
-  }
-
-  @Test
-  public void testRemoveFromClusterNodeLabels1() throws Exception {
-    Set<String> oldNodeLabels = Sets.newHashSet();
-    oldNodeLabels.add("ALL");
-
-    Response response = interceptor.removeFromClusterNodeLabels(oldNodeLabels, null);
-    Assert.assertNotNull(response);
-
-    Object entityObj = response.getEntity();
-    Assert.assertNotNull(entityObj);
-
-    String entity = String.valueOf(entityObj);
-    String[] entities = StringUtils.split(entity, ",");
-    Assert.assertNotNull(entities);
-    Assert.assertEquals(4, entities.length);
-
-    // The order in which the cluster returns messages is uncertain,
-    // we confirm the result by contains
-    String expectedMsg =
-        "SubCluster-0:SUCCESS,SubCluster-1:SUCCESS,SubCluster-2:SUCCESS,SubCluster-3:SUCCESS";
-    Arrays.stream(entities).forEach(item -> Assert.assertTrue(expectedMsg.contains(item)));
-  }
-
-  @Test
-  public void testRemoveFromClusterNodeLabels2() throws Exception {
-    Set<String> oldNodeLabels = Sets.newHashSet();
-    oldNodeLabels.add("A0");
-
-    Response response = interceptor.removeFromClusterNodeLabels(oldNodeLabels, null);
-    Assert.assertNotNull(response);
-
-    Object entityObj = response.getEntity();
-    Assert.assertNotNull(entityObj);
-
-    String expectedValue = "SubCluster-0:SUCCESS,";
-    String entity = String.valueOf(entityObj);
-    Assert.assertTrue(entity.contains(expectedValue));
-  }
-
-  @Test
-  public void testRemoveFromClusterNodeLabelsError() throws Exception {
-    // the oldNodeLabels is null
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "Parameter error, the oldNodeLabels is null or empty.",
-        () -> interceptor.removeFromClusterNodeLabels(null, null));
-
-    // the oldNodeLabels is empty
-    Set<String> oldNodeLabels = Sets.newHashSet();
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "Parameter error, the oldNodeLabels is null or empty.",
-        () -> interceptor.removeFromClusterNodeLabels(oldNodeLabels, null));
-
-    // error oldNodeLabels
-    Set<String> oldNodeLabels1 = Sets.newHashSet();
-    oldNodeLabels1.add("A1");
-    LambdaTestUtils.intercept(YarnRuntimeException.class, "removeFromClusterNodeLabels Error",
-        () -> interceptor.removeFromClusterNodeLabels(oldNodeLabels1, null));
-  }
-
-  @Test
-  public void testGetSchedulerConfiguration() throws Exception {
-    Response response = interceptor.getSchedulerConfiguration(null);
-    Assert.assertNotNull(response);
-    Assert.assertEquals(OK, response.getStatus());
-
-    Object entity = response.getEntity();
-    Assert.assertNotNull(entity);
-    Assert.assertTrue(entity instanceof FederationConfInfo);
-
-    FederationConfInfo federationConfInfo = FederationConfInfo.class.cast(entity);
-    List<ConfInfo> confInfos = federationConfInfo.getList();
-    Assert.assertNotNull(confInfos);
-    Assert.assertEquals(4, confInfos.size());
-
-    List<String> errors = federationConfInfo.getErrorMsgs();
-    Assert.assertEquals(0, errors.size());
-
-    Set<String> subClusterSet = subClusters.stream()
-        .map(subClusterId -> subClusterId.getId()).collect(Collectors.toSet());
-
-    for (ConfInfo confInfo : confInfos) {
-      List<ConfInfo.ConfItem> confItems = confInfo.getItems();
-      Assert.assertNotNull(confItems);
-      Assert.assertTrue(confItems.size() > 0);
-      Assert.assertTrue(subClusterSet.contains(confInfo.getSubClusterId()));
-    }
-  }
-
-  @Test
-  public void testGetClusterUserInfo() {
-    String requestUserName = "test-user";
-    HttpServletRequest hsr = mock(HttpServletRequest.class);
-    when(hsr.getRemoteUser()).thenReturn(requestUserName);
-    ClusterUserInfo clusterUserInfo = interceptor.getClusterUserInfo(hsr);
-
-    Assert.assertNotNull(clusterUserInfo);
-    Assert.assertTrue(clusterUserInfo instanceof FederationClusterUserInfo);
-
-    FederationClusterUserInfo federationClusterUserInfo =
-        (FederationClusterUserInfo) clusterUserInfo;
-
-    List<ClusterUserInfo> fedClusterUserInfoList = federationClusterUserInfo.getList();
-    Assert.assertNotNull(fedClusterUserInfoList);
-    Assert.assertEquals(4, fedClusterUserInfoList.size());
-
-    List<String> subClusterIds = subClusters.stream().map(
-        subClusterId -> subClusterId.getId()).collect(Collectors.toList());
-    MockRM mockRM = interceptor.getMockRM();
-
-    for (ClusterUserInfo fedClusterUserInfo : fedClusterUserInfoList) {
-      // Check subClusterId
-      String subClusterId = fedClusterUserInfo.getSubClusterId();
-      Assert.assertNotNull(subClusterId);
-      Assert.assertTrue(subClusterIds.contains(subClusterId));
-
-      // Check requestedUser
-      String requestedUser = fedClusterUserInfo.getRequestedUser();
-      Assert.assertNotNull(requestedUser);
-      Assert.assertEquals(requestUserName, requestedUser);
-
-      // Check rmLoginUser
-      String rmLoginUser = fedClusterUserInfo.getRmLoginUser();
-      Assert.assertNotNull(rmLoginUser);
-      Assert.assertEquals(mockRM.getRMLoginUser(), rmLoginUser);
-    }
-  }
-
-  @Test
-  public void testUpdateSchedulerConfigurationErrorMsg() throws Exception {
-    SchedConfUpdateInfo mutationInfo = new SchedConfUpdateInfo();
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "Parameter error, the subClusterId is empty or null.",
-        () -> interceptor.updateSchedulerConfiguration(mutationInfo, null));
-
-    LambdaTestUtils.intercept(IllegalArgumentException.class,
-        "Parameter error, the schedConfUpdateInfo is empty or null.",
-        () -> interceptor.updateSchedulerConfiguration(null, null));
-  }
-
-  @Test
-  public void testUpdateSchedulerConfiguration()
-      throws AuthorizationException, InterruptedException {
-    SchedConfUpdateInfo updateInfo = new SchedConfUpdateInfo();
-    updateInfo.setSubClusterId("1");
-    Map<String, String> goodUpdateMap = new HashMap<>();
-    goodUpdateMap.put("goodKey", "goodVal");
-    QueueConfigInfo goodUpdateInfo = new
-        QueueConfigInfo("root.default", goodUpdateMap);
-    updateInfo.getUpdateQueueInfo().add(goodUpdateInfo);
-    Response response = interceptor.updateSchedulerConfiguration(updateInfo, null);
-
-    Assert.assertNotNull(response);
-    Assert.assertEquals(OK, response.getStatus());
-
-    String expectMsg = "Configuration change successfully applied.";
-    Object entity = response.getEntity();
-    Assert.assertNotNull(entity);
-
-    String entityMsg = String.valueOf(entity);
-    Assert.assertEquals(expectMsg, entityMsg);
-  }
-
-  @Test
-  public void testGetClusterInfo() {
-    ClusterInfo clusterInfos = interceptor.getClusterInfo();
-    Assert.assertNotNull(clusterInfos);
-    Assert.assertTrue(clusterInfos instanceof FederationClusterInfo);
-
-    FederationClusterInfo federationClusterInfos =
-        (FederationClusterInfo) (clusterInfos);
-
-    List<ClusterInfo> fedClusterInfosList = federationClusterInfos.getList();
-    Assert.assertNotNull(fedClusterInfosList);
-    Assert.assertEquals(4, fedClusterInfosList.size());
-
-    List<String> subClusterIds = subClusters.stream().map(
-        subClusterId -> subClusterId.getId()).collect(Collectors.toList());
-
-    MockRM mockRM = interceptor.getMockRM();
-    String yarnVersion = YarnVersionInfo.getVersion();
-
-    for (ClusterInfo clusterInfo : fedClusterInfosList) {
-      String subClusterId = clusterInfo.getSubClusterId();
-      // Check subClusterId
-      Assert.assertTrue(subClusterIds.contains(subClusterId));
-
-      // Check state
-      String clusterState = mockRM.getServiceState().toString();
-      Assert.assertEquals(clusterState, clusterInfo.getState());
-
-      // Check rmStateStoreName
-      String rmStateStoreName =
-          mockRM.getRMContext().getStateStore().getClass().getName();
-      Assert.assertEquals(rmStateStoreName, clusterInfo.getRMStateStore());
-
-      // Check RM Version
-      Assert.assertEquals(yarnVersion, clusterInfo.getRMVersion());
-
-      // Check haZooKeeperConnectionState
-      String rmHAZookeeperConnectionState = mockRM.getRMContext().getHAZookeeperConnectionState();
-      Assert.assertEquals(rmHAZookeeperConnectionState,
-          clusterInfo.getHAZookeeperConnectionState());
-    }
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestFederationInterceptorRESTRetry.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestFederationInterceptorRESTRetry.java
deleted file mode 100644
index 762a4417980..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestFederationInterceptorRESTRetry.java
+++ /dev/null
@@ -1,581 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.List;
-
-import javax.ws.rs.core.Response;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.test.LambdaTestUtils;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.exceptions.YarnRuntimeException;
-import org.apache.hadoop.yarn.server.federation.policies.FederationPolicyUtils;
-import org.apache.hadoop.yarn.server.federation.policies.manager.UniformBroadcastPolicyManager;
-import org.apache.hadoop.yarn.server.federation.store.impl.MemoryFederationStateStore;
-import org.apache.hadoop.yarn.server.federation.store.records.GetApplicationHomeSubClusterRequest;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreTestUtil;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NewApplication;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodesInfo;
-import org.apache.hadoop.yarn.server.router.clientrm.PassThroughClientRequestInterceptor;
-import org.apache.hadoop.yarn.server.router.clientrm.TestableFederationClientInterceptor;
-import org.apache.hadoop.yarn.webapp.NotFoundException;
-import org.junit.Assert;
-import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * Extends the {@code BaseRouterWebServicesTest} and overrides methods in order
- * to use the {@code RouterWebServices} pipeline test cases for testing the
- * {@code FederationInterceptorREST} class. The tests for
- * {@code RouterWebServices} has been written cleverly so that it can be reused
- * to validate different request interceptor chains.
- * <p>
- * It tests the case with SubClusters down and the Router logic of retries. We
- * have 1 good SubCluster and 2 bad ones for all the tests.
- */
-public class TestFederationInterceptorRESTRetry
-    extends BaseRouterWebServicesTest {
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestFederationInterceptorRESTRetry.class);
-  private static final int SERVICE_UNAVAILABLE = 503;
-  private static final int ACCEPTED = 202;
-  private static final int OK = 200;
-  // running and registered
-  private static SubClusterId good;
-  // registered but not running
-  private static SubClusterId bad1;
-  private static SubClusterId bad2;
-  private static List<SubClusterId> scs = new ArrayList<SubClusterId>();
-  private TestableFederationInterceptorREST interceptor;
-  private MemoryFederationStateStore stateStore;
-  private FederationStateStoreTestUtil stateStoreUtil;
-  private String user = "test-user";
-
-  @Override
-  public void setUp() {
-    super.setUpConfig();
-
-    Configuration conf = this.getConf();
-
-    // Compatible with historical test cases, we set router.allow-partial-result.enable=false.
-    conf.setBoolean(YarnConfiguration.ROUTER_INTERCEPTOR_ALLOW_PARTIAL_RESULT_ENABLED, false);
-
-    interceptor = new TestableFederationInterceptorREST();
-
-    stateStore = new MemoryFederationStateStore();
-    stateStore.init(conf);
-    FederationStateStoreFacade.getInstance(conf).reinitialize(stateStore,
-        getConf());
-    stateStoreUtil = new FederationStateStoreTestUtil(stateStore);
-
-    interceptor.setConf(this.getConf());
-    interceptor.init(user);
-
-    // Create SubClusters
-    good = SubClusterId.newInstance("1");
-    bad1 = SubClusterId.newInstance("2");
-    bad2 = SubClusterId.newInstance("3");
-    scs.add(good);
-    scs.add(bad1);
-    scs.add(bad2);
-
-    // The mock RM will not start in these SubClusters, this is done to simulate
-    // a SubCluster down
-
-    interceptor.registerBadSubCluster(bad1);
-    interceptor.registerBadSubCluster(bad2);
-  }
-
-  @Override
-  public void tearDown() {
-    interceptor.shutdown();
-    super.tearDown();
-  }
-
-  private void setupCluster(List<SubClusterId> scsToRegister)
-      throws YarnException {
-
-    try {
-      // Clean up the StateStore before every test
-      stateStoreUtil.deregisterAllSubClusters();
-
-      for (SubClusterId sc : scsToRegister) {
-        stateStoreUtil.registerSubCluster(sc);
-      }
-    } catch (YarnException e) {
-      LOG.error(e.getMessage());
-      Assert.fail();
-    }
-  }
-
-  @Override
-  protected YarnConfiguration createConfiguration() {
-    YarnConfiguration conf = new YarnConfiguration();
-    conf.setBoolean(YarnConfiguration.FEDERATION_ENABLED, true);
-
-    conf.set(YarnConfiguration.ROUTER_WEBAPP_DEFAULT_INTERCEPTOR_CLASS,
-        MockDefaultRequestInterceptorREST.class.getName());
-
-    String mockPassThroughInterceptorClass =
-        PassThroughClientRequestInterceptor.class.getName();
-
-    // Create a request interceptor pipeline for testing. The last one in the
-    // chain is the federation interceptor that calls the mock resource manager.
-    // The others in the chain will simply forward it to the next one in the
-    // chain
-    conf.set(YarnConfiguration.ROUTER_CLIENTRM_INTERCEPTOR_CLASS_PIPELINE,
-        mockPassThroughInterceptorClass + ","
-            + TestableFederationClientInterceptor.class.getName());
-
-    conf.set(YarnConfiguration.FEDERATION_POLICY_MANAGER,
-        UniformBroadcastPolicyManager.class.getName());
-
-    // Disable StateStoreFacade cache
-    conf.setInt(YarnConfiguration.FEDERATION_CACHE_TIME_TO_LIVE_SECS, 0);
-
-    return conf;
-  }
-
-  /**
-   * This test validates the correctness of GetNewApplication in case the
-   * cluster is composed of only 1 bad SubCluster.
-   */
-  @Test
-  public void testGetNewApplicationOneBadSC()
-      throws YarnException, IOException, InterruptedException {
-
-    setupCluster(Arrays.asList(bad2));
-
-    Response response = interceptor.createNewApplication(null);
-    Assert.assertEquals(SERVICE_UNAVAILABLE, response.getStatus());
-    Assert.assertEquals(FederationPolicyUtils.NO_ACTIVE_SUBCLUSTER_AVAILABLE,
-        response.getEntity());
-  }
-
-  /**
-   * This test validates the correctness of GetNewApplication in case the
-   * cluster is composed of only 2 bad SubClusters.
-   */
-  @Test
-  public void testGetNewApplicationTwoBadSCs()
-      throws YarnException, IOException, InterruptedException {
-
-    LOG.info("Test getNewApplication with two bad SCs.");
-
-    setupCluster(Arrays.asList(bad1, bad2));
-
-    Response response = interceptor.createNewApplication(null);
-    Assert.assertEquals(SERVICE_UNAVAILABLE, response.getStatus());
-    Assert.assertEquals(FederationPolicyUtils.NO_ACTIVE_SUBCLUSTER_AVAILABLE,
-        response.getEntity());
-  }
-
-  /**
-   * This test validates the correctness of GetNewApplication in case the
-   * cluster is composed of only 1 bad SubCluster and 1 good one.
-   */
-  @Test
-  public void testGetNewApplicationOneBadOneGood()
-      throws YarnException, IOException, InterruptedException {
-
-    LOG.info("Test getNewApplication with one bad, one good SC.");
-
-    setupCluster(Arrays.asList(good, bad2));
-    Response response = interceptor.createNewApplication(null);
-    Assert.assertNotNull(response);
-    Assert.assertEquals(OK, response.getStatus());
-
-    NewApplication newApp = (NewApplication) response.getEntity();
-    Assert.assertNotNull(newApp);
-
-    ApplicationId appId = ApplicationId.fromString(newApp.getApplicationId());
-    Assert.assertNotNull(appId);
-
-    Assert.assertEquals(Integer.parseInt(good.getId()), appId.getClusterTimestamp());
-  }
-
-  /**
-   * This test validates the correctness of SubmitApplication in case the
-   * cluster is composed of only 1 bad SubCluster.
-   */
-  @Test
-  public void testSubmitApplicationOneBadSC()
-      throws YarnException, IOException, InterruptedException {
-
-    LOG.info("Test submitApplication with one bad SC.");
-
-    setupCluster(Arrays.asList(bad2));
-
-    ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    ApplicationSubmissionContextInfo context =
-        new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-
-    Response response = interceptor.submitApplication(context, null);
-    Assert.assertEquals(SERVICE_UNAVAILABLE, response.getStatus());
-    Assert.assertEquals(FederationPolicyUtils.NO_ACTIVE_SUBCLUSTER_AVAILABLE,
-        response.getEntity());
-  }
-
-  /**
-   * This test validates the correctness of SubmitApplication in case the
-   * cluster is composed of only 2 bad SubClusters.
-   */
-  @Test
-  public void testSubmitApplicationTwoBadSCs()
-      throws YarnException, IOException, InterruptedException {
-    setupCluster(Arrays.asList(bad1, bad2));
-
-    ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    ApplicationSubmissionContextInfo context =
-        new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-
-    Response response = interceptor.submitApplication(context, null);
-    Assert.assertEquals(SERVICE_UNAVAILABLE, response.getStatus());
-    Assert.assertEquals(FederationPolicyUtils.NO_ACTIVE_SUBCLUSTER_AVAILABLE,
-        response.getEntity());
-  }
-
-  /**
-   * This test validates the correctness of SubmitApplication in case the
-   * cluster is composed of only 1 bad SubCluster and a good one.
-   */
-  @Test
-  public void testSubmitApplicationOneBadOneGood()
-      throws YarnException, IOException, InterruptedException {
-    System.out.println("Test submitApplication with one bad, one good SC");
-    setupCluster(Arrays.asList(good, bad2));
-
-    ApplicationId appId =
-        ApplicationId.newInstance(System.currentTimeMillis(), 1);
-    ApplicationSubmissionContextInfo context =
-        new ApplicationSubmissionContextInfo();
-    context.setApplicationId(appId.toString());
-    Response response = interceptor.submitApplication(context, null);
-
-    Assert.assertEquals(ACCEPTED, response.getStatus());
-
-    Assert.assertEquals(good,
-        stateStore
-            .getApplicationHomeSubCluster(
-                GetApplicationHomeSubClusterRequest.newInstance(appId))
-            .getApplicationHomeSubCluster().getHomeSubCluster());
-  }
-
-  /**
-   * This test validates the correctness of GetApps in case the cluster is
-   * composed of only 1 bad SubCluster.
-   */
-  @Test
-  public void testGetAppsOneBadSC()
-      throws YarnException, IOException, InterruptedException {
-
-    setupCluster(Arrays.asList(bad2));
-
-    AppsInfo response = interceptor.getApps(null, null, null, null, null, null,
-        null, null, null, null, null, null, null, null, null);
-    Assert.assertNull(response);
-  }
-
-  /**
-   * This test validates the correctness of GetApps in case the cluster is
-   * composed of only 2 bad SubClusters.
-   */
-  @Test
-  public void testGetAppsTwoBadSCs()
-      throws YarnException, IOException, InterruptedException {
-    setupCluster(Arrays.asList(bad1, bad2));
-
-    AppsInfo response = interceptor.getApps(null, null, null, null, null, null,
-        null, null, null, null, null, null, null, null, null);
-    Assert.assertNull(response);
-  }
-
-  /**
-   * This test validates the correctness of GetApps in case the cluster is
-   * composed of only 1 bad SubCluster and a good one.
-   */
-  @Test
-  public void testGetAppsOneBadOneGood()
-      throws YarnException, IOException, InterruptedException {
-    setupCluster(Arrays.asList(good, bad2));
-
-    AppsInfo response = interceptor.getApps(null, null, null, null, null, null,
-        null, null, null, null, null, null, null, null, null);
-    Assert.assertNotNull(response);
-    Assert.assertEquals(1, response.getApps().size());
-  }
-
-  /**
-   * This test validates the correctness of GetNode in case the cluster is
-   * composed of only 1 bad SubCluster.
-   */
-  @Test
-  public void testGetNodeOneBadSC()
-      throws YarnException, IOException, InterruptedException {
-
-    setupCluster(Arrays.asList(bad2));
-    try {
-      interceptor.getNode("testGetNodeOneBadSC");
-      Assert.fail();
-    } catch (NotFoundException e) {
-      Assert.assertTrue(
-          e.getMessage().contains("nodeId, testGetNodeOneBadSC, is not found"));
-    }
-  }
-
-  /**
-   * This test validates the correctness of GetNode in case the cluster is
-   * composed of only 2 bad SubClusters.
-   */
-  @Test
-  public void testGetNodeTwoBadSCs()
-      throws YarnException, IOException, InterruptedException {
-    setupCluster(Arrays.asList(bad1, bad2));
-
-    try {
-      interceptor.getNode("testGetNodeTwoBadSCs");
-      Assert.fail();
-    } catch (NotFoundException e) {
-      Assert.assertTrue(e.getMessage()
-          .contains("nodeId, testGetNodeTwoBadSCs, is not found"));
-    }
-  }
-
-  /**
-   * This test validates the correctness of GetNode in case the cluster is
-   * composed of only 1 bad SubCluster and a good one.
-   */
-  @Test
-  public void testGetNodeOneBadOneGood()
-      throws YarnException, IOException, InterruptedException {
-    setupCluster(Arrays.asList(good, bad2));
-
-    NodeInfo response = interceptor.getNode(null);
-    Assert.assertNotNull(response);
-    // Check if the only node came from Good SubCluster
-    Assert.assertEquals(good.getId(),
-        Long.toString(response.getLastHealthUpdate()));
-  }
-
-  /**
-   * This test validates the correctness of GetNodes in case the cluster is
-   * composed of only 1 bad SubCluster.
-   */
-  @Test
-  public void testGetNodesOneBadSC() throws Exception {
-
-    setupCluster(Arrays.asList(bad2));
-
-    LambdaTestUtils.intercept(YarnRuntimeException.class, "RM is stopped",
-        () -> interceptor.getNodes(null));
-  }
-
-  /**
-   * This test validates the correctness of GetNodes in case the cluster is
-   * composed of only 2 bad SubClusters.
-   */
-  @Test
-  public void testGetNodesTwoBadSCs() throws Exception {
-
-    setupCluster(Arrays.asList(bad1, bad2));
-
-    LambdaTestUtils.intercept(YarnRuntimeException.class, "RM is stopped",
-        () -> interceptor.getNodes(null));
-  }
-
-  /**
-   * This test validates the correctness of GetNodes in case the cluster is
-   * composed of only 1 bad SubCluster and a good one.
-   */
-  @Test
-  public void testGetNodesOneBadOneGood() throws Exception {
-    setupCluster(Arrays.asList(good, bad2));
-
-    LambdaTestUtils.intercept(YarnRuntimeException.class, "RM is stopped",
-        () -> interceptor.getNodes(null));
-  }
-
-  /**
-   * This test validates the correctness of GetNodes in case the cluster is
-   * composed of only 1 bad SubCluster. The excepted result would be a
-   * ClusterMetricsInfo with all its values set to 0.
-   */
-  @Test
-  public void testGetClusterMetricsOneBadSC()
-      throws YarnException, IOException, InterruptedException {
-    setupCluster(Arrays.asList(bad2));
-
-    ClusterMetricsInfo response = interceptor.getClusterMetricsInfo();
-    Assert.assertNotNull(response);
-    // check if we got an empty metrics
-    checkEmptyMetrics(response);
-  }
-
-  /**
-   * This test validates the correctness of GetClusterMetrics in case the
-   * cluster is composed of only 2 bad SubClusters. The excepted result would be
-   * a ClusterMetricsInfo with all its values set to 0.
-   */
-  @Test
-  public void testGetClusterMetricsTwoBadSCs()
-      throws YarnException, IOException, InterruptedException {
-    setupCluster(Arrays.asList(bad1, bad2));
-
-    ClusterMetricsInfo response = interceptor.getClusterMetricsInfo();
-    Assert.assertNotNull(response);
-    // check if we got an empty metrics
-    Assert.assertEquals(0, response.getAppsSubmitted());
-  }
-
-  /**
-   * This test validates the correctness of GetClusterMetrics in case the
-   * cluster is composed of only 1 bad SubCluster and a good one. The good
-   * SubCluster provided a ClusterMetricsInfo with appsSubmitted set to its
-   * SubClusterId. The expected result would be appSubmitted equals to its
-   * SubClusterId. SubClusterId in this case is an integer.
-   */
-  @Test
-  public void testGetClusterMetricsOneBadOneGood()
-      throws YarnException, IOException, InterruptedException {
-    setupCluster(Arrays.asList(good, bad2));
-
-    ClusterMetricsInfo response = interceptor.getClusterMetricsInfo();
-    Assert.assertNotNull(response);
-    checkMetricsFromGoodSC(response);
-    // The merge operations is tested in TestRouterWebServiceUtil
-  }
-
-  private void checkMetricsFromGoodSC(ClusterMetricsInfo response) {
-    Assert.assertEquals(Integer.parseInt(good.getId()),
-        response.getAppsSubmitted());
-    Assert.assertEquals(Integer.parseInt(good.getId()),
-        response.getAppsCompleted());
-    Assert.assertEquals(Integer.parseInt(good.getId()),
-        response.getAppsPending());
-    Assert.assertEquals(Integer.parseInt(good.getId()),
-        response.getAppsRunning());
-    Assert.assertEquals(Integer.parseInt(good.getId()),
-        response.getAppsFailed());
-    Assert.assertEquals(Integer.parseInt(good.getId()),
-        response.getAppsKilled());
-  }
-
-  private void checkEmptyMetrics(ClusterMetricsInfo response) {
-    Assert.assertEquals(0, response.getAppsSubmitted());
-    Assert.assertEquals(0, response.getAppsCompleted());
-    Assert.assertEquals(0, response.getAppsPending());
-    Assert.assertEquals(0, response.getAppsRunning());
-    Assert.assertEquals(0, response.getAppsFailed());
-    Assert.assertEquals(0, response.getAppsKilled());
-
-    Assert.assertEquals(0, response.getReservedMB());
-    Assert.assertEquals(0, response.getAvailableMB());
-    Assert.assertEquals(0, response.getAllocatedMB());
-
-    Assert.assertEquals(0, response.getReservedVirtualCores());
-    Assert.assertEquals(0, response.getAvailableVirtualCores());
-    Assert.assertEquals(0, response.getAllocatedVirtualCores());
-
-    Assert.assertEquals(0, response.getContainersAllocated());
-    Assert.assertEquals(0, response.getReservedContainers());
-    Assert.assertEquals(0, response.getPendingContainers());
-
-    Assert.assertEquals(0, response.getTotalMB());
-    Assert.assertEquals(0, response.getTotalVirtualCores());
-    Assert.assertEquals(0, response.getTotalNodes());
-    Assert.assertEquals(0, response.getLostNodes());
-    Assert.assertEquals(0, response.getUnhealthyNodes());
-    Assert.assertEquals(0, response.getDecommissioningNodes());
-    Assert.assertEquals(0, response.getDecommissionedNodes());
-    Assert.assertEquals(0, response.getRebootedNodes());
-    Assert.assertEquals(0, response.getActiveNodes());
-    Assert.assertEquals(0, response.getShutdownNodes());
-  }
-
-  @Test
-  public void testGetNodesOneBadSCAllowPartial() throws Exception {
-    // We set allowPartialResult to true.
-    // In this test case, we set up a subCluster,
-    // and the subCluster status is bad, we can't get the response,
-    // an exception should be thrown at this time.
-    interceptor.setAllowPartialResult(true);
-    setupCluster(Arrays.asList(bad2));
-
-    NodesInfo nodesInfo = interceptor.getNodes(null);
-    Assert.assertNotNull(nodesInfo);
-
-    // We need to set allowPartialResult=false
-    interceptor.setAllowPartialResult(false);
-  }
-
-  @Test
-  public void testGetNodesTwoBadSCsAllowPartial() throws Exception {
-    // We set allowPartialResult to true.
-    // In this test case, we set up 2 subClusters,
-    // and the status of these 2 subClusters is bad. When we call the interface,
-    // an exception should be returned.
-    interceptor.setAllowPartialResult(true);
-    setupCluster(Arrays.asList(bad1, bad2));
-
-    NodesInfo nodesInfo = interceptor.getNodes(null);
-    Assert.assertNotNull(nodesInfo);
-
-    // We need to set allowPartialResult=false
-    interceptor.setAllowPartialResult(false);
-  }
-
-  @Test
-  public void testGetNodesOneBadOneGoodAllowPartial() throws Exception {
-
-    // allowPartialResult = true,
-    // We tolerate exceptions and return normal results
-    interceptor.setAllowPartialResult(true);
-    setupCluster(Arrays.asList(good, bad2));
-
-    NodesInfo response = interceptor.getNodes(null);
-    Assert.assertNotNull(response);
-    Assert.assertEquals(1, response.getNodes().size());
-    // Check if the only node came from Good SubCluster
-    Assert.assertEquals(good.getId(),
-        Long.toString(response.getNodes().get(0).getLastHealthUpdate()));
-
-    // allowPartialResult = false,
-    // We do not tolerate exceptions and will throw exceptions directly
-    interceptor.setAllowPartialResult(false);
-
-    setupCluster(Arrays.asList(good, bad2));
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestFederationWebApp.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestFederationWebApp.java
deleted file mode 100644
index f703dab9552..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestFederationWebApp.java
+++ /dev/null
@@ -1,135 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.router.Router;
-import org.apache.hadoop.yarn.webapp.test.WebAppTests;
-import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.io.IOException;
-
-public class TestFederationWebApp extends TestRouterWebServicesREST {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestFederationWebApp.class);
-
-  @Test
-  public void testFederationWebViewNotEnable()
-      throws InterruptedException, YarnException, IOException {
-    LOG.info("testFederationWebView - NotEnable Federation.");
-    // Test Federation is not Enabled
-    Configuration config = new YarnConfiguration();
-    config.setBoolean(YarnConfiguration.FEDERATION_ENABLED, false);
-    WebAppTests.testPage(FederationPage.class, Router.class, new MockRouter(config));
-  }
-
-  @Test
-  public void testFederationWebViewEnable()
-      throws InterruptedException, YarnException, IOException {
-    LOG.info("testFederationWebView - Enable Federation.");
-    // Test Federation Enabled
-    Configuration config = new YarnConfiguration();
-    config.setBoolean(YarnConfiguration.FEDERATION_ENABLED, true);
-    WebAppTests.testPage(FederationPage.class, Router.class, new MockRouter(config));
-  }
-
-  @Test
-  public void testFederationAboutViewEnable()
-      throws InterruptedException, YarnException, IOException {
-    LOG.info("testFederationAboutViewEnable - Enable Federation.");
-    // Test Federation Enabled
-    Configuration config = new YarnConfiguration();
-    config.setBoolean(YarnConfiguration.FEDERATION_ENABLED, true);
-    WebAppTests.testPage(AboutPage.class, Router.class, new MockRouter(config));
-  }
-
-  @Test
-  public void testFederationAboutViewNotEnable()
-      throws InterruptedException, YarnException, IOException {
-    LOG.info("testFederationAboutViewNotEnable - NotEnable Federation.");
-    // Test Federation Not Enabled
-    Configuration config = new YarnConfiguration();
-    config.setBoolean(YarnConfiguration.FEDERATION_ENABLED, false);
-    WebAppTests.testPage(AboutPage.class, Router.class, new MockRouter(config));
-  }
-
-  @Test
-  public void testFederationNodeViewEnable()
-      throws InterruptedException, YarnException, IOException {
-    LOG.info("testFederationNodeViewEnable - Enable Federation.");
-    // Test Federation Enabled
-    Configuration config = new YarnConfiguration();
-    config.setBoolean(YarnConfiguration.FEDERATION_ENABLED, true);
-    WebAppTests.testPage(NodesPage.class, Router.class, new MockRouter(config));
-  }
-
-  @Test
-  public void testFederationNodeViewNotEnable()
-      throws InterruptedException, YarnException, IOException {
-    LOG.info("testFederationNodeViewNotEnable - NotEnable Federation.");
-    // Test Federation Not Enabled
-    Configuration config = new YarnConfiguration();
-    config.setBoolean(YarnConfiguration.FEDERATION_ENABLED, false);
-    WebAppTests.testPage(NodesPage.class, Router.class, new MockRouter(config));
-  }
-
-  @Test
-  public void testFederationAppViewEnable()
-      throws InterruptedException, YarnException, IOException {
-    LOG.info("testFederationAppViewEnable - Enable Federation.");
-    // Test Federation Enabled
-    Configuration config = new YarnConfiguration();
-    config.setBoolean(YarnConfiguration.FEDERATION_ENABLED, true);
-    WebAppTests.testPage(AppsPage.class, Router.class, new MockRouter(config));
-  }
-
-  @Test
-  public void testFederationAppViewNotEnable()
-      throws InterruptedException, YarnException, IOException {
-    LOG.info("testFederationAppViewNotEnable - NotEnable Federation.");
-    // Test Federation Not Enabled
-    Configuration config = new YarnConfiguration();
-    config.setBoolean(YarnConfiguration.FEDERATION_ENABLED, false);
-    WebAppTests.testPage(AppsPage.class, Router.class, new MockRouter(config));
-  }
-
-  @Test
-  public void testNodeLabelAppViewNotEnable()
-      throws InterruptedException, YarnException, IOException {
-    LOG.info("testNodeLabelAppViewNotEnable - NotEnable Federation.");
-    // Test Federation Not Enabled
-    Configuration config = new YarnConfiguration();
-    config.setBoolean(YarnConfiguration.FEDERATION_ENABLED, false);
-    WebAppTests.testPage(NodeLabelsPage.class, Router.class, new MockRouter(config));
-  }
-
-  @Test
-  public void testNodeLabelAppViewEnable()
-      throws InterruptedException, YarnException, IOException {
-    LOG.info("testNodeLabelAppViewEnable - Enable Federation.");
-    // Test Federation Not Enabled
-    Configuration config = new YarnConfiguration();
-    config.setBoolean(YarnConfiguration.FEDERATION_ENABLED, true);
-    WebAppTests.testPage(NodeLabelsPage.class, Router.class, new MockRouter(config));
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestRouterWebAppProxy.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestRouterWebAppProxy.java
deleted file mode 100644
index 205b6e9236a..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestRouterWebAppProxy.java
+++ /dev/null
@@ -1,298 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- * <p>
- * http://www.apache.org/licenses/LICENSE-2.0
- * <p>
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.yarn.api.ApplicationClientProtocol;
-import org.apache.hadoop.yarn.api.ApplicationHistoryProtocol;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportRequest;
-import org.apache.hadoop.yarn.api.protocolrecords.GetApplicationReportResponse;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.ApplicationReport;
-import org.apache.hadoop.yarn.api.records.YarnApplicationState;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.exceptions.ApplicationNotFoundException;
-import org.apache.hadoop.yarn.server.federation.store.records.ApplicationHomeSubCluster;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterInfo;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterRegisterRequest;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterState;
-import org.apache.hadoop.yarn.server.federation.utils.FederationStateStoreFacade;
-import org.apache.hadoop.yarn.server.router.Router;
-import org.apache.hadoop.yarn.server.router.clientrm.FederationClientInterceptor;
-import org.apache.hadoop.yarn.server.router.clientrm.RouterClientRMService.RequestInterceptorChainWrapper;
-import org.apache.hadoop.yarn.server.webproxy.FedAppReportFetcher;
-import org.eclipse.jetty.server.Server;
-import org.eclipse.jetty.server.ServerConnector;
-import org.eclipse.jetty.servlet.ServletContextHandler;
-import org.eclipse.jetty.servlet.ServletHolder;
-import org.eclipse.jetty.util.thread.QueuedThreadPool;
-import org.junit.BeforeClass;
-import org.junit.Test;
-import org.mockito.Mockito;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import javax.servlet.http.HttpServlet;
-import javax.servlet.http.HttpServletRequest;
-import javax.servlet.http.HttpServletResponse;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.OutputStream;
-import java.net.HttpURLConnection;
-import java.net.URL;
-
-import static org.junit.Assert.assertEquals;
-import static org.mockito.Mockito.mock;
-
-public class TestRouterWebAppProxy {
-
-  private static final Logger LOG = LoggerFactory.getLogger(TestRouterWebAppProxy.class);
-
-  public static final String AM_PREFIX = "AM";
-  public static final String RM_PREFIX = "RM";
-  public static final String AHS_PREFIX = "AHS";
-
-  /*
-   * Mocked Server is used for simulating the web of AppMaster, ResourceMamanger or TimelineServer.
-   * */
-  private static Server mockServer;
-  private static int mockServerPort = 0;
-
-  /**
-   * Simple http server. Server should send answer with status 200
-   */
-  @BeforeClass
-  public static void setUp() throws Exception {
-    mockServer = new Server(0);
-    ((QueuedThreadPool) mockServer.getThreadPool()).setMaxThreads(20);
-    ServletContextHandler context = new ServletContextHandler();
-    context.setContextPath("/");
-    context.addServlet(new ServletHolder(new MockWebServlet(AM_PREFIX)), "/amweb/*");
-    context.addServlet(new ServletHolder(new MockWebServlet(RM_PREFIX)), "/cluster/app/*");
-    context.addServlet(new ServletHolder(new MockWebServlet(AHS_PREFIX)),
-        "/applicationhistory/app/*");
-    mockServer.setHandler(context);
-    ((ServerConnector) mockServer.getConnectors()[0]).setHost("localhost");
-    mockServer.start();
-    mockServerPort = ((ServerConnector) mockServer.getConnectors()[0]).getLocalPort();
-    LOG.info("Running embedded servlet container at: http://localhost:" + mockServerPort);
-  }
-
-  @Test(timeout=10000)
-  public void testRouterWebAppProxyFed() throws Exception {
-
-    Configuration conf = new Configuration();
-    conf.set(YarnConfiguration.ROUTER_WEBAPP_ADDRESS, "localhost:9090");
-    conf.setBoolean(YarnConfiguration.FEDERATION_ENABLED, true);
-    conf.setBoolean(YarnConfiguration.APPLICATION_HISTORY_ENABLED, true);
-    conf.set(YarnConfiguration.TIMELINE_SERVICE_WEBAPP_ADDRESS, "localhost:" + mockServerPort);
-    // overriding num of web server threads, see HttpServer.HTTP_MAXTHREADS
-    conf.setInt("hadoop.http.max.threads", 10);
-
-    // Create sub cluster information.
-    SubClusterId subClusterId1 = SubClusterId.newInstance("scid1");
-    SubClusterId subClusterId2 = SubClusterId.newInstance("scid2");
-    SubClusterInfo subClusterInfo1 = SubClusterInfo.newInstance(subClusterId1, "10.0.0.1:1",
-        "10.0.0.1:1", "10.0.0.1:1", "localhost:" + mockServerPort, SubClusterState.SC_RUNNING, 0,
-        "");
-    SubClusterInfo subClusterInfo2 = SubClusterInfo.newInstance(subClusterId2, "10.0.0.2:1",
-        "10.0.0.2:1", "10.0.0.2:1", "10.0.0.2:1", SubClusterState.SC_RUNNING, 0, "");
-
-    // App1 and App2 is running applications.
-    ApplicationId appId1 = ApplicationId.newInstance(0, 1);
-    ApplicationId appId2 = ApplicationId.newInstance(0, 2);
-    String appUrl1 = "http://localhost:" + mockServerPort + "/amweb/" + appId1;
-    String proxyAppUrl1 = "http://localhost:" + mockServerPort + "/proxy/" + appId1;
-    String appUrl2 = "http://localhost:" + mockServerPort + "/amweb/" + appId2;
-    String proxyAppUrl2 = "http://localhost:" + mockServerPort + "/proxy/" + appId2;
-    // App3 is accepted application, has not registered original url to am.
-    ApplicationId appId3 = ApplicationId.newInstance(0, 3);
-    String proxyAppUrl3 = "http://localhost:" + mockServerPort + "/proxy/" + appId3;
-    // App4 is finished application, has remove from rm, but not remove from timeline server.
-    ApplicationId appId4 = ApplicationId.newInstance(0, 4);
-    String proxyAppUrl4 = "http://localhost:" + mockServerPort + "/proxy/" + appId4;
-
-    // Mock for application
-    ApplicationClientProtocol appManager1 = mock(ApplicationClientProtocol.class);
-    Mockito.when(appManager1.getApplicationReport(GetApplicationReportRequest.newInstance(appId1)))
-        .thenReturn(GetApplicationReportResponse.newInstance(
-            newApplicationReport(appId1, YarnApplicationState.RUNNING, proxyAppUrl1, appUrl1)));
-    Mockito.when(appManager1.getApplicationReport(GetApplicationReportRequest.newInstance(appId3)))
-        .thenReturn(GetApplicationReportResponse.newInstance(
-            newApplicationReport(appId3, YarnApplicationState.ACCEPTED, proxyAppUrl2, null)));
-
-    ApplicationClientProtocol appManager2 = mock(ApplicationClientProtocol.class);
-    Mockito.when(appManager2.getApplicationReport(GetApplicationReportRequest.newInstance(appId2)))
-        .thenReturn(GetApplicationReportResponse.newInstance(
-            newApplicationReport(appId2, YarnApplicationState.RUNNING, proxyAppUrl3, appUrl2)));
-    Mockito.when(appManager2.getApplicationReport(GetApplicationReportRequest.newInstance(appId4)))
-        .thenThrow(new ApplicationNotFoundException("APP NOT FOUND"));
-
-    ApplicationHistoryProtocol historyManager = mock(ApplicationHistoryProtocol.class);
-    Mockito.when(
-            historyManager.getApplicationReport(GetApplicationReportRequest.newInstance(appId4)))
-        .thenReturn(GetApplicationReportResponse.newInstance(
-            newApplicationReport(appId4, YarnApplicationState.FINISHED, proxyAppUrl4, null)));
-
-    // Initial federation store.
-    FederationStateStoreFacade facade = FederationStateStoreFacade.getInstance(conf);
-    facade.getStateStore()
-        .registerSubCluster(SubClusterRegisterRequest.newInstance(subClusterInfo1));
-    facade.getStateStore()
-        .registerSubCluster(SubClusterRegisterRequest.newInstance(subClusterInfo2));
-    facade.addApplicationHomeSubCluster(
-        ApplicationHomeSubCluster.newInstance(appId1, subClusterId1));
-    facade.addApplicationHomeSubCluster(
-        ApplicationHomeSubCluster.newInstance(appId2, subClusterId2));
-    facade.addApplicationHomeSubCluster(
-        ApplicationHomeSubCluster.newInstance(appId3, subClusterId1));
-    facade.addApplicationHomeSubCluster(
-        ApplicationHomeSubCluster.newInstance(appId4, subClusterId2));
-
-    // Start router for test
-    Router router = new Router();
-    router.init(conf);
-    router.start();
-    String user = UserGroupInformation.getCurrentUser().getUserName();
-    RequestInterceptorChainWrapper wrapper = mock(RequestInterceptorChainWrapper.class);
-    FederationClientInterceptor interceptor = mock(FederationClientInterceptor.class);
-    Mockito.when(interceptor.getApplicationReport(GetApplicationReportRequest.newInstance(appId1)))
-        .thenReturn(GetApplicationReportResponse.newInstance(
-            newApplicationReport(appId1, YarnApplicationState.RUNNING, proxyAppUrl1, appUrl1)));
-    Mockito.when(interceptor.getApplicationReport(GetApplicationReportRequest.newInstance(appId2)))
-        .thenReturn(GetApplicationReportResponse.newInstance(
-            newApplicationReport(appId2, YarnApplicationState.RUNNING, proxyAppUrl2, appUrl2)));
-    Mockito.when(interceptor.getApplicationReport(GetApplicationReportRequest.newInstance(appId3)))
-        .thenReturn(GetApplicationReportResponse.newInstance(
-            newApplicationReport(appId3, YarnApplicationState.ACCEPTED, proxyAppUrl3, null)));
-    Mockito.when(interceptor.getApplicationReport(GetApplicationReportRequest.newInstance(appId4)))
-        .thenReturn(GetApplicationReportResponse.newInstance(
-            newApplicationReport(appId4, YarnApplicationState.FINISHED, proxyAppUrl4, null)));
-    Mockito.when(wrapper.getRootInterceptor()).thenReturn(interceptor);
-    router.getClientRMProxyService().getUserPipelineMap().put(user, wrapper);
-    try {
-      // set Mocked rm and timeline
-      FedAppReportFetcher appReportFetcher = router.getFetcher();
-      appReportFetcher.registerSubCluster(subClusterInfo1, appManager1);
-      appReportFetcher.registerSubCluster(subClusterInfo2, appManager2);
-      appReportFetcher.setHistoryManager(historyManager);
-
-      // App1 is running in subcluster1, and original url is registered in rm of subCluster1.
-      // So router will get original url from rm by getApplicationReport. Then router
-      // will fetch the webapp directly.
-      GetApplicationReportResponse response = router.getClientRMProxyService()
-          .getApplicationReport(GetApplicationReportRequest.newInstance(appId1));
-      URL url = new URL(response.getApplicationReport().getTrackingUrl());
-      HttpURLConnection conn = (HttpURLConnection) url.openConnection();
-      conn.connect();
-      assertEquals(HttpURLConnection.HTTP_OK, conn.getResponseCode());
-      assertEquals(AM_PREFIX + "/" + appId1, readResponse(conn));
-      conn.disconnect();
-
-      // App2 is running in subcluster2, and original url is registered
-      // in rm of subCluster2. So router will get original url from rm by
-      // getApplicationReport. Then router will fetch the webapp directly.
-      response = router.getClientRMProxyService()
-          .getApplicationReport(GetApplicationReportRequest.newInstance(appId2));
-      url = new URL(response.getApplicationReport().getTrackingUrl());
-      conn = (HttpURLConnection) url.openConnection();
-      conn.connect();
-      assertEquals(HttpURLConnection.HTTP_OK, conn.getResponseCode());
-      assertEquals(AM_PREFIX + "/" + appId2, readResponse(conn));
-      conn.disconnect();
-
-      // App3 is accepted in subcluster1, and original url is not registered
-      // yet. So router will fetch the application web from rm.
-      response = router.getClientRMProxyService()
-          .getApplicationReport(GetApplicationReportRequest.newInstance(appId3));
-      url = new URL(response.getApplicationReport().getTrackingUrl());
-      conn = (HttpURLConnection) url.openConnection();
-      conn.connect();
-      assertEquals(HttpURLConnection.HTTP_OK, conn.getResponseCode());
-      assertEquals(RM_PREFIX + "/" + appId3, readResponse(conn));
-      conn.disconnect();
-
-      // App4 is finished in subcluster2, and have removed from rm, but not
-      // removed from timeline server. So rouer will fetch the
-      // application web from timeline server.
-      response = router.getClientRMProxyService()
-          .getApplicationReport(GetApplicationReportRequest.newInstance(appId4));
-      url = new URL(response.getApplicationReport().getTrackingUrl());
-      conn = (HttpURLConnection) url.openConnection();
-      conn.connect();
-      assertEquals(HttpURLConnection.HTTP_OK, conn.getResponseCode());
-      assertEquals(AHS_PREFIX + "/" + appId4, readResponse(conn));
-      conn.disconnect();
-    } finally {
-      router.close();
-    }
-  }
-
-  private ApplicationReport newApplicationReport(ApplicationId appId, YarnApplicationState state,
-                                                 String trackingUrl, String origTrackingUrl) {
-    return ApplicationReport.newInstance(appId, null, "testuser", null, null, null, 0, null, state,
-        null, trackingUrl, 0, 0, 0, null, null, origTrackingUrl, 0f, null, null);
-  }
-
-  private String readResponse(HttpURLConnection conn) throws IOException {
-    InputStream input = conn.getInputStream();
-    byte[] bytes = new byte[input.available()];
-    input.read(bytes);
-    return new String(bytes);
-  }
-
-  /*
-   * This servlet is used for simulate the web of AppMaster, ResourceManager,
-   * TimelineServer and so on.
-   * */
-  public static class MockWebServlet extends HttpServlet {
-
-    private String role;
-
-    public MockWebServlet(String role) {
-      this.role = role;
-    }
-
-    @Override
-    protected void doGet(HttpServletRequest req, HttpServletResponse resp)
-        throws IOException {
-      if (req.getPathInfo() != null) {
-        resp.getWriter().write(role + req.getPathInfo());
-      }
-      resp.setStatus(HttpServletResponse.SC_OK);
-    }
-
-    @Override
-    protected void doPost(HttpServletRequest req, HttpServletResponse resp)
-        throws IOException {
-      InputStream is = req.getInputStream();
-      OutputStream os = resp.getOutputStream();
-      int c = is.read();
-      while (c > -1) {
-        os.write(c);
-        c = is.read();
-      }
-      is.close();
-      os.close();
-      resp.setStatus(HttpServletResponse.SC_OK);
-    }
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestRouterWebServiceUtil.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestRouterWebServiceUtil.java
deleted file mode 100644
index 5e480e7714a..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestRouterWebServiceUtil.java
+++ /dev/null
@@ -1,775 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Map;
-import java.util.Random;
-import java.util.concurrent.TimeUnit;
-
-import com.sun.jersey.api.client.Client;
-import com.sun.jersey.api.client.config.ClientConfig;
-import org.apache.hadoop.yarn.api.records.ApplicationId;
-import org.apache.hadoop.yarn.api.records.YarnApplicationState;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationStatisticsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.StatisticsItemInfo;
-import org.apache.hadoop.yarn.server.uam.UnmanagedApplicationManager;
-import org.junit.Assert;
-import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import static org.mockito.Mockito.mock;
-import static org.mockito.Mockito.when;
-
-/**
- * Test class to validate RouterWebServiceUtil methods.
- */
-public class TestRouterWebServiceUtil {
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestRouterWebServiceUtil.class);
-
-  private static final ApplicationId APPID1 = ApplicationId.newInstance(1, 1);
-  private static final ApplicationId APPID2 = ApplicationId.newInstance(2, 1);
-  private static final ApplicationId APPID3 = ApplicationId.newInstance(3, 1);
-  private static final ApplicationId APPID4 = ApplicationId.newInstance(4, 1);
-
-  private static final String NODE1 = "Node1";
-  private static final String NODE2 = "Node2";
-  private static final String NODE3 = "Node3";
-  private static final String NODE4 = "Node4";
-
-  /**
-   * This test validates the correctness of RouterWebServiceUtil#mergeAppsInfo
-   * in case we want to merge 4 AMs. The expected result would be the same 4
-   * AMs.
-   */
-  @Test
-  public void testMerge4DifferentApps() {
-
-    AppsInfo apps = new AppsInfo();
-    int value = 1000;
-
-    AppInfo app1 = new AppInfo();
-    app1.setAppId(APPID1.toString());
-    app1.setAMHostHttpAddress("http://i_am_the_AM1:1234");
-    app1.setState(YarnApplicationState.FINISHED);
-    app1.setNumAMContainerPreempted(value);
-    apps.add(app1);
-
-    AppInfo app2 = new AppInfo();
-    app2.setAppId(APPID2.toString());
-    app2.setAMHostHttpAddress("http://i_am_the_AM2:1234");
-    app2.setState(YarnApplicationState.ACCEPTED);
-    app2.setAllocatedVCores(2 * value);
-
-    apps.add(app2);
-
-    AppInfo app3 = new AppInfo();
-    app3.setAppId(APPID3.toString());
-    app3.setAMHostHttpAddress("http://i_am_the_AM3:1234");
-    app3.setState(YarnApplicationState.RUNNING);
-    app3.setReservedMB(3 * value);
-    apps.add(app3);
-
-    AppInfo app4 = new AppInfo();
-    app4.setAppId(APPID4.toString());
-    app4.setAMHostHttpAddress("http://i_am_the_AM4:1234");
-    app4.setState(YarnApplicationState.NEW);
-    app4.setAllocatedMB(4 * value);
-    apps.add(app4);
-
-    AppsInfo result = RouterWebServiceUtil.mergeAppsInfo(apps.getApps(), false);
-    Assert.assertNotNull(result);
-    Assert.assertEquals(4, result.getApps().size());
-
-    List<String> appIds = new ArrayList<String>();
-    AppInfo appInfo1 = null, appInfo2 = null, appInfo3 = null, appInfo4 = null;
-    for (AppInfo app : result.getApps()) {
-      appIds.add(app.getAppId());
-      if (app.getAppId().equals(APPID1.toString())) {
-        appInfo1 = app;
-      }
-      if (app.getAppId().equals(APPID2.toString())) {
-        appInfo2 = app;
-      }
-      if (app.getAppId().equals(APPID3.toString())) {
-        appInfo3 = app;
-      }
-      if (app.getAppId().equals(APPID4.toString())) {
-        appInfo4 = app;
-      }
-    }
-
-    Assert.assertTrue(appIds.contains(APPID1.toString()));
-    Assert.assertTrue(appIds.contains(APPID2.toString()));
-    Assert.assertTrue(appIds.contains(APPID3.toString()));
-    Assert.assertTrue(appIds.contains(APPID4.toString()));
-
-    // Check preservations APP1
-    Assert.assertEquals(app1.getState(), appInfo1.getState());
-    Assert.assertEquals(app1.getNumAMContainerPreempted(),
-        appInfo1.getNumAMContainerPreempted());
-
-    // Check preservations APP2
-    Assert.assertEquals(app2.getState(), appInfo2.getState());
-    Assert.assertEquals(app3.getAllocatedVCores(),
-        appInfo3.getAllocatedVCores());
-
-    // Check preservations APP3
-    Assert.assertEquals(app3.getState(), appInfo3.getState());
-    Assert.assertEquals(app3.getReservedMB(), appInfo3.getReservedMB());
-
-    // Check preservations APP3
-    Assert.assertEquals(app4.getState(), appInfo4.getState());
-    Assert.assertEquals(app3.getAllocatedMB(), appInfo3.getAllocatedMB());
-  }
-
-  /**
-   * This test validates the correctness of RouterWebServiceUtil#mergeAppsInfo
-   * in case we want to merge 2 UAMs and their own AM. The status of the AM is
-   * FINISHED, so we check the correctness of the merging of the historical
-   * values. The expected result would be 1 report with the merged information.
-   */
-  @Test
-  public void testMergeAppsFinished() {
-
-    AppsInfo apps = new AppsInfo();
-
-    String amHost = "http://i_am_the_AM1:1234";
-    AppInfo am = new AppInfo();
-    am.setAppId(APPID1.toString());
-    am.setAMHostHttpAddress(amHost);
-    am.setState(YarnApplicationState.FINISHED);
-
-    int value = 1000;
-    setAppInfoFinished(am, value);
-
-    apps.add(am);
-
-    AppInfo uam1 = new AppInfo();
-    uam1.setAppId(APPID1.toString());
-    apps.add(uam1);
-
-    setAppInfoFinished(uam1, value);
-
-    AppInfo uam2 = new AppInfo();
-    uam2.setAppId(APPID1.toString());
-    apps.add(uam2);
-
-    setAppInfoFinished(uam2, value);
-
-    // in this case the result does not change if we enable partial result
-    AppsInfo result = RouterWebServiceUtil.mergeAppsInfo(apps.getApps(), false);
-    Assert.assertNotNull(result);
-    Assert.assertEquals(1, result.getApps().size());
-
-    AppInfo app = result.getApps().get(0);
-
-    Assert.assertEquals(APPID1.toString(), app.getAppId());
-    Assert.assertEquals(amHost, app.getAMHostHttpAddress());
-    Assert.assertEquals(value * 3, app.getPreemptedResourceMB());
-    Assert.assertEquals(value * 3, app.getPreemptedResourceVCores());
-    Assert.assertEquals(value * 3, app.getNumNonAMContainerPreempted());
-    Assert.assertEquals(value * 3, app.getNumAMContainerPreempted());
-    Assert.assertEquals(value * 3, app.getPreemptedMemorySeconds());
-    Assert.assertEquals(value * 3, app.getPreemptedVcoreSeconds());
-  }
-
-  private void setAppInfoFinished(AppInfo am, int value) {
-    am.setPreemptedResourceMB(value);
-    am.setPreemptedResourceVCores(value);
-    am.setNumNonAMContainerPreempted(value);
-    am.setNumAMContainerPreempted(value);
-    am.setPreemptedMemorySeconds(value);
-    am.setPreemptedVcoreSeconds(value);
-  }
-
-  /**
-   * This test validates the correctness of RouterWebServiceUtil#mergeAppsInfo
-   * in case we want to merge 2 UAMs and their own AM. The status of the AM is
-   * RUNNING, so we check the correctness of the merging of the runtime values.
-   * The expected result would be 1 report with the merged information.
-   */
-  @Test
-  public void testMergeAppsRunning() {
-
-    AppsInfo apps = new AppsInfo();
-
-    String amHost = "http://i_am_the_AM2:1234";
-    AppInfo am = new AppInfo();
-    am.setAppId(APPID2.toString());
-    am.setAMHostHttpAddress(amHost);
-    am.setState(YarnApplicationState.RUNNING);
-
-    int value = 1000;
-    setAppInfoRunning(am, value);
-
-    apps.add(am);
-
-    AppInfo uam1 = new AppInfo();
-    uam1.setAppId(APPID2.toString());
-    uam1.setState(YarnApplicationState.RUNNING);
-    apps.add(uam1);
-
-    setAppInfoRunning(uam1, value);
-
-    AppInfo uam2 = new AppInfo();
-    uam2.setAppId(APPID2.toString());
-    uam2.setState(YarnApplicationState.RUNNING);
-    apps.add(uam2);
-
-    setAppInfoRunning(uam2, value);
-
-    // in this case the result does not change if we enable partial result
-    AppsInfo result = RouterWebServiceUtil.mergeAppsInfo(apps.getApps(), false);
-    Assert.assertNotNull(result);
-    Assert.assertEquals(1, result.getApps().size());
-
-    AppInfo app = result.getApps().get(0);
-
-    Assert.assertEquals(APPID2.toString(), app.getAppId());
-    Assert.assertEquals(amHost, app.getAMHostHttpAddress());
-    Assert.assertEquals(value * 3, app.getAllocatedMB());
-    Assert.assertEquals(value * 3, app.getAllocatedVCores());
-    Assert.assertEquals(value * 3, app.getReservedMB());
-    Assert.assertEquals(value * 3, app.getReservedVCores());
-    Assert.assertEquals(value * 3, app.getRunningContainers());
-    Assert.assertEquals(value * 3, app.getMemorySeconds());
-    Assert.assertEquals(value * 3, app.getVcoreSeconds());
-    Assert.assertEquals(3, app.getResourceRequests().size());
-  }
-
-  private void setAppInfoRunning(AppInfo am, int value) {
-    am.getResourceRequests().add(new ResourceRequestInfo());
-    am.setAllocatedMB(value);
-    am.setAllocatedVCores(value);
-    am.setReservedMB(value);
-    am.setReservedVCores(value);
-    am.setRunningContainers(value);
-    am.setMemorySeconds(value);
-    am.setVcoreSeconds(value);
-  }
-
-  /**
-   * This test validates the correctness of RouterWebServiceUtil#mergeAppsInfo
-   * in case we want to merge 2 UAMs without their own AM. The expected result
-   * would be an empty report or a partial report of the 2 UAMs depending on the
-   * selected policy.
-   */
-  @Test
-  public void testMerge2UAM() {
-
-    AppsInfo apps = new AppsInfo();
-
-    AppInfo app1 = new AppInfo();
-    app1.setAppId(APPID1.toString());
-    app1.setName(UnmanagedApplicationManager.APP_NAME);
-    app1.setState(YarnApplicationState.RUNNING);
-    apps.add(app1);
-
-    AppInfo app2 = new AppInfo();
-    app2.setAppId(APPID1.toString());
-    app2.setName(UnmanagedApplicationManager.APP_NAME);
-    app2.setState(YarnApplicationState.RUNNING);
-    apps.add(app2);
-
-    AppsInfo result = RouterWebServiceUtil.mergeAppsInfo(apps.getApps(), false);
-    Assert.assertNotNull(result);
-    Assert.assertEquals(0, result.getApps().size());
-
-    // By enabling partial result, the expected result would be a partial report
-    // of the 2 UAMs
-    AppsInfo result2 = RouterWebServiceUtil.mergeAppsInfo(apps.getApps(), true);
-    Assert.assertNotNull(result2);
-    Assert.assertEquals(1, result2.getApps().size());
-    Assert.assertEquals(YarnApplicationState.RUNNING,
-        result2.getApps().get(0).getState());
-  }
-
-  /**
-   * This test validates the correctness of RouterWebServiceUtil#mergeAppsInfo
-   * in case we want to merge 1 UAM that does not depend on Federation. The
-   * excepted result would be the same app report.
-   */
-  @Test
-  public void testMergeUAM() {
-
-    AppsInfo apps = new AppsInfo();
-
-    AppInfo app1 = new AppInfo();
-    app1.setAppId(APPID1.toString());
-    app1.setName("Test");
-    apps.add(app1);
-
-    // in this case the result does not change if we enable partial result
-    AppsInfo result = RouterWebServiceUtil.mergeAppsInfo(apps.getApps(), false);
-    Assert.assertNotNull(result);
-    Assert.assertEquals(1, result.getApps().size());
-  }
-
-  /**
-   * This test validates the correctness of
-   * RouterWebServiceUtil#deleteDuplicateNodesInfo in case we want to merge 4
-   * Nodes. The expected result would be the same 4 Nodes.
-   */
-  @Test
-  public void testDeleteDuplicate4DifferentNodes() {
-
-    NodesInfo nodes = new NodesInfo();
-
-    NodeInfo nodeInfo1 = new NodeInfo();
-    nodeInfo1.setId(NODE1);
-    nodes.add(nodeInfo1);
-
-    NodeInfo nodeInfo2 = new NodeInfo();
-    nodeInfo2.setId(NODE2);
-    nodes.add(nodeInfo2);
-
-    NodeInfo nodeInfo3 = new NodeInfo();
-    nodeInfo3.setId(NODE3);
-    nodes.add(nodeInfo3);
-
-    NodeInfo nodeInfo4 = new NodeInfo();
-    nodeInfo4.setId(NODE4);
-    nodes.add(nodeInfo4);
-
-    NodesInfo result =
-        RouterWebServiceUtil.deleteDuplicateNodesInfo(nodes.getNodes());
-    Assert.assertNotNull(result);
-    Assert.assertEquals(4, result.getNodes().size());
-
-    List<String> nodesIds = new ArrayList<String>();
-
-    for (NodeInfo node : result.getNodes()) {
-      nodesIds.add(node.getNodeId());
-    }
-
-    Assert.assertTrue(nodesIds.contains(NODE1));
-    Assert.assertTrue(nodesIds.contains(NODE2));
-    Assert.assertTrue(nodesIds.contains(NODE3));
-    Assert.assertTrue(nodesIds.contains(NODE4));
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RouterWebServiceUtil#deleteDuplicateNodesInfo(ArrayList)} in case we
-   * want to merge 3 nodes with the same id. The expected result would be 1 node
-   * report with the newest healthy report.
-   */
-  @Test
-  public void testDeleteDuplicateNodes() {
-
-    NodesInfo nodes = new NodesInfo();
-
-    NodeInfo node1 = new NodeInfo();
-    node1.setId(NODE1);
-    node1.setLastHealthUpdate(0);
-    nodes.add(node1);
-
-    NodeInfo node2 = new NodeInfo();
-    node2.setId(NODE1);
-    node2.setLastHealthUpdate(1);
-    nodes.add(node2);
-
-    NodeInfo node3 = new NodeInfo();
-    node3.setId(NODE1);
-    node3.setLastHealthUpdate(2);
-    nodes.add(node3);
-
-    NodesInfo result =
-        RouterWebServiceUtil.deleteDuplicateNodesInfo(nodes.getNodes());
-    Assert.assertNotNull(result);
-    Assert.assertEquals(1, result.getNodes().size());
-
-    NodeInfo node = result.getNodes().get(0);
-
-    Assert.assertEquals(NODE1, node.getNodeId());
-    Assert.assertEquals(2, node.getLastHealthUpdate());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RouterWebServiceUtil#mergeMetrics}.
-   */
-  @Test
-  public void testMergeMetrics() {
-    ClusterMetricsInfo metrics = new ClusterMetricsInfo();
-    ClusterMetricsInfo metricsResponse = new ClusterMetricsInfo();
-
-    long seed = System.currentTimeMillis();
-    setUpClusterMetrics(metrics, seed);
-    // ensure that we don't reuse the same seed when setting up metricsResponse
-    // or it might mask bugs
-    seed += 1000000000;
-    setUpClusterMetrics(metricsResponse, seed);
-    ClusterMetricsInfo metricsClone = createClusterMetricsClone(metrics);
-    RouterWebServiceUtil.mergeMetrics(metrics, metricsResponse);
-
-    Assert.assertEquals(
-        metricsResponse.getAppsSubmitted() + metricsClone.getAppsSubmitted(),
-        metrics.getAppsSubmitted());
-    Assert.assertEquals(
-        metricsResponse.getAppsCompleted() + metricsClone.getAppsCompleted(),
-        metrics.getAppsCompleted());
-    Assert.assertEquals(
-        metricsResponse.getAppsPending() + metricsClone.getAppsPending(),
-        metrics.getAppsPending());
-    Assert.assertEquals(
-        metricsResponse.getAppsRunning() + metricsClone.getAppsRunning(),
-        metrics.getAppsRunning());
-    Assert.assertEquals(
-        metricsResponse.getAppsFailed() + metricsClone.getAppsFailed(),
-        metrics.getAppsFailed());
-    Assert.assertEquals(
-        metricsResponse.getAppsKilled() + metricsClone.getAppsKilled(),
-        metrics.getAppsKilled());
-
-    Assert.assertEquals(
-        metricsResponse.getReservedMB() + metricsClone.getReservedMB(),
-        metrics.getReservedMB());
-    Assert.assertEquals(
-        metricsResponse.getAvailableMB() + metricsClone.getAvailableMB(),
-        metrics.getAvailableMB());
-    Assert.assertEquals(
-        metricsResponse.getAllocatedMB() + metricsClone.getAllocatedMB(),
-        metrics.getAllocatedMB());
-
-    Assert.assertEquals(
-        metricsResponse.getReservedVirtualCores()
-            + metricsClone.getReservedVirtualCores(),
-        metrics.getReservedVirtualCores());
-    Assert.assertEquals(
-        metricsResponse.getAvailableVirtualCores()
-            + metricsClone.getAvailableVirtualCores(),
-        metrics.getAvailableVirtualCores());
-    Assert.assertEquals(
-        metricsResponse.getAllocatedVirtualCores()
-            + metricsClone.getAllocatedVirtualCores(),
-        metrics.getAllocatedVirtualCores());
-
-    Assert.assertEquals(
-        metricsResponse.getContainersAllocated()
-            + metricsClone.getContainersAllocated(),
-        metrics.getContainersAllocated());
-    Assert.assertEquals(
-        metricsResponse.getReservedContainers()
-            + metricsClone.getReservedContainers(),
-        metrics.getReservedContainers());
-    Assert.assertEquals(
-        metricsResponse.getPendingContainers()
-            + metricsClone.getPendingContainers(),
-        metrics.getPendingContainers());
-
-    Assert.assertEquals(
-        metricsResponse.getTotalMB() + metricsClone.getTotalMB(),
-        metrics.getTotalMB());
-    Assert.assertEquals(
-        metricsResponse.getUtilizedMB() + metricsClone.getUtilizedMB(),
-        metrics.getUtilizedMB());
-    Assert.assertEquals(
-        metricsResponse.getTotalVirtualCores()
-            + metricsClone.getTotalVirtualCores(),
-        metrics.getTotalVirtualCores());
-    Assert.assertEquals(
-        metricsResponse.getUtilizedVirtualCores() + metricsClone.getUtilizedVirtualCores(),
-        metrics.getUtilizedVirtualCores());
-    Assert.assertEquals(
-        metricsResponse.getTotalNodes() + metricsClone.getTotalNodes(),
-        metrics.getTotalNodes());
-    Assert.assertEquals(
-        metricsResponse.getLostNodes() + metricsClone.getLostNodes(),
-        metrics.getLostNodes());
-    Assert.assertEquals(
-        metricsResponse.getUnhealthyNodes() + metricsClone.getUnhealthyNodes(),
-        metrics.getUnhealthyNodes());
-    Assert.assertEquals(
-        metricsResponse.getDecommissioningNodes()
-            + metricsClone.getDecommissioningNodes(),
-        metrics.getDecommissioningNodes());
-    Assert.assertEquals(
-        metricsResponse.getDecommissionedNodes()
-            + metricsClone.getDecommissionedNodes(),
-        metrics.getDecommissionedNodes());
-    Assert.assertEquals(
-        metricsResponse.getRebootedNodes() + metricsClone.getRebootedNodes(),
-        metrics.getRebootedNodes());
-    Assert.assertEquals(
-        metricsResponse.getActiveNodes() + metricsClone.getActiveNodes(),
-        metrics.getActiveNodes());
-    Assert.assertEquals(
-        metricsResponse.getShutdownNodes() + metricsClone.getShutdownNodes(),
-        metrics.getShutdownNodes());
-  }
-
-  private ClusterMetricsInfo createClusterMetricsClone(
-      ClusterMetricsInfo metrics) {
-    ClusterMetricsInfo metricsClone = new ClusterMetricsInfo();
-    metricsClone.setAppsSubmitted(metrics.getAppsSubmitted());
-    metricsClone.setAppsCompleted(metrics.getAppsCompleted());
-    metricsClone.setAppsPending(metrics.getAppsPending());
-    metricsClone.setAppsRunning(metrics.getAppsRunning());
-    metricsClone.setAppsFailed(metrics.getAppsFailed());
-    metricsClone.setAppsKilled(metrics.getAppsKilled());
-
-    metricsClone.setReservedMB(metrics.getReservedMB());
-    metricsClone.setAvailableMB(metrics.getAvailableMB());
-    metricsClone.setAllocatedMB(metrics.getAllocatedMB());
-
-    metricsClone.setReservedVirtualCores(metrics.getReservedVirtualCores());
-    metricsClone.setAvailableVirtualCores(metrics.getAvailableVirtualCores());
-    metricsClone.setAllocatedVirtualCores(metrics.getAllocatedVirtualCores());
-
-    metricsClone.setContainersAllocated(metrics.getContainersAllocated());
-    metricsClone.setContainersReserved(metrics.getReservedContainers());
-    metricsClone.setContainersPending(metrics.getPendingContainers());
-
-    metricsClone.setTotalMB(metrics.getTotalMB());
-    metricsClone.setUtilizedMB(metrics.getUtilizedMB());
-    metricsClone.setTotalVirtualCores(metrics.getTotalVirtualCores());
-    metricsClone.setUtilizedVirtualCores(metrics.getUtilizedVirtualCores());
-    metricsClone.setTotalNodes(metrics.getTotalNodes());
-    metricsClone.setLostNodes(metrics.getLostNodes());
-    metricsClone.setUnhealthyNodes(metrics.getUnhealthyNodes());
-    metricsClone.setDecommissioningNodes(metrics.getDecommissioningNodes());
-    metricsClone.setDecommissionedNodes(metrics.getDecommissionedNodes());
-    metricsClone.setRebootedNodes(metrics.getRebootedNodes());
-    metricsClone.setActiveNodes(metrics.getActiveNodes());
-    metricsClone.setShutdownNodes(metrics.getShutdownNodes());
-    return metricsClone;
-
-  }
-
-  private void setUpClusterMetrics(ClusterMetricsInfo metrics, long seed) {
-    LOG.info("Using seed: " + seed);
-    Random rand = new Random(seed);
-    metrics.setAppsSubmitted(rand.nextInt(1000));
-    metrics.setAppsCompleted(rand.nextInt(1000));
-    metrics.setAppsPending(rand.nextInt(1000));
-    metrics.setAppsRunning(rand.nextInt(1000));
-    metrics.setAppsFailed(rand.nextInt(1000));
-    metrics.setAppsKilled(rand.nextInt(1000));
-
-    metrics.setReservedMB(rand.nextInt(1000));
-    metrics.setAvailableMB(rand.nextInt(1000));
-    metrics.setAllocatedMB(rand.nextInt(1000));
-
-    metrics.setReservedVirtualCores(rand.nextInt(1000));
-    metrics.setAvailableVirtualCores(rand.nextInt(1000));
-    metrics.setAllocatedVirtualCores(rand.nextInt(1000));
-
-    metrics.setContainersAllocated(rand.nextInt(1000));
-    metrics.setContainersReserved(rand.nextInt(1000));
-    metrics.setContainersPending(rand.nextInt(1000));
-
-    metrics.setTotalMB(rand.nextInt(1000));
-    metrics.setUtilizedMB(metrics.getTotalMB() - rand.nextInt(100));
-    metrics.setTotalVirtualCores(rand.nextInt(1000));
-    metrics.setUtilizedVirtualCores(metrics.getUtilizedVirtualCores() - rand.nextInt(100));
-    metrics.setTotalNodes(rand.nextInt(1000));
-    metrics.setLostNodes(rand.nextInt(1000));
-    metrics.setUnhealthyNodes(rand.nextInt(1000));
-    metrics.setDecommissioningNodes(rand.nextInt(1000));
-    metrics.setDecommissionedNodes(rand.nextInt(1000));
-    metrics.setRebootedNodes(rand.nextInt(1000));
-    metrics.setActiveNodes(rand.nextInt(1000));
-    metrics.setShutdownNodes(rand.nextInt(1000));
-  }
-
-  public static AppAttemptInfo generateAppAttemptInfo(int attemptId) {
-    AppAttemptInfo appAttemptInfo = mock(AppAttemptInfo.class);
-    when(appAttemptInfo.getAppAttemptId()).thenReturn("AppAttemptId_" + attemptId);
-    when(appAttemptInfo.getAttemptId()).thenReturn(0);
-    when(appAttemptInfo.getFinishedTime()).thenReturn(1659621705L);
-    when(appAttemptInfo.getLogsLink()).thenReturn("LogLink_" + attemptId);
-    return appAttemptInfo;
-  }
-
-  @Test
-  public void testMergeApplicationStatisticsInfo() {
-    ApplicationStatisticsInfo infoA = new ApplicationStatisticsInfo();
-    ApplicationStatisticsInfo infoB = new ApplicationStatisticsInfo();
-
-    StatisticsItemInfo item1 = new StatisticsItemInfo(YarnApplicationState.ACCEPTED, "*", 10);
-    StatisticsItemInfo item2 = new StatisticsItemInfo(YarnApplicationState.ACCEPTED, "*", 20);
-
-    infoA.add(item1);
-    infoB.add(item2);
-
-    List<ApplicationStatisticsInfo> lists = new ArrayList<>();
-    lists.add(infoA);
-    lists.add(infoB);
-
-    ApplicationStatisticsInfo mergeInfo =
-        RouterWebServiceUtil.mergeApplicationStatisticsInfo(lists);
-    ArrayList<StatisticsItemInfo> statItem = mergeInfo.getStatItems();
-
-    Assert.assertNotNull(statItem);
-    Assert.assertEquals(1, statItem.size());
-
-    StatisticsItemInfo first = statItem.get(0);
-
-    Assert.assertEquals(item1.getCount() + item2.getCount(), first.getCount());
-    Assert.assertEquals(item1.getType(), first.getType());
-    Assert.assertEquals(item1.getState(), first.getState());
-  }
-
-  @Test
-  public void testMergeDiffApplicationStatisticsInfo() {
-    ApplicationStatisticsInfo infoA = new ApplicationStatisticsInfo();
-    StatisticsItemInfo item1 = new StatisticsItemInfo(YarnApplicationState.ACCEPTED, "*", 10);
-    StatisticsItemInfo item2 =
-        new StatisticsItemInfo(YarnApplicationState.NEW_SAVING, "test1", 20);
-    infoA.add(item1);
-    infoA.add(item2);
-
-    ApplicationStatisticsInfo infoB = new ApplicationStatisticsInfo();
-    StatisticsItemInfo item3 =
-        new StatisticsItemInfo(YarnApplicationState.NEW_SAVING, "test1", 30);
-    StatisticsItemInfo item4 = new StatisticsItemInfo(YarnApplicationState.FINISHED, "test3", 40);
-    infoB.add(item3);
-    infoB.add(item4);
-
-    List<ApplicationStatisticsInfo> lists = new ArrayList<>();
-    lists.add(infoA);
-    lists.add(infoB);
-
-    ApplicationStatisticsInfo mergeInfo =
-        RouterWebServiceUtil.mergeApplicationStatisticsInfo(lists);
-
-    Assert.assertEquals(3, mergeInfo.getStatItems().size());
-    List<StatisticsItemInfo> mergeInfoStatItems = mergeInfo.getStatItems();
-
-    StatisticsItemInfo item1Result = null;
-    StatisticsItemInfo item2Result = null;
-    StatisticsItemInfo item3Result = null;
-
-    for (StatisticsItemInfo item : mergeInfoStatItems) {
-      // ACCEPTED
-      if (item.getState() == YarnApplicationState.ACCEPTED) {
-        item1Result = item;
-      }
-
-      // NEW_SAVING
-      if (item.getState() == YarnApplicationState.NEW_SAVING) {
-        item2Result = item;
-      }
-
-      // FINISHED
-      if (item.getState() == YarnApplicationState.FINISHED) {
-        item3Result = item;
-      }
-    }
-
-    Assert.assertEquals(YarnApplicationState.ACCEPTED, item1Result.getState());
-    Assert.assertEquals(item1.getCount(), item1Result.getCount());
-    Assert.assertEquals(YarnApplicationState.NEW_SAVING, item2Result.getState());
-    Assert.assertEquals((item2.getCount() + item3.getCount()), item2Result.getCount());
-    Assert.assertEquals(YarnApplicationState.FINISHED, item3Result.getState());
-    Assert.assertEquals(item4.getCount(), item3Result.getCount());
-  }
-
-  @Test
-  public void testCreateJerseyClient() {
-    // Case1,  default timeout, The default timeout is 30s.
-    YarnConfiguration configuration = new YarnConfiguration();
-    Client client01 = RouterWebServiceUtil.createJerseyClient(configuration);
-    Map<String, Object> properties = client01.getProperties();
-    int readTimeOut = (int) properties.get(ClientConfig.PROPERTY_READ_TIMEOUT);
-    int connectTimeOut = (int) properties.get(ClientConfig.PROPERTY_CONNECT_TIMEOUT);
-    Assert.assertEquals(30000, readTimeOut);
-    Assert.assertEquals(30000, connectTimeOut);
-    client01.destroy();
-
-    // Case2, set a negative timeout, We'll get the default timeout(30s)
-    YarnConfiguration configuration2 = new YarnConfiguration();
-    configuration2.setLong(YarnConfiguration.ROUTER_WEBAPP_CONNECT_TIMEOUT, -1L);
-    configuration2.setLong(YarnConfiguration.ROUTER_WEBAPP_READ_TIMEOUT, -1L);
-    Client client02 = RouterWebServiceUtil.createJerseyClient(configuration2);
-    Map<String, Object> properties02 = client02.getProperties();
-    int readTimeOut02 = (int) properties02.get(ClientConfig.PROPERTY_READ_TIMEOUT);
-    int connectTimeOut02 =  (int) properties02.get(ClientConfig.PROPERTY_CONNECT_TIMEOUT);
-    Assert.assertEquals(30000, readTimeOut02);
-    Assert.assertEquals(30000, connectTimeOut02);
-    client02.destroy();
-
-    // Case3, Set the maximum value that exceeds the integer
-    // We'll get the default timeout(30s)
-    YarnConfiguration configuration3 = new YarnConfiguration();
-    long connectTimeOutLong = (long) Integer.MAX_VALUE + 1;
-    long readTimeOutLong = (long) Integer.MAX_VALUE + 1;
-
-    configuration3.setLong(YarnConfiguration.ROUTER_WEBAPP_CONNECT_TIMEOUT, connectTimeOutLong);
-    configuration3.setLong(YarnConfiguration.ROUTER_WEBAPP_READ_TIMEOUT, readTimeOutLong);
-    Client client03 = RouterWebServiceUtil.createJerseyClient(configuration3);
-    Map<String, Object> properties03 = client03.getProperties();
-    int readTimeOut03 = (int) properties03.get(ClientConfig.PROPERTY_READ_TIMEOUT);
-    int connectTimeOut03 = (int) properties03.get(ClientConfig.PROPERTY_CONNECT_TIMEOUT);
-    Assert.assertEquals(30000, readTimeOut03);
-    Assert.assertEquals(30000, connectTimeOut03);
-    client03.destroy();
-  }
-
-  @Test
-  public void testJerseyClient() {
-    // Case1, Set to negative 1.
-    YarnConfiguration conf = new YarnConfiguration();
-    conf.setLong(YarnConfiguration.ROUTER_WEBAPP_CONNECT_TIMEOUT, -1L);
-    conf.setLong(YarnConfiguration.ROUTER_WEBAPP_READ_TIMEOUT, -1L);
-
-    int connectTimeOut = (int) getTimeDuration(conf,
-        YarnConfiguration.ROUTER_WEBAPP_CONNECT_TIMEOUT,
-        YarnConfiguration.DEFAULT_ROUTER_WEBAPP_CONNECT_TIMEOUT);
-    int readTimeout = (int) getTimeDuration(conf,
-        YarnConfiguration.ROUTER_WEBAPP_READ_TIMEOUT,
-        YarnConfiguration.DEFAULT_ROUTER_WEBAPP_READ_TIMEOUT);
-    Assert.assertEquals(-1, connectTimeOut);
-    Assert.assertEquals(-1, readTimeout);
-
-    // Case2, Set the maximum value that exceeds the integer.
-    // Converted to int, there will be a value out of bounds.
-    YarnConfiguration conf1 = new YarnConfiguration();
-    long connectTimeOutLong = (long) Integer.MAX_VALUE + 1;
-    long readTimeOutLong = (long) Integer.MAX_VALUE + 1;
-    conf1.setLong(YarnConfiguration.ROUTER_WEBAPP_CONNECT_TIMEOUT, connectTimeOutLong);
-    conf1.setLong(YarnConfiguration.ROUTER_WEBAPP_READ_TIMEOUT, readTimeOutLong);
-
-    int connectTimeOut1 = (int) getTimeDuration(conf1,
-        YarnConfiguration.ROUTER_WEBAPP_CONNECT_TIMEOUT,
-        YarnConfiguration.DEFAULT_ROUTER_WEBAPP_CONNECT_TIMEOUT);
-    int readTimeout1 = (int) getTimeDuration(conf1,
-        YarnConfiguration.ROUTER_WEBAPP_READ_TIMEOUT,
-        YarnConfiguration.DEFAULT_ROUTER_WEBAPP_READ_TIMEOUT);
-    Assert.assertEquals(-2147483648, connectTimeOut1);
-    Assert.assertEquals(-2147483648, readTimeout1);
-  }
-
-  private long getTimeDuration(YarnConfiguration conf, String varName, long defaultValue) {
-    return conf.getTimeDuration(varName, defaultValue, TimeUnit.MILLISECONDS);
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestRouterWebServices.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestRouterWebServices.java
deleted file mode 100644
index dbcd7db21c9..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestRouterWebServices.java
+++ /dev/null
@@ -1,340 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import java.io.IOException;
-import java.security.PrivilegedExceptionAction;
-import java.util.Map;
-
-import javax.ws.rs.core.Response;
-
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.yarn.exceptions.YarnException;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationStatisticsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LabelsToNodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerTypeInfo;
-import org.apache.hadoop.yarn.server.router.webapp.RouterWebServices.RequestInterceptorChainWrapper;
-import org.apache.hadoop.yarn.server.webapp.dao.AppAttemptInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainerInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainersInfo;
-import org.junit.Assert;
-import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-/**
- * Test class to validate the WebService interceptor model inside the Router.
- */
-public class TestRouterWebServices extends BaseRouterWebServicesTest {
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestRouterWebServices.class);
-
-  private String user = "test1";
-
-  /**
-   * Test that all requests get forwarded to the last interceptor in the chain
-   * get back the responses.
-   */
-  @Test
-  public void testRouterWebServicesE2E() throws Exception {
-
-    ClusterInfo clusterInfo = get(user);
-    Assert.assertNotNull(clusterInfo);
-
-    ClusterInfo clusterInfo2 = getClusterInfo(user);
-    Assert.assertNotNull(clusterInfo2);
-
-    ClusterMetricsInfo clusterMetricsInfo = getClusterMetricsInfo(user);
-    Assert.assertNotNull(clusterMetricsInfo);
-
-    SchedulerTypeInfo schedulerTypeInfo = getSchedulerInfo(user);
-    Assert.assertNotNull(schedulerTypeInfo);
-
-    String dumpResult = dumpSchedulerLogs(user);
-    Assert.assertNotNull(dumpResult);
-
-    NodesInfo nodesInfo = getNodes(user);
-    Assert.assertNotNull(nodesInfo);
-
-    NodeInfo nodeInfo = getNode(user);
-    Assert.assertNotNull(nodeInfo);
-
-    AppsInfo appsInfo = getApps(user);
-    Assert.assertNotNull(appsInfo);
-
-    ActivitiesInfo activitiesInfo = getActivities(user);
-    Assert.assertNotNull(activitiesInfo);
-
-    AppActivitiesInfo appActiviesInfo = getAppActivities(user);
-    Assert.assertNotNull(appActiviesInfo);
-
-    ApplicationStatisticsInfo applicationStatisticsInfo =
-        getAppStatistics(user);
-    Assert.assertNotNull(applicationStatisticsInfo);
-
-    AppInfo appInfo = getApp(user);
-    Assert.assertNotNull(appInfo);
-
-    AppState appState = getAppState(user);
-    Assert.assertNotNull(appState);
-
-    Response response = updateAppState(user);
-    Assert.assertNotNull(response);
-
-    NodeToLabelsInfo nodeToLabelsInfo = getNodeToLabels(user);
-    Assert.assertNotNull(nodeToLabelsInfo);
-
-    LabelsToNodesInfo labelsToNodesInfo = getLabelsToNodes(user);
-    Assert.assertNotNull(labelsToNodesInfo);
-
-    Response response2 = replaceLabelsOnNodes(user);
-    Assert.assertNotNull(response2);
-
-    Response response3 = replaceLabelsOnNode(user);
-    Assert.assertNotNull(response3);
-
-    NodeLabelsInfo nodeLabelsInfo = getClusterNodeLabels(user);
-    Assert.assertNotNull(nodeLabelsInfo);
-
-    Response response4 = addToClusterNodeLabels(user);
-    Assert.assertNotNull(response4);
-
-    Response response5 = removeFromClusterNodeLabels(user);
-    Assert.assertNotNull(response5);
-
-    NodeLabelsInfo nodeLabelsInfo2 = getLabelsOnNode(user);
-    Assert.assertNotNull(nodeLabelsInfo2);
-
-    AppPriority appPriority = getAppPriority(user);
-    Assert.assertNotNull(appPriority);
-
-    Response response6 = updateApplicationPriority(user);
-    Assert.assertNotNull(response6);
-
-    AppQueue appQueue = getAppQueue(user);
-    Assert.assertNotNull(appQueue);
-
-    Response response7 = updateAppQueue(user);
-    Assert.assertNotNull(response7);
-
-    Response response8 = createNewApplication(user);
-    Assert.assertNotNull(response8);
-
-    Response response9 = submitApplication(user);
-    Assert.assertNotNull(response9);
-
-    Response response10 = postDelegationToken(user);
-    Assert.assertNotNull(response10);
-
-    Response response11 = postDelegationTokenExpiration(user);
-    Assert.assertNotNull(response11);
-
-    Response response12 = cancelDelegationToken(user);
-    Assert.assertNotNull(response12);
-
-    Response response13 = createNewReservation(user);
-    Assert.assertNotNull(response13);
-
-    Response response14 = submitReservation(user);
-    Assert.assertNotNull(response14);
-
-    Response response15 = updateReservation(user);
-    Assert.assertNotNull(response15);
-
-    Response response16 = deleteReservation(user);
-    Assert.assertNotNull(response16);
-
-    Response response17 = listReservation(user);
-    Assert.assertNotNull(response17);
-
-    AppTimeoutInfo appTimeoutInfo = getAppTimeout(user);
-    Assert.assertNotNull(appTimeoutInfo);
-
-    AppTimeoutsInfo appTimeoutsInfo = getAppTimeouts(user);
-    Assert.assertNotNull(appTimeoutsInfo);
-
-    Response response18 = updateApplicationTimeout(user);
-    Assert.assertNotNull(response18);
-
-    AppAttemptsInfo appAttemptsInfo = getAppAttempts(user);
-    Assert.assertNotNull(appAttemptsInfo);
-
-    AppAttemptInfo appAttemptInfo = getAppAttempt(user);
-    Assert.assertNotNull(appAttemptInfo);
-
-    ContainersInfo containersInfo = getContainers(user);
-    Assert.assertNotNull(containersInfo);
-
-    ContainerInfo containerInfo = getContainer(user);
-    Assert.assertNotNull(containerInfo);
-
-    Response response19 = updateSchedulerConfiguration(user);
-    Assert.assertNotNull(response19);
-
-    Response response20 = getSchedulerConfiguration(user);
-    Assert.assertNotNull(response20);
-  }
-
-  /**
-   * Tests if the pipeline is created properly.
-   */
-  @Test
-  public void testRequestInterceptorChainCreation() throws Exception {
-    RESTRequestInterceptor root =
-        super.getRouterWebServices().createRequestInterceptorChain();
-    int index = 0;
-    while (root != null) {
-      // The current pipeline is:
-      // PassThroughRESTRequestInterceptor - index = 0
-      // PassThroughRESTRequestInterceptor - index = 1
-      // PassThroughRESTRequestInterceptor - index = 2
-      // MockRESTRequestInterceptor - index = 3
-      switch (index) {
-      case 0: // Fall to the next case
-      case 1: // Fall to the next case
-      case 2:
-        // If index is equal to 0,1 or 2 we fall in this check
-        Assert.assertEquals(PassThroughRESTRequestInterceptor.class.getName(),
-            root.getClass().getName());
-        break;
-      case 3:
-        Assert.assertEquals(MockRESTRequestInterceptor.class.getName(),
-            root.getClass().getName());
-        break;
-      default:
-        Assert.fail();
-      }
-      root = root.getNextInterceptor();
-      index++;
-    }
-    Assert.assertEquals("The number of interceptors in chain does not match", 4,
-        index);
-  }
-
-  /**
-   * Test if the different chains for users are generated, and LRU cache is
-   * working as expected.
-   */
-  @Test
-  public void testUsersChainMapWithLRUCache()
-      throws YarnException, IOException, InterruptedException {
-    getInterceptorChain("test1");
-    getInterceptorChain("test2");
-    getInterceptorChain("test3");
-    getInterceptorChain("test4");
-    getInterceptorChain("test5");
-    getInterceptorChain("test6");
-    getInterceptorChain("test7");
-    getInterceptorChain("test8");
-
-    Map<String, RequestInterceptorChainWrapper> pipelines =
-        getRouterWebServices().getPipelines();
-    Assert.assertEquals(8, pipelines.size());
-
-    getInterceptorChain("test9");
-    getInterceptorChain("test10");
-    getInterceptorChain("test1");
-    getInterceptorChain("test11");
-
-    // The cache max size is defined in TEST_MAX_CACHE_SIZE
-    Assert.assertEquals(10, pipelines.size());
-
-    RequestInterceptorChainWrapper chain = pipelines.get("test1");
-    Assert.assertNotNull("test1 should not be evicted", chain);
-
-    chain = pipelines.get("test2");
-    Assert.assertNull("test2 should have been evicted", chain);
-  }
-
-  /**
-   * This test validates if the RESTRequestInterceptor chain for the user
-   * can build and init correctly when a multi-client process begins to
-   * request RouterWebServices for the same user simultaneously.
-   */
-  @Test
-  public void testWebPipelineConcurrent() throws InterruptedException {
-    final String user = "test1";
-
-    /*
-     * ClientTestThread is a thread to simulate a client request to get a
-     * RESTRequestInterceptor for the user.
-     */
-    class ClientTestThread extends Thread {
-      private RESTRequestInterceptor interceptor;
-      @Override public void run() {
-        try {
-          interceptor = pipeline();
-        } catch (IOException | InterruptedException e) {
-          e.printStackTrace();
-        }
-      }
-      private RESTRequestInterceptor pipeline()
-          throws IOException, InterruptedException {
-        return UserGroupInformation.createRemoteUser(user).doAs(
-            new PrivilegedExceptionAction<RESTRequestInterceptor>() {
-              @Override
-              public RESTRequestInterceptor run() throws Exception {
-                RequestInterceptorChainWrapper wrapper =
-                    getInterceptorChain(user);
-                RESTRequestInterceptor interceptor =
-                    wrapper.getRootInterceptor();
-                Assert.assertNotNull(interceptor);
-                LOG.info("init web interceptor success for user" + user);
-                return interceptor;
-              }
-            });
-      }
-    }
-
-    /*
-     * We start the first thread. It should not finish initing a chainWrapper
-     * before the other thread starts. In this way, the second thread can
-     * init at the same time of the first one. In the end, we validate that
-     * the 2 threads get the same chainWrapper without going into error.
-     */
-    ClientTestThread client1 = new ClientTestThread();
-    ClientTestThread client2 = new ClientTestThread();
-    client1.start();
-    client2.start();
-    client1.join();
-    client2.join();
-
-    Assert.assertNotNull(client1.interceptor);
-    Assert.assertNotNull(client2.interceptor);
-    Assert.assertSame(client1.interceptor, client2.interceptor);
-  }
-
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestRouterWebServicesREST.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestRouterWebServicesREST.java
deleted file mode 100644
index 40c9c76fc1c..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestRouterWebServicesREST.java
+++ /dev/null
@@ -1,1477 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import static javax.servlet.http.HttpServletResponse.SC_ACCEPTED;
-import static javax.servlet.http.HttpServletResponse.SC_BAD_REQUEST;
-import static javax.servlet.http.HttpServletResponse.SC_SERVICE_UNAVAILABLE;
-import static javax.servlet.http.HttpServletResponse.SC_OK;
-import static javax.ws.rs.core.MediaType.APPLICATION_JSON;
-import static javax.ws.rs.core.MediaType.APPLICATION_XML;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.ADD_NODE_LABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_APPID;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_APPID_APPATTEMPTS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_APPID_APPATTEMPTS_APPATTEMPTID;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_APPID_APPATTEMPTS_APPATTEMPTID_CONTAINERS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_APPID_PRIORITY;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_APPID_QUEUE;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_APPID_STATE;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_NEW_APPLICATION;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_TIMEOUT;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APPS_TIMEOUTS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APP_ID;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.APP_STATISTICS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.GET_NODE_LABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.GET_NODE_TO_LABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.INFO;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.LABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.LABEL_MAPPINGS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.METRICS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.NODE_RESOURCE;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.NODES;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.NODES_NODEID;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.NODES_NODEID_GETLABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.NODES_NODEID_REPLACE_LABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.REMOVE_NODE_LABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.REPLACE_NODE_TO_LABELS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.RESERVATION_DELETE;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.RESERVATION_NEW;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.RESERVATION_SUBMIT;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.RESERVATION_UPDATE;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.RM_WEB_SERVICE_PATH;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.SCHEDULER;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.SCHEDULER_ACTIVITIES;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.SCHEDULER_APP_ACTIVITIES;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.SCHEDULER_LOGS;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.STATES;
-import static org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWSConsts.TIME;
-import static org.apache.hadoop.yarn.server.router.webapp.HTTPMethods.POST;
-import static org.apache.hadoop.yarn.server.router.webapp.HTTPMethods.PUT;
-import static org.apache.hadoop.yarn.webapp.WebServicesTestUtils.assertResponseStatusCode;
-import static org.apache.hadoop.yarn.webapp.util.WebAppUtils.getNMWebAppURLWithoutScheme;
-import static org.apache.hadoop.yarn.webapp.util.WebAppUtils.getRMWebAppURLWithScheme;
-import static org.apache.hadoop.yarn.webapp.util.WebAppUtils.getRouterWebAppURLWithScheme;
-import static org.junit.Assert.assertEquals;
-import static org.junit.Assert.assertNotNull;
-import static org.junit.Assert.fail;
-
-import java.io.File;
-import java.io.IOException;
-import java.security.PrivilegedExceptionAction;
-import java.util.ArrayList;
-import java.util.LinkedList;
-import java.util.List;
-import java.util.Set;
-import java.util.concurrent.CompletionService;
-import java.util.concurrent.ExecutorCompletionService;
-import java.util.concurrent.ExecutorService;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
-import org.apache.hadoop.conf.Configuration;
-import org.apache.hadoop.security.UserGroupInformation;
-import org.apache.hadoop.test.GenericTestUtils;
-import org.apache.hadoop.util.concurrent.HadoopExecutors;
-import org.apache.hadoop.yarn.api.records.NodeLabel;
-import org.apache.hadoop.yarn.api.records.Resource;
-import org.apache.hadoop.yarn.api.records.ResourceOption;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.server.nodemanager.NodeManager;
-import org.apache.hadoop.yarn.server.resourcemanager.ResourceManager;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.RMWebServiceProtocol;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppActivitiesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppAttemptsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppPriority;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppQueue;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppState;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.AppTimeoutsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationStatisticsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ApplicationSubmissionContextInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ClusterMetricsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.LabelsToNodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NewApplication;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NewReservation;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsEntryList;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodeToLabelsInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.NodesInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationDeleteRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationSubmissionRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ReservationUpdateRequestInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.ResourceOptionInfo;
-import org.apache.hadoop.yarn.server.resourcemanager.webapp.dao.SchedulerTypeInfo;
-import org.apache.hadoop.yarn.server.router.Router;
-import org.apache.hadoop.yarn.server.webapp.WebServices;
-import org.apache.hadoop.yarn.server.webapp.dao.AppsInfo;
-import org.apache.hadoop.yarn.server.webapp.dao.ContainersInfo;
-import org.codehaus.jettison.json.JSONObject;
-import org.junit.AfterClass;
-import org.junit.BeforeClass;
-import org.junit.Test;
-
-import org.apache.hadoop.thirdparty.com.google.common.util.concurrent.ThreadFactoryBuilder;
-import com.sun.jersey.api.client.Client;
-import com.sun.jersey.api.client.ClientHandlerException;
-import com.sun.jersey.api.client.ClientResponse;
-import com.sun.jersey.api.client.WebResource;
-import com.sun.jersey.api.client.ClientResponse.Status;
-import com.sun.jersey.api.client.WebResource.Builder;
-
-import net.jcip.annotations.NotThreadSafe;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import javax.servlet.http.HttpServletRequest;
-
-/**
- * This test validate E2E the correctness of the RouterWebServices. It starts
- * Router, RM and NM in 3 different processes to avoid servlet conflicts. Each
- * test creates a REST call to Router and validate that the operation complete
- * successfully.
- */
-@NotThreadSafe
-public class TestRouterWebServicesREST {
-
-  /** The number of concurrent submissions for multi-thread test. */
-  private static final int NUM_THREADS_TESTS = 100;
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestRouterWebServicesREST.class);
-
-  private static String userName = "test";
-
-  private static JavaProcess rm;
-  private static JavaProcess nm;
-  private static JavaProcess router;
-
-  private static String rmAddress;
-  private static String routerAddress;
-  private static String nmAddress;
-
-  private static Configuration conf;
-
-  /**
-   * Wait until the webservice is up and running.
-   */
-  public static void waitWebAppRunning(
-      final String address, final String path) {
-    try {
-      final Client clientToRouter = Client.create();
-      final WebResource toRouter = clientToRouter
-          .resource(address)
-          .path(path);
-      GenericTestUtils.waitFor(() -> {
-        try {
-          ClientResponse response = toRouter
-              .accept(APPLICATION_JSON)
-              .get(ClientResponse.class);
-          if (response.getStatus() == SC_OK) {
-            // process is up and running
-            return true;
-          }
-        } catch (ClientHandlerException e) {
-          // process is not up and running
-        }
-        return false;
-      }, 1000, 20 * 1000);
-    } catch (Exception e) {
-      fail("Web app not running");
-    }
-  }
-
-  @BeforeClass
-  public static void setUp() throws Exception {
-    conf = new YarnConfiguration();
-
-    File baseDir = GenericTestUtils.getTestDir("processes");
-    baseDir.mkdirs();
-    String baseName = TestRouterWebServicesREST.class.getSimpleName();
-
-    File rmOutput = new File(baseDir, baseName + "-rm.log");
-    rmOutput.createNewFile();
-    List<String> addClasspath = new LinkedList<>();
-    addClasspath.add("../hadoop-yarn-server-timelineservice/target/classes");
-    rm = new JavaProcess(ResourceManager.class, addClasspath, rmOutput);
-    rmAddress = getRMWebAppURLWithScheme(conf);
-    waitWebAppRunning(rmAddress, RM_WEB_SERVICE_PATH);
-
-    File routerOutput = new File(baseDir, baseName + "-router.log");
-    routerOutput.createNewFile();
-    router = new JavaProcess(Router.class, routerOutput);
-    routerAddress = getRouterWebAppURLWithScheme(conf);
-    waitWebAppRunning(routerAddress, RM_WEB_SERVICE_PATH);
-
-    File nmOutput = new File(baseDir, baseName + "-nm.log");
-    nmOutput.createNewFile();
-    nm = new JavaProcess(NodeManager.class, nmOutput);
-    nmAddress = "http://" + getNMWebAppURLWithoutScheme(conf);
-    waitWebAppRunning(nmAddress, "/ws/v1/node");
-  }
-
-  @AfterClass
-  public static void stop() throws Exception {
-    if (nm != null) {
-      nm.stop();
-    }
-    if (router != null) {
-      router.stop();
-    }
-    if (rm != null) {
-      rm.stop();
-    }
-  }
-
-  /**
-   * Performs 2 GET calls one to RM and the one to Router. In positive case, it
-   * returns the 2 answers in a list.
-   */
-  private static <T> List<T> performGetCalls(final String path,
-      final Class<T> returnType, final String queryName,
-      final String queryValue) throws IOException, InterruptedException {
-    Client clientToRouter = Client.create();
-    WebResource toRouter = clientToRouter.resource(routerAddress).path(path);
-
-    Client clientToRM = Client.create();
-    WebResource toRM = clientToRM.resource(rmAddress).path(path);
-
-    final Builder toRouterBuilder;
-    final Builder toRMBuilder;
-
-    if (queryValue != null && queryName != null) {
-      toRouterBuilder = toRouter
-          .queryParam(queryName, queryValue)
-          .accept(APPLICATION_XML);
-      toRMBuilder = toRM
-          .queryParam(queryName, queryValue)
-          .accept(APPLICATION_XML);
-    } else {
-      toRouterBuilder = toRouter.accept(APPLICATION_XML);
-      toRMBuilder = toRM.accept(APPLICATION_XML);
-    }
-
-    return UserGroupInformation.createRemoteUser(userName)
-        .doAs((PrivilegedExceptionAction<List<T>>) () -> {
-          ClientResponse response =
-              toRouterBuilder.get(ClientResponse.class);
-          ClientResponse response2 = toRMBuilder.get(ClientResponse.class);
-          assertEquals(SC_OK, response.getStatus());
-          assertEquals(SC_OK, response2.getStatus());
-          List<T> responses = new ArrayList<>();
-          responses.add(response.getEntity(returnType));
-          responses.add(response2.getEntity(returnType));
-          return responses;
-        });
-  }
-
-  /**
-   * Performs a POST/PUT/DELETE call to Router and returns the ClientResponse.
-   */
-  private static ClientResponse performCall(final String webAddress,
-      final String queryKey, final String queryValue, final Object context,
-      final HTTPMethods method) throws IOException, InterruptedException {
-
-    return UserGroupInformation.createRemoteUser(userName)
-        .doAs((PrivilegedExceptionAction<ClientResponse>) () -> {
-          Client clientToRouter = Client.create();
-          WebResource toRouter = clientToRouter
-              .resource(routerAddress)
-              .path(webAddress);
-
-          WebResource toRouterWR = toRouter;
-          if (queryKey != null && queryValue != null) {
-            toRouterWR = toRouterWR.queryParam(queryKey, queryValue);
-          }
-
-          Builder builder;
-          if (context != null) {
-            builder = toRouterWR.entity(context, APPLICATION_JSON);
-            builder = builder.accept(APPLICATION_JSON);
-          } else {
-            builder = toRouter.accept(APPLICATION_JSON);
-          }
-
-          ClientResponse response = null;
-
-          switch (method) {
-          case DELETE:
-            response = builder.delete(ClientResponse.class);
-            break;
-          case POST:
-            response = builder.post(ClientResponse.class);
-            break;
-          case PUT:
-            response = builder.put(ClientResponse.class);
-            break;
-          default:
-            break;
-          }
-
-          return response;
-        });
-  }
-
-  /**
-   * This test validates the correctness of {@link RMWebServiceProtocol#get()}
-   * inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testInfoXML() throws Exception {
-
-    List<ClusterInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH, ClusterInfo.class, null, null);
-
-    ClusterInfo routerResponse = responses.get(0);
-    ClusterInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getRMVersion(),
-        routerResponse.getRMVersion());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getClusterInfo()} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testClusterInfoXML() throws Exception {
-
-    List<ClusterInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + INFO, ClusterInfo.class, null, null);
-
-    ClusterInfo routerResponse = responses.get(0);
-    ClusterInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getRMVersion(),
-        routerResponse.getRMVersion());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getClusterMetricsInfo()} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testMetricsInfoXML() throws Exception {
-
-    List<ClusterMetricsInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + METRICS, ClusterMetricsInfo.class, null, null);
-
-    ClusterMetricsInfo routerResponse = responses.get(0);
-    ClusterMetricsInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getActiveNodes(),
-        routerResponse.getActiveNodes());
-  }
-
-  /*
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getSchedulerInfo()} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testSchedulerInfoXML() throws Exception {
-
-    List<SchedulerTypeInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + SCHEDULER, SchedulerTypeInfo.class, null, null);
-
-    SchedulerTypeInfo routerResponse = responses.get(0);
-    SchedulerTypeInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getSchedulerInfo().getSchedulerType(),
-        routerResponse.getSchedulerInfo().getSchedulerType());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getNodes(String)} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testNodesEmptyXML() throws Exception {
-
-    List<NodesInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + NODES, NodesInfo.class, null, null);
-
-    NodesInfo routerResponse = responses.get(0);
-    NodesInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getNodes().size(),
-        routerResponse.getNodes().size());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getNodes(String)} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testNodesXML() throws Exception {
-
-    List<NodesInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + NODES, NodesInfo.class, STATES, "LOST");
-
-    NodesInfo routerResponse = responses.get(0);
-    NodesInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getNodes().size(),
-        routerResponse.getNodes().size());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getNode(String)} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testNodeXML() throws Exception {
-
-    List<NodeInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + format(NODES_NODEID, getNodeId()),
-        NodeInfo.class, null, null);
-
-    NodeInfo routerResponse = responses.get(0);
-    NodeInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getVersion(),
-        routerResponse.getVersion());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#updateNodeResource} inside Router.
-   */
-  @Test
-  public void testUpdateNodeResource() throws Exception {
-
-    // wait until a node shows up and check the resources
-    GenericTestUtils.waitFor(() -> getNodeId() != null, 100, 5 * 1000);
-    String nodeId = getNodeId();
-
-    // assert memory and default vcores
-    List<NodeInfo> responses0 = performGetCalls(
-        RM_WEB_SERVICE_PATH + format(NODES_NODEID, getNodeId()),
-        NodeInfo.class, null, null);
-    NodeInfo nodeInfo0 = responses0.get(0);
-    assertEquals(8192, nodeInfo0.getTotalResource().getMemorySize());
-    assertEquals(8, nodeInfo0.getTotalResource().getvCores());
-
-    // update memory to 4096MB and 5 cores
-    Resource resource = Resource.newInstance(4096, 5);
-    ResourceOptionInfo resourceOption = new ResourceOptionInfo(
-        ResourceOption.newInstance(resource, 1000));
-    ClientResponse routerResponse = performCall(
-        RM_WEB_SERVICE_PATH + format(NODE_RESOURCE, nodeId),
-        null, null, resourceOption, POST);
-    assertResponseStatusCode(Status.OK, routerResponse.getStatusInfo());
-    JSONObject json = routerResponse.getEntity(JSONObject.class);
-    JSONObject totalResource = json.getJSONObject("resourceInfo");
-    assertEquals(resource.getMemorySize(), totalResource.getLong("memory"));
-    assertEquals(resource.getVirtualCores(), totalResource.getLong("vCores"));
-
-    // assert updated memory and cores
-    List<NodeInfo> responses1 = performGetCalls(
-        RM_WEB_SERVICE_PATH + format(NODES_NODEID, getNodeId()),
-        NodeInfo.class, null, null);
-    NodeInfo nodeInfo1 = responses1.get(0);
-    assertEquals(4096, nodeInfo1.getTotalResource().getMemorySize());
-    assertEquals(5, nodeInfo1.getTotalResource().getvCores());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getActivities(HttpServletRequest, String, String)} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testActiviesXML() throws Exception {
-
-    List<ActivitiesInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + SCHEDULER_ACTIVITIES,
-        ActivitiesInfo.class, null, null);
-
-    ActivitiesInfo routerResponse = responses.get(0);
-    ActivitiesInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getAppActivities} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testAppActivitiesXML() throws Exception {
-
-    String appId = submitApplication();
-
-    List<AppActivitiesInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + SCHEDULER_APP_ACTIVITIES,
-        AppActivitiesInfo.class, APP_ID, appId);
-
-    AppActivitiesInfo routerResponse = responses.get(0);
-    AppActivitiesInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getAppStatistics} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testAppStatisticsXML() throws Exception {
-
-    submitApplication();
-
-    List<ApplicationStatisticsInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + APP_STATISTICS,
-        ApplicationStatisticsInfo.class, STATES, "RUNNING");
-
-    ApplicationStatisticsInfo routerResponse = responses.get(0);
-    ApplicationStatisticsInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getStatItems().size(),
-        routerResponse.getStatItems().size());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#dumpSchedulerLogs} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testDumpSchedulerLogsXML() throws Exception {
-
-    // Test with a wrong HTTP method
-    ClientResponse badResponse =
-        performCall(RM_WEB_SERVICE_PATH + SCHEDULER_LOGS,
-            null, null, null, PUT);
-
-    assertEquals(SC_SERVICE_UNAVAILABLE, badResponse.getStatus());
-
-    // Test with the correct HTTP method
-    ClientResponse response = performCall(
-        RM_WEB_SERVICE_PATH + SCHEDULER_LOGS, TIME, "1", null, POST);
-
-    assertEquals(SC_BAD_REQUEST, response.getStatus());
-    String ci = response.getEntity(String.class);
-    assertNotNull(ci);
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#createNewApplication} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testNewApplicationXML() throws Exception {
-
-    // Test with a wrong HTTP method
-    ClientResponse badResponse = performCall(
-        RM_WEB_SERVICE_PATH + APPS_NEW_APPLICATION, null,
-        null, null, PUT);
-
-    assertEquals(SC_SERVICE_UNAVAILABLE, badResponse.getStatus());
-
-    // Test with the correct HTTP method
-    ClientResponse response = performCall(
-        RM_WEB_SERVICE_PATH + APPS_NEW_APPLICATION, null,
-        null, null, POST);
-
-    assertEquals(SC_OK, response.getStatus());
-    NewApplication ci = response.getEntity(NewApplication.class);
-    assertNotNull(ci);
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#submitApplication} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testSubmitApplicationXML() throws Exception {
-
-    // Test with a wrong HTTP method
-    ClientResponse badResponse = performCall(
-        RM_WEB_SERVICE_PATH + APPS, null, null, null, PUT);
-
-    assertEquals(SC_SERVICE_UNAVAILABLE, badResponse.getStatus());
-
-    // Test with the correct HTTP method
-    ApplicationSubmissionContextInfo context =
-        new ApplicationSubmissionContextInfo();
-    context.setApplicationId(getNewApplicationId().getApplicationId());
-
-    ClientResponse response = performCall(
-        RM_WEB_SERVICE_PATH + APPS, null, null, context, POST);
-
-    assertEquals(SC_ACCEPTED, response.getStatus());
-    String ci = response.getEntity(String.class);
-    assertNotNull(ci);
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getApps} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testAppsXML() throws Exception {
-
-    submitApplication();
-
-    List<AppsInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + APPS, AppsInfo.class, null, null);
-
-    AppsInfo routerResponse = responses.get(0);
-    AppsInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getApps().size(),
-        routerResponse.getApps().size());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getApp} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testAppXML() throws Exception {
-
-    String appId = submitApplication();
-
-    List<AppInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + format(APPS_APPID, appId),
-        AppInfo.class, null, null);
-
-    AppInfo routerResponse = responses.get(0);
-    AppInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getAMHostHttpAddress(),
-        routerResponse.getAMHostHttpAddress());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getAppAttempts} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testAppAttemptXML() throws Exception {
-
-    String appId = submitApplication();
-
-    List<AppAttemptsInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_APPATTEMPTS, appId),
-        AppAttemptsInfo.class, null, null);
-
-    AppAttemptsInfo routerResponse = responses.get(0);
-    AppAttemptsInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getAttempts().size(),
-        routerResponse.getAttempts().size());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getAppState} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testAppStateXML() throws Exception {
-
-    String appId = submitApplication();
-
-    List<AppState> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_STATE, appId),
-        AppState.class, null, null);
-
-    AppState routerResponse = responses.get(0);
-    AppState rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getState(),
-        routerResponse.getState());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#updateAppState} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testUpdateAppStateXML() throws Exception {
-
-    String appId = submitApplication();
-    String pathApp =
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_STATE, appId);
-
-    // Test with a wrong HTTP method
-    ClientResponse badResponse = performCall(
-        pathApp, null, null, null, POST);
-
-    assertEquals(SC_SERVICE_UNAVAILABLE, badResponse.getStatus());
-
-    // Test with the correct HTTP method
-    AppState appState = new AppState("KILLED");
-
-    ClientResponse response = performCall(
-        pathApp, null, null, appState, PUT);
-
-    assertEquals(SC_ACCEPTED, response.getStatus());
-    AppState ci = response.getEntity(AppState.class);
-    assertNotNull(ci);
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getAppPriority} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testAppPriorityXML() throws Exception {
-
-    String appId = submitApplication();
-
-    List<AppPriority> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_PRIORITY, appId),
-        AppPriority.class, null, null);
-
-    AppPriority routerResponse = responses.get(0);
-    AppPriority rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(rmResponse.getPriority(), routerResponse.getPriority());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#updateApplicationPriority(
-   *     AppPriority, HttpServletRequest, String)} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testUpdateAppPriorityXML() throws Exception {
-
-    String appId = submitApplication();
-
-    // Test with a wrong HTTP method
-    ClientResponse badResponse = performCall(
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_PRIORITY, appId),
-        null, null, null, POST);
-
-    assertEquals(SC_SERVICE_UNAVAILABLE, badResponse.getStatus());
-
-    // Test with the correct HTTP method
-    AppPriority appPriority = new AppPriority(1);
-
-    ClientResponse response = performCall(
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_PRIORITY, appId),
-        null, null, appPriority, PUT);
-
-    assertEquals(SC_OK, response.getStatus());
-    AppPriority ci = response.getEntity(AppPriority.class);
-    assertNotNull(ci);
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getAppQueue(HttpServletRequest, String)} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testAppQueueXML() throws Exception {
-
-    String appId = submitApplication();
-
-    List<AppQueue> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_QUEUE, appId),
-        AppQueue.class, null, null);
-
-    AppQueue routerResponse = responses.get(0);
-    AppQueue rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(rmResponse.getQueue(), routerResponse.getQueue());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#updateAppQueue(AppQueue, HttpServletRequest, String)}
-   * inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testUpdateAppQueueXML() throws Exception {
-
-    String appId = submitApplication();
-
-    // Test with a wrong HTTP method
-    ClientResponse badResponse = performCall(
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_QUEUE, appId),
-        null, null, null, POST);
-
-    assertEquals(SC_SERVICE_UNAVAILABLE, badResponse.getStatus());
-
-    // Test with the correct HTTP method
-    AppQueue appQueue = new AppQueue("default");
-
-    ClientResponse response = performCall(
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_QUEUE, appId),
-        null, null, appQueue, PUT);
-
-    assertEquals(SC_OK, response.getStatus());
-    AppQueue ci = response.getEntity(AppQueue.class);
-    assertNotNull(ci);
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getAppTimeouts} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testAppTimeoutsXML() throws Exception {
-
-    String appId = submitApplication();
-
-    List<AppTimeoutsInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + format(APPS_TIMEOUTS, appId),
-        AppTimeoutsInfo.class, null, null);
-
-    AppTimeoutsInfo routerResponse = responses.get(0);
-    AppTimeoutsInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getAppTimeouts().size(),
-        routerResponse.getAppTimeouts().size());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getAppTimeout} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testAppTimeoutXML() throws Exception {
-
-    String appId = submitApplication();
-    String pathApp = RM_WEB_SERVICE_PATH + format(APPS_TIMEOUTS, appId);
-    List<AppTimeoutInfo> responses = performGetCalls(
-        pathApp + "/" + "LIFETIME", AppTimeoutInfo.class, null, null);
-
-    AppTimeoutInfo routerResponse = responses.get(0);
-    AppTimeoutInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getExpireTime(),
-        routerResponse.getExpireTime());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#updateApplicationTimeout}
-   * inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testUpdateAppTimeoutsXML() throws Exception {
-
-    String appId = submitApplication();
-
-    // Test with a wrong HTTP method
-    ClientResponse badResponse = performCall(
-        RM_WEB_SERVICE_PATH + format(APPS_TIMEOUT, appId),
-        null, null, null, POST);
-
-    assertEquals(SC_SERVICE_UNAVAILABLE, badResponse.getStatus());
-
-    // Test with a bad request
-    AppTimeoutInfo appTimeoutInfo = new AppTimeoutInfo();
-
-    ClientResponse response = performCall(
-        RM_WEB_SERVICE_PATH + format(APPS_TIMEOUT, appId),
-        null, null, appTimeoutInfo, PUT);
-
-    assertEquals(SC_BAD_REQUEST, response.getStatus());
-    String ci = response.getEntity(String.class);
-    assertNotNull(ci);
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#createNewReservation(HttpServletRequest)} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testNewReservationXML() throws Exception {
-
-    // Test with a wrong HTTP method
-    ClientResponse badResponse = performCall(
-        RM_WEB_SERVICE_PATH + RESERVATION_NEW,
-        null, null, null, PUT);
-
-    assertEquals(SC_SERVICE_UNAVAILABLE, badResponse.getStatus());
-
-    // Test with the correct HTTP method
-    ClientResponse response = performCall(
-        RM_WEB_SERVICE_PATH + RESERVATION_NEW,
-        null, null, null, POST);
-
-    assertEquals(SC_OK, response.getStatus());
-    NewReservation ci = response.getEntity(NewReservation.class);
-    assertNotNull(ci);
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#submitReservation(
-   *     ReservationSubmissionRequestInfo, HttpServletRequest)} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testSubmitReservationXML() throws Exception {
-
-    // Test with a wrong HTTP method
-    ClientResponse badResponse = performCall(
-        RM_WEB_SERVICE_PATH + RESERVATION_SUBMIT, null,
-        null, null, PUT);
-
-    assertEquals(SC_SERVICE_UNAVAILABLE, badResponse.getStatus());
-
-    // Test with the correct HTTP method
-    ReservationSubmissionRequestInfo context =
-        new ReservationSubmissionRequestInfo();
-    context.setReservationId(getNewReservationId().getReservationId());
-    // ReservationDefinition is null
-
-    ClientResponse response = performCall(
-        RM_WEB_SERVICE_PATH + RESERVATION_SUBMIT, null, null, context, POST);
-
-    assertEquals(SC_BAD_REQUEST, response.getStatus());
-    String ci = response.getEntity(String.class);
-    assertNotNull(ci);
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#updateReservation(
-   *     ReservationUpdateRequestInfo, HttpServletRequest)} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testUpdateReservationXML() throws Exception {
-
-    // Test with a wrong HTTP method
-    ClientResponse badResponse = performCall(
-        RM_WEB_SERVICE_PATH + RESERVATION_UPDATE, null, null, null, PUT);
-
-    assertEquals(SC_SERVICE_UNAVAILABLE, badResponse.getStatus());
-
-    // Test with the correct HTTP method
-    String reservationId = getNewReservationId().getReservationId();
-    ReservationUpdateRequestInfo context = new ReservationUpdateRequestInfo();
-    context.setReservationId(reservationId);
-
-    ClientResponse response = performCall(
-        RM_WEB_SERVICE_PATH + RESERVATION_UPDATE, null, null, context, POST);
-
-    assertEquals(SC_BAD_REQUEST, response.getStatus());
-    String ci = response.getEntity(String.class);
-    assertNotNull(ci);
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#deleteReservation(
-   *     ReservationDeleteRequestInfo, HttpServletRequest)} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testDeleteReservationXML() throws Exception {
-
-    // Test with a wrong HTTP method
-    ClientResponse badResponse = performCall(
-        RM_WEB_SERVICE_PATH + RESERVATION_DELETE, null, null, null, PUT);
-
-    assertEquals(SC_SERVICE_UNAVAILABLE, badResponse.getStatus());
-
-    // Test with the correct HTTP method
-    String reservationId = getNewReservationId().getReservationId();
-    ReservationDeleteRequestInfo context = new ReservationDeleteRequestInfo();
-    context.setReservationId(reservationId);
-
-    ClientResponse response = performCall(
-        RM_WEB_SERVICE_PATH + RESERVATION_DELETE, null, null, context, POST);
-
-    assertEquals(SC_BAD_REQUEST, response.getStatus());
-    String ci = response.getEntity(String.class);
-    assertNotNull(ci);
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getNodeToLabels(HttpServletRequest)} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testGetNodeToLabelsXML() throws Exception {
-
-    List<NodeToLabelsInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + GET_NODE_TO_LABELS,
-        NodeToLabelsInfo.class, null, null);
-
-    NodeToLabelsInfo routerResponse = responses.get(0);
-    NodeToLabelsInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getNodeToLabels().size(),
-        routerResponse.getNodeToLabels().size());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getClusterNodeLabels(HttpServletRequest)} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testGetClusterNodeLabelsXML() throws Exception {
-
-    List<NodeLabelsInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + GET_NODE_LABELS,
-        NodeLabelsInfo.class, null, null);
-
-    NodeLabelsInfo routerResponse = responses.get(0);
-    NodeLabelsInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getNodeLabels().size(),
-        routerResponse.getNodeLabels().size());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getLabelsOnNode(HttpServletRequest, String)} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testGetLabelsOnNodeXML() throws Exception {
-
-    List<NodeLabelsInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + format(NODES_NODEID_GETLABELS, getNodeId()),
-        NodeLabelsInfo.class, null, null);
-
-    NodeLabelsInfo routerResponse = responses.get(0);
-    NodeLabelsInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getNodeLabels().size(),
-        routerResponse.getNodeLabels().size());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getLabelsToNodes(Set<String>)} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testGetLabelsMappingEmptyXML() throws Exception {
-
-    List<LabelsToNodesInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + LABEL_MAPPINGS,
-        LabelsToNodesInfo.class, null, null);
-
-    LabelsToNodesInfo routerResponse = responses.get(0);
-    LabelsToNodesInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getLabelsToNodes().size(),
-        routerResponse.getLabelsToNodes().size());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#getLabelsToNodes(Set<String>)} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testGetLabelsMappingXML() throws Exception {
-
-    List<LabelsToNodesInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + LABEL_MAPPINGS,
-        LabelsToNodesInfo.class, LABELS, "label1");
-
-    LabelsToNodesInfo routerResponse = responses.get(0);
-    LabelsToNodesInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getLabelsToNodes().size(),
-        routerResponse.getLabelsToNodes().size());
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#addToClusterNodeLabels(
-   *     NodeLabelsInfo, HttpServletRequest)} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testAddToClusterNodeLabelsXML() throws Exception {
-
-    // Test with a wrong HTTP method
-    ClientResponse badResponse = performCall(
-        RM_WEB_SERVICE_PATH + ADD_NODE_LABELS,
-        null, null, null, PUT);
-
-    assertEquals(SC_SERVICE_UNAVAILABLE, badResponse.getStatus());
-
-    // Test with the correct HTTP method
-
-    List<NodeLabel> nodeLabels = new ArrayList<>();
-    nodeLabels.add(NodeLabel.newInstance("default"));
-    NodeLabelsInfo context = new NodeLabelsInfo(nodeLabels);
-
-    ClientResponse response = performCall(
-        RM_WEB_SERVICE_PATH + ADD_NODE_LABELS, null, null, context, POST);
-
-    assertEquals(SC_OK, response.getStatus());
-    String ci = response.getEntity(String.class);
-    assertNotNull(ci);
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#removeFromClusterNodeLabels} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testRemoveFromClusterNodeLabelsXML()
-      throws Exception {
-
-    // Test with a wrong HTTP method
-    ClientResponse badResponse = performCall(
-        RM_WEB_SERVICE_PATH + REMOVE_NODE_LABELS, null, null, null, PUT);
-
-    assertEquals(SC_SERVICE_UNAVAILABLE, badResponse.getStatus());
-
-    // Test with the correct HTTP method
-    addNodeLabel();
-
-    ClientResponse response = performCall(
-        RM_WEB_SERVICE_PATH + REMOVE_NODE_LABELS,
-        LABELS, "default", null, POST);
-
-    assertEquals(SC_OK, response.getStatus());
-    String ci = response.getEntity(String.class);
-    assertNotNull(ci);
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#replaceLabelsOnNodes} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testReplaceLabelsOnNodesXML() throws Exception {
-
-    // Test with a wrong HTTP method
-    ClientResponse badResponse = performCall(
-        RM_WEB_SERVICE_PATH + REPLACE_NODE_TO_LABELS, null, null, null, PUT);
-
-    assertEquals(SC_SERVICE_UNAVAILABLE, badResponse.getStatus());
-
-    // Test with the correct HTTP method
-    addNodeLabel();
-
-    NodeToLabelsEntryList context = new NodeToLabelsEntryList();
-
-    ClientResponse response = performCall(
-        RM_WEB_SERVICE_PATH + REPLACE_NODE_TO_LABELS,
-        null, null, context, POST);
-
-    assertEquals(SC_OK, response.getStatus());
-    String ci = response.getEntity(String.class);
-    assertNotNull(ci);
-  }
-
-  /**
-   * This test validates the correctness of
-   * {@link RMWebServiceProtocol#replaceLabelsOnNode} inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testReplaceLabelsOnNodeXML() throws Exception {
-
-    // Test with a wrong HTTP method
-    String pathNode = RM_WEB_SERVICE_PATH +
-        format(NODES_NODEID_REPLACE_LABELS, getNodeId());
-    ClientResponse badResponse = performCall(
-        pathNode, null, null, null, PUT);
-
-    assertEquals(SC_SERVICE_UNAVAILABLE, badResponse.getStatus());
-
-    // Test with the correct HTTP method
-    addNodeLabel();
-
-    ClientResponse response = performCall(
-        pathNode, LABELS, "default", null, POST);
-
-    assertEquals(SC_OK, response.getStatus());
-    String ci = response.getEntity(String.class);
-    assertNotNull(ci);
-  }
-
-  /**
-   * This test validates the correctness of {@link WebServices#getAppAttempt}
-   * inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testGetAppAttemptXML() throws Exception {
-
-    String appId = submitApplication();
-    String pathAttempts = RM_WEB_SERVICE_PATH + format(
-        APPS_APPID_APPATTEMPTS_APPATTEMPTID, appId, getAppAttempt(appId));
-    List<AppAttemptInfo> responses = performGetCalls(
-        pathAttempts, AppAttemptInfo.class, null, null);
-
-    AppAttemptInfo routerResponse = responses.get(0);
-    AppAttemptInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getAppAttemptId(),
-        routerResponse.getAppAttemptId());
-  }
-
-  /**
-   * This test validates the correctness of {@link WebServices#getContainers}
-   * inside Router.
-   */
-  @Test(timeout = 2000)
-  public void testGetContainersXML() throws Exception {
-
-    String appId = submitApplication();
-    String pathAttempts = RM_WEB_SERVICE_PATH + format(
-        APPS_APPID_APPATTEMPTS_APPATTEMPTID_CONTAINERS,
-        appId, getAppAttempt(appId));
-    List<ContainersInfo> responses = performGetCalls(
-        pathAttempts, ContainersInfo.class, null, null);
-
-    ContainersInfo routerResponse = responses.get(0);
-    ContainersInfo rmResponse = responses.get(1);
-
-    assertNotNull(routerResponse);
-    assertNotNull(rmResponse);
-
-    assertEquals(
-        rmResponse.getContainers().size(),
-        routerResponse.getContainers().size());
-  }
-
-  @Test(timeout = 60000)
-  public void testGetAppsMultiThread() throws Exception {
-    final int iniNumApps = getNumApps();
-
-    // This submits an application
-    testGetContainersXML();
-    // This submits an application
-    testAppsXML();
-
-    // Wait at most 10 seconds until we see all the applications
-    GenericTestUtils.waitFor(() -> {
-      try {
-        // Check if we have the 2 apps we submitted
-        return getNumApps() == iniNumApps + 2;
-      } catch (Exception e) {
-        fail();
-      }
-      return false;
-    }, 100, 10 * 1000);
-
-    // Multithreaded getApps()
-    ExecutorService threadpool = HadoopExecutors.newCachedThreadPool(
-        new ThreadFactoryBuilder()
-            .setNameFormat("REST Tester #%d")
-            .build());
-    CompletionService<Void> svc = new ExecutorCompletionService<>(threadpool);
-    try {
-      // Submit a bunch of operations concurrently
-      for (int i = 0; i < NUM_THREADS_TESTS; i++) {
-        svc.submit(() -> {
-          assertEquals(iniNumApps + 2, getNumApps());
-          return null;
-        });
-      }
-    } finally {
-      threadpool.shutdown();
-    }
-
-    assertEquals(iniNumApps + 2, getNumApps());
-  }
-
-  /**
-   * Get the number of applications in the system.
-   * @return Number of applications in the system
-   * @throws Exception If we cannot get the applications.
-   */
-  private int getNumApps() throws Exception {
-    List<AppsInfo> responses = performGetCalls(
-        RM_WEB_SERVICE_PATH + APPS, AppsInfo.class, null, null);
-    AppsInfo routerResponse = responses.get(0);
-    AppsInfo rmResponse = responses.get(1);
-    assertEquals(rmResponse.getApps().size(), routerResponse.getApps().size());
-    return rmResponse.getApps().size();
-  }
-
-  private String getNodeId() {
-    Client clientToRM = Client.create();
-    WebResource toRM = clientToRM.resource(rmAddress)
-        .path(RM_WEB_SERVICE_PATH + NODES);
-    ClientResponse response =
-        toRM.accept(APPLICATION_XML).get(ClientResponse.class);
-    NodesInfo ci = response.getEntity(NodesInfo.class);
-    List<NodeInfo> nodes = ci.getNodes();
-    if (nodes.isEmpty()) {
-      return null;
-    }
-    return nodes.get(0).getNodeId();
-  }
-
-  private NewApplication getNewApplicationId() {
-    Client clientToRM = Client.create();
-    WebResource toRM = clientToRM.resource(rmAddress)
-        .path(RM_WEB_SERVICE_PATH + APPS_NEW_APPLICATION);
-    ClientResponse response =
-        toRM.accept(APPLICATION_XML).post(ClientResponse.class);
-    return response.getEntity(NewApplication.class);
-  }
-
-  private String submitApplication() {
-    ApplicationSubmissionContextInfo context =
-        new ApplicationSubmissionContextInfo();
-    String appId = getNewApplicationId().getApplicationId();
-    context.setApplicationId(appId);
-
-    Client clientToRouter = Client.create();
-    WebResource toRM = clientToRouter.resource(rmAddress)
-        .path(RM_WEB_SERVICE_PATH + APPS);
-    toRM.entity(context, APPLICATION_XML)
-        .accept(APPLICATION_XML)
-        .post(ClientResponse.class);
-    return appId;
-  }
-
-  private NewReservation getNewReservationId() {
-    Client clientToRM = Client.create();
-    WebResource toRM = clientToRM.resource(rmAddress)
-        .path(RM_WEB_SERVICE_PATH + RESERVATION_NEW);
-    ClientResponse response = toRM.
-        accept(APPLICATION_XML)
-        .post(ClientResponse.class);
-    return response.getEntity(NewReservation.class);
-  }
-
-  private String addNodeLabel() {
-    Client clientToRM = Client.create();
-    WebResource toRM = clientToRM.resource(rmAddress)
-        .path(RM_WEB_SERVICE_PATH + ADD_NODE_LABELS);
-    List<NodeLabel> nodeLabels = new ArrayList<>();
-    nodeLabels.add(NodeLabel.newInstance("default"));
-    NodeLabelsInfo context = new NodeLabelsInfo(nodeLabels);
-    ClientResponse response = toRM
-        .entity(context, APPLICATION_XML)
-        .accept(APPLICATION_XML)
-        .post(ClientResponse.class);
-    return response.getEntity(String.class);
-  }
-
-  private String getAppAttempt(String appId) {
-    Client clientToRM = Client.create();
-    String pathAppAttempt =
-        RM_WEB_SERVICE_PATH + format(APPS_APPID_APPATTEMPTS, appId);
-    WebResource toRM = clientToRM.resource(rmAddress)
-        .path(pathAppAttempt);
-    ClientResponse response = toRM
-        .accept(APPLICATION_XML)
-        .get(ClientResponse.class);
-    AppAttemptsInfo ci = response.getEntity(AppAttemptsInfo.class);
-    return ci.getAttempts().get(0).getAppAttemptId();
-  }
-
-  /**
-   * Convert format using {name} (HTTP base) into %s (Java based).
-   * @param format Initial format using {}.
-   * @param args Arguments for the format.
-   * @return New format using %s.
-   */
-  private static String format(String format, Object... args) {
-    Pattern p = Pattern.compile("\\{.*?}");
-    Matcher m = p.matcher(format);
-    String newFormat = m.replaceAll("%s");
-    return String.format(newFormat, args);
-  }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestableFederationInterceptorREST.java b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestableFederationInterceptorREST.java
deleted file mode 100644
index 0e37b7c9749..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/java/org/apache/hadoop/yarn/server/router/webapp/TestableFederationInterceptorREST.java
+++ /dev/null
@@ -1,124 +0,0 @@
-/**
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * "License"); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an "AS IS" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.hadoop.yarn.server.router.webapp;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.Map;
-
-import org.apache.hadoop.metrics2.lib.DefaultMetricsSystem;
-import org.apache.hadoop.yarn.conf.YarnConfiguration;
-import org.apache.hadoop.yarn.server.federation.store.records.SubClusterId;
-import org.apache.hadoop.yarn.server.resourcemanager.MockRM;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.ResourceScheduler;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler;
-import org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacitySchedulerConfiguration;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import static org.apache.hadoop.yarn.server.router.webapp.BaseRouterWebServicesTest.QUEUE_DEDICATED_FULL;
-import static org.apache.hadoop.yarn.server.router.webapp.BaseRouterWebServicesTest.QUEUE_DEFAULT_FULL;
-import static org.apache.hadoop.yarn.server.router.webapp.BaseRouterWebServicesTest.QUEUE_DEFAULT;
-import static org.apache.hadoop.yarn.server.router.webapp.BaseRouterWebServicesTest.QUEUE_DEDICATED;
-
-/**
- * Extends the FederationInterceptorREST and overrides methods to provide a
- * testable implementation of FederationInterceptorREST.
- */
-public class TestableFederationInterceptorREST
-    extends FederationInterceptorREST {
-
-  private List<SubClusterId> badSubCluster = new ArrayList<>();
-  private MockRM mockRM = null;
-
-  private static final Logger LOG =
-      LoggerFactory.getLogger(TestableFederationInterceptorREST.class);
-
-  /**
-   * For testing purpose, some subclusters has to be down to simulate particular
-   * scenarios as RM Failover, network issues. For this reason we keep track of
-   * these bad subclusters. This method make the subcluster unusable.
-   *
-   * @param badSC the subcluster to make unusable
-   */
-  protected void registerBadSubCluster(SubClusterId badSC) {
-
-    // Adding in the cache the bad SubCluster, in this way we can stop them
-    getOrCreateInterceptorForSubCluster(badSC, "1.2.3.4:4");
-
-    badSubCluster.add(badSC);
-    MockDefaultRequestInterceptorREST interceptor =
-        (MockDefaultRequestInterceptorREST) super.getInterceptorForSubCluster(
-            badSC);
-    interceptor.setRunning(false);
-  }
-
-  protected void setupResourceManager() throws IOException {
-
-    if (mockRM != null) {
-      return;
-    }
-
-    try {
-
-      DefaultMetricsSystem.setMiniClusterMode(true);
-      CapacitySchedulerConfiguration conf = new CapacitySchedulerConfiguration();
-
-      // Define default queue
-      conf.setCapacity(QUEUE_DEFAULT_FULL, 20);
-      // Define dedicated queues
-      String[] queues = new String[]{QUEUE_DEFAULT, QUEUE_DEDICATED};
-      conf.setQueues(CapacitySchedulerConfiguration.ROOT, queues);
-      conf.setCapacity(QUEUE_DEDICATED_FULL, 80);
-      conf.setReservable(QUEUE_DEDICATED_FULL, true);
-
-      conf.setClass(YarnConfiguration.RM_SCHEDULER,
-          CapacityScheduler.class, ResourceScheduler.class);
-      conf.setBoolean(YarnConfiguration.RM_RESERVATION_SYSTEM_ENABLE, true);
-      conf.setBoolean(YarnConfiguration.RM_WORK_PRESERVING_RECOVERY_ENABLED, false);
-
-      mockRM = new MockRM(conf);
-      mockRM.start();
-      mockRM.registerNode("127.0.0.1:5678", 100*1024, 100);
-
-      Map<SubClusterId, DefaultRequestInterceptorREST> interceptors = super.getInterceptors();
-      for (DefaultRequestInterceptorREST item : interceptors.values()) {
-        MockDefaultRequestInterceptorREST interceptor = (MockDefaultRequestInterceptorREST) item;
-        interceptor.setMockRM(mockRM);
-      }
-    } catch (Exception e) {
-      LOG.error("setupResourceManager failed.", e);
-      throw new IOException(e);
-    }
-  }
-
-  @Override
-  public void shutdown() {
-    if (mockRM != null) {
-      mockRM.stop();
-      mockRM = null;
-    }
-    super.shutdown();
-  }
-
-  public MockRM getMockRM() {
-    return mockRM;
-  }
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/capability b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/capability
deleted file mode 100644
index e6cf4a1cd03..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/capability
+++ /dev/null
@@ -1,21 +0,0 @@
-{
-    "___asflicense__": [
-         "",
-         "Licensed to the Apache Software Foundation (ASF) under one",
-         "or more contributor license agreements.  See the NOTICE file",
-         "distributed with this work for additional information",
-         "regarding copyright ownership.  The ASF licenses this file",
-         "to you under the Apache License, Version 2.0 (the",
-         "\"License\"); you may not use this file except in compliance",
-         "with the License.  You may obtain a copy of the License at",
-         "",
-         "     http://www.apache.org/licenses/LICENSE-2.0",
-         "",
-         "Unless required by applicable law or agreed to in writing, software",
-         "distributed under the License is distributed on an \"AS IS\" BASIS,",
-         "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
-         "See the License for the specific language governing permissions and",
-         "limitations under the License."
-     ],
-     "clusterMetrics":{"appsSubmitted":"0","appsCompleted":"0","appsPending":"0","appsRunning":"0","appsFailed":"0","appsKilled":"0","reservedMB":"0","availableMB":"4096","allocatedMB":"0","pendingMB":"0","reservedVirtualCores":"0","availableVirtualCores":"4","allocatedVirtualCores":"0","pendingVirtualCores":"0","containersAllocated":"0","containersReserved":"0","containersPending":"0","totalMB":"4096","totalVirtualCores":"4","utilizedMBPercent":"0","utilizedVirtualCoresPercent":"0","rmSchedulerBusyPercent":"-1","totalNodes":"1","lostNodes":"0","unhealthyNodes":"0","decommissioningNodes":"0","decommissionedNodes":"0","rebootedNodes":"0","activeNodes":"1","shutdownNodes":"0","containerAssignedPerSecond":"0","totalUsedResourcesAcrossPartition":{"memory":"0","vCores":"0","resourceInformations":{"resourceInformation":[{"attributes":null,"maximumAllocation":"9223372036854775807","minimumAllocation":"0","name":"memory-mb","resourceType":"COUNTABLE","units":"Mi","value":"0"},{"attributes":null,"maximumAllocation":"9223372036854775807","minimumAllocation":"0","name":"vcores","resourceType":"COUNTABLE","units":"","value":"0"}]}},"totalClusterResourcesAcrossPartition":{"memory":"4096","vCores":"4","resourceInformations":{"resourceInformation":[{"attributes":null,"maximumAllocation":"9223372036854775807","minimumAllocation":"0","name":"memory-mb","resourceType":"COUNTABLE","units":"Mi","value":"4096"},{"attributes":null,"maximumAllocation":"9223372036854775807","minimumAllocation":"0","name":"vcores","resourceType":"COUNTABLE","units":"","value":"4"}]}},"totalReservedResourcesAcrossPartition":{"memory":"0","vCores":"0","resourceInformations":{"resourceInformation":[{"attributes":null,"maximumAllocation":"9223372036854775807","minimumAllocation":"0","name":"memory-mb","resourceType":"COUNTABLE","units":"Mi","value":"0"},{"attributes":null,"maximumAllocation":"9223372036854775807","minimumAllocation":"0","name":"vcores","resourceType":"COUNTABLE","units":"","value":"0"}]}},"totalAllocatedContainersAcrossPartition":"0","crossPartitionMetricsAvailable":"true","rmEventQueueSize":"0","schedulerEventQueueSize":"0"}
-}
\ No newline at end of file
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/capacity-scheduler.xml b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/capacity-scheduler.xml
deleted file mode 100644
index a8487f3f3c0..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/capacity-scheduler.xml
+++ /dev/null
@@ -1,156 +0,0 @@
-<!--
-  Licensed under the Apache License, Version 2.0 (the "License");
-  you may not use this file except in compliance with the License.
-  You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License. See accompanying LICENSE file.
--->
-<configuration>
-
-  <property>
-    <name>yarn.scheduler.capacity.maximum-applications</name>
-    <value>10000</value>
-    <description>
-      Maximum number of applications that can be pending and running.
-    </description>
-  </property>
-
-  <property>
-    <name>yarn.scheduler.capacity.maximum-am-resource-percent</name>
-    <value>0.1</value>
-    <description>
-      Maximum percent of resources in the cluster which can be used to run
-      application masters i.e. controls number of concurrent running
-      applications.
-    </description>
-  </property>
-
-  <property>
-    <name>yarn.scheduler.capacity.resource-calculator</name>
-    <value>org.apache.hadoop.yarn.util.resource.DefaultResourceCalculator</value>
-    <description>
-      The ResourceCalculator implementation to be used to compare
-      Resources in the scheduler.
-      The default i.e. DefaultResourceCalculator only uses Memory while
-      DominantResourceCalculator uses dominant-resource to compare
-      multi-dimensional resources such as Memory, CPU etc.
-    </description>
-  </property>
-
-  <property>
-    <name>yarn.scheduler.capacity.root.queues</name>
-    <value>default,decided,target</value>
-    <description>
-      The queues at the this level (root is the root queue).
-    </description>
-  </property>
-
-  <property>
-    <name>yarn.scheduler.capacity.root.default.capacity</name>
-    <value>50</value>
-    <description>Default queue target capacity.</description>
-  </property>
-
-  <property>
-    <name>yarn.scheduler.capacity.root.target.capacity</name>
-    <value>10</value>
-    <description>target queue capacity.</description>
-  </property>
-
-  <property>
-    <name>yarn.scheduler.capacity.root.decided.capacity</name>
-    <value>40</value>
-    <description>decided queue capacity.</description>
-  </property>
-
-  <property>
-    <name>yarn.scheduler.capacity.root.default.user-limit-factor</name>
-    <value>1</value>
-    <description>
-      Default queue user limit a percentage from 0.0 to 1.0.
-    </description>
-  </property>
-
-  <property>
-    <name>yarn.scheduler.capacity.root.default.maximum-capacity</name>
-    <value>100</value>
-    <description>
-      The maximum capacity of the default queue.
-    </description>
-  </property>
-
-  <property>
-    <name>yarn.scheduler.capacity.root.default.state</name>
-    <value>RUNNING</value>
-    <description>
-      The state of the default queue. State can be one of RUNNING or STOPPED.
-    </description>
-  </property>
-
-  <property>
-    <name>yarn.scheduler.capacity.root.target.state</name>
-    <value>RUNNING</value>
-    <description>
-      The state of the target queue. State can be one of RUNNING or STOPPED.
-    </description>
-  </property>
-
-  <property>
-    <name>yarn.scheduler.capacity.root.default.acl_submit_applications</name>
-    <value>*</value>
-    <description>
-      The ACL of who can submit jobs to the default queue.
-    </description>
-  </property>
-
-  <property>
-    <name>yarn.scheduler.capacity.root.target.acl_submit_applications</name>
-    <value>*</value>
-    <description>
-      The ACL of who can submit jobs to the target queue.
-    </description>
-  </property>
-
-  <property>
-    <name>yarn.scheduler.capacity.root.default.acl_administer_queue</name>
-    <value>*</value>
-    <description>
-      The ACL of who can administer jobs on the default queue.
-    </description>
-  </property>
-
-  <property>
-    <name>yarn.scheduler.capacity.root.target.acl_administer_queue</name>
-    <value>*</value>
-    <description>
-      The ACL of who can administer jobs on the target queue.
-    </description>
-  </property>
-
-  <property>
-    <name>yarn.scheduler.capacity.root.decided.reservable</name>
-    <value>true</value>
-    <description>
-      indicates to the ReservationSystem that the queues resources
-      is available for users to reserve.
-    </description>
-  </property>
-
-  <property>
-    <name>yarn.scheduler.capacity.node-locality-delay</name>
-    <value>-1</value>
-    <description>
-      Number of missed scheduling opportunities after which the CapacityScheduler
-      attempts to schedule rack-local containers.
-      Typically this should be set to number of racks in the cluster, this
-      feature is disabled by default, set to -1.
-    </description>
-  </property>
-
-</configuration>
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/fair-scheduler.xml b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/fair-scheduler.xml
deleted file mode 100644
index cc00c45c97d..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/fair-scheduler.xml
+++ /dev/null
@@ -1,43 +0,0 @@
-<?xml version="1.0"?>
-<!--
-  Licensed under the Apache License, Version 2.0 (the "License");
-  you may not use this file except in compliance with the License.
-  You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License. See accompanying LICENSE file.
--->
-
-<!--
-  This file contains pool and user allocations for the Fair Scheduler.
-  Its format is explained in the Fair Scheduler documentation at
-  http://hadoop.apache.org/docs/current/hadoop-yarn/hadoop-yarn-site/FairScheduler.html.
-  The documentation also includes a sample config file.
--->
-
-<allocations>
-  <queue name="root">
-    <weight>1.0</weight>
-    <queue name="a">
-      <weight>0.33</weight>
-      <minResources>8192 mb, 4 vcores</minResources>
-      <maxResources>16384 mb, 8 vcores</maxResources>
-    </queue>
-    <queue name="b">
-      <weight>0.33</weight>
-      <minResources>8192 mb, 4 vcores</minResources>
-      <maxResources>16384 mb, 8 vcores</maxResources>
-    </queue>
-    <queue name="c">
-      <weight>0.34</weight>
-      <minResources>8192 mb, 4 vcores</minResources>
-      <maxResources>16384 mb, 8 vcores</maxResources>
-    </queue>
-  </queue>
-  <userMaxAppsDefault>5</userMaxAppsDefault>
-</allocations>
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/log4j.properties b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/log4j.properties
deleted file mode 100644
index 81a3f6ad5d2..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/log4j.properties
+++ /dev/null
@@ -1,19 +0,0 @@
-#   Licensed under the Apache License, Version 2.0 (the "License");
-#   you may not use this file except in compliance with the License.
-#   You may obtain a copy of the License at
-#
-#       http://www.apache.org/licenses/LICENSE-2.0
-#
-#   Unless required by applicable law or agreed to in writing, software
-#   distributed under the License is distributed on an "AS IS" BASIS,
-#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-#   See the License for the specific language governing permissions and
-#   limitations under the License.
-
-# log4j configuration used during build and unit tests
-
-log4j.rootLogger=info,stdout
-log4j.threshold=ALL
-log4j.appender.stdout=org.apache.log4j.ConsoleAppender
-log4j.appender.stdout.layout=org.apache.log4j.PatternLayout
-log4j.appender.stdout.layout.ConversionPattern=%d{ISO8601} %-5p [%t] %c{2} (%F:%M(%L)) - %m%n
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/profiles/sample-profiles-1.json b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/profiles/sample-profiles-1.json
deleted file mode 100644
index 8485ab6f3d5..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/profiles/sample-profiles-1.json
+++ /dev/null
@@ -1,24 +0,0 @@
-{
-    "___asflicense__": [
-        "",
-        "Licensed to the Apache Software Foundation (ASF) under one",
-        "or more contributor license agreements.  See the NOTICE file",
-        "distributed with this work for additional information",
-        "regarding copyright ownership.  The ASF licenses this file",
-        "to you under the Apache License, Version 2.0 (the",
-        "\"License\"); you may not use this file except in compliance",
-        "with the License.  You may obtain a copy of the License at",
-        "",
-        "     http://www.apache.org/licenses/LICENSE-2.0",
-        "",
-        "Unless required by applicable law or agreed to in writing, software",
-        "distributed under the License is distributed on an \"AS IS\" BASIS,",
-        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.",
-        "See the License for the specific language governing permissions and",
-        "limitations under the License."
-    ],
-    "default" : {
-        "memory-mb" : 2048,
-        "vcores" : 2
-    }
-}
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/yarn-site.xml b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/yarn-site.xml
deleted file mode 100644
index 94b7972dae7..00000000000
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/hadoop-yarn-server-router/src/test/resources/yarn-site.xml
+++ /dev/null
@@ -1,54 +0,0 @@
-<?xml version="1.0" encoding="UTF-8"?>
-<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
-<!--
-  Licensed under the Apache License, Version 2.0 (the "License");
-  you may not use this file except in compliance with the License.
-  You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
-  Unless required by applicable law or agreed to in writing, software
-  distributed under the License is distributed on an "AS IS" BASIS,
-  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-  See the License for the specific language governing permissions and
-  limitations under the License. See accompanying LICENSE file.
--->
-
-<configuration>
-  <property>
-    <name>yarn.resourcemanager.reservation-system.enable</name>
-    <value>true</value>
-  </property>
-  <property>
-    <name>yarn.node-labels.enabled</name>
-    <value>true</value>
-  </property>
-  <property>
-    <name>yarn.resourcemanager.webapp.address</name>
-    <value>0.0.0.0:8080</value>
-  </property>
-  <property>
-    <name>yarn.cluster.max-application-priority</name>
-    <value>50</value>
-  </property>
-  <property>
-    <name>yarn.resourcemanager.resource-profiles.enabled</name>
-    <value>true</value>
-  </property>
-  <property>
-    <name>yarn.resourcemanager.resource-profiles.source-file</name>
-    <value>profiles/sample-profiles-1.json</value>
-  </property>
-  <property>
-    <name>yarn.federation.policy-manager-params</name>
-    <value>{"routerPolicyWeights":{"entry":[{"key":{"id":"SC-2"},"value":"0.3"},{"key":{"id":"SC-1"},"value":"0.7"}]},"amrmPolicyWeights":{"entry":[{"key":{"id":"SC-2"},"value":"0.4"},{"key":{"id":"SC-1"},"value":"0.6"}]},"headroomAlpha":"1.0"}</value>
-  </property>
-  <property>
-    <name>yarn.resourcemanager.cluster-id</name>
-    <value>local-cluster</value>
-  </property>
-  <property>
-    <name>yarn.router.interceptor.allow-partial-result.enable</name>
-    <value>true</value>
-  </property>
-</configuration>
diff --git a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/pom.xml b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/pom.xml
index bc89f53f578..d30ba8bee60 100644
--- a/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/pom.xml
+++ b/hadoop-yarn-project/hadoop-yarn/hadoop-yarn-server/pom.xml
@@ -45,7 +45,6 @@
     <module>hadoop-yarn-server-timelineservice</module>
     <module>hadoop-yarn-server-timelineservice-hbase</module>
     <module>hadoop-yarn-server-timelineservice-hbase-tests</module>
-    <module>hadoop-yarn-server-router</module>
     <module>hadoop-yarn-server-timelineservice-documentstore</module>
     <module>hadoop-yarn-server-globalpolicygenerator</module>
   </modules>
diff --git a/hadoop-yarn-project/pom.xml b/hadoop-yarn-project/pom.xml
index 1b63feee876..da50ab149ad 100644
--- a/hadoop-yarn-project/pom.xml
+++ b/hadoop-yarn-project/pom.xml
@@ -73,10 +73,6 @@
       <groupId>org.apache.hadoop</groupId>
       <artifactId>hadoop-yarn-server-web-proxy</artifactId>
     </dependency>
-    <dependency>
-      <groupId>org.apache.hadoop</groupId>
-      <artifactId>hadoop-yarn-server-router</artifactId>
-    </dependency>
     <dependency>
       <groupId>org.apache.hadoop</groupId>
       <artifactId>hadoop-yarn-server-globalpolicygenerator</artifactId>
