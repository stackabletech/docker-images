Subject: [PATCH] HBASE-25292 Improve InetSocketAddress usage discipline
 (#2669)

Network identities should be bound late. Remote addresses should be
resolved at the last possible moment, just before connect(). Network
identity mappings can change, so our code should not inappropriately
cache them. Otherwise we might miss a change and fail to operate normally.

Revert "HBASE-14544 Allow HConnectionImpl to not refresh the dns on errors"
Removes hbase.resolve.hostnames.on.failure and related code. We always
resolve hostnames, as late as possible.

Preserve InetSocketAddress caching per RPC connection. Avoids potential
lookups per Call.

Replace InetSocketAddress with Address where used as a map key. If we want
to key by hostname and/or resolved address we should be explicit about it.
Using Address chooses mapping by hostname and port only.

Add metrics for potential nameservice resolution attempts, whenever an
InetSocketAddress is instantiated for connect; and metrics for failed
resolution, whenever InetSocketAddress#isUnresolved on the new instance
is true.

* Use ServerName directly to build a stub key

* Resolve and cache ISA on a RpcChannel as late as possible, at first call

* Remove now invalid unit test TestCIBadHostname

We resolve DNS at the latest possible time, at first call, and do not
resolve hostnames for creating stubs at all, so this unit test cannot
work now.

Reviewed-by: Mingliang Liu <liuml07@apache.org>
Signed-off-by: Duo Zhang <zhangduo@apache.org>
---
Index: hbase-server/src/main/java/org/apache/hadoop/hbase/util/MethodTimer.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/util/MethodTimer.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/util/MethodTimer.java
new file mode 100644
--- /dev/null	(date 1701385840105)
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/util/MethodTimer.java	(date 1701385840105)
@@ -0,0 +1,75 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.hadoop.hbase.util;
+
+import java.util.LinkedHashMap;
+import java.util.Map;
+import org.apache.yetus.audience.InterfaceAudience;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+@InterfaceAudience.Private
+public class MethodTimer {
+
+  private static final Logger LOG = LoggerFactory.getLogger(MethodTimer.class);
+
+  private final long startTime;
+  private final Map<String, Long> checkpoints = new LinkedHashMap<>();
+
+  public MethodTimer() {
+    startTime = EnvironmentEdgeManager.currentTime();
+  }
+
+  public void checkpoint(String identifier) {
+    checkpoints.put(identifier, EnvironmentEdgeManager.currentTime());
+  }
+
+  public void endAndLogIfSlow(long threshold) {
+    checkpoint("End");
+
+    long endTime = EnvironmentEdgeManager.currentTime();
+    long totalTime = endTime - startTime;
+    if (totalTime > threshold) {
+      StringBuilder builder = new StringBuilder();
+      int size = checkpoints.size();
+
+      builder.append('[');
+      long lastCheckpoint = startTime;
+      int count = 0;
+      for (Map.Entry<String, Long> entry : checkpoints.entrySet()) {
+        long currentCheckpoint = entry.getValue();
+        builder.append(entry.getKey());
+        builder.append(" -> ");
+        builder.append(currentCheckpoint - startTime);
+        builder.append("/");
+        builder.append(currentCheckpoint - lastCheckpoint);
+
+        count++;
+        // Append ", " only if it's not the last element
+        if (count < size) {
+          builder.append(", ");
+        }
+        lastCheckpoint = entry.getValue();
+      }
+      builder.append(']');
+
+      LOG.info("STACKABLE slow get detected. Total Execution Time: {}ms. Timings: {}", totalTime,
+        builder);
+    }
+  }
+}
Index: hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServer.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServer.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServer.java
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServer.java	(revision e04956f7bb5d95a54612a99905ee2d8e7f0de23a)
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/MetricsRegionServer.java	(date 1701182891572)
@@ -62,7 +62,7 @@
   // Incremented per write.
   private Meter serverWriteQueryMeter;
   protected long slowMetricTime;
-  protected static final int DEFAULT_SLOW_METRIC_TIME = 1000; // milliseconds
+  public static final int DEFAULT_SLOW_METRIC_TIME = 1000; // milliseconds
 
   public MetricsRegionServer(MetricsRegionServerWrapper regionServerWrapper, Configuration conf,
       MetricsTable metricsTable) {
Index: hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java	(revision e04956f7bb5d95a54612a99905ee2d8e7f0de23a)
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/regionserver/RSRpcServices.java	(date 1701422978372)
@@ -142,6 +142,7 @@
 import org.apache.hadoop.hbase.util.Bytes;
 import org.apache.hadoop.hbase.util.DNS;
 import org.apache.hadoop.hbase.util.EnvironmentEdgeManager;
+import org.apache.hadoop.hbase.util.MethodTimer;
 import org.apache.hadoop.hbase.util.Pair;
 import org.apache.hadoop.hbase.util.ServerRegionReplicaUtil;
 import org.apache.hadoop.hbase.wal.WAL;
@@ -260,6 +261,8 @@
 import org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.CompactionDescriptor;
 import org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.FlushDescriptor;
 import org.apache.hadoop.hbase.shaded.protobuf.generated.WALProtos.RegionEventDescriptor;
+import static org.apache.hadoop.hbase.regionserver.MetricsRegionServer.DEFAULT_SLOW_METRIC_TIME;
+import static org.apache.hadoop.hbase.regionserver.MetricsRegionServer.SLOW_METRIC_TIME;
 
 /**
  * Implements the regionserver RPC services.
@@ -312,7 +315,7 @@
 
   // Request counter for rpc scan
   final LongAdder rpcScanRequestCount = new LongAdder();
-  
+
   // Request counter for scans that might end up in full scans
   final LongAdder rpcFullScanRequestCount = new LongAdder();
 
@@ -357,6 +360,9 @@
    * Row size threshold for multi requests above which a warning is logged
    */
   private final int rowSizeWarnThreshold;
+
+  private final long slowOperationWarningThreshold;
+
   /*
    * Whether we should reject requests with very high no of rows i.e. beyond threshold
    * defined by rowSizeWarnThreshold
@@ -1207,6 +1213,8 @@
     rejectRowsWithSizeOverThreshold =
       conf.getBoolean(REJECT_BATCH_ROWS_OVER_THRESHOLD, DEFAULT_REJECT_BATCH_ROWS_OVER_THRESHOLD);
 
+    slowOperationWarningThreshold = conf.getLong(SLOW_METRIC_TIME, DEFAULT_SLOW_METRIC_TIME);
+
     final RpcSchedulerFactory rpcSchedulerFactory;
     try {
       rpcSchedulerFactory = getRpcSchedulerFactoryClass().asSubclass(RpcSchedulerFactory.class)
@@ -2559,7 +2567,6 @@
       requestCount.increment();
       rpcGetRequestCount.increment();
       region = getRegion(request.getRegion());
-
       GetResponse.Builder builder = GetResponse.newBuilder();
       ClientProtos.Get get = request.getGet();
       // An asynchbase client, https://github.com/OpenTSDB/asynchbase, starts by trying to do
@@ -2575,7 +2582,6 @@
       Result r = null;
       RpcCallContext context = RpcServer.getCurrentCall().orElse(null);
       quota = getRpcQuotaManager().checkQuota(region, OperationQuota.OperationType.GET);
-
       Get clientGet = ProtobufUtil.toGet(get);
       if (get.getExistenceOnly() && region.getCoprocessorHost() != null) {
         existence = region.getCoprocessorHost().preExists(clientGet);
@@ -2636,6 +2642,8 @@
 
   private Result get(Get get, HRegion region, RegionScannersCloseCallBack closeCallBack,
       RpcCallContext context) throws IOException {
+    MethodTimer timer = new MethodTimer();
+
     region.prepareGet(get);
     boolean stale = region.getRegionInfo().getReplicaId() != 0;
 
@@ -2643,6 +2651,7 @@
     List<Cell> results = new ArrayList<>();
     long before = EnvironmentEdgeManager.currentTime();
     // pre-get CP hook
+    timer.checkpoint("start_preget");
     if (region.getCoprocessorHost() != null) {
       if (region.getCoprocessorHost().preGet(get, results)) {
         region.metricsUpdateForGet(results, before);
@@ -2650,14 +2659,19 @@
             .create(results, get.isCheckExistenceOnly() ? !results.isEmpty() : null, stale);
       }
     }
+    timer.checkpoint("end_preget");
     Scan scan = new Scan(get);
     if (scan.getLoadColumnFamiliesOnDemandValue() == null) {
       scan.setLoadColumnFamiliesOnDemand(region.isLoadingCfsOnDemandDefault());
     }
     RegionScannerImpl scanner = null;
     try {
+      timer.checkpoint("start_getscanner");
       scanner = region.getScanner(scan);
+      timer.checkpoint("end_getscanner");
+      timer.checkpoint("start_scannernext");
       scanner.next(results);
+      timer.checkpoint("end_scannernext");
     } finally {
       if (scanner != null) {
         if (closeCallBack == null) {
@@ -2677,10 +2691,14 @@
     }
 
     // post-get CP hook
+    timer.checkpoint("start_postget");
     if (region.getCoprocessorHost() != null) {
       region.getCoprocessorHost().postGet(get, results);
     }
     region.metricsUpdateForGet(results, before);
+    timer.checkpoint("end_postget");
+
+    timer.endAndLogIfSlow(slowOperationWarningThreshold);
 
     return Result.create(results, get.isCheckExistenceOnly() ? !results.isEmpty() : null, stale);
   }
