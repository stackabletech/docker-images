#!/bin/sh
#
# Call`bin/hbase snapshot export` with the AWS libraries on the
# classpath and an extended core-site.xml
#
# The following environment variables must be set if the snapshot is
# copied from or to S3:
#   * AWS_ACCESS_KEY_ID - AWS access key ID
#   * AWS_SECRET_KEY - AWS secret key
#   * AWS_ENDPOINT - S3 endpoint to connect to, e.g.
#     "http://minio:9000/"
#   * AWS_SSL_ENABLED - Enable or disable SSL connections to S3, e.g.
#     "true" or "false"
#   * AWS_PATH_STYLE_ACCESS - Enable or disable S3 path style access,
#     e.g. "true" or "false"
#
# Example:
#   export \
#       AWS_ACCESS_KEY_ID=my-access-key \
#       AWS_SECRET_KEY=my-secret-key \
#       AWS_ENDPOINT=http://minio:9000/ \
#       AWS_SSL_ENABLED=false \
#       AWS_PATH_STYLE_ACCESS=true
#   export-snapshot-to-s3 \
#       --snapshot my-snapshot \
#       --copy-to s3a://my-bucket/my-snapshot
set -eu

append_path() {
  if [ -z "$1" ]; then
    echo "$2"
  else
    echo "$1:$2"
  fi
}

# Append AWS JARs to the HBase classpath
HBASE_CLASSPATH=$(append_path "${HBASE_CLASSPATH:-}" "${LIBS}")
export HBASE_CLASSPATH

# Copy the configuration files to a temporary directory, so that they
# can be modified.
CONF_DIR=$(mktemp --directory)
cp /stackable/conf/* "$CONF_DIR"

# Add the `fs.s3a.*` properties to the core-site.xml, so that they are
# read from environment variables. The environment variables
# AWS_ACCESS_KEY_ID and AWS_SECRET_KEY are already read by the Hadoop
# tools. Unfortunately, the Java system properties are not considered.
#
# The expressions `${env...}` must not be expanded by the shell and
# therefore the sed script is intentionally enclosed in single quotes:
# shellcheck disable=SC2016
sed --in-place '/<\/configuration>/{
    i <property><name>fs.s3a.endpoint</name><value>${env.AWS_ENDPOINT}</value></property>
    i <property><name>fs.s3a.connection.ssl.enabled</name><value>${env.AWS_SSL_ENABLED:-true}</value></property>
    i <property><name>fs.s3a.path.style.access</name><value>${env.AWS_PATH_STYLE_ACCESS:-false}</value></property>
}' "$CONF_DIR/core-site.xml"

# The HDFS JARs are not on the CLASSPATH when calling
# `hbase snapshot export` which results in the error
# 'No FileSystem for scheme "hdfs"'. Passsing the argument
# `--internal-classpath` solves this problem.
/stackable/hbase-${PRODUCT}/bin/hbase \
    --config "$CONF_DIR" \
    --internal-classpath \
    snapshot export "$@"

rm --recursive "$CONF_DIR"
